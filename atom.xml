<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>IPCreator</title>
  <subtitle>Growing up is the only password.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://ipcreator.me/"/>
  <updated>2017-03-03T12:30:12.689Z</updated>
  <id>http://ipcreator.me/</id>
  
  <author>
    <name>For life</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Thanks to...</title>
    <link href="http://ipcreator.me/2017/12/31/MyView/Diary/special-thanks/"/>
    <id>http://ipcreator.me/2017/12/31/MyView/Diary/special-thanks/</id>
    <published>2017-12-31T15:59:06.000Z</published>
    <updated>2017-03-03T12:30:12.689Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://okkntqe2h.bkt.clouddn.com/thanks.png" alt=""></p>
<p>Standing on Shoulders of Giants</p>
<p>站在巨人的肩上，才有可能在有限的时间里取得最大的成绩…</p>
<p>发现趋势，追随趋势，顺势而安、乘势而起、造势而雄，不做旁观者，要成弄潮儿<br>如果进入了痛苦的高原期，请记住：付出与收获成正比，成功之路本身就不轻松，与戴皇冠必承其重，<br>此时，你需要坚信自己的判断和选择，坚持、坚持再坚持，基于量变到质变的法则，<br>一般都会“踏破铁鞋无觅处，得来全不费工夫”，届时，”待到山花烂漫时，君在丛中笑”。</p>
<p>学之者不如好之者，好之者不如乐之者，兴趣是最好的老师<br>化整为零，先易后难，循序渐进，各个击破，坚持是成功的密码，自胜者强</p>
<p>若贪多求快，则欲速不达<br>若聚焦极致，则迎刃而解</p>
 <a id="more"></a>
<h2 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/nougat_bg.jpg" alt=""><br><a href="https://developer.android.com/index.html" target="_blank" rel="external">Android</a>——See what’s new with Android - from phones to watches and more.<br><a href="http://blog.csdn.net/guolin_blog" target="_blank" rel="external">郭霖的专栏</a>——每当你在感叹，如果有这样一个东西就好了的时候，请注意，其实这是你的机会<br><a href="http://blog.csdn.net/luoshengyang" target="_blank" rel="external">老罗的Android之旅</a>——爱生活，爱Android<br><a href="http://hukai.me/" target="_blank" rel="external">胡凯</a><br><a href="http://blog.csdn.net/eclipsexys" target="_blank" rel="external">eclipse_xu</a><br><a href="http://hukai.me/android-training-course-in-chinese/index.html" target="_blank" rel="external">Android官方培训课程中文版(v0.9.7)</a><br><a href="http://blog.csdn.net/aqi00/article/details/50012511" target="_blank" rel="external">湖前琴亭</a>——好好做技术，认真写博文<br><a href="https://book.douban.com/subject/26855851/" target="_blank" rel="external">Android群英传</a>——神兵利器<br><a href="https://book.douban.com/subject/26644935/" target="_blank" rel="external">Android源码设计模式解析与实战</a><br><a href="https://book.douban.com/subject/26915433/" target="_blank" rel="external">第一行代码：Android（第2版）</a><br><a href="https://book.douban.com/subject/19986441/" target="_blank" rel="external">Android系统源代码情景分析</a></p>
<h2 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h2><p><img src="https://camo.githubusercontent.com/ee91ac3c9f5ad840ebf70b54284498fe0e6ddb92/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f74665f6c6f676f5f7472616e73702e706e67" alt=""><br><a href="https://www.tensorflow.org/" target="_blank" rel="external">TensorFlow</a>——An open-source software library for Machine Intelligence<br><a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">tensorflow</a><br><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples" target="_blank" rel="external">tensorflow examples</a><br><a href="https://github.com/miyosuda/TensorFlowAndroidDemo" target="_blank" rel="external">TensorFlowAndroidDemo</a><br><a href="https://github.com/miyosuda/TensorFlowAndroidMNIST" target="_blank" rel="external">TensorFlowAndroidMNIST</a><br><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" target="_blank" rel="external">TensorFlow 官方文档中文版</a><br><a href="https://github.com/tobegit3hub/deep_recommend_system" target="_blank" rel="external">deep_recommend_system</a><br><a href="https://github.com/FishermanZzhang/ID-Card_with_TensorFlow_Opencv_in_Android" target="_blank" rel="external">ID-Card_with_TensorFlow_Opencv_in_Android</a><br><a href="https://github.com/natanielruiz/android-yolo" target="_blank" rel="external">android-yolo</a>——Real-time object detection on Android using the YOLO network with TensorFlow<br><a href="https://github.com/dongchangzhang/NewFeelings" target="_blank" rel="external">NewFeelings</a>——Android平台相册应用，使用Google开源机器学习框架tensorflow处理图片以提供更好的图片浏览体验<br><a href="https://github.com/aerdy/Android-Tensorflow-Sample" target="_blank" rel="external">TensorFlow Android Camera Demo</a><br><a href="https://book.douban.com/subject/26708119/" target="_blank" rel="external">机器学习</a><br><a href="https://book.douban.com/subject/26838557/" target="_blank" rel="external">智能时代</a>——大数据与智能革命重新定义未来<br><a href="https://book.douban.com/subject/10750155/" target="_blank" rel="external">数学之美</a><br><a href="https://book.douban.com/subject/19949020/" target="_blank" rel="external">程序员的数学</a>——编程的基础是计算机科学，而计算机科学的基础是数学。<br><a href="https://book.douban.com/subject/26593822/" target="_blank" rel="external">程序员的数学 2概率统计</a><br><a href="https://book.douban.com/subject/26740548/" target="_blank" rel="external">程序员的数学 3线性代数</a></p>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/github-logo.jpg" alt=""><br><a href="https://github.com/" target="_blank" rel="external">Github</a><br><a href="https://coding.net/" target="_blank" rel="external">Coding</a><br><a href="http://stackoverflow.com/" target="_blank" rel="external">Stack Overflow</a><br><a href="http://www.qiniu.com/pricing" target="_blank" rel="external">七牛</a><br><a href="http://www.google.com/ncr" target="_blank" rel="external">Google</a><br><a href="http://zhibimo.com/read/xiaolai/everyone-can-use-english/" target="_blank" rel="external">English</a><br><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="external">Git教程</a><br><a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">Python教程</a><br><a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="external">hexo-theme-yilia</a><br><a href="https://atom.io/" target="_blank" rel="external">atom</a>——A hackable text editor for the 21st Century<br><a href="https://book.douban.com/subject/10794788/" target="_blank" rel="external">鸟哥的Linux私房菜（第三版）</a><br><a href="https://book.douban.com/subject/5333562/" target="_blank" rel="external">深入理解计算机系统</a><br><a href="大话数据结构"></a><br><a href="大话设计模式"></a><br><a href="https://book.douban.com/subject/26829016/" target="_blank" rel="external">Python编程：从入门到实践</a><br><a href="https://book.douban.com/subject/25708312/" target="_blank" rel="external">C++ Primer 中文版（第 5 版）</a><br><a href="https://book.douban.com/subject/2130190/" target="_blank" rel="external">Java编程思想 （第4版）</a><br><a href="https://book.douban.com/subject/1139336/" target="_blank" rel="external">C程序设计语言</a></p>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p><a href="http://stormzhang.com/android/2014/07/07/learn-android-from-rookie/" target="_blank" rel="external">ANDROID学习之路</a><br><a href="https://zhuanlan.zhihu.com/p/19959253?columnSlug=xiao-jing-mo" target="_blank" rel="external">编程入门指南 v1.5</a></p>
<h2 id="Open-Source"><a href="#Open-Source" class="headerlink" title="Open Source"></a>Open Source</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/Example1.gif" alt=""><br><a href="https://github.com/airbnb/lottie-android" target="_blank" rel="external">lottie-android</a><br><a href="https://github.com/zhongyao/Android-Universal-Image-Loader" target="_blank" rel="external">Android-Universal-Image-Loader</a><br><a href="https://github.com/koral--/android-gif-drawable" target="_blank" rel="external">android-gif-drawable</a><br><a href="https://github.com/wasabeef/awesome-android-ui" target="_blank" rel="external">awesome-android-ui</a><br><a href="https://github.com/Trinea/android-open-project" target="_blank" rel="external">android-open-project</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/thanks.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Standing on Shoulders of Giants&lt;/p&gt;
&lt;p&gt;站在巨人的肩上，才有可能在有限的时间里取得最大的成绩…&lt;/p&gt;
&lt;p&gt;发现趋势，追随趋势，顺势而安、乘势而起、造势而雄，不做旁观者，要成弄潮儿&lt;br&gt;如果进入了痛苦的高原期，请记住：付出与收获成正比，成功之路本身就不轻松，与戴皇冠必承其重，&lt;br&gt;此时，你需要坚信自己的判断和选择，坚持、坚持再坚持，基于量变到质变的法则，&lt;br&gt;一般都会“踏破铁鞋无觅处，得来全不费工夫”，届时，”待到山花烂漫时，君在丛中笑”。&lt;/p&gt;
&lt;p&gt;学之者不如好之者，好之者不如乐之者，兴趣是最好的老师&lt;br&gt;化整为零，先易后难，循序渐进，各个击破，坚持是成功的密码，自胜者强&lt;/p&gt;
&lt;p&gt;若贪多求快，则欲速不达&lt;br&gt;若聚焦极致，则迎刃而解&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Growing Up" scheme="http://ipcreator.me/tags/Growing-Up/"/>
    
  </entry>
  
  <entry>
    <title>Dev Bugs</title>
    <link href="http://ipcreator.me/2017/12/31/MyView/Diary/Tech/android-trouble-resolver/"/>
    <id>http://ipcreator.me/2017/12/31/MyView/Diary/Tech/android-trouble-resolver/</id>
    <published>2017-12-31T14:59:06.000Z</published>
    <updated>2017-03-03T12:28:44.577Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://om8nmvpn9.bkt.clouddn.com/wiseman.jpeg" alt=""></p>
<p>什么是智者？就是一个坑不跌两回呗</p>
<p>The wiser man doesn’t fall into the same pit twice.</p>
 <a id="more"></a>
<h2 id="模拟器离线"><a href="#模拟器离线" class="headerlink" title="模拟器离线"></a>模拟器离线</h2><p>通过DDMS的File Explorer查看文件提示<br>com.android.ddmlib.AdbCommandRejectedException: device offline</p>
<p>【解决办法】在cmd下输入：<br>Step1：  adb kill-server<br>Step2： adb start-server<br>或者打开进程管理器，把adb关掉，再重启adb。</p>
<h2 id="button透明"><a href="#button透明" class="headerlink" title="button透明"></a>button透明</h2><figure class="highlight arduino"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">半透明&lt;Button android:<span class="built_in">background</span>=<span class="string">"#11000000"</span>  /&gt;</div><div class="line">透明&lt;Button android:<span class="built_in">background</span>=<span class="string">"#00000000"</span> /&gt;</div></pre></td></tr></table></figure>
<p><strong>原理</strong>：颜色和不透明度 (alpha) 值以十六进制表示法表示。任何一种颜色的值范围都是 0 到 255（00 到 ff）。对于 alpha，00 表示完全透明，ff 表示完全不透明。表达式顺序是“aabbggrr”，其中“aa=alpha”（00 到 ff）；“bb=blue”（00 到 ff）；“gg=green”（00 到 ff)；“rr=red”（00 到 ff）。所以要实现半透明只需将‘bb’,‘gg’,‘rr’的值都设为‘00’，只调节‘aa’的值（00到方法）就可以控制不同的透明度。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://om8nmvpn9.bkt.clouddn.com/wiseman.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;什么是智者？就是一个坑不跌两回呗&lt;/p&gt;
&lt;p&gt;The wiser man doesn’t fall into the same pit twice.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>RollPlayer</title>
    <link href="http://ipcreator.me/2017/03/03/MyView/Diary/Tech/my-favor-music-player/"/>
    <id>http://ipcreator.me/2017/03/03/MyView/Diary/Tech/my-favor-music-player/</id>
    <published>2017-03-03T01:42:06.000Z</published>
    <updated>2017-03-03T12:28:12.825Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://om8nmvpn9.bkt.clouddn.com/music.png" alt=""></p>
<p>做自己喜欢又擅长的，同时解决生活中的实际痛点，简单极致、有用有趣，It’s my life.</p>
 <a id="more"></a>
<h2 id="项目需求"><a href="#项目需求" class="headerlink" title="项目需求"></a>项目需求</h2><p>功能要求：一个窗口，一个目录，一些自己喜欢的歌曲，随机选择歌曲，支持单曲循环播放，支持歌词显示；<br>应用场景：徒步、登山、坐享时使用。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://om8nmvpn9.bkt.clouddn.com/music.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;做自己喜欢又擅长的，同时解决生活中的实际痛点，简单极致、有用有趣，It’s my life.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>AndroidStudio技巧</title>
    <link href="http://ipcreator.me/2017/03/03/Program/Resources/tips-of-androidstudio/"/>
    <id>http://ipcreator.me/2017/03/03/Program/Resources/tips-of-androidstudio/</id>
    <published>2017-03-03T00:31:06.000Z</published>
    <updated>2017-03-03T00:45:28.726Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.codeceo.com/article/android-studio-skills.html" target="_blank" rel="external">提高效率的 Android Studio 技巧汇总</a></p>
<p><img src="http://static.codeceo.com/images/2015/08/android-studio-logo.png" alt=""></p>
<p>工欲善其事必先利其器，磨刀不误砍柴工</p>
 <a id="more"></a>
<h2 id="Enter和Tab在代码提示时的区别"><a href="#Enter和Tab在代码提示时的区别" class="headerlink" title="Enter和Tab在代码提示时的区别"></a>Enter和Tab在代码提示时的区别</h2><p> 看图!<br> <img src="http://static.codeceo.com/images/2015/11/0ff1495a69e7f791a6f664f279016617.gif" alt=""></p>
<h2 id="Bookmarks"><a href="#Bookmarks" class="headerlink" title="Bookmarks!"></a>Bookmarks!</h2><p>如其名，书签。帮助快速回到指定的位置，实际使用中简直爽得不行。</p>
<p><strong>f11</strong></p>
<p>将当前位置添加到书签中或者从书签中移除。</p>
<p><strong>shift+f11</strong></p>
<p>显示有哪些书签。</p>
<p><img src="http://static.codeceo.com/images/2015/11/6d48930da07ca6c8858aad67e9be48c1.gif" alt=""></p>
<h2 id="The-File-Structure-Popup"><a href="#The-File-Structure-Popup" class="headerlink" title="The File Structure Popup"></a>The File Structure Popup</h2><p><strong>ctrl+f12</strong></p>
<p>此快捷键可以调出当前文件的大纲，并通过模糊匹配快速跳转至指定的方法。<br>勾选上“show anonymous classes”后其功能相当于Eclipse中的ctrl+o</p>
<p><img src="http://static.codeceo.com/images/2015/11/b9a22088dd4c98e411f2a2b1329fee16.gif" alt=""></p>
<h2 id="Hide-All-Panels"><a href="#Hide-All-Panels" class="headerlink" title="Hide All Panels"></a>Hide All Panels</h2><p><strong>ctrl + shit +F12</strong></p>
<p>关闭或者恢复其他窗口。在编写代码的时候非常方便的全屏编辑框，可以更加专心的coding…</p>
<p><img src="http://static.codeceo.com/images/2015/11/04e27f2ff4e98ae04802bb81b8ca54ab.gif" alt=""></p>
<h2 id="Parameter-Info"><a href="#Parameter-Info" class="headerlink" title="Parameter Info"></a>Parameter Info</h2><p><strong>ctrl+p</strong></p>
<p>在调用一些方法的时候免不了会忘记或者不知道此方法需要哪些参数。ctrl+p可以显示出此方法需要的参数。必备技能之一。</p>
<h2 id="Lines-Edit"><a href="#Lines-Edit" class="headerlink" title="Lines Edit"></a>Lines Edit</h2><p><strong>ctrl+y</strong><br>删除行</p>
<h2 id="Find-Actions"><a href="#Find-Actions" class="headerlink" title="Find Actions"></a>Find Actions</h2><p><strong>ctrl+shift+a</strong></p>
<p>对于没有设置快捷键或者忘记快捷键的菜单或者动作（Action），可能通过输入其名字快速调用。神技！！！</p>
<p>例如想要编译，只需要输入”release”，则列表框中就会出现”assembleRelease”选项，选择就可以进行编译。</p>
<p><img src="http://static.codeceo.com/images/2015/11/4e600b142e3e4d86398b7b4db66db33f.gif" alt=""></p>
<p><strong>分析堆栈信息</strong></p>
<p>Find Actions(ctrl+shift+a)输入 <strong>analyze stacktrace”</strong> 即可查看堆栈信息。<br><img src="http://static.codeceo.com/images/2015/11/3a824abd46773ba887c577f4cff1ff0c.gif" alt=""></p>
<p><strong>分析某个值的来源</strong><br>Find Actions(ctrl+shift+a)输入”Analyze Data Flow to Here”，可以查看某个变量某个参数其值是如何一路赋值过来的。<br>对于分析代码非常有用。<br><img src="http://static.codeceo.com/images/2015/11/2f68ddf53a1e6506c42e84b766ab6005.gif" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.codeceo.com/article/android-studio-skills.html&quot;&gt;提高效率的 Android Studio 技巧汇总&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.codeceo.com/images/2015/08/android-studio-logo.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;工欲善其事必先利其器，磨刀不误砍柴工&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>如何正确地写出单例模式</title>
    <link href="http://ipcreator.me/2017/03/03/Program/Concepts/how-to-write-singe-instance/"/>
    <id>http://ipcreator.me/2017/03/03/Program/Concepts/how-to-write-singe-instance/</id>
    <published>2017-03-03T00:31:06.000Z</published>
    <updated>2017-03-03T01:28:44.188Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/" target="_blank" rel="external">Jark’s Blog
</a></p>
<p>单例模式算是设计模式中最容易理解，也是最容易手写代码的模式了吧。但是其中的坑却不少，所以也常作为面试题来考。本文主要对几种单例写法的整理，并分析其优缺点。很多都是一些老生常谈的问题，但如果你不知道如何创建一个线程安全的单例，不知道什么是双检锁，那这篇文章可能会帮助到你。</p>
 <a id="more"></a>
<h2 id="懒汉式，线程不安全"><a href="#懒汉式，线程不安全" class="headerlink" title="懒汉式，线程不安全"></a>懒汉式，线程不安全</h2><p>当被问到要实现一个单例模式时，很多人的第一反应是写出如下的代码，包括教科书上也是这样教我们的。<br><figure class="highlight smali"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">public class Singleton &#123;</div><div class="line">   <span class="keyword"> private</span><span class="keyword"> static</span> Singleton instance;</div><div class="line">   <span class="keyword"> private</span> Singleton ()&#123;&#125;</div><div class="line"></div><div class="line">   <span class="keyword"> public</span><span class="keyword"> static</span> Singleton getInstance() &#123;</div><div class="line">    <span class="built_in"> if </span>(instance == null) &#123;</div><div class="line">        <span class="built_in"> instance </span>=<span class="built_in"> new </span>Singleton();</div><div class="line">     &#125;</div><div class="line">    <span class="built_in"> return </span>instance;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这段代码简单明了，而且使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例。也就是说在多线程下不能正常工作。</p>
<p>懒汉式，线程安全<br>为了解决上面的问题，最简单的方法是将整个 getInstance() 方法设为同步（synchronized）。<br><figure class="highlight smali"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">public<span class="keyword"> static</span> synchronized Singleton getInstance() &#123;</div><div class="line">   <span class="built_in"> if </span>(instance == null) &#123;</div><div class="line">       <span class="built_in"> instance </span>=<span class="built_in"> new </span>Singleton();</div><div class="line">    &#125;</div><div class="line">   <span class="built_in"> return </span>instance;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance() 方法。但是同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。这就引出了双重检验锁。</p>
<p><strong>双重检验锁</strong><br>双重检验锁模式（double checked locking pattern），是一种使用同步块加锁的方法。程序员称其为双重检查锁，因为会有两次检查 instance == null，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的 if，如果在同步块内不进行二次检验的话就会生成多个实例了。<br><figure class="highlight smali"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">public<span class="keyword"> static</span> Singleton getSingleton() &#123;</div><div class="line">   <span class="built_in"> if </span>(instance == null) &#123;                         //Single Checked</div><div class="line">        synchronized (Singleton.class) &#123;</div><div class="line">           <span class="built_in"> if </span>(instance == null) &#123;                 //Double Checked</div><div class="line">               <span class="built_in"> instance </span>=<span class="built_in"> new </span>Singleton();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">   <span class="built_in"> return </span>instance ;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这段代码看起来很完美，很可惜，它是有问题。主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。</p>
<ol>
<li>给 instance 分配内存</li>
<li>调用 Singleton 的构造函数来初始化成员变量</li>
<li>将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）<br>但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。</li>
</ol>
<p>我们只需要将 instance 变量声明成 volatile 就可以了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton instance; <span class="comment">//声明成 volatile</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getSingleton</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;                         </div><div class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</div><div class="line">                <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;       </div><div class="line">                    instance = <span class="keyword">new</span> Singleton();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> instance;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。</p>
<p>但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。</p>
<p>相信你不会喜欢这种复杂又隐含问题的方式，当然我们有更好的实现线程安全的单例模式的办法。</p>
<h2 id="饿汉式-static-final-field"><a href="#饿汉式-static-final-field" class="headerlink" title="饿汉式 static final field"></a>饿汉式 static final field</h2><p>这种方法非常简单，因为单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。<br><figure class="highlight smali"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">public class Singleton&#123;</div><div class="line">    //类加载时就初始化</div><div class="line">   <span class="keyword"> private</span><span class="keyword"> static</span><span class="keyword"> final</span> Singleton<span class="built_in"> instance </span>=<span class="built_in"> new </span>Singleton();</div><div class="line"></div><div class="line">   <span class="keyword"> private</span> Singleton()&#123;&#125;</div><div class="line"></div><div class="line">   <span class="keyword"> public</span><span class="keyword"> static</span> Singleton getInstance()&#123;</div><div class="line">       <span class="built_in"> return </span>instance;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种写法如果完美的话，就没必要在啰嗦那么多双检锁的问题了。缺点是它不是一种懒加载模式（lazy initialization），单例会在加载类后一开始就被初始化，即使客户端没有调用 getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如 Singleton 实例的创建是依赖参数或者配置文件的，在 getInstance() 之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。</p>
<h2 id="静态内部类-static-nested-class"><a href="#静态内部类-static-nested-class" class="headerlink" title="静态内部类 static nested class"></a>静态内部类 static nested class</h2><p>我比较倾向于使用静态内部类的方法，这种方法也是《Effective Java》上所推荐的。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;  </div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();  </div><div class="line">    &#125;  </div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </div><div class="line">        <span class="keyword">return</span> SingletonHolder.INSTANCE;</div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。</p>
<h2 id="枚举-Enum"><a href="#枚举-Enum" class="headerlink" title="枚举 Enum"></a>枚举 Enum</h2><p>用枚举写单例实在太简单了！这也是它最大的优点。下面这段代码就是声明枚举实例的通常做法。<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public <span class="class"><span class="keyword">enum</span> <span class="title">EasySingleton</span>&#123;</span></div><div class="line">    INSTANCE;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。但是还是很少看到有人这样写，可能是因为不太熟悉吧。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一般来说，单例模式有五种写法：懒汉、饿汉、双重检验锁、静态内部类、枚举。上述所说都是线程安全的实现，文章开头给出的第一种方法不算正确的写法。</p>
<p>就我个人而言，一般情况下直接使用饿汉式就好了，如果明确要求要懒加载（lazy initialization）会倾向于使用静态内部类，如果涉及到反序列化创建对象时会试着使用枚举的方式来实现单例。</p>
<h2 id="Read-More"><a href="#Read-More" class="headerlink" title="Read More"></a>Read More</h2><p><a href="http://javarevisited.blogspot.sg/2014/05/double-checked-locking-on-singleton-in-java.html" target="_blank" rel="external">Double Checked Locking on Singleton Class in Java</a><br><a href="http://javarevisited.blogspot.sg/2012/07/why-enum-singleton-are-better-in-java.html" target="_blank" rel="external">Why Enum Singleton are better in Java</a><br><a href="http://javarevisited.blogspot.com/2012/12/how-to-create-thread-safe-singleton-in-java-example.html" target="_blank" rel="external">How to create thread safe Singleton in Java</a><br><a href="http://javarevisited.blogspot.com/2011/03/10-interview-questions-on-singleton.html" target="_blank" rel="external">10 Singleton Pattern Interview questions in Java</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/&quot;&gt;Jark’s Blog
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;单例模式算是设计模式中最容易理解，也是最容易手写代码的模式了吧。但是其中的坑却不少，所以也常作为面试题来考。本文主要对几种单例写法的整理，并分析其优缺点。很多都是一些老生常谈的问题，但如果你不知道如何创建一个线程安全的单例，不知道什么是双检锁，那这篇文章可能会帮助到你。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>开源软件及国内发展现状</title>
    <link href="http://ipcreator.me/2017/03/02/Program/Concepts/history-of-open-source/"/>
    <id>http://ipcreator.me/2017/03/02/Program/Concepts/history-of-open-source/</id>
    <published>2017-03-02T01:33:06.000Z</published>
    <updated>2017-03-02T02:06:38.151Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.fmsoft.cn/zhcn/about/blog/185/" target="_blank" rel="external">魏永明</a>（飞漫软件CEO）。本文经章文嵩、陈渝审阅。</p>
<p><img src="http://cms.csdnimg.cn/article/201306/21/51c411d5c48fa.jpg" alt=""></p>
 <a id="more"></a>
<h2 id="1-开源是大势所趋"><a href="#1-开源是大势所趋" class="headerlink" title="1 开源是大势所趋"></a>1 开源是大势所趋</h2><p>随着计算机技术的发展，尤其是互联网技术和相关企业的兴起，开源软件在操作系统、编译工具链、数据库、WEB服务器、移动操作系统等各个方面已经成为主流。而且许多企业利用开源软件形成了独特的商业模式。比如谷歌的 Android 操作系统，从 2007 年开源发布第一个版本起，到今天已经发展到 4.1 版本，占据了智能手机操作系统一半以上的市场份额，谷歌也通过 Android 操作系统在移动互联网这一新兴行业中占据了领先和主导地位。再比如在服务器端广泛使用的关系型数据库 MySQL，在以开源软件和商业许可并行的模式下，得到了快速发展，并在 2008 年作价 10 亿美金由 Sun 收购（后者又在 2009 年被 Oracle 公司以 74 亿美金的高价收购）。相反，以前一直和开源软件做斗争的微软公司，却因为无法快速推出适应市场的 Windows Phone 操作系统，在移动互联网竞争中处于下风。为顺应潮流，微软也开始拥抱开源，比如向Samba项目贡献代码，放弃自己研发多年的大数据项目而选择Hadoop为其大数据的核心等。</p>
<p>显然，纵观 IT 行业这二十多年的发展，开源软件从黑客的理想之国，已经形成了一股推进计算机及相关行业不停进步的巨大力量。很多人可能尚未意识到，我们使用的电脑中运行有开源软件，手机中运行有开源软件，家里的电视也运行有开源软件，甚至小小的数码产品（如电子相框）中也运行有开源软件，尤其是互联网服务器端软件，几乎全部是开源软件。毫不夸张地说，开源软件已经渗透到了我们日常生活的方方面面。那么，开源软件到底什么，开源软件尤其是国内的开源软件及社区的现状如何，发展面临哪些困难和问题？</p>
<h2 id="2-开源软件的基本概念"><a href="#2-开源软件的基本概念" class="headerlink" title="2 开源软件的基本概念"></a>2 开源软件的基本概念</h2><p>在讲述国内开源软件的发展情况之前，我们先就开源软件的一些基本概念做一些普及。</p>
<h3 id="2-1-为什么会有开源软件？"><a href="#2-1-为什么会有开源软件？" class="headerlink" title="2.1 为什么会有开源软件？"></a>2.1 为什么会有开源软件？</h3><p>广义上讲，开源软件指所有公开源代码的软件，包括某些商业软件也可能是开源的。但我们通常所说的开源软件，是狭义上的，指任何人可以通过极低的成本（如仅仅访问互联网而无需其他额外费用）获得该软件源代码的软件，也就是其源代码向公众开放。和狭义上的开源软件相对应的，就是那些不向公众公开源代码的软件，通常就是商业软件。</p>
<p>实质上，在计算机出现的最初年代，几乎所有的软件都是开源的。那时的计算机企业，主要是以销售硬件产品为主，软件几乎都是附送的，加上那时的软件规模都不大，以源代码形式提供给用户还可以缓解一定的技术支持压力——有问题由用户自己修改解决。所以，最初的软件几乎都是以开源的方式提供的。因此，对着迷于计算机编程的工程师来讲，获得软件的源代码几乎是天经地义的事情。这样，当以微软为代表的企业开始实践纯软件产品的商业模式（核心思想是提供二进制可执行程序的使用许可，而不提供源代码），就引起了许多计算机编程爱好者的不满：给我一堆二进制程序，我如何才能按我自己的想法改进程序？在这种背景下，真正意义上的开源软件就自然而然地产生了。</p>
<h3 id="2-2-开源软件的发展历程"><a href="#2-2-开源软件的发展历程" class="headerlink" title="2.2 开源软件的发展历程"></a>2.2 开源软件的发展历程</h3><p>开源软件的发展，和互联网的发展密不可分。真正有规模的开源软件，应该是从上个世纪 90 年代开始进入公众视线，也就是互联网开始兴起的年代。我们大致可以将开源软件的发展分为如下三个阶段：</p>
<p>萌芽阶段（上世纪九十年代之前）。这个阶段主要以个人和大学为主，因为发布条件受限，大多数开源软件无法得到有效传播，而仅仅流传于互相熟悉的程序员和老师、学生之间。这个阶段的典型开源软件为 BSD 操作系统。</p>
<p>以非盈利组织为主的阶段。这个阶段应从上个世纪九十年代算起，说起这个阶段，我们不得不提到 Richard Stallman 发起的自由软件基金会，还有 Apache 基金会等。前者发起的 GNU 项目（1983 年发起，九十年代后随 Linux普及），成就了 Linux 操作系统；后者维护的 Apache WEB服务器，在互联网上几乎占据了统治地位。</p>
<p>以大型IT企业为主的阶段。这个阶段出现于 2005 年之后，以谷歌为代表的大型互联网企业，开始以各种方式发布开源软件，最为著名的是 Chrome 浏览器以及 Android 操作系统；当然还有 Intel、Nokia 等企业主导的 Moblin、MeeGo 等基于 Linux 的智能手机操作系统。</p>
<h3 id="2-3-开源软件许可证"><a href="#2-3-开源软件许可证" class="headerlink" title="2.3 开源软件许可证"></a>2.3 开源软件许可证</h3><p>笔者看来，软件作者选择向公众开放源代码，其理由无外乎如下三种：</p>
<p>第一，那些认为所有软件都应该以源代码方式发布的。如 Richard Stallman，他认为所有的软件都应该是开放源代码的，甚至为了建造一个理想中的全开源软件世界，创立了自由软件基金会，发明了 GPL 许可证，发起了 GNU 项目。</p>
<p>第二，通过开源软件展示自己的软件设计、算法和编码水平，并期望获得他人认可的。大部分小型软件或者程序的作者，或者由大学主持和维护的开源软件，出于这种目的向公众开放源代码。</p>
<p>第三，通过开源软件谋求获得广泛推广，并通过提供增值的产品或者服务来获得商业收益的。这通常是商业企业选择开源软件的原因。如 FireFox、MySQL、Android、WebKit 等属于这种情形。</p>
<p>为了达到上述三种不同的目的，人们在现有软件著作权的法律框架内，发明了多种用于开源软件的许可证。这些许可证从法律上帮助对开源软件有不同诉求的软件作者，获得自己想要的结果。要想具体了解这些许可证的实质内容，我们首先需要更加深入地了解软件著作权。</p>
<p>许多开发者对软件著作权只有一个初步的、模糊的认知。我们经常会在各种软件的启动画面或者关于对话框中刚看到类似“版权所有 (C) 2012 某公司；保留所有权利”的用语。这说明，软件著作权包含了很多权利，所以才有“保留所有权利”这样的说法。具体而言，软件著作权大致包括如下几个权利：</p>
<p><strong>署名权</strong>。就是署上自己大名的权利，向人们说明这是我的作品。这里的“我”，可能是个人，也可能是法人单位。</p>
<p><strong>修改权</strong>。就是是否可以修改软件，比如翻译软件界面中的文字。对非开源软件，就是是否允许你反编译软件并修改的权利。对开源软件来讲，就是修改其中可能存在的缺陷，或对一些代码进行优化、重构等等。</p>
<p><strong>复制权</strong>。就是将软件进行复制的权利。和图书类比，就是你能不能抄写和/或复印图书。</p>
<p><strong>发布权</strong>。就是将软件副本交给他人的权利，不管是收费的还是不收费的。</p>
<p>对商业软件而言，这些权利都被保留，意思是什么呢？就是说，你不能修改，也不能复制，还不能随便发布给别人。那用户能做什么，唯一的就是安装和使用这个软件了。当然，大部分商业软件都附带有一个《最终用户许可协议》，其中告诉了你能做什么，不能做什么。比如，你可以因为备份的原因复制这个软件。另外，还定义了很多免责条款，比如，如果 90 天内软件的存储介质损坏，可以免费替换；如果因为使用本软件导致数据丢失或损坏，概不负责之类的。</p>
<p>对开源软件而言，因为任何人可以几乎无成本获得软件的源代码或者最终程序，用户使用这个软件要是有了问题，都去询问作者，那作者就吃不消了。所以，开源软件也通常使用某个特定的许可证来约定作者以及使用者所承担的权利和义务。</p>
<p>自由软件基金会制定的 GPL 许可证，应该是开源软件使用的各种许可证中最为严格的。为了区别于其他开源软件，Richard Stallman 将使用 GPL 许可证的开源软件称为自由软件。GPL 许可证的核心内容是：</p>
<p>你可以随意复制和发布软件。如果以二进制方式发布软件，则必须能够让获得二进制版本的人，以不付出额外成本的方式获得其源代码。<br>你可以随意修改源代码。一旦要发布修改后的软件，必须同时发布修改后的源代码。也就是说，修改版本也必须以 GPL 许可证发布。这就是 GPL 许可证被称为病毒许可证的一个最重要原因。<br><strong>如果 GPL 软件作为其他软件的一部分使用（后者称为 GPL 软件的衍生作品），不论是静态链接还是动态链接，衍生作品也要遵循 GPL 许可证。这是 GPL 许可证被称为病毒许可证的另外一个重要原因。</strong><br>无任何担保。就是说，使用 GPL 软件，出了问题不要找原作者，你需要自己负责。</p>
<p>Richard Stallman 希望通过这样严格的 GPL 许可证，来建立一个所有软件均遵循 GPL 的理想软件世界。除了 Richard Stallman 所倡导的理想王国之外，还有许多个人和组织，以不同于自由软件的方式来发展开源软件。这些开源软件所使用的许可证相比 GPL 要宽松一些，或者很宽松。这些开源软件作者，通常属于本节前面所讲的第二、第三种人，所以他们使用的许可证有如下共同点：</p>
<p>&gt;<br>免担保，责任由使用者自负。<br>随便复制和发布。<br>不限制商用。</p>
<p>这些许可证的不同点在于：</p>
<p><strong>Apache 许可证</strong>：如有修改，必须保留已有的版权声明，且必须包含新的版权声明。通俗理解，就是要 <strong>保留原作者信息，也就是署名权</strong>。</p>
<p><strong>BSD 许可证</strong>：<strong>不允许在衍生软件作品中提原作者的名字</strong>，其理由是，因为你的修改可能污染原有代码，破坏原作品的品质。</p>
<p><strong>MIT 许可证</strong>：在衍生软件作品中，<strong>必须提原作者的名字</strong>；其理由是，原有代码作者应得到充分尊重。</p>
<p><strong>Mozilla 许可证（MPL）</strong>：就原有软件所做修改，必须可以以各种可能的方式发布其源代码（包括使用 GPL 许可证），且应该有修改说明。</p>
<p>除了上述许可证之外，还有一个广泛使用的 LGPL 许可证。该许可证最初是针对函数库专门制定的。为了避免类似 C 基础库这样的软件因为采用 GPL 许可证而让使用它的软件（衍生作品）成为 GPL 软件，从而定义了 LGPL 许可证。试想，如果 C 基础库也采用 GPL 许可证，那就失去了它本身存在的实际价值，因为其他任何非 GPL 软件都不能使用采用 GPL 的 C 基础库。所以，<strong>LGPL 定义，当 C 基础库这样的软件以动态链接的形式由其他软件使用时，这些软件就可以不遵守 GPL 许可证，甚至可以是商业软件。</strong> 另外，本某种角度看，LGPL 和 MPL 本质上是一样的。</p>
<p>当然，除了上面的各种许可证，还有的开源软件作者根本不关心保留什么权利，或者对其作品做什么样的约束，相反，这些作者开源其软件，就是为了“有用”，任何人拿这种软件做什么，对原作者来讲，都是无所谓的。这种软件亦称为“礼物软件”，相当于作者放弃了有关软件著作权的所有权利，也就是所谓置于“公共领域（public domain）”当中——随你怎么用。</p>
<h3 id="2-4-为什么开源软件会得到快速发展并广泛应用？"><a href="#2-4-为什么开源软件会得到快速发展并广泛应用？" class="headerlink" title="2.4 为什么开源软件会得到快速发展并广泛应用？"></a>2.4 为什么开源软件会得到快速发展并广泛应用？</h3><p>很多人不理解，既然作者这么大方地将源代码都公开了，只是为了“有用”，且不提供任何“担保”，看起来原作者是无法直接获利的，那为什么没有直接的利益驱动，开源软件却能够得到这么快速的发展和广泛应用呢？</p>
<p>笔者初探其原因，大致有四：</p>
<ol>
<li><p>开源软件虽说不提供任何担保，但既然原作者愿意公开源代码，说明作者对代码的质量还是非常有信心的。实际上，开源软件的作者通常都是编码高手（俗称“黑客”），其质量甚至超过某些商业软件。</p>
</li>
<li><p>开源软件因为其免费特征，能够得到大量用户的使用和验证，通过形成和用户（往往也是编码高手）之间的互动和交流，能够以最快的速度修复可能的缺陷，改善软件设计。Linux 内核的发展就形成了一个以全世界内核高手为主的松散社区，通过快速迭代开发，加上其免费特征，迅速占据了原先由商业 UNIX 系统控制的服务器操作系统领域。</p>
</li>
<li><p>因为任何人都可以得到其源代码，所以很多用户就可以自行修改其源代码，以满足自己的一些特别需求。</p>
</li>
<li><p>因为开源软件的涉及面非常广，利用已有的各种成熟开源软件，任何具有一定实力的组织，均可在较短时间内形成一个基本成熟的软件平台，进而可和已有的商业软件平台进行竞争。谷歌的 Android 系统属于此种情况的典型。</p>
</li>
</ol>
<p>所以，尽管开源软件的发展历程并不是一帆风顺的，但基于以上原因，开源软件显现出了其强大的生命力。各种基于开源软件的成功商业模式，也为开源软件的发展注入了加速剂。有关围绕开源软件的成功商业模式，可见本文第 4 章。</p>
<h2 id="3-国内开源软件的发展及社区现状"><a href="#3-国内开源软件的发展及社区现状" class="headerlink" title="3 国内开源软件的发展及社区现状"></a>3 国内开源软件的发展及社区现状</h2><h3 id="3-1-国内开源软件的发展简史"><a href="#3-1-国内开源软件的发展简史" class="headerlink" title="3.1 国内开源软件的发展简史"></a>3.1 国内开源软件的发展简史</h3><p>国内开源软件的发展大致始于 1997 年前后。那时，中国第一个（局部）互联网（CERNET）刚刚建立不久，1995 年在清华大学建立的著名水木清华 BBS 就是开源软件。自那之后，Linux 内核以及 GNU 项目中的成百上千个开源软件突然展现在国人的面前。在这之前，国内软件开发者，几乎没有人会认为获得程序的源代码是天经地义的事情（写到此处，笔者再次感叹文化和背景的不同所带来的认知差别）。但随着带有源代码的 Linux 操作系统随着互联网以及廉价光盘的广泛传播，当你能看到这些优秀的软件是如何设计和编写出来的的时候，我相信，大部分程序开发者都会和笔者一样——那心情岂止是“激动”两个字可以形容的？</p>
<p>在这样的背景下，中国也出现了一些开源软件。最初由国人开发的开源软件，主要解决的是 Linux 系统的汉化问题，流传最为广泛的应该是可以显示和输入中文的伪终端应用程序 CCE。在 1998 年之后的两三年内，出现了如下三个开源软件：</p>
<p>章文嵩博士开发的 LVS（Linux Virtual Server），后来被 Linux 内核收录，成为使用 Linux 操作系统搭建集群服务器的重要核心软件组件。</p>
<p>当时的清华大学博士生苏哲开发的 Smart Boot Manager，是一种引导管理器，类似现在流行的 GRUB，主要解决引导多种操作系统的问题。苏哲后来主持开发的 SCIM 系统，被各种流行的 Linux 发行版收录，成为了 Linux 操作系统上提供多语种输入法支持的标准框架。</p>
<p>笔者开发的 MiniGUI，后来由笔者创立的北京飞漫软件技术有限公司继续维护和发展，在功能手机、数码相框、工业控制系统和工业仪表中得到了广泛应用。</p>
<p>上述三个开源软件，成为中国开源软件早期的代表作，在国际上具有较强的影响力，很多台湾同行也知道这些软件，提起来往往是赞不绝口。</p>
<p>在此之后，国内开源软件的发展长期处于停滞状态，这和 2000 年左右 DotCOM 泡沫的破裂有一定的关系。DotCOM 泡沫的破裂，让许多梦想通过开源软件来创造商业奇迹的 Linux 发行版厂商很是受伤。比如，笔者曾经供职过的蓝点软件，在 NASDAQ OTCBB 板借壳上市，半年之内股价从 20 多美金跌到 0.2 美金，后于 2001 年贱卖。RedHat 等知名 Linux 发行版厂商也深受其害，另外一些抗跌能力不强的从事开源软件相关业务的企业更是一蹶不振，甚至关门大吉。</p>
<p>DotCOM 泡沫的破裂，给很多支持开源软件的理想主义者浇了一桶凉水，开源软件的商业化发展步伐减缓，从而影响了国内开源软件的发展。2000年前后几年，以北京、武汉等地的 LUG（Linux User Group）为代表的各类开源软件组织非常活跃，而从 2003 年开始，逐渐降温甚至消失。</p>
<p>但是，国际上深信理想主义的黑客文化并没有因为 Linux 发行版厂商的商业化遇阻而停止发展，Linux 内核、GNU 项目、GNOME 和 KDE 等等软件继续向前发展。同时，2005 年后，又出现了如下在当前 IT 领域有着举足轻重影响力的几款开源软件：</p>
<p><strong>Mozilla 基金会（以 Mozilla 基金会下属 Mozilla 公司的成立为准）以及 FireFox 浏览器</strong>。Mozilla 公司通过 FireFox 浏览器获得了来自谷歌等公司的大量合作收入，从而实践了没有赞助也能自负盈亏的商业模式。</p>
<p><strong>WebKit 浏览器引擎</strong>。WebKit 浏览器是苹果 Safari 浏览器、谷歌 Chrome 浏览器使用的浏览器核心引擎。WebKit 其实是由苹果公司发起的开源项目，在早期 KDE 系统的 KHTML 和 KJS 两个子系统基础上发展而来。</p>
<p><strong>谷歌的 Android 操作系统</strong>。Android 操作系统的上层虽然是虚拟机和 Java 应用，但底层却使用了大量开源软件，如 Linux 内核、SQLite 内嵌式数据库、FreeType 矢量字体渲染库等等。</p>
<p>显然，从 2005 年起，开源软件的发展从一个低谷重新引来了发展的高潮，而这次，与前述的第三个阶段吻合，即以大型 IT 企业为主导进行发展。在此期间，国内也出现了为数不多的一些开源软件项目，其中以清华大学陈渝副教授主持的 SkyEye 最具代表性。该项目旨在提供一个面向嵌入式软件开发和调试的 ARM 或其他架构的纯软件仿真器（虚拟机）。该项目持续活跃长达七年时间，吸引了许多来自海外的高手参与，是为数不多具有国际影响力，且充分体现了国际化协作、分享的开源软件项目。</p>
<p>与此同时，RedHat 以及国内的红旗等公司，也开始通过提供针对服务器的 Linux 定制版本而获得可观收入，之后，Ubuntu 这一在桌面系统上广泛应用的 Linux 发行版也实践了其成功的商业模式，占据了绝大部分 Linux 桌面发行版的市场份额。</p>
<p>2008年金融危机后，传统企业为了降低IT的总拥有成本逐步使用Linux和开源软件，尤其是金融企业，世界上主要证券交易所如纽约交易所、NASDAQ、东京交易所、伦敦交易所等先后迁移到Linux。这标志着开源软件进入了不可逆转的发展通道。</p>
<p>从 2005 年开始，国内的开源软件也开始进入上面所说的由大型企业主导的第三个阶段，参与开源项目的企业当中，最为活跃的是淘宝，接下来是新浪、百度、腾讯和华为等。同时，随着“开源中国”等社区的兴起，个人主持或者参与的开源软件逐渐多了起来。根据“开源中国”收录的开源软件，当前已经有一千多个由国人开发或者主持的开源软件。这和十年前相比，已经有了非常大的进步。有兴趣的读者可访问 <a href="http://www.oschina.net" target="_blank" rel="external">http://www.oschina.net</a> 了解。其中值得一提的开源软件有：</p>
<p><strong>TFS</strong>。TFS是一款由淘宝开发的分布式对象存储系统，于2010年9月开源，在淘宝它存储了几百亿张图片和交易快照。新浪微博已在生产系统中使用TFS作图片等对象存储。淘宝承诺发布的开源版本与自身使用的版本保持高度一致，并同步更新，这为国内开源软件的发展起到了积极的推动作用，TFS已经成为国内企业利用开源方式形成核心竞争力的典范。</p>
<p><strong>TAIR</strong>。TAIR 是一个高性能、可扩展、高可靠的分布式key/value存储系统，淘宝在2010年6月开源。在淘宝约有600台TAIR服务器广泛应用在Web服务器和数据库中间作对象缓存。国内的豆丁网等公司已使用TAIR。</p>
<p><strong>OceanBase</strong>。OceanBase是一个高性能海量数据库系统，由淘宝开发，于 2011 年 5 月开源。淘宝在其收藏夹等多项功能中使用该数据库，已经历实际应用的检验。</p>
<p><strong>RT-Thread</strong>。这是一个由国人主持开发的开源实时操作系统，曾获得“第六届中日韩开源软件竞赛”的技术优胜奖（其他两个技术优胜奖获得者为淘宝OceanBase 和红旗Qomo Linux）。RT-Thread 目前也获得了诸多商业应用。</p>
<p><strong>Linux Deepin</strong>。这是近几年发展起来的面向桌面的中文 Linux 发行版，由一群来自武汉的 Linux 高手发起并维护。</p>
<p><strong>ucore</strong>：2010 年暑假开始，陈渝博士组织清华大学学生开展教学用开源操作系统ucore的设计与实现，并直接用于清华大学的操作系统课程，学生可参考实验文档和ucore源码通过实践逐步深入掌握操作系统。这相对国内操作系统旧有的教学方法有较大改变，获得了国内外操作系统教学领域专家的认可，并将在教育部的支持下进行更大范围内的推广。</p>
<h3 id="3-2-国内开源软件的特点和问题"><a href="#3-2-国内开源软件的特点和问题" class="headerlink" title="3.2 国内开源软件的特点和问题"></a>3.2 国内开源软件的特点和问题</h3><p>但国内开源软件也存在很多问题，如缺乏重量级软件，缺乏持续维护和更新，质量一般，用户不多等等。另外，如开源中国创始人所言，国人所开发的这些开源软件，和国际主流开源软件脱节严重，绝大多数的状态是单打独斗。</p>
<p>比如淘宝主导或参与的开源软件，大多数和互联网服务器后台、云计算相关，这些项目的主要用户是淘宝自己。因为门户之见，这些软件很难被其他的互联网企业所使用，大家不停地“造轮子”而忽视了开源软件发展必须具备的“共享”、“协作”之精神。当然，这种情况正在改变，比如上面提到的淘宝 TFS 系统已被其他互联网企业使用，ucore 项目也得到了诸多国内、国外大学积极响应和支持。</p>
<p>笔者希望国内的开源软件作者能够和国际主流的开源软件步伐保持一致，摒弃门户之见，要么加入国际化的开源软件，要么将自己主持的开源软件逐步国际化。这样，我们的开源软件才能得到源源不断的前进动力，也才能在国际化舞台上扮演更加重要的角色。</p>
<h3 id="3-3-新的力量"><a href="#3-3-新的力量" class="headerlink" title="3.3 新的力量"></a>3.3 新的力量</h3><p>但不论如何，国内大型 IT 企业参与开源软件本身就是一个良好的开端，将为中国开源软件的发展起到非常大的促进作用。</p>
<p>与此同时，各种开源社区活动也越来越活跃，比如具有政府背景的“开源软件高峰论坛”和草根性质的“我们的开源软件”巡回展演等。在最近的“我们的开源软件”巡回展演中，参与介绍的开源软件多达几十种，参会人员众多，而这一切都是社区成员通过“微博”等方式发起和组织的。</p>
<p>这表明，开源软件即将在国内引起新一轮的发展浪潮。</p>
<h2 id="4-开源我的软件？"><a href="#4-开源我的软件？" class="headerlink" title="4 开源我的软件？"></a>4 开源我的软件？</h2><p>在高物价、高房价的今天，大部分人对此问题的第一反应是：“我就一刚解决温饱的码农，我开源，谁养我？”这问题，和我们在十年前推广开源软件理念时遇到的问题几乎一样。但其实，这话已经大大落后于时代了！我们不仅仅可以通过使用其他人的开源软件赚钱，还可以通过开源自己的软件来赚钱。</p>
<h3 id="4-1-别人靠开源软件如何赚钱？"><a href="#4-1-别人靠开源软件如何赚钱？" class="headerlink" title="4.1 别人靠开源软件如何赚钱？"></a>4.1 别人靠开源软件如何赚钱？</h3><p>在证明上述论点之前，我们先看看别人是如何利用开源软件赚钱的。靠开源软件赚钱的方式（经过验证的）无外乎有如下几种：</p>
<p><strong>双许可证模式</strong>。即在采取严格的开源软件许可证的同时（通常选择 GPL），给商业用户提供非 GPL 许可方式。这本质上是一种贩卖软件许可的行为，但开源软件带给开发者一个很大的好处，即传播迅速，快速迭代。笔者主持的 MiniGUI 项目就采用这种模式，在过去的五年当中，获得了几千万元的软件许可收费。当然，使用这个模式最成功的当属MySQL。</p>
<p><strong>基础软件采用宽松许可证，同时向基础软件的商业用户贩卖增值服务或者增强组件、开发工具等的许可。</strong> 这种模式可用于类似 RT-Thread 这类的基础性软件上，RT-Thread 本身可以是开源且可无偿商用的，但其上的各种增值组件，如网络、文件系统、图形系统等，可以是商业软件。国外采用这种模式的以各类 CMS 系统为主。比如 Drupal 和 Concrete 系统，其基本系统是开源且免费的，但其上的许多插件、主题、模版等是收费的。有兴趣的读者可访问 <a href="http://www.concrete5.org" target="_blank" rel="external">http://www.concrete5.org</a> 网站，其中还有“Marketplace（市场）”频道。</p>
<p><strong>混合模式，既贩卖工具等软件的许可，同时还向用户提供付费服务的模式。</strong> 比如 Ubuntu Linux 发行版。</p>
<p><strong>成为平台型软件，并承载自己的互联网业务</strong>。这种模式在大型互联网企业中应用广泛。比如谷歌开发并开源 Chrome 浏览器，短短几年抢占了微软的很多市场份额，通过在 Chrome 中默认使用谷歌搜索引擎而获得极大的收入；再比如谷歌开源 Android，一方面为了遏制苹果 iOS 的增长势头，一方面通过预置 Google 搜索而获得了大量来自移动互联网的流量收入。</p>
<p>显然，有了先驱们的成功案例，作为开源软件参与者，不论是企业还是个人，都可能名利双收。</p>
<h3 id="4-2-IT-企业为何要参与开源软件？"><a href="#4-2-IT-企业为何要参与开源软件？" class="headerlink" title="4.2 IT 企业为何要参与开源软件？"></a>4.2 IT 企业为何要参与开源软件？</h3><p>IT 行业中的企业，即使是销售硬件产品的企业，也在不停地开发各种软件，同时也大量使用各种开源软件。对这类企业，开源自己开发的软件其动力是什么？</p>
<p>作为企业，参与或者主导一个开源软件，其最为明显的动力应该是上述的第四个商业模式，即打造一个平台型软件。但是，就中国 IT 企业来讲，笔者尚未看到有此种实力，或者此种抱负的企业存在，毕竟，打造一个平台需要长期的投入，一般情况需要五年或者更长的时间。貌似中国没有一个企业有这个耐心来投入五年这么长的时间在一个软件上。</p>
<p>那么为什么企业还要参与到开源软件的开发中？笔者认为，谋不了大利就谋点小利，企业主导或参与开源软件，至少有如下几个好处：</p>
<p>提高企业的美誉度。在利用开源软件的同时，也参与到开源软件当中，企业的美誉度会得到很大的提升。</p>
<p>员工更有激情。因为自己的作品能够公之于众，虽然著作权本质上属于企业，但作为实际的编码者，可以通过开源自己的作品来获得额外的成就感和满足感。这对于稳定开发团队、提高开发人员的积极性会有很大的帮助。</p>
<p>当然，也许过不了几年，中国也能出现实践第四种商业模式的大型 IT 企业，让我们拭目以待吧！</p>
<h3 id="4-3-个人开发者如何利用开源软件获益？"><a href="#4-3-个人开发者如何利用开源软件获益？" class="headerlink" title="4.3 个人开发者如何利用开源软件获益？"></a>4.3 个人开发者如何利用开源软件获益？</h3><p>如果你是一名开源软件的开发者，打算利用自己的软件开创一家软件公司，该如何做？第一，我们要确定好自己的商业模式；第二，为自己的开源软件选择恰当的许可证。</p>
<p>如果决定选择双许可证模式，应选择 GPL 这样较为严格的许可证，这是这种商业模式能够成功的基础。当然，选择双许可证会阻碍产品在商业用户中的推广。尤其是对初生的开源软件来讲，显然是一种两难的境地。MiniGUI 之所以可以采用双许可证模式，是因为在成立公司之前和最初的一段时间内，MiniGUI 采取的是 LGPL 许可证，之后在软件足够成熟的时候才改为 GPL 许可证，另外，MiniGUI 用于功能手机等系统中时，因为这种设备一般使用实时操作系统，缺乏应用 LGPL/GPL 许可证的技术条件，所以面向这种设备收取许可费也是天经地义的事情。MySQL 采用双许可证模式得以成功的原因，在于 MySQL AB 公司并不会对仅仅用于WEB服务器的 MySQL 商用行为收费，因为这种情况下，商业用户并不会发布 MySQL 的副本——它只是在服务器上运行而已。</p>
<p>所以，看起来上面提到的第二种、第三种商业模式是最适合个人开发者或者初创公司的商业模式，能够很快的速度推广和迭代软件本身，还能够确保有足够的收入来保证下一步的发展。在这种模式下，应该选择较为宽松的许可证。但大部分开源软件作者，因为并不真正理解开源软件的许可证，所以采取了错误的许可证（指在法律上是错误的）。比如 RT-Thread，一方面采用 GPL V2 许可证，一方面又承诺不会对商业使用收费。这其实没有解决根本的法律问题，也就是，使用 RT-Thread 开发的衍生作品，到底要不要遵循 GPL？这个问题和是否收费没有直接关系。要解决这个问题，其实很简单，采用类似 Apache、BSD 或者 MIT 许可证即可。有读者会问，那为什么不能采用 LGPL 许可证？就 RT-Thread 这样的软件来讲，采用 LGPL 和 GPL 没有本质的区别，因为 RT-Thread 的应用场合下一般不支持函数库的动态链接，这导致失去了适用 LGPL 许可证的技术条件。</p>
<p>那么上面提到的最后一种模式，是否适用于个人开发者或者初创公司？笔者的答案是，这种模式是大公司的玩法，小团队或者小公司是没法做这类事情的。</p>
<p>当然，一家软件公司的成败所涉及因素很多，不仅仅取决于产品和服务等技术因素，也取决于很多其他的因素，比如大的市场环境、政策因素等等。因此，真正拿自己的开源软件经营一家企业的并不多，更多人开发开源软件，还是因为个人兴趣，以及对获得业界尊重和名望的驱使。</p>
<p>但真正能够获得业界尊重的开源软件开发者及其开源软件，其实也并不多。也就是说，要通过开发开源软件获得上面所说的“名”，需要开发者具有较高的开发水平和相关能力。这其中主要的能力有：</p>
<p><strong>好的选题</strong>。好的选题应该能够跟得上 IT 领域的前沿技术，最好避免重复造轮子的尴尬境地。</p>
<p><strong>较高水平的软件架构设计能力以及编码能力</strong>。既然开放了软件的源代码，那自然希望有人去看，并欣赏这些源代码。所以，拥有较高水平的软件架构设计能力、编码能力，是开源软件能够获得用户青睐的一大条件。<br>较高水平的文档能力。除了编码之外，要让你的开源软件得到大量的用户，你还需要能够编写漂亮的文档，起码要能够撰写很好的安装指导说明文件。</p>
<p><strong>适度的宣传能力</strong>。不论好坏，适当宣传自己的开源软件，是获得公众认知的一个良好方式。宣传并不意味着需要花钱，你可以参加各种开源会议，或者在微博上进行宣传，或者通过一些开源社区帮助你来宣传自己的作品。</p>
<p><strong>适度的坚持</strong>。好的软件是打磨出来的，如果仅仅靠一时兴趣弄个软件并开源，并没有持续改善，那肯定会半途而废。</p>
<p>当然，除了自己创作一个全新的开源软件之外，要获得上面所说的“名”，还有一个办法是加入到已有的知名开源软件的开发中，尤其是海外的知名开源软件开发中。你可以从帮助他们“汉化”软件开始，然后提交补丁，最后成为主要的开发者。</p>
<h2 id="5-大专院校应该成为开源软件的主力军"><a href="#5-大专院校应该成为开源软件的主力军" class="headerlink" title="5 大专院校应该成为开源软件的主力军"></a>5 大专院校应该成为开源软件的主力军</h2><p>一个有趣的现象是，很多开源软件其实就是作者在大专院校或者研究机构工作或学习时发起的，比如本文提到的三个国内早期的开源软件项目。甚至某些开源软件由特定的大学主持和维护，如 BSD 操作系统、PostgreSQL 关系数据库、Minix 操作系统等等。</p>
<p>从国际视角看，开源软件的发展离不开一些知名大学的参与，BSD 和 MIT 许可证分别由加州大学伯克利分校和麻省理工学院定义，并由两所大学在其众多开源软件中使用，也被其他开源软件广泛应用。值得一提的是，<strong>苹果公司 Mac 操作系统和 iOS 操作系统，均使用了加州大学伯克利分校开发的 BSD 操作系统内核。</strong></p>
<p>从现实情况看，国内在各大公司工作的程序员们，除非因为供职单位支持，否则很难独立发起和维护一个大型的开源软件，但在大专院校和科研机构工作的老师和学生，则有得天独厚的条件（主要是有大量的时间，并可能和科研课题和教学任务相结合）来发起和持续维护一个开源软件项目。清华大学陈渝副教授主持的 SkyEye 和 ucore 两个开源项目就是典型的案例。笔者希望国内有更多的大专院校和科研单位（尤其是教师）能够积极参与到开源软件的发展当中，并成为国内开源软件的主力军。</p>
<h2 id="6-政府和开源社区应该做什么？"><a href="#6-政府和开源社区应该做什么？" class="headerlink" title="6 政府和开源社区应该做什么？"></a>6 政府和开源社区应该做什么？</h2><p>说实话，笔者并不认为政府在开源软件的发展中应该起主导作用。政府要做的就是制定公平、合理的规则，促进相关法律法规的完善。</p>
<p>从法律上讲，你编写了一个程序，你就自动获得这个程序的软件著作权。在实际操作中，<strong>法律要求进行软件著作权的登记，就如同房产证一样，你非要有个政府颁发的证书才能得到法律的承认</strong>。我们暂且不论这个做法是否合理，也不论登记收费这事儿，你需要了解的是，在中国，如果你打算遵循 GPL 许可证开源你的软件，你就无法登记著作权！</p>
<p>当然，众所周知，中国的知识产权保护力度不够，不仅仅阻碍了软件产业的发展，也阻碍了开源软件的发展。</p>
<p>还有，在中国，要注册一家非公益性的 NGO 组织（国外各种软件基金会都是这类组织），是非常非常困难的。这导致截止今天，中国没有任何一家支持开源软件为己任的非营利性基金会组织。</p>
<p>政府所要做的，就是撤销那些违背历史发展大潮的法规和规定，并建立完善的知识产权保护制度，加强对盗版等的打击力度，教育国民尊重他人劳动成果，而不是仅仅停留在口头上。</p>
<p>政府，把上面这些问题解决好了，比直接参与推动开源软件什么的，要强许多倍！比如，加大知识产权的保护力度，一方面可以让商业软件在传统贩卖软件使用许可的商业模式下得到良性发展的机会，也可以让一部分人转向使用免费的开源软件，进而促进开源软件的发展。</p>
<p>当然，在现阶段，通过从财政中拿出来一些钱，设立一些奖励基金之类的东西，给开源软件的作者以一些奖励，也许是更有效的途径。</p>
<p>开源软件本就应该是以松散、自组织的形式开发和发展，开源社区的存在，为开源软件开发者和使用者提供赖以生存的土壤。开源社区可以是网站、论坛，也可以是松散的交流、展演等。当然，开源社区第一步要解决的问题就是自己的生存问题。</p>
<p>笔者的建议是，开源社区应该尝试在现有法律框架下，以有限责任公司的治理结构来做国外开源基金会所做的工作。通过这样一种方式，可以有效避免无法注册 NGO 组织的问题，然后从企业（尤其是那些大型互联网企业）当中募集捐款，通过赞助一些开源项目，逐步推进开源软件社区的良性发展。</p>
<p>另外，国内开源社区还需要从使用者社区转向开发者社区，为开发者参与开源软件提供便利，如建立类似 GitHub/SourceForge 那样的开源软件托管站点，为开源软件项目提供邮件列表、论坛、博客服务等等。</p>
<h2 id="7-结语——给那些仅仅使用开源软件但不做贡献的企业"><a href="#7-结语——给那些仅仅使用开源软件但不做贡献的企业" class="headerlink" title="7 结语——给那些仅仅使用开源软件但不做贡献的企业"></a>7 结语——给那些仅仅使用开源软件但不做贡献的企业</h2><p>将开源软件和商业结合，不管是在自己的项目中使用开源软件，还是靠自己的开源软件来赚钱，都无可厚非。关键是，我们需要 <strong>尊重开源软件著作权的拥有者，按照开源软件所采纳的许可证办事</strong>，只有这样，开源软件才能得到长足发展。</p>
<p>通常，开源软件的作者发布开源软件，是希望获得最多用户使用的，在此基础上，作者要么会获得业界的追捧而一夜成名，要么获得一定的商业利益。所以，从某种角度上讲，使用开源软件本身就是对开源软件的一种支持。</p>
<p>但是，这并不意味着你可以随意使用他人的开源软件。合法使用开源软件的前提，就是遵守开源软件的许可证规定的各种义务。</p>
<p>当然，更有积极意义的方式是，将使用开源软件中遇到的问题或者修正、增强代码提交给开源软件的作者，帮助其改善作品。其实，这是任何使用开源软件的企业都能做到的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.fmsoft.cn/zhcn/about/blog/185/&quot;&gt;魏永明&lt;/a&gt;（飞漫软件CEO）。本文经章文嵩、陈渝审阅。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://cms.csdnimg.cn/article/201306/21/51c411d5c48fa.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
  </entry>
  
  <entry>
    <title>Android模拟器影响系统音量的解决方法</title>
    <link href="http://ipcreator.me/2017/03/01/MyView/Diary/Tech/android-emulator-system-sound/"/>
    <id>http://ipcreator.me/2017/03/01/MyView/Diary/Tech/android-emulator-system-sound/</id>
    <published>2017-03-01T13:06:06.000Z</published>
    <updated>2017-03-01T13:18:17.855Z</updated>
    
    <content type="html"><![CDATA[<p> <img src="http://okkntqe2h.bkt.clouddn.com/volume.PNG" alt=""></p>
<p>用常识思维解决问题，既简单又快捷…有时候离解决方案只有一步之遥。</p>
 <a id="more"></a>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p> 系统配置：Acer Predator G9-593<br> AndroidStudio：2.2.3<br> AndroidSDK：更新到2017.03.01的最新版本<br> AndroidStudio一打开模拟器，正在播放的音乐音量瞬间变小<br> 程序员离开了音乐，就如烟鬼离开了烟，不解决不痛快</p>
<h2 id="常识思维"><a href="#常识思维" class="headerlink" title="常识思维"></a>常识思维</h2><p>Google一下，相关页面较少，表明这是个不常见的问题，另外，阅读他人给出的解决方案，譬如：重装AndroidStudio、SDK甚至Win10系统等，一看还就是“电脑出问题，不是重启就是关机后再开机”的老套路，不明所以又爱自以为是。</p>
<p>稍微有个靠谱的推荐解决方案，就是设置”系统检测到通讯活动存在时，自动降低音量“选项，但我尝试之后，结果仍是“鞋子虽好，但不适合我”。<br><img src="http://okkntqe2h.bkt.clouddn.com/way1.PNG" alt=""></p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p> 自己动手，丰衣足食，既然是音量高低的问题，那就先到系统设置查找声音相关选项，按照自己的习惯，先遍历各个按钮和选项…等下，这不就是音量设置选项吗？拉大一点尝试一下，还不行，切换到杜比音效选项，发现处于关闭状态，打开尝试一下，OK…“你知不知道，我等到花儿也谢了…”歌神的歌声又开始飘扬了…<br> <img src="http://okkntqe2h.bkt.clouddn.com/way2-1.PNG" alt=""></p>
<p>   <img src="http://okkntqe2h.bkt.clouddn.com/way2-2.PNG" alt=""></p>
<p><strong>注意一个坑，要选中“Speakers”，Properties按钮才可用</strong></p>
<blockquote>
<p>不要怕点怕设置，要敢于尝试，大不了再恢复默认设置嘛…从电脑和手机，从系统到应用，一般都支持恢复默认选项，如果你开发的软件还不支持该功能，建议还是尽快纳入TODO List…</p>
</blockquote>
<p><img src="http://okkntqe2h.bkt.clouddn.com/dolby.PNG" alt=""></p>
<p>其实，音量设置的总开关在Volume Mixer，可以自由设定…<br> <img src="http://okkntqe2h.bkt.clouddn.com/volume.PNG" alt=""></p>
<h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p> Google上找到了一样的解决方案…又一个GG远胜于BD的例子<br> <img src="http://okkntqe2h.bkt.clouddn.com/Another%20problem.PNG" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; &lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/volume.PNG&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;用常识思维解决问题，既简单又快捷…有时候离解决方案只有一步之遥。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Growing Up" scheme="http://ipcreator.me/tags/Growing-Up/"/>
    
  </entry>
  
  <entry>
    <title>Android安全攻防战，反编译与混淆技术完全解析</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Android/awesome-articles-of-android/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Android/awesome-articles-of-android/</id>
    <published>2017-02-27T05:57:06.000Z</published>
    <updated>2017-02-27T06:24:14.661Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="http://blog.csdn.net/guolin_blog/article/details/49738023" target="_blank" rel="external">Android安全攻防战，反编译与混淆技术完全解析（上）</a><br> <a href="http://blog.csdn.net/guolin_blog/article/details/50451259" target="_blank" rel="external"> Android安全攻防战，反编译与混淆技术完全解析（下）</a></p>
<p> <img src="http://img.blog.csdn.net/20160312190016290" alt=""></p>
<p> 之前一直有犹豫过要不要写这篇文章，毕竟去反编译人家的程序并不是什么值得骄傲的事情。不过单纯从技术角度上来讲，掌握反编译功能确实是一项非常有用的技能，可能平常不太会用得到，但是一旦真的需要用到的了，而你却不会的话，那就非常头疼了。另外既然别人可以反编译程序，我们当然有理由应该对程序进行一定程度的保护，因此代码混淆也是我们必须要掌握的一项技术。那么最近的两篇文章我们就围绕反编译和混淆这两个主题来进行一次完全解析。</p>
 <a id="more"></a>
<h2 id="反编译"><a href="#反编译" class="headerlink" title="反编译"></a>反编译</h2><p>我们都知道，Android程序打完包之后得到的是一个APK文件，这个文件是可以直接安装到任何Android手机上的，我们反编译其实也就是对这个APK文件进行反编译。Android的反编译主要又分为两个部分，一个是对代码的反编译，一个是对资源的反编译，我们马上来逐个学习一下。</p>
<p>在开始学习之前，首先我们需要准备一个APK文件，为了尊重所有开发者，我就不拿任何一个市面上的软件来演示了，而是自己写一个Demo用来测试。</p>
<p>这里我希望代码越简单越好，因此我们建立一个新项目，在Activity里加入一个按钮，当点击按钮时弹出一个Toast，就这么简单，代码如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public <span class="class"><span class="keyword">class</span> <span class="title">MainActivity</span> <span class="keyword">extends</span> <span class="title">AppCompatActivity</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="keyword">protected</span> void onCreate(<span class="type">Bundle</span> savedInstanceState) &#123;</div><div class="line">        <span class="keyword">super</span>.onCreate(savedInstanceState);</div><div class="line">        setContentView(<span class="type">R</span>.layout.activity_main);</div><div class="line">        <span class="type">Button</span> button = (<span class="type">Button</span>) findViewById(<span class="type">R</span>.id.button);</div><div class="line">        button.setOnClickListener(<span class="keyword">new</span> <span class="type">View</span>.<span class="type">OnClickListener</span>() &#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            public void onClick(<span class="type">View</span> v) &#123;</div><div class="line">                <span class="type">Toast</span>.makeText(<span class="type">MainActivity</span>.<span class="keyword">this</span>, <span class="string">"you clicked button"</span>, <span class="type">Toast</span>.<span class="type">LENGTH_SHORT</span>).show();</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>activity_main.xml中的资源如下所示：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="php"><span class="meta">&lt;?</span>xml version=<span class="string">"1.0"</span> encoding=<span class="string">"utf-8"</span><span class="meta">?&gt;</span></span></div><div class="line"><span class="tag">&lt;<span class="name">RelativeLayout</span></span></div><div class="line">    <span class="attr">xmlns:android</span>=<span class="string">"http://schemas.android.com/apk/res/android"</span></div><div class="line">    <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></div><div class="line">    <span class="attr">android:layout_height</span>=<span class="string">"match_parent"</span></div><div class="line">    <span class="attr">android:paddingBottom</span>=<span class="string">"@dimen/activity_vertical_margin"</span></div><div class="line">    <span class="attr">android:paddingLeft</span>=<span class="string">"@dimen/activity_horizontal_margin"</span></div><div class="line">    <span class="attr">android:paddingRight</span>=<span class="string">"@dimen/activity_horizontal_margin"</span></div><div class="line">    <span class="attr">android:paddingTop</span>=<span class="string">"@dimen/activity_vertical_margin"</span>&gt;</div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">Button</span></span></div><div class="line">        <span class="attr">android:id</span>=<span class="string">"@+id/button"</span></div><div class="line">        <span class="attr">android:layout_width</span>=<span class="string">"wrap_content"</span></div><div class="line">        <span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span></div><div class="line">        <span class="attr">android:text</span>=<span class="string">"Button"</span>/&gt;</div><div class="line"><span class="tag">&lt;/<span class="name">RelativeLayout</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>然后我们将代码打成一个APK包，并命名成Demo.apk，再把它安装到手机上，结果如下所示：<br><img src="http://img.blog.csdn.net/20160204142511216" alt=""></p>
<p>好的，到这里准备工作就已经基本完成了，接下来就让我们开始对这个Demo程序进行反编译吧。</p>
<h2 id="反编译代码"><a href="#反编译代码" class="headerlink" title="反编译代码"></a>反编译代码</h2><p>要想将APK文件中的代码反编译出来，我们需要用到以下两款工具：</p>
<p><strong>dex2jar</strong> 这个工具用于将dex文件转换成jar文件<br>下载地址：<a href="http://sourceforge.net/projects/dex2jar/files/" target="_blank" rel="external">http://sourceforge.net/projects/dex2jar/files/</a><br><strong>jd-gui</strong> 这个工具用于将jar文件转换成java代码<br>下载地址：<a href="http://jd.benow.ca/" target="_blank" rel="external">http://jd.benow.ca/</a><br>将这两个工具都下载好并解压，然后我们就开始对Demo程序进行反编译。解压dex2jar压缩包后，你会发现有很多个文件，如下图所示：<br><img src="http://img.blog.csdn.net/20160204153609614" alt=""></p>
<p>其中我们要用到的是d2j-dex2jar.bat这个文件，当然如果你是linux或mac系统的话就要用d2j-dex2jar.sh这个文件。<br>然后我们将Demo.apk文件也进行解压，如果不知道怎么直接解压的可以先将文件重命名成Demo.zip，然后用解压软件打开。解压之后你会发现里面有一个classes.dex文件，如下图所示：<br><img src="http://img.blog.csdn.net/20160204160337530" alt=""></p>
<p>这个classes.dex文件就是存放所有java代码的地方了，我们将它拷贝到dex2jar解压后的目录下，并在cmd中也进入到同样的目录，然后执行：</p>
<blockquote>
<p>d2j-dex2jar classes.dex</p>
</blockquote>
<p>执行结果如下图所示：<br><img src="http://img.blog.csdn.net/20160204160725801" alt=""></p>
<p>没有报任何错误，这就说明我们已经转换成功了。现在观察dex2jar目录，你会发现多了一个文件，如下图所示：<br><img src="http://img.blog.csdn.net/20160204161831426" alt=""></p>
<p>可以看到，classes-dex2jar.jar这个文件就是我们借助工具之后成功转换出来的jar文件了。但是对于我们而言，jar文件也不是可读的，因此这里还需要再借助一下jd-gui这个工具来将jar文件转换成java代码。<br>下面就很简单了，使用jd-gui工具打开classes-dex2jar.jar这个文件，结果如下图所示：<br><img src="http://img.blog.csdn.net/20160204162548914" alt=""></p>
<p>OK，由此可见，我们的代码反编译工作已经成功了，MainActivity中的代码非常清晰，基本已经做到了90%以上的还原工作。但是如果想要做到100%的代码还原还是非常有难度的，因为像setContentView()方法传入的参数，其实就是一个资源的id值而已，那么这里反编译也就只能将相应的id值进行还原，而无法变成像R.layout.activity_main这样直观的代码展示。<br>另外，除了MainActivity之外，还有很多其它的代码也被反编译出来了，因为当前项目有引用support-v4和support-v7的包，这些引用的library也会作为代码的一部分被打包到classes.dex文件当中，因此反编译的时候这些代码也会一起被还原。<br>好的，学完了反编译代码，接下来我们看一下如何反编译资源。</p>
<h2 id="反编译资源"><a href="#反编译资源" class="headerlink" title="反编译资源"></a>反编译资源</h2><p>其实细心的朋友可能已经观察到了，刚才Demo.apk的解压目录当中不是已经有资源文件了吗，有AndroidManifest.xml文件，也有res目录。进入res目录当中，内容如下图所示：<br><img src="http://img.blog.csdn.net/20160205114006588" alt=""></p>
<p>这不是所有资源文件都在这里了么？其实这些资源文件都是在打包的时候被编译过了，我们直接打开的话是看不到明文的，不信的话我们打开AndroidManifest.xml文件来瞧一瞧，内容如下图所示：<br><img src="http://img.blog.csdn.net/20160205114422374" alt=""></p>
<p>可以看到，这代码是完全没法阅读的。当然如果你去打开activity_main.xml看看，结果也不会好到哪儿去：<br><img src="http://img.blog.csdn.net/20160205114648290" alt=""></p>
<p>由此可见，直接对APK包进行解压是无法得到它的原始资源文件的，因此我们还需要对资源进行反编译才行。<br>要想将APK文件中的资源反编译出来，又要用到另外一个工具了：<br><strong>apktool</strong> 这个工具用于最大幅度地还原APK文件中的9-patch图片、布局、字符串等等一系列的资源。<br>下载地址：<a href="http://ibotpeaches.github.io/Apktool/install/" target="_blank" rel="external">http://ibotpeaches.github.io/Apktool/install/</a><br>关于这个工具的下载我还要再补充几句，我们需要的就是apktool.bat和apktool.jar这两个文件。目前apktool.jar的最新版本是2.0.3，这里我就下载最新的了，然后将apktool_2.0.3.jar重命名成apktool.jar，并将它们放到同一个文件夹下就可以了，如下图所示：<br><img src="http://img.blog.csdn.net/20160205125449076" alt=""></p>
<p>接下来的工作就很简单了，我们将Demo.apk拷贝到和这两个文件同样的目录当中，然后cmd也进入到这个目录下，并在cmd中执行如下命令：</p>
<blockquote>
<p>apktool d Demo.apk</p>
</blockquote>
<p>其中d是decode的意思，表示我们要对Demo.apk这个文件进行解码。那除了这个基本用法之外，我们还可以再加上一些附加参数来控制decode的更多行为：</p>
<p>-f 如果目标文件夹已存在，则强制删除现有文件夹（默认如果目标文件夹已存在，则解码失败）。<br>-o 指定解码目标文件夹的名称（默认使用APK文件的名字来命名目标文件夹）。<br>-s 不反编译dex文件，也就是说classes.dex文件会被保留（默认会将dex文件解码成smali文件）。<br>-r 不反编译资源文件，也就是说resources.arsc文件会被保留（默认会将resources.arsc解码成具体的资源文件）。<br>常用用法就这么多了，那么上述命令的执行结果如下图所示：<br><img src="http://img.blog.csdn.net/20160205130623698" alt=""></p>
<p>这就说明反编译资源已经成功了。<br>当然即使你在和我执行一模一样的操作，也有可能会在这里反编译失败，比如说会报如下错误：<br><img src="http://img.blog.csdn.net/20160205131116809" alt=""></p>
<p>出现这个错误的原因很有可能是你之前使用过apktool的老版本进行过反编译操作，然后apktool就会在你系统的C:\Users\Administrator\apktool\framework这个目录下生成一个名字为1.apk的缓存文件，将这个缓存文件删除掉，然后再重新执行反编译命令应该就可以成功了。<br>现在你会发现在当前目录下多了一个Demo文件夹，这个文件夹中存放的就是反编译的结果了。我们可以打开AndroidManifest.xml来瞧一瞧，如下图所示：<br><img src="http://img.blog.csdn.net/20160205184526870" alt=""></p>
<p>怎么样？这样就完全能看得懂了吧，然后可以再到res/layout中看一下activity_main.xml文件，如下图所示：<br><img src="http://img.blog.csdn.net/20160205185353442" alt=""></p>
<p>可以看到，activity_main.xml中的内容基本和源代码中的内容是一致的，外层是一个RelativeLayout，里面则是一个Button。你可以再到其它目录中去看一看别的资源，基本上都是可以正常还原的，这样我们就把反编译资源的方法也已经掌握了。</p>
<h2 id="重新打包"><a href="#重新打包" class="headerlink" title="重新打包"></a>重新打包</h2><p>那么对于反编译出来的文件夹，我们能不能重新把它打包成APK文件呢？答案是肯定的，只不过我实在想不出有什么义正言辞的理由可以让我们这么做。有的人会说汉化，没错，汉化的方式确实就是将一个APK进行反编译，然后翻译其中的资源再重新打包，但是不管怎么说这仍然是将别人的程序进行破解，所以我并不认为这是什么光荣的事情。那么我们就不去讨论本身这件事情的对或错，这里只是站在技术的角度来学习一下重新打包的相关知识。<br>首先我们来看一下通过apktool反编译后的包目录情况，如下图所示：<br><img src="http://img.blog.csdn.net/20160208234027946" alt=""></p>
<p>其中，original文件夹下存放的是未经反编译过、原始的AndroidManifest.xml文件，res文件夹下存放的是反编译出来的所有资源，smali文件夹下存放的是反编译出来的所有代码，AndroidManifest.xml则是经过反编译还原后的manifest文件。这里值得一提的是smali文件夹，如果你进入到这个文件夹中你会发现它的目录结构和我们源码中src的目录结构是几乎一样的，主要的区别就是所有的java文件都变成了smali文件。<strong>smali文件其实也是真正的源代码，只不过它的语法和java完全不同，它有点类似于汇编的语法，是Android虚拟机所使用的寄存器语言</strong>，语法结构大概如下所示：<br><img src="http://img.blog.csdn.net/20160208235859750" alt=""></p>
<p>看上去有点晕头转向是吗？但是如果你一旦能够看得懂smali文件的话，那么你就可以做很恐怖的事情了——你可以随意修改应用程序内的逻辑，将其进行破解！<br>不过我对这种黑技术并没有什么太大的兴趣，因此我也没有去做具体研究，但即使是这样，也已经可以对程序的逻辑做一定程度的修改了。比如说当我们点击按钮时会弹出you clicked button这样一句Toast，逻辑是写在MainActivity按钮点击事件的匿名类当中的，因此这段代码反编译之后一定就会在MainActivity$1.smali这个文件当中，让我们打开瞧一瞧，部分代码如下所示：<br><img src="http://img.blog.csdn.net/20160209154620278" alt=""></p>
<p>虽说多数的代码我是看不懂的，但其中第47行实在太明显了，Toast显示的内容不就是在这里定义的么，那么如果我们想把Demo程序hack掉，就可以将这段字符串给改掉，比如说我把它改成Your app is been hacked。<br>关于smali的语法，网上的资料也非常多，如果你对这门技术十分感兴趣的话可以直接上网去搜，这里我只是简单介绍一下，就不再深入讲解相关知识了。<br>改了一处代码后我们再来改一处资源吧，比如这里想要把Demo的应用图标给换掉，那么首先我们要准备好一张新的图片，如下图所示：<br><img src="http://img.blog.csdn.net/20160209161422695" alt=""><br>然后从AndroidManifest.xml文件中可以看出，应用图标使用的是ic_launcher.png这张图片，那么我们将上面篮球这张图片命名成ic_launcher.png，然后拷贝到所有以res/mipmap开头的文件夹当中完成替换操作。<br>在做了两处改动之后，我们现在来把反编译后的Demo文件夹重新打包成APK吧，其实非常简单，只需要在cmd中执行如下命令：</p>
<blockquote>
<p>apktool b Demo -o New_Demo.apk</p>
</blockquote>
<p>其中b是build的意思，表示我们要将Demo文件夹打包成APK文件，-o用于指定新生成的APK文件名，这里新的文件叫作New_Demo.apk。执行结果如下图所示：<br><img src="http://img.blog.csdn.net/20160209163551554" alt=""></p>
<p>现在你会发现在同级目录下面生成了一个新的APK文件：<br><img src="http://img.blog.csdn.net/20160209175505785" alt=""></p>
<p>不过不要高兴得太早了，目前这个New_Demo.apk还是不能安装的，因为它还没有进行签名。那么如果这是别人的程序的话，我们从哪儿能拿到它原来的签名文件呢？很显然，这是根本没有办法拿到的，因此我们只能拿自己的签名文件来对这个APK文件重新进行签名，但同时也表明我们重新打包出来的软件就是个十足的盗版软件。这里大家学学技术就好了，希望不要有任何人去做什么坏事情。<br>那么这里我就用一个之前生成好的签名文件了，使用Android Studio或者Eclipse都可以非常简单地生成一个签名文件。<br>有了签名文件之后在cmd中执行签名命令就可以进行签名了，命令格式如下：</p>
<blockquote>
<p>jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore 签名文件名 -storepass 签名密码 待签名的APK文件名 签名的别名</p>
</blockquote>
<p>其中jarsigner命令文件是存放在jdk的bin目录下的，需要将bin目录配置在系统的环境变量当中才可以在任何位置执行此命令。<br>签名之后的APK文件现在已经可以安装到手机上了，不过在此之前Android还极度建议我们对签名后的APK文件进行一次对齐操作，因为这样可以使得我们的程序在Android系统中运行得更快。对齐操作使用的是zipalign工具，该工具存放于<android sdk="">/build-tools/<version>目录下，将这个目录配置到系统环境变量当中就可以在任何位置执行此命令了。命令格式如下：</version></android></p>
<blockquote>
<p>zipalign 4 New_Demo.apk New_Demo_aligned.apk</p>
</blockquote>
<p>其中4是固定值不能改变，后面指定待对齐的APK文件名和对齐后的APK文件名。运行这段命令之后就会生成一个New_Demo_aligned.apk文件，如下所示：<br><img src="http://img.blog.csdn.net/20160209175645990" alt=""></p>
<p>这个New_Demo_aligned.apk就是我们重新打包签名对齐后的文件了，现在把它安装到手机上，效果如下图所示：<br><img src="http://img.blog.csdn.net/20160212105044897" alt=""></p>
<p>可以看到，应用图标已经成功改成了篮球，另外点击按钮后弹出的Toast的提示也变成了我们修改后的文字，说明重新打包操作确实已经成功了。<br>好的，我们把反编译代码、反编译资源、重新打包这三大主题的内容都已经掌握了，关于反编译相关的内容就到这里，下篇文章会介绍Android代码混淆方面的相关技术，感兴趣的朋友请继续阅读： Android安全攻防战，反编译与混淆技术完全解析（下） 。</p>
<p>在上一篇文章当中，我们学习了Android程序反编译方面的知识，包括反编译代码、反编译资源、以及重新打包等内容。通过这些内容我们也能看出来，其实我们的程序并没有那么的安全。可能资源被反编译影响还不是很大，重新打包又由于有签名的保护导致很难被盗版，但代码被反编译就有可能会泄漏核心技术了，因此一款安全性高的程序最起码要做到的一件事就是：对代码进行混淆。</p>
<p>混淆代码并不是让代码无法被反编译，而是将代码中的类、方法、变量等信息进行重命名，把它们改成一些毫无意义的名字。因为对于我们而言可能Cellphone类的call()方法意味着很多信息，而A类的b()方法则没有任何意义，但是对于计算机而言，它们都是平等的，计算机不会试图去理解Cellphone是什么意思，它只会按照设定好的逻辑来去执行这些代码。所以说混淆代码可以在不影响程序正常运行的前提下让破解者很头疼，从而大大提升了程序的安全性。</p>
<p>今天是我们Android安全攻防战系列的下篇，本篇文章的内容建立在上篇的基础之上，还没有阅读过的朋友可以先去参考 <a href="http://blog.csdn.net/guolin_blog/article/details/49738023" target="_blank" rel="external">Android安全攻防战，反编译与混淆技术完全解析（上）</a> 。</p>
<p>混淆</p>
<p>本篇文章中介绍的混淆技术都是基于Android Studio的，Eclipse的用法也基本类似，但是就不再为Eclipse专门做讲解了。</p>
<p>我们要建立一个Android Studio项目，并在项目中添加一些能够帮助我们理解混淆知识的代码。这里我准备好了一些，我们将它们添加到Android Studio当中。</p>
<p>首先新建一个MyFragment类，代码如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">public <span class="class"><span class="keyword">class</span> <span class="title">MyFragment</span> <span class="keyword">extends</span> <span class="title">Fragment</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="type">String</span> toastTip = <span class="string">"toast in MyFragment"</span>;</div><div class="line"></div><div class="line">    <span class="meta">@Nullable</span></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    public <span class="type">View</span> onCreateView(<span class="type">LayoutInflater</span> inflater, <span class="meta">@Nullable</span> <span class="type">ViewGroup</span> container, <span class="meta">@Nullable</span> <span class="type">Bundle</span> savedInstanceState) &#123;</div><div class="line">        <span class="type">View</span> view = inflater.inflate(<span class="type">R</span>.layout.fragment_layout, container, <span class="literal">false</span>);</div><div class="line">        methodWithGlobalVariable();</div><div class="line">        methodWithLocalVariable();</div><div class="line">        <span class="keyword">return</span> view;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public void methodWithGlobalVariable() &#123;</div><div class="line">        <span class="type">Toast</span>.makeText(getActivity(), toastTip, <span class="type">Toast</span>.<span class="type">LENGTH_SHORT</span>).show();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public void methodWithLocalVariable() &#123;</div><div class="line">        <span class="type">String</span> logMessage = <span class="string">"log in MyFragment"</span>;</div><div class="line">        logMessage = logMessage.toLowerCase();</div><div class="line">        <span class="type">System</span>.out.println(logMessage);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可以看到，MyFragment是继承自Fragment的，并且MyFragment中有一个全局变量。onCreateView()方法是Fragment的生命周期函数，这个不用多说，在onCreateView()方法中又调用了methodWithGlobalVariable()和methodWithLocalVariable()方法，这两个方法的内部分别引用了一个全局变量和一个局部变量。</p>
<p>接下来新建一个Utils类，代码如下所示：<br><figure class="highlight pf"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">public class Utils &#123;</div><div class="line"></div><div class="line">    public void methodNormal() &#123;</div><div class="line">        String <span class="keyword">log</span>Message = <span class="string">"this is normal method"</span>;</div><div class="line">        <span class="keyword">log</span>Message = <span class="keyword">log</span>Message.<span class="keyword">to</span>LowerCase();</div><div class="line">        System.<span class="keyword">out</span>.println(<span class="keyword">log</span>Message);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public void methodUnused() &#123;</div><div class="line">        String <span class="keyword">log</span>Message = <span class="string">"this is unused method"</span>;</div><div class="line">        <span class="keyword">log</span>Message = <span class="keyword">log</span>Message.<span class="keyword">to</span>LowerCase();</div><div class="line">        System.<span class="keyword">out</span>.println(<span class="keyword">log</span>Message);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这是一个非常普通的工具类，没有任何继承关系。Utils中有两个方法methodNormal()和methodUnused()，它们的内部逻辑都是一样的，唯一的据别是稍后methodNormal()方法会被调用，而methodUnused()方法不会被调用。</p>
<p>下面再新建一个NativeUtils类，代码如下所示：<br><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">NativeUtils</span> &#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> native <span class="keyword">void</span> <span class="title">methodNative</span>(<span class="params"></span>)</span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">methodNotNative</span>(<span class="params"></span>) </span>&#123;</div><div class="line">        String logMessage = <span class="string">"this is not native method"</span>;</div><div class="line">        logMessage = logMessage.toLowerCase();</div><div class="line">        System.<span class="keyword">out</span>.println(logMessage);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个类中同样有两个方法，一个是native方法，一个是非native方法。<br>最后，修改MainActivity中的代码，如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainActivity</span> <span class="keyword">extends</span> <span class="title">AppCompatActivity</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> String toastTip = <span class="string">"toast in MainActivity"</span>;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>.onCreate(savedInstanceState);</div><div class="line">        setContentView(R.layout.activity_main);</div><div class="line">        getSupportFragmentManager().beginTransaction().add(R.id.fragment, <span class="keyword">new</span> MyFragment()).commit();</div><div class="line">        Button button = (Button) findViewById(R.id.button);</div><div class="line">        button.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</div><div class="line">                methodWithGlobalVariable();</div><div class="line">                methodWithLocalVariable();</div><div class="line">                Utils utils = <span class="keyword">new</span> Utils();</div><div class="line">                utils.methodNormal();</div><div class="line">                NativeUtils.methodNative();</div><div class="line">                NativeUtils.methodNotNative();</div><div class="line">                Connector.getDatabase();</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodWithGlobalVariable</span><span class="params">()</span> </span>&#123;</div><div class="line">        Toast.makeText(MainActivity.<span class="keyword">this</span>, toastTip, Toast.LENGTH_SHORT).show();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodWithLocalVariable</span><span class="params">()</span> </span>&#123;</div><div class="line">        String logMessage = <span class="string">"log in MainActivity"</span>;</div><div class="line">        logMessage = logMessage.toLowerCase();</div><div class="line">        System.out.println(logMessage);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可以看到，MainActivity和MyFragment类似，也是定义了methodWithGlobalVariable()和methodWithLocalVariable()这两个方法，然后MainActivity对MyFragment进行了添加，并在Button的点击事件里面调用了自身的、Utils的、以及NativeUtils中的方法。注意调用native方法需要有相应的so库实现，不然的话就会报UnsatisefiedLinkError，不过这里其实我也并没有真正的so库实现，只是演示一下让大家看看混淆结果。点击事件的最后一行调用的是LitePal中的方法，因为我们还要测试一下引用第三方Jar包的场景，到LitePal项目的主页去下载最新的Jar包，然后放到libs目录下即可。</p>
<p>完整的build.gradle内容如下所示：<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">apply</span> plugin: <span class="string">'com.android.application'</span></div><div class="line"></div><div class="line">android &#123;</div><div class="line">    <span class="attribute">compileSdkVersion</span> <span class="number">23</span></div><div class="line">    buildToolsVersion <span class="string">"23.0.2"</span></div><div class="line"></div><div class="line">    defaultConfig &#123;</div><div class="line">        <span class="attribute">applicationId</span> <span class="string">"com.example.guolin.androidtest"</span></div><div class="line">        minSdkVersion <span class="number">15</span></div><div class="line">        targetSdkVersion <span class="number">23</span></div><div class="line">        versionCode <span class="number">1</span></div><div class="line">        versionName <span class="string">"1.0"</span></div><div class="line">    &#125;</div><div class="line">    buildTypes &#123;</div><div class="line">        <span class="section">release</span> &#123;</div><div class="line">            <span class="attribute">minifyEnabled</span> <span class="literal">false</span></div><div class="line">            proguardFiles getDefaultProguardFile(<span class="string">'proguard-android.txt'</span>), <span class="string">'proguard-rules.pro'</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">dependencies &#123;</div><div class="line">    <span class="attribute">compile</span> fileTree(dir: <span class="string">'libs'</span>, include: [<span class="string">'*.jar'</span>])</div><div class="line">    compile <span class="string">'com.android.support:appcompat-v7:23.2.0'</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>好的，到这里准备工作就已经基本完成了，接下来我们就开始对代码进行混淆吧。</p>
<h2 id="混淆APK"><a href="#混淆APK" class="headerlink" title="混淆APK"></a>混淆APK</h2><p>在Android Studio当中混淆APK实在是太简单了，借助SDK中自带的Proguard工具，只需要修改build.gradle中的一行配置即可。可以看到，现在build.gradle中minifyEnabled的值是false，这里我们只需要把值改成true，打出来的APK包就会是混淆过的了。如下所示：<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="section">release</span> &#123;</div><div class="line">    <span class="attribute">minifyEnabled</span> <span class="literal">true</span></div><div class="line">    proguardFiles getDefaultProguardFile(<span class="string">'proguard-android.txt'</span>), <span class="string">'proguard-rules.pro'</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其中minifyEnabled用于设置是否启用混淆，proguardFiles用于选定混淆配置文件。注意这里是在release闭包内进行配置的，因此只有打出正式版的APK才会进行混淆，Debug版的APK是不会混淆的。当然这也是非常合理的，因为Debug版的APK文件我们只会用来内部测试，不用担心被人破解。<br>那么现在我们来打一个正式版的APK文件，在Android Studio导航栏中点击Build-&gt;Generate Signed APK，然后选择签名文件并输入密码，如果没有签名文件就创建一个，最终点击Finish完成打包，生成的APK文件会自动存放在app目录下。除此之外也可以在build.gradle文件当中添加签名文件配置，然后通过gradlew assembleRelease来打出一个正式版的APK文件，这种方式APK文件会自动存放在app/build/outputs/apk目录下。<br>那么现在已经得到了APK文件，接下来就用上篇文章中学到的反编译知识来对这个文件进行反编译吧，结果如下图所示：<br><img src="http://img.blog.csdn.net/20160307204433418" alt=""></p>
<p>很明显可以看出，我们的代码混淆功能已经生效了。</p>
<p>下面我们尝试来阅读一下这个混淆过后的代码，最顶层的包名结构主要分为三部分，第一个a.a已经被混淆的面目全非了，但是可以猜测出这个包下是LitePal的所有代码。第二个android.support可以猜测出是我们引用的android support库的代码，第三个com.example.guolin.androidtest则很明显就是我们项目的主包名了，下面将里面所有的类一个个打开看一下。<br>首先MainActivity中的代码如下所示：<br><img src="http://img.blog.csdn.net/20160307210746838" alt=""></p>
<p>可以看到，MainActivity的类名是没有混淆的，onCreate()方法也没有被混淆，但是我们定义的方法、全局变量、局部变量都被混淆了。<br>再来打开下一个类NativeUtils，如下所示：<br><img src="http://img.blog.csdn.net/20160307211556583" alt=""></p>
<p>NativeUtils的类名没有被混淆，其中声明成native的方法也没有被混淆，但是非native方法的方法名和局部变量都被混淆了。<br>接下来是a类的代码，如下所示：<br><img src="http://img.blog.csdn.net/20160307211929322" alt=""></p>
<p>很明显，这个是MainActivity中按钮点击事件的匿名类，在onClick()方法中的调用代码虽然都被混淆了，但是调用顺序是不会改变的，对照源代码就可以看出哪一行是调用的什么方法了。<br>再接下来是b类，代码如下所示：<br><img src="http://img.blog.csdn.net/20160307212322827" alt=""></p>
<p>虽然被混淆的很严重，但是我们还是可以看出这个是MyFragment类。其中所有的方法名、全局变量、局部变量都被混淆了。<br>最后再来看下c类，代码如下所示：<br><img src="http://img.blog.csdn.net/20160307212639769" alt=""></p>
<p>c类中只有一个a方法，从字符串的内容我们可以看出，这个是Utils类中的methodNormal()方法。</p>
<p>我为什么要创建这样的一个项目呢？因为从这几个类当中很能看出一些问题，接下来我们就分析一下上面的混淆结果。</p>
<p>首先像Utils这样的普通类肯定是会被混淆的，不管是类名、方法名还是变量都不会放过。除了混淆之外Utils类还说明了一个问题，就是minifyEnabled会对资源进行压缩，因为Utils类中我们明明定义了两个方法，但是反编译之后就只剩一个方法了，因为另外一个方法没有被调用，所以认为是多余的代码，在打包的时候就给移除掉了。不仅仅是代码，没有被调用的资源同样也会被移除掉，因此minifyEnabled除了混淆代码之外，还可以起到压缩APK包的作用。</p>
<p>接着看一下MyFragment，这个类也是混淆的比较彻底的，基本没有任何保留。那有些朋友可能会有疑问，Fragment怎么说也算是系统组件吧，就算普通方法名被混淆了，至少像onCreateView()这样的生命周期方法不应该被混淆吧？其实生命周期方法会不会被混淆和我们使用Fragment的方式有关，比如在本项目中，我使用的是android.support.v4.app.Fragment，support-v4包下的，就连Fragment的源码都被一起混淆了，因此生命周期方法当然也不例外了。但如果你使用的是android.app.Fragment，这就是调用手机系统中预编译好的代码了，很明显我们的混淆无法影响到系统内置的代码，因此这种情况下onCreateView()方法名就不会被混淆，但其它的方法以及变量仍然会被混淆。</p>
<p>接下来看一下MainActivity，同样也是系统组件之一，但MainActivity的保留程度就比MyFragment好多了，至少像类名、生命周期方法名都没有被混淆，这是为什么呢？根据我亲身测试得出结论，凡是需要在AndroidManifest.xml中去注册的所有类的类名以及从父类重写的方法名都自动不会被混淆。因此，除了Activity之外，这份规则同样也适用于Service、BroadcastReceiver和ContentProvider。</p>
<p>最后看一下NativeUtils类，这个类的类名也没有被混淆，这是由于它有一个声明成native的方法。只要一个类中有存在native方法，它的类名就不会被混淆，native方法的方法名也不会被混淆，因为C++代码要通过包名+类名+方法名来进行交互。 但是类中的别的代码还是会被混淆的。</p>
<p>除此之外，第三方的Jar包都是会被混淆的，LitePal不管是包名还是类名还是方法名都被完完全全混淆掉了。</p>
<p>这些就是Android Studio打正式APK时默认的混淆规则。</p>
<p>那么这些混淆规则是在哪里定义的呢？其实就是刚才在build.gradle的release闭包下配置的proguard-android.txt文件，这个文件存放于<android sdk="">/tools/proguard目录下，我们打开来看一下：<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># This is a configuration file for ProGuard.</span></div><div class="line"><span class="comment"># http://proguard.sourceforge.net/index.html#manual/usage.html</span></div><div class="line"></div><div class="line">-dontusemixedcaseclassnames</div><div class="line">-dontskipnonpubliclibraryclasses</div><div class="line">-verbose</div><div class="line"></div><div class="line"><span class="comment"># Optimization is turned off by default. Dex does not like code run</span></div><div class="line"><span class="comment"># through the ProGuard optimize and preverify steps (and performs some</span></div><div class="line"><span class="comment"># of these optimizations on its own).</span></div><div class="line">-dontoptimize</div><div class="line">-dontpreverify</div><div class="line"><span class="comment"># Note that if you want to enable optimization, you cannot just</span></div><div class="line"><span class="comment"># include optimization flags in your own project configuration file;</span></div><div class="line"><span class="comment"># instead you will need to point to the</span></div><div class="line"><span class="comment"># "proguard-android-optimize.txt" file instead of this one from your</span></div><div class="line"><span class="comment"># project.properties file.</span></div><div class="line"></div><div class="line">-keepattributes *Annotation*</div><div class="line">-keep public <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">google</span>.<span class="title">vending</span>.<span class="title">licensing</span>.<span class="title">ILicensingService</span></span></div><div class="line">-keep public <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">android</span>.<span class="title">vending</span>.<span class="title">licensing</span>.<span class="title">ILicensingService</span></span></div><div class="line"></div><div class="line"><span class="comment"># For native methods, see http://proguard.sourceforge.net/manual/examples.html#native</span></div><div class="line">-keepclasseswithmembernames <span class="class"><span class="keyword">class</span> * &#123;</span></div><div class="line">    native &lt;methods&gt;;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># keep setters in Views so that animations can still work.</span></div><div class="line"><span class="comment"># see http://proguard.sourceforge.net/manual/examples.html#beans</span></div><div class="line">-keepclassmembers public <span class="class"><span class="keyword">class</span> * <span class="title">extends</span> <span class="title">android</span>.<span class="title">view</span>.<span class="title">View</span> &#123;</span></div><div class="line">   void set*(***);</div><div class="line">   *** get*();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># We want to keep methods in Activity that could be used in the XML attribute onClick</span></div><div class="line">-keepclassmembers <span class="class"><span class="keyword">class</span> * <span class="title">extends</span> <span class="title">android</span>.<span class="title">app</span>.<span class="title">Activity</span> &#123;</span></div><div class="line">   public void *(android.view.View);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># For enumeration classes, see http://proguard.sourceforge.net/manual/examples.html#enumerations</span></div><div class="line">-keepclassmembers <span class="class"><span class="keyword">enum</span> * &#123;</span></div><div class="line">    public static **[] values();</div><div class="line">    public static ** valueOf(java.lang.String);</div><div class="line">&#125;</div><div class="line"></div><div class="line">-keepclassmembers <span class="class"><span class="keyword">class</span> * <span class="title">implements</span> <span class="title">android</span>.<span class="title">os</span>.<span class="title">Parcelable</span> &#123;</span></div><div class="line">  public static final android.os.Parcelable$Creator CREATOR;</div><div class="line">&#125;</div><div class="line"></div><div class="line">-keepclassmembers <span class="class"><span class="keyword">class</span> **.<span class="title">R</span>$* &#123;</span></div><div class="line">    public static &lt;fields&gt;;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># The support library contains references to newer platform versions.</span></div><div class="line"><span class="comment"># Dont warn about those in case this app is linking against an older</span></div><div class="line"><span class="comment"># platform version.  We know about them, and they are safe.</span></div><div class="line">-dontwarn android.support.**</div></pre></td></tr></table></figure></android></p>
<p>这个就是默认的混淆配置文件了，我们来一起逐行阅读一下。</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">-<span class="ruby">dontusemixedcaseclassnames 表示混淆时不使用大小写混合类名。</span></div><div class="line">-<span class="ruby">dontskipnonpubliclibraryclasses 表示不跳过library中的非public的类。</span></div><div class="line">-<span class="ruby">verbose 表示打印混淆的详细信息。</span></div><div class="line">-<span class="ruby">dontoptimize 表示不进行优化，建议使用此选项，因为根据proguard-android-optimize.txt中的描述，优化可能会造成一些潜在风险，不能保证在所有版本的Dalvik上都正常运行。</span></div><div class="line">-<span class="ruby">dontpreverify 表示不进行预校验。这个预校验是作用在Java平台上的，Android平台上不需要这项功能，去掉之后还可以加快混淆速度。</span></div><div class="line">-<span class="ruby">keepattributes *Annotation* 表示对注解中的参数进行保留。</span></div><div class="line"></div><div class="line">-<span class="ruby">keep public <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">google</span>.<span class="title">vending</span>.<span class="title">licensing</span>.<span class="title">ILicensingService</span></span></span></div><div class="line">-<span class="ruby">keep public <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">android</span>.<span class="title">vending</span>.<span class="title">licensing</span>.<span class="title">ILicensingService</span></span></span></div><div class="line"></div><div class="line">表示不混淆上述声明的两个类，这两个类我们基本也用不上，是接入Google原生的一些服务时使用的。</div><div class="line"></div><div class="line">-<span class="ruby">keepclasseswithmembernames <span class="class"><span class="keyword">class</span> * &#123;</span></span></div><div class="line">    native &lt;methods&gt;;</div><div class="line">&#125;</div><div class="line"></div><div class="line">表示不混淆任何包含native方法的类的类名以及native方法名，这个和我们刚才验证的结果是一致的。</div><div class="line"></div><div class="line">-<span class="ruby">keepclassmembers public <span class="class"><span class="keyword">class</span> * <span class="title">extends</span> <span class="title">android</span>.<span class="title">view</span>.<span class="title">View</span> &#123;</span></span></div><div class="line">   void set*(***);</div><div class="line">   *** get*();</div><div class="line">&#125;</div><div class="line"></div><div class="line">表示不混淆任何一个View中的setXxx()和getXxx()方法，因为属性动画需要有相应的setter和getter的方法实现，混淆了就无法工作了。</div><div class="line"></div><div class="line">-<span class="ruby">keepclassmembers <span class="class"><span class="keyword">class</span> * <span class="title">extends</span> <span class="title">android</span>.<span class="title">app</span>.<span class="title">Activity</span> &#123;</span></span></div><div class="line">   public void *(android.view.View);</div><div class="line">&#125;</div><div class="line"></div><div class="line">表示不混淆Activity中参数是View的方法，因为有这样一种用法，在XML中配置android:onClick=”buttonClick”属性，当用户点击该按钮时就会调用Activity中的buttonClick(View view)方法，如果这个方法被混淆的话就找不到了。</div><div class="line"></div><div class="line">-<span class="ruby">keepclassmembers enum * &#123;</span></div><div class="line">    public static **[] values();</div><div class="line">    public static ** valueOf(java.lang.String);</div><div class="line">&#125;</div><div class="line"></div><div class="line">表示不混淆枚举中的values()和valueOf()方法，枚举我用的非常少，这个就不评论了。</div><div class="line"></div><div class="line">-<span class="ruby">keepclassmembers <span class="class"><span class="keyword">class</span> * <span class="title">implements</span> <span class="title">android</span>.<span class="title">os</span>.<span class="title">Parcelable</span> &#123;</span></span></div><div class="line">  public static final android.os.Parcelable$Creator CREATOR;</div><div class="line">&#125;</div><div class="line"></div><div class="line">表示不混淆Parcelable实现类中的CREATOR字段，毫无疑问，CREATOR字段是绝对不能改变的，包括大小写都不能变，不然整个Parcelable工作机制都会失败。</div><div class="line"></div><div class="line">-<span class="ruby">keepclassmembers <span class="class"><span class="keyword">class</span> **.<span class="title">R</span>$* &#123;</span></span></div><div class="line">    public static &lt;fields&gt;;</div><div class="line">&#125;</div><div class="line"></div><div class="line">表示不混淆R文件中的所有静态字段，我们都知道R文件是通过字段来记录每个资源的id的，字段名要是被混淆了，id也就找不着了。</div><div class="line">-<span class="ruby">dontwarn android.support.** 表示对android.support包下的代码不警告，因为support包中有很多代码都是在高版本中使用的，如果我们的项目指定的版本比较低在打包时就会给予警告。不过support包中所有的代码都在版本兼容性上做足了判断，因此不用担心代码会出问题，所以直接忽略警告就可以了。</span></div></pre></td></tr></table></figure>
<p>好了，这就是proguard-android.txt文件中所有默认的配置，而我们混淆代码也是按照这些配置的规则来进行混淆的。经过我上面的讲解之后，相信大家对这些配置的内容基本都能理解了。不过proguard语法中还真有几处非常难理解的地方，我自己也是研究了好久才搞明白，下面和大家分享一下这些难懂的语法部分。</p>
<p>proguard中一共有三组六个keep关键字，很多人搞不清楚它们的区别，这里我们通过一个表格来直观地看下：</p>
<p>关键字    描述<br>keep    保留类和类中的成员，防止它们被混淆或移除。<br>keepnames    保留类和类中的成员，防止它们被混淆，但当成员没有被引用时会被移除。<br>keepclassmembers    只保留类中的成员，防止它们被混淆或移除。<br>keepclassmembernames    只保留类中的成员，防止它们被混淆，但当成员没有被引用时会被移除。<br>keepclasseswithmembers    保留类和类中的成员，防止它们被混淆或移除，前提是指名的类中的成员必须存在，如果不存在则还是会混淆。<br>keepclasseswithmembernames    保留类和类中的成员，防止它们被混淆，但当成员没有被引用时会被移除，前提是指名的类中的成员必须存在，如果不存在则还是会混淆。</p>
<p>除此之外，proguard中的通配符也比较让人难懂，proguard-android.txt中就使用到了很多通配符，我们来看一下它们之间的区别：</p>
<p>通配符    描述</p>
<p><field>    匹配类中的所有字段</field></p>
<p><method>    匹配类中的所有方法</method></p>
<p><init>    匹配类中的所有构造函数</init></p>
<ul>
<li>匹配任意长度字符，但不含包名分隔符(.)。比如说我们的完整类名是com.example.test.MyActivity，使用com.<em>，或者com.exmaple.</em>都是无法匹配的，因为<em>无法匹配包名中的分隔符，正确的匹配方式是com.exmaple.</em>.<em>，或者com.exmaple.test.</em>，这些都是可以的。但如果你不写任何其它内容，只有一个<em>，那就表示匹配所有的东西。<br><strong>    匹配任意长度字符，并且包含包名分隔符(.)。比如proguard-android.txt中使用的-dontwarn android.support.</strong>就可以匹配android.support包下的所有内容，包括任意长度的子包。<br>**</em>    匹配任意参数类型。比如void set<em>(**</em>)就能匹配任意传入的参数类型，<em>** get</em>()就能匹配任意返回值的类型。<br>…    匹配任意长度的任意类型参数。比如void test(…)就能匹配任意void test(String a)或者是void test(int a, String b)这些方法。</li>
</ul>
<p>虽说上面表格已经解释的很详细了，但是很多人对于keep和keepclasseswithmembers这两个关键字的区别还是搞不懂。确实，它们之间用法有点太像了，我做了很多次试验它们的结果都是相同的。其实唯一的区别就在于类中声明的成员存不存在，我们还是通过一个例子来直接地看一下，先看keepclasseswithmember关键字：</p>
<p>-keepclasseswithmember class * {<br>    native <methods>;<br>}</methods></p>
<p>这段代码的意思其实很明显，就是保留所有含有native方法的类的类名和native方法名，而如果某个类中没有含有native方法，那就还是会被混淆。</p>
<p>但是如果改成keep关键字，结果会完全不一样：</p>
<p>-keep class * {<br>    native <methods>;<br>}</methods></p>
<p>使用keep关键字后，你会发现代码中所有类的类名都不会被混淆了，因为keep关键字看到class *就认为应该将所有类名进行保留，而不会关心该类中是否含有native方法。当然这样写只会保证类名不会被混淆，类中的成员还是会被混淆的。</p>
<p>比较难懂的用法大概就这些吧，掌握了这些内容之后我们就能继续前进了。</p>
<p>回到Android Studio项目当中，刚才打出的APK虽然已经成功混淆了，但是混淆的规则都是按照proguard-android.txt中默认的规则来的，当然我们也可以修改proguard-android.txt中的规则，但是直接在proguard-android.txt中修改会对我们本机上所有项目的混淆规则都生效，那么有没有什么办法只针对当前项目的混淆规则做修改呢？当然是有办法的了，你会发现任何一个Android Studio项目在app模块目录下都有一个proguard-rules.pro文件，这个文件就是用于让我们编写只适用于当前项目的混淆规则的，那么接下来我们就利用刚才学到的所有知识来对混淆规则做修改吧。</p>
<p>这里我们先列出来要实现的目标：</p>
<p>对MyFragment类进行完全保留，不混淆其类名、方法名、以及变量名。<br>对Utils类中的未调用方法进行保留，防止其被移除掉。<br>对第三方库进行保留，不混淆android-support库，以及LitePal库中的代码。</p>
<p>下面我们就来逐一实现这些目标。<br>首先要对MyFragment类进行完全保留可以使用keep关键字，keep后声明完整的类名，然后保留类中的所有内容可以使用*通配符实现，如下所示：</p>
<p>-keep class com.example.guolin.androidtest.MyFragment {<br>    *;<br>}</p>
<p>然后保留Utils类中的未调用方法可以使用keepclassmembers关键字，后跟Utils完整类名，然后在内部声明未调用的方法，如下所示：</p>
<p>-keepclassmembers class com.example.guolin.androidtest.Utils {<br>    public void methodUnused();<br>}</p>
<p>最后不要混淆第三方库，目前我们使用了两种方式来引入第三方库，一种是通过本地jar包引入的，一种是通过remote引入的，其实这两种方式没什么区别，要保留代码都可以使用**这种通配符来实现，如下所示：</p>
<p>-keep class org.litepal.<em>* {
    </em>;<br>}</p>
<p>-keep class android.support.<em>* {
    </em>;<br>}</p>
<p>所有内容都在这里了，现在我们重新打一个正式版的APK文件，然后再反编译看看效果：<br><img src="http://img.blog.csdn.net/20160309225842296" alt=""></p>
<p>可以看到，现在android-support包中所有代码都被保留下来了，不管是包名、类名、还是方法名都没有被混淆。LitePal中的代码也是同样的情况：<br><img src="http://img.blog.csdn.net/20160309230132784" alt=""></p>
<p>再来看下MyFragment中的代码，如下所示：<br><img src="http://img.blog.csdn.net/20160309230332887" alt=""></p>
<p>可以看到，MyFragment中的代码也没有被混淆，按照我们的要求被完全保留下来了。<br>最后再来看一下Utils类中的代码：<br><img src="http://img.blog.csdn.net/20160309230528216" alt=""></p>
<p>很明显，Utils类并没有被完全保留下来，类名还是被混淆了，methodNormal()方法也被混淆了，但是methodUnused()没有被混淆，当然也没有被移除，因为我们的混淆配置生效了。</p>
<p>经过这些例子的演示，相信大家已经对Proguard的用法有了相当不错的理解了，那么根据自己的业务需求来去编写混淆配置相信也不是什么难事了吧？</p>
<p>Progaurd的使用非常灵活，基本上能够覆盖你所能想到的所有业务逻辑。这里再举个例子，之前一直有人问我使用LitePal时的混淆配置怎么写，其实真的很简单，LitePal作为开源库并不需要混淆，上面的配置已经演示了如何不混淆LitePal代码，然后所有代码中的Model是需要进行反射的，也不能混淆，那么只需要这样写就行了：<br>-keep class <em> extends org.litepal.crud.DataSupport {
    </em>;<br>}</p>
<p>因为LitePal中所有的Model都是应该继承DataSupport类的，所以这里我们将所有继承自DataSupport的类都进行保留就可以了。<br>关于混淆APK的用法就讲这么多，如果你还想继续了解关于Proguard的更多用法，可以参考官方文档：<a href="http://proguard.sourceforge.net/index.html#manual/usage.html" target="_blank" rel="external">http://proguard.sourceforge.net/index.html#manual/usage.html</a></p>
<h2 id="混淆Jar"><a href="#混淆Jar" class="headerlink" title="混淆Jar"></a>混淆Jar</h2><p>在本篇文章的第二部分我想讲一讲混淆Jar包的内容，因为APK不一定是我们交付的唯一产品。就比如说我自己，我在公司是负责写SDK的，对于我来说交付出去的产品就是Jar包，而如果Jar包不混淆的话将会很容易就被别人反编译出来，从而泄漏程序逻辑。</p>
<p>实际上Android对混淆Jar包的支持在很早之前就有了，不管你使用多老版本的SDK，都能在 <android sdk="">/tools目录下找到proguard这个文件夹。然后打开里面的bin目录，你会看到如下文件：<br><img src="http://img.blog.csdn.net/20160310231053316" alt=""></android></p>
<p>其中proguardgui.bat文件是允许我们以图形化的方式来对Jar包进行混淆的一个工具，今天我们就来讲解一下这个工具的用法。<br>在开始讲解这个工具之前，首先我们需要先准备一个Jar包，当然你从哪里搞到一个Jar包都是可以的，不过这里为了和刚才的混淆逻辑统一，我们就把本篇文章中的项目代码打成一个Jar包吧。<br>Eclipse中导出Jar包的方法非常简单，相信所有人都会，可是Android Studio当中就比较让人头疼了，因为Android Studio并没有提供一个专门用于导出Jar包的工具，因此我们只能自己动手了。<br>我们需要知道，任何一个Android Studio项目，只要编译成功之后就会在项目模块的build/intermediates/classes/debug目录下生成代码编译过后的class文件，因此只需通过打包命令将这些class文件打包成Jar包就行了，打开cmd，切换到项目的根目录，然后输入如下命令：</p>
<blockquote>
<p>jar -cvf androidtest.jar -C app/build/intermediates/classes/debug .</p>
</blockquote>
<p>在项目的根目录下就会生成androidtest.jar这个文件，这样我们就把Jar包准备好了。<br>现在双击proguardgui.bat打开混淆工具，如果是Mac或Ubuntu系统则使用sh proguardgui.sh命令打开混淆工具，界面如下图所示：<br><img src="http://img.blog.csdn.net/20160312190016290" alt=""></p>
<p>其实从主界面上我们就能看出，这个Proguard工具支持Shrinking、Optimization、Obfuscation、Preverification四项操作，在左侧的侧边栏上也能看到相应的这些选项。Proguard的工作机制仍然还是要依赖于配置文件，当然我们也可以通过proguardgui工具来生成配置文件，不过由于配置选项太多了，每个都去一一设置太复杂，而且大多数还都是我们用不到的配置。因此最简单的方式就是直接拿现有的配置文件，然后再做些修改就行了。<br>那么我们从<android sdk="">/tools/proguard目录下将proguard-android.txt文件复制一份出来，然后点击主界面上的Load configuration按钮来加载复制出来的这份proguard-android.txt文件，完成后点击Next将进入Input/Output界面。<br>Input/Output界面是用于导入要混淆的Jar包、配置混淆后文件的输出路径、以及导入该Jar包所依赖的所有其它Jar包的。我们要混淆的当然就是androidtest.jar这个文件，那么这个Jar包又依赖了哪些Jar包呢？这里就需要整理一下了。<br>首先我们写的都是Java代码，Java代码的运行要基于Jre基础之上，没有Jre计算机将无法识别Java的语法，因此第一个要依赖的就是Jre的rt.jar。<br>然后由于我们导出的Jar包中有Android相关的代码，比如Activity、Fragment等，因此还需要添加Android的编译库，android.jar。<br>除此之外，我们使用的AppCompatActivity和Fragment分别来自于appcompat-v7包和support-v4包，那么这两个Jar包也是需要引入的。<br>最后就是代码中还引入了litepal-1.3.1.jar。<br>整理清楚了之后我们就来一个个添加，Input/Output有上下两个操作界面，上面是用于导入要混淆的Jar包和配置混淆后文件的输出路径的，下面则是导入该Jar包所依赖的所有其它Jar包的，全部导入后结果如下图所示：<br><img src="http://img.blog.csdn.net/20160312201710712" alt=""></android></p>
<p>这些依赖的Jar包所存在的路径每台电脑都不一样，你所需要做的就是在你自己的电脑上成功找到这些依赖的Jar包并导入即可。<br>不过细心的朋友可能会发现，我在上面整理出了五个依赖的Jar包，但是在图中却添加了六个。这是我在写这篇文章时碰到的一个新的坑，也是定位了好久才解决的，我觉得有必要重点提一下。由于我平时混淆Jar包时里面很少会有Activity，所以没遇到过这个问题，但是本篇文章中的演示Jar包中不仅包含了Activty，还是继承自AppCompatActivity的。而AppCompatActivity的继承结构并不简单，如下图所示：<br><img src="http://img.blog.csdn.net/20160312204407738" alt=""></p>
<p>其中AppCompatActivity是在appcompat-v7包中的，它的父类FragmentActivity是在support-v4包中的，这两个包我们都已经添加依赖了。但是FragmentActivity的父类就坑爹了，如果你去看BaseFragmentActivityHoneycomb和BaseFragmentActivityDonut这两个类的源码，你会发现它们都是在support-v4包中的：<br><img src="http://img.blog.csdn.net/20160312205140269" alt=""></p>
<p><img src="http://img.blog.csdn.net/20160312205157303" alt=""></p>
<p>可是如果你去support-v4的Jar包中找一下，你会发现压根就没有这两个类，所以我当时一直混淆报错就是因为这两个类不存在，继承结构在这里断掉了。而这两个类其实被规整到了另外一个internal的Jar包中，所以当你要混淆的Jar包中有Activity，并且还是继承自AppCompatActivity或FragmentActivity的话，那么就一定要记得导入这个internal Jar包的依赖，如下图所示：<br><img src="http://img.blog.csdn.net/20160312210100619" alt=""></p>
<p>接下来点击Next进入Shrink界面，这个界面没什么需要配置的东西，但记得要将Shrink选项钩掉，因为我们这个Jar包是独立存在的，没有任何项目引用，如果钩中Shrink选项的话就会认为我们所有的代码都是无用的，从而把所有代码全压缩掉，导出一个空的Jar包。<br>继续点击Next进入Obfuscation界面，在这里可以添加一些混淆的逻辑，和混淆APK时不同的是，这里并不会自动帮我们排除混淆四大组件，因此必须要手动声明一下才行。点击最下方的Add按钮，然后在弹出的界面上编写排除逻辑，如下图所示：<br><img src="http://img.blog.csdn.net/20160312220931102" alt=""></p>
<p>很简单，就是在继承那一栏写上android.app.Activity就行了，其它的组件原理也相同。<br>继续点击Next进入Optimiazation界面，不用修改任何东西，因为我们本身就不启用Optimization功能。继续点击Next进入Information界面，也不用修改任何东西，因为我们也不启用Preverification功能。<br>接着点击Next，进入Process界面，在这里可以通过点击View configuration按钮来预览一下目前我们的混淆配置文件，内容如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">-injars /<span class="type">Users</span>/guolin/<span class="type">AndroidStudioProjects</span>/<span class="type">AndroidTest</span>/androidtest.jar</div><div class="line">-outjars /<span class="type">Users</span>/guolin/androidtest_obfuscated.jar</div><div class="line"></div><div class="line">-libraryjars /<span class="type">Library</span>/<span class="type">Java</span>/<span class="type">JavaVirtualMachines</span>/jdk1<span class="number">.7</span><span class="number">.0</span>_79.jdk/<span class="type">Contents</span>/<span class="type">Home</span>/jre/lib/rt.jar</div><div class="line">-libraryjars /<span class="type">Users</span>/guolin/<span class="type">Library</span>/<span class="type">Android</span>/sdk/platforms/android<span class="number">-23</span>/android.jar</div><div class="line">-libraryjars /<span class="type">Users</span>/guolin/<span class="type">AndroidStudioProjects</span>/<span class="type">AndroidTest</span>/app/build/intermediates/exploded-aar/com.android.support/appcompat-v7/<span class="number">23.2</span><span class="number">.0</span>/jars/classes.jar</div><div class="line">-libraryjars /<span class="type">Users</span>/guolin/<span class="type">AndroidStudioProjects</span>/<span class="type">AndroidTest</span>/app/build/intermediates/exploded-aar/com.android.support/support-v4/<span class="number">23.2</span><span class="number">.0</span>/jars/classes.jar</div><div class="line">-libraryjars /<span class="type">Users</span>/guolin/<span class="type">AndroidStudioProjects</span>/<span class="type">AndroidTest</span>/app/build/intermediates/exploded-aar/com.android.support/support-v4/<span class="number">23.2</span><span class="number">.0</span>/jars/libs/internal_impl<span class="number">-23.2</span><span class="number">.0</span>.jar</div><div class="line">-libraryjars /<span class="type">Users</span>/guolin/<span class="type">AndroidStudioProjects</span>/<span class="type">AndroidTest</span>/app/libs/litepal<span class="number">-1.3</span><span class="number">.1</span>.jar</div><div class="line"></div><div class="line">-dontshrink</div><div class="line">-dontoptimize</div><div class="line">-dontusemixedcaseclassnames</div><div class="line">-keepattributes *<span class="type">Annotation</span>*</div><div class="line">-dontpreverify</div><div class="line">-verbose</div><div class="line">-dontwarn android.support.**</div><div class="line"></div><div class="line"></div><div class="line">-keep public <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">google</span>.<span class="title">vending</span>.<span class="title">licensing</span>.<span class="title">ILicensingService</span></span></div><div class="line"></div><div class="line">-keep public <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">android</span>.<span class="title">vending</span>.<span class="title">licensing</span>.<span class="title">ILicensingService</span></span></div><div class="line"></div><div class="line"># keep setters in <span class="type">Views</span> so that animations can still work.</div><div class="line"># see http:<span class="comment">//proguard.sourceforge.net/manual/examples.html#beans</span></div><div class="line">-keepclassmembers public <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">view</span>.<span class="title">View</span> </span>&#123;</div><div class="line">    void set*(***);</div><div class="line">    *** get*();</div><div class="line">&#125;</div><div class="line"></div><div class="line"># <span class="type">We</span> want to keep methods in <span class="type">Activity</span> that could be used in the <span class="type">XML</span> attribute onClick</div><div class="line">-keepclassmembers <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">app</span>.<span class="title">Activity</span> </span>&#123;</div><div class="line">    public void *(android.view.<span class="type">View</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line">-keepclassmembers <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">os</span>.<span class="title">Parcelable</span> </span>&#123;</div><div class="line">    public static <span class="keyword">final</span> android.os.<span class="type">Parcelable</span>$<span class="type">Creator</span> <span class="type">CREATOR</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line">-keepclassmembers <span class="class"><span class="keyword">class</span> <span class="title">**</span>.<span class="title">R$*</span> </span>&#123;</div><div class="line">    public static &lt;fields&gt;;</div><div class="line">&#125;</div><div class="line"></div><div class="line">-keep <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">app</span>.<span class="title">Activity</span></span></div><div class="line"></div><div class="line">-keep <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">app</span>.<span class="title">Service</span></span></div><div class="line"></div><div class="line">-keep <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">content</span>.<span class="title">BroadcastReceiver</span></span></div><div class="line"></div><div class="line">-keep <span class="class"><span class="keyword">class</span> <span class="title">*</span> <span class="keyword">extends</span> <span class="title">android</span>.<span class="title">content</span>.<span class="title">ContentProvider</span></span></div><div class="line"></div><div class="line"># <span class="type">Also</span> keep - <span class="type">Enumerations</span>. <span class="type">Keep</span> the special static methods that are required in</div><div class="line"># enumeration classes.</div><div class="line">-keepclassmembers enum  * &#123;</div><div class="line">    public static **[] values();</div><div class="line">    public static ** valueOf(java.lang.<span class="type">String</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"># <span class="type">Keep</span> names - <span class="type">Native</span> method names. <span class="type">Keep</span> all native <span class="class"><span class="keyword">class</span><span class="title">/method</span> <span class="title">names</span>.</span></div><div class="line">-keepclasseswithmembers,allowshrinking <span class="class"><span class="keyword">class</span> <span class="title">*</span> </span>&#123;</div><div class="line">    native &lt;methods&gt;;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>恩，由此可见其实GUI工具只是给我们提供了一个方便操作的平台，背后工作的原理还是通过这些配置来实现的，相信上面的配置内容大家应该都能看得懂了吧。<br>接下来我们还可以点击Save configuration按钮来保存一下当前的配置文件，这样下次混淆的时候就可以直接Load进来而不用修改任何东西了。<br>最后点击Process!按钮来开始混淆处理，中间会提示一大堆的Note信息，我们不用理会，只要看到最终显示Processing completed successfully，就说明混淆Jar包已经成功了，如下图所示：<br><img src="http://img.blog.csdn.net/20160312223044035" alt=""></p>
<p>混淆后的文件我将它配置在了/Users/guolin/androidtest_obfuscated.jar这里，如果反编译一下这个文件，你会发现和刚才反编译APK得到的结果是差不多的：MainActivity的类名以及从父类继承的方法名不会被混淆，NativeUtils的类名和其中的native方法名不会被混淆，Utils的methodUnsed方法不会被移除，因为我们禁用了Shrink功能，其余的代码都会被混淆。由于结果实在是太相似了，我就不再贴图了，参考本篇文章第一部分的截图即可。</p>
<p>好了，本篇文章的内容就到这里，混淆技术掌握这么多相信已经足够大家在平时的工作当中使用了。当然除了使用混淆之外，还有一些加固软件也能提升程序的安全性，不过这些软件都是第三方的，并非Google原生支持，所以我就不进行讲解和推荐了。那么我们Android安全攻防战系列的文章到此结束，感谢大家有耐心看到最后。</p>
<p>关注我的技术公众号，每天都有优质技术文章推送。关注我的娱乐公众号，工作、学习累了的时候放松一下自己。</p>
<p>微信扫一扫下方二维码即可关注：<br><img src="http://img.blog.csdn.net/20160507110203928" alt=""><br><img src="http://img.blog.csdn.net/20161011100137978" alt="">         </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/guolin_blog/article/details/49738023&quot;&gt;Android安全攻防战，反编译与混淆技术完全解析（上）&lt;/a&gt;&lt;br&gt; &lt;a href=&quot;http://blog.csdn.net/guolin_blog/article/details/50451259&quot;&gt; Android安全攻防战，反编译与混淆技术完全解析（下）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;http://img.blog.csdn.net/20160312190016290&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt; 之前一直有犹豫过要不要写这篇文章，毕竟去反编译人家的程序并不是什么值得骄傲的事情。不过单纯从技术角度上来讲，掌握反编译功能确实是一项非常有用的技能，可能平常不太会用得到，但是一旦真的需要用到的了，而你却不会的话，那就非常头疼了。另外既然别人可以反编译程序，我们当然有理由应该对程序进行一定程度的保护，因此代码混淆也是我们必须要掌握的一项技术。那么最近的两篇文章我们就围绕反编译和混淆这两个主题来进行一次完全解析。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>多媒体技术基础之---重新认识声音</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-sound/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-sound/</id>
    <published>2017-02-27T03:25:06.000Z</published>
    <updated>2017-02-27T03:36:29.623Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-3995439.html" target="_blank" rel="external">wjlkoorey</a></p>
<p>声音一个最基本的常识就是“它是一种能量”，初中物理课上我们也学过声音的三要素分别是音色、音调和响度。<br>    音色：简单理解，就是一种声音的固有特征。比如，电子琴和小提琴发出的声音是有明显区别的，笛子和古筝也有各自的声音特征。有些声音模仿秀的选手可以通过训练，达到模仿不同人或者不同乐器的效果。<br>   音调：也就是我们所说的频率，单位是赫兹Hz，频率越高听起来越刺耳、越尖锐，频率越低听起来越低沉、越浑厚。医学研究表明，人的听觉系统能察觉的最低频率为20Hz，最高为20000Hz，超出这个范围人类一般就听不到了。其实现实生活中根本就不存在完全能听到20Hz~20kHz这样的人，并且随着年龄的增长、体质的变化，人能听到的声音只会是这个区间的一个子集。<br><img src="http://blog.chinaunix.net/attachment/201311/10/23069658_138409370409ZO.png" alt=""></p>
   <a id="more"></a>
<p>人对不同频率、不同分贝的声音的生理反应也是有差别的，正如我们中医里提到的“五音”(角、徵、宫、商、羽)和身体脏腑(心、肝、脾、肺、肾)以及对人心神(喜、怒、忧、思、悲)的影响是一样的。</p>
<p><img src="http://blog.chinaunix.net/attachment/201311/10/23069658_1384093724q0YL.png" alt=""></p>
<p>例如“宫”调，风格悠扬沉静、淳厚庄重，根据五音通五脏的理论，宫调入脾，对消化系统的作用比较明显。这就是为什么很多古代电视或者电影里，皇庭寿宴席的时候一般都是奏宫乐。如果对中华文化感兴趣的朋友肯定注意到，我们古代繁体字的药材的“藥”和音乐的“樂”的字根是一样的，可见老祖宗造字时并不是瞎画的，这说明声音的确还是可以治病。现在精通音律的老师傅是越来越少了。感慨一句，中华文明，博大精深，后继者何也？呜呼。。。扯远了，收一下。</p>
<pre><code>而人一般能发出的声音频率也是男女有别，大致范围如下：
</code></pre><p>低音<br>中音<br>高音<br>男<br>82 Hz～392Hz<br>123 Hz～493Hz<br>164 Hz～698Hz<br>女<br>220 Hz～1.1kHz</p>
<p>响度：就是声音的大小，一般用“分贝”来表示，单位是dB，这个参数说明了声音所携带的能量的大小，声音越大，在相同传播介质里所能传递的距离就远。</p>
<p> 在物理世界里，我们的声音在传输过程中都是连续，像下面这个样子：<br> <img src="http://blog.chinaunix.net/attachment/201311/10/23069658_13840939771O1F.jpg" alt=""></p>
<p>可是如果要让计算机来处理它，就牵扯到我们经常说的数字化了。关于声音在数字化过程中有三个核心步骤：采样、量化和编码。</p>
<p>采样：在模拟声音的时间轴上周期性地取点，将时域连续的模拟信号变成离散信号的过程就叫做采样。每秒钟的采样点越多，数字化之后的声音就越接近原模拟声音。每秒钟的采样次数就叫做采样频率，根据奈奎斯特定律，采样频率fs和被采样声音的最高频率fmax的关系如下：</p>
<p>fs≥2fmax</p>
<pre><code>PS：有些地方把声音的频谱范围也叫做声音的带宽，指的是声音从最低频率到最高频率之间的宽度。
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201311/10/23069658_1384094004w8fw.jpg" alt=""></p>
<p>量化：用于表示在采样点所获取的声音能量值。量化就是将空域连续的模拟信号转换成离散信号的过程。量化精度越高，所能表示的声音采样范围就越大，量化误差就也越小，相应地，所占用的存储空间也就越大。简而言之，就是对于采样所得到的样本点，我们打算用几位二进制数来表示它。例如，如果是8bit的量化精度，那么我们最多能表示的采样点就只有256个；如果是16bit，最多能表示的采样点就可以多达65536个。<br><img src="http://blog.chinaunix.net/attachment/201311/10/23069658_1384094029b5Cz.jpg" alt=""></p>
<p>编码：对于经过采样量化后的数据按一定的算法进行编码处理。在计算机里最接近模拟声音的编码方式就是PCM脉冲编码方式。那么对于上述量化结果，我们发现这段音频采样点的量化空间最多也就是11个，我们用4bit就可以完全表示它们了。所以量化精度就是4bit，可表示的样本空间是[0~15]，因此，上述编码序列就是{3，5，6，7，8，5，4，8，10，8，5，1，1，2，5}。</p>
<p> 当然，真正到了量化阶段时又分均匀量化和非均匀量化，量化的同时就自动编码成PCM格式的数据了。通常意义来说，量化和编码都是同时进行的。</p>
<p>ITU-T建议的G.711是最早公布的语音编码标准，它规定了A律13折线和u律15折线PCM编码的两种方案。这里就不再继续展开了，都是数学层面的东东，不纠结。中国和欧洲采用的A律13折线的PCM编码方式，北美和日本采用的是u律15折线的PCM编码方式。</p>
<p>在计算机里我们就认为PCM就是数字音频信号的原始无损格式，其存储方式通常是.wav文件，即wav格式的音频文件就是原始的未经任何压缩处理的数字音频文件，这样的文件大部分情况下都来自于录音设备。如果你使用音频格式转换工具将mp3转成wav的话，那么很不幸的是你的这个wav并不是无损格式的文件，因为mp3格式的文件是对原始wav文件经过有损压缩后得来的，而这个过程不是可逆的，即mp3转成的wav只有原始wav的部分信息。但从人的听觉系统来说，一般人是分辨不出来其中的差别，除非用专业发烧级音响设备，再加上一双有着专业特性的耳朵，区别还是很明显的。</p>
<p> 例如，我们手头现在有款奥林巴斯的LS-14专业数码录音笔，我们将采样频率设为44100Hz，量化精度为16bit，采用双声道的模式进行音频录制，每秒钟所产生的数据量为44100x16x2=176400 bit，那么3分钟将会产生的声音数据约为30.28MB。显然，这个结果显然不太令人满意，接下来就有了各种音频压缩算法的出现，也就是多媒体技术术语里所说的编码器，其实就是压缩算法而已。目的只有一个：在高保真原有音质的前提下，最大限度地对数字化之后的PCM编码文件进行压缩，以降低其所占的磁盘空间。整个过程可以描述如下：<br> <img src="http://blog.chinaunix.net/attachment/201311/10/23069658_138409406581r9.jpg" alt=""></p>
<p>幸运的是，现在PCM编码方式已经固化在很多音频设备的DSP芯片里了，不需要我们关心。一种编码算法一定对应一种相应的解码算法才行，不然编来有毛用。我们可以看到，整个过程中PCM编码格式充当了各种编解码器之间转换的中间桥梁，这也就是为什么我们说PCM格式的声音文是计算机里的“模拟文件”的原因了。不管是不同音频压缩格式之间的互相转换，还是最终输送给数模转换器的格式都是PCM格式。<br><img src="http://blog.chinaunix.net/attachment/201311/10/23069658_1384094084gcI8.jpg" alt=""><br>上面几种格式里有个flac和其他几种格式有着本质的区别，flac是无损压缩格式，和它齐名还有家喻户晓的ape格式。什么意思？无损格式的音频文件是在对原始wav文件压缩是没有删减过滤它的任何信息的情况下，完全通过算法活生生的把wav文件的体重给减了下来，而且flac和ape可以完整还原原始wav的所有信息，一个毫毛都不差。ape的压缩比高达55%。这和那些有损压缩的mp3、ogg、aac等是没法相比的，因为人家是无损的，就这么简单。有些人喜欢听CD，而另外一些人则喜欢听mp3，其实他们根本就不是一个级别的，也没有可比性的。最后，献上天王的一首单曲以飨各位看官肯花宝贵的时间听我在这里唧唧歪歪的大半天，配上森海或者AKG的耳机好好享受一下生活吧(不敢保证每个人能都听到那种感觉，毕竟人家mp3也不是盖的)。</p>
<p>   人生不止眼前的代码和BUG，还有耳朵与音乐。</p>
<p>   附件：<a href="http://dl.vmall.com/c0qe0zv7zm" target="_blank" rel="external">Billie.Jean-ape</a>和<a href="http://dl.vmall.com/c0ub3dwmx4" target="_blank" rel="external">Billie.Jean-mp3</a></p>
<h2 id="多媒体技术基础之—Come-on！来点儿音乐吧"><a href="#多媒体技术基础之—Come-on！来点儿音乐吧" class="headerlink" title="多媒体技术基础之—Come on！来点儿音乐吧"></a><a href="http://blog.chinaunix.net/uid-23069658-id-4008256.html" target="_blank" rel="external">多媒体技术基础之—Come on！来点儿音乐吧</a></h2><p>其实要说在Linux系统下播放音乐，确实是一件让人非常抓狂的事情，抛开各种音频格式的商业授权不说，即使提供给你相应的解码库，能玩儿得转的人那又是少之又少。可能有些盆友说ubuntu这方面确实做得不错，一旦默认安装好，几乎不用装任何其他东西，常见的是音频文件都可以正常播放了。因为我天生就有股喜欢折腾的劲儿，所以关于ubuntu确实不怎么感冒，只能说萝卜白菜各有所爱吧。今天我们以wav文件(也就是上一篇博文所提到的PCM格式的音频文件)为例，看看在Linux下怎么播放它，顺便会简单介绍一下Linux系统的音频驱动框架的基础知识。<br>   说到Linux系统下的音频系统驱动框架，最常见的有OSS和ALSA。我们先来简单了解一下这两个框架，以及它们的历史渊源。<br>   OSS全称是Open Sound System，叫做开放式音频系统，最早是Unix系统上一种统一的音频接口。这种基于文件系统的统一访问方式，就意味着对声音的操作完全可以像对普通文件那样执行open，read，write和close等操作，这也正是得益于文件系统的强大有力支撑。OSS中，主要提供了一下几种音频设备的抽象设备文件：<br>   /dev/mixer：用来访问声卡中内置的混音器mixer，用于调整音量大小和选择音源；<br>    /dev/dsp、/dev/audio：读这个设备就相当于录音，写这个设备就相当于放音。/dev/dsp与/dev/audio的主要区别在于所采样的PCM编码方式的不同，/dev/audio使用的是μ律编码(存在这个设备文件的目的主要是为了与SunOS兼容，所以在非SunOS系统中尽量不要使用)，而/dev/dsp使用8-bit（无符号）的线性编码；<br>   /dev/sequencer、/dev/sequencer2：主要用于访问声卡内置的，或者连接在MIDI接口的合成器synthesizer。<br>    还有其他的诸如/dev/adsp、/dev/dmmidi、/dev/midi等等，一些不常用的就先不管了。看一下我的CentOS 5.3内核版本2.6.21系统中的音频设备文件：<br><img src="http://blog.chinaunix.net/attachment/201311/24/23069658_13853074187WTO.jpg" alt=""><br>   我们可以直接使用Unix/Linux的命令来放音和录音，例如，命令cat /dev/dsp &gt;xyz 可用来录音，录音的结果放在xyz文件中；命令cat xyz &gt;/dev/dsp播放声音文件xyz。当然，我们还可以通过open、close、read、write、ioctl等这些文件的操作函数直接控制这些设备，达到对声音应用程序级别的访问与控制。那么这么看来OSS应该还算比较完美了，Linux下的声音编程应该没有难度才对，怎么会说Linux下声音变成是一件很头疼的事儿呢？<br>    其实OSS自从诞生到OSSv3版及其之前，都是Linux的原始声音系统，并集成在内核代码里。当OSS被4Front Technologies收购后，于2002年OSSv4作为商业软件的出现时，它的命运就被我们接下来要介绍的ALSA给改写了。其实严格意义上来说，商业化不是导致OSS没落的根本原因，也有技术层面的因素在，比如OSS的混音功能。由于先天的设计缺陷，OSS对混音的支持非常糟糕，由于当时的声卡本身是支持多路输出的混合，所以OSS就偷懒了，将混音的任务交给了声卡，所以那个年代的程序猿们为了操作混音器，代码里充斥着大量的ioctl函数，现在看起来相当难受。<br>   ALSA全称是Advanced Linux Sound Architecture，叫做Linux系统下的高级音频架构，它主要为声卡提供的驱动组件，以替代原先的 OSS。这个项目最早始于1998年Gravis Ultrasound所开发的驱动，它一直作为一个单独的软件包开发，直到2002年他被引进入Linux内核的开发版本(2.5.4-2.5.5)。自从2.6版本开始ALSA成为Linux内核中默认的标准音频驱动程序集，而OSS则被标记为废弃。所以，现在看来OSS被ALSA替代，闭源和商业化都只是外因，内因还是其设计的缺陷。虽然2007年4Front又宣布OSSv4重新在GPL协议下重新开源，但已经人去楼空秋已暮了，现在ALSA对OSS的支持也比较好了，不知道OSS还能否王者归来。其实这些都不重要，对于开发者来说，简单、便捷、高效、实用才是王道，优美的框架结构，完善的文档支持强过口水战百倍。<br>目前ALSA已经成为Linux系统里主流的音频系统框架，在2.6.21的内核里已经看不到OSS的影子了。在内核设备驱动层面，ALSA提供了alsa-driver，同时在应用层，ALSA也为我们提供了alsa-lib，应用程序只要调用alsa-lib所提供的API，就可以完成对底层音频硬件的控制：<br><img src="http://blog.chinaunix.net/attachment/201311/24/23069658_13853074737dQd.gif" alt=""><br>    上图向我们展示了ALSA的一个简单的结构，用户空间的alsa-lib对应用程序提供统一的API接口，这样可以隐藏了驱动层的实现细节，简化了应用程序的实现难度。内核空间中，alsa-soc其实是对alsa-driver的进一步封装，针对嵌入式设备提供了一些列增强的功能，通常也被叫做ASoC，即Alsa-soc的缩写，像Android系统中底层就用了ASoC。想了解ALSA更多细节的盆友可以访问他们的官网：<a href="http://www.alsa-project.org/main/index.php/Main_Page" target="_blank" rel="external">http://www.alsa-project.org/main/index.php/Main_Page</a></p>
<pre><code>下面，我们首先看一下OSS下如何播放wav文件：
</code></pre><figure class="highlight arduino"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">点击(此处)折叠或打开</div><div class="line"><span class="comment">/*playsound.c*/</span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/soundcard.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> AUDIO_DEVICE <span class="meta-string">"/dev/dsp"</span></span></div><div class="line"></div><div class="line"><span class="keyword">int</span> play_sound(<span class="keyword">char</span> *filename,<span class="keyword">int</span> rate,<span class="keyword">int</span> bits)&#123;</div><div class="line">        <span class="keyword">struct</span> stat stat_buf;</div><div class="line">        <span class="keyword">unsigned</span> <span class="keyword">char</span> *buf = NULL;</div><div class="line">        <span class="keyword">int</span> result,arg,status,handler,fd;</div><div class="line"></div><div class="line">        fd = <span class="built_in">open</span>(filename,O_RDONLY);</div><div class="line">        <span class="built_in">if</span>(fd&lt;<span class="number">0</span>)</div><div class="line">        <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line">        <span class="built_in">if</span>(fstat(fd,&amp;stat_buf))</div><div class="line">        &#123;</div><div class="line">                <span class="built_in">close</span>(fd);</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="built_in">if</span>(!stat_buf.st_size)</div><div class="line">        &#123;</div><div class="line">                <span class="built_in">close</span>(fd);</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        buf=malloc(stat_buf.st_size);</div><div class="line">        <span class="built_in">if</span>(!buf)&#123;</div><div class="line">                <span class="built_in">close</span>(fd);</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="built_in">if</span>(<span class="built_in">read</span>(fd,buf,stat_buf.st_size)&lt;<span class="number">0</span>)&#123;</div><div class="line">                free(buf);</div><div class="line">                <span class="built_in">close</span>(fd);</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        handler = <span class="built_in">open</span>(AUDIO_DEVICE,O_WRONLY);</div><div class="line">        <span class="built_in">if</span>(<span class="number">-1</span> == handler)&#123;</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        arg = rate*<span class="number">2</span>;</div><div class="line">        status = ioctl(handler,SOUND_PCM_WRITE_RATE,&amp;arg);</div><div class="line">        <span class="built_in">if</span>(<span class="number">-1</span> == status)</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line">        arg = bits;</div><div class="line">        status = ioctl(handler,SOUND_PCM_WRITE_BITS,&amp;arg);</div><div class="line">        <span class="built_in">if</span>(<span class="number">-1</span> == status)</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line">        result = <span class="built_in">write</span>(handler,buf,stat_buf.st_size);</div><div class="line">        <span class="built_in">if</span>(<span class="number">-1</span> == result)</div><div class="line">                <span class="built_in">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line">        free(buf);</div><div class="line">        <span class="built_in">close</span>(fd);</div><div class="line">        <span class="built_in">close</span>(handler);</div><div class="line">        <span class="built_in">return</span> result;</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">int</span> main(<span class="keyword">int</span> argc,<span class="keyword">char</span>** argv)&#123;</div><div class="line">        play_sound(argv[<span class="number">1</span>],atoi(argv[<span class="number">2</span>]),atoi(argv[<span class="number">3</span>]));</div><div class="line">        <span class="built_in">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>因为只是演示用，所以错误判断就少了一些。另外，为了让我们的播放程序自动获得音频文件的参数，诸如采样率，量化精度等，我又提供了一个shell脚本player：<br>点击(此处)折叠或打开</p>
<p>#!/bin/sh<br>[ “$#” -eq 0 ] &amp;&amp; {<br>echo “Usage: $0 filename”<br>exit<br>}<br>BITS=<code>file $1 | cut -d&#39; &#39; -f9</code><br>RATE=<code>file $1 | cut -d&#39; &#39; -f12</code></p>
<p>echo “Playing…$(file $1)”<br>./playsound $1 $RATE $BITS<br>    将上述C文件编译，然后，在命令行之./player 文件名，不出意外的话就可以听到声音了，只可惜没办法演示这个过程：<br><img src="http://blog.chinaunix.net/attachment/201311/24/23069658_13853075854iMV.jpg" alt=""><br>   我的系统确实可以听到，但是声音比较小，如果你在命令行执行amixer的话，应该可以看到下面的输出信息：<br><img src="http://blog.chinaunix.net/attachment/201311/24/23069658_138530762766Px.jpg" alt=""><br>   我的声卡音量居然只有75%(因为我用的虚拟机)，然后一句“amixer set Master 100%”命令下去，再重新播放声音，应该就很happy了。<br><img src="http://blog.chinaunix.net/attachment/201311/24/23069658_1385307678NQug.jpg" alt=""><br>    其实大家可能有点疑惑，不是前面介绍了半天ALSA的好处了，怎么用OSS来示范，是不是专拣软柿子捏啊。再说了，现在很多人的系统几乎都不支持OSS了，上面的代码有毛用。其实我也很不甘心，所以又重新装了CentOS6.3的虚拟系统，用ALSA的API再来播一下wav看得行不，经过N个小时的折腾，皇天不负有心人—It’s OK！(新手入门，大家来找BUG吧 :) )<br>   内核版本2.6.32，看一下/dev目录下确实没有dsp和mixer设备文件了，取而代之的/dev/snd目录。在centos5.3里我们也见到过这个目录，但当时还只是试用阶段，现在alsa已经完全扶正了：<br><img src="http://blog.chinaunix.net/attachment/201311/24/23069658_138530769878Ug.jpg" alt=""><br>播放代码如下：<br>点击(此处)折叠或打开<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/soundcard.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;alsa/asoundlib.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="meta">#define ALSA_MAX_BUF_SIZE 65535</span></div><div class="line"></div><div class="line"><span class="built_in">int</span> play_sound(char* filename,<span class="built_in">int</span> rate,<span class="built_in">int</span> bits,<span class="built_in">int</span> channel,<span class="built_in">int</span> order)</div><div class="line">&#123;</div><div class="line">        long loops<span class="comment">;</span></div><div class="line">        <span class="built_in">int</span> rc,size,dir<span class="comment">;</span></div><div class="line">        snd_pcm_t *handle<span class="comment">;</span></div><div class="line">        snd_pcm_hw_params_t *params<span class="comment">;</span></div><div class="line">        snd_pcm_uframes_t frames,periodsize<span class="comment">;</span></div><div class="line">        snd_mixer_t *mixer<span class="comment">;</span></div><div class="line">        snd_mixer_elem_t *pcm_element<span class="comment">;</span></div><div class="line"></div><div class="line">        char *buffer<span class="comment">;</span></div><div class="line">        unsigned <span class="built_in">int</span> val<span class="comment">;</span></div><div class="line">        FILE *fp = fopen(filename,<span class="string">"rb"</span>)<span class="comment">;</span></div><div class="line">        rc = snd_pcm_open(&amp;handle,<span class="string">"default"</span>,SND_PCM_STREAM_PLAYBACK,<span class="number">0</span>)<span class="comment">;</span></div><div class="line"></div><div class="line">        snd_pcm_hw_params_alloca(&amp;params)<span class="comment">;</span></div><div class="line">        snd_pcm_hw_params_any(handle,params)<span class="comment">;</span></div><div class="line">        snd_pcm_hw_params_set_access(handle,params,SND_PCM_ACCESS_RW_INTERLEAVED)<span class="comment">;</span></div><div class="line">        <span class="keyword">switch</span>(order)&#123;</div><div class="line">                <span class="keyword">case</span> <span class="number">1</span>:</div><div class="line">                        snd_pcm_hw_params_set_format(handle,params,SND_PCM_FORMAT_S16_LE)<span class="comment">;</span></div><div class="line">                        <span class="built_in">break</span><span class="comment">;</span></div><div class="line">                <span class="keyword">case</span> <span class="number">2</span>:</div><div class="line">                        snd_pcm_hw_params_set_format(handle,params,SND_PCM_FORMAT_S16_BE)<span class="comment">;</span></div><div class="line">                        <span class="built_in">break</span><span class="comment">;</span></div><div class="line">                defualt:</div><div class="line">                        <span class="built_in">break</span><span class="comment">;</span></div><div class="line">        &#125;</div><div class="line">        snd_pcm_hw_params_set_channels(handle,params,channel)<span class="comment">;</span></div><div class="line"></div><div class="line">        val = rate<span class="comment">;</span></div><div class="line">        snd_pcm_hw_params_set_rate_near(handle,params,&amp;val,<span class="number">0</span>)<span class="comment">;</span></div><div class="line">        snd_pcm_hw_params_get_buffer_size_max(params,&amp;frames)<span class="comment">;</span></div><div class="line">        frames = frames &lt; ALSA_MAX_BUF_SIZE? frames:ALSA_MAX_BUF_SIZE<span class="comment">;</span></div><div class="line">        rc = snd_pcm_hw_params_set_buffer_size_near(handle,params,&amp;frames)<span class="comment">;</span></div><div class="line">        snd_pcm_hw_params_get_period_size_min(params,&amp;periodsize,<span class="literal">NULL</span>)<span class="comment">;</span></div><div class="line">        <span class="keyword">if</span>(!periodsize)&#123;</div><div class="line">                periodsize=size/<span class="number">4</span><span class="comment">;</span></div><div class="line">        &#125;</div><div class="line">        rc = snd_pcm_hw_params_set_period_size_near(handle,params,&amp;periodsize,<span class="literal">NULL</span>)<span class="comment">;</span></div><div class="line">        rc = snd_pcm_hw_params(handle,params)<span class="comment">;</span></div><div class="line"></div><div class="line">        snd_mixer_open(&amp;mixer,<span class="number">0</span>)<span class="comment">;</span></div><div class="line">        snd_mixer_attach(mixer,<span class="string">"default"</span>)<span class="comment">;</span></div><div class="line">        snd_mixer_selem_register(mixer,<span class="literal">NULL</span>,<span class="literal">NULL</span>)<span class="comment">;</span></div><div class="line">        snd_mixer_load(mixer)<span class="comment">;</span></div><div class="line">        <span class="keyword">for</span>(pcm_element = snd_mixer_first_elem(mixer)<span class="comment">;pcm_element;pcm_element=snd_mixer_elem_next(pcm_element))</span></div><div class="line">        &#123;</div><div class="line">                <span class="keyword">if</span>(snd_mixer_elem_get_type(pcm_element)==SND_MIXER_ELEM_SIMPLE &amp;&amp; snd_mixer_selem_is_active(pcm_element))</div><div class="line">                &#123;</div><div class="line">                        <span class="keyword">if</span>(!strcmp(snd_mixer_selem_get_name(pcm_element),<span class="string">"Master"</span>))</div><div class="line">                        &#123;</div><div class="line">                                snd_mixer_selem_set_playback_volume_range(pcm_element,<span class="number">0</span>,<span class="number">100</span>)<span class="comment">;</span></div><div class="line">                                snd_mixer_selem_set_playback_volume_all(pcm_element,(long)<span class="number">100</span>)<span class="comment">;</span></div><div class="line">                        &#125;</div><div class="line">                &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        buffer = (char*)malloc(size)<span class="comment">;</span></div><div class="line">        <span class="keyword">while</span>(<span class="number">1</span>)</div><div class="line">        &#123;</div><div class="line">                rc = fread(buffer,<span class="number">1</span>,size,fp)<span class="comment">;</span></div><div class="line">                <span class="keyword">if</span>(<span class="number">0</span>== rc)</div><div class="line">                        <span class="built_in">break</span><span class="comment">;</span></div><div class="line">                <span class="keyword">while</span>((rc = snd_pcm_writei(handle,buffer,size))&lt;<span class="number">0</span>)</div><div class="line">                &#123;</div><div class="line">                        usleep(<span class="number">200</span>)<span class="comment">;</span></div><div class="line">                        <span class="keyword">if</span>(-EPIPE == rc)</div><div class="line">                                snd_pcm_prepare(handle)<span class="comment">;</span></div><div class="line">                        <span class="keyword">else</span> <span class="keyword">if</span>(<span class="number">0</span> &gt; rc)</div><div class="line">                                printf(<span class="string">"error fomr writei\n"</span>)<span class="comment">;</span></div><div class="line">                &#125;</div><div class="line">        &#125;</div><div class="line">        snd_pcm_drain(handle)<span class="comment">;</span></div><div class="line">        snd_pcm_close(handle)<span class="comment">;</span></div><div class="line">        free(buffer)<span class="comment">;</span></div><div class="line">        snd_mixer_close(mixer)<span class="comment">;</span></div><div class="line">        fclose(fp)<span class="comment">;</span></div><div class="line">        <span class="keyword">return</span> <span class="number">0</span><span class="comment">;</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="built_in">int</span> main(<span class="built_in">int</span> argc,char** argv)&#123;</div><div class="line">        play_sound(argv[<span class="number">1</span>],atoi(argv[<span class="number">2</span>]),atoi(argv[<span class="number">3</span>]),atoi(argv[<span class="number">4</span>]),atoi(argv[<span class="number">5</span>]))<span class="comment">;</span></div><div class="line">        <span class="keyword">return</span> <span class="number">0</span><span class="comment">;</span></div><div class="line">&#125;</div><div class="line">   然后将player脚本也对应修改一下：   </div><div class="line">点击(此处)折叠或打开</div><div class="line"><span class="meta">#!/bin/sh</span></div><div class="line">[ <span class="string">"$#"</span> -eq <span class="number">0</span> ] &amp;&amp; &#123;</div><div class="line">echo <span class="string">"Usage: $0 filename"</span></div><div class="line"><span class="keyword">exit</span></div><div class="line">&#125;</div><div class="line">ORDER=`file $1 | cut -d<span class="string">' '</span> -f3`</div><div class="line">BITS=`file $1 | cut -d<span class="string">' '</span> -f9`</div><div class="line">CHANNEL=`file $1 | cut -d<span class="string">' '</span> -f11`</div><div class="line">RATE=`file $1 | cut -d<span class="string">' '</span> -f12`</div><div class="line"><span class="meta">#channel</span></div><div class="line"><span class="keyword">if</span> [ <span class="string">"$CHANNEL"</span> == <span class="string">"stereo"</span> ]<span class="comment">; then</span></div><div class="line">CHANNEL=<span class="number">2</span></div><div class="line"><span class="keyword">else</span></div><div class="line">CHANNEL=<span class="number">1</span></div><div class="line">fi</div><div class="line"><span class="meta">#platform-byte-order</span></div><div class="line"><span class="keyword">if</span> [ <span class="string">"$ORDER"</span> == <span class="string">"(little-endian)"</span> ]<span class="comment">; then</span></div><div class="line">ORDER=<span class="number">1</span></div><div class="line"><span class="keyword">else</span></div><div class="line">ORDER=<span class="number">2</span></div><div class="line">fi</div><div class="line">echo <span class="string">"Playing...$(file $1)"</span></div><div class="line">./playsound $1 $RATE $BITS $CHANNEL $ORDER</div></pre></td></tr></table></figure></p>
<p> 编译C文件时，由于我们用了alsa库，所以gcc的编译选项要加上-lasound才可以。如果播放时声音很小，可以用amixer来调节音量。如果不幸的是你系统里找不到amixer命令的话，就用yum install alsa-utils或者下载alsa源码来安装吧。</p>
<p> 附件是测试用的音频文件，另外，后面我会将完整支持OSS和ALSA两种架构的最终播放代码放在github上，有需要的盆友到时候可以拿去鼓捣鼓捣，今天就先到这里吧。</p>
<p> 附件:<a href="http://www.kuaipan.cn/file/id_32913876282507542.htm" target="_blank" rel="external">news.wav</a></p>
<h2 id="CentOS6-4完全安装FFmpeg手记"><a href="#CentOS6-4完全安装FFmpeg手记" class="headerlink" title="CentOS6.4完全安装FFmpeg手记 "></a><a href="http://blog.chinaunix.net/uid-23069658-id-4018842.html" target="_blank" rel="external">CentOS6.4完全安装FFmpeg手记 </a></h2><p> 鼓捣媒体的人对FFmpeg应该不会陌生，它不仅功能强大，结构优美，灵活、易扩展，也是很其他多媒体播放器的基础，例如VLC，Mplayer等等，还有好多商业播放器都用了ffmpeg，但这些商业软件却没有遵守GPL公约，所以它们都被钉在了ffmpeg官网的“耻辱柱”上。关于ffmpeg还有一点题外话，那就是有一个叫做libav的开源项目。libav是从ffmpeg分化出来的一个项目，而这个项目诞生的原因和技术本身并没有任何关系，最大的分歧在于ffmpeg内部有一帮人对于ffmpeg项目的管理方式觉得不happy了，所以他们就自立门户，成立了libav这个项目。有意思的是libav官网的logo和ffmpeg官网的logo有点“小过节”，libav把ffmpeg官网那个偏着脑袋的logo给端正了，至于他们想传达的意义我觉得每个人都应该有自己的理解和认识。好了，开场预热就到这里，该干活了。<br>   CentOS6.4的内核版本2.6.32-358，GCC版本是4.4.7，安装ffmpeg的版本是1.2，ffmpeg官网最新的版本是2.1，看着版本号差异挺大，其实从1.2到2.1中间仅隔了一个2.0版，是2013年7月10号刚发布。<br>   安装前的准备工作当然是先安装各种工具：</p>
<p>点击(此处)折叠或打开<br>[root@localhost src]# pwd<br>/usr/local/src<br>[root@localhost src]# yum install automake autoconf make gcc gcc-c++ libtool zlib zlib-devel curl curl-devel alsa-lib alsa-lib-devel gettext gettext-devel expat expat-devel<br>   ffmpeg作为一个多媒体框架和平台，最大的优势就在于可以很灵活地支持多种编解码和其他特性，只要第三方外部库支撑都可以做到。本次安装下列第三包依赖包：<br>   faac：全称是Free Advanced Audio Coder，是MPEG-4和MPEG-2 AAC的一款常用的开源编解码器；<br>   lame：一款常见的mp3的开源编解码器；<br>   libass：先说一下ASS/SSA，其全称是Advanced Substation Alpha/Substation Alpha，是一种功能极为强大的字幕格式，主要用在视频文件里显示字幕。而libASS是一个轻量级的对ASS/SSA格式字幕进行渲染的函数库，使用C编写,效率非常高；<br>   libdc1394：这是面向高级语言编程接口的一个库，主要提供了对符合IEEE 1394规范的数码摄录设备的一组操作接口。符合1395规范的数码相机标准的全称是1394-based Digital Camera Specifications，简称为IIDC或DCAM。安装dc1394需要先安装raw1394；<br>   libfreetype2：freetype是一个用C语言实现的一个字体光栅化库，它可以用来将字符栅格化并映射成位图以及提供其他字体相关业务的支持。freetype提供了一个简单、易用并统一的接口来访问字体文件的内容。freetype不仅被自由桌面系统软件所使用，同时它也是现代视频游戏广泛使用的栅格化引擎；<br>   libvorbis：这个库主要用于处理ogg格式的音频文件，而ogg全称是ogg vorbis，一种类似mp3的音频压缩格式。不同于mp3的是ogg完全免费、开放和没有专利限制的。ogg文件格式可以不断地进行大小和音质的改良，而不影响旧有的编码器或播放器，主要由Xiph.org基金会开发；<br>   libtheora：theora也是Xiph.org基金会开发，是一种有损的影像压缩格式；<br>   openssl：这个就不多说了，很多安全框架的基础；<br>   rtmpdump：一个开源的rtmp格式的流媒体库，RTMP(Real Time Messaging Protocol)是Adobe Systems公司为它自家的flash播放器和服务器之间音频、视频和数据传输开发的一种开放的传输协议；<br>   speex：speex是一套主要针对语音的开源免费、无专利保护的音频压缩格式，致力于通过提供一个可以替代高性能语音编解码来降低语音应用输入门槛。相对于其它编解码器，speex非常适合网络应用，因为它专为2-44kpbs语音码流所设计，所以在网络应用上有着自己独特的优势；<br>   twolame：一个开源的mp2格式的编解码库；<br>   vo-aacenc：AAC格式的常用的音频编码器；<br>   xvidcore：是一个开放源代码的MPEG-4视频编解码器；<br>   x264：目前最流行，最常见的H.264视频格式的一个开源的编解码器；</p>
<p>   将需要的软件包全部下载后，剩下的事儿就非常简单：“三大步”—configure &amp;&amp; make &amp;&amp; make install<br>   安装顺序如下：faac、lame、libtheora(需要先安装libogg)、libvorbis、vo-aacenc、xvidcore、x264、libdc1394(需要先安装libraw1394)、libass(需要先依次安装libfreetype2、fribidi和fonconfig)、openssl、librtmp、libspeex、twolame、yasm，最后安装ffmpeg。</p>
<p>   在通过源码包安装上述软件时，如果在configure阶段没有用–prefix指定安装目录，默认情况下安装的顶级目录是/usr/local，可执行程序会被安装到/usr/local/bin，动态库被安装到/usr/local/lib，头文件在/usr/local/include等等。这样会有一个小小的麻烦，例如当先安装libogg后，再安装libtheora时，你有可能会收到如下的错误提示信息：<br>checking pkg-config is at least version 0.9.0… yes<br>checking for OGG… no<br>checking for Ogg… no<br><strong><em> Could not run Ogg test program, checking why…
</em></strong> The test program compiled, but did not run. This usually means<br><strong><em> that the run-time linker is not finding Ogg or finding the wrong
</em></strong> version of Ogg. If it is not finding Ogg, you’ll need to set your<br><strong><em> LD_LIBRARY_PATH environment variable, or edit /etc/ld.so.conf to point
</em></strong> to the installed location  Also, make sure you have run ldconfig if that<br><em>*</em> is required on your system</p>
<hr>
<p><strong><em> If you have an old version installed, it is best to remove it, although
</em></strong> you may also be able to get things to work by modifying LD_LIBRARY_PATH<br>configure: error:<br>    libogg is required to build this package!<br>    please see <a href="http://www.xiph.org/" target="_blank" rel="external">http://www.xiph.org/</a> for how to<br>    obtain a copy.</p>
<p>   明明安装了ogg但theora却认为咱们没安装。原因在哪里，当然是动态库的查找路径了，想了解详情的童鞋请移步这里。我的解决办法是在 /etc/ld.so.conf.d/目录下创建一个名为local-libraries.conf的文件，内容很简单，只有一行：</p>
<p>点击(此处)折叠或打开<br>[root@localhost src]# cat /etc/ld.so.conf.d/local-libraries.conf<br>/usr/local/lib<br>[root@localhost src]#</p>
<p>   然后执行ldconfig -v，然后再安装libtheora就很happy了。<br>   当然还没完，当你在安装libass时，当你把所有依赖包都先安装之后，在configure阶段，它总会提醒你说：<br>Package requirements (freetype2 &gt;= 9.10.3) were not met</p>
<p>   任凭你怎么执行ldconfig都没用。不过你要是注意到错误提示信息其实问题的解决也就挺简单，在configure阶段在探测依赖包时用到了一个叫做pkg-config的工具，它会自动去查找当前系统是否支持某些类型的动态库文件，主要是通过一个<em>.pc文件。而一些标准so库源码包里都会提供一个这样的文件以便pkg-config来用，而问题就在pkg-config查找</em>.pc文件的路径上。关于这个工具更多细节就不展开了，感兴趣的朋友可以去google一下。这里我的解决办法是：</p>
<p>点击(此处)折叠或打开<br>[root@localhost libass-0.10.1]# export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH<br>    然后安装libass时也就很happy了。<br>    最后，在安装ffmpeg前需要先安装yasm，版本至少1.2.0以上。</p>
<pre><code>下面是我的安装ffmpeg时相关软件包的配置情况，以便各位参考：
</code></pre><p>1 faac<br>[root@localhost faac]#./bootstrap<br>[root@localhost faac]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost faac]#make &amp;&amp; make install</p>
<p>2 lame<br>[root@localhost lame-3.98.4]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost lame-3.98.4]#make &amp;&amp; make install</p>
<p>3 libogg<br>[root@localhost libogg-1.3.0]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libogg-1.3.0]#make &amp;&amp; make install</p>
<p>4 libtheora<br>[root@localhost libtheora-1.1.1]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libtheora-1.1.1]#ldconfig -v<br>[root@localhost libtheora-1.1.1]#make &amp;&amp; make install</p>
<p>5 libvorbis<br>[root@localhost libvorbis-1.3.3]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libvorbis-1.3.3]#make &amp;&amp; make install</p>
<p>6 vo-aacenc<br>[root@localhost vo-aacenc-0.1.2]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost vo-aacenc-0.1.2]#make &amp;&amp; make install</p>
<p>7 xvidcore<br>[root@localhost xvidcore-1.3.2]#./configure –prefix=/usr/local/<br>[root@localhost xvidcore-1.3.2]#make &amp;&amp; make install</p>
<p>8 yasm<br>[root@localhost yasm-1.2.0]#./configure –prefix=/usr/local/<br>[root@localhost yasm-1.2.0]#make &amp;&amp; make install</p>
<p>9 x264<br>[root@localhost x264-snapshot-20130505-2245]#./configure –prefix=/usr/local/ –enable-shared –enable-pic<br>[root@localhost x264-snapshot-20130505-2245]#make &amp;&amp; make install</p>
<p>10 libraw1394<br>[root@localhost libraw1394-2.0.5]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libraw1394-2.0.5]#make &amp;&amp; make install</p>
<p>11 libdc1394<br>[root@localhost libdc1394-2.2.1]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libdc1394-2.2.1]#make &amp;&amp; make install</p>
<p>12 libfreetype<br>[root@localhost libfreetype2-master]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libfreetype2-master]#make &amp;&amp; make install</p>
<p>13 fribidi<br>[root@localhost fribidi-0.19.4]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost fribidi-0.19.4]#make &amp;&amp; make install</p>
<p>14 fonconfig<br>[root@localhost fontconfig-2.9.0]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost fontconfig-2.9.0]#make &amp;&amp; make install</p>
<p>15 libass<br>[root@localhost libass-0.10.1]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost libass-0.10.1]#make &amp;&amp; make install (xuyao )</p>
<p>16 openssl<br>[root@localhost openssl-1.0.1c]#./config –prefix=/usr/local/ –openssldir=/usr/local/openssl threads zlib-dynamic shared<br>[root@localhost openssl-1.0.1c]#make &amp;&amp; make install</p>
<p>17 librtmp<br>[root@localhost rtmpdump-2.3]#make SYS=posix<br>[root@localhost rtmpdump-2.3]#make install</p>
<p>18 libspeex<br>[root@localhost speex-1.2rc1]#./configure –prefix=/usr/local/ –enable-shared –enable-sse<br>[root@localhost speex-1.2rc1]#make &amp;&amp; make install</p>
<p>19 twolame<br>[root@localhost twolame-0.3.13]#./configure –prefix=/usr/local/ –enable-shared<br>[root@localhost twolame-0.3.13]#make &amp;&amp; make install</p>
<p>20 FFmpeg<br>[root@localhost ffmpeg-1.2]#./configure –prefix=/usr/local/ –enable-gpl –enable-version3 –enable-nonfree –enable-shared –enable-zlib –enable-bzlib –enable-libfaac –enable-libmp3lame –enable-libtheora –enable-libvo-aacenc –enable-libvorbis –enable-libx264 –enable-libxvid –enable-pic –enable-pthreads –enable-libdc1394 –enable-libass –enable-pic –enable-openssl –enable-libtwolame –enable-libspeex –enable-librtmp –enable-libfreetype<br>[root@localhost ffmpeg-1.2]#make &amp;&amp; make install</p>
<pre><code>安装完成后，测试一下：
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201311/30/23069658_1385809025K33k.jpg" alt=""><br>   为了方便各位测试，本文中用到的所有软件包已经放在网盘里，有需要的朋友请到<a href="http://dl.vmall.com/c0xhuwtm1m" target="_blank" rel="external">这里</a>下载。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3995439.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;声音一个最基本的常识就是“它是一种能量”，初中物理课上我们也学过声音的三要素分别是音色、音调和响度。&lt;br&gt;    音色：简单理解，就是一种声音的固有特征。比如，电子琴和小提琴发出的声音是有明显区别的，笛子和古筝也有各自的声音特征。有些声音模仿秀的选手可以通过训练，达到模仿不同人或者不同乐器的效果。&lt;br&gt;   音调：也就是我们所说的频率，单位是赫兹Hz，频率越高听起来越刺耳、越尖锐，频率越低听起来越低沉、越浑厚。医学研究表明，人的听觉系统能察觉的最低频率为20Hz，最高为20000Hz，超出这个范围人类一般就听不到了。其实现实生活中根本就不存在完全能听到20Hz~20kHz这样的人，并且随着年龄的增长、体质的变化，人能听到的声音只会是这个区间的一个子集。&lt;br&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201311/10/23069658_138409370409ZO.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Multimedia" scheme="http://ipcreator.me/tags/Multimedia/"/>
    
  </entry>
  
  <entry>
    <title>多媒体技术基础之---视频</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-video/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-video/</id>
    <published>2017-02-27T03:19:06.000Z</published>
    <updated>2017-02-27T03:24:48.940Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-4193903.html" target="_blank" rel="external">wjlkoorey</a></p>
<p>我们都知道，视频本质上源于电影。2014年冯导的《私人订制》里葛大爷对“全球最俗大导”说了那么一番话，印象比较深刻：“经过考证，电影是大众娱乐，起源于走马灯。本身就是一俗艺术，和雅压根儿就不沾边。”而当代科学史研究者们大都依据文学家范成大（1126—1193）的诗文记载，认为南宋时才有走马灯。走马灯的两个主要特点分别是：<br>一、利用热气流作动力；<br>二、以涡轮装置带动灯上画面转动。<br><img src="http://blog.chinaunix.net/attachment/201404/2/23069658_1396447551ns0f.gif" alt=""></p>
   <a id="more"></a>
<p>   以这两点继续追溯可以到北宋年间，著名北宋诗人吴潜观灯有感，写下:“半勺兰膏暖焰生，恍疑赤壁夜鏖兵。骑乘猛燎奔驰疾，人运长枪转战轻。旗影静移云母帐，剑铓微掣水晶营。何人幻此圆机妙，独向元宵策美名。”从内容到形式详述走马灯闪亮登场的过程。也就是说走马灯距今已有将近1300多年的历史了。然而，在当代电影起源发展史上走马灯却很少被人提起。</p>
<p>   关于电影的起源，美国人会告诉你说是爱迪生发明的；法国人会说是卢米埃尔兄弟发明的。其实 <strong>电影是建立在一种名为“视觉暂留原理”的基础上</strong>。人脑保留视像的时间会比眼睛真正记录它的时间略长一点。如果不是这样，我们对世界的视觉感知就会不断被眨眼的动作打断。但实际上，在双眼闭上的那一刹那，大脑会“保存”视像。类似地，当静止的图像以最短的间隔从人眼前闪过时，大脑也会发挥保存图像的作用。<strong>电影不是真的在动，而是一组以每秒24格的速度放映的静止画面，这样的速度使人觉得动作是连续的。</strong></p>
<p>   该原理是比利时著名物理学家约瑟夫普拉多于1829年发现。随后，普拉多依据此原理于1832年发明了“诡盘”。“诡盘”能使被描画在锯齿形的硬纸盘上的画片因运动而活动起来，而且能使视觉上产生的活动画面分解为各种不同的形象。“诡盘”的出现，标志着电影的发明进入到了科学实验阶段。随后的美国人霍尔纳、奥地利的冯乌却迪奥斯、法国的W尼埃普斯、美国旧金山摄影师爱德华幕布里奇、法国生理学家马莱都为随后电影业的发展做出过巨大的贡献。<br>   <img src="http://blog.chinaunix.net/attachment/201404/2/23069658_1396447593j7w4.jpg" alt=""></p>
<p>1889年，美国发明大王爱迪生在发明了电影留影机后，又经过5年的实验后，发明了电影视镜。他将摄制的胶片影像在纽约公映，轰动了美国。但他的电影视镜每次仅能供一人观赏，一次放几十英尺的胶片，内容是跑马、舞蹈表演等。他的电影视镜是利用胶片的连续转动，造成活动的幻觉，电影视镜传到我国后被称之为 “西洋镜”。如果大家看过徐克导演，李连杰、关之琳主演的《黄飞鸿》，“十三姨”手里经常拿着的那个拍电影的东西就是西洋镜。但“十三姨”那会儿用的西洋镜已经是法国卢米埃尔兄弟改良过之后的版本。</p>
<p>1895年，法国的奥古斯特卢米埃尔和路易卢米埃尔兄弟，在爱迪生的 “电影视镜”和他们自己研制的 “连续摄影机”的基础上，研制成功了“活动电影机”。“活动电影机”有摄影、放映和洗印等三种主要功能。它以每秒16画格的速度拍摄和放映影片，图像清晰稳定。1895年3月22日，他们在巴黎法国科技大会上首放影片《卢米埃尔工厂的大门》获得成功。同年12月28日，他们在巴黎的卡普辛路14号大咖啡馆里，正式向社会公映了他们自己摄制的一批纪实短片，有《火车到站》、《水浇园丁》、《婴儿的午餐》、《工厂的大门》等12部影片。卢米埃尔兄弟是第一个利用银幕进行投射式放映电影的人，因此他们也被后人誉为近代电影的开山鼻祖。</p>
<p> 这里我们来看一下电影中“帧”的概念。<strong>根据“视觉残留原理”24帧/秒是可以给人带来基本流畅、感觉不到卡顿的基本体验的最低播放频率。</strong> 传统的电影都是用连续长胶片拍摄，主要在银幕上播放。另外还有一点，就是电影在放映时胶片是连续的。例如，前面一个胶片离放映窗还有2/3的距离时，下一张胶片的1/3就已经进入放映窗了。这样一来老式电影播放时会经常出现时快时慢，无连续感等现象。所以在放映电影时通常都会给放映窗口增加一个遮光器，即放映窗有个电机带动着一个黑色的扇叶不停的转动，将每格胶片遮挡两次，这样就将每秒24帧的频率提升一倍到48Hz(注意：早期电影的拍摄和放映仍旧是以24帧/秒的帧率进行的)，这样一来我们的眼睛就会觉得图像更加连贯和流畅了。</p>
<p>  当模拟电视出现后，出现了一对名词“隔行扫描”和“逐行扫描”，以及PAL制和NTSC制两个概念。为了不冲淡主题，关于这两个知识点大家可以如果想进一步了解，可以点击“这里”。简而言之，在隔行扫描的显示设备中，每一帧图像被分割为两场画面交替显示。第一场(奇数场)电子枪只扫一帧图像的所有描奇数行，依次扫描1、3、5…行，而第二场(偶数场)电子枪只扫描偶数行，依次扫描2、4、6…行等等。逐行扫描显示一帧图像时，电子枪只要一行接着一行扫，不用区分奇偶场，扫完所有行就OK了。关于PAL制和NTSC制区别记住下述两点：<br>   PAL制电视机供电频率50Hz，场频50场/秒，帧频率25帧/秒，扫描线625行。代表国家中国、德国、新加坡等；<br>   NTSC制电视机供电频率60Hz，场频60场/秒，帧频30帧/秒，扫描线525行。代表地区美国日本等。</p>
<p>   当然，不管是通过无线电还是互联网来传输电影或者视频，都避不开数字化的话题。现在的数字摄像机已不像传统的胶片摄像机那样简陋，数字摄像机在拍摄的时候我们只要设置好我们需要的参数就可以了。那么在数字视频中，帧的概念已经不同于传统胶卷上一个图像的意义了。之前我们计算过，一部1024×768分辨率，采用aRGB色彩空间存储，8位深度，时常90分钟的视频，需要占用的带宽是3Mbps，占用的存储空间是15.83GB左右。</p>
<p>   所以，对于数字图像，我们一般有两方面的压缩。一是帧内压缩，就是采用YUV色彩空间，然后配合各种压缩算法(例如H.264，mpeg4等等)在不影响用户视觉体验的前提下，最大限度的降低图像本身所占用的空间；二是帧间压缩，因为通常情况下，相邻两帧图像之间其实有很多重复，相似信息，可以采用帧间自适应、行程编码、预测编码、运动补偿等方式。</p>
<p>   采用压缩算法时，在制作或者转换视频时一般将几帧图像分为一个组GOP，为了防止运动变化，帧数不宜过多。在用ffmpeg转换视频时有一个参数可以设置这个GOP。数字视频里每个帧都被归成三类：关键帧I，非关键帧P或者B。一个GOP就是一个I帧、数个P、B帧的分组。<br>   I帧：表示关键帧，是一帧画面的完整的所有信息；解码时只需要本帧数据就可以显示画面；</p>
<p>   P帧：表示前向预测帧，表示的是这一帧跟之前的一个关键帧I（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面；</p>
<p>   B帧：是双向预测帧，即B帧是本帧与前后帧的差别。B帧一般需要参考其前向的I帧或者P帧，以及后一个P帧的数据才能完整解码一帧图像数据。</p>
<p>所以说，只有关键帧才可以独立的完整复原图像，P帧和B帧都是图像的相对信息差量，他们单独存在时并不能完整解码视频文件的一帧图像信息。<br>   说的云里雾里的，让我们看个实际的例子。那就是本周五即将上映的《美国队长2》的宣传片：<br>   <img src="http://blog.chinaunix.net/attachment/201404/2/23069658_13964466949rUx.jpg" alt=""></p>
<p>我们用Elecard截取其中一个片段，看一下它的帧编码、显示顺序情况：<br>   这个文件的帧编码信息是，红色为I帧，蓝色为P帧，绿色为B帧，其帧编码顺序是：<br>   IPPPPPPPPPPPPPPPPPPPBBPBBPBBPBBBPBBPBPBPBBP…<br>   但是显示设备解码显示时却不能按照这样的顺序进行，为什么？因为解码B帧时需要参考其前面的I帧或者P帧，以及后面的P帧才可以完整解码B帧的画面。下面我们将用表格分析一下帧的显示顺序和编码顺序的区别：(为了画表格方便，我将I帧后面紧挨着的19个P帧缩减为3个，但这并不影响分析效果)。修改后的编码顺序为：<br>    <img src="http://blog.chinaunix.net/attachment/201404/2/23069658_1396446776Xyfs.jpg" alt=""><br>      视频帧编码顺序和显示顺序分别如下表所示：<br>   <img src="http://blog.chinaunix.net/attachment/201404/2/23069658_1396446855faY8.jpg" alt=""><br>      本文只是简单对视频文件中基本帧的概念作了介绍，方便入门的朋友学习了解。至于编解码、音视频同步、显示等技术领域暂时还不涉及，有需要再说吧。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-4193903.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们都知道，视频本质上源于电影。2014年冯导的《私人订制》里葛大爷对“全球最俗大导”说了那么一番话，印象比较深刻：“经过考证，电影是大众娱乐，起源于走马灯。本身就是一俗艺术，和雅压根儿就不沾边。”而当代科学史研究者们大都依据文学家范成大（1126—1193）的诗文记载，认为南宋时才有走马灯。走马灯的两个主要特点分别是：&lt;br&gt;一、利用热气流作动力；&lt;br&gt;二、以涡轮装置带动灯上画面转动。&lt;br&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201404/2/23069658_1396447551ns0f.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Multimedia" scheme="http://ipcreator.me/tags/Multimedia/"/>
    
  </entry>
  
  <entry>
    <title>多媒体技术基础之---图像</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-picture/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-picture/</id>
    <published>2017-02-27T03:04:06.000Z</published>
    <updated>2017-02-27T03:19:13.799Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-4065867.html" target="_blank" rel="external">wjlkoorey</a></p>
<p>2012年11月13日，83岁的柯达公司退休工程师布赖斯·拜尔(Bryce Bayer)离开了这个世界，永远离开了我们，离开了爱戴他的人们，而他在数字图像领域的杰出成就不应该就这样被淹没在历史的洪流里，所以，谨以2014年第一篇博文献给伟大的布赖斯·拜尔先生。<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_1388929985kw9Y.jpg" alt=""></p>
   <a id="more"></a>
<h2 id="图像的历史"><a href="#图像的历史" class="headerlink" title="图像的历史"></a>图像的历史</h2><p>   根据维基百科的记载，世界上的第一张照片是法国人约瑟夫·尼塞福尔·涅普斯于1826年拍摄完成。1825年时，涅普斯委托法国光学仪器商人夏尔·雪弗莱（Charles Chevalier）为他的暗箱（camera obscura）制作光学镜片，并于1826年(有说1827年)将其发明的感光材料放进暗箱，拍摄现存最早的照片。作品在其法国勃艮第的家里拍摄完成，通过其阁楼上的窗户拍摄，曝光时间超过8小时。<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_1388930037AYYP.jpg" alt=""></p>
<pre><code>当年，他拍照时采用的感光剂是氯化银(silver chloride)。氯化银的一个非常重要的特性是当光线照射氯化银时，氯化银会分解成纯银和氯气，纯银在空气中很快氧化变成黑色。因此，底片颜色越深代表光线越强，颜色越浅代表光线越弱。黑白照片就是这样拍出来的。为了避免冲淡主题，如果想了解照片又是如何洗出来的盆友们，请点击[这里](http://zhishi.maigoo.com/7845.html)。
</code></pre><p>   为了了解图像基础，我们首先需要一些额外知识来做铺垫和填充：<strong>图像的本质。不像声音，图像其实是我们人的视觉系统对外界的一种感受。</strong> 听着有点玄乎，还是让我们先从彩色图像说起吧！(因为黑白图像实在太简单了)</p>
<h2 id="图像的本质"><a href="#图像的本质" class="headerlink" title="图像的本质"></a>图像的本质</h2><p>   人类的视觉系统为什么能感知各种各样的颜色呢？这个问题最早可以追溯到18世纪，当时的Young（1809）和Helmholtz（1824）共同提出了人类视觉的三原色学说(也就是我们现在经常说提到的RGB色彩空间的鼻祖)，他们认为即：人类的视网膜存在三种视锥细胞，分别含有对红、绿、蓝三种光线敏感的视色素，当一定波长的光线作用于视网膜时，以一定的比例使三种视锥细胞分别产生不同程度的兴奋，这样的信息传至中枢，就产生某一种颜色的感觉。</p>
<pre><code>到了70年代，由于实验技术的进步，关于视网膜中有三种对不同波长光线特别敏感的视锥细胞的假说，已经被许多出色的实验所证实。例如：
</code></pre><p>   ①有人用不超过单个视锥直径的细小单色光束，逐个检查并绘制在体(最初实验是在金鱼和蝾螈等动物进行，以后是人)视锥细胞的光谱吸收曲线，发现所有绘制出来的曲线不外三种类型，分别代表了三类光谱吸收特性不同的视锥细胞，一类的吸收峰值在420nm处，一类在534nm处，一类在564nm处，差不多正好相当于蓝、绿、红三色光的波长。与上述视觉三原色学说的假设相符。<br>   ②用微电极记录单个视锥细胞感受器电位的方法，也得到了类似的结果，即不同单色光所引起的不同视锥细胞的超极化型感受器电位的大小也不同，峰值出现的情况也符合于三原色学说。<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_1388930928uTu9.jpg" alt=""><br>    19世纪中期，英国物理学家麦克斯韦以视觉三原色作为前提和假设，提出红绿蓝作为基色，可以拍出彩色图片的论断。1861年，在麦克斯韦的指导下，人类的第一张彩色照片诞生了。拍摄采用的方法也非常简单，就是在镜头前分别用红丝带、绿丝带、蓝丝带过滤光线，曝光形成三张底片，然后用三部放映机向同一处投影这三张底片，每部放映机的镜头前都拧上对应颜色的镜头，它们的合成效果就是一张彩色照片。<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_1388931281rrwO.jpg" alt=""><br>    然而，真正意义上的彩色胶卷其实是柯达公司1933年生产。虽然2013年柯达刚刚宣布破产，但也无法否认他曾在影像界的王者地位。</p>
<h2 id="图像数字化的原理"><a href="#图像数字化的原理" class="headerlink" title="图像数字化的原理"></a>图像数字化的原理</h2><pre><code>第二次世界大战结束后，随着原子能技术、微电子、计算机、分子生物和遗传工程等领域的重大突破，标志着人类第三次科技革命的开始。随后的年代里，听到的最多的一个词就是“数字化”，到处都在谈数字化，就像当我们时下都说的“土豪”这个词。那时，如果你和人见面不聊点“e时代”的东西，还真不好意思。

很多人都可能不知道，图像领域数字化的理论基础是爱因斯坦的光电理论，通过图像传感器(image sensor)将光信号转换成电信号，然后再将模拟的电信号转换成数字信号来完成。**图像传感器本质上就是一个感光元件**，它与我们常见的太阳能电池有一些类似之处，**整块感光元件就是一个太阳能电池矩阵，每个像素点对应一个感光单位。** 当光照射到感光单元后，它会测量出光的强度然后产生一个相应的电信号，在经过模数转换电路A/D对电信号进行采样，紧接着是量化和编码并存储。这就是完成了图像的数字化。
</code></pre><p>   然而，<strong>图像传感器有个非常大的缺陷：它只能感受光的强弱，无法感受光的波长。由于光的颜色是由波长决定的，所以图像传播器无法记录光的颜色值</strong>，也就是说，它只能拍黑白照片，这当然是无法容忍的。在前面麦克斯韦等人的影响下，人们开始尝试如何将彩色图片进行数字化。根据RGB三原色理论，一种解决办法就是照相机内置三个图像传感器，分别记录红、绿、蓝三种颜色，然后再将这三个值合并。这种方法能产生最准确的颜色信息，但是成本太高(现在很多高端大气上档次的人在追求这种模式，也已经有厂家推出了相应的设备，但价格非一般人能负担得起)。 1974年，柯达公司的工程师布赖斯·拜尔提出了一个全新方案，只用一块图像传感器，就解决了颜色的识别。他的做法是在图像传感器前面，设置一个滤光层(Color filter array)，上面布满了滤光点，与下层的像素点逐一对应。也就是说，<strong>如果传感器是1600×1200个像素，那么它的上层就有1600×1200个滤光点。</strong><br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_1388931468z90y.jpg" alt=""><br>    每个感光单元就是一个像素，它前面的遮光片点只能允许通过红、绿、蓝之中的一种颜色，这意味着在它下层的像素点只可能有四种颜色：红、绿、蓝、黑(表示没有任何光通过)，就像给每个像素点都“戴”了一个单色光的过滤眼镜一样。它的工作原理如下：<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_13889315088xdf.gif" alt=""></p>
<pre><code>每个感光单元就像有刻度的小桶，光线就像雨一样洒在小桶里，小桶的容量越大，所能度量的雨的大小范围(图像的动态范围)就越大，桶的刻度越多(色彩位数越高)度量的精度就越高。
有些童鞋可能就纳闷了，既然每个像素点只能记录一种颜色，到底是如何拍出彩色图像的呢？所以说，感光元件上的滤光点的排列是有讲究的，这也是布赖斯·拜尔的智慧：每个绿点的四周，分布着2个红点、2个蓝点、4个绿点。这意味着，整体上，绿点的数量是其他两种颜色点的两倍。这是因为研究显示人眼对绿色最敏感，所以滤光层的绿点最多。
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_138893155902ja.jpg" alt=""><br>    我们可以看到，每个滤光点周围有规律地分布其他颜色的滤光点，那么就有可能结合它们的值，判断出光线本来的颜色。以黄光为例，它由红光和绿光混合而成，那么通过滤光层以后，红点和绿点下面的像素都会有值，但是蓝点下面的像素没有值，因此看一个像素周围的颜色分布有红色和绿色，但是没有蓝色-就可以推测出来这个像素点的本来颜色应该是黄色。这个过程可以表示如下，而这种计算颜色的方法，就叫做”去马赛克”(demosaicing)法：<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_1388931594s1ep.jpg" alt=""><br>    虽然，每个像素的颜色都是算出来的，并不是真正的值，但是由于计算的结果相当准确，因此这种做法得到广泛应用。目前，绝大部分的数码相机都采用它，来生成彩色数码照片。高级的数码相机，还提供未经算法处理的原始马赛克图像，这就是raw格式(raw image format)。为了纪念发明者布赖斯·拜尔，它被称作”拜尔模式”或”拜尔滤光法” (Bayer filter)。<br><img src="http://blog.chinaunix.net/attachment/201401/5/23069658_13889316401bDo.jpg" alt=""></p>
<p>数码相机成像原理<br>   OK，有了以上知识的普及和扫盲，下面让我们看一下数码相机的成像过程和原理，其实前面已经提到一点。<br>   前面我们提到的那个感光元件，是数码相机或数码录像机的核心部件，目前业界有两种感光介质：<br>   一种是CCD，是英文 Charge Coupled Device (即电荷耦合器件)的缩写，是一种特殊的半导体器件，也是用来采集信号的一种感应元件，技术要求很高，全世界只有 6 家公司掌握了 CCD研制的核心技术，成品率较低，成本较高。<br>   另一种是CMOS，全称是Complementary Metal-Oxide-Semiconductor(即互补金属氧化物半导体)，它在微处理器和闪存等半导体技术上占有重要的地位，也是一种可用来感受光线变化的半导体，其组成元素主要是硅和锗，通过CMOS上带负电和带正电的晶体管来实现基本功能。这两个互补效应所产生的电流即可被处理芯片记录和解读成影像。</p>
<p>   无论是CCD还是CMOS，其作用和地位都是完成光信号到电信号的转换。两者之争也是数码界一个亘古以来就很久远的话题，2009以前还是CCD的天下，2009年之后(标志性事件就是2008年索尼发布了背照式CMOS，代号Exmor R)，CMOS一下子又火了，CCD逐渐沦落。随着技术、生产工艺、科技的进步，说不定哪天CCD又把CMOS甩开八百里开外，这个谁也说不准，我们就不搅和到这场口水战里了。这里大家只要知道在数码录制设备里，CCD和CMOS都是感光元器件，完成光电信号的转换对我们来说就OK了。</p>
<p>   以前传统相机拍照时，光线通过镜头汇聚，再通过按动快门打开快门门帘让汇聚光投射到胶片上来成像，相机机身只充当了一个暗箱的作用。数码相机的原理和其类似，数码相机肯定也有镜头，通过镜头的光线不像传统相机那样直接投射到胶片，而是直接投射到上面我们提到的感光元件的光敏单元上，这些感光器由半导体元件构成，由数字相机的内置智能控制装置对入射光线进行分析处理，并自动调整合适的焦距、暴光时间、色度、白平衡等参数，然后将这些数据传送给模/数转换器ADC(Analog Digital Converter)，ADC最后把这些电子模拟信号转换成数字信号。如果这个时候直接对数字信号进行存储，就是所谓的图像的Raw格式，照片的质量比普通的高，而且能在后期电脑上进行几乎无损的一些参数调整。严格意义上来说，Raw不应该算是一种图像格式，它仅仅是一个数据包而已。Raw仅仅是将数码相机图像传感器（CCD）感光产生的电信号数字化之后的采样值忠实地记录下来打包直接保存，并未进行任何计算和压缩，具有独特的设备相关性。它所记录的不是图像点的色彩、亮度信息，而是感光芯片的感光记录，是落在每个感光单元上的光线的多少，至于这个点处于什么位置，这个位置上是什么颜色的滤色片，需要根据芯片的型号来定义。<br>目前，大多数数码相机的图像感光器的量化位一般都是12bit或14bit，就是说每个感光单元的感光信息用 12 或 14 位的二进制数字记录下来，对于 12 位的器件，每个点的亮度可以有2^12=4096 级的梯度区别，14 位的器件每个点的亮度可以有 2^14=16384 级的梯度区别，而一般JPEG 格式只能记录 24 位的 RGB 位图(尽管实际是以 YCbCr 色彩空间模型来记录，但图像处理、显示软件打开这些图像时，以及屏幕显示这些图片时，仍然要转换为 RGB分量)，但每个点 24位的数据要记录 R、G、B 三种颜色，分解到一种颜色就只能有 8 位了，最终能记录的亮度梯度就只有256 级了。数码相机早期还有一种格式，现在用的比较少，那就是TIFF 格式。虽然TIFF可记录 48 位(每个色彩 16 位)的图像信息，可以不丢失色彩位，但那样文件体积将变得十分庞大，而且多出的数据位只能用空白数据来填补，浪费存储资源。色彩位的差别直接关系到图像的动态范围和色彩饱和度，一旦保存为低色彩位的图像文件，将有相当量的感光信息被舍弃，这些舍弃的信息将无法找回。 另外，无论拍摄时采用 TIFF还是 JPEG，都是相机利用内部的图像处理芯片预先将数据计算过的，这个计算过程中就要用到相机的白平衡设置、色彩空间设置、曝光补偿设置等等，万一这些设置不准确，计算所产生的图像就会偏色或者曝光不准，一旦这种错误比较严重，信息损失过多，会导致照片报废。然而，JPEG图像格式是目前大众化数码相机缺省的图像保存格式。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>好了，本文如果还有人没看明白，我只能很遗憾的说我已经尽了自己最大的努力，力争用最简单的文字来表述复杂的概念和理论，剩下的就只能靠每个人的修为了。最后，我再将数码相机成像的整个过程总结一下：<br>从镜头进来的光线，投射到数码相机感光元件的很多个微小光敏感光单元上，每个感光单元以电信号的形式记录下照射到它上面的光的强度，然后通过DSP芯片的运算，将电信号通过预先内置在芯片里设定好的算法计算成符合现实标准的数码图像文件并加以存储，最后我们后期就可以编辑、修改、或者通过网络来传输图像了。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>最后，如果有朋友选购数码相机时，看到一个数码相机声称其最高像素是2040万，但它标注的分辨率却为5184×3888=2015万像素，你也不能说人家在忽悠咱们。因为人家也没说2040万像素都拿来成像，这也符合相关标准。在你选择不同的拍照质量时，分辨率当然会降下来，用高分辨率的镜头拍出低分辨率的数字图像？你认为是怎么实现的呢？其似乎也不难，对于这种需求当今大多数相机都是通过主控芯片让感光器件“遮挡”部分感光单元，只让另一部分感光单元接受光照即可实现。关于图像质量的问题，每个感光单元的比特位直接决定了图像最终的表现亮度和色彩的性能，反映到图像上就是每个像素点所占的bit数，或者说字节数。<br>以上便是我对数字图像入门知识的一点简单的记录和分享，毕竟不是专业搞图像的，欢迎各位路过的专业达人、高人、达人、大虾们指点拍砖。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-4065867.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2012年11月13日，83岁的柯达公司退休工程师布赖斯·拜尔(Bryce Bayer)离开了这个世界，永远离开了我们，离开了爱戴他的人们，而他在数字图像领域的杰出成就不应该就这样被淹没在历史的洪流里，所以，谨以2014年第一篇博文献给伟大的布赖斯·拜尔先生。&lt;br&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201401/5/23069658_1388929985kw9Y.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Multimedia" scheme="http://ipcreator.me/tags/Multimedia/"/>
    
  </entry>
  
  <entry>
    <title>多媒体技术基础之---色彩空间</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-color/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-essence-of-color/</id>
    <published>2017-02-27T02:58:06.000Z</published>
    <updated>2017-02-27T05:40:39.898Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-4075912.html" target="_blank" rel="external">wjlkoorey</a></p>
<p>上一篇博文里，我们已经了解到图像是如何数字化的，但是关于数字图像的存储和显示问题还没提到，但在了解数字图像的存储和显示之前，我们先得弄明白数字图像里一个让很多人迷糊的概念：色彩空间。有的技术文献里也将其表述为颜色模型、颜色空间等，说的都是同一个东西。<br><img src="http://blog.chinaunix.net/attachment/201401/9/23069658_13892831996lzw.jpg" alt=""></p>
   <a id="more"></a>
<p> 关于色彩空间，我们最熟悉的就是RGB了，即数字图像的每个像素点用3字节表示，每个字节分别表示该像素点红、绿和蓝色的分量，根据视觉三原色理论，那么这个像素点的最终颜色也就确定了下来。刚开始的时候，确实使用3个字节（3<em>8位）来分别表示一个像素里面的Red,Green和Blue的发光强度数值，后来又增加了一字节用于表示透明度，也就是在Photoshop里经常看到的Alpha值。前三个字节只表示红绿蓝三基色的值，最后一个字节表示前面三种基色叠加结果的透明度的值。在这个前提下，假如我们有一副1440</em>900分辨率的一张图片，按照RGB的方式，每个像素点用4字节表示，则这幅图片将占：1440<em>900</em>4= 5184000Byte=5MB左右的存储空间；如果是3320*1876分辨率的一张照片则高达24MB。当然，这个体积对目前的存储系统来说已经不是什么大问题了，但对我们目前的网络带宽还是提出了非常严峻的挑战。再进一步，如果我们要制作视频，按照电影理论：每秒钟至少24帧图像连续播放，人的视觉才不会感觉停留和卡顿。依然以1440×900解析率的片源为例，每秒钟的数据量则高达120MB字节！！！每秒啊，这是什么概念，如果是90分钟的总播放时长，你能想象要占多少存储空间？耗费多少网络带宽么？关于视频先搁置起来，以后再细说。</p>
<p> 那如何在尽量不降低图片质量的情况下，如何才能最大限度的减小文件数据呢？当然，大家肯定想到应该是各种图像压缩算法该登场了。确实没错，但经过前人的实践证明，在采用RGB颜色模型记录数字图像时，无论采用何种算法，整体压缩比非常的不理想，因为原始数据确实太大了。这时候，英国著名科学家Iain Ainsworth经过大量科学研究得出了一条结论：The human visual system (HVS) is less sensitive to colour than to luminance (brightness)。也就是说 <strong>人类视觉系统对亮度的感觉比对颜色更加敏感。利用这一特性，将图像的亮度信息和颜色信息分离，并使用不同长度的bit位进行存储，这样可以在对主观感觉影响很小的前提下，更加有效的存储图像数据</strong> 因此，另一种颜色空间模型—YUV及其它的各种裂变体就如雨后春笋般遍地而生了。估计当年很多人和我一样，在学计算机多媒体信息处理这门课时，看到这个概念和后面的各种变种，那真是一个头，两个大。不过今天，我力争用最少的语言，最直白的逻辑来向大家阐述清楚这个概念。</p>
<p>   说到YUV色彩空间，从它衍生出的其他几种颜色空间经常会让人产生混淆，最常见的就是YUV经常和YCbCr混用，还有YPbPr的出现让本来就已经很“混乱”的家族又变成了一锅浆糊。下面我们就来一一了解谈谈这几种东东。</p>
<h2 id="YUV"><a href="#YUV" class="headerlink" title="YUV"></a>YUV</h2><p>首先我们简单了解一下YUV的由来。在早期从黑白电视机向彩色电视机(都是模拟信号的年代)过度的那段时间里，工程师们为了继续沿用黑白电视机的基础技术和架构，根据前面说过人的视觉对图像的亮度比图像的色彩更敏感的特性，发明了YUV颜色空间。因为当年的黑白电视机里都已经具备处理图像信号亮度的器件，所以，彩色电视机的工程师们就只增加了两个色差信号U(蓝色色差)和V(红色色差)，就形成了我们所说的YUV颜色空间。所以说，YUV的真正意义在于：在模拟电视系统里，实现了亮度信号Y和色差信号U、V的分离，主要用于优化彩色视频信号的传输，后向兼容老式黑白电视系统，同时与原始的RGB相比，YUV只需占用极少的频宽，而RGB要求三个独立的视频信号同时传输。既然YUV是派生于RGB，那它们之间就肯定有换算公式。请客官们少安毋躁。</p>
<h2 id="YCbCr"><a href="#YCbCr" class="headerlink" title="YCbCr"></a>YCbCr</h2><p>  当从模拟图像发展到数字图像年代的时候，伟大的科学家们又在YUV颜色空间的基础上提出了YCbCr颜色空间。也就是说，YCbCr颜色空间主要用于彩色数字图像信息的编码、压缩和传输用的。例如，<strong>MPEG和JPEG两大组织的各种图像、视频压缩算法都是基于YCbCr颜色空间来提出的</strong>，例如H.264,mpeg其实都是在YCbCr颜色空间里运算的。</p>
<h2 id="YPbPr"><a href="#YPbPr" class="headerlink" title="YPbPr"></a>YPbPr</h2><p>  也是用在模拟的彩色信号处理领域，可以认为YPbPr是YCbCr的模拟版本。那么什么时候会见到YPbPr呢？那就是当你的显示设备的视频输入接口或者输出设备的视频输出接口还有下面这样一组时，你就会见到YPbPr了：<br><img src="http://blog.chinaunix.net/attachment/201401/9/23069658_1389283153zz4y.jpg" alt=""></p>
<p>  为了显示图像，你还得配备一根这样的视频连接线：<br><img src="http://blog.chinaunix.net/attachment/201401/9/23069658_1389283170pck1.jpg" alt=""><br>   其中绿线传输Y信号，蓝线传输Pb信号，红线传输Pr信号。</p>
<p>  最后，我们用来总结一下上述几种颜色空间的应用场合和它们之间的转换关系：<br><img src="http://blog.chinaunix.net/attachment/201401/12/23069658_13895334419ukt.jpg" alt=""></p>
<p>  上图中，直接在网络上传送模拟信号的年代已经过去了，这里将其画出来的主要目的是告诉大家它们曾经存在过。</p>
<p>  因此，综上所述，目前在计算机行业的数字图形图像处理领域，当我们提到YUV时，其实就隐含的指示了我们所说的是YCbCr，把模拟信号年代那些东东赶紧统统扫出脑袋吧(当然除非你目前还在搞模拟视频的相关研究和开发就恕小生无理了)。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-4075912.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上一篇博文里，我们已经了解到图像是如何数字化的，但是关于数字图像的存储和显示问题还没提到，但在了解数字图像的存储和显示之前，我们先得弄明白数字图像里一个让很多人迷糊的概念：色彩空间。有的技术文献里也将其表述为颜色模型、颜色空间等，说的都是同一个东西。&lt;br&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201401/9/23069658_13892831996lzw.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Multimedia" scheme="http://ipcreator.me/tags/Multimedia/"/>
    
  </entry>
  
  <entry>
    <title>Linux系统中“动态库”和“静态库”那点事儿</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-linux-library/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-linux-library/</id>
    <published>2017-02-27T02:24:06.000Z</published>
    <updated>2017-02-27T02:37:50.307Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-3142046.html" target="_blank" rel="external">wjlkoorey </a></p>
<p>更多参考：<a href="http://blog.chinaunix.net/uid-23069658-id-3981406.html" target="_blank" rel="external">深入理解C语言的函数调用过程 </a></p>
<p>今天我们主要来说说Linux系统下基于动态库(.so)和静态(.a)的程序那些猫腻。在这之前，我们需要了解一下源代码到可执行程序之间到底发生了什么神奇而美妙的事情。</p>
<p>在Linux操作系统中，普遍使用ELF格式作为可执行程序或者程序生成过程中的中间格式。<strong>ELF（Executable and Linking Format，可执行连接格式）</strong> 是UNIX系统实验室（USL）作为应用程序二进制接口（Application BinaryInterface，ABI）而开发和发布的。工具接口标准委员会（TIS）选择了正在发展中的ELF标准作为工作在32位Intel体系上不同操作系统之间可移植的二进制文件格式。本文不对ELF文件格式及其组成做太多解释，以免冲淡本文的主题，大家只要知道这么个概念就行。以后再详解Linux中的ELF格式。源代码到可执行程序的转换时需要经历如下图所示的过程：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537030mwmn.gif" alt=""></p>
   <a id="more"></a>
<p>l 编译是指把用高级语言编写的程序转换成相应处理器的汇编语言程序的过程。从本质上讲，编译是一个文本转换的过程。对嵌入式系统而言，一般要把用C语言编写的程序转换成处理器的汇编代码。编译过程包含了C语言的语法解析和汇编码的生成两个步骤。编译一般是逐个文件进行的，对于每一个C语言编写的文件，可能还需要进行预处理。</p>
<p>l 汇编是从汇编语言程序生成目标系统的二进制代码（机器代码）的过程。机器代码的生成和处理器有密切的联系。相对于编译过程的语法解析，汇编的过程相对简单。这是因为 <strong>对于一款特定的处理器，其汇编语言和二进制的机器代码是一一对应的</strong> 汇编过程的输入是汇编代码，这个汇编代码可能来源于编译过程的输出，也可以是直接用汇编语言书写的程序。</p>
<p>l 连接是指将汇编生成的多段机器代码组合成一个可执行程序。一般来说，通过编译和汇编过程，每一个源文件将生成一个目标文件。<strong>连接器的作用就是将这些目标文件组合起来，组合的过程包括了代码段、数据段等部分的合并，以及添加相应的文件头。</strong></p>
<p>GCC是Linux下主要的程序生成工具，它除了编译器、汇编器、连接器外，还包括一些辅助工具。在下面的分析过程中我会教大家这些工具的基本使用方法，Linux的强大之处在于，对于不太懂的命令或函数，有一个很强大的“男人”时刻stand by your side，有什么不会的就去命令行终端输入：man [命令名或函数名]，然后阿拉神灯就会显灵了。</p>
<p>对于最后编译出来的可执行程序，当我们执行它的时候，操作系统又是如何反应的呢？我们先从宏观上来个总体把握，如图2所示：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537040ALw9.gif" alt=""></p>
<p>作为UNIX操作系统的一种，Linux的操作系统提供了一系列的接口，这些接口被称为系统调用（System Call）。在UNIX的理念中，系统调用”提供的是机制，而不是策略”。C语言的库函数通过调用系统调用来实现，库函数对上层提供了C语言库文件的接口。在应用程序层，通过调用C语言库函数和系统调用来实现功能。一般来说，应用程序大多使用C语言库函数实现其功能，较少使用系统调用。</p>
<p>那么最后的可执行文件到底是什么样子呢？前面已经说过，这里我们不深入分析ELF文件的格式，只是给出它的一个结构图和一些简单的说明，以方便大家理解。</p>
<p>ELF文件格式包括三种主要的类型：可执行文件、可重定向文件、共享库。</p>
<p>1．可执行文件（应用程序）<br>可执行文件包含了代码和数据，是可以直接运行的程序。</p>
<p>2．可重定向文件（<em>.o）<br>可重定向文件又称为目标文件，它包含了代码和数据（这些数据是和其他重定位文件和共享的object文件一起连接时使用的）。
</em>.o文件参与程序的连接（创建一个程序）和程序的执行（运行一个程序），它提供了一个方便有效的方法来用并行的视角看待文件的内容，这些<em>.o文件的活动可以反映出不同的需要。<br>Linux下，我们可以用gcc -c编译源文件时可将其编译成</em>.o格式。</p>
<p>3．共享文件（*.so）<br>也称为动态库文件，它包含了代码和数据（这些数据是在连接时候被连接器ld和运行时动态连接器使用的）。动态连接器可能称为ld.so.1，libc.so.1或者 ld-linux.so.1。我的CentOS6.0系统中该文件为：/lib/ld-2.12.so</p>
<p><img src="http://hi.csdn.net/attachment/201203/12/0_13315370473OsQ.gif" alt=""></p>
<p>一个ELF文件从连接器（Linker）的角度看，是一些节的集合；从程序加载器（Loader）的角度看，它是一些段（Segments）的集合。ELF格式的程序和共享库具有相同的结构，只是段的集合和节的集合上有些不同。</p>
<h3 id="那么到底什么是库呢？"><a href="#那么到底什么是库呢？" class="headerlink" title="那么到底什么是库呢？"></a>那么到底什么是库呢？</h3><p>库从本质上来说是一种可执行代码的二进制格式，可以被载入内存中执行。库分静态库和动态库两种。</p>
<p>静态库：这类库的名字一般是libxxx.a，xxx为库的名字。利用静态函数库编译成的文件比较大，因为整个函数库的所有数据都会被整合进目标代码中，他的优点就显而易见了，即编译后的执行程序不需要外部的函数库支持，因为所有使用的函数都已经被编译进去了。当然这也会成为他的缺点，因为如果静态函数库改变了，那么你的程序必须重新编译。</p>
<p>动态库：这类库的名字一般是libxxx.M.N.so，同样的xxx为库的名字，M是库的主版本号，N是库的副版本号。当然也可以不要版本号，但名字必须有。相对于静态函数库，动态函数库在编译的时候并没有被编译进目标代码中，你的程序执行到相关函数时才调用该函数库里的相应函数，因此动态函数库所产生的可执行文件比较小。由于函数库没有被整合进你的程序，而是程序运行时动态的申请并调用，所以程序的运行环境中必须提供相应的库。动态函数库的改变并不影响你的程序，所以动态函数库的升级比较方便。linux系统有几个重要的目录存放相应的函数库，如/lib /usr/lib。</p>
<p>当要使用静态的程序库时，连接器会找出程序所需的函数，然后将它们拷贝到执行文件，由于这种拷贝是完整的，所以一旦连接成功，静态程序库也就不再需要了。然而，对动态库而言，就不是这样。动态库会在执行程序内留下一个标记指明当程序执行时，首先必须载入这个库。由于动态库节省空间，linux下进行连接的缺省操作是首先连接动态库，也就是说，如果同时存在静态和动态库，不特别指定的话，将与动态库相连接。</p>
<p>OK,有了这些知识，接下来大家就可以弄明白我所做的事情是干什么了。都说例子是最好老师，我们就从例子入手。</p>
<h3 id="1、静态链接库"><a href="#1、静态链接库" class="headerlink" title="1、静态链接库"></a>1、静态链接库</h3><p>   我们先制作自己的静态链接库，然后再使用它。制作静态链接库的过程中要用到gcc和ar命令。<br>  准备两个库的源码文件st1.c和st2.c，用它们来制作库libmytest.a，如下：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537129vFvv.gif" alt=""><br>    静态库文件libmytest.a已经生成，用file命令查看其属性，发现它确实是归档压缩文件。用ar -t libmytest.a可以查看一个静态库包含了那些obj文件：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537139q26s.gif" alt=""><br>    接下来我们就写个测试程序来调用库libmytest.a中所提供的两个接口print1()和print2()。<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537148mLvA.gif" alt=""><br>    看到没，静态库的编写和调用就这么简单，学会了吧。这里gcc的参数-L是告诉编译器库文件的路径是当前目录，-l是告诉编译器要使用的库的名字叫mytest。</p>
<h3 id="2、动态库"><a href="#2、动态库" class="headerlink" title="2、动态库"></a>2、动态库</h3><pre><code>静态库*.a文件的存在主要是为了支持较老的a.out格式的可执行文件而存在的。目前用的最多的要数动态库了。
</code></pre><p>动态库的后缀为*.so。在Linux发行版中大多数的动态库基本都位于/usr/lib和/lib目录下。在开发和使用我们自己动态库之前，请容许我先落里罗嗦的跟大家唠叨唠叨Linux下和动态库相关的事儿吧。</p>
<p>有时候当我们的应用程序无法运行时，它会提示我们说它找不到什么样的库，或者哪个库的版本又不合它胃口了等等之类的话。那么应用程序它是怎么知道需要哪些库的呢？我们前面已几个学了个很棒的命令ldd，用就是用来查看一个文件到底依赖了那些so库文件。</p>
<p>Linux系统中动态链接库的配置文件一般在/etc/ld.so.conf文件内，它里面存放的内容是可以被Linux共享的动态联库所在的目录的名字。我的系统中，该文件的内容如下：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537159ntMG.gif" alt=""><br>    然后/etc/ld.so.conf.d/目录下存放了很多*.conf文件，如下：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537167i202.gif" alt=""><br>    其中每个conf文件代表了一种应用的库配置内容，以mysql为例：<br><img src="http://hi.csdn.net/attachment/201203/12/0_13315371781xP9.gif" alt=""><br>    如果您是和我一样装的CentOS6.0的系统，那么细心的读者可能会发现，在/etc目录下还存在一个名叫ld.so.cache的文件。从名字来看，我们知道它肯定是动态链接库的什么缓存文件。<br>对，您说的一点没错。为了使得动态链接库可以被系统使用，当我们修改了/etc/ld.so.conf或/etc/ld.so.conf.d/目录下的任何文件，或者往那些目录下拷贝了新的动态链接库文件时，都需要运行一个很重要的命令：ldconfig，该命令位于/sbin目录下，主要的用途就是负责搜索/lib和/usr/lib，以及配置文件/etc/ld.so.conf里所列的目录下搜索可用的动态链接库文件，然后创建处动态加载程序/lib/ld-linux.so.2所需要的连接和(默认)缓存文件/etc/ld.so.cache(此文件里保存着已经排好序的动态链接库名字列表)。<br>也就是说：当用户在某个目录下面创建或拷贝了一个动态链接库，若想使其被系统共享，可以执行一下”ldconfig目录名”这个命令。此命令的功能在于让ldconfig将指定目录下的动态链接库被系统共享起来，即：在缓存文件/etc/ld.so.cache中追加进指定目录下的共享库。请注意：如果此目录不在/lib,/usr/lib及/etc/ld.so.conf文件所列的目录里面，则再次单独运行ldconfig时，此目录下的动态链接库可能不被系统共享了。单独运行ldconfig时，它只会搜索/lib、/usr/lib以及在/etc/ld.so.conf文件里所列的目录，用它们来重建/etc/ld.so.cache。<br>因此，等会儿我们自己开发的共享库就可以将其拷贝到/lib、/etc/lib目录里，又或者修改/etc/ld.so.conf文件将我们自己的库路径添加到该文件中，再执行ldconfig命令。<br>非了老半天功夫，终于把基础打好了，猴急的您早已按耐不住激情的想动手尝试了吧！哈哈。。。OK，说整咱就开整，接下来我就带领大家一步一步来开发自己的动态库，然后教大家怎么去使用它。<br>我们有一个头文件my_so_test.h和三个源文件test_a.c、test_b.c和test_c.c，将他们制作成一个名为libtest.so的动态链接库文件：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537188au0x.gif" alt=""><br>OK，万事俱备，只欠东风。如何将这些文件编译成一个我们所需要的so文件呢？可以分两步来完成，也可以一步到位：<br>方法一：<br>         1、先生成目标.o文件：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537195Ejhj.gif" alt=""><br>       2、再生成so文件：<br><img src="http://hi.csdn.net/attachment/201203/12/0_13315372030wU1.gif" alt=""><br>-shared该选项指定生成动态连接库（让连接器生成T类型的导出符号表，有时候也生成弱连接W类型的导出符号），不用该标志外部程序无法连接。相当于一个可执行文件。<br>-fPIC：表示编译为位置独立的代码，不用此选项的话编译后的代码是位置相关的所以动态载入时是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。<br>方法二：一步到位。<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331540214c18A.gif" alt=""><br>至此，我们制作的动态库文件libtest.so就算大功告成了。</p>
<p>接下来，就是如何使用这个动态库了。动态链接库的使用有两种方法：既可以在运行时对其进行动态链接，又可以动态加载在程序中是用它们。接下来，我就这两种方法分别对其介绍。</p>
<h2 id="动态库的使用"><a href="#动态库的使用" class="headerlink" title="+++动态库的使用+++"></a>+++动态库的使用+++</h2><pre><code>用法一：动态链接。
</code></pre><p><img src="http://hi.csdn.net/attachment/201203/12/0_1331537210T1RI.gif" alt=""><br>使用“-ltest”标记来告诉GCC驱动程序在连接阶段引用共享函数库libtest.so。“-L.”标记告诉GCC函数库可能位于当前目录。否则GNU连接器会查找标准系统函数目录。<br>这里我们注意，ldd的输出它说我们的libtest.so它没找到。还记得我在前面动态链接库一节刚开始时的那堆唠叨么，现在你应该很明白了为什么了吧。因为我们的libtest.so既不在/etc/ld.so.cache里，又不在/lib、/usr/lib或/etc/ld.so.conf所指定的任何一个目录中。怎么办？还用我告诉你？管你用啥办法，反正我用的ldconfig <code>pwd</code>搞定的：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537220Jd4w.gif" alt=""><br>       执行结果如下：<br><img src="http://hi.csdn.net/attachment/201203/12/0_133153722711o3.gif" alt=""><br>偶忍不住又要罗嗦一句了，相信俺，我的唠叨对大家是有好处。我为什么用这种方法呢？因为我是在给大家演示动态库的用法，完了之后我就把libtest.so给删了，然后再重构ld.so.cache，对我的系统不会任何影响。倘若我是开发一款软件，或者给自己的系统DIY一个非常有用的功能模块，那么我更倾向于将libtest.so拷贝到/lib、/usr/lib目录下，或者我还有可能在/usr/local/lib/目录下新建一文件夹xxx，将so库拷贝到那儿去，并在/etc/ld.so.conf.d/目录下新建一文件mytest.conf，内容只有一行“/usr/local/lib/xxx/libtest.so”，再执行ldconfig。如果你之前还是不明白怎么解决那个“not found”的问题，那么现在总该明白了吧。<br>    方法二：动态加载。<br>动态加载是非常灵活的，它依赖于一套Linux提供的标准API来完成。在源程序里，你可以很自如的运用API来加载、使用、释放so库资源。以下函数在代码中使用需要包含头文件：dlfcn.h<br><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">函数原型</div><div class="line">说明</div><div class="line"><span class="keyword">const</span> <span class="keyword">char</span> *dlerror(<span class="keyword">void</span>)</div><div class="line">当动态链接库操作函数执行失败时，dlerror可以返回出错信息，返回值为NULL时表示操作函数执行成功。</div><div class="line"><span class="keyword">void</span> *dlopen(<span class="keyword">const</span> <span class="keyword">char</span> *filename, <span class="keyword">int</span> flag)</div><div class="line">用于打开指定名字（filename）的动态链接库，并返回操作句柄。调用失败时，将返回NULL值，否则返回的是操作句柄。</div><div class="line"><span class="keyword">void</span> *dlsym(<span class="keyword">void</span> *handle, <span class="keyword">char</span> *symbol)</div><div class="line">根据动态链接库操作句柄（handle）与符号（symbol），返回符号对应的函数的执行代码地址。由此地址，可以带参数执行相应的函数。</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">dlclose</span> (<span class="params"><span class="keyword">void</span> *handle</span>)</span></div><div class="line">用于关闭指定句柄的动态链接库，只有当此动态链接库的使用计数为0时，才会真正被系统卸载。2.2在程序中使用动态链接库函数。</div><div class="line">       <span class="title">dlsym</span>(<span class="params"><span class="keyword">void</span> *handle, <span class="keyword">char</span> *symbol</span>)</div><div class="line">filename:如果名字不以“/”开头，则非绝对路径名，将按下列先后顺序查找该文件。</div><div class="line">   （1）用户环境变量中的LD_LIBRARY值；</div><div class="line">   （2）动态链接缓冲文件/etc/ld.so.cache</div><div class="line">   （3）目录/lib,/usr/lib</div><div class="line">      flag表示在什么时候解决未定义的符号（调用）。取值有两个：</div><div class="line">       1） RTLD_LAZY : 表明在动态链接库的函数代码执行时解决。</div><div class="line">      2） RTLD_NOW :表明在dlopen返回前就解决所有未定义的符号，一旦未解决，dlopen将返回错误。</div><div class="line">        <span class="title">dlsym</span>(<span class="params"><span class="keyword">void</span> *handle, <span class="keyword">char</span> *symbol</span>)</div><div class="line">        <span class="title">dlsym</span>(<span class="params"></span>)的用法一般如下：</div><div class="line">       <span class="keyword">void</span>（*<span class="keyword">add</span>）（<span class="keyword">int</span> x,<span class="keyword">int</span> y）； <span class="comment">/*说明一下要调用的动态函数add */</span></div><div class="line"><span class="keyword">add</span>=dlsym（<span class="string">"xxx.so"</span>,<span class="string">"add"</span>）； <span class="comment">/* 打开xxx.so共享库，取add函数地址 */</span></div><div class="line"><span class="keyword">add</span>（<span class="number">89</span>,<span class="number">369</span>）； <span class="comment">/* 带两个参数89和369调用add函数 */</span></div></pre></td></tr></table></figure></p>
<pre><code>看我出招：
</code></pre><p><img src="http://hi.csdn.net/attachment/201203/12/0_1331537235Y6Ia.gif" alt=""><br>        执行结果：<br><img src="http://hi.csdn.net/attachment/201203/12/0_1331537241hhBr.gif" alt=""><br>使用动态链接库，源程序中要包含dlfcn.h头文件，写程序时注意dlopen等函数的正确调用，编译时要采用-rdynamic选项与-ldl选项(不然编译无法通过)，以产生可调用动态链接库的执行代码。<br>         OK，通过本文的指导、练习相信各位应该对Linux的库机制有了些许了解，最主要的是会开发使用库文件了。由于本人知识所限，文中某些观点如果不到位或理解有误的地方还请各位个人不吝赐教。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3142046.html&quot;&gt;wjlkoorey &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更多参考：&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3981406.html&quot;&gt;深入理解C语言的函数调用过程 &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;今天我们主要来说说Linux系统下基于动态库(.so)和静态(.a)的程序那些猫腻。在这之前，我们需要了解一下源代码到可执行程序之间到底发生了什么神奇而美妙的事情。&lt;/p&gt;
&lt;p&gt;在Linux操作系统中，普遍使用ELF格式作为可执行程序或者程序生成过程中的中间格式。&lt;strong&gt;ELF（Executable and Linking Format，可执行连接格式）&lt;/strong&gt; 是UNIX系统实验室（USL）作为应用程序二进制接口（Application BinaryInterface，ABI）而开发和发布的。工具接口标准委员会（TIS）选择了正在发展中的ELF标准作为工作在32位Intel体系上不同操作系统之间可移植的二进制文件格式。本文不对ELF文件格式及其组成做太多解释，以免冲淡本文的主题，大家只要知道这么个概念就行。以后再详解Linux中的ELF格式。源代码到可执行程序的转换时需要经历如下图所示的过程：&lt;br&gt;&lt;img src=&quot;http://hi.csdn.net/attachment/201203/12/0_1331537030mwmn.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Linux" scheme="http://ipcreator.me/tags/Linux/"/>
    
      <category term="Network" scheme="http://ipcreator.me/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>Linux网络编程</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-network-programming/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-network-programming/</id>
    <published>2017-02-27T02:11:06.000Z</published>
    <updated>2017-02-27T05:40:24.268Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/figure2.gif" alt=""></p>
<p>Linux的整个网络协议栈都构建与Linux Kernel中，整个栈也是严格按照分层的思想来设计的，整个栈共分为五层，分别是 ：</p>
<p>1． 系统调用接口层，实质是一个面向用户空间应用程序的接口调用库，向用户空间应用程序提供使用网络服务的接口。<br>2． 协议无关的接口层，就是SOCKET层，这一层的目的是屏蔽底层的不同协议（更准确的来说主要是TCP与UDP，当然还包括RAW IP， SCTP等），以便与系统调用层之间的接口可以简单，统一。简单的说，不管我们应用层使用什么协议，都要通过系统调用接口来建立一个SOCKET，这个SOCKET其实是一个巨大的sock结构，它和下面一层的网络协议层联系起来，屏蔽了不同的网络协议的不同，只把数据部分呈献给应用层（通过系统调用接口来呈献）。<br>3． 网络协议实现层，毫无疑问，这是整个协议栈的核心。这一层主要实现各种网络协议，最主要的当然是IP，ICMP，ARP，RARP，TCP，UDP等。这一层包含了很多设计的技巧与算法，相当的不错。<br>4． 与具体设备无关的驱动接口层，这一层的目的主要是为了统一不同的接口卡的驱动程序与网络协议层的接口，它将各种不同的驱动程序的功能统一抽象为几个特殊的动作，如open，close，init等，这一层可以屏蔽底层不同的驱动程序。<br>5． 驱动程序层，这一层的目的就很简单了，就是建立与硬件的接口层。<br>可以看到，Linux网络协议栈是一个严格分层的结构，其中的每一层都执行相对独立的功能，结构非常清晰。<br>其中的两个“无关”层的设计非常棒，通过这两个“无关”层，其协议栈可以非常轻松的进行扩展。在我们自己的软件设计中，可以吸收这种设计方法。</p>
   <a id="more"></a>
<h3 id="更多参考："><a href="#更多参考：" class="headerlink" title="更多参考："></a>更多参考：</h3><p>   <a href="https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/" target="_blank" rel="external">Linux 网络栈剖析</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3280895.html" target="_blank" rel="external">Linux网络编程：原始套接字的魔力【上】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3283534.html" target="_blank" rel="external">Linux网络编程：原始套接字的魔力【下】 </a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3293289.html" target="_blank" rel="external">Linux网络编程：原始套接字的魔力【续】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3297286.html" target="_blank" rel="external">揭开网络编程常见API的面纱【上】 </a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3300460.html" target="_blank" rel="external">揭开网络编程常见API的面纱【下】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3276167.html" target="_blank" rel="external">Linux网络编程：基于UDP的程序开发回顾篇 </a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3273673.html" target="_blank" rel="external">Linux网络编程：基于TCP的程序开发回顾篇 </a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3271110.html" target="_blank" rel="external">Linux环境下网络编程杂谈 </a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3141409.html" target="_blank" rel="external"> linux 内核网络，数据接收流程图</a><br>   <a href="http://blog.csdn.net/echoisland/article/details/6993756" target="_blank" rel="external"> linux 内核网络,数据发送流程图</a></p>
<p>   <a href="http://blog.chinaunix.net/uid-23069658-id-3245853.html" target="_blank" rel="external">(十六)洞悉linux下的Netfilter&amp;iptables：开发自己的hook函数【实战】(下)</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3243434.html" target="_blank" rel="external">(十五)洞悉linux下的Netfilter&amp;iptables：开发自己的hook函数【实战】(上)</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3230608.html" target="_blank" rel="external">(十四)洞悉linux下的Netfilter&amp;iptables：开发一个match模块【实战】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3225602.html" target="_blank" rel="external">(十三)洞悉linux下的Netfilter&amp;iptables：为防火墙增添功能模块【实战】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3223404.html" target="_blank" rel="external">(十二)洞悉linux下的Netfilter&amp;iptables：iptables命令行工具源码解析【下】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3222686.html" target="_blank" rel="external">(十一)洞悉linux下的Netfilter&amp;iptables：iptables命令行工具源码解析【上】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3211992.html" target="_blank" rel="external">(十)洞悉linux下的Netfilter&amp;iptables：网络地址转换原理之SNAT</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3210931.html" target="_blank" rel="external">(九)洞悉linux下的Netfilter&amp;iptables：网络地址转换原理之DNAT</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3188216.html" target="_blank" rel="external">(八)洞悉linux下的Netfilter&amp;iptables：状态防火墙</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3175235.html" target="_blank" rel="external">(七)洞悉linux下的Netfilter&amp;iptables：如何理解连接跟踪机制？【下】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3173360.html" target="_blank" rel="external">(六)洞悉linux下的Netfilter&amp;iptables：如何理解连接跟踪机制？【中】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3169450.html" target="_blank" rel="external">(五)洞悉linux下的Netfilter&amp;iptables：如何理解连接跟踪机制？【上】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3166140.html" target="_blank" rel="external">(四)洞悉linux下的Netfilter&amp;iptables：包过滤子系统iptable_filter</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3163999.html" target="_blank" rel="external">(三)洞悉linux下的Netfilter&amp;iptables：内核中的rule，match和target</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3162264.html" target="_blank" rel="external">(二)洞悉linux下的Netfilter&amp;iptables：内核中的ip_tables小觑</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3160506.html" target="_blank" rel="external">(一)洞悉linux下的Netfilter&amp;iptables：什么是Netfilter？</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3141413.html" target="_blank" rel="external">Linux Netfilter实现机制和扩展技术 </a></p>
<h2 id="协议简介"><a href="#协议简介" class="headerlink" title="协议简介"></a>协议简介</h2><p>虽然对于网络的正式介绍一般都参考了 OSI（Open Systems Interconnection）模型，但是本文对 Linux 中基本网络栈的介绍分为四层的 Internet 模型（如图 1 所示）。<br><img src="https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/figure1.gif" alt=""><br>图 1. 网络栈的 Internet 模型<br>网络栈的 Internet 模型<br>这个栈的最底部是链路层。链路层是指提供对物理层访问的设备驱动程序，这可以是各种介质，例如串口链路或以太网设备。链路层上面是网络层，它负责将报文定向到目标位置。再上一层称为传输层，负责端到端的通信（例如，在一台主机内部）。尽管网络层负责管理主机之间的通信，但是传输层需要负责管理主机内部各端之间的通信。最后一层是应用层，它通常是一个语义层，能够理解要传输的数据。例如，超文本传输协议（HTTP）就负责传输服务器和客户机之间对 Web 内容的请求与响应。<br>实际来说，网络栈的各个层次有一些更为人所熟知的名字。在链路层上，可以找到以太网，这是最常用的一种高速介质。更早的链路层协议包括一些串口协议，例如 SLIP（Serial Line Internet Protocol）、CSLIP（Compressed SLIP）和PPP（Point-to-Point Protocol）。最常见的网络层协议是 IP（Internet Protocol），但是网络层中还存在一些满足其他需求的协议，例如 ICMP（Internet Control Message Protocol）和ARP（ Address Resolution Protocol）。在传输层上是 TCP（Transmission Control Protocol）和 UDP（User Datagram Protocol）。最后，应用层中包含很多大家都非常熟悉的协议，包括标准的 Web 协议 HTTP 和电子邮件协议 SMTP（Simple Mail Transfer Protocol）。</p>
<h2 id="核心网络架构"><a href="#核心网络架构" class="headerlink" title="核心网络架构"></a>核心网络架构</h2><p>现在继续了解 Linux 网络栈的架构以及如何实现这种 Internet 模型。图 2 提供了 Linux 网络栈的高级视图。最上面是用户空间层，或称为应用层，其中定义了网络栈的用户。底部是物理设备，提供了对网络的连接能力（串口或诸如以太网之类的高速网络）。中间是内核空间，即网络子系统，也是本文介绍的重点。流经网络栈内部的是 socket 缓冲区（sk_buffs），它负责在源和汇点之间传递报文数据。您很快就将看到 sk_buff 的结构。<br><img src="https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/figure2.gif" alt=""><br>图 2. Linux 高级网络栈架构<br>Linux 高级网络栈架构<br>首先，让我们来快速浏览一下 Linux 网络子系统的核心元素，后续章节中会更详细进行介绍。顶部（请参阅图 2）是系统调用接口。它简单地为用户空间的应用程序提供了一种访问内核网络子系统的方法。位于其下面的是一个协议无关层，它提供了一种通用方法来使用底层传输层协议。然后是实际协议，在 Linux 中包括内嵌的协议 TCP、UDP，当然还有 IP。然后是另外一个协议无关层，提供了与各个设备驱动程序通信的通用接口，最下面是设备驱动程序本身。</p>
<h2 id="系统调用接口"><a href="#系统调用接口" class="headerlink" title="系统调用接口"></a>系统调用接口</h2><p>系统调用接口可以从两个角度进行描述。用户发起网络调用时，通过系统调用接口进入内核的过程应该是多路的。最后调用 ./net/socket.c 中的 sys_socketcall 结束该过程，然后进一步将调用分路发送到指定目标。系统调用接口的另一种描述是使用普通文件操作作为网络 I/O。例如，典型的读写操作可以在网络 socket 上执行（socket 使用一个文件描述符表示，与一个普通文件一样）。因此，尽管有很多操作是网络专用的（使用 socket 调用创建一个 socket，使用 connect 调用连接一个收信方，等等），但是也有一些标准的文件操作可以应用于网络对象，就像操作普通文件一样。最后，系统调用接口提供了在用户空间应用程序和内核之间转移控制的方法。</p>
<h2 id="协议无关接口"><a href="#协议无关接口" class="headerlink" title="协议无关接口"></a>协议无关接口</h2><p>socket 层是一个协议无关接口，它提供了一组通用函数来支持各种不同协议。socket 层不但可以支持典型的 TCP 和 UDP 协议，而且还可以支持 IP、裸以太网和其他传输协议，例如 SCTP（Stream Control Transmission Protocol）。<br>通过网络栈进行的通信都需要对 socket 进行操作。Linux 中的 socket 结构是 struct sock，这个结构是在 linux/include/net/sock.h 中定义的。这个巨大的结构中包含了特定 socket 所需要的所有状态信息，其中包括 socket 所使用的特定协议和在 socket 上可以执行的一些操作。<br>网络子系统可以通过一个定义了自己功能的特殊结构来了解可用协议。每个协议都维护了一个名为 proto 的结构（可以在 linux/include/net/sock.h 中找到）。这个结构定义了可以在从 socket 层到传输层中执行特定的 socket 操作（例如，如何创建一个 socket，如何使用 socket 建立一个连接，如何关闭一个 socket 等等）。</p>
<h2 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h2><p>网络协议这一节对一些可用的特定网络协议作出了定义（例如 TCP、UDP 等）。它们都是在 linux/net/ipv4/af_inet.c 文件中一个名为 inet_init 的函数中进行初始化的（因为 TCP 和 UDP 都是 inet 簇协议的一部分）。 inet_init 函数使用 proto_register 函数来注册每个内嵌协议。这个函数是在 linux/net/core/sock.c 中定义的，除了可以将这个协议添加到活动协议列表中之外，如果需要，该函数还可以选择分配一到多个 slab 缓存。<br>通过 linux/net/ipv4/ 目录中 udp.c 和 raw.c 文件中的 proto 接口，您可以了解各个协议是如何标识自己的。这些协议接口每个都按照类型和协议映射到 inetsw_array，该数组将内嵌协议与操作映射到一起。inetsw_array 结构及其关系如图 3 所示。最初，会调用 inet_init 中的 inet_register_protosw 将这个数组中的每个协议都初始化为 inetsw。函数 inet_init 也会对各个 inet 模块进行初始化，例如 ARP、ICMP 和 IP 模块，以及 TCP 和 UDP 模块。<br><img src="https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/figure3.gif" alt=""></p>
<blockquote>
<p>Socket 协议的相互关系<br>回想以下在创建 socket 时，需要指定类型和协议，例如my_sock = socket( AF_INET, SOCK_STREAM, 0 )。AF_INET 表示一个 Internet 地址簇，它使用的是一个流 socket，定义为 SOCK_STREAM（如此处的 inetsw_array 所示）。</p>
</blockquote>
<p>注意在 图 3 中，proto 结构定义了传输特有的方法，而 proto_ops 结构则定义了通用的 socket 方法。可以通过调用 inet_register_protosw 将其他协议加入到 inetsw 协议中。例如，SCTP 就是通过调用 linux/net/sctp/protocol.c 中的 sctp_init 加入其中的。有关 SCTP 的更多信息，请参阅 参考资料 一节的内容。<br>socket 中的数据移动是使用一个所谓的 socket 缓冲区（sk_buff）的核心结构实现的。sk_buff 中包含了报文数据，以及涉及协议栈中多个层次的状态数据。所发送或接收的每个报文都是使用一个 sk_buff 表示的。sk_buff 结构是在 linux/include/linux/skbuff.h 中定义的，如图 4 所示。<br>图 4. Socket 缓冲区及其与其他结构的关系<br><img src="https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/figure4.gif" alt=""><br>如图所示，多个 sk_buff 可以针对某个给定连接链接在一起。每个 sk_buff 都在设备结构（net_device）中标识报文发送的目的地，或者接收报文的来源地。由于每个报文都是使用一个 sk_buff 表示的，因此报文头都可以通过一组指针（th、iph 和 mac[用于 Media Access Control 或者 MAC 头]）方便地进行定位。由于 sk_buff 是 socket 数据管理的中心，因此创建了很多支持函数来对它们进行管理。其中有些函数用于创建和销毁 sk_buff 结构，或对它进行克隆或排队管理。<br>针对给定的 socket，Socket 缓冲区可以链接在一起，这样可以包含众多信息，包括到协议头的链接、时间戳（报文是何时发送或接收的），以及与这个报文相关的设备。</p>
<h2 id="设备无关接口"><a href="#设备无关接口" class="headerlink" title="设备无关接口"></a>设备无关接口</h2><p>协议层下面是另外一个无关接口层，它将协议与具有很多各种不同功能的硬件设备连接在一起。这一层提供了一组通用函数供底层网络设备驱动程序使用，让它们可以对高层协议栈进行操作。<br>首先，设备驱动程序可能会通过调用 register_netdevice 或 unregister_netdevice 在内核中进行注册或注销。调用者首先填写 net_device 结构，然后传递这个结构进行注册。内核调用它的 init 函数（如果定义了这种函数），然后执行一组健全性检查，并创建一个 sysfs 条目，然后将新设备添加到设备列表中（内核中的活动设备链表）。在 linux/include/linux/netdevice.h 中可以找到这个 net_device 结构。这些函数都是在 linux/net/core/dev.c 中实现的。<br>要从协议层向设备中发送 sk_buff，就需要使用 dev_queue_xmit 函数。这个函数可以对 sk_buff 进行排队，从而由底层设备驱动程序进行最终传输（使用 sk_buff 中引用的 net_device 或 sk_buff-&gt;dev 所定义的网络设备）。dev 结构中包含了一个名为 hard_start_xmit 的方法，其中保存有发起 sk_buff 传输所使用的驱动程序函数。<br>报文的接收通常是使用 netif_rx 执行的。当底层设备驱动程序接收一个报文（包含在所分配的 sk_buff 中）时，就会通过调用 netif_rx 将 sk_buff 上传至网络层。然后，这个函数通过 netif_rx_schedule 将 sk_buff 在上层协议队列中进行排队，供以后进行处理。可以在 linux/net/core/dev.c 中找到 dev_queue_xmit 和 netif_rx 函数。<br>最近，内核中引入了一种新的应用程序编程接口（NAPI），该接口允许驱动程序与设备无关层（dev）进行交互。有些驱动程序使用的是 NAPI，但是大多数驱动程序仍然在使用老式的帧接收接口（比例大约是 6 比 1）。NAPI 在高负载的情况下可以产生更好的性能，它避免了为每个传入的帧都产生中断。</p>
<h2 id="设备驱动程序"><a href="#设备驱动程序" class="headerlink" title="设备驱动程序"></a>设备驱动程序</h2><p>网络栈底部是负责管理物理网络设备的设备驱动程序。例如，包串口使用的 SLIP 驱动程序以及以太网设备使用的以太网驱动程序都是这一层的设备。<br>在进行初始化时，设备驱动程序会分配一个 net_device 结构，然后使用必须的程序对其进行初始化。这些程序中有一个是 dev-&gt;hard_start_xmit，它定义了上层应该如何对 sk_buff 排队进行传输。这个程序的参数为 sk_buff。这个函数的操作取决于底层硬件，但是通常 sk_buff 所描述的报文都会被移动到硬件环或队列中。就像是设备无关层中所描述的一样，对于 NAPI 兼容的网络驱动程序来说，帧的接收使用了 netif_rx 和 netif_receive_skb 接口。NAPI 驱动程序会对底层硬件的能力进行一些限制。有关更详细的信息，请参阅 参考资料 一节的内容。<br>设备驱动程序在 dev 结构中配置好自己的接口之后，调用 register_netdevice 便可以使用该配置。在 linux/drivers/net 中可以找出网络设备专用的驱动程序。</p>
<h2 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h2><p>Linux 源代码是学习有关大多数设备类型的设备驱动程序设计最佳方法，包括网络设备驱动程序。在这里可以找到的是各种设计的变化以及对可用内核 API 的使用，但是所学到的每一点都会非常有用，都可以作为新设备驱动程序的起点。除非您需要一种新协议，否则网络栈中的其余代码都是通用的，都会非常有用。即使现在，TCP（用于流协议）或 UDP（用于基于消息的协议）的实现都可以作为开始新开发有用模块使用。</p>
<h2 id="笔记摘抄"><a href="#笔记摘抄" class="headerlink" title="笔记摘抄"></a>笔记摘抄</h2><p>   在开发面向连接的TCP和面向无连接的UDP程序时，我们所关心的核心问题在于数据收发层面，数据的传输特性由TCP或UDP来保证：<br>   <img src="http://blog.chinaunix.net/attachment/201207/19/23069658_13427133838Oc8.jpg" alt=""></p>
<p>   先简单复习一下TCP报文的格式，因为我们本身不是讲协议的设计思想，所以只会提及和我们接下来主题相关的字段，如果想对TCP协议原理进行深入了解那么《TCP/IP详解卷1》无疑是最好的选择。<br>   <img src="http://blog.chinaunix.net/attachment/201207/19/23069658_1342713558R24N.jpg" alt=""></p>
<p>   下IP报文的首部格式：<br>   <img src="http://blog.chinaunix.net/attachment/201207/19/23069658_1342713564cE9N.jpg" alt=""></p>
<p>   直接从链路层收发数据帧，听起来好像很神奇的样子。在Linux系统中要从链路层(MAC)直接收发数帧，比较普遍的做法就是用libpcap和libnet两个动态库来实现。但今天我们就要用原始套接字来实现这个功能。<br>   <img src="http://blog.chinaunix.net/attachment/201207/22/23069658_1342973461ECTj.jpg" alt=""></p>
<p>   链路层中是根据MAC地址来确定唯一一台主机。以太帧格式如下：<br>   <img src="http://blog.chinaunix.net/attachment/201207/30/23069658_13436562130J5j.jpg" alt=""></p>
<p>   面向连接的TCP程序设计<br>       基于TCP的程序开发分为服务器端和客户端两部分，常见的核心步骤和流程：<br><img src="http://blog.chinaunix.net/attachment/201207/13/23069658_1342193576yEs2.jpg" alt=""></p>
<p>基于无连接的UDP程序设计<br>       同样，在开发基于UDP的应用程序时，其主要流程如下：<br><img src="http://blog.chinaunix.net/attachment/201207/16/23069658_1342453438q0Q0.jpg" alt=""></p>
<p>1、socket(family,type,protocol)<br>       当我们在开发网络应用程序时，使用该系统调用来创建一个套接字。该API所做的工作如下所示：<br><img src="http://blog.chinaunix.net/attachment/201208/1/23069658_1343830689LI36.jpg" alt=""></p>
<p>2、bind (sockfd, sockaddr, addrlen)<br>       该系统调用在内核中的执行过程如下：<br><img src="http://blog.chinaunix.net/attachment/201208/1/23069658_1343830689LI36.jpg" alt=""></p>
<p>3、listen(sockfd, backlog)<br><img src="http://blog.chinaunix.net/attachment/201208/1/23069658_1343830697FIpB.jpg" alt=""><br>      这里我们可以看到面向无连接的套接字和原始套接字是不用listen的，只有流式套接字才有效。</p>
<p>4、connect(sockfd, sockaddr, addrlen)<br><img src="http://blog.chinaunix.net/attachment/201208/1/23069658_1343830700VZj8.jpg" alt=""><br>      从这幅图中我们确实看到，connect()系统调用不但可以面向连接的套接字，也可用于无连接及原始套接字。</p>
<p>5、accept(sockfd, sockaddr, addrlen)<br><img src="http://blog.chinaunix.net/attachment/201208/1/23069658_1343830704GP1Z.jpg" alt=""><br>    同样地，我们看到只有面向连接的流式套接字调用accept()才有意义。最终调用的是tcp_prot对象的accept成员函数。</p>
<pre><code>数据接收
   在接收数据的过程，主要分两个阶段：BOTTOM-HALF和TOP-HALF。
BOTTOM-HALF：

![](http://blog.chinaunix.net/attachment/201208/3/23069658_1344005514lM97.jpg)

BOTTOM-HALF最后将收到的skb填充到socket套接字的接收队列里，参见下图。

TOP-HALF：
紧承BOTTOM-HALF阶段，该阶段的主要任务就是从接收队列里拿出一个skb然后将其传递到用户空间去，如下：
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201208/3/23069658_1344005520RD47.jpg" alt=""></p>
<p>数据发送<br>    同样的，数据发送也分两个阶段，对照接收的情况，发送数据时肯定也存在一个发送队列，这样想就对了。前面关于发送数据包时我们介绍过的API有write()、send()、sendto()还有一个sendmsg()没介绍到。<br>    TOP-HALF如下：<br>    <img src="http://blog.chinaunix.net/attachment/201208/3/23069658_13440055257uNe.jpg" alt=""></p>
<pre><code>BOTTOM-HALF如下所示：
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201208/3/23069658_1344005532BaaL.jpg" alt=""></p>
<p>经过这么一份探索，我们对这几个数据收发的API至少理解的要比别人深刻些了吧。至于不同函数之间的回调、调用关系是如何搭建的，我们在协议栈分析章节再做进一步讨论。最后来一张全家福：<br><img src="http://blog.chinaunix.net/attachment/201208/3/23069658_134400554217ZM.jpg" alt=""></p>
<p> <a href="http://blog.chinaunix.net/uid-23069658-id-3141409.html" target="_blank" rel="external">linux 内核网络，数据接收流程图</a><br><img src="http://blog.csdn.net/images/blog_csdn_net/cz_hyf/receive.gif" alt=""></p>
<p><a href="http://blog.csdn.net/echoisland/article/details/6993756" target="_blank" rel="external">linux 内核网络,数据发送流程图</a><br><img src="http://blog.csdn.net/images/blog_csdn_net/cz_hyf/send.gif" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.ibm.com/developerworks/cn/linux/l-linux-networking-stack/figure2.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Linux的整个网络协议栈都构建与Linux Kernel中，整个栈也是严格按照分层的思想来设计的，整个栈共分为五层，分别是 ：&lt;/p&gt;
&lt;p&gt;1． 系统调用接口层，实质是一个面向用户空间应用程序的接口调用库，向用户空间应用程序提供使用网络服务的接口。&lt;br&gt;2． 协议无关的接口层，就是SOCKET层，这一层的目的是屏蔽底层的不同协议（更准确的来说主要是TCP与UDP，当然还包括RAW IP， SCTP等），以便与系统调用层之间的接口可以简单，统一。简单的说，不管我们应用层使用什么协议，都要通过系统调用接口来建立一个SOCKET，这个SOCKET其实是一个巨大的sock结构，它和下面一层的网络协议层联系起来，屏蔽了不同的网络协议的不同，只把数据部分呈献给应用层（通过系统调用接口来呈献）。&lt;br&gt;3． 网络协议实现层，毫无疑问，这是整个协议栈的核心。这一层主要实现各种网络协议，最主要的当然是IP，ICMP，ARP，RARP，TCP，UDP等。这一层包含了很多设计的技巧与算法，相当的不错。&lt;br&gt;4． 与具体设备无关的驱动接口层，这一层的目的主要是为了统一不同的接口卡的驱动程序与网络协议层的接口，它将各种不同的驱动程序的功能统一抽象为几个特殊的动作，如open，close，init等，这一层可以屏蔽底层不同的驱动程序。&lt;br&gt;5． 驱动程序层，这一层的目的就很简单了，就是建立与硬件的接口层。&lt;br&gt;可以看到，Linux网络协议栈是一个严格分层的结构，其中的每一层都执行相对独立的功能，结构非常清晰。&lt;br&gt;其中的两个“无关”层的设计非常棒，通过这两个“无关”层，其协议栈可以非常轻松的进行扩展。在我们自己的软件设计中，可以吸收这种设计方法。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Linux" scheme="http://ipcreator.me/tags/Linux/"/>
    
      <category term="Network" scheme="http://ipcreator.me/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>从头构建自己的Linux系统</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/start-up-of-linux/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/start-up-of-linux/</id>
    <published>2017-02-27T02:03:06.000Z</published>
    <updated>2017-02-27T02:03:51.359Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-3343885.html" target="_blank" rel="external">wjlkoorey</a></p>
<p><img src="http://blog.chinaunix.net/attachment/201303/23/23069658_1364022276448d.gif" alt=""></p>
<p>在博文“<a href="http://blog.chinaunix.net/uid-23069658-id-3142047.html" target="_blank" rel="external">Linux系统启动过程分析</a>”中我们了解了linux系统的启动流程，今天我们就来手动一步一步从头来构建一个最小的linux系统，然后用模拟器将其加载起来。常见的模拟器有Qemu、Bochs、VMWare、VPC、Virtual Box和Xen等，以及特殊的模拟UML(User-Mode-Linux)，这里我们选择用VMWare。</p>
   <a id="more"></a>
<pre><code>我们制作的Linux系统有shell功能，支持Web Server，telnet等服务，以及ifconfig，vi等常见工具。准备工作：
在http://www.kernel.org 下载内核源代码 linux-2.6.21.tar.bz2；
在http://www.busybox.org 下载busybox源码 busybox-1.14.4.tar.bz2。
在本地新建一个目录，例如/home/DIY，当然你可以随便选择，然后将下载的内核源码和busybox源码包拷贝到/home/DIY目录下；
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347285972uzot.jpg" alt=""><br>    A)、构造根文件系统<br>    我们都知道标准的发行版linux其目录结构一般是如下这个样子：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_13472860152b32.jpg" alt=""><br>    我们制作的linux运行起来之后当然也应该有个类似的目录结构。这里我们只选择一些必须的目录，因为我们构建的是“最小”的Linux系统。<br>    在/home/DIY目录下依次执行如下命令：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347286127dDXv.jpg" alt=""><br>    在rootfs/etc目录下分别建立如下各个文件group、inittab、profile、protocols、<br>rcS和services：<br>点击(此处)折叠或打开</p>
<p>###################### /etc/group ###################### from here<br>root:x:0:<br>ftp:x:800:<br>nogroup:x:65534:</p>
<p>######################/etc/inittab ###################### from here<br>::sysinit:/etc/rcS<br>tty1::askfirst:-/bin/sh –login<br>tty2::askfirst:-/bin/sh –login<br>tty3::askfirst:-/bin/sh –login</p>
<p>######################/etc/profile ###################### from here</p>
<p>#!/bin/sh</p>
<p>cat &lt;&lt;EOF</p>
<p>Welcome to  DIY</p>
<p>EOF<br>export PATH=/bin:/sbin:/usr/bin:/usr/sbin</p>
<p>######################/etc/protocols ###################### from here</p>
<h1 id="Internet-IP-protocols"><a href="#Internet-IP-protocols" class="headerlink" title="Internet (IP) protocols"></a>Internet (IP) protocols</h1><p>#<br>ip    0    IP<br>icmp    1    ICMP<br>igmp    2    IGMP<br>ggp    3    GGP<br>ipencap    4    IP-ENCAP<br>st    5    ST<br>tcp    6    TCP<br>egp    8    EGP<br>igp    9    IGP<br>pup    12    PUP<br>udp    17    UDP<br>hmp    20    HMP<br>xns-idp    22    XNS-IDP<br>rdp    27    RDP<br>iso-tp4    29    ISO-TP4<br>xtp    36    XTP<br>ddp    37    DDP<br>idpr-cmtp 38    IDPR-CMTP<br>idrp    45    IDRP<br>rsvp    46    RSVP<br>gre    47    GRE<br>esp    50    IPSEC-ESP<br>ah    51    IPSEC-AH<br>skip    57    SKIP<br>rspf    73    RSPF CPHB<br>vmtp    81    VMTP<br>eigrp    88    EIGRP<br>ospf    89    OSPFIGP<br>ax.25    93    AX.25<br>ipip    94    IPIP<br>etherip    97    ETHERIP<br>encap    98    ENCAP<br>pim    103    PIM<br>ipcomp    108    IPCOMP<br>vrrp    112    VRRP<br>l2tp    115    L2TP<br>isis    124    ISIS<br>sctp    132    SCTP<br>fc    133    FC</p>
<p>######################/etc/rcS ###################### from here</p>
<p>#!/bin/sh</p>
<p>export PATH=/bin:/sbin:/usr/bin:/usr/sbin<br>mount -t proc none /proc<br>mount -t sysfs none /sys<br>mount -t tmpfs tmpfs /dev -o size=512K,mode=0755<br>echo DIY &gt; /proc/sys/kernel/hostname</p>
<p>mkdir -p /var/run /var/log /var/lock /var/state \<br>         /var/tmp /var/mnt /dev/pts /dev/shm<br>mount devpts /dev/pts -t devpts</p>
<p>echo /bin/mdev &gt; /proc/sys/kernel/hotplug<br>mdev -s</p>
<p>ifconfig lo 127.0.0.1 up<br>ifconfig eth0 192.168.1.1 netmask 255.255.255.0 up</p>
<p>telnetd -l /bin/sh<br>httpd -h /www</p>
<p>###################/etc/services ################# from here<br>ssh    22/tcp<br>ssh    22/udp<br>telnet    23/tcp<br>telnet    23/udp<br>http    80/tcp    www www-http<br>http    80/udp    www www-http<br>login    513/tcp<br>shell    514/tcp    cmd<br>    再在rootfs/www目录下建立一个index.html文件，内容如下：<br>点击(此处)折叠或打开</p>
<p></p><h1>Success!</h1><p></p>
<p></p><p>Welcome to DIY linux!</p><br>    最后rootfs目录的组织结构如下：<p></p>
<p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347286131jGjr.jpg" alt=""><br>    其他的命令行工具由接下来的busybox生成。<br>    B)、编译busybox<br>    在Linux系统中常用的工具，如 bash、grep命令、sed 命令、telnetd等，这里为了方便省事，我就用busybox来代替了。现在的busybox拥有非常多的工具，真正成为一个“Busy”的box。后面的例子将尝试只使用 busybox来充当所有应用层所需要的工具集。包括Shell，网络配置，web服务器，telnet等。而busybox也由此得到一个称号“嵌入式世界的瑞士军刀”。</p>
<p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347286135MHsQ.jpg" alt=""><br>    将修改后的“ <a href="http://blog.chinaunix.net/attachment/attach/23/06/96/5823069658e50981fdbbfec6c9bf052e2250a0fba1.txt" target="_blank" rel="external">busybox.config.txt</a>   ”复制到busybox-1.14.4目录下重命名为“.config”，注意文件名前面的点“.”绝对不能省略。</p>
<p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287650blYG.jpg" alt=""><br>    之后弹出如下界面：</p>
<p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287704pnSv.jpg" alt=""><br>    在配置界面下，我们依次选择：Busybox Settings =&gt; Build Options 然后选中(按空格键)，这里我们将编译生成静态库的busybox，如下图中所示选项：</p>
<p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287709zv94.jpg" alt=""><br>    配置busybox的安装目录，依次选择：Busybox Settings =&gt; Installation Options ，如下：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_13472877465653.jpg" alt=""><br>    保存配置后执行编译命令make：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287779joj0.jpg" alt=""><br>    编译完成后执行make install：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287785pc6p.jpg" alt=""><br>    这样我们编译的busybox工具就安装到前面我们创建的rootfs目录中了，此时rootfs目录下的组织结构就变成了如下这个样子：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287856Nm1K.jpg" alt=""><br>    不管是bin，sbin，usr/bin还是usr/sbin目录下的命令都是到/bin/busybox应用程序的软连接。目前rootfs这个目录结构和我们常见的linux发行版的目录结构还是有些差异，所以我们继续往rootfs中增加dev，proc，tmp，var，lib，root和sys目录：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347287895zW4p.jpg" alt=""><br>    这样子就更像一个“标准”linux发行版的样子了。接下来我们来制作一个ramdisk的初始化文件，名为initrd。Linux内置支持以RAM磁盘的形式来启动。关于Linux系统的启动流程请参见博文“Linux系统启动过程分析”里的详细描述。<br>    C)、制作initrd文件<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288002U90O.jpg" alt=""><br>    D)、编译Linux内核源码<br>    解压内核源码，然后将我修改后的内核配置文件“ linux.config.txt   ”拷贝到linux-2.6.21目录下，重命名为“.config”，如下：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288136iSA4.jpg" alt=""><br>    执行make menuconfig可以查看哪些配置项已经被选上：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288142C8Gn.jpg" alt=""><br>    执行make命令开始编译内核：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288152gMkw.jpg" alt=""><br>    我们提供的内核配置文件linux.conf将模块已经静态编译到内核中去了，这样就会造成内核比较大，如果是采用动态加载模块的话，需要将所有模块安装到前面制作的ramdisk里。编译好的内核镜像，一般位于：<br>•    对于x86平台，压缩后的核心是 arch/x86/boot/bzImage；<br>•    对于MIPS平台，压缩后的核心是 arch/powerpc/boot/zImage；<br>•    对于arm平台，压缩后的核心是 arch/arm/boot/zImage<br>……<br>E)、用VMWare加载内核<br>将arch/x86/boot/bzImage和/home/DIY/initrd文件拷贝到linux系统的/boot目录下，然后修改/boot/grub/menu.lst，在其中添加如下一项：<br>点击(此处)折叠或打开<br>title DIY Your OS<br>   root (hd0,0)<br>   kernel /bzImage rw root=/dev/ram rootfs_size=8M<br>   initrd /initrd<br>   PS：因为我们制作的initrd文件大小就是8M，所以rootfs_size=8M。<br>    重启VMware，在启动界面我们自己built的linux系统：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_13472882411HVV.jpg" alt=""><br>    启动后效果如下：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288291YEn1.jpg" alt=""><br>    我们可以看到eth0接口已经up了，其IP地址默认为192.168.1.1，因为我虚拟机的IP地址池是192.168.6.*网段的，所以手动将eth0的接口IP设置为192.168.6.135：<br><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288378iAFa.jpg" alt=""><br>然后通过web和telnet访问我们自己做的系统，最终的访问结果如下：</p>
<p><img src="http://blog.chinaunix.net/attachment/201209/10/23069658_1347288420b44Z.jpg" alt=""></p>
<h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><p>通过今天的学习相信大家对Linux系统的运行原理和启动流程的认识又上了一个新的台阶，更重要的是学会了如何手动构建一个“最小”的Linux“发行版”系统。那么，现在回过头来再看那些商业版的Linux系统，其实本质和我们今天做工作的差不多，所以，如果有条件我们也可以发行一个自己的系统了:)。</p>
<h2 id="Linux系统启动过程分析"><a href="#Linux系统启动过程分析" class="headerlink" title="Linux系统启动过程分析 "></a><a href="http://blog.chinaunix.net/uid-23069658-id-3142047.html" target="_blank" rel="external">Linux系统启动过程分析 </a></h2><p>经过对Linux系统有了一定了解和熟悉后，想对其更深层次的东西做进一步探究。这当中就包括系统的启动流程、文件系统的组成结构、基于动态库和静态库的程序在执行时的异同、协议栈的架构和原理、驱动程序的机制等等。<br>       本人在综合了现有网上大家智慧的基础上，结合对2.6.32的内核代码的研读，基于CentOS 6.0系统对Linux的启动流程做了些分析。由于才疏学浅，知识所限，有些地方分析不妥之处还请各位高手不吝赐教。<br>        OK，我们言归正传。对于一台安装了Linux系统的主机来说，当用户按下开机按钮时，一共要经历以下几个过程，如图：<br><img src="http://blog.chinaunix.net/attachment/201303/23/23069658_1364022276448d.gif" alt=""></p>
<pre><code>其中，每个过程都执行了自己该做的初始化部分的事情，有些过程又可分为好几个子过程。接下来，我们就对每个阶段做一个详细分析和讲解。
</code></pre><p>BIOS自检</p>
<pre><code>稍有计算机基础的人都应该听过BIOS(Basic Input / Output System)，又称基本输入输出系统，可以视为是一个永久地记录在ROM中的一个软件，是操作系统输入输出管理系统的一部分。早期的BIOS芯片确实是&quot;只读&quot;的，里面的内容是用一种烧录器写入的，一旦写入就不能更改，除非更换芯片。现在的主机板都使用一种叫Flash EPROM的芯片来存储系统BIOS，里面的内容可通过使用主板厂商提供的擦写程序擦除后重新写入，这样就给用户升级BIOS提供了极大的方便。
BIOS的功能由两部分组成，分别是POST码和Runtime服务。POST阶段完成后它将从存储器中被清除，而Runtime服务会被一直保留，用于目标操作系统的启动。BIOS两个阶段所做的详细工作如下：
 步骤1：上电自检POST(Power-on self test)，主要负责检测系统外围关键设备（如：CPU、内存、显卡、I/O、键盘鼠标等）是否正常。例如，最常见的是内存松动的情况，BIOS自检阶段会报错，系统就无法启动起来；
 步骤2：步骤1成功后，便会执行一段小程序用来枚举本地设备并对其初始化。这一步主要是根据我们在BIOS中设置的系统启动顺序来搜索用于启动系统的驱动器，如硬盘、光盘、U盘、软盘和网络等。我们以硬盘启动为例，BIOS此时去读取硬盘驱动器的第一个扇区(MBR，512字节)，然后执行里面的代码。实际上这里BIOS并不关心启动设备第一个扇区中是什么内容，它只是负责读取该扇区内容、并执行。
</code></pre><p>至此，BIOS的任务就完成了，此后将系统启动的控制权移交到MBR部分的代码。<br>        PS: 在个人电脑中，Linux的启动是从0xFFFF0地址开始的。</p>
<p>系统引导</p>
<pre><code>我们首先来了解一下MBR，它是Master Boot Record的缩写。硬盘的0柱面、0磁头、1扇区称为主引导扇区。它由三个部分组成，主引导程序(Bootloader)、 硬盘分区表DPT（Disk Partition table）和硬盘有效标志（55AA），其结构图如下所示：
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201303/23/23069658_1364022306CqJH.gif" alt=""></p>
<pre><code> 磁盘分区表包含以下三部分：
 1）、Partition ID  （5：延申  82：Swap   83：Linux   8e：LVM     fd：RAID）
 2）、Partition起始磁柱
 3）、Partition的磁柱数量
通常情况下，诸如lilo、grub这些常见的引导程序都直接安装在MBR中。我们以grub为例来分析这个引导过程。
grub引导也分为两个阶段stage1阶段和stage2阶段(有些较新的grub又定义了stage1.5阶段)。
 1)、stage1：stage1是直接被写入到MBR中去的，这样机器一启动检测完硬件后，就将控制权交给了GRUB的代码。也就是上图所看到的前446个字节空间中存放的是stage1的代码。BIOS将stage1载入内存中0x7c00处并跳转执行。stage1（/stage1/start.S）的任务非常单纯，仅仅是将硬盘0头0道2扇区读入内存。而0头0道2扇区内容是源代码中的/stage2/start.S，编译后512字节，它是stage2或者stage1_5的入口。而此时，stage1是没有识别文件系统的能力的。如果感觉脑子有些晕了，那么下面的过程就直接跳过，去看stage2吧！
 【外传】定位硬盘的0头0道2扇区的过程：
  BIOS将stage1载入内存0x7c00处并执行，然后调用BIOS INIT13中断，将硬盘0头0道2扇区内容载入内存0x7000处，然后调用copy_buffer将其转移到内存0x8000处。在定位0头0道2扇区时通常有两种寻址方式：LBA和CHS。如果你是刨根问底儿型的爱好者，那么此时去找谷哥打听打听这两种方式的来龙去脉吧。
  2)、stage2：严格来说这里还应该再区分个stage1.5的，就一并把stage1.5放在这里一起介绍了，免得大家看得心里乱哄哄的。好的，我们继续说0头0到2扇区的/stage2/start.S文件，当它的内容被读入到内存之后，它的主要作用就是负责将stage2或stage1.5从硬盘读到内存中。如果是stage2，它将被载入到0x820处；如果是stage1.5，它将被载入到0x2200处。这里的stage2或者stage1_5不是/boot分区/boot/grub目录下的文件，因为这个时候grub还没有能力识别任何文件系统。
 ?  如果start.S加载stage1.5：stage1.5它存放在硬盘0头0道3扇区向后的位置，stage1_5作为stage1和stage2中间的桥梁，stage1_5有识别文件系统的能力，此后grub才有能力去访问/boot分区/boot/grub目录下的 stage2文件，将stage2载入内存并执行。
 ?  如果start.S加载stage2：同样，这个stage2也不是/boot分区/boot/grub目录下的stage2，这个时候start.S读取的是存放在/boot分区Boot Sector的stage2。这种情况下就有一个限制：因为start.S通过BIOS中断方式直接对硬盘寻址（而非通过访问具体的文件系统），其寻址范围有限，限制在8GB以内。因此这种情况需要将/boot分区分在硬盘8GB寻址空间之前。
 假如是情形2，我们将/boot/grub目录下的内容清空，依然能成功启动grub；假如是情形1，将/boot/grub目录下stage2删除后，则系统启动过程中grub会启动失败。
</code></pre><p>启动内核</p>
<pre><code>当stage2被载入内存执行时，它首先会去解析grub的配置文件/boot/grub/grub.conf，然后加载内核镜像到内存中，并将控制权转交给内核。而内核会立即初始化系统中各设备并做相关的配置工作，其中包括CPU、I/O、存储设备等。
</code></pre><p>关于Linux的设备驱动程序的加载，有一部分驱动程序直接被编译进内核镜像中，另一部分驱动程序则是以模块的形式放在initrd(ramdisk)中。<br>      Linux内核需要适应多种不同的硬件架构，但是将所有的硬件驱动编入内核又是不实际的，而且内核也不可能每新出一种硬件结构，就将该硬件的设备驱动写入内核。实际上Linux的内核镜像仅是包含了基本的硬件驱动，在系统安装过程中会检测系统硬件信息，根据安装信息和系统硬件信息将一部分设备驱动写入 initrd 。这样在以后启动系统时，一部分设备驱动就放在initrd中来加载。这里有必要给大家再多介绍一下initrd这个东东：<br>       initrd 的英文含义是 bootloader initialized RAM disk，就是由 boot loader 初始化的内存盘。在 linu2.6内核启动前，boot loader 会将存储介质中的 initrd 文件加载到内存，内核启动时会在访问真正的根文件系统前先访问该内存中的 initrd 文件系统。在 boot loader 配置了 initrd 的情况下，内核启动被分成了两个阶段，第一阶段先执行 initrd 文件系统中的init，完成加载驱动模块等任务，第二阶段才会执行真正的根文件系统中的 /sbin/init 进程。<br>      另外一个概念：initramfs<br>       initramfs 是在 kernel 2.5中引入的技术，实际上它的含义就是：在内核镜像中附加一个cpio包，这个cpio包中包含了一个小型的文件系统，当内核启动时，内核将这个 cpio包解开，并且将其中包含的文件系统释放到rootfs中，内核中的一部分初始化代码会放到这个文件系统中，作为用户层进程来执行。这样带来的明显的好处是精简了内核的初始化代码，而且使得内核的初始化过程更容易定制。<br>疑惑的是：我的内核是2.6.32-71.el6.i686版本，但在我的/boot分区下面却存在的是/boot/initramfs-2.6.32-71.el6.i686.img类型的文件，没搞明白，还望高人解惑。我只知道在2.6内核中支持两种格式的initrd，一种是2.4内核的文件系统镜像image-initrd，一种是cpio格式。接下来我们就来探究一下initramfs-2.6.32-71.el6.i686.img里到底放了那些东西。<br><img src="http://blog.chinaunix.net/attachment/201303/23/23069658_1364022354796s.gif" alt=""><br>    在tmp文件夹中解压initrd.img里的内容：<br><img src="http://blog.chinaunix.net/attachment/201303/23/23069658_1364022370Prdp.gif" alt=""></p>
<p>如果initrd.img文件的格式显示为“initrd.img:ISO 9660 CD-ROM filesystem data”，则可直接输入命令“mount -o loop initrd.img /mnt/test”进行挂载。<br>         通过上的分析和我们的验证，我们确实得到了这样的结论：<br>         grub的stage2将initrd加载到内存里，让后将其中的内容释放到内容中，内核便去执行initrd中的init脚本，这时内核将控制权交给了init文件处理。我们简单浏览一下init脚本的内容，发现它也主要是加载各种存储介质相关的设备驱动程序。当所需的驱动程序加载完后，会创建一个根设备，然后将根文件系统rootfs以只读的方式挂载。这一步结束后，释放未使用的内存，转换到真正的根文件系统上面去，同时运行/sbin/init程序，执行系统的1号进程。此后系统的控制权就全权交给/sbin/init进程了。<br>l  初始化系统<br>经过千辛万苦的跋涉，我们终于接近黎明的曙光了。接下来就是最后一步了：初始化系统。/sbin/init进程是系统其他所有进程的父进程，当它接管了系统的控制权先之后，它首先会去读取/etc/inittab文件来执行相应的脚本进行系统初始化，如设置键盘、字体，装载模块，设置网络等。主要包括以下工作：<br>1)、执行系统初始化脚本(/etc/rc.d/rc.sysinit)，对系统进行基本的配置，以读写方式挂载根文件系统及其它文件系统，到此系统算是基本运行起来了，后面需要进行运行级别的确定及相应服务的启动。rc.sysinit所做的事情(不同的Linux发行版，该文件可能有些差异)如下：<br>（1）获取网络环境与主机类型。首先会读取网络环境设置文件”/etc/sysconfig/network”，获取主机名称与默认网关等网络环境。<br>（2）测试与载入内存设备/proc及usb设备/sys。除了/proc外，系统会主动检测是否有usb设备，并主动加载usb驱动，尝试载入usb文件系统。<br>（3）决定是否启动SELinux。<br>（4）接口设备的检测与即插即用（pnp）参数的测试。<br>（5）用户自定义模块的加载。用户可以再”/etc/sysconfig/modules/<em>.modules”加入自定义的模块，此时会加载到系统中。<br>（6）加载核心的相关设置。按”/etc/sysctl.conf”这个文件的设置值配置功能。<br>（7）设置系统时间（clock）。<br>（8）设置终端的控制台的字形。<br>（9）设置raid及LVM等硬盘功能。<br>（10）以方式查看检验磁盘文件系统。<br>（11）进行磁盘配额quota的转换。<br>（12）重新以读取模式载入系统磁盘。<br>（13）启动quota功能。<br>（14）启动系统随机数设备（产生随机数功能）。<br>（15）清楚启动过程中的临时文件。<br>（16）将启动信息加载到”/var/log/dmesg”文件中。<br> 当/etc/rc.d/rc.sysinit执行完后，系统就可以顺利工作了，只是还需要启动系统所需要的各种服务，这样主机才可以提供相关的网络和主机功能，因此便会执行下面的脚本。<br>2)、执行/etc/rc.d/rc脚本。该文件定义了服务启动的顺序是先K后S，而具体的每个运行级别的服务状态是放在/etc/rc.d/rc</em>.d（<em>=0~6）目录下，所有的文件均是指向/etc/init.d下相应文件的符号链接。rc.sysinit通过分析/etc/inittab文件来确定系统的启动级别，然后才去执行/etc/rc.d/rc</em>.d下的文件。<br>/etc/init.d-&gt; /etc/rc.d/init.d<br>/etc/rc -&gt;/etc/rc.d/rc<br>/etc/rc<em>.d -&gt;/etc/rc.d/rc</em>.d<br>/etc/rc.local-&gt; /etc/rc.d/rc.local<br>/etc/rc.sysinit-&gt; /etc/rc.d/rc.sysinit<br>也就是说，/etc目录下的init.d、rc、rc<em>.d、rc.local和rc.sysinit均是指向/etc/rc.d目录下相应文件和文件夹的符号链接。我们以启动级别3为例来简要说明一下。<br>/etc/rc.d/rc3.d目录，该目录下的内容全部都是以 S 或 K 开头的链接文件，都链接到”/etc/rc.d/init.d”目录下的各种shell脚本。S表示的是启动时需要start的服务内容，K表示关机时需要关闭的服务内容。/etc/rc.d/rc</em>.d中的系统服务会在系统后台启动，如果要对某个运行级别中的服务进行更具体的定制，通过chkconfig命令来操作，或者通过setup、ntsys、system-config-services来进行定制。如果我们需要自己增加启动的内容，可以在init.d目录中增加相关的shell脚本，然后在rc*.d目录中建立链接文件指向该shell脚本。这些shell脚本的启动或结束顺序是由S或K字母后面的数字决定，数字越小的脚本越先执行。例如，/etc/rc.d/rc3.d /S01sysstat就比/etc/rc.d/rc3.d /S99local先执行。<br>3)、执行用户自定义引导程序/etc/rc.d/rc.local。其实当执行/etc/rc.d/rc3.d/S99local时，它就是在执行/etc/rc.d/rc.local。S99local是指向rc.local的符号链接。就是一般来说，自定义的程序不需要执行上面所说的繁琐的建立shell增加链接文件的步骤，只需要将命令放在rc.local里面就可以了，这个shell脚本就是保留给用户自定义启动内容的。<br>4)、完成了系统所有的启动任务后，linux会启动终端或X-Window来等待用户登录。tty1,tty2,tty3…这表示在运行等级1，2，3，4的时候，都会执行”/sbin/mingetty”，而且执行了6个，所以linux会有6个纯文本终端，mingetty就是启动终端的命令。<br>除了这6个之外还会执行”/etc/X11/prefdm-nodaemon”这个主要启动X-Window<br>至此，系统就启动完毕了。以上分析不到的地方还请各位大虾不吝指正。<br>关于Linux的其他分析内容下次再继续写。<br>最后附上一张非常完整的系统启动流程图，适合各个水平阶段的读者。<br><img src="http://blog.chinaunix.net/attachment/201303/23/23069658_13640223868sSU.gif" alt=""></p>
<p>参考文献：<br><a href="http://www.cnblogs.com/scnutiger/archive/2009/09/30/1576795.html" target="_blank" rel="external">http://www.cnblogs.com/scnutiger/archive/2009/09/30/1576795.html</a><br><a href="http://www.it.com.cn/f/edu/0411/24/51090.htm" target="_blank" rel="external">http://www.it.com.cn/f/edu/0411/24/51090.htm</a><br><a href="http://bbs.chinaunix.net/thread-2046548-1-1.html" target="_blank" rel="external">http://bbs.chinaunix.net/thread-2046548-1-1.html</a><br><a href="http://space.itpub.net/8111049/viewspace-680043" target="_blank" rel="external">http://space.itpub.net/8111049/viewspace-680043</a><br><a href="http://dongdiy.blog.51cto.com/1908223/366909" target="_blank" rel="external">http://dongdiy.blog.51cto.com/1908223/366909</a><br><a href="http://icarusli.iteye.com/blog/625755" target="_blank" rel="external">http://icarusli.iteye.com/blog/625755</a><br><a href="http://www.54sa.net/?p=549" target="_blank" rel="external">http://www.54sa.net/?p=549</a><br><a href="http://roclinux.cn/?p=1301" target="_blank" rel="external">http://roclinux.cn/?p=1301</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3343885.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201303/23/23069658_1364022276448d.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在博文“&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3142047.html&quot;&gt;Linux系统启动过程分析&lt;/a&gt;”中我们了解了linux系统的启动流程，今天我们就来手动一步一步从头来构建一个最小的linux系统，然后用模拟器将其加载起来。常见的模拟器有Qemu、Bochs、VMWare、VPC、Virtual Box和Xen等，以及特殊的模拟UML(User-Mode-Linux)，这里我们选择用VMWare。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Linux" scheme="http://ipcreator.me/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>小议Linux系统下的文件系统</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-file-system/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-file-system/</id>
    <published>2017-02-27T01:14:06.000Z</published>
    <updated>2017-02-27T05:38:05.833Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-3437835.html" target="_blank" rel="external">wjlkoorey</a></p>
<p>Linux的老江湖们对这个概念当然不会陌生，然而刚接触Linux的新手们就会被文件系统这个概念弄得晕头转向，恰好我当年正好属于后者。</p>
<p>从windows下转到Linux的童鞋听到最多的应该是fat32和ntfs(在windows 2000之后所出现的一种新型的日志文件系统)，那个年代经常听到说“我要把C盘格式化成ntfs格式，D盘格式化成fat32格式”。一到Linux下，很多入门Linux的书籍中当牵扯到文件系统这个术语时，二话不说，不管三七二十一就给出了下面这个图，然后逐一解释一下每个目录是拿来干啥的、里面会放什么类型的文件就完事儿了，弄得初学者经常“丈二和尚摸不着头脑”。难道这就是Linux下的文件系统。而且新手一直被“灌输”一个思想：Linux下一切都是文件，不再像Windows那样用扩展名来为文件分类等等。这就让那些喜欢刨根问底的fresh-fish很是不爽，他们本着对学术的严谨、技术的狂热的态度，一心想弄明白：到底什么才是文件系统。本文的目的就是和大家分享一下我当初是如何学习Linux的文件系统的，也算是一个“老”油条的一些心得吧。</p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/linux%E7%9B%AE%E5%BD%95.png" alt=""></p>
   <a id="more"></a>
<h3 id="更多参考："><a href="#更多参考：" class="headerlink" title="更多参考："></a>更多参考：</h3><p>   <a href="http://blog.chinaunix.net/uid-23069658-id-3468489.html" target="_blank" rel="external"> 戏说文件系统之ext2【上】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3475672.html" target="_blank" rel="external"> 戏说文件系统之ext2【下】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3499922.html" target="_blank" rel="external"> 戏说文件系统之ext2【续】</a><br>   <a href="http://blog.chinaunix.net/uid-23069658-id-3529783.html" target="_blank" rel="external">戏说文件系统之ext3【上】 </a></p>
<p>“文件系统”的主语是“文件”，那么文件系统的意思就是“用于管理文件的(管理)系统”，而这套管理系统所管理的对象当然就是文件了。在大多数操作系统里，“文件是数据的集合”这个基本点是一致的，而这些数据最终都是存储在存储介质里，如硬盘、光盘、U盘等。</p>
<p>另一方面，用户在管理数据时也是文件为基本单位，他们所关心的问题是：<br>1、我的文件在什么地方放着？<br>2、我如何将数据存入某个文件？<br>3、如何从文件里将数据读出来？<br>3、不再需要的文件怎么将其删除？</p>
<p>简而言之，文件系统就是一套用于定义文件的命名和组织数据的规范，其根本目的是便对文件进行查询和存取。</p>
<p>Unix/Linux系统中的文件系统有个很重要的特性就挂载，即文件系统在使用前必须被挂载在一个实际的目录下才能使用，这是因为类Unix系统中的文件系统都遵循了FHS(Filesystem Hierarchy Standard)。在FHS中详细定义了类Unix操作系统中各种应用软件、管理工具、开发工具、脚本和帮助文件所处的位置。这样，通过该标准，软件发布商和用户在不同的发行版的linux系统里都能预测软件安装后，文件和目录所处的位置。</p>
<p>文件系统为了实现对文件更好的管理、组织方式，引入了目录的概念。目录里不但可以保存文件还可以保存目录，以目录为依托，最终会形成一个目录树的结构。根据FHS的规定，Linux不同的发行版都存在如下的目录结构：<br><img src="http://okkntqe2h.bkt.clouddn.com/Linux%E4%B8%8D%E5%90%8C%E7%9A%84%E5%8F%91%E8%A1%8C%E7%89%88%E9%83%BD%E5%AD%98%E5%9C%A8%E5%A6%82%E4%B8%8B%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.jpg" alt=""><br>上图中一个比较特殊的目录就是硬盘的根目录“/”，如果我们将一块硬盘格式化成ext3或ext4格式后，通过mount命令将其挂载到根目录下，就形成了我们通常所说的“根文件系统”。根文件系统不是一个新实体，而是指挂载在根目录下的存储设备(或某个分区)实际所使用的文件系统类型。当“根文件系统”被挂载后，内存中就有了如上所示的目录结构树。这里提醒一点，千万不要以为你在命令行输入“cd /usr/src/”等命令时是在“操作”硬盘，其实你是在内存的VFS的目录树里。这里就不展开了，后面剖析VFS时再详细介绍。作为用户在使用文件系统时，对于某个具体的存储设备，例如U盘或硬盘，无非是首先执行诸如mk2fs或mkfs.xxx这样的命令对存储设备进行格式化，将其格式化成某种类型的文件系统，然后用mount命令将该存设备挂载到某个具体的目录下，然后对该目录下的文件进行“增、删、改、查”就可以实现对该存储设备上数据的操作。</p>
<p>这里就有几个关键点需要大家留意了，以便我们后面分析VSF机制时心里能做到“提前亮”。在类Unix系统中讨论文件系统，不可回避的要就要牵扯到挂载(mount)机制，在windows下这个过程已经被微软封装了，普通用户察觉不到，至少在我接触windows这么些年从来没听谁跟我提起过windows下的mount机制。所以我们在分析源码时可以留意一下挂载的实现机制。另一个就是目录，这个再熟悉不过，Unix/Linux和Windows，几乎所有的操作系统都至此，其目的就是用来对文件进行组织便于用户管理，即站在用户的角度来说就是回答了“我的文件在哪儿放着”的问题。</p>
<p>在Linux早期设计阶段，文件系统与内核代码是整合在一起的，这样做的缺点是显而易见的。假如，我的系统只能识别ext3格式的文件系统，我的U盘是fat32格式，那么很不幸的是我的U盘将不会被我的系统所识别，所以fat32格式的U盘在我们的系统上将无法使用。为了支持不同种类的文件系统，Linux采用了在Unix系统中已经广泛采用的设计思想，通过虚拟文件系统VFS来屏蔽下层各种不同类型文件系统的实现细节和差异。<br><img src="http://okkntqe2h.bkt.clouddn.com/VFS%E6%9D%A5%E5%B1%8F%E8%94%BD%E4%B8%8B%E5%B1%82%E5%90%84%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82%E5%92%8C%E5%B7%AE%E5%BC%82.jpg" alt=""><br>其实VFS最早是由Sun公司提出的，目的是实现网络文件系统NFS(Network File System)，其基本思想是将各种文件系统的公共部分抽取出来，形成一个抽象层。对用户的应用程序而言，VFS提供了文件系统的系统调用接口。而对具体的文件系统来说，VFS通过一系列统一的外部接口屏蔽了实现细节，使得对文件的操作不再关心下层文件系统的类型，更不用关心具体的存储介质，这一切都是透明的。</p>
<h3 id="小结一下："><a href="#小结一下：" class="headerlink" title="小结一下："></a>小结一下：</h3><p>所谓文件系统就是操作系统用来明确磁盘或分区上的文件以及数据结构的一种方法，也就是磁盘上文件的组织方法。普通用户所看到的文件系统，是以目录结构而存在的一个多级分层的树状结构，但作为开发人员我们得知道其实每个目录下都可以挂载不同类型的文件系统。最后一点是，每个文件系统可以占用磁盘的一个分区，而不是整个硬盘，这一点请注意。VFS并不是一个实际的文件系统，它是类Unix操作系统给我们提供的一种用于统一管理具体文件系统的机制。当我们要开发一种新的文件系统时，需要遵照VFS的规范，才能享受VFS带来的好处。</p>
<p>未完，待续…</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3437835.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Linux的老江湖们对这个概念当然不会陌生，然而刚接触Linux的新手们就会被文件系统这个概念弄得晕头转向，恰好我当年正好属于后者。&lt;/p&gt;
&lt;p&gt;从windows下转到Linux的童鞋听到最多的应该是fat32和ntfs(在windows 2000之后所出现的一种新型的日志文件系统)，那个年代经常听到说“我要把C盘格式化成ntfs格式，D盘格式化成fat32格式”。一到Linux下，很多入门Linux的书籍中当牵扯到文件系统这个术语时，二话不说，不管三七二十一就给出了下面这个图，然后逐一解释一下每个目录是拿来干啥的、里面会放什么类型的文件就完事儿了，弄得初学者经常“丈二和尚摸不着头脑”。难道这就是Linux下的文件系统。而且新手一直被“灌输”一个思想：Linux下一切都是文件，不再像Windows那样用扩展名来为文件分类等等。这就让那些喜欢刨根问底的fresh-fish很是不爽，他们本着对学术的严谨、技术的狂热的态度，一心想弄明白：到底什么才是文件系统。本文的目的就是和大家分享一下我当初是如何学习Linux的文件系统的，也算是一个“老”油条的一些心得吧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/linux%E7%9B%AE%E5%BD%95.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="File System" scheme="http://ipcreator.me/tags/File-System/"/>
    
  </entry>
  
  <entry>
    <title>硬盘的存储原理和内部架构</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-hard-disk/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-hard-disk/</id>
    <published>2017-02-27T00:58:06.000Z</published>
    <updated>2017-02-27T05:39:34.066Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-3413957.html" target="_blank" rel="external">wjlkoorey</a></p>
<p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_13533340196613.jpg" alt=""></p>
<p>本来想写个文件系统的专题，结果发现对硬盘的内部架构和存储原理还是比较模糊，因为不了解“一点”硬盘的存储原理对文件系统的认识老是感觉镜花水月，不踏实。经过搜集整理资料就由了本文的问世。借用Bean_lee兄一句话：成果和荣耀归于前辈。</p>
   <a id="more"></a>
<p>首先，让我们看一下硬盘的发展史：<br>1956年9月13日，IBM的IBM 350 RAMAC(Random Access Method of Accounting and Control)是现代硬盘的雏形，整个硬盘需要50个直径为24英寸表面涂有磁浆的盘片，它相当于两个冰箱的体积，不过其存储容量只有5MB。<br>1971年，IBM开始采用一种名叫Merlin的技术生产硬盘，这种技术据称能使硬盘头更好地在盘片上索引。<br>1973年，IBM 3340问世，主流采用采用红色。这个大家伙每平方英寸存储1.7MB的数据，在当时已经创了一个纪录。许多公司共享这些系统，需要时按照时间和存储空间租用它。租赁价值为7.81美元每兆，这个价格比当时汽油的价格还贵38%。它拥有“温彻斯特”这个绰号，也就是我们现在所熟知的“温氏架构”。来源于它两个30MB的存储单元，恰好是当时出名的“温彻斯特来福枪”的口径和填弹量。至此，硬盘的基本架构被确立。<br>1979年，IBM发明了Thin Film磁头，使硬盘的数据定位更加准确，因此使得硬盘的密度大幅提升。<br>1980年，两位前IBM员工创立的公司开发出5.25英寸规格的5MB硬盘，这是首款面向台式机的产品，而该公司正是希捷公司（Seagate）公司。<br>1982年，日立发布了全球首款容量超过1GB的硬盘。这就是容量为1.2GB的H-8598硬盘。这块硬盘拥有10片14英寸盘片，两个读写磁头。<br>1980年代末，IBM推出MR（Magneto Resistive磁阻）技术令磁头灵敏度大大提升，使盘片的存储密度较之前的20Mbpsi（bit/每平方英寸）提高了数十倍，该技术为硬盘容量的巨大提升奠定了基础。1991年，IBM应用该技术推出了首款3.5英寸的1GB硬盘。<br>1970年到1991年，硬盘碟片的存储密度以每年25%~30%的速度增长；从1991年开始增长到60%～80%；至今，速度提升到100%甚至是200%。从1997年开始的惊人速度提升得益于IBM的GMR（Giant Magneto Resistive，巨磁阻）技术，它使磁头灵敏度进一步提升，进而提高了存储密度。<br>1993年，康诺（Conner Peripherals）推出了CP30344硬盘容量是340MB。<br>1995年，为了配合Intel的LX芯片组，昆腾与Intel携手发布UDMA 33接口—EIDE标准将原来接口数据传输率从16.6MB/s提升到了33MB/s。同年，希捷开发出液态轴承（FDB，Fluid Dynamic Bearing）马达。所谓的FDB就是指将陀螺仪上的技术引进到硬盘生产中，用厚度相当于头发直径十分之一的油膜取代金属轴承，减轻了硬盘噪音与发热量。<br>1996年，希捷收购康诺（Conner Peripherals）<br>1998年2月，UDMA 66规格面世。<br>2000年10月，迈拓（Maxtor）收购昆腾。<br>2003年1月，日立宣布完成20.5亿美元的收购IBM硬盘事业部计划，并成立日立环球存储科技公司（Hitachi Global StorageTechnologies, Hitachi GST）。<br>2005年日立环储和希捷都宣布了将开始大量采用磁盘垂直写入技术（perpendicular recording），该原理是将平行于盘片的磁场方向改变为垂直（90度），更充分地利用的存储空间。<br>2005年12月21日，希捷宣布收购迈拓（Maxtor）。<br>2007年1月，日立环球存储科技宣布将会发售全球首只1Terabyte的硬盘，比原先的预定时间迟了一年多。硬盘的售价为399美元，平均每美分可以购得27.5MB硬盘空间。<br>2011年3月，西部数据以43亿美元的价格，收购日立环球存储科技。<br>2011年4月，希捷宣布与三星强化策略伙伴关系。</p>
<p>从硬盘问世至今已经过了56个年头，不管是容量、体积还是生产工艺都较之前有了重大革新和改进，但一直都保持了“温氏”的架构(固态硬盘除外，它不是我们今天的主角)。经过封装后的硬盘，对我们一般呈现出如下的样子：</p>
<p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_135333387102xH.jpg" alt=""></p>
<p>背面：<br><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_1353333877zG6U.jpg" alt=""></p>
<p>打开后盖：<br><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_13533338896Qgs.jpg" alt=""></p>
<p>硬盘主要由盘体、控制电路板和接口部件组成。盘体就是一个密封，封装了多个盘片的腔体；控制电路包含硬盘BIOS，主控芯片和硬盘缓存等单元；接口部件包含电源、数据接口主从跳线等。<br>    硬盘的盘片一般采用合金材料，多数为铝合金(IBM曾经开发过玻璃材质的盘片，好像现在有些厂家也生产玻璃材质的盘片，但不多见)，盘面上涂着磁性材料，厚度一般在0.5mm左右。有些硬盘只装一张盘片，有些则有多张。硬盘盘片安装在主轴电机的转轴上，在主轴电机的带动下作高速旋转。每张盘片的容量称为单碟容量，而一块硬盘的总容量就是所有盘片容量的总和。早期硬盘由于单碟容量低，所以盘片较多。现代的硬盘盘片一般只有少数几片。 盘片上的记录密度很大，而且盘片工作时会高速旋转，为保证其工作的稳定，数据保存的长久，所以硬片都是密封在硬盘内部。不可自行拆卸硬盘，在普通环境下空气中的灰尘、指纹、头发丝等细小杂质都会对硬盘造成永久损害。一个被大卸八块的硬盘如下：</p>
<p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_13533340196613.jpg" alt=""></p>
<p>接下来我们了解一下硬盘的盘面，柱面，磁道和扇区的概念。</p>
<pre><code>盘面
硬盘一般会有一个或多个盘片，每个盘片可以有两个面(Side)，即第1个盘片的正面称为0面，反面称为1面；第2个盘片的正面称为2面，反面称为3面...依次类推。每个盘面对应一个磁头(head)用于读写数据。第一个盘面的正面的磁头称为0磁头，背面称为1磁头；第二个盘片正面的磁头称为2磁头，背面称为3磁头，以此类推。盘面数和磁头数是相等的。
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_1353333899SpvU.jpg" alt=""></p>
<p>一张单面的盘片需要一个磁头，双面的盘片则需要两个磁头。硬盘采用高精度、轻型磁头驱动和定位系统。这种系统能使磁头在盘面上快速移动，读写硬盘时，磁头依靠磁盘的高速旋转引起的空气动力效应悬浮在盘面上，与盘面的距离不到1微米(约为头发直径的百分之一)，可以在极短的时间内精确定位到计算机指令指定的磁道上。<br>    早期由于定位系统限制，磁头传动臂只能在盘片的内外磁道之间移动。因此，不管开机还是关机，磁头总在盘片上。所不同的是，关机时磁头停留在盘片启停区，开机时磁头“飞行”在磁盘片上方。</p>
<pre><code>磁道
每个盘片的每个盘面被划分成多个狭窄的同心圆环，数据就是存储在这样的同心圆环上，我们将这样的圆环称为磁道(Track)，每个盘面可以划分多个磁道。关机时磁头停留在硬盘的着陆区(Landing Zone)，这个着陆区以前是位于离盘心最近的区域，不存放任何数据。在后期的硬盘工艺中有些硬盘生产厂商将这个区域被移动到了盘片的外面，如下所示：
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_1353333893jFV3.jpg" alt=""></p>
<p>在每个盘面的最外圈，离盘心最远的地方是“0”磁道，向盘心方向依次增长为1磁道，2磁道，等等。硬盘数据的存放就是从最外圈开始。</p>
<pre><code>扇区
根据硬盘规格的不同，磁道数可以从几百到成千上万不等。每个磁道上可以存储数KB的数据，但计算机并不需要一次读写这么多数据。在这一这基础上，又把每个磁道划分成若干弧段，每段称为一个扇区(Sector)。扇区是硬盘上存储的物理单位，每个扇区可存储128×2N次方（N＝0,1,2,3）字节的数据。从DOS时代起，每扇区是128×22＝512字节，现在已经成了业界不成文的规定，也没有哪个硬盘厂商试图去改变这种约定。也就是说即使计算机只需要硬盘上存储的某个字节，也须一次把这个字节所在的扇区中的全部512字节读入内存，再选择所需的那个字节。扇区的编号是从1开始，而不是0，这一点需要注意。另外，硬盘在划分扇区时，和软盘是有一定区别的。软盘的一个磁道中，扇区号一般依次编排，如1号，2号，3号...以此类推。但在硬盘磁道中，扇区号是按照某个间隔跳跃着编排。比如，2号扇区并不是1号扇区后的按顺序的第一个而是第八个，3号扇区又是2号扇区后的按顺序的第八个，依此类推，这个“八”称为交叉因子。
这个交叉因子的来历有必要详述一下，我们知道，数据读取经常需要按顺序读取一系列相邻的扇区(逻辑数据相邻)。如对磁道扇区按物理顺序进行编号，很有可能出现当磁头读取完第一个扇区后，由于盘片转速过快来不及读取下一个扇区，(要知道物理相邻扇区位置距离是极小的)，必须等待转完一圈，这极大浪费了时间。所以就用交叉来解决这个问题。增加了交叉因子后的扇区编号一般是下面这个样子：
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_1353334399LCDw.jpg" alt=""><br>柱面<br>    柱面其实是我们抽象出来的一个逻辑概念，前面说过，离盘心最远的磁道为0磁道，依此往里为1磁道，2磁道，3磁道….，不同面上相同磁道编号则组成了一个圆柱面，即所称的柱面(Cylinder)。这里要注意，硬盘数据的读写是按柱面进行，即磁头读写数据时首先在同一柱面内从0磁头开始进行操作，依次向下在同一柱面的不同盘面(即磁头上)进行操作，只有在同一柱面所有的磁头全部读写完毕后磁头才转移到下一柱面，因为选取磁头只需通过电子切换即可，而选取柱面则必须通过机械切换。电子切换比从在机械上磁头向邻近磁道移动快得多。因此，数据的读写按柱面进行，而不按盘面进行。 读写数据都是按照这种方式进行，尽可能提高了硬盘读写效率。</p>
<pre><code>簇
将物理相邻的若干个扇区称为了一个簇。操作系统读写磁盘的基本单位是扇区，而文件系统的基本单位是簇(Cluster)。在Windows下，随便找个几字节的文件，在其上面点击鼠标右键选择属性，看看实际大小与占用空间两项内容，如大小：15 字节 (15 字节)， 占用空间：4.00 KB (4，096 字节)。这里的占用空间就是你机器分区的簇大小，因为再小的文件都会占用空间，逻辑基本单位是4K，所以都会占用4K。 簇一般有这几类大小 4K，8K，16K，32K，64K等。簇越大存储性能越好，但空间浪费严重。簇越小性能相对越低，但空间利用率高。NTFS格式的文件系统簇的大小为4K。
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_1353333904wZ21.jpg" alt=""></p>
<p>硬盘读写数据的过程<br>    现代硬盘寻道都是采用CHS(Cylinder Head Sector)的方式，硬盘读取数据时，读写磁头沿径向移动，移到要读取的扇区所在磁道的上方，这段时间称为寻道时间(seek time)。因读写磁头的起始位置与目标位置之间的距离不同，寻道时间也不同。目前硬盘一般为2到30毫秒，平均约为9毫秒。磁头到达指定磁道后，然后通过盘片的旋转，使得要读取的扇区转到读写磁头的下方，这段时间称为旋转延迟时间(rotational latencytime)。</p>
<pre><code>一个7200（转/每分钟）的硬盘，每旋转一周所需时间为60×1000÷7200=8.33毫秒，则平均旋转延迟时间为8.33÷2=4.17毫秒（平均情况下，需要旋转半圈）。平均寻道时间和平均选装延迟称为平均存取时间。

所以，最后看一下硬盘的容量计算公式：
硬盘容量=盘面数×柱面数×扇区数×512字节


在博文“Linux启动过程分析”中我们提到过MBR，它是存在于硬盘的0柱面，0磁头，1扇区里，占512字节的空间。这512字节里包含了主引导程序Bootloader和磁盘分区表DPT。其中Bootloader占446字节，分区表占64字节，一个分区要占用16字节，64字节的分区表只能被划分4个分区，这也就是目前我们的硬盘最多只能支持4个分区记录的原因。
</code></pre><p><img src="http://blog.chinaunix.net/attachment/201211/19/23069658_1353334783PHx3.gif" alt=""></p>
<p>即，如果你将硬盘分成4个主分区的话，必须确保所有的磁盘空间都被使用了(这不是废话么)，一般情况下我们都是划分一个主分区加一个扩展分区，然后在扩展分区里再继续划分逻辑分区。当然，逻辑分区表也需要分区表，它是存在于扩展分区的第一个扇区里，所以逻辑分区的个数最多也只能有512/16=32个，并不是想分多少个逻辑分区都可以。<br>    注意，我们所说的扩展分区也是要占用分区表项的。例如，如果我们的硬盘只划分一个主分区和一个逻辑分区，此时的分区表的排列如下：<br>   Device Boot      Start         End      Blocks   Id  System<br>/dev/sda1   *           1          19      152586   83  Linux<br>/dev/sda2              20        2569    20482875   83  Extended<br>/dev/sda5            2570        19457     4128705   82  Linux<br>    主分区为1号分区，扩展分区占用了2号分区，3和4号扩展分区被预留了下来，逻辑分区从5开始编号依次递增，这里我们只划分了一个逻辑分区。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3413957.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201211/19/23069658_13533340196613.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本来想写个文件系统的专题，结果发现对硬盘的内部架构和存储原理还是比较模糊，因为不了解“一点”硬盘的存储原理对文件系统的认识老是感觉镜花水月，不踏实。经过搜集整理资料就由了本文的问世。借用Bean_lee兄一句话：成果和荣耀归于前辈。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="File System" scheme="http://ipcreator.me/tags/File-System/"/>
    
  </entry>
  
  <entry>
    <title>显示卡的“心脏” GPU工作原理介绍</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-GPU/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-GPU/</id>
    <published>2017-02-27T00:58:06.000Z</published>
    <updated>2017-02-27T05:39:04.098Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.eechina.com/thread-176224-1-1.html" target="_blank" rel="external">designapp</a></p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/gpu%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%A4%A7%E8%87%B4%E5%88%86%E6%88%90%205%20%E4%B8%AA%E6%AD%A5%E9%AA%A4.png" alt=""></p>
<p>图形处理器(英语：Graphics Processing Unit，缩写：gpu)，又称显示核心、视觉处理器、显示芯片，是一种专门在个人电脑、工作站、游戏机和一些移动设备(如平板电脑、智能手机等)上图像运算工作的微处理器。</p>
<p>用途是将计算机系统所需要的显示信息进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。显卡作为电脑主机里的一个重要组成部分，承担输出显示图形的任务，对于从事专业图形设计的人来说显卡非常重要。</p>
<a id="more"></a>
<p>gpu由于历史原因，是为了视频游戏而产生的(至今其主要驱动力还是不断增长的视频游戏市场)，在三维游戏中常常出现的一类操作是对海量数据进行相同的操作，如：对每一个顶点进行同样的坐标变换，对每一个顶点按照同样的光照模型计算颜色值。</p>
<p>gpu的众核架构非常适合把同样的指令流并行发送到众核上，采用不同的输入数据执行。在 2003-2004年左右，图形学之外的领域专家开始注意到gpu与众不同的计算能力，开始尝试把gpu用于通用计算(即GPgpu)。之后NVIDIA发布了CUDA，amd和等公司也发布了OpenCL，gpu开始在通用计算领域得到广泛应用，包括：数值分析，海量数据处理(排序，Map- Reduce等)，金融分析等等。</p>
<p>简而言之，<strong>当程序员为cpu编写程序时，他们倾向于利用复杂的逻辑结构优化算法从而减少计算任务的运行时间，即Latency。当程序员为gpu编写程序时，则利用其处理海量数据的优势，通过提高总的数据吞吐量(Throughput)来掩盖 Lantency。</strong> 目前，cpu和gpu的区别正在逐渐缩小，因为gpu也在处理不规则任务和线程间通信方面有了长足的进步。另外，功耗问题对于gpu比cpu更严重。</p>
<p>gpu是显示卡的“心脏”，也就相当于cpu在电脑中的作用，它决定了该显卡的档次和大部分性能，同时也是2D显示卡和3D显示卡的区别依据。</p>
<p>2D显示芯片在处理3D图像和特效时主要依赖cpu的处理能力，称为“软加速”。3D显示芯片是将三维图像和特效处理功能集中在显示芯片内，也即所谓的“硬件加速”功能。显示芯片通常是显示卡上最大的芯片(也是引脚最多的)。gpu使显卡减少了对cpu的依赖，并进行部分原本cpu的工作，尤其是在3D图形处理时。gpu所采用的核心技术有硬体T&amp;L、立方环境材质贴图和顶点混合、纹理压缩和凹凸映射贴图、双重纹理四像素256位渲染引擎等，而硬体T&amp;L技术可以说是gpu的标志。</p>
<h2 id="gpu工作原理-工作原理"><a href="#gpu工作原理-工作原理" class="headerlink" title="gpu工作原理-工作原理"></a>gpu工作原理-工作原理</h2><p>简单的说gpu就是能够从硬件上支持T&amp;L(Transform and LighTIng，多边形转换与光源处理)的显示芯片，因为T&amp;L是3D渲染中的一个重要部分，其作用是计算多边形的3D位置和处理动态光线效果，也可以称为“几何处理”。一个好的T&amp;L单元，可以提供细致的3D物体和高级的光线特效;只不过大多数PC中，T&amp;L的大部分运算是交由cpu处理的(这就也就是所谓的软件T&amp;L)，由于cpu的任务繁多，除了T&amp;L之外，还要做内存管理、输入响应等非3D图形处理工作，因此在实际运算的时候性能会大打折扣，常常出现显卡等待cpu数据的情况，其运算速度远跟不上今天复杂三维游戏的要求。即使cpu的工作频率超过 1GHz或更高，对它的帮助也不大，由于这是PC本身设计造成的问题，与cpu的速度无太大关系。</p>
<p>gpu图形处理，可以大致分成 5 个步骤，如下图箭头的部分。分别为 vertex shader、primiTIve processing、rasterisaTIon、fragment shader、tesTIng and blending。<br><img src="http://okkntqe2h.bkt.clouddn.com/gpu%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%A4%A7%E8%87%B4%E5%88%86%E6%88%90%205%20%E4%B8%AA%E6%AD%A5%E9%AA%A4.png" alt=""></p>
<p>第一步，vertex shader。是将三维空间中数个(x，y，z)顶点放进 gpu 中。在这一步骤中，电脑会在内部模拟出一个三维空间，并将这些顶点放置在这一空间内部。接着，投影在同一平面上，也是我们将看到的画面。同时，存下各点距离投影面的垂直距离，以便做后续的处理。</p>
<p>这个过程就像是本地球观看星星一般。地球的天空，就像是一个投影面，所有的星星，不管远近皆投影在同一面上。本地球的我们，抬起头来观看星星，分不出星星的远近，只能分辨出亮度。gpu 所投影出的结果，和这个情况类似。<br><img src="http://okkntqe2h.bkt.clouddn.com/%E6%8A%AC%E8%B5%B7%E5%A4%B4%E6%9D%A5%E8%A7%82%E7%9C%8B%E6%98%9F%E6%98%9F%EF%BC%8C%E5%88%86%E4%B8%8D%E5%87%BA%E6%98%9F%E6%98%9F%E7%9A%84%E8%BF%9C%E8%BF%91%EF%BC%8C%E5%8F%AA%E8%83%BD%E5%88%86%E8%BE%A8%E5%87%BA%E4%BA%AE%E5%BA%A6.png" alt=""></p>
<p>从地球所看到的星空，星星就像是投影到一球面上，除非使用特别的仪器，不然分不出星星和地球的距离</p>
<p>第二步，primitive processing。是将相关的点链接在一起，以形成图形。在一开始输入数个顶点进入 gpu 时，程序会特别注记哪些点是需要组合在一起，以形成一线或面。就像是看星座的时候一样，将相关连的星星连起来，形成特定的图案。</p>
<p>第三步，rasterisation。因为电脑的屏幕是由一个又一个的像素组成，因此，需要将一条连续的直线，使用绘图的演算法，以方格绘出该直线。图形也是以此方式，先标出边线，再用方格填满整个平面。</p>
<p>第四步，fragment shader。将格点化后的图形着上颜色。所需着上的颜色也是于输入时便被注记。在游玩游戏时，这一步相当耗费 gpu 的计算资源，因为光影的效果、物体表面材质皆是在这一步进行，这些计算决定着游戏画面的精细程度。因此在游玩游戏时，调高游戏画面品质大幅增加这一步的计算负担，降低游戏品质。<br><img src="http://okkntqe2h.bkt.clouddn.com/%E5%B0%86%E4%B8%80%E4%B8%AA%E4%B8%89%E8%A7%92%E5%BD%A2%EF%BC%8C%E7%94%A8%E6%96%B9%E6%A0%BC%E5%91%88%E7%8E%B0%E8%BF%91%E4%BC%BC%E5%8E%9F%E5%A7%8B%E5%9B%BE%E6%A1%88%EF%BC%8C%E5%B9%B6%E7%9D%80%E4%B8%8A%E9%A2%9C%E8%89%B2%E3%80%82%E4%B8%80%E5%9D%97%E5%8F%88%E4%B8%80%E5%9D%97%E7%9A%84%E6%96%B9%E6%A0%BC%EF%BC%8C%E5%B0%B1%E6%98%AF%E6%98%BE%E7%A4%BA%E5%99%A8%E4%B8%8A%E7%9A%84%E5%83%8F%E7%B4%A0.png" alt=""></p>
<p>将一个三角形，用方格呈现近似原始图案，并着上颜色。一块又一块的方格，就是显示器上的像素</p>
<p>最后一步，testing and blending。便是将第一步所获得的投影垂直距离取出，和第四步的结果一同做最后处理。在去除被会被其他较近距离的物体挡住的物体后，让剩下的图形放进 gpu 的输出内存。之后，结果便会被送到电脑屏幕显示。</p>
<h2 id="gpu工作原理-主要供应商"><a href="#gpu工作原理-主要供应商" class="headerlink" title="gpu工作原理-主要供应商"></a>gpu工作原理-主要供应商</h2><p>gpu有非常多的厂商都生产，和cpu一样，生产的厂商比较多，但大家熟悉的却只有INA，以至于大家以为gpu只有三大厂商。</p>
<h3 id="英特尔"><a href="#英特尔" class="headerlink" title="英特尔"></a>英特尔</h3><p>英特尔的gpu基本为集成显卡芯片，用于英特尔的主板和英特尔的cpu。可能你想不到，要是只按市场占有率计算，英特尔随着他主板及cpu发售的集成gpu占据了整个gpu市场的60%以上。</p>
<p>他的gpu主要有：唯一一款独立显卡芯片Intel 740(i740)。Extreme Graphics系列、GMA系列(集成于芯片组中)。现在的HD Graphics系列[1] 、Iris? Graphics系列[2] 、Iris? Pro Graphics[2] 系列等(集成于cpu中)。</p>
<h3 id="NVIDIA"><a href="#NVIDIA" class="headerlink" title="NVIDIA"></a>NVIDIA</h3><p>NVIDIA是现在最大的独立显卡芯片生产销售商。他的gpu包括大家熟悉的Geforce系列 ，包括GTX、GTS、GT等。专业工作站的Quadro系列 ，超级计算的Tesla系列 ，多显示器商用的NVS系列 ，移动设备的Tegra系列 。</p>
<p>以前也销售集成在主板上的集成显卡芯片，这些随着主板芯片组一起发售，但是由于amd收购ATI后自身主板芯片组gpu能力提高，NVIDIA芯片组如日中天的景象已经消失了。曾经为游戏机Xbox、PS3供应gpu。</p>
<h3 id="amd-ATI"><a href="#amd-ATI" class="headerlink" title="amd(ATI)"></a>amd(ATI)</h3><p>amd是世界上第二大的独立显卡芯片生产销售商，他的前身就是ATI，2006年amd以54亿美元收购ATI。他的gpu主要是大家熟悉的Radeon系列，包括以前的X、HD系列，近几年的R9、R7、R5、R3，现在的RX系列等。专业工作站的FireGL系列，超级计算的FireStream系列，多显示器商用的FireMV系列，现在前三者已合并为FirePro系列 。</p>
<p>早期ATI还生产过Wonder系列、Mach系列、Rage系列芯片。除了独立显卡之外amd还拥有集成显卡芯片，集成于芯片组、APU中。由于amd收购ATI后，其主板市场迅速扩大，已经夺取了NVIDIA在amd处理器主板芯片组的半壁江山。就现在的发售量和发售盈利方面，amd的gpu市场占有率方面仍然略输于NVIDIA。amd也是游戏机Xbox 360、Wii、Wii U、PS4、Xbox One的gpu供应商。</p>
<h3 id="3dfx"><a href="#3dfx" class="headerlink" title="3dfx"></a>3dfx</h3><p>是一家于1994年成立的生产3D gpu及显卡的公司。曾经生产了Voodoo系列显卡，并且研发了SLI技术。由于经营不善等问题于2002年被NVIDIA收购。</p>
<h3 id="Matrox"><a href="#Matrox" class="headerlink" title="Matrox"></a>Matrox</h3><p>Matrox当年和NVIDIA，ATI一起争夺独立显卡芯片市场份额的一家公司，在曾经的一个时期Matrox的显卡和NVIDIA，ATI曾经在性能上比肩过。但由于后来其开发能力日渐衰退，在GF5时期，也就是ATI的9000系列时期，Matrox由于性能上整整落后了GF5900和Raden9800一个世代而逐渐被淘汰，淡出了民用独立显卡市场。但时下Matrox仍然在工程用专业显卡方面有自己的地位。</p>
<p>这些显卡用于工程主图和多头输出仍然很强力。与NVIDIA和amd的专业显卡不同，NVIDIA，ATI的专业显卡涉足的是3D领域，而Matrox得专业显卡涉足的是2D领域，也就是CAD。但由于OpenCL、CUDA的日渐普及，DX10以上显卡将在所有支持CUDA的程序上表现出惊人的性能，也就是说当CUDA在各种运用软件普及的那天，Matrox也必将退出2D专业卡的市场。</p>
<h3 id="SiS和VIA"><a href="#SiS和VIA" class="headerlink" title="SiS和VIA"></a>SiS和VIA</h3><p>矽统和威盛时下是对孪生兄弟，但他们曾经也是分开的两家公司，并且都生产自己主板的集成显卡芯片。但这可怜的两兄弟已经逐步在淡出主板市场了，也就必定将淡出gpu市场。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.eechina.com/thread-176224-1-1.html&quot;&gt;designapp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/gpu%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%A4%A7%E8%87%B4%E5%88%86%E6%88%90%205%20%E4%B8%AA%E6%AD%A5%E9%AA%A4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;图形处理器(英语：Graphics Processing Unit，缩写：gpu)，又称显示核心、视觉处理器、显示芯片，是一种专门在个人电脑、工作站、游戏机和一些移动设备(如平板电脑、智能手机等)上图像运算工作的微处理器。&lt;/p&gt;
&lt;p&gt;用途是将计算机系统所需要的显示信息进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。显卡作为电脑主机里的一个重要组成部分，承担输出显示图形的任务，对于从事专业图形设计的人来说显卡非常重要。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="GPU" scheme="http://ipcreator.me/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>CPU的内部架构和工作原理</title>
    <link href="http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-cpu/"/>
    <id>http://ipcreator.me/2017/02/27/Program/Concepts/the-anatomy-of-cpu/</id>
    <published>2017-02-27T00:06:06.000Z</published>
    <updated>2017-02-27T00:44:31.430Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.chinaunix.net/uid-23069658-id-3563960.html" target="_blank" rel="external">wjlkoorey</a></p>
<p><strong>更多参考</strong><br><a href="http://blog.csdn.net/yang_yulei/article/details/22529437" target="_blank" rel="external"> 处理器体系结构（了解CPU的基本运行原理）——《深入理解计算机系统》</a><br><a href="http://blog.csdn.net/yang_yulei/article/details/22613327" target="_blank" rel="external">CPU的实模式与保护模式（简介）</a></p>
<p>一直以来，总以为CPU内部真是如当年学习《计算机组成原理》时书上所介绍的那样，是各种逻辑门器件的组合。当看到纳米技术时就想，真的可以把那些器件做的那么小么？直到看了<a href="http://v.youku.com/v_show/id_XMjQyMDAyMTUy.html" target="_blank" rel="external">Intel CPU制作流程</a>及<a href="http://v.youku.com/v_show/id_XMzcyODU1NDIw.html" target="_blank" rel="external">AMD芯片的制作流程</a>的介绍不禁感慨，原来科技是如此的发达。</p>
<p>本文我们以Intel为例对CPU的工作原理做简单介绍，仅仅是简单介绍，那么AMD，ARM，MIPS甚至PowerPC你应该会触类旁通才对。</p>
<a id="more"></a>
<p>还记得那是1968年7月18日，鲍勃-诺斯和戈登-摩尔的新公司在美国加利福尼亚州，美丽的圣弗朗西斯科湾畔芒延维尤城的梅多费大街365号开张了。并在成立不久斥资15000美元从一家叫INTELCO的公司手中买下了Intel名称的使用权。由此Intel这位半导体巨人开始了他在IT行业传奇般的历史。</p>
<p>   1971年11月15日，这一天被当作全球IT界具有里程碑意义的日子而被写入许多计算机专业教科书。Intel公司的工程师特德·霍夫发明了世界上第一个微处理器—4004，这款4位微处理器虽然只有45条指令，而且每秒只能执行5万条指令。甚至比不上1946年由美国陆军宾夕法尼亚大学研制的世界第一台计算机ENIAC。但它的集成度却要高很多，一块4004的重量还不到一盅司。 他因发明了微处理器，被英国《经济学家》杂志称为“第二次世界大战以来最有影响的科学家之一”。Intel公司的CPU发展历程如下表所示：</p>
<p><img src="http://blog.chinaunix.net/attachment/201304/3/23069658_1364999823QSwa.jpg" alt=""></p>
<p>以及后面的Pentium 1,2,3和4，再到酷睿、酷睿2，这里就不再一一列举。Intel从8086开始，就进入了我们所谓的x86时代。而80386的诞生则标志着Intel正是进入了32位微处理器的时代。从80386到Pentium 4这个年代的CPU，就是传说中的IA-32时代。<br>   我们都知道CPU的根本任务就是执行指令，对计算机来说最终都是一串由“0”和“1”组成的序列。CPU从逻辑上可以划分成3个模块，分别是控制单元、运算单元和存储单元，这三部分由CPU内部总线连接起来。如下所示：</p>
<p>   <img src="http://blog.chinaunix.net/attachment/201304/3/23069658_1364999862MRMY.jpg" alt=""></p>
<h3 id="控制单元："><a href="#控制单元：" class="headerlink" title="控制单元："></a>控制单元：</h3><p>   控制单元是整个CPU的指挥控制中心，由指令寄存器IR(Instruction Register)、指令译码器ID(Instruction Decoder)和操作控制器OC(Operation Controller)等，对协调整个电脑有序工作极为重要。它根据用户预先编好的程序，依次从存储器中取出各条指令，放在指令寄存器IR中，通过指令译码(分析)确定应该进行什么操作，然后通过操作控制器OC，按确定的时序，向相应的部件发出微操作控制信号。操作控制器OC中主要包括节拍脉冲发生器、控制矩阵、时钟脉冲发生器、复位电路和启停电路等控制逻辑。</p>
<h3 id="运算单元："><a href="#运算单元：" class="headerlink" title="运算单元："></a>运算单元：</h3><p>是运算器的核心。可以执行算术运算(包括加减乘数等基本运算及其附加运算)和逻辑运算(包括移位、逻辑测试或两个值比较)。相对控制单元而言，运算器接受控制单元的命令而进行动作，即运算单元所进行的全部操作都是由控制单元发出的控制信号来指挥的，所以它是执行部件。</p>
<h3 id="存储单元："><a href="#存储单元：" class="headerlink" title="存储单元："></a>存储单元：</h3><p>包括CPU片内缓存和寄存器组，是CPU中暂时存放数据的地方，里面保存着那些等待处理的数据，或已经处理过的数据，CPU访问寄存器所用的时间要比访问内存的时间短。采用寄存器，可以减少CPU访问内存的次数，从而提高了CPU的工作速度。但因为受到芯片面积和集成度所限，寄存器组的容量不可能很大。寄存器组可分为专用寄存器和通用寄存器。专用寄存器的作用是固定的，分别寄存相应的数据。而通用寄存器用途广泛并可由程序员规定其用途，通用寄存器的数目因微处理器而异。这个是我们以后要介绍这个重点，这里先提一下。</p>
<p>我们将上图细化一下，可以得出CPU的工作原理概括如下：<br><img src="http://blog.chinaunix.net/attachment/201304/6/23069658_1365263161V4M0.jpg" alt=""></p>
<p>总的来说，CPU从内存中一条一条地取出指令和相应的数据，按指令操作码的规定，对数据进行运算处理，直到程序执行完毕为止。</p>
<p>   上图中我没有画总线，只是用逻辑方式对其进行呈现。原因早期Intel的微处理器，诸如8085，8086/8088CPU，普遍采用了地址总线和数据总线复用技术，即将部分(或全部)地址总线与数据总线共用CPU的一些引脚。例如8086外部地址总线有20根，数据总线复用了地址总线的前16根引脚。复用的数据总线和地址总线虽然可以少CPU的引脚数，但却引入了控制逻辑及操作序列上的复杂性。所以，自80286开始，Intel的CPU才采用分开的地址总线和数据总线。</p>
<p>   不管是复用还是分开，对我们理解CPU的运行原理没啥影响，上图没画总线的目的就是怕有些人太过于追求细节，一头扎下去，浮不起来，不能从宏观上藐视敌人。</p>
<p>   OK，总结一下，</p>
<h3 id="CPU的运行原理"><a href="#CPU的运行原理" class="headerlink" title="CPU的运行原理"></a>CPU的运行原理</h3><p>   就是：控制单元在时序脉冲的作用下，将指令计数器里所指向的指令地址(这个地址是在内存里的)送到地址总线上去，然后CPU将这个地址里的指令读到指令寄存器进行译码。对于执行指令过程中所需要用到的数据，会将数据地址也送到地址总线，然后CPU把数据读到CPU的内部存储单元(就是内部寄存器)暂存起来，最后命令运算单元对数据进行处理加工。周而复始，一直这样执行下去，天荒地老，海枯枝烂，直到停电。</p>
<p>   如果你对这段话还是觉得比较晕乎，那么就看我们老师是怎么讲的：<br>   1、取指令：CPU的控制器从内存读取一条指令并放入指令寄存器。指令的格式一般是这个样子滴：<br>   <img src="http://blog.chinaunix.net/attachment/201304/3/23069658_13649999376WN1.jpg" alt=""></p>
<p>   操作码就是汇编语言里的mov,add,jmp等符号码；操作数地址说明该指令需要的操作数所在的地方，是在内存里还是在CPU的内部寄存器里。<br>   2、指令译码：指令寄存器中的指令经过译码，决定该指令应进行何种操作(就是指令里的操作码)、操作数在哪里(操作数的地址)。<br>   3、 执行指令，分两个阶段“取操作数”和“进行运算”。<br>   4、 修改指令计数器，决定下一条指令的地址。</p>
<p>   <img src="http://blog.chinaunix.net/attachment/201304/3/23069658_1364999970ofpV.jpg" alt=""></p>
<p>   关于CPU我们从宏观上把握到这个程度就OK了，后面我们会逐步进入微观阶段，依次介绍80X86寄存器及其用途，NASM汇编和AT&amp;T的区别，以及C代码中嵌入的汇编语言的写法。之所以介绍汇编语言目的不是说用汇编去写代码，那是相当的不现实，除非你是硬件驱动工程师。稍微偏上层一点的开发人员懂点低等的东西，对自己理解整个系统的架构和原理是相当有好处的。</p>
<pre><code>未完，待续…
</code></pre><p><a href="http://blog.chinaunix.net/uid-23069658-id-3569341.html" target="_blank" rel="external"> 寻访x86处理器“实模式”和“保护模式”的前世今生</a></p>
<pre><code>8086的诞生，标志着Intel 正式进入了x86时代，这是个多么具有纪念意义的日子：1978-6-8。同时，8086的诞生也是处理器内存寻址技术的第一次飞跃。
</code></pre><p>对于一根实际的、实实在在的、物理的、可看得见、摸得着的内存条而言，处理器把它当做8位一个字节的序列来管理和存取，每一个内存字节都有一个对应的地址，我们叫它物理地址，用地址可以表示的长度叫做寻址空间。而CPU是如何去访问内存单元里的数据的方式就叫做寻址。</p>
<p>8086得CPU在内存寻址方面第一次引入了一个非常重要的概念—-段。在8086之前都是4位机和8位机的天下，那是并没有段的概念。当程序要访问内存时都是要给出内存的实际物理地址，这样在程序源代码中就会出现很多硬编码的物理地址。这样的程序可想而知，难重定位，可控性弱，结构丑陋，那个年代写这样的程序在我们现在看来是多么让人恼火的一件事儿。</p>
<p>8080问世后四年也就是1978年，Intel开始设计16位CPU，正常来说8086的寻址空间应该是216=64KB才对，但Intel就偏偏不这干，8086的目标寻址空间直指1M，也就是说8086的地址总线位宽要达到20位。如何让16位的内部寄存器对20位的外部地址空间进行寻址，Intel的工程师们从当时的PDP-11小型机身上找到了灵感。PDP-11是美国迪吉多电脑(Digital Equipment Corp.)公司于1970到1980年代热销的16位迷你电脑，PDP-11的内存管理单元(MMU)可以将16位地址映射到24位地址空间里(至于人家是怎么弄，我就真不晓得了)。</p>
<p>为了支持分段机制，Intel在8086的CPU里新增了4个寄存器，分别是代码段CS，数据段DS，堆栈段SS和其他ES(以后深入介绍一下这几个兄弟伙，这涉及到进程的在内存的运行情况)。这样一来，一个物理地址就由两个部分组成，分别是“段地址”:“段内偏移量”。例如，ES=0x1000，DI=0xFFFF，那么这个数据ES:DI在内存里的绝对物理地址就是：<br>AD(Absolute Address)=(ES)*(0x10)+(DI)=0x1FFFF<br>就是讲段基地址左移4位然后加上段内偏移量就得到了物理内存里的绝对地址，经过这么一个变换，就可以得到一个20位的地址，8086就可以对20位的1M内存空间进行寻址了。如下：</p>
<p><img src="http://blog.chinaunix.net/attachment/201304/7/23069658_1365349219pq6G.jpg" alt=""></p>
<p>很明显，这种方式可以寻址的最高地址为0xFFFF:0xFFFF，其地址空间为0x00000~0x10FFEF，因为8086的地址总线是20位，最大只能访问到1MB的物理地址空间，即物理地址空间是0x00000~0xFFFFF。当程序访问0x100000~0x10FFEF这一段地址时，因为其逻辑上是正常的，CPU并不会认为其访问越界而产生异常，但这段地址确实没有实际的物理地址与其对应，怎么办？此时CPU采取的策略是，对于这部分超出1M地址空间的部分，自动将其从物理0地址处开始映射。也就是说，系统计算实际物理地址时是按照对1M求模运算的方式进行的，在有些技术文献里你会看到这种技术被称之为wrap-around。还是通过一幅图来描述一下吧：</p>
<p><img src="http://blog.chinaunix.net/attachment/201304/7/23069658_1365349238u3J7.jpg" alt=""></p>
<p>根据前面的讲解我们可以发现段基址有个特征，其低4位全为0，也就是说每个段的起始地址一定是16的整数倍，这是分段的一个基本原则。这样每个段的最小长度是16字节，而最大长度只能是64KB。这里我们可以计算一下，1MB的物理地址空间能划分成多少个段。<br>如果每个段的长度为16字节，这样1MB物理地址空间最多可以划分成64K个段；<br>如果每个段的长度为64KB，那么1MB的物理地址空间最多能划分成16个段。<br>8086这种分段基址虽然实现了寻址空间的提升，但是也带来一些问题：<br>1、同一个物理地址可以有多种表示方法。例如0x01C0:0x0000和0x0000:0x1C00所表示的物理地址都是0x01C00。<br>2、地址空间缺乏保护机制。对于每一个由段寄存器的内容确定的“基地址”，一个进程总是能够访问从此开始64KB的连续地址空间，而无法加以限制。另一方面，可以用来改变段寄存器内容的指令也不是什么“特权指令”，也就是说，通过改变段寄存器的内容，一个进程可以随心所欲地访问内存中的任何一个单元，而丝毫不受限制。不能对一个进程的内存访问加以限制，也就谈不上对其他进程以及系统本身的保护。与此相应，一个CPU如果缺乏对内存访问的限制，或者说保护，就谈不上什么内存管理，也就谈不上是现代意义上的中央处理器。<br>总结一下：8086和后来的80186，这种只能访问1MB地址空间的工作模式，我们将其称之为“实模式”。我的理解就是“实际地址模式”,因为通过段基址和段偏移算出来的地址，经过模1MB之后得出来的地址都是实际内存的物理地址。</p>
<p>由于8086的上述问题，1982年，Intel在80286的CPU里，首次引入的地址保护的概念。也就是说80286的CPU能够对内存及一些其他外围设备做硬件级的保护设置（实质上就是屏蔽一些地址的访问）。自从最初的x86微处理器规格以后，它对程序开发完全向下兼容，80286芯片被制作成启动时继承了以前版本芯片的特性，工作在实模式下，在这种模式下实际上是关闭了新的保护功能特性，因此能使以往的软件继续工作在新的芯片下。后续的x86处理器都是在计算机加电启动时都是工作在实模式下。<br>也就是说，在保护模式下，程序不能再随意的访问物理内存了，有些内存地址CPU做了明确的保护限制。<br>1985年80386的问世，使Intel完成了从16位到32位CPU的飞跃，这中间80286毫无疑问的就成了这次飞跃的跳板。80286的地址线已经达到24位，可寻址空间是16MB，但Intel当初设计80286时提出的目标是向下兼容，这也是Intel一贯的作风，正是这种作风为Intel后面设计80386时增添了几根儿烦恼丝。所以，在“实模式”下，80286所表现的行为和8086所表现的完全一样。<br>80386是32位CPU，也就是说它的ALU数据总线是32位，地址总线的位宽和CPU内部数据总线的位宽是一致的，都是32位，其寻址范围可达4GB。如果重新设计80386的架构，其结构应该相当简洁才对。但是80386却很遗憾的无法做到这一点，作为一个产品系列中的成员分子，80386必须继续维持“前辈”们的那些段寄存器，必须支持实模式，同时还要支持保护模式。可以看得出来，80386其实也不容易。</p>
<p>所以，Intel决定在80386的段寄存器(CS,DS,SS,ES)的基础上构筑保护模式，并且继续保留段寄存器为16位,同时又增添了两个段寄存器FS和GS。显然，为了实现保护模式，光是用段寄存器来确定一个基地址是不够的，至少还要有一个地址段的长度，并且还需要一些诸如访问权限之类的其他信息。所以，这里需要的是一个数据结构(这个数据结构就叫做“段描述符”，以后会看到)，而并非一个单纯的基地址。对此， Intel设计人员的基本思路是：<br>在保护模式下改变段寄存器的功能，使其从一个单纯的段基址变成指向一个“段描述符”的指针。因此，当一个访存指令发出一个内存地址时， CPU按照下面过程实现从指令中的32位逻辑地址到32位线性地址，再到物理地址的转换：<br>1、首先根据指令的性质来确定该使用哪一个段寄存器，例如操作指令中的地址在代码段CS里，而数据指令中的地址在数据段DS里。这一点与实地址模式相同。<br>2、根据段寄存器里的内容，找到相应的“段描述符”结构。<br>3、然后，从“段描述符”里得到的才是段基址。<br>4、将指令中的地址作为偏移量，然后和段描述符结构中规定的段长度进行比较，看齐是否越界。<br>5、根据指令的性质和段描述符中的访问权限来确定当前指令操作是否越权。<br>6、最后才将指令中的地址作为偏移量，与段基址相加得到线性地址，或者叫虚拟地址。<br>7、最后根据线性地址算出实际的物理地址。<br>所以，实模式就是80186及其之前的CPU只能寻址1MB物理地址空间，且寻到的就是实实在在的物理地址的模式，用户程序想干啥干啥，无法无天；而保护模式，就是说用户成的程序，某些地址你是不能访问的，或者说是有限制性的访问，且你访问到的地址不再是物理地址了，而是一个虚拟的地址。这个虚拟地址要经过一系列算法处理，最终映射到实际物理地址单元里去。<br>现在运行在X86CPU上的主流操作系统，如Linux，FreeBSD，Windows95以后的版本以及OS/2等都是工作在保护模式下。一般情况下，处理器只有在上电启动，引导阶段，初始化系统时才会进入实模式，当实模式阶段的任务完成后，它就切换到了保护模式。当切换到保护模式后就很难再回到实模式了，几乎不可能。(注意我的用词)<br>    未完，待续…</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.chinaunix.net/uid-23069658-id-3563960.html&quot;&gt;wjlkoorey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更多参考&lt;/strong&gt;&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/yang_yulei/article/details/22529437&quot;&gt; 处理器体系结构（了解CPU的基本运行原理）——《深入理解计算机系统》&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/yang_yulei/article/details/22613327&quot;&gt;CPU的实模式与保护模式（简介）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一直以来，总以为CPU内部真是如当年学习《计算机组成原理》时书上所介绍的那样，是各种逻辑门器件的组合。当看到纳米技术时就想，真的可以把那些器件做的那么小么？直到看了&lt;a href=&quot;http://v.youku.com/v_show/id_XMjQyMDAyMTUy.html&quot;&gt;Intel CPU制作流程&lt;/a&gt;及&lt;a href=&quot;http://v.youku.com/v_show/id_XMzcyODU1NDIw.html&quot;&gt;AMD芯片的制作流程&lt;/a&gt;的介绍不禁感慨，原来科技是如此的发达。&lt;/p&gt;
&lt;p&gt;本文我们以Intel为例对CPU的工作原理做简单介绍，仅仅是简单介绍，那么AMD，ARM，MIPS甚至PowerPC你应该会触类旁通才对。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="CPU" scheme="http://ipcreator.me/tags/CPU/"/>
    
  </entry>
  
  <entry>
    <title>Android硬件加速原理与实现简介</title>
    <link href="http://ipcreator.me/2017/02/26/Program/Android/the-essence-of-hardware-accelarate-in-android/"/>
    <id>http://ipcreator.me/2017/02/26/Program/Android/the-essence-of-hardware-accelarate-in-android/</id>
    <published>2017-02-26T14:57:06.000Z</published>
    <updated>2017-02-27T00:24:17.038Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/hardware-accelerate.html" target="_blank" rel="external">子健</a></p>
<p>在手机客户端尤其是Android应用的开发过程中，我们经常会接触到“硬件加速”这个词。由于操作系统对底层软硬件封装非常完善，上层软件开发者往往对硬件加速的底层原理了解很少，也不清楚了解底层原理的意义，因此常会有一些误解，如硬件加速是不是通过特殊算法实现页面渲染加速，或是通过硬件提高CPU/GPU运算速率实现渲染加速。</p>
<p>本文尝试从底层硬件原理，一直到上层代码实现，对硬件加速技术进行简单介绍，其中上层实现基于Android 6.0。</p>
<a id="more"></a>
<h2 id="了解硬件加速对App开发的意义"><a href="#了解硬件加速对App开发的意义" class="headerlink" title="了解硬件加速对App开发的意义"></a>了解硬件加速对App开发的意义</h2><p>对于App开发者，简单了解硬件加速原理及上层API实现，开发时就可以充分利用硬件加速提高页面的性能。以Android举例，实现一个圆角矩形按钮通常有两种方案：使用PNG图片；使用代码（XML/Java）实现。简单对比两种方案如下。</p>
<p>方案    原理    特点<br>使用PNG图片（BitmapDrawable）    解码PNG图片生成Bitmap，传到底层，由GPU渲染    图片解码消耗CPU运算资源，Bitmap占用内存大，绘制慢<br>使用XML或Java代码实现（ShapeDrawable）    直接将Shape信息传到底层，由GPU渲染    消耗CPU资源少，占用内存小，绘制快</p>
<h3 id="页面渲染背景知识"><a href="#页面渲染背景知识" class="headerlink" title="页面渲染背景知识"></a>页面渲染背景知识</h3><p>页面渲染时，被绘制的元素最终要转换成矩阵像素点（即多维数组形式，类似安卓中的Bitmap），才能被显示器显示。<br>页面由各种基本元素组成，例如圆形、圆角矩形、线段、文字、矢量图（常用贝塞尔曲线组成）、Bitmap等。<br>元素绘制时尤其是动画绘制过程中，经常涉及插值、缩放、旋转、透明度变化、动画过渡、毛玻璃模糊，甚至包括3D变换、物理运动（例如游戏中常见的抛物线运动）、多媒体文件解码（主要在桌面机中有应用，移动设备一般不用GPU做解码）等运算。<br>绘制过程经常需要进行逻辑较简单、但数据量庞大的浮点运算。</p>
<h3 id="CPU与GPU结构对比"><a href="#CPU与GPU结构对比" class="headerlink" title="CPU与GPU结构对比"></a>CPU与GPU结构对比</h3><p>CPU（Central Processing Unit，中央处理器）是计算机设备核心器件，用于执行程序代码，软件开发者对此都很熟悉；GPU（Graphics Processing Unit，图形处理器）主要用于处理图形运算，通常所说“显卡”的核心部件就是GPU。</p>
<p>下面是CPU和GPU的结构对比图。其中：<br><img src="http://tech.meituan.com/img/hardware-accelerate/cpu-gpu.png" alt=""><br>黄色的Control为控制器，用于协调控制整个CPU的运行，包括取出指令、控制其他模块的运行等；<br>绿色的ALU（Arithmetic Logic Unit）是算术逻辑单元，用于进行数学、逻辑运算；<br>橙色的Cache和DRAM分别为缓存和RAM，用于存储信息。</p>
<p>从结构图可以看出，CPU的控制器较为复杂，而ALU数量较少。因此<strong>CPU擅长各种复杂的逻辑运算，但不擅长数学尤其是浮点运算。</strong></p>
<p>以8086为例，一百多条汇编指令大部分都是逻辑指令，数学计算相关的主要是16位加减乘除和移位运算。一次整型和逻辑运算一般需要1~3个机器周期，而浮点运算要转换成整数计算，一次运算可能消耗上百个机器周期。<br>更简单的<strong>CPU甚至只有加法指令，减法用补码加法实现，乘法用累加实现，除法用减法循环实现。</strong><br>现代CPU一般都带有硬件浮点运算器（FPU），但主要适用于数据量不大的情况。<br>CPU是串行结构。以计算100个数字为例，对于CPU的一个核，每次只能计算两个数的和，结果逐步累加。<br>和CPU不同的是，<strong>GPU就是为实现大量数学运算设计的。从结构图中可以看到，GPU的控制器比较简单，但包含了大量ALU。GPU中的ALU使用了并行设计，且具有较多浮点运算单元。</strong></p>
<blockquote>
<p><strong>硬件加速的主要原理，就是通过底层软件代码，将CPU不擅长的图形计算转换成GPU专用指令，由GPU完成。</strong></p>
</blockquote>
<p>扩展：很多计算机中的GPU有自己独立的显存；没有独立显存则使用共享内存的形式，从内存中划分一块区域作为显存。显存可以保存GPU指令等信息。</p>
<h3 id="并行结构举例：级联加法器"><a href="#并行结构举例：级联加法器" class="headerlink" title="并行结构举例：级联加法器"></a>并行结构举例：级联加法器</h3><p>为了方便理解，这里先从底层电路结构的角度举一个例子。如下图为一个加法器，对应实际的数字电路结构。</p>
<p>A、B为输入，C为输出，且A、B、C均为总线，以32位CPU为例，则每根总线实际由32根导线组成，每根导线用不同的电压表示一个二进制的0或1。<br>Clock为时钟信号线，每个固定的时钟周期可向其输入一个特定的电压信号，每当一个时钟信号到来时，A和B的和就会输出到C。<br><img src="http://tech.meituan.com/img/hardware-accelerate/cascade-adder-1.png" alt=""></p>
<p>现在我们要计算8个整数的和。</p>
<p>对于CPU这种串行结构，代码编写很简单，用for循环把所有数字逐个相加即可。串行结构只有一个加法器，需要7次求和运算；每次计算完部分和，还要将其再转移到加法器的输入端，做下一次计算。整个过程至少要消耗十几个机器周期。</p>
<p>而对于并行结构，一种常见的设计是级联加法器，如下图，其中所有的clock连在一起。当需要相加的8个数据在输入端A1~B4准备好后，经过三个时钟周期，求和操作就完成了。如果数据量更大、级联的层级更大，则并行结构的优势更明显。</p>
<p>由于电路的限制，不容易通过提高时钟频率、减小时钟周期的方式提高运算速度。并行结构通过增加电路规模、并行处理，来实现更快的运算。但并行结构不容易实现复杂逻辑，因为同时考虑多个支路的输出结果，并协调同步处理的过程很复杂（有点像多线程编程）。<br><img src="http://tech.meituan.com/img/hardware-accelerate/cascade-adder-2.png" alt=""></p>
<p>GPU并行计算举例<br>假设我们有如下图像处理任务，给每个像素值加1。GPU并行计算的方式简单粗暴，在资源允许的情况下，可以为每个像素开一个GPU线程，由其进行加1操作。数学运算量越大，这种并行方式性能优势越明显。<br><img src="http://tech.meituan.com/img/hardware-accelerate/render-task.png" alt=""></p>
<h2 id="Android中的硬件加速"><a href="#Android中的硬件加速" class="headerlink" title="Android中的硬件加速"></a>Android中的硬件加速</h2><p>在Android中，大多数应用的界面都是利用常规的View来构建的（除了游戏、视频、图像等应用可能直接使用OpenGL ES）。下面根据Android 6.0原生系统的Java层代码，对View的软件和硬件加速渲染做一些分析和对比。</p>
<p>DisplayList<br>DisplayList是一个基本绘制元素，包含元素原始属性（位置、尺寸、角度、透明度等），对应Canvas的drawXxx()方法（如下图）。</p>
<p>信息传递流程：Canvas(Java API) —&gt; OpenGL(C/C++ Lib) —&gt; 驱动程序 —&gt; GPU。</p>
<p>在Android 4.1及以上版本，DisplayList支持属性，如果View的一些属性发生变化（比如Scale、Alpha、Translate），只需把属性更新给GPU，不需要生成新的DisplayList。</p>
<p>RenderNode<br>一个RenderNode包含若干个DisplayList，通常一个RenderNode对应一个View，包含View自身及其子View的所有DisplayList。<br><img src="http://tech.meituan.com/img/hardware-accelerate/canvas-draw.png" alt=""></p>
<h2 id="Android绘制流程（Android-6-0）"><a href="#Android绘制流程（Android-6-0）" class="headerlink" title="Android绘制流程（Android 6.0）"></a>Android绘制流程（Android 6.0）</h2><p>下面是安卓View完整的绘制流程图，主要通过阅读源码和调试得出，虚线箭头表示递归调用。</p>
<p>从ViewRootImpl.performTraversals到PhoneWindow.DecroView.drawChild是每次遍历View树的固定流程，首先根据标志位判断是否需要重新布局并执行布局；然后进行Canvas的创建等操作开始绘制。</p>
<p>如果硬件加速不支持或者被关闭，则使用软件绘制，生成的Canvas即Canvas.class的对象；<br>如果支持硬件加速，则生成的是DisplayListCanvas.class的对象；<br>两者的isHardwareAccelerated()方法返回的值分别为false、true，View根据这个值判断是否使用硬件加速。<br>View中的draw(canvas,parent,drawingTime) - draw(canvas) - onDraw - dispachDraw - drawChild这条递归路径（下文简称Draw路径），调用了Canvas.drawXxx()方法，在软件渲染时用于实际绘制；在硬件加速时，用于构建DisplayList。<br>View中的updateDisplayListIfDirty - dispatchGetDisplayList - recreateChildDisplayList这条递归路径（下文简称DisplayList路径），仅在硬件加速时会经过，用于在遍历View树绘制的过程中更新DisplayList属性，并快速跳过不需要重建DisplayList的View。</p>
<p>Android 6.0中，和DisplayList相关的API目前仍被标记为“@hide”不可访问，表示还不成熟，后续版本可能开放。<br>硬件加速情况下，draw流程执行结束后DisplayList构建完成，然后通过ThreadedRenderer.nSyncAndDrawFrame()利用GPU绘制DisplayList到屏幕上。<br><img src="http://tech.meituan.com/img/hardware-accelerate/render-func.png" alt=""></p>
<h2 id="纯软件绘制-VS-硬件加速（Android-6-0）"><a href="#纯软件绘制-VS-硬件加速（Android-6-0）" class="headerlink" title="纯软件绘制 VS 硬件加速（Android 6.0）"></a>纯软件绘制 VS 硬件加速（Android 6.0）</h2><p>下面根据具体的几种场景，具体分析一下硬件加速前后的流程与加速效果。</p>
<p>渲染场景    纯软件绘制    硬件加速    加速效果分析<br>页面初始化    绘制所有View    创建所有DisplayList    GPU分担了复杂计算任务<br>在一个复杂页面调用背景透明TextView的setText()，且调用后其尺寸位置不变    重绘脏区所有View    TextView及每一级父View重建DisplayList    重叠的兄弟节点不需CPU重绘，GPU会自行处理<br>TextView逐帧播放Alpha / Translation / Scale动画    每帧都要重绘脏区所有View    除第一帧同场景2，之后每帧只更新TextView对应RenderNode的属性    刷新一帧性能极大提高，动画流畅度提高<br>修改TextView透明度    重绘脏区所有View    直接调用RenderNode.setAlpha()更新    加速前需全页面遍历，并重绘很多View；加速后只触发DecorView.updateDisplayListIfDirty，不再往下遍历，CPU执行时间可忽略不计</p>
<p>场景1中，无论是否加速，遍历View树并都会走Draw路径。硬件加速后Draw路径不做实际绘制工作，只是构建DisplayList，复杂的绘制计算任务被GPU分担，已经有了较大的加速效果。<br>场景2中，TextView设置前后尺寸位置不变，不会触发重新Layout。</p>
<p>软件绘制时，TextView所在区域即为脏区。由于TextView有透明区域，遍历View树的过程中，和脏区重叠的多数View都要重绘，包括与之重叠的兄弟节点和他们的父节点（详见后面的介绍），不需要绘制的View在draw(canvas,parent,drawingTime)方法中判断直接返回。</p>
<p>硬件加速后，也需要遍历View树，但只有TextView及其每一层父节点需要重建DisplayList，走的是Draw路径，其他View直接走了DisplayList路径，剩下的工作都交给GPU处理。页面越复杂，两者性能差距越明显。</p>
<p>场景3中，软件绘制每一帧都要做大量绘制工作，很容易导致动画卡顿。硬件加速后，动画过程直接走DisplayList路径更新DisplayList的属性，动画流畅度能得到极大提高。</p>
<p>场景4中，两者的性能差距更明显。简单修改透明度，软件绘制仍然要做很多工作；硬件加速后一般直接更新RenderNode的属性，不需要触发invalidate，也不会遍历View树（除了少数View可能要对Alpha做特殊响应并在onSetAlpha()返回true，代码如下）。<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> class View &#123;</div><div class="line">    <span class="comment">// ...</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">void</span> setAlpha(@FloatRange(from=<span class="number">0.0</span>, to=<span class="number">1.0</span>) <span class="built_in">float</span> <span class="built_in">alpha</span>) &#123;</div><div class="line">        ensureTransformationInfo();</div><div class="line">        <span class="keyword">if</span> (mTransformationInfo.mAlpha != <span class="built_in">alpha</span>) &#123;</div><div class="line">            mTransformationInfo.mAlpha = <span class="built_in">alpha</span>;</div><div class="line">            <span class="keyword">if</span> (onSetAlpha((<span class="built_in">int</span>) (<span class="built_in">alpha</span> * <span class="number">255</span>))) &#123;</div><div class="line">                <span class="comment">// ...</span></div><div class="line">                invalidate(<span class="keyword">true</span>);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                <span class="comment">// ...</span></div><div class="line">                mRenderNode.setAlpha(getFinalAlpha());</div><div class="line">                <span class="comment">// ...</span></div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">protected</span> <span class="built_in">boolean</span> onSetAlpha(<span class="built_in">int</span> <span class="built_in">alpha</span>) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// ...</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="软件绘制刷新逻辑简介"><a href="#软件绘制刷新逻辑简介" class="headerlink" title="软件绘制刷新逻辑简介"></a>软件绘制刷新逻辑简介</h3><p>实际阅读源码并实验，得出通常情况下的软件绘制刷新逻辑：</p>
<p>默认情况下，View的clipChildren属性为true，即每个View绘制区域不能超出其父View的范围。如果设置一个页面根布局的clipChildren属性为false，则子View可以超出父View的绘制区域。<br>当一个View触发invalidate，且没有播放动画、没有触发layout的情况下：</p>
<p>对于全不透明的View，其自身会设置标志位PFLAG_DIRTY，其父View会设置标志位PFLAG_DIRTY_OPAQUE。在draw(canvas)方法中，只有这个View自身重绘。<br>对于可能有透明区域的View，其自身和父View都会设置标志位PFLAG_DIRTY。</p>
<p>clipChildren为true时，脏区会被转换成ViewRoot中的Rect，刷新时层层向下判断，当View与脏区有重叠则重绘。如果一个View超出父View范围且与脏区重叠，但其父View不与脏区重叠，这个子View不会重绘。<br>clipChildren为false时，ViewGroup.invalidateChildInParent()中会把脏区扩大到自身整个区域，于是与这个区域重叠的所有View都会重绘。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>至此，硬件加速相关的内容就介绍完了，这里做个简单总结：</p>
<p>CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。<br>页面由各种基础元素（DisplayList）构成，渲染时需要进行大量浮点运算。</p>
<p>硬件加速条件下，CPU用于控制复杂绘制逻辑、构建或更新DisplayList；GPU用于完成图形计算、渲染DisplayList。</p>
<p>硬件加速条件下，刷新界面尤其是播放动画时，CPU只重建或更新必要的DisplayList，进一步提高渲染效率。</p>
<p>实现同样效果，应尽量使用更简单的DisplayList，从而达到更好的性能（Shape代替Bitmap等）。</p>
<h2 id="参考资料与扩展阅读"><a href="#参考资料与扩展阅读" class="headerlink" title="参考资料与扩展阅读"></a>参考资料与扩展阅读</h2><p><a href="http://www.cnblogs.com/LBSer/p/4592862.html" target="_blank" rel="external">GPU—并行计算利器</a><br><a href="http://www.eechina.com/thread-176224-1-1.html" target="_blank" rel="external">显示卡的“心脏”GPU工作原理介绍</a><br><a href="http://hust.cf/matlab/2016/05/15/Matlab%E7%9A%84GPU%E5%8A%A0%E9%80%9F.html" target="_blank" rel="external">Matlab的GPU加速</a><br><a href="http://blog.csdn.net/yang_yulei/article/details/22529437" target="_blank" rel="external">处理器体系结构：了解CPU的基本运行原理</a><br><a href="http://blog.chinaunix.net/uid-23069658-id-3563960.html" target="_blank" rel="external">CPU的内部架构和工作原理</a><br><a href="http://xilinx.eetrend.com/article/10087" target="_blank" rel="external">什么是异构多处理系统，为什么需要异构多处理系统</a><br><a href="http://blog.csdn.net/luoshengyang/article/details/45943255" target="_blank" rel="external">Android应用程序UI硬件加速渲染的Display List构建过程分析</a><br><a href="http://blog.csdn.net/luoshengyang/article/details/46281499" target="_blank" rel="external">Android应用程序UI硬件加速渲染的Display List渲染过程分析</a><br><a href="http://www.jianshu.com/p/996bca12eb1d" target="_blank" rel="external">Android Choreographer源码分析</a><br><a href="http://blog.csdn.net/innost/article/details/8272867" target="_blank" rel="external">Android Project Butter分析</a></p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/hardware-accelerate.html&quot;&gt;子健&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在手机客户端尤其是Android应用的开发过程中，我们经常会接触到“硬件加速”这个词。由于操作系统对底层软硬件封装非常完善，上层软件开发者往往对硬件加速的底层原理了解很少，也不清楚了解底层原理的意义，因此常会有一些误解，如硬件加速是不是通过特殊算法实现页面渲染加速，或是通过硬件提高CPU/GPU运算速率实现渲染加速。&lt;/p&gt;
&lt;p&gt;本文尝试从底层硬件原理，一直到上层代码实现，对硬件加速技术进行简单介绍，其中上层实现基于Android 6.0。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
      <category term="CPU" scheme="http://ipcreator.me/tags/CPU/"/>
    
      <category term="GPU" scheme="http://ipcreator.me/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>聊聊clean code</title>
    <link href="http://ipcreator.me/2017/02/26/Program/Concepts/the-ways-of-keep-code-clean/"/>
    <id>http://ipcreator.me/2017/02/26/Program/Concepts/the-ways-of-keep-code-clean/</id>
    <published>2017-02-26T14:57:06.000Z</published>
    <updated>2017-02-26T23:49:00.094Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/clean-code.html" target="_blank" rel="external">王烨</a><br><img src="http://okkntqe2h.bkt.clouddn.com/clean-code.jpg" alt=""><br>clean code，顾名思义就是整洁的代码，或者说清晰、漂亮的代码，相信大多数工程师都希望自己能写出这样的代码。</p>
<p>也许这是个千人千面的话题，每个工程师都有自己的理解。比如我，从一个天天被骂代码写得烂的人，逐渐学习成长，到现在也能写的出“人模人样”的代码来了。这期间算是积累了一点经验心得，想和大家分享，抛砖引玉。</p>
<p>本文主要针对面向对象编程的clean code来阐述，面向过程代码的思路会比较不同，不在本文的讨论范畴。</p>
<a id="more"></a>
<h3 id="代码整洁的大前提"><a href="#代码整洁的大前提" class="headerlink" title="代码整洁的大前提"></a>代码整洁的大前提</h3><p>代码大部分时候是用来维护的，而不是用来实现功能的<br>这个原则适用于大部分的工程。我们的代码，一方面是编译好让机器执行，完成功能需求；另一方面，是写给身边的队友和自己看的，需要长期维护，而且大部分项目都不是朝生夕死的短命鬼。</p>
<p>大部分情况下，如果不能写出清晰好看的代码，可能自己一时爽快，后续维护付出的代价和成本将远高于你的想象。</p>
<h3 id="对清晰好看代码的追求精神，比所有的技巧都要重要。"><a href="#对清晰好看代码的追求精神，比所有的技巧都要重要。" class="headerlink" title="对清晰好看代码的追求精神，比所有的技巧都要重要。"></a>对清晰好看代码的追求精神，比所有的技巧都要重要。</h3><p>优秀的代码大部分是可以<strong>自描述</strong>的，好于文档和注释<br>当你翻看很多开源代码时，会发现注释甚至比我们自己写的项目都少，但是却能看的很舒服。当读完源码时，很多功能设计就都清晰明了了。通过仔细斟酌的方法命名、清晰的流程控制，代码本身就可以拿出来当作文档使用，而且它永远不会过期。</p>
<p>相反，注释不能让写的烂的代码变的更好。如果别人只能依靠注释读懂你的代码的时候，你一定要反思代码出现了什么问题（当然，这里不是说大家不要写注释了）。</p>
<p>说下比较适合写注释的两种场景：</p>
<p>public interface，向别人明确发布你功能的语义，输入输出，且不需要关注实现。<br>功能容易有歧义的点，或者涉及比较深层专业知识的时候。比如，如果你写一个客户端，各种config参数的含义等。</p>
<h3 id="设计模式只是手段，代码清晰才是目的"><a href="#设计模式只是手段，代码清晰才是目的" class="headerlink" title="设计模式只是手段，代码清晰才是目的"></a>设计模式只是手段，代码清晰才是目的</h3><p>之前见过一些所谓“高手”的代码都比较抽象，各种工厂、各种继承。想找到一个实现总是要山路十八弯，一个工程里大部分的类是抽象类或者接口，找不到一两句实现的代码，整个读起代码来很不顺畅。我跟他聊起来的时候，他的主要立场是：保留合适的扩展点，克服掉所有的硬编码。</p>
<p>其实在我看来，也许他的代码被“过度设计”了。首先必须要承认的是，在同一个公司工作的同事，水平是参差不齐的。无论你用了如何高大上的设计，如果大多数人都不能理解你的代码或者读起来很费劲的话，其实这是一个失败的设计。</p>
<p>当你的系统内大部分抽象只有一个实现的时候，要好好思考一下，是不是设计有点过度了，清晰永远是第一准则。</p>
<h3 id="代码整洁的常见手段"><a href="#代码整洁的常见手段" class="headerlink" title="代码整洁的常见手段"></a>代码整洁的常见手段</h3><p>记住原则后，我们开始进入实践环节，先来看下有哪些促成clean code的常见手段。</p>
<h3 id="code-review"><a href="#code-review" class="headerlink" title="code review"></a>code review</h3><p>很多大公司会用git的pull request机制来做code review。我们重点应该review什么？是代码的格式、业务逻辑还是代码风格？我想说的是，凡是能通过机器检查出来的事情，无需通过人。比如换行、注释、方法长度、代码重复等。除了基本功能需求的逻辑合理没有bug外，我们更应该关注代码的设计与风格。比如，一段功能是不是应该属于一个类、是不是有很多相似的功能可以抽取出来复用、代码太过冗长难懂等等。</p>
<p>我个人非常推崇集体code review，因为很多时候，组里相对高级的工程师能够一眼发现代码存在较大设计缺陷，提出改进意见或者重构方式。我们可以在整个小组内形成一个好的文化传承和风格统一，并且很大程度上培养了大家对clean code的热情。</p>
<h3 id="勤于重构"><a href="#勤于重构" class="headerlink" title="勤于重构"></a>勤于重构</h3><p>好的代码，一般都不是一撮而就的。即使一开始设计的代码非常优秀，随着业务的快速迭代，也可能被改的面目全非。</p>
<p>为了避免重构带来的负面影响（delay需求或者带来bug），我们需要做好以下的功课：<br>① 掌握一些常见的“无痛”重构技巧，这在下文会有具体讲解。<br>② 小步快跑，不要企图一口吃成个胖子。改一点，测试一点，一方面减少代码merge的痛苦，另一方面减少上线的风险。<br>③ 建立自动化测试机制，要做到即使代码改坏了，也能保证系统最小核心功能的可用，并且保证自己修改的部分被测试覆盖到。<br>④ 熟练掌握IDE的自动重构功能。这些会很大程度上减少我们的体力劳动，避免犯错。</p>
<h3 id="静态检查"><a href="#静态检查" class="headerlink" title="静态检查"></a>静态检查</h3><p>现在市面上有很多代码静态检查的工具，也是发现bug和风格不好的比较容易的方式。可以与发布系统做集成，强制把主要问题修复掉才可以上线。目前美团点评技术团队内部的研发流程中已经普遍接入了Sonar质量管理平台。</p>
<h3 id="多读开源代码和身边优秀同学的代码"><a href="#多读开源代码和身边优秀同学的代码" class="headerlink" title="多读开源代码和身边优秀同学的代码"></a>多读开源代码和身边优秀同学的代码</h3><p>感谢开源社区，为我们提供了这么好的学习机会。无论是JDK的源码，还是经典的Netty、Spring、Jetty，还是一些小工具如Guava等，都是clean code的典范。多多学习，多多反思和总结，必有收益。</p>
<h3 id="代码整洁的常见技巧"><a href="#代码整洁的常见技巧" class="headerlink" title="代码整洁的常见技巧"></a>代码整洁的常见技巧</h3><p>前面的内容都属于热身，让大家有个整体宏观的认识。下面终于进入干货环节了，我会分几个角度讲解编写整洁代码的常见技巧和误区。</p>
<h3 id="通用技巧"><a href="#通用技巧" class="headerlink" title="通用技巧"></a>通用技巧</h3><h3 id="单一职责"><a href="#单一职责" class="headerlink" title="单一职责"></a>单一职责</h3><p>这是整洁代码的最重要也是最基本的原则了。简单来讲，大到一个module、一个package，小到一个class、一个method乃至一个属性，都应该承载一个明确的职责。要定义的东西，如果不能用一句话描述清楚职责，就把它拆掉。</p>
<p>我们平时写代码时，最容易犯的错误是：一个方法干了好几件事或者一个类承载了许多功能。</p>
<p>先来聊聊方法的问题。个人非常主张把方法拆细，这是复用的基础。如果方法干了两件事情，很有可能其中一个功能的其他业务有差别就不好重用了。另外语义也是不明确的。经常看到一个get()方法里面竟然修改了数据，这让使用你方法的人情何以堪？如果不点进去看看实现，可能就让程序陷入bug，让测试陷入麻烦。</p>
<p>再来聊聊类的问题。我们经常会看到“又臭又长”的service/biz层的代码，里面有几十个方法，干什么的都有：既有增删改查，又有业务逻辑的聚合。每次找到一个方法都费劲。不属于一个领域或者一个层次的功能，就不要放到一起。</p>
<p>我们team在code review中，最常被批评的问题，就是一个方法应该归属于哪个类。</p>
<h3 id="优先定义整体框架"><a href="#优先定义整体框架" class="headerlink" title="优先定义整体框架"></a>优先定义整体框架</h3><p>我写代码的时候，比较喜欢先去定义整体的框架，就是写很多空实现，来把整体的业务流程穿起来。良好的方法签名，用入参和出参来控制流程。这样能够避免陷入业务细节无法自拔。在脑海中先定义清楚流程的几个阶段，并为每个阶段找到合适的方法／类归属。</p>
<p>这样做的好处是，阅读你代码的人，无论读到什么深度，都可以清晰地了解每一层的职能，如果不care下一层的实现，完全可以跳过不看，并且方法的粒度也会恰到好处。</p>
<p>简而言之，我比较推崇写代码的时候“广度优先”而不是“深度优先”，这和我读代码的方式是一致的。当然，这件事情跟个人的思维习惯有一定的关系，可能对抽象思维能力要求会更高一些。如果开始写代码的时候这些不够清晰，起码要通过不断地重构，使代码达到这样的成色。</p>
<h3 id="清晰的命名"><a href="#清晰的命名" class="headerlink" title="清晰的命名"></a>清晰的命名</h3><p>老生常谈的话题，这里不展开讲了，但是必须要mark一下。有的时候，我思考一个方法命名的时间，比写一段代码的时间还长。原因还是那个逻辑：每当你写出一个类似于”temp”、”a”、”b”这样变量的时候，后面每一个维护代码的人，都需要用几倍的精力才能理顺。</p>
<p>并且这也是代码自描述最重要的基础。</p>
<h3 id="避免过长参数"><a href="#避免过长参数" class="headerlink" title="避免过长参数"></a>避免过长参数</h3><p>如果一个方法的参数长度超过4个，就需要警惕了。一方面，没有人能够记得清楚这些函数的语义；另一方面，代码的可读性会很差；最后，如果参数非常多，意味着一定有很多参数，在很多场景下，是没有用的，我们只能构造默认值的方式来传递。</p>
<p>解决这个问题的方法很简单，一般情况下我们会构造paramObject。用一个struct或者一个class来承载数据，一般这种对象是value object，不可变对象。这样，能极大程度提高代码的可复用性和可读性。在必要的时候，提供合适的build方法，来简化上层代码的开发成本。</p>
<h3 id="避免过长方法和类"><a href="#避免过长方法和类" class="headerlink" title="避免过长方法和类"></a>避免过长方法和类</h3><p>一个类或者方法过长的时候，读者总是很崩溃的。简单地把方法、类和职责拆细，往往会有立竿见影的成效。以类为例，拆分的维度有很多，常见的是横向／纵向。例如，如果一个service，处理的是跟一个库表对象相关的所有逻辑，横向拆分就是根据业务，把建立／更新／修改／通知等逻辑拆到不同的类里去；而纵向拆分，指的是<br>把数据库操作/MQ操作/Cache操作/对象校验等，拆到不同的对象里去，让主流程尽量简单可控，让同一个类，表达尽量同一个维度的东西。</p>
<h3 id="让相同长度的代码段表示相同粒度的逻辑"><a href="#让相同长度的代码段表示相同粒度的逻辑" class="headerlink" title="让相同长度的代码段表示相同粒度的逻辑"></a>让相同长度的代码段表示相同粒度的逻辑</h3><p>这里想表达的是，尽量多地去抽取private方法，让代码具有自描述的能力。举个简单的例子<br><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doSomeThing</span>(<span class="params">Map params1,Map params2</span>)</span>&#123;</div><div class="line">Do1 do1 = getDo1(params1);</div><div class="line">Do2 do2 = <span class="keyword">new</span> Do2();</div><div class="line">do2.setA(params2.<span class="keyword">get</span>(<span class="string">"a"</span>));</div><div class="line">do2.setB(params2.<span class="keyword">get</span>(<span class="string">"b"</span>));</div><div class="line">do2.setC(params2.<span class="keyword">get</span>(<span class="string">"c"</span>));</div><div class="line">mergeDO(do1,do2);</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getDo1</span>(<span class="params">Map params1</span>)</span>;</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">mergeDo</span>(<span class="params">do1,do2</span>)</span>&#123;...&#125;;</div></pre></td></tr></table></figure></p>
<p>类似这种代码，在业务代码中随处可见。获取do1是一个方法，merge是一个方法，但获取do2的代码却在主流程里写了。这种代码，流程越长，读起来越累。很多人读代码的逻辑，是“广度优先”的。先读懂主流程，再去看细节。类似这种代码，如果能够把构造do2的代码，提取一个private 方法，就会舒服很多。</p>
<h2 id="面向对象设计技巧"><a href="#面向对象设计技巧" class="headerlink" title="面向对象设计技巧"></a>面向对象设计技巧</h2><h3 id="贫血与领域驱动"><a href="#贫血与领域驱动" class="headerlink" title="贫血与领域驱动"></a>贫血与领域驱动</h3><p>不得不承认，Spring已经成为企业级Java开发的事实标准。而大部分公司采用的三层/四层贫血模型，已经让我们的编码习惯，变成了面向DAO而不是面向对象。</p>
<p>缺少了必要的模型抽象和设计环节，使得代码冗长，复用程度比较差。每次撸代码的时候，从mapper撸起，好像已经成为不成文的规范。</p>
<p>好处是上手简单，学习成本低。但是每次都不能重用，然后面对两三千行的类看着眼花的时候，我的心是很痛的。关于领域驱动的设计模式，本文不会展开去讲。回归面向对象，还是跟大家share一些比较好的code技巧，能够在一个通用的框架下，尽量好的写出漂亮可重用的code。</p>
<p>个人认为，一个好的系统，一定离不开一套好的模型定义。梳理清楚系统中的核心模型，清楚的定义每个方法的类归属，无论对于代码的可读性、可交流性，还是和产品的沟通，都是有莫大好处的。</p>
<h3 id="为每个方法找到合适的类归属，数据和行为尽量要在一起"><a href="#为每个方法找到合适的类归属，数据和行为尽量要在一起" class="headerlink" title="为每个方法找到合适的类归属，数据和行为尽量要在一起"></a>为每个方法找到合适的类归属，数据和行为尽量要在一起</h3><p>如果一个类的所有方法，都是在操作另一个类的对象。这时候就要仔细想一想类的设计是否合理了。理论上讲，面向对象的设计，主张数据和行为在一起。这样，对象之间的结构才是清晰的，也能减少很多不必要的参数传递。</p>
<p>不过这里面有一个要讨论的方法：service对象。如果操作一个对象数据的所有方法都建立在对象内部，可能使对象承载了很多并不属于它本身职能的方法。</p>
<p>例如，我定义一个类，叫做person，。这个类有很多行为，比如：吃饭、睡觉、上厕所、生孩子；也有很多字段，比如：姓名、年龄、性格。</p>
<p>很明显，字段从更大程度上来讲，是定义和描述我这个人的，但很多行为和我的字段并不相关。上厕所的时候是不会关心我是几岁的。如果把所有关于人的行为全部在person内部承载，这个类一定会膨胀的不行。</p>
<p>这时候就体现了service方法的价值，如果一个行为，无法明确属于哪个领域对象，牵强地融入领域对象里，会显得很不自然。这时候，无状态的service可以发挥出它的作用。但一定要把握好这个度，回归本质，我们要把属于每个模型的行为合理的去划定归属。</p>
<h3 id="警惕static"><a href="#警惕static" class="headerlink" title="警惕static"></a>警惕static</h3><p>static方法，本质上来讲是面向过程的，无法清晰地反馈对象之间的关系。虽然有一些代码实例（自己实现单例或者Spring托管等）的无状态方法可以用static来表示，但这种抽象是浅层次的。说白了，如果我们所有调用static的地方，都写上import static，那么所有的功能就由类自己在承载了。</p>
<p>让我画一个类图？尴尬了……画不出来。</p>
<p>而单例的膨胀，很大程度上也是贫血模型带来的副作用。如果对象本身有血有肉，就不需要这么多无状态方法。</p>
<h3 id="static真正适用的场景：工具方法，而不是业务方法。"><a href="#static真正适用的场景：工具方法，而不是业务方法。" class="headerlink" title="static真正适用的场景：工具方法，而不是业务方法。"></a>static真正适用的场景：工具方法，而不是业务方法。</h3><h3 id="巧用method-object"><a href="#巧用method-object" class="headerlink" title="巧用method object"></a>巧用method object</h3><p>method object是大型重构的常用技巧。当一段逻辑特别复杂的代码，充斥着各种参数传递和是非因果判断的时候，我首先想到的重构手段是提取method object。所谓method object，是一个有数据有行为的对象。依赖的数据会成为这个对象的变量，所有的行为会成为这个对象的内部方法。利用成员变量代替参数传递，会让代码简洁清爽很多。并且，把一段过程式的代码转换成对象代码，为很多面向对象编程才可以使用的继承／封装／多态等提供了基础。</p>
<p>举个例子，上文引用的代码如果用method object表示大概会变成这样<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> DoMerger&#123;</div><div class="line">   <span class="built_in">map</span> params1;</div><div class="line">   <span class="built_in">map</span> params2;</div><div class="line">   Do1 do1;</div><div class="line">   Do2 do2;</div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="title">DoMerger</span><span class="params">(Map params1,Map params2)</span></span>&#123;</div><div class="line">      <span class="keyword">this</span>.params1 = params1;</div><div class="line">      <span class="keyword">this</span>.params2 = parmas2;</div><div class="line">   &#125;</div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">()</span></span>&#123;</div><div class="line">       do1 = getDo1();</div><div class="line">       do2 = getDo2();</div><div class="line">      mergeDO(do1,do2);</div><div class="line">   &#125;</div><div class="line">   <span class="function"><span class="keyword">private</span> Do1 <span class="title">getDo1</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">private</span> Do2 <span class="title">getDo2</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">mergeDo</span><span class="params">()</span></span>&#123;</div><div class="line">       print(do1+do2);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="面向接口编程"><a href="#面向接口编程" class="headerlink" title="面向接口编程"></a>面向接口编程</h3><p>面向接口编程是很多年来大家形成的共识和最佳实践。最早的理论是便于实现的替换，但现在更显而易见的好处是避免public方法的膨胀。一个对外publish的接口，一定有明确的职责。要判断每一个public方法是否应该属于同一个interface，是很容易的。</p>
<p>整个代码基于接口去组织，会很自然地变得非常清晰易读。关注实现的人才去看实现，不是嘛？</p>
<h3 id="正确使用继承和组合"><a href="#正确使用继承和组合" class="headerlink" title="正确使用继承和组合"></a>正确使用继承和组合</h3><p>这也是个在业界被讨论过很久的问题，也有很多论调。最新的观点是组合的使用一般情况下比继承更为灵活，尤其是单继承的体系里，所以倾向于使用组合，否则会让子类承载很多不属于自己的职能。</p>
<p>个人对此观点持保留意见，在我经历过的代码中，有一个小规律，我分析一下。</p>
<p>protected abstract 这种是最值得使用继承的，父类保留扩展点，子类扩展，没什么好说的。</p>
<p>protected final 这种方法，子类是只能使用不能修改实现的。一般有两种情况：<br>① 抽象出主流程不能被修改的，然而一般情况下，public final更适合这个职能。如果只是流程的一部分，需要思考这个流程的类归属，大部分变成public组合到其他类里是更合适的。<br>② 父类是抽象类无法直接对外提供服务，又不希望子类修改它的行为，这种大多数情况下属于工具方法，比较适合用另一个领域对象来承载并用组合的方式来使用。</p>
<p>protected 这种是有争议的，是父类有默认实现但子类可以扩展的。凡是有扩展可能的，使用继承更理想一些。否则，定义成final并考虑成组合。</p>
<p>综上所述，个人认为继承更多的是为扩展提供便利，为复用而存在的方法最好使用组合的方式。当然，更为大的原则是明确每个方法的领域划分。</p>
<h2 id="代码复用技巧"><a href="#代码复用技巧" class="headerlink" title="代码复用技巧"></a>代码复用技巧</h2><h3 id="模板方法"><a href="#模板方法" class="headerlink" title="模板方法"></a>模板方法</h3><p>这是我用得最多的设计模式了。每当有两个行为类似但又不完全相同的代码段时，我总是会想到模板方法。提取公共流程和可复用的方法到父类，保留不同的地方作为abstract方法，由不同的子类去实现。</p>
<p>并在合适的时机，pull method up（复用）或者 pull method down（特殊逻辑）。</p>
<p>最后，把不属于流程的、但可复用的方法，判断是不是属于基类的领域职责，再使用继承或者组合的方法，为这些方法找到合适的安家之处。</p>
<h3 id="extract-method"><a href="#extract-method" class="headerlink" title="extract method"></a>extract method</h3><p>很多复用的级别没有这么大，也许只是几行相同的逻辑被copy了好几次，何不尝试提取方法（private）。又能明确方法行为，又能做到代码复用，何乐不为？</p>
<h3 id="责任链"><a href="#责任链" class="headerlink" title="责任链"></a>责任链</h3><p>经常看到这样的代码，一连串类似的行为，只是数据或者行为不一样。如一堆校验器，如果成功怎么样、失败怎么样；或者一堆对象构建器，各去构造一部分数据。碰到这种场景，我总是喜欢定义一个通用接口，入参是完整的要校验／构造的参数，<br>出参是成功/失败的标示或者是void。然后有很多实现器分别实现这个接口，再用一个集合把这堆行为串起来。最后，遍历这个集合，串行或者并行的执行每一部分的逻辑。</p>
<p>这样做的好处是：<br>① 很多通用的代码可以在责任链原子对象的基类里实现；<br>② 代码清晰，开闭原则，每当有新的行为产生的时候，只需要定义行的实现类并添加到集合里即可；<br>③ 为并行提供了基础。</p>
<h3 id="为集合显式定义它的行为"><a href="#为集合显式定义它的行为" class="headerlink" title="为集合显式定义它的行为"></a>为集合显式定义它的行为</h3><p>集合是个有意思的东西，本质上它是个容器，但由于泛型的存在，它变成了可以承载所有对象的容器。很多非集合的类，我们可以定义清楚他们的边界和行为划分，但是装进集合里，它们却都变成了一个样子。不停地有代码，各种循环集合，做一些相似的操作。</p>
<p>其实很多时候，可以把对集合的操作显示地封装起来，让它变得更有血有肉。</p>
<p>例如一个Map，它可能表示一个配制、一个缓存等等。如果所有的操作都是直接操作Map，那么它的行为就没有任何语义。第一，读起来就必须要深入细节；第二，如果想从获取配置读取缓存的地方加个通用的逻辑，例如打个log什么的，你可以想象是多么的崩溃。</p>
<p>个人提倡的做法是，对于有明确语义的集合的一些操作，尤其是全局的集合或者被经常使用的集合，做一些封装和抽象，如把Map封装成一个Cache类或者一个config类，再提供GetFromCache这样的方法。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文从clean code的几个大前提出发，然后提出了实践clean code的一些手段，重点放在促成clean code的一些常用编码和重构技巧。<br>当然，这些只代表笔者本人的一点点感悟。好的代码，最最需要的，还是大家不断追求卓越的精神。欢迎大家一起探索交流这个领域，为clean code提供更多好的思路与方法。</p>
<h3 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h3><p>王烨，现在是美团点评旅游后台研发组的工程师，之前曾经在百度、去哪儿和优酷工作过，专注Java后台开发。对于网络编程和并发编程具有浓厚的兴趣，曾经做过一些基础组件，也翻过一些源码，属于比较典型的宅男技术控。期待能够与更多知己，在coding的路上并肩前行~<br>联系邮箱：wangye03@meituan.com</p>
<p><a href="http://tech.meituan.com/performance_tunning.html" target="_blank" rel="external">常见性能优化策略的总结 晓明</a></p>
<p>本文要感谢我职级评定过程中的一位评委，他建议把之前所做的各种性能优化的案例和方案加以提炼、总结，以文档的形式沉淀下来，并在内部进行分享。力求达到如下效果：</p>
<ol>
<li><p>形成可实践、可借鉴、可参考的各种性能优化的方案以及选型考虑点，同时配合具体的真实案例，其他人遇到相似问题时，不用从零开始。</p>
</li>
<li><p>有助于开阔视野，除了性能优化之外，也能提供通用的常见思路以及方案选型的考虑点，帮助大家培养在方案选型时的意识、思维以及做各种权衡的能力。</p>
</li>
</ol>
<p>文章在内部分享后，引起强烈分享，得到了不少同事和朋友的认可和好评，觉得对日常的工作有很好的指导作用。考虑到这些经验可能对业界同行也有帮助，所以在美团点评技术团队博客公开。</p>
<h2 id="常见性能优化策略分类"><a href="#常见性能优化策略分类" class="headerlink" title="常见性能优化策略分类"></a>常见性能优化策略分类</h2><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>之所以把代码放到第一位，是因为这一点最容易引起技术人员的忽视。很多技术人员拿到一个性能优化的需求以后，言必称缓存、异步、JVM等。实际上，第一步就应该是分析相关的代码，找出相应的瓶颈，再来考虑具体的优化策略。有一些性能问题，完全是由于代码写的不合理，通过直接修改一下代码就能解决问题的，比如for循环次数过多、作了很多无谓的条件判断、相同逻辑重复多次等。</p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>数据库的调优，总的来说分为以下三部分：</p>
<h3 id="SQL调优"><a href="#SQL调优" class="headerlink" title="SQL调优"></a>SQL调优</h3><p>这是最常用、每一个技术人员都应该掌握基本的SQL调优手段（包括方法、工具、辅助系统等）。这里以MySQL为例，最常见的方式是，由自带的慢查询日志或者开源的慢查询系统定位到具体的出问题的SQL，然后使用explain、profile等工具来逐步调优，最后经过测试达到效果后上线。这方面的细节，可以参考<strong>MySQL索引原理及慢查询优化</strong>。</p>
<h3 id="架构层面的调优"><a href="#架构层面的调优" class="headerlink" title="架构层面的调优"></a>架构层面的调优</h3><p>这一类调优包括读写分离、多从库负载均衡、水平和垂直分库分表等方面，一般需要的改动较大，但是频率没有SQL调优高，而且一般需要DBA来配合参与。那么什么时候需要做这些事情？我们可以通过内部监控报警系统（比如Zabbix），定期跟踪一些指标数据是否达到瓶颈，一旦达到瓶颈或者警戒值，就需要考虑这些事情。通常，DBA也会定期监控这些指标值。</p>
<h3 id="连接池调优"><a href="#连接池调优" class="headerlink" title="连接池调优"></a>连接池调优</h3><p>我们的应用为了实现数据库连接的高效获取、对数据库连接的限流等目的，通常会采用连接池类的方案，即每一个应用节点都管理了一个到各个数据库的连接池。随着业务访问量或者数据量的增长，原有的连接池参数可能不能很好地满足需求，这个时候就需要结合当前使用连接池的原理、具体的连接池监控数据和当前的业务量作一个综合的判断，通过反复的几次调试得到最终的调优参数。</p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>本地缓存（HashMap/ConcurrentHashMap、Ehcache、Guava Cache等），缓存服务（Redis/Tair/Memcache等）。</p>
<h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>什么情况适合用缓存？考虑以下两种场景：</p>
<p>短时间内相同数据重复查询多次且数据更新不频繁，这个时候可以选择先从缓存查询，查询不到再从数据库加载并回设到缓存的方式。此种场景较适合用单机缓存。<br>高并发查询热点数据，后端数据库不堪重负，可以用缓存来扛。</p>
<h3 id="选型考虑"><a href="#选型考虑" class="headerlink" title="选型考虑"></a>选型考虑</h3><p>如果数据量小，并且不会频繁地增长又清空（这会导致频繁地垃圾回收），那么可以选择本地缓存。具体的话，如果需要一些策略的支持（比如缓存满的逐出策略），可以考虑Ehcache；如不需要，可以考虑HashMap；如需要考虑多线程并发的场景，可以考虑ConcurentHashMap。<br>其他情况，可以考虑缓存服务。目前从资源的投入度、可运维性、是否能动态扩容以及配套设施来考虑，我们优先考虑Tair。除非目前Tair还不能支持的场合（比如分布式锁、Hash类型的value），我们考虑用Redis。</p>
<h3 id="设计关键点"><a href="#设计关键点" class="headerlink" title="设计关键点"></a>设计关键点</h3><p>什么时候更新缓存？如何保障更新的可靠性和实时性？<br>更新缓存的策略，需要具体问题具体分析。这里以门店POI的缓存数据为例，来说明一下缓存服务型的缓存更新策略是怎样的？目前约10万个POI数据采用了Tair作为缓存服务，具体更新的策略有两个：</p>
<p>接收门店变更的消息，准实时更新。<br>给每一个POI缓存数据设置5分钟的过期时间，过期后从DB加载再回设到DB。这个策略是对第一个策略的有力补充，解决了手动变更DB不发消息、接消息更新程序临时出错等问题导致的第一个策略失效的问题。通过这种双保险机制，有效地保证了POI缓存数据的可靠性和实时性。<br>缓存是否会满，缓存满了怎么办？<br>对于一个缓存服务，理论上来说，随着缓存数据的日益增多，在容量有限的情况下，缓存肯定有一天会满的。如何应对？<br>① 给缓存服务，选择合适的缓存逐出算法，比如最常见的LRU。<br>② 针对当前设置的容量，设置适当的警戒值，比如10G的缓存，当缓存数据达到8G的时候，就开始发出报警，提前排查问题或者扩容。<br>③ 给一些没有必要长期保存的key，尽量设置过期时间。</p>
<h3 id="缓存是否允许丢失？丢失了怎么办？"><a href="#缓存是否允许丢失？丢失了怎么办？" class="headerlink" title="缓存是否允许丢失？丢失了怎么办？"></a>缓存是否允许丢失？丢失了怎么办？</h3><p>根据业务场景判断，是否允许丢失。如果不允许，就需要带持久化功能的缓存服务来支持，比如Redis或者Tair。更细节的话，可以根据业务对丢失时间的容忍度，还可以选择更具体的持久化策略，比如Redis的RDB或者AOF。</p>
<h3 id="缓存被“击穿”问题"><a href="#缓存被“击穿”问题" class="headerlink" title="缓存被“击穿”问题"></a>缓存被“击穿”问题</h3><p>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑另外一个问题：缓存被“击穿”的问题。</p>
<p>概念：缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。<br>如何解决：业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。类似下面的代码：<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">String</span> <span class="built_in">get</span>(<span class="built_in">key</span>) &#123;</div><div class="line">    <span class="keyword">String</span> value = redis.<span class="built_in">get</span>(<span class="built_in">key</span>);</div><div class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123; <span class="comment">//代表缓存值过期</span></div><div class="line">        <span class="comment">//设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db</span></div><div class="line">        <span class="keyword">if</span> (redis.setnx(key_mutex, <span class="number">1</span>, <span class="number">3</span> * <span class="number">60</span>) == <span class="number">1</span>) &#123;  <span class="comment">//代表设置成功</span></div><div class="line">             value = db.<span class="built_in">get</span>(<span class="built_in">key</span>);</div><div class="line">                    redis.<span class="built_in">set</span>(<span class="built_in">key</span>, value, expire_secs);</div><div class="line">                    redis.del(key_mutex);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;  <span class="comment">//这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可</span></div><div class="line">                    sleep(<span class="number">50</span>);</div><div class="line">                    <span class="built_in">get</span>(<span class="built_in">key</span>);  <span class="comment">//重试</span></div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">return</span> value;      </div><div class="line">        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h2><h3 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h3><p>针对某些客户端的请求，在服务端可能需要针对这些请求做一些附属的事情，这些事情其实用户并不关心或者用户不需要立即拿到这些事情的处理结果，这种情况就比较适合用异步的方式处理这些事情。</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>缩短接口响应时间，使用户的请求快速返回，用户体验更好。<br>避免线程长时间处于运行状态，这样会引起服务线程池的可用线程长时间不够用，进而引起线程池任务队列长度增大，从而阻塞更多请求任务，使得更多请求得不到技术处理。<br>线程长时间处于运行状态，可能还会引起系统Load、CPU使用率、机器整体性能下降等一系列问题，甚至引发雪崩。异步的思路可以在不增加机器数和CPU数的情况下，有效解决这个问题。<br>常见做法<br>一种做法，是额外开辟线程，这里可以采用额外开辟一个线程或者使用线程池的做法，在IO线程（处理请求响应）之外的线程来处理相应的任务，在IO线程中让response先返回。</p>
<p>如果异步线程处理的任务设计的数据量非常巨大，那么可以引入阻塞队列BlockingQueue作进一步的优化。具体做法是让一批异步线程不断地往阻塞队列里扔数据，然后额外起一个处理线程，循环批量从队列里拿预设大小的一批数据，来进行批处理（比如发一个批量的远程服务请求），这样进一步提高了性能。</p>
<p>另一种做法，是使用消息队列（MQ）中间件服务，MQ天生就是异步的。一些额外的任务，可能不需要我这个系统来处理，但是需要其他系统来处理。这个时候可以先把它封装成一个消息，扔到消息队列里面，通过消息中间件的可靠性保证把消息投递到关心它的系统，然后让这个系统来做相应的处理。</p>
<p>比如C端在完成一个提单动作以后，可能需要其它端做一系列的事情，但是这些事情的结果不会立刻对C端用户产生影响，那么就可以先把C端下单的请求响应先返回给用户，返回之前往MQ中发一个消息即可。而且这些事情理应不是C端的负责范围，所以这个时候用MQ的方式，来解决这个问题最合适。</p>
<h2 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h2><h3 id="和缓存的区别"><a href="#和缓存的区别" class="headerlink" title="和缓存的区别"></a>和缓存的区别</h3><p>先说明一下，这里介绍的和缓存那一节不一样，虽然可能会使用一样的数据存储方案（比如Redis或者Tair），但是使用的方式不一样，这一节介绍的是把它作为DB来用。如果当作DB来用，需要有效保证数据存储方案的可用性、可靠性。</p>
<h3 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h3><p>需要结合具体的业务场景，看这块业务涉及的数据是否适合用NoSQL来存储，对数据的操作方式是否适合用NoSQL的方式来操作，或者是否需要用到NoSQL的一些额外特性（比如原子加减等）。</p>
<p>如果业务数据不需要和其他数据作关联，不需要事务或者外键之类的支持，而且有可能写入会异常频繁，这个时候就比较适合用NoSQL（比如HBase）。</p>
<p>比如，美团点评内部有一个对exception做的监控系统，如果在应用系统发生严重故障的时候，可能会短时间产生大量exception数据，这个时候如果选用MySQL，会造成MySQL的瞬间写压力飙升，容易导致MySQL服务器的性能急剧恶化以及主从同步延迟之类的问题，这种场景就比较适合用Hbase类似的NoSQL来存储。</p>
<h2 id="JVM调优"><a href="#JVM调优" class="headerlink" title="JVM调优"></a>JVM调优</h2><h3 id="什么时候调？"><a href="#什么时候调？" class="headerlink" title="什么时候调？"></a>什么时候调？</h3><p>通过监控系统（如没有现成的系统，自己做一个简单的上报监控的系统也很容易）上对一些机器关键指标（gc time、gc count、各个分代的内存大小变化、机器的Load值与CPU使用率、JVM的线程数等）的监控报警，也可以看gc log和jstat等命令的输出，再结合线上JVM进程服务的一些关键接口的性能数据和请求体验，基本上就能定位出当前的JVM是否有问题，以及是否需要调优。</p>
<h3 id="怎么调？"><a href="#怎么调？" class="headerlink" title="怎么调？"></a>怎么调？</h3><p>如果发现高峰期CPU使用率与Load值偏大，这个时候可以观察一些JVM的thread count以及gc count（可能主要是young gc count），如果这两个值都比以往偏大（也可以和一个历史经验值作对比），基本上可以定位是young gc频率过高导致，这个时候可以通过适当增大young区大小或者占比的方式来解决。<br>如果发现关键接口响应时间很慢，可以结合gc time以及gc log中的stop the world的时间，看一下整个应用的stop the world的时间是不是比较多。如果是，可能需要减少总的gc time，具体可以从减小gc的次数和减小单次gc的时间这两个维度来考虑，一般来说，这两个因素是一对互斥因素，我们需要根据实际的监控数据来调整相应的参数（比如新生代与老生代比值、eden与survivor比值、MTT值、触发cms回收的old区比率阈值等）来达到一个最优值。<br>如果发生full gc或者old cms gc非常频繁，通常这种情况会诱发STW的时间相应加长，从而也会导致接口响应时间变慢。这种情况，大概率是出现了“内存泄露”，Java里的内存泄露指的是一些应该释放的对象没有被释放掉（还有引用拉着它）。那么这些对象是如何产生的呢？为啥不会释放呢？对应的代码是不是出问题了？问题的关键是搞明白这个，找到相应的代码，然后对症下药。所以问题的关键是转化成寻找这些对象。怎么找？综合使用jmap和MAT，基本就能定位到具体的代码。</p>
<h2 id="多线程与分布式"><a href="#多线程与分布式" class="headerlink" title="多线程与分布式"></a>多线程与分布式</h2><h3 id="使用场景-3"><a href="#使用场景-3" class="headerlink" title="使用场景"></a>使用场景</h3><p>离线任务、异步任务、大数据任务、耗时较长任务的运行**，适当地利用，可达到加速的效果。</p>
<p>注意：线上对响应时间要求较高的场合，尽量少用多线程，尤其是服务线程需要等待任务线程的场合（很多重大事故就是和这个息息相关），如果一定要用，可以对服务线程设置一个最大等待时间。</p>
<h3 id="常见做法"><a href="#常见做法" class="headerlink" title="常见做法"></a>常见做法</h3><p>如果单机的处理能力可以满足实际业务的需求，那么尽可能地使用单机多线程的处理方式，减少复杂性；反之，则需要使用多机多线程的方式。</p>
<p>对于单机多线程，可以引入线程池的机制，作用有二：</p>
<h3 id="提高性能，节省线程创建和销毁的开销"><a href="#提高性能，节省线程创建和销毁的开销" class="headerlink" title="提高性能，节省线程创建和销毁的开销"></a>提高性能，节省线程创建和销毁的开销</h3><p>限流，给线程池一个固定的容量，达到这个容量值后再有任务进来，就进入队列进行排队，保障机器极限压力下的稳定处理能力在使用JDK自带的线程池时，一定要仔细理解构造方法的各个参数的含义，如core pool size、max pool size、keepAliveTime、worker queue等，在理解的基础上通过不断地测试调整这些参数值达到最优效果。<br>如果单机的处理能力不能满足需求，这个时候需要使用多机多线程的方式。这个时候就需要一些分布式系统的知识了。首先就必须引入一个单独的节点，作为调度器，其他的机器节点都作为执行器节点。调度器来负责拆分任务，和分发任务到合适的执行器节点；执行器节点按照多线程的方式（也可能是单线程）来执行任务。这个时候，我们整个任务系统就由单击演变成一个集群的系统，而且不同的机器节点有不同的角色，各司其职，各个节点之间还有交互。这个时候除了有多线程、线程池等机制，像RPC、心跳等网络通信调用的机制也不可少。后续我会出一个简单的分布式调度运行的框架。</p>
<h3 id="度量系统（监控、报警、服务依赖管理）"><a href="#度量系统（监控、报警、服务依赖管理）" class="headerlink" title="度量系统（监控、报警、服务依赖管理）"></a>度量系统（监控、报警、服务依赖管理）</h3><p>严格来说，度量系统不属于性能优化的范畴，但是这方面和性能优化息息相关，可以说为性能优化提供一个强有力的数据参考和支撑。没有度量系统，基本上就没有办法定位到系统的问题，也没有办法有效衡量优化后的效果。很多人不重视这方面，但我认为它是系统稳定性和性能保障的基石。</p>
<h3 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h3><p>如果要设计这套系统，总体来说有哪些关键流程需要设计呢？<br>① 确定指标<br>② 采集数据<br>③ 计算数据，存储结果<br>④ 展现和分析</p>
<p>需要监控和报警哪些指标数据？需要关注哪些？<br>按照需求出发，主要需要二方面的指标：</p>
<p>接口性能相关，包括单个接口和全部的QPS、响应时间、调用量（统计时间维度越细越好；最好是，既能以节点为维度，也可以以服务集群为维度，来查看相关数据）。其中还涉及到服务依赖关系的管理，这个时候需要用到服务依赖管理系统<br>单个机器节点相关，包括CPU使用率、Load值、内存占用率、网卡流量等。如果节点是一些特殊类型的服务（比如MySQL、Redis、Tair），还可以监控这些服务特有的一些关键指标。<br>数据采集方式<br>通常采用异步上报的方式，具体做法有两种：第一种，发到本地的Flume端口，由Flume进程收集到远程的Hadoop集群或者Storm集群来进行运算；第二种，直接在本地运算好以后，使用异步和本地队列的方式，发送到监控服务器。</p>
<h3 id="数据计算"><a href="#数据计算" class="headerlink" title="数据计算"></a>数据计算</h3><p>可以采用离线运算（MapReduce/Hive）或者实时/准实时运算（Storm/Spark）的方式，运算后的结果存入MySQL或者HBase；某些情况，也可以不计算，直接采集发往监控服务器。</p>
<p>展现和分析<br>提供统一的展现分析平台，需要带报表（列表/图表）监控和报警的功能。</p>
<h2 id="真实案例分析"><a href="#真实案例分析" class="headerlink" title="真实案例分析"></a>真实案例分析</h2><h3 id="案例一：商家与控制区关系的刷新job"><a href="#案例一：商家与控制区关系的刷新job" class="headerlink" title="案例一：商家与控制区关系的刷新job"></a>案例一：商家与控制区关系的刷新job</h3><p>背景<br>这是一个每小时定期运行一次的job，作用是用来刷新商家与控制区的关系。具体规则就是根据商家的配送范围（多个）与控制区是否有交集，如果有交集，就把这个商家划到这个控制区的范围内。</p>
<p>业务需求<br>需要这个过程越短越好，最好保持在20分钟内。</p>
<p>优化过程<br>原有代码的主要处理流程是：</p>
<p>拿到所有门店的配送范围列表和控制区列表。<br>遍历控制区列表，针对每一个控制区：<br>a. 遍历商家的配送范围列表，找到和这个控制区相交的配送范围列表。<br>b. 遍历上述商家配送范围列表，对里面的商家ID去重，保存到一个集合里。<br>c. 批量根据上述商家ID集合，取到对应的商家集合。<br>d. 遍历上述商家集合，从中拿到每一个商家对象，进行相应的处理（根据是否已是热门商家、自营、在线支付等条件来判断是否需要插入或者更新之前的商家和控制区的关系）。<br>e. 删除这个控制区当前已有的，但是不应该存在的商家关系列表。<br>分析代码，发现第2步的a步骤和b步骤，找出和某控制区相交的配送范围集合并对商家ID去重，可以采用R树空间索引的方式来优化。具体做法是：</p>
<p>任务开始先更新R树，然后利用R树的结构和匹配算法来拿到和控制区相交的配送范围ID列表。<br>再批量根据配送范围ID列表，拿到配送范围列表。<br>然后针对这一批配送范围列表（数量很小），用原始多边形相交匹配的方法做进一步过滤，并且对过滤后的商家ID去重。<br>这个优化已经在第一期优化中上线，整个过程耗时由40多分钟缩短到20分钟以内。</p>
<p>第一期优化改为R树以后，运行了一段时间，随着数据量增大，性能又开始逐渐恶化，一个月后已经恶化到50多分钟。于是继续深入代码分析，寻找了两个优化点，安排第二期优化并上线。</p>
<p>这两个优化点是：</p>
<p>第2步的c步骤，原来是根据门店ID列表从DB批量获取门店，现在可以改成mget的方式从缓存批量获取（此时商家数据已被缓存）；<br>第2步的d步骤，根据是否已是热门商家、自营、在线支付等条件来判断是否需要插入或者更新之前的商家和控制区的关系。<br>上线后效果<br>通过日志观察，执行时间由50多分钟缩短到15分钟以内，下图是截取了一天的4台机器的日志时间（单位：毫秒）：<br>poi优化效果图<br>可以看到，效果还是非常明显的。<br><img src="http://tech.meituan.com/img/poi%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C%E5%9B%BE.png" alt=""></p>
<h3 id="案例二：POI缓存设计与实现"><a href="#案例二：POI缓存设计与实现" class="headerlink" title="案例二：POI缓存设计与实现"></a>案例二：POI缓存设计与实现</h3><p>背景<br>2014年Q4，数据库中关于POI（这里可以简单理解为外卖的门店）相关的数据的读流量急剧上升，虽然说加入从库节点可以解决一部分问题，但是毕竟节点的增加是会达到极限的，达到极限后主从复制会达到瓶颈，可能会造成数据不一致。所以此时，急需引入一种新的技术方案来分担数据库的压力，降低数据库POI相关数据的读流量。另外，任何场景都考虑加DB从库的做法，会对资源造成一定的浪费。</p>
<p>实现方案<br>基于已有的经过考验的技术方案，我选择Tair来作为缓存的存储方案，来帮DB分担来自于各应用端的POI数据的读流量的压力。理由主要是从可用性、高性能、可扩展性、是否经过线上大规模数据和高并发流量的考验、是否有专业运维团队、是否有成熟工具等几个方面综合考量决定。</p>
<p>详细设计<br>第一版设计<br>缓存的更新策略，根据业务的特点、已有的技术方案和实现成本，选择了用MQ来接收POI改变的消息来触发缓存的更新，但是这个过程有可能失败；同时启用了key的过期策略，并且调用端会先判断是否过期，如过期，会从后端DB加载数据并回设到缓存，再返回。通过两个方面双保险确保了缓存数据的可用。</p>
<p>第二版设计<br>第一版设计运行到一段时间以后，我们发现了两个问题：</p>
<p>某些情况下不能保证数据的实时一致（比如技术人员手动改动DB数据、利用MQ更新缓存失败），这个时候只能等待5分钟的过期时间，有的业务是不允许的。<br>加入了过期时间导致另外一个问题：Tair在缓存不命中的那一刻，会尝试从硬盘中Load数据，如果硬盘没有再去DB中Load数据。这无疑会进一步延长Tair的响应时间，这样不仅使得业务的超时比率加大，而且会导致Tair的性能进一步变差。<br>为了解决上述问题，我们从美团点评负责基础架构的同事那里了解到Databus可以解决缓存数据在某些情况下不一致的问题，并且可以去掉过期时间机制，从而提高查询效率，避免tair在内存不命中时查询硬盘。而且为了防止DataBus单点出现故障影响我们的业务，我们保留了之前接MQ消息更新缓存的方案，作了切换开关，利用这个方案作容错，整体架构如下：<br><img src="http://tech.meituan.com/img/poi%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E5%9B%BE.png" alt=""></p>
<p>上线后效果<br>上线后，通过持续地监控数据发现，随着调用量的上升，到DB的流量有了明显地减少，极大地减轻了DB的压力。同时这些数据接口的响应时间也有了明显地减少。缓存更新的双重保障机制，也基本保证了缓存数据的可用。见下图：<br><img src="http://tech.meituan.com/img/poi%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C%E5%9B%BE_1.png" alt=""><br>poi缓存优化效果图</p>
<h3 id="案例三：业务运营后台相关页面的性能优化"><a href="#案例三：业务运营后台相关页面的性能优化" class="headerlink" title="案例三：业务运营后台相关页面的性能优化"></a>案例三：业务运营后台相关页面的性能优化</h3><p>背景<br>随着业务的快速发展，带来的访问量和数据量的急剧上升，通过我们相应的监控系统可以发现，系统的某些页面的性能开始出现恶化。 从用户方的反馈，也证明了这点。此时此刻，有必要迅速排期，敏捷开发，对这些页面进行调优。</p>
<p>欢迎页<br>需求背景：欢迎页是地推人员乃至总部各种角色人员进入外卖运营后台的首页，会显示地推人员最想看到最关心的一些核心数据，其重要性不言而喻，所以该页面的性能恶化会严重影响到用户体验。因此，首先需要优化的就是欢迎页。通过相应定位和分析，发现导致性能恶化的主要原因有两个：数据接口层和计算展现层。<br>解决方案：对症下药，分而治之。经过仔细排查、分析定位，数据接口层采用接口调用批量化、异步RPC调用的方式来进行有效优化，计算展现层决定采用预先计算、再把计算好的结果缓存的方式来提高查询速度。其中，缓存方案根据业务场景和技术特点，选用Redis。定好方案后，快速开发上线。<br>上线效果：上线后性能对比图，如下：<br><img src="http://tech.meituan.com/img/%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C%E5%9B%BE_1.png" alt=""><br>组织架构页<br>需求背景：组织架构页，采用了四层树形结构图，一起呈现加载，第一版上线后发现性能非常差。用户迫切希望对这个页面的性能进行调优。<br>解决方案：经过分析代码，定位到一个比较经典的问题：里面执行了太多次小数据量的SQL查询。于是采用多个SQL合并成大SQL的方式，然后使用本地缓存来缓存这些数据，合理预估数据量和性能，充分测试后上线。<br>上线效果：上线后性能对比图，如下：<br><img src="http://tech.meituan.com/img/%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C%E5%9B%BE_2.png" alt=""><br>订单关联楼宇页<br>需求背景：随着订单量日益增大，订单表积累的数据日益增多，订单关联楼宇页的性能也日益变差（响应时间线性上升）。而这个页面和地推人员的业绩息息相关，所以地推人员使用该页面的频率非常高，性能日益恶化极大地影响了地推人员的用户体验。<br>解决方案：经过分析与设计，决定采用当时已有的订单二级索引月分表来代替原始的订单表来供前端的查询请求；并且限制住筛选的时间条件，使得筛选的开始时间和结束时间不能跨月（事先和用户沟通过，可以接受，能满足用户的基本需求），这样就只需一个月分索引表即可，通过适当的功能限制来达到性能的调优。这样从二级索引月分表中根据各种查询条件查到最终的分页的订单ID集合，然后再根据订单ID从订单库来查出相应的订单数据集合。<br>上线效果：上线后发现在调用量几乎没怎么变的情况下，性能提升明显，如下图：<br><img src="http://tech.meituan.com/img/%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C%E5%9B%BE_3.png" alt=""><br>其他<br>除了上面介绍的之外，优化还涉及前端、分布式文件系统、CDN、全文索引、空间索引等几方面。限于篇幅，我们留到未来再做介绍。</p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/clean-code.html&quot;&gt;王烨&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/clean-code.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;clean code，顾名思义就是整洁的代码，或者说清晰、漂亮的代码，相信大多数工程师都希望自己能写出这样的代码。&lt;/p&gt;
&lt;p&gt;也许这是个千人千面的话题，每个工程师都有自己的理解。比如我，从一个天天被骂代码写得烂的人，逐渐学习成长，到现在也能写的出“人模人样”的代码来了。这期间算是积累了一点经验心得，想和大家分享，抛砖引玉。&lt;/p&gt;
&lt;p&gt;本文主要针对面向对象编程的clean code来阐述，面向过程代码的思路会比较不同，不在本文的讨论范畴。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
  </entry>
  
  <entry>
    <title>实例详解机器学习如何解决问题</title>
    <link href="http://ipcreator.me/2017/02/26/BusinessAI/example-of-machine-learning-in-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/BusinessAI/example-of-machine-learning-in-meituan/</id>
    <published>2017-02-26T14:34:06.000Z</published>
    <updated>2017-02-27T05:43:01.735Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/mt-mlinaction-how-to-ml.html" target="_blank" rel="external">huawolf</a></p>
<p><img src="http://tech.meituan.com/img/how_to_ml/extract_fea.png" alt=""></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>随着大数据时代的到来，机器学习成为解决问题的一种重要且关键的工具。不管是工业界还是学术界，机器学习都是一个炙手可热的方向，但是学术界和工业界对机器学习的研究各有侧重，学术界侧重于对机器学习理论的研究，工业界侧重于如何用机器学习来解决实际问题。我们结合美团在机器学习上的实践，进行一个实战（InAction）系列的介绍（带“机器学习InAction系列”标签的文章），介绍机器学习在解决工业界问题的实战中所需的基本技术、经验和技巧。本文主要结合实际问题，概要地介绍机器学习解决实际问题的整个流程，包括对问题建模、准备训练数据、抽取特征、训练模型和优化模型等关键环节；另外几篇则会对这些关键环节进行更深入地介绍。</p>
<p>下文分为1）机器学习的概述，2）对问题建模，3）准备训练数据，4）抽取特征，5）训练模型，6）优化模型，7）总结 共7个章节进行介绍。</p>
<a id="more"></a>
<p>机器学习的概述：</p>
<h2 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h2><p>随着机器学习在实际工业领域中不断获得应用，这个词已经被赋予了各种不同含义。在本文中的“机器学习”含义与wikipedia上的解释比较契合，如下：<br>Machine learning is a scientific discipline that deals with the construction and study of algorithms that can learn from data.</p>
<p>机器学习可以分为无监督学习（unsupervised learning）和有监督学习（supervised learning），在工业界中，有监督学习是更常见和更有价值的方式，下文中主要以这种方式展开介绍。如下图中所示，有监督的机器学习在解决实际问题时，有两个流程，一个是离线训练流程（蓝色箭头），包含数据筛选和清洗、特征抽取、模型训练和优化模型等环节；另一个流程则是应用流程（绿色箭头），对需要预估的数据，抽取特征，应用离线训练得到的模型进行预估，获得预估值作用在实际产品中。在这两个流程中，离线训练是最有技术挑战的工作（在线预估流程很多工作可以复用离线训练流程的工作），所以下文主要介绍离线训练流程。</p>
<p><img src="http://tech.meituan.com/img/how_to_ml/model.png" alt=""><br>model</p>
<h2 id="什么是模型（model）？"><a href="#什么是模型（model）？" class="headerlink" title="什么是模型（model）？"></a>什么是模型（model）？</h2><p>模型，是机器学习中的一个重要概念，简单的讲，指特征空间到输出空间的映射；一般由模型的假设函数和参数w组成（下面公式就是Logistic Regression模型的一种表达，在训练模型的章节做稍详细的解释）；一个模型的假设空间（hypothesis space），指给定模型所有可能w对应的输出空间组成的集合。工业界常用的模型有Logistic Regression（简称LR）、Gradient Boosting Decision Tree（简称GBDT）、Support Vector Machine（简称SVM）、Deep Neural Network（简称DNN）等。<br><img src="http://latex.codecogs.com/png.latex?h_{w}\left%20(%20x%20\right%20" alt="">=P\left%20(%20y=1|x;w%20\right%20)%20=\frac{1}{1+e^{-wx}})</p>
<p>模型训练就是基于训练数据，获得一组参数w，使得特定目标最优，即获得了特征空间到输出空间的最优映射，具体怎么实现，见训练模型章节。</p>
<h2 id="为什么要用机器学习解决问题？"><a href="#为什么要用机器学习解决问题？" class="headerlink" title="为什么要用机器学习解决问题？"></a>为什么要用机器学习解决问题？</h2><p>目前处于大数据时代，到处都有成T成P的数据，简单规则处理难以发挥这些数据的价值；<br>廉价的高性能计算，使得基于大规模数据的学习时间和代价降低；<br>廉价的大规模存储，使得能够更快地和代价更小地处理大规模数据；<br>存在大量高价值的问题，使得花大量精力用机器学习解决问题后，能获得丰厚收益。</p>
<h2 id="机器学习应该用于解决什么问题？"><a href="#机器学习应该用于解决什么问题？" class="headerlink" title="机器学习应该用于解决什么问题？"></a>机器学习应该用于解决什么问题？</h2><p>目标问题需要价值巨大，因为机器学习解决问题有一定的代价；<br>目标问题有大量数据可用，有大量数据才能使机器学习比较好地解决问题（相对于简单规则或人工）；<br>目标问题由多种因素（特征）决定，机器学习解决问题的优势才能体现（相对于简单规则或人工）；<br>目标问题需要持续优化，因为机器学习可以基于数据自我学习和迭代，持续地发挥价值。</p>
<h2 id="对问题建模"><a href="#对问题建模" class="headerlink" title="对问题建模"></a>对问题建模</h2><p>本文以DEAL（团购单）交易额预估问题为例（就是预估一个给定DEAL一段时间内卖了多少钱），介绍使用机器学习如何解决问题。首先需要：</p>
<p>收集问题的资料，理解问题，成为这个问题的专家；<br>拆解问题，简化问题，将问题转化机器可预估的问题。<br>深入理解和分析DEAL交易额后，可以将它分解为如下图的几个问题：<br><img src="http://tech.meituan.com/img/how_to_ml/deal_problem.png" alt=""><br>deal_problem</p>
<h2 id="单个模型？多个模型？如何来选择？"><a href="#单个模型？多个模型？如何来选择？" class="headerlink" title="单个模型？多个模型？如何来选择？"></a>单个模型？多个模型？如何来选择？</h2><p>按照上图进行拆解后，预估DEAL交易额就有2种可能模式，一种是直接预估交易额；另一种是预估各子问题，如建立一个用户数模型和建立一个访购率模型（访问这个DEAL的用户会购买的单子数），再基于这些子问题的预估值计算交易额。</p>
<p>不同方式有不同优缺点，具体如下：<br>模式    缺点    优点<br>单模型    1. 预估难度大</p>
<ol>
<li>风险比较高    1. 理论上可以获得最优预估（实际上很难）</li>
<li>一次解决问题<br>多模型    1. 可能产生积累误差</li>
<li>训练和应用成本高    1. 单个子模型更容易实现比较准地预估</li>
<li>可以调整子模型的融合方式，以达到最佳效果<br>选择哪种模式？<br>1）问题可预估的难度，难度大，则考虑用多模型；<br>2）问题本身的重要性，问题很重要，则考虑用多模型；<br>3）多个模型的关系是否明确，关系明确，则可以用多模型。<br>如果采用多模型，如何融合？<br>可以根据问题的特点和要求进行线性融合，或进行复杂的融合。以本文问题为例，至少可以有如下两种：<br><img src="http://tech.meituan.com/img/how_to_ml/model_merg.png" alt=""><br>model_merg</li>
</ol>
<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p>对于DEAL交易额这个问题，我们认为直接预估难度很大，希望拆成子问题进行预估，即多模型模式。那样就需要建立用户数模型和访购率模型，因为机器学习解决问题的方式类似，下文只以访购率模型为例。要解决访购率问题，首先要选择模型，我们有如下的一些考虑：</p>
<p>主要考虑<br>1）选择与业务目标一致的模型；<br>2）选择与训练数据和特征相符的模型。</p>
<p>训练数据少，High Level特征多，则使用“复杂”的非线性模型（流行的GBDT、Random Forest等）；<br>训练数据很大量，Low Level特征多，则使用“简单”的线性模型（流行的LR、Linear-SVM等）。<br>补充考虑<br>1）当前模型是否被工业界广泛使用；<br>2）当前模型是否有比较成熟的开源工具包（公司内或公司外）；<br>3）当前工具包能够的处理数据量能否满足要求；<br>4）自己对当前模型理论是否了解，是否之前用过该模型解决问题。<br>为实际问题选择模型，需要转化问题的业务目标为模型评价目标，转化模型评价目标为模型优化目标；根据业务的不同目标，选择合适的模型，具体关系如下：<br><img src="http://tech.meituan.com/img/how_to_ml/select_model.png" alt=""><br>select_model</p>
<p>通常来讲，预估真实数值（回归）、大小顺序（排序）、目标所在的正确区间（分类）的难度从大到小，根据应用所需，尽可能选择难度小的目标进行。对于访购率预估的应用目标来说，我们至少需要知道大小顺序或真实数值，所以我们可以选择Area Under Curve（AUC）或Mean Absolute Error（MAE）作为评估目标，以Maximum likelihood为模型损失函数（即优化目标）。综上所述，我们选择spark版本 GBDT或LR，主要基于如下考虑：<br>1）可以解决排序或回归问题；<br>2）我们自己实现了算法，经常使用，效果很好；<br>3）支持海量数据；<br>4）工业界广泛使用。</p>
<h2 id="准备训练数据"><a href="#准备训练数据" class="headerlink" title="准备训练数据"></a>准备训练数据</h2><p>深入理解问题，针对问题选择了相应的模型后，接下来则需要准备数据；数据是机器学习解决问题的根本，数据选择不对，则问题不可能被解决，所以准备训练数据需要格外的小心和注意：</p>
<h3 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h3><p>待解决问题的数据本身的分布尽量一致；<br>训练集/测试集分布与线上预测环境的数据分布尽可能一致，这里的分布是指（x,y）的分布，不仅仅是y的分布；<br>y数据噪音尽可能小，尽量剔除y有噪音的数据；<br>非必要不做采样，采样常常可能使实际数据分布发生变化，但是如果数据太大无法训练或者正负比例严重失调（如超过100:1）,则需要采样解决。</p>
<h3 id="常见问题及解决办法"><a href="#常见问题及解决办法" class="headerlink" title="常见问题及解决办法"></a>常见问题及解决办法</h3><p>待解决问题的数据分布不一致：<br>1）访购率问题中DEAL数据可能差异很大，如美食DEAL和酒店DEAL的影响因素或表现很不一致，需要做特别处理；要么对数据提前归一化，要么将分布不一致因素作为特征，要么对各类别DEAL单独训练模型。<br>数据分布变化了：<br>1）用半年前的数据训练模型，用来预测当前数据，因为数据分布随着时间可能变化了，效果可能很差。尽量用近期的数据训练，来预测当前数据，历史的数据可以做降权用到模型，或做transfer learning。<br>y数据有噪音：<br>1）在建立CTR模型时，将用户没有看到的Item作为负例，这些Item是因为用户没有看到才没有被点击，不一定是用户不喜欢而没有被点击，所以这些Item是有噪音的。可以采用一些简单规则，剔除这些噪音负例，如采用skip-above思想，即用户点过的Item之上，没有点过的Item作为负例（假设用户是从上往下浏览Item）。<br>采样方法有偏，没有覆盖整个集合：<br>1）访购率问题中，如果只取只有一个门店的DEAL进行预估，则对于多门店的DEAL无法很好预估。应该保证一个门店的和多个门店的DEAL数据都有；<br>2）无客观数据的二分类问题，用规则来获得正/负例，规则对正/负例的覆盖不全面。应该随机抽样数据，进行人工标注，以确保抽样数据和实际数据分布一致。</p>
<h3 id="访购率问题的训练数据"><a href="#访购率问题的训练数据" class="headerlink" title="访购率问题的训练数据"></a>访购率问题的训练数据</h3><p>收集N个月的DEAL数据（x）及相应访购率（y）；<br>收集最近N个月，剔除节假日等非常规时间 （保持分布一致）；<br>只收集在线时长&gt;T 且 访问用户数 &gt; U的DEAL （减少y的噪音）；<br>考虑DEAL销量生命周期 （保持分布一致）；<br>考虑不同城市、不同商圈、不同品类的差别 （保持分布一致）。</p>
<h2 id="抽取特征"><a href="#抽取特征" class="headerlink" title="抽取特征"></a>抽取特征</h2><p>完成数据筛选和清洗后，就需要对数据抽取特征，就是完成输入空间到特征空间的转换（见下图）。针对线性模型或非线性模型需要进行不同特征抽取，线性模型需要更多特征抽取工作和技巧，而非线性模型对特征抽取要求相对较低。<br><img src="http://tech.meituan.com/img/how_to_ml/extract_fea.png" alt=""><br>extract_fea</p>
<p>通常，特征可以分为High Level与Low Level，High Level指含义比较泛的特征，Low Level指含义比较特定的特征，举例来说：</p>
<pre><code>DEAL A1属于POIA，人均50以下，访购率高；
DEAL A2属于POIA，人均50以上，访购率高；
DEAL B1属于POIB，人均50以下，访购率高；
DEAL B2属于POIB，人均50以上，访购率底；
</code></pre><p>基于上面的数据，可以抽到两种特征，POI（门店）或人均消费；POI特征则是Low Level特征，人均消费则是High Level特征；假设模型通过学习，获得如下预估：</p>
<p>如果DEALx 属于POIA（Low Level feature），访购率高；<br>如果DEALx 人均50以下（High Level feature），访购率高。<br>所以，总体上，Low Level 比较有针对性，单个特征覆盖面小（含有这个特征的数据不多），特征数量（维度）很大。High Level比较泛化，单个特征覆盖面大（含有这个特征的数据很多），特征数量（维度）不大。长尾样本的预测值主要受High Level特征影响。高频样本的预测值主要受Low Level特征影响。</p>
<p>对于访购率问题，有大量的High Level或Low Level的特征，其中一些展示在下图：<br><img src="http://tech.meituan.com/img/how_to_ml/fea_list.png" alt=""><br>fea_list</p>
<p>非线性模型的特征<br>1）可以主要使用High Level特征，因为计算复杂度大，所以特征维度不宜太高；<br>2）通过High Level非线性映射可以比较好地拟合目标。<br>线性模型的特征<br>1）特征体系要尽可能全面，High Level和Low Level都要有；<br>2）可以将High Level转换Low Level，以提升模型的拟合能力。</p>
<h3 id="特征归一化"><a href="#特征归一化" class="headerlink" title="特征归一化"></a>特征归一化</h3><p>特征抽取后，如果不同特征的取值范围相差很大，最好对特征进行归一化，以取得更好的效果，常见的归一化方式如下：</p>
<p>Rescaling<br>归一化到[0,1] 或 [-1，1]，用类似方式</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>特征抽取和归一化之后，如果发现特征太多，导致模型无法训练，或很容易导致模型过拟合，则需要对特征进行选择，挑选有价值的特征。</p>
<p>Filter：<br>假设特征子集对模型预估的影响互相独立，选择一个特征子集，分析该子集和数据Label的关系，如果存在某种正相关，则认为该特征子集有效。衡量特征子集和数据Label关系的算法有很多，如Chi-square，Information Gain。<br>Wrapper：<br>选择一个特征子集加入原有特征集合，用模型进行训练，比较子集加入前后的效果，如果效果变好，则认为该特征子集有效，否则认为无效。<br>Embedded：<br>将特征选择和模型训练结合起来，如在损失函数中加入L1 Norm ，L2 Norm。</p>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>完成特征抽取和处理后，就可以开始模型训练了，下文以简单且常用的Logistic Regression模型（下称LR模型）为例，进行简单介绍。<br>设有m个（x,y）训练数据，其中x为特征向量，y为label，；w为模型中参数向量，即模型训练中需要学习的对象。<br>所谓训练模型，就是选定假说函数和损失函数，基于已有训练数据（x,y），不断调整w，使得损失函数最优，相应的w就是最终学习结果，也就得到相应的模型。</p>
<p>###模型函数<br>1）假说函数，即假设x和y存在一种函数关系：</p>
<p>2）损失函数，基于上述假设函数，构建模型损失函数（优化目标），在LR中通常以（x,y）的最大似然估计为目标：</p>
<h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><p>梯度下降（Gradient Descent）<br>即w沿着损失函数的负梯度方向进行调整，示意图见下图，的梯度即一阶导数（见下式），梯度下降有多种类型，如随机梯度下降或批量梯度下降。</p>
<p>随机梯度下降（Stochastic Gradient Descent），每一步随机选择一个样本，计算相应的梯度，并完成w的更新，如下式，</p>
<p>批量梯度下降（Batch Gradient Descent）,每一步都计算训练数据中的所有样本对应的梯度，w沿着这个梯度方向迭代，即</p>
<p>gradient_descent<br><img src="http://tech.meituan.com/img/how_to_ml/gradient_descent.png" alt=""><br>牛顿法（Newton’s Method）<br>牛顿法的基本思想是在极小点附近通过对目标函数做二阶Taylor展开，进而找到L(w)的极小点的估计值。形象地讲，在wk处做切线，该切线与L(w)=0的交点即为下一个迭代点wk+1（示意图如下）。w的更新公式如下，其中目标函数的二阶偏导数，即为大名鼎鼎的Hessian矩阵。</p>
<p>拟牛顿法（Quasi-Newton Methods）：计算目标函数的二阶偏导数，难度较大，更为复杂的是目标函数的Hessian矩阵无法保持正定；不用二阶偏导数而构造出可以近似Hessian矩阵的逆的正定对称阵，从而在”拟牛顿”的条件下优化目标函数。<br>BFGS： 使用BFGS公式对H(w)进行近似，内存中需要放H(w),内存需要O(m2)级别；<br>L-BFGS：存储有限次数（如k次）的更新矩阵，用这些更新矩阵生成新的H(w),内存降至O(m)级别；<br>OWLQN: 如果在目标函数中引入L1正则化，需要引入虚梯度来解决目标函数不可导问题，OWLQN就是用来解决这个问题。<br><img src="http://tech.meituan.com/img/how_to_ml/newton.png" alt=""><br>newton<br>Coordinate Descent<br>对于w，每次迭代，固定其他维度不变，只对其一个维度进行搜索，确定最优下降方向（示意图如下），公式表达如下：<br><img src="http://tech.meituan.com/img/how_to_ml/coordinate_descent.jpg" alt=""><br>coordinate_descent</p>
<h2 id="优化模型"><a href="#优化模型" class="headerlink" title="优化模型"></a>优化模型</h2><p>经过上文提到的数据筛选和清洗、特征设计和选择、模型训练，就得到了一个模型，但是如果发现效果不好？怎么办？<br>【首先】<br>反思目标是否可预估，数据和特征是否存在bug。<br>【然后】<br>分析一下模型是Overfitting还是Underfitting，从数据、特征和模型等环节做针对性优化。</p>
<h3 id="Underfitting-amp-Overfitting"><a href="#Underfitting-amp-Overfitting" class="headerlink" title="Underfitting &amp; Overfitting"></a>Underfitting &amp; Overfitting</h3><p>所谓Underfitting，即模型没有学到数据内在关系，如下图左一所示，产生分类面不能很好的区分X和O两类数据；产生的深层原因，就是模型假设空间太小或者模型假设空间偏离。<br>所谓Overfitting，即模型过渡拟合了训练数据的内在关系，如下图右一所示，产生分类面过好地区分X和O两类数据，而真实分类面可能并不是这样，以至于在非训练数据上表现不好；产生的深层原因，是巨大的模型假设空间与稀疏的数据之间的矛盾。<br><img src="http://tech.meituan.com/img/how_to_ml/underfitting_overfitting.png" alt=""><br>underfitting_overfitting</p>
<p>在实战中，可以基于模型在训练集和测试集上的表现来确定当前模型到底是Underfitting还是Overfitting，判断方式如下表：</p>
<p>训练集表现    测试集表现    问题<br>&lt; 期望目标值    &lt; 期望目标值    Underfitting</p>
<blockquote>
<p>期望目标值    接近或略逊于训练集    合适<br>期望目标值    远差于训练集    Overfitting</p>
<h3 id="怎么解决Underfitting和Overfitting问题？"><a href="#怎么解决Underfitting和Overfitting问题？" class="headerlink" title="怎么解决Underfitting和Overfitting问题？"></a>怎么解决Underfitting和Overfitting问题？</h3></blockquote>
<p>问题    数据    特征    模型<br>Underfitting    清洗数据    1. 增加特征</p>
<ol>
<li>删除噪音特征    1. 调低正则项的惩罚参数</li>
<li>换更“复杂”的模型（如把线性模型换为非线性模型）</li>
<li>多个模型级联或组合<br>Overfitting    增加数据    1. 进行特征选择</li>
<li>降维（如对特征进行聚类、主题模型进行处理等）</li>
<li>提高正则项的惩罚参数</li>
<li>减少训练迭代次数</li>
<li>换更“简单”的模型（如把非线性模型换为线性模型）<br>4.<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>综上所述，机器学习解决问题涉及到问题建模、准备训练数据、抽取特征、训练模型和优化模型等关键环节，有如下要点：</li>
</ol>
<p>理解业务，分解业务目标，规划模型可预估的路线图。<br>数据：<br>y数据尽可能真实客观；<br>训练集/测试集分布与线上应用环境的数据分布尽可能一致。<br>特征：<br>利用Domain Knowledge进行特征抽取和选择；<br>针对不同类型的模型设计不同的特征。<br>模型：<br>针对不同业务目标、不同数据和特征，选择不同的模型；<br>如果模型不符合预期，一定检查一下数据、特征、模型等处理环节是否有bug；<br>考虑模型Underfitting和Qverfitting，针对性地优化。</p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">![](http://latex.codecogs.com/png.latex?x^&#123;<span class="meta">%27</span>&#125;=\frac&#123;x-min(x)&#125;&#123;max(x)-min(x)&#125;)</div><div class="line"></div><div class="line">![](http://latex.codecogs.com/png.latex?h<span class="number">_</span>&#123;w&#125;\left<span class="meta">%20</span>(<span class="meta">%20x</span><span class="meta">%20</span>\right<span class="meta">%20</span>)=P\left<span class="meta">%20</span>(<span class="meta">%20y</span>=<span class="number">1</span>|x;w<span class="meta">%20</span>\right<span class="meta">%20</span>)<span class="meta">%20</span>=\frac&#123;<span class="number">1</span>&#125;&#123;<span class="number">1</span>+e^&#123;-wx&#125;&#125;)</div><div class="line">![](http://latex.codecogs.com/png.latex?L\left<span class="meta">%20</span>(<span class="meta">%20w</span><span class="meta">%20</span><span class="meta">%20</span>\right<span class="meta">%20</span>)=\sum<span class="number">_</span>&#123;i=<span class="number">1</span>&#125;^&#123;m&#125;y^&#123;(i)&#125;logh<span class="number">_</span>&#123;w&#125;(x^&#123;(i)&#125;)+(<span class="number">1</span>-y^&#123;(i)&#125;)log(<span class="number">1</span>-h<span class="number">_</span>&#123;w&#125;(x^&#123;(i)&#125;)))</div><div class="line">![](http://latex.codecogs.com/png.latex?L^&#123;<span class="meta">%27</span>&#125;\left<span class="meta">%20</span>(<span class="meta">%20w</span>\right<span class="meta">%20</span>)=\sum<span class="number">_</span>&#123;i=<span class="number">1</span>&#125;^&#123;m&#125;(y^&#123;(i)&#125;-h<span class="number">_</span>&#123;w&#125;(x^&#123;(i)&#125;))x^&#123;(i)&#125;)</div><div class="line">![](http://latex.codecogs.com/png.latex?w:=w+\eta<span class="meta">%20L</span>^&#123;<span class="meta">%27</span>&#125;(w)=w+\eta<span class="meta">%20</span>(y^&#123;(i)&#125;-h<span class="number">_</span>&#123;w&#125;(x^&#123;(i)&#125;))x^&#123;(i)&#125;)</div><div class="line">![](http://latex.codecogs.com/png.latex?w:=w+\eta<span class="meta">%20L</span>^&#123;<span class="meta">%27</span>&#125;(w)=w+\eta<span class="meta">%20</span>\sum<span class="number">_</span>&#123;i=<span class="number">1</span>&#125;^&#123;m&#125;(y^&#123;(i)&#125;-h<span class="number">_</span>&#123;w&#125;(x^&#123;(i)&#125;))x^&#123;(i)&#125;)</div><div class="line">![](http://latex.codecogs.com/png.latex?w:=w-\frac&#123;L^&#123;<span class="meta">%27</span>&#125;(w)&#125;&#123;L^&#123;<span class="meta">%27</span><span class="meta">%27</span>&#125;(w)&#125;=w-H^&#123;-<span class="number">1</span>&#125;L^&#123;<span class="meta">%27</span>&#125;(w))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/mt-mlinaction-how-to-ml.html&quot;&gt;huawolf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tech.meituan.com/img/how_to_ml/extract_fea.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;随着大数据时代的到来，机器学习成为解决问题的一种重要且关键的工具。不管是工业界还是学术界，机器学习都是一个炙手可热的方向，但是学术界和工业界对机器学习的研究各有侧重，学术界侧重于对机器学习理论的研究，工业界侧重于如何用机器学习来解决实际问题。我们结合美团在机器学习上的实践，进行一个实战（InAction）系列的介绍（带“机器学习InAction系列”标签的文章），介绍机器学习在解决工业界问题的实战中所需的基本技术、经验和技巧。本文主要结合实际问题，概要地介绍机器学习解决实际问题的整个流程，包括对问题建模、准备训练数据、抽取特征、训练模型和优化模型等关键环节；另外几篇则会对这些关键环节进行更深入地介绍。&lt;/p&gt;
&lt;p&gt;下文分为1）机器学习的概述，2）对问题建模，3）准备训练数据，4）抽取特征，5）训练模型，6）优化模型，7）总结 共7个章节进行介绍。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://ipcreator.me/categories/AI/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中的数据清洗与特征处理综述</title>
    <link href="http://ipcreator.me/2017/02/26/BusinessAI/data-clean-and-remark-feature-in-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/BusinessAI/data-clean-and-remark-feature-in-meituan/</id>
    <published>2017-02-26T14:24:06.000Z</published>
    <updated>2017-02-26T14:33:28.523Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/machinelearning-data-feature-process.html" target="_blank" rel="external">caohao</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>随着美团交易规模的逐步增大，积累下来的业务数据和交易数据越来越多，这些数据是美团做为一个团购平台最宝贵的财富。通过对这些数据的分析和挖掘，不仅能给美团业务发展方向提供决策支持，也为业务的迭代指明了方向。目前在美团的团购系统中大量地应用到了机器学习和数据挖掘技术，例如个性化推荐、筛选排序、搜索排序、用户建模等等，为公司创造了巨大的价值。</p>
<p>本文主要介绍在美团的推荐与个性化团队实践中的数据清洗与特征挖掘方法。主要内容已经在内部公开课”机器学习InAction系列”讲过，本博客的内容主要是讲座内容的提炼和总结。</p>
<a id="more"></a>
<h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><p><img src="http://tech.meituan.com/img/ml_data_feature_process/ml_frame.png" alt=""><br>机器学习框架<br>如上图所示是一个经典的机器学习问题框架图。数据清洗和特征挖掘的工作是在灰色框中框出的部分，即“数据清洗=&gt;特征，标注数据生成=&gt;模型学习=&gt;模型应用”中的前两个步骤。<br>灰色框中蓝色箭头对应的是离线处理部分。主要工作是</p>
<p>从原始数据，如文本、图像或者应用数据中清洗出特征数据和标注数据。<br>对清洗出的特征和标注数据进行处理，例如样本采样，样本调权，异常点去除，特征归一化处理，特征变化，特征组合等过程。最终生成的数据主要是供模型训练使用。<br>灰色框中绿色箭头对应的是在线处理的部分。所做的主要工作和离线处理的类似，主要的区别在于1.不需要清洗标注数据，只需要处理得到特征数据，在线模型使用特征数据预测出样本可能的标签。2.最终生成数据的用处，最终生成的数据主要用于模型的预测，而不是训练。<br>在离线的处理部分，可以进行较多的实验和迭代，尝试不同的样本采样、样本权重、特征处理方法、特征组合方法等，最终得到一个最优的方法，在离线评估得到好的结果后，最终将确定的方案在线上使用。<br>另外，由于在线和离线环境不同，存储数据、获取数据的方法存在较大的差异。例如离线数据获取可以将数据存储在Hadoop，批量地进行分析处理等操作，并且容忍一定的失败。而在线服务获取数据需要稳定、延时小等，可以将数据建入索引、存入KV存储系统等。后面在相应的部分会详细地介绍。</p>
<p>本文以点击下单率预测为例，结合实例来介绍如何进行数据清洗和特征处理。首先介绍下点击下单率预测任务，其业务目标是提高团购用户的用户体验，帮助用户更快更好地找到自己想买的单子。这个概念或者说目标看起来比较虚，我们需要将其转换成一个技术目标，便于度量和实现。最终确定的技术目标是点击下单率预估，去预测用户点击或者购买团购单的概率。我们将预测出来点击或者下单率高的单子排在前面，预测的越准确，用户在排序靠前的单子点击、下单的就越多，省去了用户反复翻页的开销，很快就能找到自己想要的单子。离线我们用常用的衡量排序结果的AUC指标，在线的我们通过ABTest来测试算法对下单率、用户转化率等指标的影响。</p>
<h2 id="特征使用方案"><a href="#特征使用方案" class="headerlink" title="特征使用方案"></a>特征使用方案</h2><p>在确定了目标之后，下一步，我们需要确定使用哪些数据来达到目标。需要事先梳理哪些特征数据可能与用户是否点击下单相关。我们可以借鉴一些业务经验，另外可以采用一些特征选择、特征分析等方法来辅助我们选择。具体的特征选择，特征分析等方法我们后面会详细介绍。从业务经验来判断，可能影响用户是否点击下单的因素有：</p>
<p>距离，很显然这是一个很重要的特征。如果购买一个离用户距离较远的单子，用户去消费这个单子需要付出很多的代价。 当然，也并不是没有买很远单子的用户，但是这个比例会比较小。<br>用户历史行为，对于老用户，之前可能在美团有过购买、点击等行为。<br>用户实时兴趣。<br>单子质量，上面的特征都是比较好衡量的，单子质量可能是更复杂的一个特征。<br>是否热门，用户评价人数，购买数等等。<br>在确定好要使用哪些数据之后，我们需要对使用数据的可用性进行评估，包括数据的获取难度，数据的规模，数据的准确率，数据的覆盖率等，</p>
<p>数据获取难度<br>例如获取用户id不难，但是获取用户年龄和性别较困难，因为用户注册或者购买时，这些并不是必填项。即使填了也不完全准确。这些特征可能是通过额外的预测模型预测的，那就存在着模型精度的问题。<br>数据覆盖率<br>数据覆盖率也是一个重要的考量因素，例如距离特征，并不是所有用户的距离我们都能获取到。PC端的就没有距离，还有很多用户禁止使用它们的地理位置信息等。<br>用户历史行为，只有老用户才会有行为。<br>用户实时行为，如果用户刚打开app，还没有任何行为，同样面临着一个冷启动的问题。<br>数据的准确率<br>单子质量，用户性别等，都会有准确率的问题。</p>
<h2 id="特征获取方案"><a href="#特征获取方案" class="headerlink" title="特征获取方案"></a>特征获取方案</h2><p>Ok，在选定好要用的特征之后，我们需要考虑一个问题。就是这些数据从哪可以获取？只有获取了这些数据我们才能用上。否则，提一个不可能获取到的特征，获取不到，提了也是白提。下面就介绍下特征获取方案。</p>
<p>离线特征获取方案<br>离线可以使用海量的数据，借助于分布式文件存储平台，例如HDFS等，使用例如MapReduce，Spark等处理工具来处理海量的数据等。<br>在线特征获取方案<br>在线特征比较注重获取数据的延时，由于是在线服务，需要在非常短的时间内获取到相应的数据，对查找性能要求非常高，可以将数据存储在索引、kv存储等。而查找性能与数据的数据量会有矛盾，需要折衷处理，我们使用了特征分层获取方案，如下图所示。<br><img src="http://tech.meituan.com/img/ml_data_feature_process/rank_frame.png" alt=""><br>服务架构<br>出于性能考虑。在粗排阶段，使用更基础的特征，数据直接建入索引。精排阶段，再使用一些个性化特征等。<br>特征与标注数据清洗<br>在了解特征数据放在哪儿、怎样获取之后。下一步就是考虑如何处理特征和标注数据了。下面3节都是主要讲的特征和标注处理方法</p>
<p>##标注数据清洗<br>首先介绍下如何清洗特征数据，清洗特征数据方法可以分为离线清洗和在线清洗两种方法。</p>
<p>离线清洗数据<br>离线清洗优点是方便评估新特征效果，缺点是实时性差，与线上实时环境有一定误差。对于实时特征难以训练得到恰当的权重。<br>在线清洗数据<br>在线清洗优点是实时性强，完全记录的线上实际数据，缺点是新特征加入需要一段时间做数据积累。</p>
<h2 id="样本采样与样本过滤"><a href="#样本采样与样本过滤" class="headerlink" title="样本采样与样本过滤"></a>样本采样与样本过滤</h2><p>特征数据只有在和标注数据合并之后，才能用来做为模型的训练。下面介绍下如何清洗标注数据。主要是数据采样和样本过滤。</p>
<p>数据采样，例如对于分类问题：选取正例，负例。对于回归问题，需要采集数据。对于采样得到的样本，根据需要，需要设定样本权重。当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。采样的方法包括随机采样，固定比例采样等方法。</p>
<p>除了采样外，经常对样本还需要进行过滤，包括</p>
<p>1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。<br>2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括<br>偏差检测，例如聚类，最近邻等。<br>基于统计的异常点检测算法<br>例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。<br>基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。<br>基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法</p>
<h2 id="特征分类"><a href="#特征分类" class="headerlink" title="特征分类"></a>特征分类</h2><p>在分析完特征和标注的清洗方法之后，下面来具体介绍下特征的处理方法，先对特征进行分类，对于不同的特征应该有不同的处理方法。</p>
<p>根据不同的分类方法，可以将特征分为(1)Low level特征和High level特征。(2)稳定特征与动态特征。(3)二值特征、连续特征、枚举特征。</p>
<p>Low level特征是较低级别的特征，主要是原始特征，不需要或者需要非常少的人工处理和干预，例如文本特征中的词向量特征，图像特征中的像素点，用户id，商品id等。Low level特征一般维度比较高，不能用过于复杂的模型。High level特征是经过较复杂的处理，结合部分业务逻辑或者规则、模型得到的特征，例如人工打分，模型打分等特征，可以用于较复杂的非线性模型。Low level 比较针对性，覆盖面小。长尾样本的预测值主要受high level特征影响。 高频样本的预测值主要受low level特征影响。</p>
<p>稳定特征是变化频率(更新频率)较少的特征，例如评价平均分，团购单价格等，在较长的时间段内都不会发生变化。动态特征是更新变化比较频繁的特征，有些甚至是实时计算得到的特征，例如距离特征，2小时销量等特征。或者叫做实时特征和非实时特征。针对两类特征的不同可以针对性地设计特征存储和更新方式，例如对于稳定特征，可以建入索引，较长时间更新一次，如果做缓存的话，缓存的时间可以较长。对于动态特征，需要实时计算或者准实时地更新数据，如果做缓存的话，缓存过期时间需要设置的较短。</p>
<p>二值特征主要是0/1特征，即特征只取两种值：0或者1，例如用户id特征：目前的id是否是某个特定的id，词向量特征：某个特定的词是否在文章中出现等等。连续值特征是取值为有理数的特征，特征取值个数不定，例如距离特征，特征取值为是0~正无穷。枚举值特征主要是特征有固定个数个可能值，例如今天周几，只有7个可能值：周1，周2，…，周日。在实际的使用中，我们可能对不同类型的特征进行转换，例如将枚举特征或者连续特征处理为二值特征。枚举特征处理为二值特征技巧：将枚举特征映射为多个特征，每个特征对应一个特定枚举值，例如今天周几，可以把它转换成7个二元特征：今天是否是周一，今天是否是周二，…，今天是否是周日。连续值处理为二值特征方法：先将连续值离散化（后面会介绍如何离散化)，再将离散化后的特征切分为N个二元特征，每个特征代表是否在这个区间内。</p>
<h2 id="特征处理与分析"><a href="#特征处理与分析" class="headerlink" title="特征处理与分析"></a>特征处理与分析</h2><p>在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。</p>
<p>特征归一化，离散化，缺省值处理<br>主要用于单个特征的处理。</p>
<p>归一化<br>不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。<br>离散化<br>在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，…，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。<br>缺省值处理<br>有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。</p>
<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><p>在介绍特征降维之前，先介绍下特征升维。在机器学习中，有一个VC维理论。根据VC维理论，VC维越高，打散能力越强，可容许的模型复杂度越高。在低维不可分的数据，映射到高维是可分。可以想想，给你一堆物品，人脑是如何对这些物品进行分类，依然是找出这些物品的一些特征，例如：颜色，形状，大小，触感等等，然后根据这些特征对物品做以归类，这其实就是一个先升维，后划分的过程。比如我们人脑识别香蕉。可能首先我们发现香蕉是黄色的。这是在颜色这个维度的一个切分。但是很多东西都是黄色的啊，例如哈密瓜。那么怎么区分香蕉和哈密瓜呢？我们发现香蕉形状是弯曲的。而哈密瓜是圆形的，那么我们就可以用形状来把香蕉和哈密瓜划分开了，即引入一个新维度：形状，来区分。这就是一个从“颜色”一维特征升维到二维特征的例子。</p>
<p>那问题来了，既然升维后模型能力能变强，那么是不是特征维度越高越好呢？为什么要进行特征降维&amp;特征选择？主要是出于如下考虑：1. 特征维数越高，模型越容易过拟合，此时更复杂的模型就不好用。2. 相互独立的特征维数越高，在模型不变的情况下，在测试集上达到相同的效果表现所需要的训练样本的数目就越大。 3. 特征数量增加带来的训练、测试以及存储的开销都会增大。4.在某些模型中，例如基于距离计算的模型KMeans，KNN等模型，在进行距离计算时，维度过高会影响精度和性能。5.可视化分析的需要。在低维的情况下，例如二维，三维，我们可以把数据绘制出来，可视化地看到数据。当维度增高时，就难以绘制出来了。在机器学习中，有一个非常经典的维度灾难的概念。用来描述当空间维度增加时，分析和组织高维空间，因体积指数增加而遇到各种问题场景。例如，100个平均分布的点能把一个单位区间以每个点距离不超过0.01采样；而当维度增加到10后，如果以相邻点距离不超过0.01小方格采样单位超一单位超正方体，则需要10^20 个采样点。</p>
<p>正是由于高维特征有如上描述的各种各样的问题，所以我们需要进行特征降维和特征选择等工作。特征降维常用的算法有PCA，LDA等。特征降维的目标是将高维空间中的数据集映射到低维空间数据，同时尽可能少地丢失信息，或者降维后的数据点尽可能地容易被区分</p>
<p>PCA算法<br>通过协方差矩阵的特征值分解能够得到数据的主成分，以二维特征为例，两个特征之间可能存在线性关系（例如运动的时速和秒速度），这样就造成了第二维信息是冗余的。PCA的目标是发现这种特征之间的线性关系，并去除。<br>LDA算法<br>考虑label，降维后的数据点尽可能地容易被区分</p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>特征选择的目标是寻找最优特征子集。特征选择能剔除不相关(irrelevant)或冗余(redundant )的特征，从而达到减少特征个数，提高模型精确度，减少运行时间的目的。另一方面，选取出真正相关的特征简化模型，协助理解数据产生的过程。<br>特征选择的一般过程如下图所示：<br><img src="http://tech.meituan.com/img/ml_data_feature_process/ml_feature_selection_frame.png" alt=""><br>特征选择的过程 ( M. Dash and H. Liu 1997 )<br>主要分为产生过程，评估过程，停止条件和验证过程。</p>
<p>特征选择-产生过程和生成特征子集方法<br>完全搜索(Complete)<br>广度优先搜索( Breadth First Search )<br>广度优先遍历特征子空间。枚举所有组合，穷举搜索，实用性不高。<br>分支限界搜索( Branch and Bound )<br>穷举基础上加入分支限界。例如：剪掉某些不可能搜索出比当前最优解更优的分支。<br>其他，如定向搜索 (Beam Search )，最优优先搜索 ( Best First Search )等<br>启发式搜索(Heuristic)<br>序列前向选择( SFS ， Sequential Forward Selection )<br>从空集开始，每次加入一个选最优。<br>序列后向选择( SBS ， Sequential Backward Selection )<br>从全集开始，每次减少一个选最优。<br>增L去R选择算法 ( LRS ， Plus-L Minus-R Selection )<br>从空集开始，每次加入L个，减去R个，选最优（L&gt;R)或者从全集开始，每次减去R个，增加L个，选最优(L&lt;R)。<br>其他如双向搜索( BDS ， Bidirectional Search )，序列浮动选择( Sequential Floating Selection )等</p>
<p>随机搜索(Random)<br>随机产生序列选择算法(RGSS， Random Generation plus Sequential Selection)<br>随机产生一个特征子集，然后在该子集上执行SFS与SBS算法。<br>模拟退火算法( SA， Simulated Annealing )<br>以一定的概率来接受一个比当前解要差的解，而且这个概率随着时间推移逐渐降低<br>遗传算法( GA， Genetic Algorithms )<br>通过交叉、突变等操作繁殖出下一代特征子集，并且评分越高的特征子集被选中参加繁殖的概率越高。<br>随机算法共同缺点:依赖随机因素，有实验结果难重现。</p>
<h2 id="特征选择－有效性分析"><a href="#特征选择－有效性分析" class="headerlink" title="特征选择－有效性分析"></a>特征选择－有效性分析</h2><p>对特征的有效性进行分析，得到各个特征的特征权重，根据是否与模型有关可以分为1.与模型相关特征权重，使用所有的特征数据训练出来模型，看在模型中各个特征的权重，由于需要训练出模型，模型相关的权重与此次学习所用的模型比较相关。不同的模型有不同的模型权重衡量方法。例如线性模型中，特征的权重系数等。2.与模型无关特征权重。主要分析特征与label的相关性，这样的分析是与这次学习所使用的模型无关的。与模型无关特征权重分析方法包括(1)交叉熵，(2)Information Gain，(3)Odds ratio，(4)互信息，(5)KL散度等</p>
<h2 id="特征监控"><a href="#特征监控" class="headerlink" title="特征监控"></a>特征监控</h2><p>在机器学习任务中，特征非常重要。</p>
<p>个人经验，80%的效果由特征带来。下图是随着特征数的增加，最终模型预测值与实际值的相关系数变化。<br><img src="http://tech.meituan.com/img/ml_data_feature_process/ml_feature_increase.png" alt=""><br>特征重要性<br>对于重要的特征进行监控与有效性分析，了解模型所用的特征是否存在问题，当某个特别重要的特征出问题时，需要做好备案，防止灾难性结果。需要建立特征有效性的长效监控机制<br>我们对关键特征进行了监控，下面特征监控界面的一个截图。通过监控我们发现有一个特征的覆盖率每天都在下降，与特征数据提供方联系之后，发现特征数据提供方的数据源存在着问题，在修复问题之后，该特征恢复正常并且覆盖率有了较大提升。<br><img src="http://tech.meituan.com/img/ml_data_feature_process/ml_feature_supervise.png" alt=""><br>特征监控</p>
<p>在发现特征出现异常时，我们会及时采取措施，对服务进行降级处理，并联系特征数据的提供方尽快修复。对于特征数据生成过程中缺乏监控的情况也会督促做好监控，在源头解决问题。</p>
<p>机器学习InAction系列讲座介绍：结合美团在机器学习上的实践，我们进行一个实战（InAction）系列的介绍（带“机器学习InAction系列”标签的5篇文章），介绍机器学习在解决问题的实战中所需的基本技术、经验和技巧。本文主要介绍了数据清洗与特征处理，其他四篇文章主要介绍了机器学习解决问题流程和模型训练、模型优化等工作。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>《elements of statistical learning》<br><a href="http://en.wikipedia.org/wiki/Supervised_learning" target="_blank" rel="external">http://en.wikipedia.org/wiki/Supervised_learning</a><br><a href="http://www.cnblogs.com/heaad/archive/2011/01/02/1924088.html" target="_blank" rel="external">http://www.cnblogs.com/heaad/archive/2011/01/02/1924088.html</a><br><a href="http://zh.wikipedia.org/zh-cn/维数灾难" target="_blank" rel="external">http://zh.wikipedia.org/zh-cn/维数灾难</a><br><a href="http://www.cs.waikato.ac.nz/ml/weka/" target="_blank" rel="external">http://www.cs.waikato.ac.nz/ml/weka/</a><br><a href="http://blog.csdn.net/lihaifeng555/article/details/4543752" target="_blank" rel="external">http://blog.csdn.net/lihaifeng555/article/details/4543752</a><br><a href="http://blog.csdn.net/abcjennifer/article/details/8002329" target="_blank" rel="external">http://blog.csdn.net/abcjennifer/article/details/8002329</a><br><a href="http://www.cnblogs.com/leftnoteasy/archive/2011/01/08/lda-and-pca-machine-learning.html" target="_blank" rel="external">http://www.cnblogs.com/leftnoteasy/archive/2011/01/08/lda-and-pca-machine-learning.html</a></p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/machinelearning-data-feature-process.html&quot;&gt;caohao&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;随着美团交易规模的逐步增大，积累下来的业务数据和交易数据越来越多，这些数据是美团做为一个团购平台最宝贵的财富。通过对这些数据的分析和挖掘，不仅能给美团业务发展方向提供决策支持，也为业务的迭代指明了方向。目前在美团的团购系统中大量地应用到了机器学习和数据挖掘技术，例如个性化推荐、筛选排序、搜索排序、用户建模等等，为公司创造了巨大的价值。&lt;/p&gt;
&lt;p&gt;本文主要介绍在美团的推荐与个性化团队实践中的数据清洗与特征挖掘方法。主要内容已经在内部公开课”机器学习InAction系列”讲过，本博客的内容主要是讲座内容的提炼和总结。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://ipcreator.me/categories/AI/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>深入FFM原理与实践</title>
    <link href="http://ipcreator.me/2017/02/26/BusinessAI/ffm-learning-in-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/BusinessAI/ffm-learning-in-meituan/</id>
    <published>2017-02-26T14:20:06.000Z</published>
    <updated>2017-02-26T14:23:22.429Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html" target="_blank" rel="external">del2z, 大龙</a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>FM和FFM模型是最近几年提出的模型，凭借其在数据量比较大并且特征稀疏的情况下，仍然能够得到优秀的性能和效果的特性，屡次在各大公司举办的CTR预估比赛中获得不错的战绩。美团点评技术团队在搭建DSP的过程中，探索并使用了FM和FFM模型进行CTR和CVR预估，并且取得了不错的效果。本文旨在把我们对FM和FFM原理的探索和应用的经验介绍给有兴趣的读者。</p>
<p>在计算广告领域，点击率CTR（click-through rate）和转化率CVR（conversion rate）是衡量广告流量的两个关键指标。准确的估计CTR、CVR对于提高流量的价值，增加广告收入有重要的指导作用。预估CTR/CVR，业界常用的方法有人工特征工程 + LR(Logistic Regression)、GBDT(Gradient Boosting Decision Tree) + LR[1][2][3]、FM（Factorization Machine）[2][7]和FFM（Field-aware Factorization Machine）[9]模型。在这些模型中，FM和FFM近年来表现突出，分别在由Criteo和Avazu举办的CTR预测竞赛中夺得冠军[4][5]。</p>
<p>考虑到FFM模型在CTR预估比赛中的不俗战绩，美团点评技术团队在搭建DSP（Demand Side Platform）[6]平台时，在站内CTR/CVR的预估上使用了该模型，取得了不错的效果。本文是基于对FFM模型的深度调研和使用经验，从原理、实现和应用几个方面对FFM进行探讨，希望能够从原理上解释FFM模型在点击率预估上取得优秀效果的原因。因为FFM是在FM的基础上改进得来的，所以我们首先引入FM模型，本文章节组织方式如下：</p>
<p>首先介绍FM的原理。<br>其次介绍FFM对FM的改进。<br>然后介绍FFM的实现细节。<br>最后介绍模型在DSP场景的应用。</p>
<a id="more"></a>
<p>FM原理<br>FM（Factorization Machine）是由Konstanz大学Steffen Rendle（现任职于Google）于2010年最早提出的，旨在解决稀疏数据下的特征组合问题[7]。下面以一个示例引入FM模型。假设一个广告分类的问题，根据用户和广告位相关的特征，预测用户是否点击了广告。源数据如下[8]</p>
<p>Clicked?    Country    Day    Ad_type<br>1    USA    26/11/15    Movie<br>0    China    1/7/14    Game<br>1    China    19/2/15    Game<br>“Clicked?”是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。</p>
<p>Clicked?    Country=USA    Country=China    Day=26/11/15    Day=1/7/14    Day=19/2/15    Ad_type=Movie    Ad_type=Game<br>1    1    0    1    0    0    1    0<br>0    0    1    0    1    0    0    1<br>1    0    1    0    0    1    0    1<br>由上表可以看出，经过One-Hot编码之后，大部分样本数据特征是比较稀疏的。上面的样例中，每个样本有7维特征，但平均仅有3维特征具有非零值。实际上，这种情况并不是此例独有的，在真实应用场景中这种情况普遍存在。例如，CTR/CVR预测时，用户的性别、职业、教育水平、品类偏好，商品的品类等，经过One-Hot编码转换后都会导致样本数据的稀疏性。特别是商品品类这种类型的特征，如商品的末级品类约有550个，采用One-Hot编码生成550个数值特征，但每个样本的这550个特征，有且仅有一个是有效的（非零）。由此可见，数据稀疏性是实际问题中不可避免的挑战。</p>
<p>One-Hot编码的另一个特点就是导致特征空间大。例如，商品品类有550维特征，一个categorical特征转换为550维数值特征，特征空间剧增。</p>
<p>同时通过观察大量的样本数据可以发现，某些特征经过关联之后，与label之间的相关性就会提高。例如，“USA”与“Thanksgiving”、“China”与“Chinese New Year”这样的关联特征，对用户的点击有着正向的影响。换句话说，来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，而在“Thanksgiving”却不会有特别的消费行为。这种关联特征与label的正向相关性在实际问题中是普遍存在的，如“化妆品”类商品与“女”性，“球类运动配件”的商品与“男”性，“电影票”的商品与“电影”品类偏好等。因此，引入两个特征的组合是非常有意义的。</p>
<p>多项式模型是包含特征组合的最直观的模型。在多项式模型中，特征 xixi 和 xjxj 的组合采用 xixjxixj 表示，即 xixi 和 xjxj 都非零时，组合特征 xixjxixj 才有意义。从对比的角度，本文只讨论二阶多项式模型。模型的表达式如下</p>
<p>y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1nwijxixj(1)<br>(1)y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1nwijxixj<br>其中，nn 代表样本的特征数量，xixi 是第 ii 个特征的值，w0w0、wiwi、wijwij 是模型参数。</p>
<p>从公式(1)(1)可以看出，组合特征的参数一共有 n(n−1)2n(n−1)2 个，任意两个参数都是独立的。然而，在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是，每个参数 wijwij 的训练需要大量 xixi 和 xjxj 都非零的样本；由于样本数据本来就比较稀疏，满足“xixi 和 xjxj 都非零”的样本将会非常少。训练样本的不足，很容易导致参数 wijwij 不准确，最终将严重影响模型的性能。</p>
<p>那么，如何解决二次项参数的训练问题呢？矩阵分解提供了一种解决思路。在model-based的协同过滤中，一个rating矩阵可以分解为user矩阵和item矩阵，每个user和item都可以采用一个隐向量表示[8]。比如在下图中的例子中，我们把每个user表示成一个二维向量，同时把每个item表示成一个二维向量，两个向量的点积就是矩阵中user对item的打分。<br><img src="http://tech.meituan.com/img/deep-understanding-of-ffm-principle-and-practice/ffm_mf.png" alt=""></p>
<p>类似地，所有二次项参数 wijwij 可以组成一个对称阵 WW（为了方便说明FM的由来，对角元素可以设置为正实数），那么这个矩阵就可以分解为 W=VTVW=VTV，VV 的第 jj 列便是第 jj 维特征的隐向量。换句话说，每个参数 wij=⟨vi,vj⟩wij=⟨vi,vj⟩，这就是FM模型的核心思想。因此，FM的模型方程为（本文不讨论FM的高阶形式）</p>
<p>y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,vj⟩xixj(2)<br>(2)y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,vj⟩xixj<br>其中，vivi 是第 ii 维特征的隐向量，⟨⋅,⋅⟩⟨⋅,⋅⟩ 代表向量点积。隐向量的长度为 kk（k&lt;&lt;nk&lt;&lt;n），包含 kk 个描述特征的因子。根据公式(2)(2)，二次项的参数数量减少为 knkn个，远少于多项式模型的参数数量。另外，参数因子化使得 xhxixhxi 的参数和 xixjxixj 的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计FM的二次项参数。具体来说，xhxixhxi 和 xixjxixj 的系数分别为 ⟨vh,vi⟩⟨vh,vi⟩ 和 ⟨vi,vj⟩⟨vi,vj⟩，它们之间有共同项 vivi。也就是说，所有包含“xixi 的非零组合特征”（存在某个 j≠ij≠i，使得 xixj≠0xixj≠0）的样本都可以用来学习隐向量 vivi，这很大程度上避免了数据稀疏性造成的影响。而在多项式模型中，whiwhi 和 wijwij 是相互独立的。</p>
<p>显而易见，公式(2)(2)是一个通用的拟合方程，可以采用不同的损失函数用于解决回归、二元分类等问题，比如可以采用MSE（Mean Square Error）损失函数来求解回归问题，也可以采用Hinge/Cross-Entropy损失来求解分类问题。当然，在进行二元分类时，FM的输出需要经过sigmoid变换，这与Logistic回归是一样的。直观上看，FM的复杂度是 O(kn2)O(kn2)。但是，通过公式(3)(3)的等式，FM的二次项可以化简，其复杂度可以优化到 O(kn)O(kn)[7]。由此可见，FM可以在线性时间对新样本作出预测。</p>
<p>∑i=1n∑j=i+1n⟨vi,vj⟩xixj=12∑f=1k⎛⎝(∑i=1nvi,fxi)2−∑i=1nv2i,fx2i⎞⎠(3)<br>(3)∑i=1n∑j=i+1n⟨vi,vj⟩xixj=12∑f=1k((∑i=1nvi,fxi)2−∑i=1nvi,f2xi2)<br>我们再来看一下FM的训练复杂度，利用SGD（Stochastic Gradient Descent）训练模型。模型各个参数的梯度如下</p>
<p>∂∂θy(x)=⎧⎩⎨⎪⎪1,xi,xi∑nj=1vj,fxj−vi,fx2i,ifθisw0ifθiswiifθisvi,f<br>∂∂θy(x)={1,ifθisw0xi,ifθiswixi∑j=1nvj,fxj−vi,fxi2,ifθisvi,f<br>其中，vj,fvj,f 是隐向量 vjvj 的第 ff 个元素。由于 ∑nj=1vj,fxj∑j=1nvj,fxj 只与 ff 有关，而与 ii 无关，在每次迭代过程中，只需计算一次所有 ff 的 ∑nj=1vj,fxj∑j=1nvj,fxj，就能够方便地得到所有 vi,fvi,f 的梯度。显然，计算所有 ff 的 ∑nj=1vj,fxj∑j=1nvj,fxj 的复杂度是 O(kn)O(kn)；已知 ∑nj=1vj,fxj∑j=1nvj,fxj 时，计算每个参数梯度的复杂度是 O(1)O(1)；得到梯度后，更新每个参数的复杂度是 O(1)O(1)；模型参数一共有 nk+n+1nk+n+1 个。因此，FM参数训练的复杂度也是 O(kn)O(kn)。综上可知，FM可以在线性时间训练和预测，是一种非常高效的模型。</p>
<p>FM与其他模型的对比<br>FM是一种比较灵活的模型，通过合适的特征变换方式，FM可以模拟二阶多项式核的SVM模型、MF模型、SVD++模型等[7]。</p>
<p>相比SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二项多项式核SVM需要计算核矩阵，核矩阵复杂度就是N平方。</p>
<p>相比MF而言，我们把MF中每一项的rating分改写为 rui∼βu+γi+xTuyirui∼βu+γi+xuTyi，从公式(2)(2)中可以看出，这相当于只有两类特征 uu 和 ii 的FM模型。对于FM而言，我们可以加任意多的特征，比如user的历史购买平均值，item的历史购买平均值等，但是MF只能局限在两类特征。SVD++与MF类似，在特征的扩展性上都不如FM，在此不再赘述。</p>
<p>FFM原理<br>FFM（Field-aware Factorization Machine）最初的概念来自Yu-Chin Juan（阮毓钦，毕业于中国台湾大学，现在美国Criteo工作）与其比赛队员，是他们借鉴了来自Michael Jahrer的论文[14]中的field概念提出了FM的升级版模型。通过引入field的概念，FFM把相同性质的特征归于同一个field。以上面的广告分类为例，“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。同理，商品的末级品类编码生成了550个特征，这550个特征都是说明商品所属的品类，因此它们也可以放到同一个field中。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。在FFM中，每一维特征 xixi，针对其它特征的每一种field fjfj，都会学习一个隐向量 vi,fjvi,fj。因此，隐向量不仅与特征相关，也与field相关。也就是说，“Day=26/11/15”这个特征与“Country”特征和“Ad_type”特征进行关联的时候使用不同的隐向量，这与“Country”和“Ad_type”的内在差异相符，也是FFM中“field-aware”的由来。</p>
<p>假设样本的 nn 个特征属于 ff 个field，那么FFM的二次项有 nfnf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。</p>
<p>y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,fj,vj,fi⟩xixj(4)<br>(4)y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,fj,vj,fi⟩xixj<br>其中，fjfj 是第 jj 个特征所属的field。如果隐向量的长度为 kk，那么FFM的二次参数有 nfknfk 个，远多于FM模型的 nknk 个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 O(kn2)O(kn2)。</p>
<p>下面以一个例子简单说明FFM的特征组合方式[9]。输入记录如下</p>
<p>User    Movie    Genre    Price<br>YuChin    3Idiots    Comedy, Drama    $9.99<br>这条记录可以编码成5个特征，其中“Genre=Comedy”和“Genre=Drama”属于同一个field，“Price”是数值型，不用One-Hot编码转换。为了方便说明FFM的样本格式，我们将所有的特征和对应的field映射成整数编号。</p>
<p>Field name    Field index    Feature name    Feature index<br>User    1    User=YuChin    1<br>Movie    2    Movie=3Idiots    2<br>Genre    3    Genre=Comedy    3<br>Price    4    Genre=Drama    4<br>Price    5<br>那么，FFM的组合特征有10项，如下图所示。<br>⟨v1,2,v2,1⟩⋅1⋅1+⟨v1,3,v3,1⟩⋅1⋅1+⟨v1,3,v4,1⟩⋅1⋅1+⟨v1,4,v5,1⟩⋅1⋅9.99+⟨v2,3,v3,2⟩⋅1⋅1+⟨v2,3,v4,2⟩⋅1⋅1+⟨v2,4,v5,2⟩⋅1⋅9.99+⟨v3,3,v4,3⟩⋅1⋅1+⟨v3,4,v5,3⟩⋅1⋅9.99+⟨v4,4,v5,3⟩⋅1⋅9.99<br>⟨v1,2,v2,1⟩⋅1⋅1+⟨v1,3,v3,1⟩⋅1⋅1+⟨v1,3,v4,1⟩⋅1⋅1+⟨v1,4,v5,1⟩⋅1⋅9.99+⟨v2,3,v3,2⟩⋅1⋅1+⟨v2,3,v4,2⟩⋅1⋅1+⟨v2,4,v5,2⟩⋅1⋅9.99+⟨v3,3,v4,3⟩⋅1⋅1+⟨v3,4,v5,3⟩⋅1⋅9.99+⟨v4,4,v5,3⟩⋅1⋅9.99<br>其中，红色是field编号，蓝色是特征编号，绿色是此样本的特征取值。二次项的系数是通过与特征field相关的隐向量点积得到的，二次项共有 n(n−1)2n(n−1)2 个。</p>
<p>FFM实现<br>Yu-Chin Juan实现了一个C++版的FFM模型，源码可从Github下载[10]。这个版本的FFM省略了常数项和一次项，模型方程如下。</p>
<p>ϕ(w,x)=∑j1,j2∈C2⟨wj1,f2,wj2,f1⟩xj1xj2(5)<br>(5)ϕ(w,x)=∑j1,j2∈C2⟨wj1,f2,wj2,f1⟩xj1xj2<br>其中，C2C2 是非零特征的二元组合，j1j1 是特征，属于field f1f1，wj1,f2wj1,f2 是特征 j1j1 对field f2f2 的隐向量。此FFM模型采用logistic loss作为损失函数，和L2惩罚项，因此只能用于二元分类问题。</p>
<p>minw∑i=1Llog(1+exp{−yiϕ(w,xi)})+λ2∥w∥2<br>minw∑i=1Llog⁡(1+exp⁡{−yiϕ(w,xi)})+λ2‖w‖2<br>其中，yi∈{−1,1}yi∈{−1,1} 是第 ii 个样本的label，LL 是训练样本数量，λλ 是惩罚项系数。模型采用SGD优化，优化流程如下。<br><img src="http://tech.meituan.com/img/deep-understanding-of-ffm-principle-and-practice/ffm_sgd.png" alt=""></p>
<p>参考 Algorithm1Algorithm1, 下面简单解释一下FFM的SGD优化过程。<br>算法的输入 trtr、vava、papa 分别是训练样本集、验证样本集和训练参数设置。</p>
<p>根据样本特征数量（tr.ntr.n）、field的个数（tr.mtr.m）和训练参数（papa），生成初始化模型，即随机生成模型的参数；<br>如果归一化参数 pa.normpa.norm 为真，计算训练和验证样本的归一化系数，样本 ii 的归一化系数为<br>R[i]=1∥X[i]∥<br>R[i]=1‖X[i]‖<br>对每一轮迭代，如果随机更新参数 pa.randpa.rand 为真，随机打乱训练样本的顺序；<br>对每一个训练样本，执行如下操作<br>计算每一个样本的FFM项，即公式(5)(5)中的输出 ϕϕ；<br>计算每一个样本的训练误差，如算法所示，这里采用的是交叉熵损失函数 log(1+eϕ)log⁡(1+eϕ)；<br>利用单个样本的损失函数计算梯度 gΦgΦ，再根据梯度更新模型参数；<br>对每一个验证样本，计算样本的FFM输出，计算验证误差；<br>重复步骤3~5，直到迭代结束或验证误差达到最小。<br>在SGD寻优时，代码采用了一些小技巧，对于提升计算效率是非常有效的。</p>
<p>第一，梯度分步计算。采用SGD训练FFM模型时，只采用单个样本的损失函数来计算模型参数的梯度。</p>
<p>L=Lerr+Lreg=log(1+exp{−yiϕ(w,xi)})+λ2∥w∥2<br>L=Lerr+Lreg=log⁡(1+exp⁡{−yiϕ(w,xi)})+λ2‖w‖2<br>∂L∂w=∂Lerr∂ϕ⋅∂ϕ∂w+∂Lreg∂w<br>∂L∂w=∂Lerr∂ϕ⋅∂ϕ∂w+∂Lreg∂w<br>上面的公式表明，∂Lerr∂ϕ∂Lerr∂ϕ 与具体的模型参数无关。因此，每次更新模型时，只需计算一次，之后直接调用 ∂Lerr∂ϕ∂Lerr∂ϕ 的值即可。对于更新 nfknfk 个模型参数，这种方式能够极大提升运算效率。</p>
<p>第二，自适应学习率。此版本的FFM实现没有采用常用的指数递减的学习率更新策略，而是利用 nfknfk 个浮点数的临时空间，自适应地更新学习率。学习率是参考AdaGrad算法计算的[11]，按如下方式更新</p>
<p>w′j1,f2=wj1,f2−η1+∑t(gtwj1,f2)2−−−−−−−−−−−−√⋅gwj1,f2<br>wj1,f2′=wj1,f2−η1+∑t(gwj1,f2t)2⋅gwj1,f2<br>其中，wj1,f2wj1,f2 是特征 j1j1 对field f2f2 隐向量的一个元素，元素下标未标出；gwj1,f2gwj1,f2 是损失函数对参数 wj1,f2wj1,f2 的梯度；gtwj1,f2gwj1,f2t 是第 tt 次迭代的梯度；ηη 是初始学习率。可以看出，随着迭代的进行，每个参数的历史梯度会慢慢累加，导致每个参数的学习率逐渐减小。另外，每个参数的学习率更新速度是不同的，与其历史梯度有关，根据AdaGrad的特点，对于样本比较稀疏的特征，学习率高于样本比较密集的特征，因此每个参数既可以比较快速达到最优，也不会导致验证误差出现很大的震荡。</p>
<p>第三，OpenMP多核并行计算。OpenMP是用于共享内存并行系统的多处理器程序设计的编译方案，便于移植和多核扩展[12]。FFM的源码采用了OpenMP的API，对参数训练过程SGD进行了多线程扩展，支持多线程编译。因此，OpenMP技术极大地提高了FFM的训练效率和多核CPU的利用率。在训练模型时，输入的训练参数ns_threads指定了线程数量，一般设定为CPU的核心数，便于完全利用CPU资源。</p>
<p>第四，SSE3指令并行编程。SSE3全称为数据流单指令多数据扩展指令集3，是CPU对数据层并行的关键指令，主要用于多媒体和游戏的应用程序中[13]。SSE3指令采用128位的寄存器，同时操作4个单精度浮点数或整数。SSE3指令的功能非常类似于向量运算。例如，aa 和 bb 采用SSE3指令相加（aa 和 bb 分别包含4个数据），其功能是 aa 中的4个元素与 bb 中4个元素对应相加，得到4个相加后的值。采用SSE3指令后，向量运算的速度更加快捷，这对包含大量向量运算的FFM模型是非常有利的。</p>
<p>除了上面的技巧之外，FFM的实现中还有很多调优技巧需要探索。例如，代码是按field和特征的编号申请参数空间的，如果选取了非连续或过大的编号，就会造成大量的内存浪费；在每个样本中加入值为1的新特征，相当于引入了因子化的一次项，避免了缺少一次项带来的模型偏差等。</p>
<p>FFM应用<br>在DSP的场景中，FFM主要用来预估站内的CTR和CVR，即一个用户对一个商品的潜在点击率和点击后的转化率。</p>
<p>CTR和CVR预估模型都是在线下训练，然后用于线上预测。两个模型采用的特征大同小异，主要有三类：用户相关的特征、商品相关的特征、以及用户-商品匹配特征。用户相关的特征包括年龄、性别、职业、兴趣、品类偏好、浏览/购买品类等基本信息，以及用户近期点击量、购买量、消费额等统计信息。商品相关的特征包括所属品类、销量、价格、评分、历史CTR/CVR等信息。用户-商品匹配特征主要有浏览/购买品类匹配、浏览/购买商家匹配、兴趣偏好匹配等几个维度。</p>
<p>为了使用FFM方法，所有的特征必须转换成“field_id:feat_id:value”格式，field_id代表特征所属field的编号，feat_id是特征编号，value是特征的值。数值型的特征比较容易处理，只需分配单独的field编号，如用户评论得分、商品的历史CTR/CVR等。categorical特征需要经过One-Hot编码成数值型，编码产生的所有特征同属于一个field，而特征的值只能是0或1，如用户的性别、年龄段，商品的品类id等。除此之外，还有第三类特征，如用户浏览/购买品类，有多个品类id且用一个数值衡量用户浏览或购买每个品类商品的数量。这类特征按照categorical特征处理，不同的只是特征的值不是0或1，而是代表用户浏览或购买数量的数值。按前述方法得到field_id之后，再对转换后特征顺序编号，得到feat_id，特征的值也可以按照之前的方法获得。</p>
<p>CTR、CVR预估样本的类别是按不同方式获取的。CTR预估的正样本是站内点击的用户-商品记录，负样本是展现但未点击的记录；CVR预估的正样本是站内支付（发生转化）的用户-商品记录，负样本是点击但未支付的记录。构建出样本数据后，采用FFM训练预估模型，并测试模型的性能。</p>
<p>#(field)    #(feature)    AUC    Logloss<br>站内CTR    39    2456    0.77    0.38<br>站内CVR    67    2441    0.92    0.13<br>由于模型是按天训练的，每天的性能指标可能会有些波动，但变化幅度不是很大。这个表的结果说明，站内CTR/CVR预估模型是非常有效的。</p>
<p>在训练FFM的过程中，有许多小细节值得特别关注。</p>
<p>第一，样本归一化。FFM默认是进行样本数据的归一化，即 pa.normpa.norm 为真；若此参数设置为假，很容易造成数据inf溢出，进而引起梯度计算的nan错误。因此，样本层面的数据是推荐进行归一化的。</p>
<p>第二，特征归一化。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到 [0,1][0,1] 是非常必要的。</p>
<p>第三，省略零值特征。从FFM模型的表达式(4)(4)可以看出，零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>本文主要介绍了FFM的思路来源和理论原理，并结合源码说明FFM的实际应用和一些小细节。从理论上分析，FFM的参数因子化方式具有一些显著的优势，特别适合处理样本稀疏性问题，且确保了较好的性能；从应用结果来看，站内CTR/CVR预估采用FFM是非常合理的，各项指标都说明了FFM在点击率预估方面的卓越表现。当然，FFM不一定适用于所有场景且具有超越其他模型的性能，合适的应用场景才能成就FFM的“威名”。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="external">http://blog.csdn.net/lilyth_lilyth/article/details/48032119</a><br><a href="http://www.cnblogs.com/Matrix_Yao/p/4773221.html" target="_blank" rel="external">http://www.cnblogs.com/Matrix_Yao/p/4773221.html</a><br><a href="http://www.herbrich.me/papers/adclicksfacebook.pdf" target="_blank" rel="external">http://www.herbrich.me/papers/adclicksfacebook.pdf</a><br><a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="external">https://www.kaggle.com/c/criteo-display-ad-challenge</a><br><a href="https://www.kaggle.com/c/avazu-ctr-prediction" target="_blank" rel="external">https://www.kaggle.com/c/avazu-ctr-prediction</a><br><a href="https://en.wikipedia.org/wiki/Demand-side_platform" target="_blank" rel="external">https://en.wikipedia.org/wiki/Demand-side_platform</a><br><a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="external">http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf</a><br><a href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf" target="_blank" rel="external">http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf</a><br><a href="http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf" target="_blank" rel="external">http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf</a><br><a href="https://github.com/guestwalk/libffm" target="_blank" rel="external">https://github.com/guestwalk/libffm</a><br><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad" target="_blank" rel="external">https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad</a><br><a href="http://openmp.org/wp/openmp-specifications/" target="_blank" rel="external">http://openmp.org/wp/openmp-specifications/</a><br><a href="http://blog.csdn.net/gengshenghong/article/details/7008704" target="_blank" rel="external">http://blog.csdn.net/gengshenghong/article/details/7008704</a><br><a href="https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf" target="_blank" rel="external">https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf</a></p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html&quot;&gt;del2z, 大龙&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;FM和FFM模型是最近几年提出的模型，凭借其在数据量比较大并且特征稀疏的情况下，仍然能够得到优秀的性能和效果的特性，屡次在各大公司举办的CTR预估比赛中获得不错的战绩。美团点评技术团队在搭建DSP的过程中，探索并使用了FM和FFM模型进行CTR和CVR预估，并且取得了不错的效果。本文旨在把我们对FM和FFM原理的探索和应用的经验介绍给有兴趣的读者。&lt;/p&gt;
&lt;p&gt;在计算广告领域，点击率CTR（click-through rate）和转化率CVR（conversion rate）是衡量广告流量的两个关键指标。准确的估计CTR、CVR对于提高流量的价值，增加广告收入有重要的指导作用。预估CTR/CVR，业界常用的方法有人工特征工程 + LR(Logistic Regression)、GBDT(Gradient Boosting Decision Tree) + LR[1][2][3]、FM（Factorization Machine）[2][7]和FFM（Field-aware Factorization Machine）[9]模型。在这些模型中，FM和FFM近年来表现突出，分别在由Criteo和Avazu举办的CTR预测竞赛中夺得冠军[4][5]。&lt;/p&gt;
&lt;p&gt;考虑到FFM模型在CTR预估比赛中的不俗战绩，美团点评技术团队在搭建DSP（Demand Side Platform）[6]平台时，在站内CTR/CVR的预估上使用了该模型，取得了不错的效果。本文是基于对FFM模型的深度调研和使用经验，从原理、实现和应用几个方面对FFM进行探讨，希望能够从原理上解释FFM模型在点击率预估上取得优秀效果的原因。因为FFM是在FM的基础上改进得来的，所以我们首先引入FM模型，本文章节组织方式如下：&lt;/p&gt;
&lt;p&gt;首先介绍FM的原理。&lt;br&gt;其次介绍FFM对FM的改进。&lt;br&gt;然后介绍FFM的实现细节。&lt;br&gt;最后介绍模型在DSP场景的应用。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://ipcreator.me/categories/AI/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Online Learning算法理论与实践</title>
    <link href="http://ipcreator.me/2017/02/26/BusinessAI/online-learning-in-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/BusinessAI/online-learning-in-meituan/</id>
    <published>2017-02-26T14:13:06.000Z</published>
    <updated>2017-02-27T05:44:04.666Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/online-learning.html" target="_blank" rel="external">孔东营</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><img src="http://tech.meituan.com/img/online-learning/online-learning-flow.png" alt=""><br>Online Learning是工业界比较常用的机器学习算法，在很多场景下都能有很好的效果。本文主要介绍Online Learning的基本原理和两种常用的Online Learning算法：FTRL（Follow The Regularized Leader）[1]和BPR（Bayesian Probit Regression）[2]，以及Online Learning在美团移动端推荐重排序的应用。</p>
   <a id="more"></a>
<h2 id="什么是Online-Learning"><a href="#什么是Online-Learning" class="headerlink" title="什么是Online Learning"></a>什么是Online Learning</h2><p>准确地说，Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。Online Learning的流程包括：将模型的预测结果展现给用户，然后收集用户的反馈数据，再用来训练模型，形成闭环的系统。如上图所示：</p>
<p>   Online Learning有点像自动控制系统，但又不尽相同，二者的区别是：Online Learning的优化目标是整体的损失函数最小化，而自动控制系统要求最终结果与期望值的偏差最小。</p>
<p>   传统的训练方法，模型上线后，更新的周期会比较长（一般是一天，效率高的时候为一小时），这种模型上线后，一般是静态的（一段时间内不会改变），不会与线上的状况有任何互动，假设预测错了，只能在下一次更新的时候完成更正。Online Learning训练方法不同，会根据线上预测的结果动态调整模型。如果模型预测错误，会及时做出修正。因此，Online Learning能够更加及时地反映线上变化。</p>
<p>   Online Learning的优化目标<br>   <img src="http://tech.meituan.com/img/online-learning/online-learning-model-flow.png" alt=""></p>
<p>   如上图所示，Online Learning训练过程也需要优化一个目标函数（红框标注的），但是和其他的训练方法不同，Online Learning要求快速求出目标函数的最优解，最好是能有解析解。</p>
<h2 id="怎样实现Online-Learning"><a href="#怎样实现Online-Learning" class="headerlink" title="怎样实现Online Learning"></a>怎样实现Online Learning</h2><p>   前面说到Online Learning要求快速求出目标函数的最优解。要满足这个要求，一般的做法有两种：Bayesian Online Learning和Follow The Regularized Leader。下面就详细介绍这两种做法的思路。</p>
<p>   Bayesian Online Learning<br>   贝叶斯方法能够比较自然地导出Online Learning的训练方法：给定参数先验，根据反馈计算后验，将其作为下一次预测的先验，然后再根据反馈计算后验，如此进行下去，就是一个Online Learning的过程，如下图所示。<br>   <img src="http://tech.meituan.com/img/online-learning/bayesian-online-learning-flow.png" alt=""></p>
<p>   举个例子， 我们做一个抛硬币实验，估算硬币正面的概率μμ。我们假设μμ的先验满足<br>   p(μ)=Beta(α,β)<br>   p(μ)=Beta⁡(α,β)</p>
<p>   对于观测值Y＝1Y＝1，代表是正面，我们可以算的后验：<br>   p(μ|Y=1)=Beta(α+1,β)<br>   p(μ|Y=1)=Beta⁡(α+1,β)</p>
<p>   对于观测值Y＝0Y＝0，代表是反面，我们可以算的后验：<br>   p(μ|Y=0)=Beta(α,β+1)<br>   p(μ|Y=0)=Beta⁡(α,β+1)</p>
<p>   按照上面的Bayesian Online Learning流程，我们可以得到估算μμ的Online Learning算法：</p>
<p>   初始化 αα,ββ<br>   for i = 0 … n</p>
<p>   如果 YiYi是正面<br>   α=α+1α=α+1<br>   如果 YiYi是反面<br>   β=β+1β=β+1<br>   最终: μ∼Beta(α,β)μ∼Beta⁡(α,β)，可以取μμ的期望，μ=αα+βμ=αα+β<br>   假设抛了NN次硬币，正面出现HH次，反面出现TT次，按照上面的算法，可以算得：<br>   μ=α+Hα+β+N<br>   μ=α+Hα+β+N</p>
<p>   和最大化似然函数：<br>   log[p(μ∣α,β)⋅p(Y=1∣μ)H⋅p(Y=0∣μ)T]<br>   log[p(μ∣α,β)⋅p(Y=1∣μ)H⋅p(Y=0∣μ)T]</p>
<p>   得到的解是一样的。</p>
<p>   上面的例子是针对离散分布的，我们可以再看一个连续分布的例子。</p>
<p>   有一种测量仪器，测量的方差σ2σ2是已知的， 测量结果为：Y1,Y2,Y3,…,YnY1,Y2,Y3,…,Yn, 求真实值μμ的分布。<br>   仪器的方差是σ2σ2, 所以观测值Y满足高斯分布：<br>   p(Y∣μ)=N(Y∣μ,σ2)<br>   p(Y∣μ)=N(Y∣μ,σ2)</p>
<p>   观测到 Y1,Y2,Y3,…,YnY1,Y2,Y3,…,Yn, 估计参数 μμ 。<br>   假设参数 μμ 满足高斯分布：<br>   p(μ)=N(μ∣m,v2)<br>   p(μ)=N(μ∣m,v2)</p>
<p>   观测到YiYi, 可以计算的后验：<br>   p(μ∣Yi)=N(μ∣Yiv2+mσ2σ2+v2,σ2v2σ2+v2)<br>   p(μ∣Yi)=N(μ∣Yiv2+mσ2σ2+v2,σ2v2σ2+v2)</p>
<p>   可以得到以下的Online Learning算法：</p>
<p>   初始化 mm,v2v2<br>   for i = 0 … n</p>
<p>   观测值为YiYi<br>   更新<br>   m=Yiv2+mσ2σ2+v2<br>   m=Yiv2+mσ2σ2+v2</p>
<p>   v2=σ2v2σ2+v2<br>   v2=σ2v2σ2+v2<br>   上面的两个结果都是后验跟先验是同一分布的（一般取共轭先验，就会有这样的效果），这个后验很自然的作为后面参数估计的先验。假设后验分布和先验不一样，我们该怎么办呢？</p>
<p>   举个例子：假设上面的测量仪器只能观测到YY，是大于0，还是小于0，即Yi∈{−1，1}Yi∈{−1，1},Yi=−1Yi=−1，代表观测值小于0，Yi=1Yi=1代表观测值大于0。<br>   此时，我们仍然可以计算后验分布：<br>   p(μ∣Yi＝1)=I(μ&gt;0)p(μ)∫+∞0p(μ)du<br>   p(μ∣Yi＝1)=I(μ&gt;0)p(μ)∫0+∞p(μ)du</p>
<p>   p(μ∣Yi＝−1)=I(μ&lt;0)p(μ)∫0−∞p(μ)du<br>   p(μ∣Yi＝−1)=I(μ&lt;0)p(μ)∫−∞0p(μ)du</p>
<p>   但是后验分布显然不是高斯分布（是截断高斯分布），这种情况下，我们可以用和上面分布KL距离最近的高斯分布代替。<br>   观测到Yi=1Yi=1<br>   KL(p(μ∣Yi=1)||N(μ∣m~,v~2))<br>   KL(p(μ∣Yi=1)||N(μ∣m~,v~2))</p>
<p>   可以求得：<br>   m~=m+v⋅υ(mv)<br>   m~=m+v⋅υ(mv)</p>
<p>   v~2=v2(1−ω(mv))<br>   v~2=v2(1−ω(mv))<br>   观测到Yi=−1Yi=−1<br>   KL(p(μ∣Yi=−1)||N(μ∣μ~,v~2))<br>   KL(p(μ∣Yi=−1)||N(μ∣μ~,v~2))</p>
<p>   可以求得：<br>   m~=m−v⋅υ(−mv)<br>   m~=m−v⋅υ(−mv)</p>
<p>   v~2=v2(1−ω(−mv))<br>   v~2=v2(1−ω(−mv))<br>   两者综合起来，可以求得：<br>   m~=m+Yiv⋅υ(Yimv)<br>   m~=m+Yiv⋅υ(Yimv)</p>
<p>   v~2=v2(1−ω(Yimv))<br>   v~2=v2(1−ω(Yimv))</p>
<p>   其中：<br>   υ(t)=ϕ(t)Φ(t)<br>   υ(t)=ϕ(t)Φ(t)</p>
<p>   ϕ(t)=12πexp(−12t2)<br>   ϕ(t)=12πexp(−12t2)</p>
<p>   Φ(t)=∫t−∞ϕ(t)dt<br>   Φ(t)=∫−∞tϕ(t)dt</p>
<p>   ω(t)=υ(t)∗(t−υ(t))<br>   ω(t)=υ(t)∗(t−υ(t))<br>   有了后验我们可以得到Online Bayesian Learning流程：</p>
<p>   初始化 mm,v2v2<br>   for i = 0 … n</p>
<p>   观测值为YiYi<br>   更新</p>
<p>   m=m+Yi⋅v⋅υ(Yi⋅mv)<br>   m=m+Yi⋅v⋅υ(Yi⋅mv)<br>   v2=v2(1−ω(Yi⋅mv))<br>   v2=v2(1−ω(Yi⋅mv))<br>   Bayesian Online Learning最常见的应用就是BPR（Bayesian Probit Regression）。</p>
<p>   BPR<br>   在看Online BPR前，我们先了解以下Linear Gaussian System(具体可以参考[3]的4.4节)。<br>   xx是满足多维高斯分布：<br>   p(x)=N(x∣μx,Σx)<br>   p(x)=N(x∣μx,Σx)</p>
<p>   yy是xx通过线性变换加入随机扰动ΣyΣy得到的变量：<br>   p(y∣x)=N(y∣Ax+b,Σy)<br>   p(y∣x)=N(y∣Ax+b,Σy)<br>   已知xx，我们可以得到yy的分布：</p>
<p>   p(y)=N(y∣AμX+b,Σy+AΣxAT)<br>   p(y)=N(y∣AμX+b,Σy+AΣxAT)<br>   上面这个结论的具体的推导过程可以参考[3]的4.4节，这里我们直接拿来用。</p>
<p>   我们可以假设特征权重 ww 满足独立高斯分布，即<br>   p(w)=N(w∣μ,Σ)<br>   p(w)=N(w∣μ,Σ)<br>   ：<br>   μ=[μ1,μ2,…,μD]T<br>   μ=[μ1,μ2,…,μD]T</p>
<p>   Σ=⎡⎣⎢⎢⎢⎢⎢σ210⋮00σ22⋮0……⋱…00⋮σ2D⎤⎦⎥⎥⎥⎥⎥<br>   Σ=[σ120…00σ22…0⋮⋮⋱⋮00…σD2]<br>   YY是一维变量，是ww与特征向量xx的内积，加入方差为β2β2的扰动：</p>
<p>   p(y∣w)=N(y∣xTw,β2)<br>   p(y∣w)=N(y∣xTw,β2)</p>
<p>   根据上面的式子可以得出：<br>   p(y∣w)=N(y∣xTμ,xTΣx+β2)<br>   p(y∣w)=N(y∣xTμ,xTΣx+β2)</p>
<p>   由于我们只能观测到YY，是大于0，还是小于0，即Yi∈{−1，1}Yi∈{−1，1},Yi=−1Yi=−1，代表观测值小于0，Yi=1Yi=1代表观测值大于0。</p>
<p>   对于观测值，我们可以先用KL距离近似yy的分布，我们可以算出后验：<br>   p(y∣Yi)=N(y∣m~,v~2)<br>   p(y∣Yi)=N(y∣m~,v~2)</p>
<p>   m~=xTμ+Yiυ(Yi⋅xTμxTΣx+β2−−−−−−−−−√)<br>   m~=xTμ+Yiυ(Yi⋅xTμxTΣx+β2)</p>
<p>   v~2=(xTΣx+β2)(1−ω(Yi⋅xTμxTΣx+β2−−−−−−−−−√))<br>   v~2=(xTΣx+β2)(1−ω(Yi⋅xTμxTΣx+β2))</p>
<p>   有了yy的近似分布，我们可以计算出后验：<br>   p(w∣y)∝p(y∣w)p(w)<br>   p(w∣y)∝p(y∣w)p(w)<br>   可以求得：<br>   p(wd∣y)=N(wd∣μ~d,σ~d)<br>   p(wd∣y)=N(wd∣μ~d,σ~d)</p>
<p>   μ~d=μd+Yixi,d⋅σ2dxTΣx+β2−−−−−−−−−√⋅υ(Yi⋅xTμxTΣx+β2−−−−−−−−−√)<br>   μ~d=μd+Yixi,d⋅σd2xTΣx+β2⋅υ(Yi⋅xTμxTΣx+β2)<br>   σ~d=σd⋅[1−xi,d⋅σ2dxTΣx+β2ω(Yi⋅xTμxTΣx+β2−−−−−−−−−√)]<br>   σ~d=σd⋅[1−xi,d⋅σd2xTΣx+β2ω(Yi⋅xTμxTΣx+β2)]<br>   Online Bayesian Probit Regression 训练流程如下：</p>
<p>   初始化 μ1μ1,σ21σ12, μ2μ2,σ22σ22 , … , μDμD,σ2DσD2<br>   for i = 1 … n</p>
<p>   观测值为YiYi<br>   for d = 1 … D<br>   更新</p>
<p>   μd=μd+Yixi,d⋅σ2dxTiΣxi+β2−−−−−−−−−√⋅υ⎛⎝⎜Yi⋅xTiμxTiΣxi+β2−−−−−−−−−√⎞⎠⎟<br>   μd=μd+Yixi,d⋅σd2xiTΣxi+β2⋅υ(Yi⋅xiTμxiTΣxi+β2)<br>   σd=σd⋅⎡⎣⎢1−xi,d⋅σ2dxTiΣxi+β2ω⎛⎝⎜Yi⋅xTiμxTiΣx+β2−−−−−−−−−√⎞⎠⎟⎤⎦⎥<br>   σd=σd⋅[1−xi,d⋅σd2xiTΣxi+β2ω(Yi⋅xiTμxiTΣx+β2)]<br>   FTRL<br>   除了Online Bayesian Learning，还有一种做法就是FTRL（Follow The Regularized Leader）。<br>   FTRL的网上资料很多，但是大部分介绍怎么样产生稀疏化解，而往往忽略了FTRL的基本原理。顾名思义，FTRL和稀疏化并没有关系，它只是一种做Online Learning的思想。</p>
<p>   先说说FTL（Follow The Leader）算法，FTL思想就是每次找到让之前所有损失函数之和最小的参数。流程如下：</p>
<p>   初始化 ww<br>   for t = 1 … n</p>
<p>   损失函数 ftft<br>   更新</p>
<p>   w=argminw∑i=1tfi(w)<br>   w=argminw∑i=1tfi(w)<br>   FTRL算法就是在FTL的优化目标的基础上，加入了正规化，防止过拟合：<br>   w=argminw∑i=1tfi(w)+R(w)<br>   w=argminw∑i=1tfi(w)+R(w)</p>
<p>   其中，R(w)R(w)是正规化项。</p>
<p>   FTRL算法的损失函数，一般也不是能够很快求解的，这种情况下，一般需要找一个代理的损失函数。</p>
<p>   代理损失函数需要满足几个要求：</p>
<p>   代理损失函数比较容易求解，最好是有解析解<br>   优化代理损失函数求的解，和优化原函数得到的解差距不能太大<br>   为了衡量条件2中的两个解的差距，这里需要引入regret的概念。</p>
<p>   假设每一步用的代理函数是ht(w)ht(w)<br>   每次取</p>
<p>   wt=argminwht−1(w)<br>   wt=argminwht−1(w)</p>
<p>   Regrett=∑t=1Tft(wt)−∑t=1Tft(w∗)<br>   Regrett=∑t=1Tft(wt)−∑t=1Tft(w∗)<br>   其中w∗=argminw∑ti=1fi(w)w∗=argminw∑i=1tfi(w)，是原函数的最优解。就是我们每次代理函数求出解，离真正损失函数求出解的损失差距。当然这个损失必须满足一定的条件，Online Learning才可以有效，就是：</p>
<p>   limt→∞Regrettt=0<br>   limt→∞Regrettt=0<br>   随着训练样本的增多，这两个优化目标优化出的参数的实际损失值差距越来越小。</p>
<p>   代理函数 ht(w)ht(w) 应该该怎么选呢？<br>   如果ft(w)ft(w) 是凸函数，我们可以用下面的代理损失函数：</p>
<p>   ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2<br>   ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2<br>   其中gigi 是fi(wi)fi(wi)次梯度（如果 fi(wi)fi(wi)是可导的，次梯度就是梯度）。ηtηt满足：<br>   ηt=α∑ti=1g2t−−−−−−−√<br>   ηt=α∑i=1tgt2<br>   为了产生稀疏的效果，我们也可以加入l1正规化：</p>
<p>   ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2＋λ1|w|<br>   ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2＋λ1|w|</p>
<p>   只要ft(w)ft(w) 是凸函数，上面的代理函数一定满足：</p>
<p>   limt→∞Regrettt=0<br>   limt→∞Regrettt=0<br>   上面的式子我们可以得出ww的解析解：</p>
<p>   wt+1,i={0−ηt(zt,i−sgn(zt,i)λ1))|zt,i|&lt;λ1otherwise<br>   wt+1,i={0|zt,i|&lt;λ1−ηt(zt,i−sgn(zt,i)λ1))otherwise<br>   其中<br>   zt,i=∑s=1tgs,i+∑s=1t(1ηt,i−1ηt−1,i)wt,i<br>   zt,i=∑s=1tgs,i+∑s=1t(1ηt,i−1ηt−1,i)wt,i<br>   可以得到FTRL的更新流程如下：</p>
<p>   输入αα, λ1λ1<br>   初始化 w1…Nw1…N, z1..N=0z1..N=0 , n1..N=0n1..N=0<br>   for t = 1 … T</p>
<p>   损失函数 ftft<br>   for i = 1 ..N</p>
<p>   计算</p>
<p>   gt,i=∂fi(wt−1)wt−1,i<br>   gt,i=∂fi(wt−1)wt−1,i<br>   zt+=gt,i+1α(ni+g2t,i−−−−−−−√−ni−−√)wt,i<br>   zt+=gt,i+1α(ni+gt,i2−ni)wt,i<br>   ni+=g2t,i<br>   ni+=gt,i2</p>
<p>   更新</p>
<p>   wt+1,i={0−ηt(zt,i−sgn(zt,i)λ1))|zt,i|&lt;λ1otherwise<br>   wt+1,i={0|zt,i|&lt;λ1−ηt(zt,i−sgn(zt,i)λ1))otherwise<br>   Online Learning实践<br>   前面讲了Online Learning的基本原理，这里以移动端推荐重排序为例，介绍一下Online Learning在实际中的应用。</p>
<p>   推荐重排序介绍</p>
<p>   目前的推荐系统，主要采用了两层架构，首先是触发层，会根据上下文条件和用户的历史行为，触发用户可能感兴趣的item，然后由排序模型对触发的item排序，如下图所示：<br>   <img src="http://tech.meituan.com/img/online-learning/online-learning-rerank.png" alt=""></p>
<p>   推荐重排序既能融合不同触发策略，又能较大幅度提高推荐效果（我们这里主要是下单率）。在移动端，屏幕更加小，用户每次看到的item数目更加少，排序的作用更加突出。</p>
<p>   美团重排序Online Learning架构</p>
<p>   美团Online Learning架构如下图所示：<br>   <img src="http://tech.meituan.com/img/online-learning/online-learning-server.png" alt=""></p>
<p>   线上的展示日志，点击日志和下单日志会写入不同的Kafka流。读取Kafka流，以HBase为中间缓存，完成label match（下单和点击对映到相应的展示日志），在做label match的过成中，会对把同一个session的日志放在一起，方便后面做skip above：</p>
<p>   训练数据生成</p>
<p>   移动端推荐的数据跟PC端不同，移动端一次会加载很多item，但是无法保证这些item会被用户看到。为了保证数据的准确性，我们采用了skip above的办法，如下图所示：<br>   <img src="http://tech.meituan.com/img/online-learning/online-learning-skip-above.png" alt=""></p>
<p>   假设用户点击了第i个位置，我们保留从第1条到第i+2条数据作为训练数据，其他的丢弃。这样能够最大程度的保证训练样本中的数据是被用户看到的。</p>
<p>   特征</p>
<p>   用的特征如下图所示：<br>   <img src="http://tech.meituan.com/img/online-learning/online-learning-feature.png" alt=""></p>
<p>   算法选择</p>
<p>   我们尝试了FTRL和BPR效果，线下实验效果如下表：</p>
<p>   算法       AUC         模型参数个数<br>   FTRL    0.8432    200W<br>   BPR    0.8441    1500W<br>   BPR的效果略好，但是我们线上选用了FTRL模型，主要原因是FTRL能够产生稀疏化的效果，训练出的模型会比较小。</p>
<p>   模型训练</p>
<p>   训练算法不断地从HBase中读取数据，完成模型地训练，训练模型放在Medis（美团内部地Redis）中，线上会用Medis中的模型预测下单率，根据预测的下单率，完成排序。</p>
<p>   线上效果</p>
<p>   上线后，最终的效果如下图所示，和base算法相比，下单率提高了5%。<br>   <img src="http://tech.meituan.com/img/online-learning/online-learning-result.png" alt=""></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>   [1] McMahan H B, Holt G, Sculley D, et al. Ad Click Prediction: a View from the Trenches. Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 2013.<br>   [2] Graepel T, Candela J Q, Borchert T,et al. Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine. Proceedings of the 27th International Conference on Machine Learning ICML. 2010.<br>   [3] Murphy K P. Machine Learning: A Probabilistic Perspective. The MIT Press. 2012.</p>
<p>   不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>   请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br>   <img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>   公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/online-learning.html&quot;&gt;孔东营&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://tech.meituan.com/img/online-learning/online-learning-flow.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Online Learning是工业界比较常用的机器学习算法，在很多场景下都能有很好的效果。本文主要介绍Online Learning的基本原理和两种常用的Online Learning算法：FTRL（Follow The Regularized Leader）[1]和BPR（Bayesian Probit Regression）[2]，以及Online Learning在美团移动端推荐重排序的应用。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://ipcreator.me/categories/AI/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>外卖排序系统特征生产框架</title>
    <link href="http://ipcreator.me/2017/02/26/BusinessAI/framework-of-get-features-in-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/BusinessAI/framework-of-get-features-in-meituan/</id>
    <published>2017-02-26T14:04:06.000Z</published>
    <updated>2017-02-27T05:43:35.136Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/feature_pipeline.html" target="_blank" rel="external">海文</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><img src="http://tech.meituan.com/img/feature_pipeline/001.png" alt=""><br>外卖的排序策略是由机器学习模型驱动的，模型迭代效率制约着策略优化效果。如上图所示，在排序系统里，特征是最为基础的部分：有了特征之后，我们离线训练出模型，然后将特征和模型一起推送给线上排序服务使用。特征生产Pipeline对于策略迭代的效率起着至关重要的作用。经过实践中的积累和提炼，我们整理出一套通用的特征生产框架，大大节省开发量，提高策略迭代效率。</p>
   <a id="more"></a>
<p>外卖排序系统使用GBDT（Gradient Boosting Decision Tree）树模型，比较复杂。受限于计算能力，除了上下文特征（如时间、地域、终端类型、距离等）之外，目前使用的主要是一些宽泛的统计特征，比如商家销量、商家单均价、用户的品类偏好等。这些特征的生产流程包括：离线的统计、离线到在线的同步、在线的加载等。<br><img src="http://tech.meituan.com/img/feature_pipeline/002.png" alt=""><br>   图2 特征生产流程</p>
<p>   如上图，目前外卖排序的特征生产流程主要有：</p>
<p>   特征统计：基于基础数据表（如曝光表、点击表、订单表等），统计若干时段内特定维度的总量、分布等，如商家月均销量、用户不同品类下单占比。统计结果存储于Hive表。这部分工作，简单的可基于ETL，复杂的可基于Spark。产出的特征可供离线训练和线上预测，本文主要围绕线上展开。<br>   特征推送：Hive表里的数据需要存入KV，以便线上实时使用。这一步，首先要将Hive表里的记录映射成POJO类（称为Domain类），然后将其序列化，最后将序列化串存入KV。这部分工作比较单一，基于MapReduce实现。<br>   特征获取：在线服务根据需求，从KV中取出数据，并反序列化为Domain对象。<br>   特征加载：针对模型所需特征列表，取得对应的Domain对象。这步通过调用特征获取实现。<br>   前两步为离线操作，后两步为在线操作。特征同步由离线推送和在线获取共同完成。离线生产流程是一个周期性的Pipeline，目前是以天为周期。</p>
<p>   为此，我们设计了一套通用的框架，基于此框架，只需要简单的配置和少量代码开发，就可以新增一组特征。下文将详细介绍框架的各个部分。</p>
<p>   特征统计<br>   排序模型用到的特征大部分是统计特征。有些特征比较简单，如商家的月均销量、商家单均价等，可用ETL统计(GROUP BY + SUM/AVG)；有些特征稍微复杂，如用户的品类偏好（在不同品类上的占比）、用户的下单额分布（不同金额区段的占比），用ETL就比较繁琐。针对后一种情况，我们开发了一套Spark程序来统计。我们发现，这种统计需求可以规约成一种范式：针对某些统计对象（用户、商家）的一些维度（品类、下单额），基于某些度量值（点击、下单）做统计（比例/总和）。</p>
<p>   同一对象，可统计不同维度；同一维度，有不同的度量角度；同一度量角度，有不同的统计方式。如下图：<br>   <img src="http://tech.meituan.com/img/feature_pipeline/003.png" alt=""><br>   图3 特征统计范式</p>
<p>   例如，对于用户点击品类偏好、用户下单品类偏好、用户下单额分布、用户下单总额等特征，可做范式分解：<br>   <img src="http://tech.meituan.com/img/feature_pipeline/004.png" alt=""><br>   图4 特征统计范式示例<br>   其中，</p>
<p>   统计对象、统计维度、度量值对应于Hive表中的字段（维度一般来自维度表，度量值一般来自事实表，主要是曝光、点击、下单）。为了增加灵活性，我们还允许对原始Hive字段做加工，加工后的值作为统计维度、度量值（加工的接口我们分别称为维度算子和度量算子）。<br>   统计量基于度量值做的一些聚合操作，如累加、求均值、拼接、求占比、算分位点（分布）。前两者输出一个数值，后三者输出形如”Key1:Value1,Key2:Value2”的KeyValue列表。<br>   另外，统计通常是在一定时间窗口内进行的，由于不同时期的数据价值不同（新数据比老数据更有价值），我们引入了时间衰减，对老数据降权。</p>
<p>   基于以上考虑，整个统计流程可以分解为（基于Spark）：<br>   <img src="http://tech.meituan.com/img/feature_pipeline/005.png" alt=""><br>   图5 特征统计流程</p>
<p>   按统计对象字段做聚合（GROUP BY）。统计对象字段由配置给定。对于外卖排序主要为uuid、poi_id。这一步可能会有数据倾斜，需要更多优化。<br>   计算维度。支持维度算子，可以对原始维度字段做处理，如对金额字段做分段处理，以分段后的金额作为维度。<br>   按统计维度聚合（GROUP BY）。这是在对象聚合的基础上做的二次聚合。维度字段由配置给定，可以有多个字段，表示交叉特征统计，如不同时段的品类偏好，维度字段为：时段、品类。<br>   时间衰减并累加。衰减各个时间的度量值，并把所有时间的度量值累加，作为加权后的度量值。时间字段和度量字段由配置给定。时间字段主要为日期，度量字段主要为曝光、点击、下单。经过维度聚合后，度量值都在特定维度值对应的记录集上做累加，每个维度对应一个度量值，维度和度量值是一个KeyValue的映射关系。<br>   计算度量值。度量字段也可以通过度量算子做进一步处理，算子得到的结果作为度量值。也可以有多个字段，如点击和曝光字段，配合除法算子，可以得到点击率作为度量值。<br>   计算统计量。经过对象和维度聚合后，对象、维度、度量值建立了二级映射关系：对象维度度量值，相当于一个二维Map：Map&lt;对象, Map&lt;维度, 度量值&gt;&gt;。统计量是对Map&lt;维度, 度量值&gt;做一个聚合操作。每个统计量对应输出Hive表中的一个字段。现在主要支持如下几种算子：<br>   累加：对该维度的所有度量值求和；<br>   求均值：该维度所有取值情况对应的度量值的均值；<br>   拼接：把Map&lt;维度, 度量值&gt;序列化为”Key1:Value1, Key2:Value2”形式，以便以字符串的形式存储于一个输出字段内。为了防止序列化串太长，可通过配置设定只保留度量值最大的top N；<br>   求占比：该维度所有取值情况对应的度量值占度量值总和的比重，即Map&lt;维度, 度量值/Sum(度量值)&gt;。然后再做拼接输出；<br>   算分位点：有时候想直到某些维度的分布情况，比如用户下单金额的分布以考察用户的消费能力。分位点可以作为分布的一种简单而有效的表示方法。该算子输出每个分位点的维度值，形如”分位点1:维度值1, 分位点2:维度值2”。此时，度量值只是用来算比值。<br>   维度算子、度量算子、统计算子都可以通过扩展接口的方式实现自定义。</p>
<p>   如下是统计用户点击品类偏好、用户下单品类偏好、用户下单额分布的配置文件和Hive表示例([Toml][1]格式)<br>   <img src="http://tech.meituan.com/img/feature_pipeline/006.png" alt=""><br>   图6 特征统计配置示例</p>
<p>   相对于ETL，这套Spark统计框架更为简单清晰，还可以同时统计多个相关的特征。通过简单的配置就可以实现特征的统计，开发量比较小。</p>
<p>   特征同步<br>   离线统计得到的特征存储在Hive表中，出于性能的考虑，不能在线上直接访问。我们需要把特征从Hive中推送到更为高效的KV数据库中，线上服务再从KV中获取。整个同步过程可以分为如下步骤：<br>   <img src="http://tech.meituan.com/img/feature_pipeline/007.png" alt=""><br>   图7 特征推送流程</p>
<p>   ORM：将Hive表中的每行记录映射为Domain对象（类似于[Hibernate][2]的功能）<br>   序列化：将Domain对象序列化，然后存储到KV中。一个Domain类包含一组相关的、可同时在一个任务中统计的特征数据。每个Domain对象都有一个key值来作为自己唯一的标志—实现key()接口。同时，由于不同类型的Domain都会存储在一起，我们还需要为每种类型的Domain设定一个Key值前缀prefix以示区别。因此，KV中的Key是Domain.prefix + Domain.key，Value是序列化串。我们支持json和protostuff两种序列化方式。<br>   反序列化：在线服务根据key和Domain.prefix从KV中得到序列化串，并反序列化为Domain对象。<br>   前两步为离线操作，第三步为在线操作（在预测代码中被调用）。</p>
<p>   我们针对Hive开发了一套ORM库（见图8），主要基于Java反射，除了支持基本类型(int/long/float/double/String等)，还支持POJO类型和集合类型(List/Map)。因为ETL不支持json拼接，为了兼容基于ETL统计的特征数据，我们的POJO以及集合类型是基于自定义的规范做编解码。针对Spark统计的特征数据，后续我们可以支持json格式的编解码。<br>   <img src="http://tech.meituan.com/img/feature_pipeline/008.png" alt=""><br>   图8 Hive ORM示意</p>
<p>   特征序列化和反序列我们统一封装为通用的KvService：负责序列化与反序列，以及读写KV。如下图：</p>
<p>   <img src="http://tech.meituan.com/img/feature_pipeline/009.png" alt=""><br>   图9 KvService<br>   对于新特征，只需要定义一个Domain类，并实现接口key()即可，KvService自动完成Key值的拼接（以Domain的类名作为Key的prefix），序列化和反序列化，读写KV。</p>
<p>   我们通过周期性的离线MapReduce任务，读取Hive表的记录，并调用KvService的put接口，将特征数据推送到KV中。由于KvService能够统一处理各种Domain类型，MapReduce任务也是通用的，无需为每个特征单独开发。</p>
<p>   对于特征同步，只需要开发Domain类，并做少量配置，开发量也很小。目前，我们为了代码的可读性，采用Domain这种强类型的方式来定义特征，如果可以弱化这种需求的话，还可以做更多的框架优化，省去Domain类开发这部分工作。</p>
<p>   特征加载<br>   通过前面几步，我们已经准备好特征数据，并存储于KV中。线上有诸多模型在运行，不同模型需要不同的特征数据。特征加载这一步主要解决怎么高效便捷地为模型提供相应的特征数据。</p>
<p>   离线得到的只是一些原始特征，在线还可能需要基于原始特征做更多的处理，得到高阶特征。比如离线得到了商家和用户的下单金额分布，在线我们可能需要基于这两个分布计算一个匹配度，以表征该商家是否在用户消费能力的承受范围之内。</p>
<p>   我们把在线特征抽象为一个特征算子：FeatureOperator。类似的，一个特征算子包含了一组相关的在线特征，且可能依赖一组相关的离线特征。它除了封装了在线特征的计算过程，还通过两个Java Annotation声明该特征算子产出的特征清单(@Features)和所需要的数据清单(@Fetchers)。所有的数据获取都是由DataFetcher调用KvService的get接口实现，拿到的Domain对象统一存储在DataPortal对象中以便后续使用。</p>
<p>   服务启动时，会自动扫描所有的FeatureOperator的Annotation（@Features、@Fetchers），拿到对应的特征清单和数据清单，从而建立起映射关系：FeatureFeatureOperatorDataFetcher。而每个模型通过配置文件给定其所需要的特征清单，这样就建立起模型到特征的映射关系（如图9）：</p>
<p>   Model → Feature → FeatureOperator → DataFetcher</p>
<p>   不同的在线特征可能会依赖相同的离线特征，也就是FeatureOperatorDataFetcher是多对多的关系。为了避免重复从KV读取相同的数据以造成性能浪费，离线特征的获取和在线特征的抽取被划分成两步：先汇总所有离线特征需求，统一获取离线特征；得到离线特征后，再进行在线特征的抽取。这样，我们也可以在离线特征加载阶段采用并发以减少网络IO延时。整个流程如图10所示：</p>
<p>   <img src="http://tech.meituan.com/img/feature_pipeline/010.png" alt=""><br>   图10 模型和特征数据的映射关系</p>
<p>   <img src="http://tech.meituan.com/img/feature_pipeline/011.png" alt=""><br>   图11 特征加载流程</p>
<p>   对于新特征，我们需要实现对应的FeatureOperator、DataFetcher。DataFetcher主要封装了Domain和DataPortal的关系。类似的，如果我们不需要以强类型的方式来保证代码的业务可读性，也可以通过优化框架省去DataFetcher和DataPortal的定制开发。</p>
<p>   总结<br>   我们在合理抽象特征生产过程的各个环节后，设计了一套较为通用的框架，只需要少量的代码开发（主要是自定义一些算子）以及一些配置，就可以很方便地生产一组特征，有效地提高了策略迭代效率。</p>
<p>   参考文献<br>   <a href="https://github.com/toml-lang/toml" target="_blank" rel="external">TOML.</a><br>   <a href="http://hibernate.org/orm/" target="_blank" rel="external">Hibernate ORM.</a></p>
<p>   不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>   请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br>   <img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>   公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/feature_pipeline.html&quot;&gt;海文&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://tech.meituan.com/img/feature_pipeline/001.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;外卖的排序策略是由机器学习模型驱动的，模型迭代效率制约着策略优化效果。如上图所示，在排序系统里，特征是最为基础的部分：有了特征之后，我们离线训练出模型，然后将特征和模型一起推送给线上排序服务使用。特征生产Pipeline对于策略迭代的效率起着至关重要的作用。经过实践中的积累和提炼，我们整理出一套通用的特征生产框架，大大节省开发量，提高策略迭代效率。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://ipcreator.me/categories/AI/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>深度学习在美团点评的应用</title>
    <link href="http://ipcreator.me/2017/02/26/BusinessAI/deep-learning-in-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/BusinessAI/deep-learning-in-meituan/</id>
    <published>2017-02-26T13:56:06.000Z</published>
    <updated>2017-02-27T05:42:03.853Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/deeplearning_application.html" target="_blank" rel="external">文竹 李彪 晓明</a></p>
<p>   <img src="http://tech.meituan.com/img/deeplearning_application/clicknet_framework.png" alt=""></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>近年来，深度学习在语音、图像、自然语言处理等领域取得非常突出的成果，成了最引人注目的技术热点之一。美团点评这两年在深度学习方面也进行了一些探索，其中在自然语言处理领域，我们将深度学习技术应用于文本分析、语义匹配、搜索引擎的排序模型等；在计算机视觉领域，我们将其应用于文字识别、目标检测、图像分类、图像质量排序等。下面我们就以语义匹配、图像质量排序及文字识别这三个应用场景为例，来详细介绍美团点评在深度学习技术及应用方面的经验和方法论。</p>
   <a id="more"></a>
<h2 id="基于深度学习的语义匹配"><a href="#基于深度学习的语义匹配" class="headerlink" title="基于深度学习的语义匹配"></a>基于深度学习的语义匹配</h2><p>   语义匹配技术，在信息检索、搜索引擎中有着重要的地位，在结果召回、精准排序等环节发挥着重要作用。</p>
<p>   传统意义上讲的语义匹配技术，更加注重文字层面的语义吻合程度，我们暂且称之为语言层的语义匹配；而在美团点评这样典型的O2O应用场景下，我们的结果呈现除了和用户表达的语言层语义强相关之外，还和用户意图、用户状态强相关。</p>
<p>   用户意图即用户是来干什么的？比如用户在百度上搜索“关内关外”，他的意图可能是想知道关内和关外代表的地理区域范围，“关内”和“关外”被作为两个词进行检索，而在美团上搜索“关内关外”，用户想找的就是“关内关外”这家饭店，“关内关外”被作为一个词来对待。</p>
<p>   再说用户状态，一个在北京和另一个在武汉的用户，在百度或淘宝上搜索任何一个词条，可能得到的结果不会差太多；但是在美团这样与地理位置强相关的场景下就会完全不一样。比如我在武汉搜“黄鹤楼”，用户找的可能是景点门票，而在北京搜索“黄鹤楼”，用户找的很可能是一家饭店。</p>
<p>   如何结合语言层信息和用户意图、状态来做语义匹配呢？</p>
<p>   我们的思路是在短文本外引入部分O2O业务场景特征，融合到所设计的深度学习语义匹配框架中，通过点击/下单数据来指引语义匹配模型的优化方向，最终把训练出的点击相关性模型应用到搜索相关业务中。下图是针对美团点评场景设计的点击相似度框架ClickNet，是比较轻量级的模型，兼顾了效果和性能两方面，能很好地推广到线上应用。<br>   <img src="http://tech.meituan.com/img/deeplearning_application/clicknet_framework.png" alt=""><br>   图1 clicknet框架</p>
<p>   表示层<br>   对Query和商家名分别用语义和业务特征表示，其中语义特征是核心，通过DNN/CNN/RNN/LSTM/GRU方法得到短文本的整体向量表示，另外会引入业务相关特征，比如用户或商家的相关信息，比如用户和商家距离、商家评价等，最终结合起来往上传。</p>
<p>   学习层<br>   通过多层全连接和非线性变化后，预测匹配得分，根据得分和Label来调整网络以学习出Query和商家名的点击匹配关系。</p>
<p>   在该算法框架上要训练效果很好的语义模型，还需要根据场景做模型调优：首先，我们从训练语料做很多优化，比如考虑样本不均衡、样本重要度、位置Bias等方面问题。其次，在模型参数调优时，考虑不同的优化算法、网络大小层次、超参数的调整等问题。经过模型训练优化，我们的语义匹配模型已经在美团点评平台搜索、广告、酒店、旅游等召回和排序系统中上线，有效提升了访购率/收入/点击率等指标。</p>
<p>   小结<br>   深度学习应用在语义匹配上，需要针对业务场景设计合适的算法框架，此外，深度学习算法虽然减少了特征工程工作，但模型调优上难度会增加，因此可以从框架设计、业务语料处理、模型参数调优三方面综合起来考虑，实现一个效果和性能兼优的模型。</p>
<h2 id="基于深度学习的图像质量排序"><a href="#基于深度学习的图像质量排序" class="headerlink" title="基于深度学习的图像质量排序"></a>基于深度学习的图像质量排序</h2><p>   国内外各大互联网公司（比如腾讯、阿里和Yelp）的线上广告业务都在关注展示什么样的图像能吸引更多点击。在美团点评，商家的首图是由商家或运营人工指定的，如何选择首图才能更好地吸引用户呢？图像质量排序算法目标就是做到自动选择更优质的首图，以吸引用户点击。</p>
<p>   传统的图像质量排序方法主要从美学角度进行质量评价，通过颜色统计、主体分布、构图等来分析图片的美感。但在实际业务场景中，用户对图片质量优劣的判断主观性很强，难以形成统一的评价标准。比如:</p>
<p>   有的用户对清晰度或分辨率更敏感；<br>   有的用户对色彩或构图更敏感；<br>   有的用户偏爱有视觉冲击力的内容而非平淡无奇的环境图。<br>   因此我们使用深度学习方法，去挖掘图片的哪些属性会影响用户的判断，以及如何有效融合这些属性对图片进行评价。</p>
<p>   我们使用AlexNet去提取图片的高层语义描述，学习美感、可记忆度、吸引度、品类等High Level特征，并补充人工设计的Low Level特征（比如色彩、锐度、对比度、角点）。在获得这些特征后，训练一个浅层神经网络对图像整体打分。该框架（如图2所示）的一个特点是联合了深度学习特征与传统特征，既引入高层语义又保留了低层通用描述，既包括全局特征又有局部特征。<br>   <img src="http://tech.meituan.com/img/deeplearning_application/%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E6%8E%92%E5%BA%8F%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6.png" alt=""><br>   图2 图像质量排序技术框架</p>
<p>   对于每个维度图片属性的学习，都需要大量的标签数据来支撑，但完全通过人工标记代价极大，因此我们借鉴了美团点评的图片来源和POI标签体系。关于吸引度属性的学习，我们选取了美团Deal相册中点击率高的图片（多数是摄影师通过单反相机拍摄）作为正例，而选取UGC相册中点击率低的图片（多数是低端手机拍摄）作为负例。关于品类属性的学习，我们将美团一级品类和常见二级品类作为图片标签。基于上述质量排序模型，我们为广告POI挑选最合适的优质首图进行展示，起到吸引用户点击，提高业务指标的目的。图3给出了基于质量排序的首图优选结果。<br>   <img src="http://tech.meituan.com/img/deeplearning_application/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E6%8E%92%E5%BA%8F%E7%9A%84%E9%A6%96%E5%9B%BE%E4%BC%98%E9%80%89.png" alt=""><br>   图3 基于图像质量排序的首图优选</p>
<p>   基于深度学习的OCR<br>   为了提升用户体验，O2O产品对OCR技术的需求已渗透到上单、支付、配送和用户评价等环节。OCR在美团点评业务中主要起着两方面作用。一方面是辅助录入，比如在移动支付环节通过对银行卡卡号的拍照识别，以实现自动绑卡，又如辅助BD录入菜单中菜品信息。另一方面是审核校验，比如在商家资质审核环节对商家上传的身份证、营业执照和餐饮许可证等证件照片进行信息提取和核验以确保该商家的合法性，比如机器过滤商家上单和用户评价环节产生的包含违禁词的图片。相比于传统OCR场景（印刷体、扫描文档），美团的OCR场景主要是针对手机拍摄的照片进行文字信息提取和识别，考虑到线下用户的多样性，因此主要面临以下挑战：</p>
<p>   成像复杂：噪声、模糊、光线变化、形变；<br>   文字复杂：字体、字号、色彩、磨损、笔画宽度不固定、方向任意；<br>   背景复杂：版面缺失，背景干扰。<br>   对于上述挑战，传统的OCR解决方案存在着以下不足：</p>
<p>   通过版面分析（二值化，连通域分析）来生成文本行，要求版面结构有较强的规则性且前背景可分性强（例如文档图像、车牌），无法处理前背景复杂的随意文字（例如场景文字、菜单、广告文字等）。<br>   通过人工设计边缘方向特征（例如HOG）来训练字符识别模型，此类单一的特征在字体变化，模糊或背景干扰时泛化能力迅速下降。<br>   过度依赖字符切分的结果，在字符扭曲、粘连、噪声干扰的情况下，切分的错误传播尤其突出。<br>   针对传统OCR解决方案的不足，我们尝试基于深度学习的OCR。</p>
<ol>
<li><p>基于Faster R-CNN和FCN的文字定位<br>首先，我们根据是否有先验信息将版面划分为受控场景（例如身份证、营业执照、银行卡）和非受控场景（例如菜单、门头图）。</p>
<p>对于受控场景，我们将文字定位转换为对特定关键字目标的检测问题。主要利用Faster R-CNN进行检测，如下图所示。为了保证回归框的定位精度同时提升运算速度，我们对原有框架和训练方式进行了微调:</p>
<p>考虑到关键字目标的类内变化有限，我们裁剪了ZF模型的网络结构，将5层卷积减少到3层。<br>训练过程中提高正样本的重叠率阈值，并根据业务需求来适配RPN层Anchor的宽高比。<br><img src="http://tech.meituan.com/img/deeplearning_application/faster_rcnn.png" alt=""><br>图4 基于Faster R-CNN的受控场景文字定位</p>
<p>对于非受控场景，由于文字方向和笔画宽度任意变化，目标检测中回归框的定位粒度不够，我们利用语义分割中常用的全卷积网络（FCN）来进行像素级别的文字/背景标注，如下图所示。为了同时保证定位的精度和语义的清晰，我们不仅在最后一层进行反卷积，而且融合了深层Layer和浅层Layer的反卷积结果<br><img src="http://tech.meituan.com/img/deeplearning_application/norestrict_fcnn.png" alt=""><br>图5 基于FCN的非受控场景文字定位</p>
</li>
<li><p>基于序列学习框架的文字识别<br>为了有效控制字符切分和识别后处理的错误传播效应，实现端到端文字识别的可训练性，我们采用如下图所示的序列学习框架。框架整体分为三层：卷积层，递归层和翻译层。其中卷积层提特征，递归层既学习特征序列中字符特征的先后关系，又学习字符的先后关系，翻译层实现对时间序列分类结果的解码。<br><img src="http://tech.meituan.com/img/deeplearning_application/e2e_framework.png" alt=""><br>图6 基于序列学习的端到端识别框架</p>
<p>由于序列学习框架对训练样本的数量和分布要求较高，我们采用了真实样本+合成样本的方式。真实样本以美团点评业务来源（例如菜单、身份证、营业执照）为主，合成样本则考虑了字体、形变、模糊、噪声、背景等因素。基于上述序列学习框架和训练数据，在多种场景的文字识别上都有较大幅度的性能提升，如下图所示。<br><img src="http://tech.meituan.com/img/deeplearning_application/ocr_compare.png" alt=""><br>图7 深度学习OCR和传统OCR的性能比较</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要以深度学习在自然语言处理、图像处理两个领域的应用为例进行了介绍，但深度学习在美团点评可能发挥的价值远远不限于此。未来，我们将继续在各个场景深入挖掘，比如在智能交互、配送调度、智能运营等，在美团点评产品的智能化道路上贡献一份力量。</p>
<h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>文竹，美团点评美团平台与酒旅事业群智能技术中心负责人，2010年从清华硕士毕业后，加入百度，先后从事机器翻译的研发及多个技术团队的管理工作。2015年4月加入美团，负责智能技术中心的管理工作，致力于推动自然语言处理、图像处理、机器学习、用户画像等技术在公司业务上的落地。</p>
<p>李彪，美团点评美团平台及酒旅事业群NLP技术负责人，曾就职搜狗、百度。2015年加入美团点评，致力于NLP技术积累和业务的落地，负责的工作包括深度学习平台和模型，文本分析在搜索、广告、推荐等业务上应用，智能客服和交互。</p>
<p>晓明，美团点评平台及酒旅事业群图像技术负责人，曾就职于三星研究院。2015年加入美团点评，主要致力于图像识别技术的积累和业务落地，作为技术负责人主导了图像机审、首图优选和OCR等项目的上线，推进了美团产品的智能化体验和人力成本的节省。</p>
</li>
</ol>
<p>   不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>   请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br>   <img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>   公众号二维码   </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/deeplearning_application.html&quot;&gt;文竹 李彪 晓明&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;http://tech.meituan.com/img/deeplearning_application/clicknet_framework.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;近年来，深度学习在语音、图像、自然语言处理等领域取得非常突出的成果，成了最引人注目的技术热点之一。美团点评这两年在深度学习方面也进行了一些探索，其中在自然语言处理领域，我们将深度学习技术应用于文本分析、语义匹配、搜索引擎的排序模型等；在计算机视觉领域，我们将其应用于文字识别、目标检测、图像分类、图像质量排序等。下面我们就以语义匹配、图像质量排序及文字识别这三个应用场景为例，来详细介绍美团点评在深度学习技术及应用方面的经验和方法论。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://ipcreator.me/categories/AI/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>美团Android DEX自动拆包及动态加载简介</title>
    <link href="http://ipcreator.me/2017/02/26/Program/Android/dynamic-load-android-dex-from-meituan/"/>
    <id>http://ipcreator.me/2017/02/26/Program/Android/dynamic-load-android-dex-from-meituan/</id>
    <published>2017-02-26T13:31:05.000Z</published>
    <updated>2017-02-26T13:36:04.621Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/mt-android-auto-split-dex.html" target="_blank" rel="external">美团Android DEX自动拆包及动态加载简介</a><br>jianshuai xiaoyang ·2015-06-15 10:00</p>
<p>概述</p>
<p>作为一个android开发者，在开发应用时，随着业务规模发展到一定程度，不断地加入新功能、添加新的类库，代码在急剧的膨胀，相应的apk包的大小也急剧增加， 那么终有一天，你会不幸遇到这个错误：</p>
<p>生成的apk在android 2.3或之前的机器上无法安装，提示INSTALL_FAILED_DEXOPT<br>方法数量过多，编译时出错，提示：<br> Conversion to Dalvik format failed:Unable to execute dex: method ID not in [0, 0xffff]: 65536</p>
<p>而问题产生的具体原因如下：</p>
<p>无法安装（Android 2.3 INSTALL_FAILED_DEXOPT）问题，是由dexopt的LinearAlloc限制引起的，在Android版本不同分别经历了4M/5M/8M/16M限制，目前主流4.2.x系统上可能都已到16M， 在Gingerbread或者以下系统LinearAllocHdr分配空间只有5M大小的， 高于Gingerbread的系统提升到了8M。Dalvik linearAlloc是一个固定大小的缓冲区。在应用的安装过程中，系统会运行一个名为dexopt的程序为该应用在当前机型中运行做准备。dexopt使用LinearAlloc来存储应用的方法信息。Android 2.2和2.3的缓冲区只有5MB，Android 4.x提高到了8MB或16MB。当方法数量过多导致超出缓冲区大小时，会造成dexopt崩溃。</p>
<p>超过最大方法数限制的问题，是由于DEX文件格式限制，一个DEX文件中method个数采用使用原生类型short来索引文件中的方法，也就是4个字节共计最多表达65536个method，field/class的个数也均有此限制。对于DEX文件，则是将工程所需全部class文件合并且压缩到一个DEX文件期间，也就是Android打包的DEX过程中， 单个DEX文件可被引用的方法总数（自己开发的代码以及所引用的Android框架、类库的代码）被限制为65536；</p>
   <a id="more"></a>
<h2 id="插件化？-MultiDex？"><a href="#插件化？-MultiDex？" class="headerlink" title="插件化？ MultiDex？"></a>插件化？ MultiDex？</h2><p>解决这个问题，一般有下面几种方案，一种方案是加大Proguard的力度来减小DEX的大小和方法数，但这是治标不治本的方案，随着业务代码的添加，方法数终究会到达这个限制，一种比较流行的方案是插件化方案，另外一种是采用google提供的MultiDex方案，以及google在推出MultiDex之前Android Developers博客介绍的通过自定义类加载过程， 再就是Facebook推出的为Android应用开发的Dalvik补丁， 但facebook博客里写的不是很详细；我们在插件化方案上也做了探索和尝试，发现部署插件化方案，首先需要梳理和修改各个业务线的代码，使之解耦，改动的面和量比较巨大，通过一定的探讨和分析，我们认为对我们目前来说采用MultiDex方案更靠谱一些，这样我们可以快速和简洁的对代码进行拆分，同时代码改动也在可以接受的范围内； 这样我们采用了google提供的MultiDex方式进行了开发。</p>
<p>插件化方案在业内有不同的实现原理，这里不再一一列举，这里只列举下Google为构建超过65K方法数的应用提供官方支持的方案：MultiDex。</p>
<p>首先使用Android SDK Manager升级到最新的Android SDK Build Tools和Android Support Library。然后进行以下两步操作：</p>
<p>1.修改Gradle配置文件，启用MultiDex并包含MultiDex支持：</p>
<p>  android {<br>    compileSdkVersion 21 buildToolsVersion “21.1.0”</p>
<pre><code>defaultConfig {
    ...
    minSdkVersion 14
    targetSdkVersion 21
    ...

    // Enabling MultiDex support.
    MultiDexEnabled true
    }
    ...
}
dependencies { compile &apos;com.android.support:MultiDex:1.0.0&apos;
</code></pre><p>}<br>2.让应用支持多DEX文件。在官方文档中描述了三种可选方法：</p>
<p>在AndroidManifest.xml的application中声明android.support.MultiDex.MultiDexApplication；<br>如果你已经有自己的Application类，让其继承MultiDexApplication；<br>如果你的Application类已经继承自其它类，你不想/能修改它，那么可以重写attachBaseContext()方法：</p>
<p>@Override<br>protected void attachBaseContext(Context base) {<br>    super.attachBaseContext(base);<br>    MultiDex.install(this);<br>}<br>并在Manifest中添加以下声明：</p>
<p>&lt;?xml version=”1.0” encoding=”utf-8”?&gt;<br>    <manifest xmlns:android="http://schemas.android.com/apk/res/android" package="com.example.android.MultiDex.myapplication"><br>        <application ...="" android:name="android.support.MultiDex.MultiDexApplication"><br>        …<br>        </application><br>    </manifest><br>如果已经有自己的Application，则让其继承MultiDexApplication即可.</p>
<p>Dex自动拆包及动态加载<br>MultiDex带来的问题<br>在第一版本采用MultiDex方案上线后，在Dalvik下MultiDex带来了下列几个问题：</p>
<p>在冷启动时因为需要安装DEX文件，如果DEX文件过大时，处理时间过长，很容易引发ANR（Application Not Responding）；<br>采用MultiDex方案的应用可能不能在低于Android 4.0 (API level 14) 机器上启动，这个主要是因为Dalvik linearAlloc的一个bug (Issue 22586);<br>采用MultiDex方案的应用因为需要申请一个很大的内存，在运行时可能导致程序的崩溃，这个主要是因为Dalvik linearAlloc 的一个限制(Issue 78035). 这个限制在 Android 4.0 (API level 14)已经增加了, 应用也有可能在低于 Android 5.0 (API level 21)版本的机器上触发这个限制；<br>而在ART下MultiDex是不存在这个问题的，这主要是因为ART下采用Ahead-of-time (AOT) compilation技术，系统在APK的安装过程中会使用自带的dex2oat工具对APK中可用的DEX文件进行编译并生成一个可在本地机器上运行的文件，这样能提高应用的启动速度，因为是在安装过程中进行了处理这样会影响应用的安装速度，对ART感兴趣的可以参考一下ART和Dalvik的区别.</p>
<p>MultiDex的基本原理是把通过DexFile来加载Secondary DEX，并存放在BaseDexClassLoader的DexPathList中。</p>
<p>下面代码片段是BaseDexClassLoader findClass的过程:<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">protected</span> <span class="keyword">Class</span>&lt;?&gt; findClass(String name) <span class="keyword">throws</span> ClassNotFoundException &#123;</div><div class="line">    List&lt;Throwable&gt; suppressedExceptions = <span class="keyword">new</span> ArrayList&lt;Throwable&gt;();</div><div class="line">    <span class="keyword">Class</span> c = pathList.findClass(name, suppressedExceptions);</div><div class="line">    <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</div><div class="line">        ClassNotFoundException cnfe = <span class="keyword">new</span> ClassNotFoundException(<span class="string">"Didn't find class \""</span> + name + <span class="string">"\" on path: "</span> + pathList);</div><div class="line">        <span class="keyword">for</span> (Throwable t : suppressedExceptions) &#123;</div><div class="line">            cnfe.addSuppressed(t);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">throw</span> cnfe;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> c;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面代码片段为怎么通过DexFile来加载Secondary DEX并放到BaseDexClassLoader的DexPathList中:</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> install(ClassLoader loader, List&lt;File&gt; additionalClassPathEntries,</div><div class="line">                            File optimizedDirectory)</div><div class="line">        <span class="keyword">throws</span> IllegalArgumentException, IllegalAccessException,</div><div class="line">        NoSuchFieldException, InvocationTargetException, NoSuchMethodException &#123;</div><div class="line">    <span class="comment">/* The patched class loader is expected to be a descendant of</span></div><div class="line">     * dalvik.system.BaseDexClassLoader. We modify its</div><div class="line">     * dalvik.system.DexPathList pathList field to append additional DEX</div><div class="line">     * file entries.</div><div class="line">     */</div><div class="line">    Field pathListField = findField(loader, <span class="string">"pathList"</span>);</div><div class="line">    <span class="keyword">Object</span> dexPathList = pathListField.<span class="built_in">get</span>(loader);</div><div class="line">    ArrayList&lt;IOException&gt; suppressedExceptions = <span class="keyword">new</span> ArrayList&lt;IOException&gt;();</div><div class="line">    expandFieldArray(dexPathList, <span class="string">"dexElements"</span>, makeDexElements(dexPathList,</div><div class="line">            <span class="keyword">new</span> ArrayList&lt;File&gt;(additionalClassPathEntries), optimizedDirectory,</div><div class="line">            suppressedExceptions));</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">if</span> (suppressedExceptions.<span class="built_in">size</span>() &gt; <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">for</span> (IOException e : suppressedExceptions) &#123;</div><div class="line">                <span class="comment">//Log.w(TAG, "Exception in makeDexElement", e);</span></div><div class="line">            &#125;</div><div class="line">            Field suppressedExceptionsField =</div><div class="line">                    findField(loader, <span class="string">"dexElementsSuppressedExceptions"</span>);</div><div class="line">            IOException[] dexElementsSuppressedExceptions =</div><div class="line">                    (IOException[]) suppressedExceptionsField.<span class="built_in">get</span>(loader);</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (dexElementsSuppressedExceptions == <span class="keyword">null</span>) &#123;</div><div class="line">                dexElementsSuppressedExceptions =</div><div class="line">                        suppressedExceptions.toArray(</div><div class="line">                                <span class="keyword">new</span> IOException[suppressedExceptions.<span class="built_in">size</span>()]);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                IOException[] combined =</div><div class="line">                        <span class="keyword">new</span> IOException[suppressedExceptions.<span class="built_in">size</span>() +</div><div class="line">                                dexElementsSuppressedExceptions.length];</div><div class="line">                suppressedExceptions.toArray(combined);</div><div class="line">                System.arraycopy(dexElementsSuppressedExceptions, <span class="number">0</span>, combined,</div><div class="line">                        suppressedExceptions.<span class="built_in">size</span>(), dexElementsSuppressedExceptions.length);</div><div class="line">                dexElementsSuppressedExceptions = combined;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            suppressedExceptionsField.<span class="built_in">set</span>(loader, dexElementsSuppressedExceptions);</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">catch</span>(Exception e) &#123;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Dex自动拆包及动态加载方案简介"><a href="#Dex自动拆包及动态加载方案简介" class="headerlink" title="Dex自动拆包及动态加载方案简介"></a>Dex自动拆包及动态加载方案简介</h2><p>通过查看MultiDex的源码，我们发现MultiDex在冷启动时容易导致ANR的瓶颈， 在2.1版本之前的Dalvik的VM版本中， MultiDex的安装大概分为几步，第一步打开apk这个zip包，第二步把MultiDex的dex解压出来（除去Classes.dex之外的其他DEX，例如：classes2.dex， classes3.dex等等)，因为android系统在启动app时只加载了第一个Classes.dex，其他的DEX需要我们人工进行安装，第三步通过反射进行安装，这三步其实都比较耗时， 为了解决这个问题我们考虑是否可以把DEX的加载放到一个异步线程中，这样冷启动速度能提高不少，同时能够减少冷启动过程中的ANR，对于Dalvik linearAlloc的一个缺陷(Issue 22586)和限制(Issue 78035)，我们考虑是否可以人工对DEX的拆分进行干预，使每个DEX的大小在一定的合理范围内，这样就减少触发Dalvik linearAlloc的缺陷和限制； 为了实现这几个目的，我们需要解决下面三个问题：</p>
<p>在打包过程中如何产生多个的DEX包？<br>如果做到动态加载，怎么决定哪些DEX动态加载呢？<br>如果启动后在工作线程中做动态加载，如果没有加载完而用户进行页面操作需要使用到动态加载DEX中的class怎么办？<br>我们首先来分析如何解决第一个问题，在使用MultiDex方案时，我们知道BuildTool会自动把代码进行拆成多个DEX包，并且可以通过配置文件来控制哪些代码放到第一个DEX包中， 下图是Android的打包流程示意图：<br><img src="http://tech.meituan.com/img/mt_android_auto_split_dex/android_packaging.png" alt=""></p>
<p>为了实现产生多个DEX包，我们可以在生成DEX文件的这一步中， 在Ant或gradle中自定义一个Task来干预DEX产生的过程，从而产生多个DEX，下图是在ant和gradle中干预产生DEX的自定task的截图:<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">tasks.whenTaskAdded &#123; <span class="keyword">task</span> -&gt;</div><div class="line">    <span class="keyword">if</span> (<span class="keyword">task</span>.name.startsWith(<span class="string">'proguard'</span>) &amp;&amp; (<span class="keyword">task</span>.name.endsWith(<span class="string">'Debug'</span>) || <span class="keyword">task</span>.name.endsWith(<span class="string">'Release'</span>))) &#123;</div><div class="line">        <span class="keyword">task</span>.<span class="keyword">doLast</span> &#123;</div><div class="line">            makeDexFileAfterProguardJar();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">task</span>.<span class="keyword">doFirst</span> &#123;</div><div class="line">            <span class="keyword">delete</span> <span class="string">"$&#123;project.buildDir&#125;/intermediates/classes-proguard"</span>;</div><div class="line"></div><div class="line">            String flavor = <span class="keyword">task</span>.name.substring(<span class="string">'proguard'</span>.length(), <span class="keyword">task</span>.name.lastIndexOf(<span class="keyword">task</span>.name.endsWith(<span class="string">'Debug'</span>) ? <span class="string">"Debug"</span> : <span class="string">"Release"</span>));</div><div class="line">            generateMainIndexKeepList(flavor.toLowerCase());</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">task</span>.name.startsWith(<span class="string">'zipalign'</span>) &amp;&amp; (<span class="keyword">task</span>.name.endsWith(<span class="string">'Debug'</span>) || <span class="keyword">task</span>.name.endsWith(<span class="string">'Release'</span>))) &#123;</div><div class="line">        <span class="keyword">task</span>.<span class="keyword">doFirst</span> &#123;</div><div class="line">            ensureMultiDexInApk();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上一步解决了如何打包出多个DEX的问题了，那我们该怎么该根据什么来决定哪些class放到Main DEX，哪些放到Secondary DEX呢（这里的Main DEX是指在2.1版本的Dalvik VM之前由android系统在启动apk时自己主动加载的Classes.dex，而Secondary DEX是指需要我们自己安装进去的DEX，例如：Classes2.dex, Classes3.dex等）， 这个需要分析出放到Main DEX中的class依赖，需要确保把Main DEX中class所有的依赖都要放进来，否则在启动时会发生ClassNotFoundException, 这里我们的方案是把Service、Receiver、Provider涉及到的代码都放到Main DEX中，而把Activity涉及到的代码进行了一定的拆分，把首页Activity、Laucher Activity、欢迎页的Activity、城市列表页Activity等所依赖的class放到了Main DEX中，把二级、三级页面的Activity以及业务频道的代码放到了Secondary DEX中，为了减少人工分析class的依赖所带了的不可维护性和高风险性，我们编写了一个能够自动分析Class依赖的脚本， 从而能够保证Main DEX包含class以及他们所依赖的所有class都在其内，这样这个脚本就会在打包之前自动分析出启动到Main DEX所涉及的所有代码，保证Main DEX运行正常。</p>
<p>随着第二个问题的迎刃而解，我们来到了比较棘手的第三问题，如果我们在后台加载Secondary DEX过程中，用户点击界面将要跳转到使用了在Secondary DEX中class的界面， 那此时必然发生ClassNotFoundException, 那怎么解决这个问题呢，在所有的Activity跳转代码处添加判断Secondary DEX是否加载完成？这个方法可行，但工作量非常大； 那有没有更好的解决方案呢？我们通过分析Activity的启动过程，发现Activity是由ActivityThread 通过Instrumentation来启动的，我们是否可以在Instrumentation中做一定的手脚呢？通过分析代码ActivityThread和Instrumentation发现，Instrumentation有关Activity启动相关的方法大概有：execStartActivity、newActivity等等，这样我们就可以在这些方法中添加代码逻辑进行判断这个Class是否加载了，如果加载则直接启动这个Activity，如果没有加载完成则启动一个等待的Activity显示给用户，然后在这个Activity中等待后台Secondary DEX加载完成，完成后自动跳转到用户实际要跳转的Activity；这样在代码充分解耦合，以及每个业务代码能够做到颗粒化的前提下，我们就做到Secondary DEX的按需加载了， 下面是Instrumentation添加的部分关键代码：<br><figure class="highlight haxe"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> ActivityResult execStartActivity(Context who, IBinder contextThread, IBinder token, Activity target,</div><div class="line">                                        Intent intent, int requestCode) &#123;</div><div class="line">    ActivityResult activityResult = <span class="literal">null</span>;</div><div class="line">    <span class="keyword">String</span> className;</div><div class="line">    <span class="keyword">if</span> (intent.getComponent() != <span class="literal">null</span>) &#123;</div><div class="line">        className = intent.getComponent().getClassName();</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        ResolveInfo resolveActivity = who.getPackageManager().resolveActivity(intent, <span class="number">0</span>);</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (resolveActivity != <span class="literal">null</span> &amp;&amp; resolveActivity.activityInfo != <span class="literal">null</span>) &#123;</div><div class="line">            className = resolveActivity.activityInfo.name;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            className = <span class="literal">null</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!TextUtils.isEmpty(className)) &#123;</div><div class="line">        boolean shouldInterrupted = !MeituanApplication.isDexAvailable();</div><div class="line">        <span class="keyword">if</span> (MeituanApplication.sIsDexAvailable.<span class="keyword">get</span>() || mByPassActivityClassNameList.contains(className)) &#123;</div><div class="line">            shouldInterrupted = <span class="literal">false</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (shouldInterrupted) &#123;</div><div class="line">            Intent interruptedIntent = <span class="keyword">new</span> <span class="type">Intent</span>(mContext, WaitingActivity.class);</div><div class="line"></div><div class="line">            activityResult = execStartActivity(who, contextThread, token, target, interruptedIntent, requestCode);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            activityResult = execStartActivity(who, contextThread, token, target, intent, requestCode);</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        activityResult = execStartActivity(who, contextThread, token, target, intent, requestCode);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> activityResult;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> Activity <span class="keyword">new</span><span class="type">Activity</span>(Class&lt;?&gt; clazz, Context context, IBinder token,</div><div class="line">                            Application application, Intent intent, ActivityInfo info,</div><div class="line">                            CharSequence title, Activity parent, <span class="keyword">String</span> id, Object lastNonConfigurationInstance)</div><div class="line">        throws InstantiationException, IllegalAccessException &#123;</div><div class="line"></div><div class="line">    <span class="keyword">String</span> className = <span class="string">""</span>;</div><div class="line">    Activity <span class="keyword">new</span><span class="type">Activity</span> = <span class="literal">null</span>;</div><div class="line">    <span class="keyword">if</span> (intent.getComponent() != <span class="literal">null</span>) &#123;</div><div class="line">        className = intent.getComponent().getClassName();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    boolean shouldInterrupted = !MeituanApplication.isDexAvailable();</div><div class="line">    <span class="keyword">if</span> (MeituanApplication.sIsDexAvailable.<span class="keyword">get</span>() || mByPassActivityClassNameList.contains(className)) &#123;</div><div class="line">        shouldInterrupted = <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (shouldInterrupted) &#123;</div><div class="line">        intent = <span class="keyword">new</span> <span class="type">Intent</span>(mContext, WaitingActivity.class);</div><div class="line">        <span class="keyword">new</span><span class="type">Activity</span> = mBase.<span class="keyword">new</span><span class="type">Activity</span>(clazz, context, token,</div><div class="line">                application, intent, info, title, parent, id,</div><div class="line">                lastNonConfigurationInstance);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">new</span><span class="type">Activity</span> = mBase.<span class="keyword">new</span><span class="type">Activity</span>(clazz, context, token,</div><div class="line">                application, intent, info, title, parent, id,</div><div class="line">                lastNonConfigurationInstance);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span><span class="type">Activity</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>实际应用中我们还遇到另外一个比较棘手的问题， 就是Field的过多的问题，Field过多是由我们目前采用的代码组织结构引入的，我们为了方便多业务线、多团队并发协作的情况下开发，我们采用的aar的方式进行开发，并同时在aar依赖链的最底层引入了一个通用业务aar，而这个通用业务aar中包含了很多资源，而ADT14以及更高的版本中对Library资源处理时，Library的R资源不再是static final的了，详情请查看google官方说明，这样在最终打包时Library中的R没法做到内联，这样带来了R field过多的情况，导致需要拆分多个Secondary DEX，为了解决这个问题我们采用的是在打包过程中利用脚本把Libray中R field（例如ID、Layout、Drawable等）的引用替换成常量，然后删去Library中R.class中的相应Field。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面就是我们在使用MultiDex过程中进化而来的DEX自动化拆包的方案， 这样我们就可以通过脚本控制来进行自动化的拆分DEX，然后在运行时自由的加载Secondary DEX，既能保证冷启动速度，又能减少运行时的内存占用。</p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/mt-android-auto-split-dex.html&quot;&gt;美团Android DEX自动拆包及动态加载简介&lt;/a&gt;&lt;br&gt;jianshuai xiaoyang ·2015-06-15 10:00&lt;/p&gt;
&lt;p&gt;概述&lt;/p&gt;
&lt;p&gt;作为一个android开发者，在开发应用时，随着业务规模发展到一定程度，不断地加入新功能、添加新的类库，代码在急剧的膨胀，相应的apk包的大小也急剧增加， 那么终有一天，你会不幸遇到这个错误：&lt;/p&gt;
&lt;p&gt;生成的apk在android 2.3或之前的机器上无法安装，提示INSTALL_FAILED_DEXOPT&lt;br&gt;方法数量过多，编译时出错，提示：&lt;br&gt; Conversion to Dalvik format failed:Unable to execute dex: method ID not in [0, 0xffff]: 65536&lt;/p&gt;
&lt;p&gt;而问题产生的具体原因如下：&lt;/p&gt;
&lt;p&gt;无法安装（Android 2.3 INSTALL_FAILED_DEXOPT）问题，是由dexopt的LinearAlloc限制引起的，在Android版本不同分别经历了4M/5M/8M/16M限制，目前主流4.2.x系统上可能都已到16M， 在Gingerbread或者以下系统LinearAllocHdr分配空间只有5M大小的， 高于Gingerbread的系统提升到了8M。Dalvik linearAlloc是一个固定大小的缓冲区。在应用的安装过程中，系统会运行一个名为dexopt的程序为该应用在当前机型中运行做准备。dexopt使用LinearAlloc来存储应用的方法信息。Android 2.2和2.3的缓冲区只有5MB，Android 4.x提高到了8MB或16MB。当方法数量过多导致超出缓冲区大小时，会造成dexopt崩溃。&lt;/p&gt;
&lt;p&gt;超过最大方法数限制的问题，是由于DEX文件格式限制，一个DEX文件中method个数采用使用原生类型short来索引文件中的方法，也就是4个字节共计最多表达65536个method，field/class的个数也均有此限制。对于DEX文件，则是将工程所需全部class文件合并且压缩到一个DEX文件期间，也就是Android打包的DEX过程中， 单个DEX文件可被引用的方法总数（自己开发的代码以及所引用的Android框架、类库的代码）被限制为65536；&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>MySQL索引原理及慢查询优化</title>
    <link href="http://ipcreator.me/2017/02/26/Program/Concepts/the-essence-of-mysql-index/"/>
    <id>http://ipcreator.me/2017/02/26/Program/Concepts/the-essence-of-mysql-index/</id>
    <published>2017-02-26T13:27:05.000Z</published>
    <updated>2017-02-27T05:40:54.717Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tech.meituan.com/mysql-index.html" target="_blank" rel="external">NeverMore</a></p>
<p>MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能够更好的使用它，已经成为开发工程师的必修课，我们经常会从职位描述上看到诸如“精通MySQL”、“SQL语句优化”、“了解数据库原理”等要求。我们知道一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，所以查询语句的优化显然是重中之重。</p>
<p>本人从13年7月份起，一直在美团核心业务系统部做慢查询的优化工作，共计十余个系统，累计解决和积累了上百个慢查询案例。随着业务的复杂性提升，遇到的问题千奇百怪，五花八门，匪夷所思。本文旨在以开发工程师的角度来解释数据库索引的原理和如何优化慢查询。</p>
   <a id="more"></a>
<p>一个慢查询引发的思考<br>select<br>   count(*)<br>from<br>   task<br>where<br>   status=2<br>   and operator_id=20839<br>   and operate_time&gt;1371169729<br>   and operate_time&lt;1371174603<br>   and type=2;<br>系统使用者反应有一个功能越来越慢，于是工程师找到了上面的SQL。<br>并且兴致冲冲的找到了我，“这个SQL需要优化，给我把每个字段都加上索引”<br>我很惊讶，问道“为什么需要每个字段都加上索引？”<br>“把查询的字段都加上索引会更快”工程师信心满满<br>“这种情况完全可以建一个联合索引，因为是最左前缀匹配，所以operate_time需要放到最后，而且还需要把其他相关的查询都拿来，需要做一个综合评估。”<br>“联合索引？最左前缀匹配？综合评估？”工程师不禁陷入了沉思。<br>多数情况下，我们知道索引能够提高查询效率，但应该如何建立索引？索引的顺序如何？许多人却只知道大概。其实理解这些概念并不难，而且索引的原理远没有想象的那么复杂。</p>
<p>MySQL索引原理</p>
<p>##索引目的<br>索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？</p>
<p>##索引原理<br>除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。<br>数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。</p>
<p>###磁盘IO与预读<br>前面提到了访问磁盘，那么这里先简单介绍一下磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。下图是计算机硬件延迟的对比图，供大家参考：<br>various-system-software-hardware-latencies<br>考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。</p>
<p>###索引的数据结构<br>前面讲了生活中索引的例子，索引的基本原理，数据库的复杂性，又讲了操作系统的相关知识，目的就是让大家了解，任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。</p>
<p>###详解b+树<br>b+树<br>如上图，是一颗b+树，关于b+树的定义可以参见B+树，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。</p>
<p>###b+树的查找过程<br>如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。</p>
<p>###b+树性质<br>1.通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。<br>2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。</p>
<p>慢查询优化<br>关于MySQL索引原理是比较枯燥的东西，大家只需要有一个感性的认识，并不需要理解得非常透彻和深入。我们回头来看看一开始我们说的慢查询，了解完索引原理之后，大家是不是有什么想法呢？先总结一下索引的几大基本原则</p>
<p>建索引的几大原则<br>1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。<br>2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式<br>3.尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录<br>4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);<br>5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可</p>
<p>回到开始的慢查询<br>根据最左匹配原则，最开始的sql语句的索引应该是status、operator_id、type、operate_time的联合索引；其中status、operator_id、type的顺序可以颠倒，所以我才会说，把这个表的所有相关查询都找到，会综合分析；<br>比如还有如下查询</p>
<p>select <em> from task where status = 0 and type = 12 limit 10;<br>select count(</em>) from task where status = 0 ;<br>那么索引建立成(status,type,operator_id,operate_time)就是非常正确的，因为可以覆盖到所有情况。这个就是利用了索引的最左匹配的原则</p>
<p>查询优化神器 - explain命令<br>关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网explain-output，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。</p>
<p>慢查询优化基本步骤<br>0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE<br>1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高<br>2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）<br>3.order by limit 形式的sql语句让排序的表优先查<br>4.了解业务方使用场景<br>5.加索引时参照建索引的几大原则<br>6.观察结果，不符合预期继续从0分析</p>
<p>几个慢查询案例<br>下面几个例子详细解释了如何分析和优化慢查询</p>
<p>复杂语句写法<br>很多情况下，我们写SQL只是为了实现功能，这只是第一步，不同的语句书写方式对于效率往往有本质的差别，这要求我们对mysql的执行计划和索引原则有非常清楚的认识，请看下面的语句</p>
<p>select<br>   distinct cert.emp_id<br>from<br>   cm_log cl<br>inner join<br>   (<br>      select<br>         emp.id as emp_id,<br>         emp_cert.id as cert_id<br>      from<br>         employee emp<br>      left join<br>         emp_certificate emp_cert<br>            on emp.id = emp_cert.emp_id<br>      where<br>         emp.is_deleted=0<br>   ) cert<br>      on (<br>         cl.ref_table=’Employee’<br>         and cl.ref_oid= cert.emp_id<br>      )<br>      or (<br>         cl.ref_table=’EmpCertificate’<br>         and cl.ref_oid= cert.cert_id<br>      )<br>where<br>   cl.last_upd_date &gt;=’2013-11-07 15:03:00’<br>   and cl.last_upd_date&lt;=’2013-11-08 16:00:00’;<br>0.先运行一下，53条记录 1.87秒，又没有用聚合语句，比较慢</p>
<p>53 rows in set (1.87 sec)<br>1.explain</p>
<p>+—-+————-+————+——-+———————————+———————–+———+——————-+——-+——————————–+<br>| id | select_type | table      | type  | possible_keys                   | key                   | key_len | ref               | rows  | Extra                          |<br>+—-+————-+————+——-+———————————+———————–+———+——————-+——-+——————————–+<br>|  1 | PRIMARY     | cl         | range | cm_log_cls_id,idx_last_upd_date | idx_last_upd_date     | 8       | NULL              |   379 | Using where; Using temporary   |<br>|  1 | PRIMARY     | <derived2> | ALL   | NULL                            | NULL                  | NULL    | NULL              | 63727 | Using where; Using join buffer |<br>|  2 | DERIVED     | emp        | ALL   | NULL                            | NULL                  | NULL    | NULL              | 13317 | Using where                    |<br>|  2 | DERIVED     | emp_cert   | ref   | emp_certificate_empid           | emp_certificate_empid | 4       | meituanorg.emp.id |     1 | Using index                    |<br>+—-+————-+————+——-+———————————+———————–+———+——————-+——-+——————————–+<br>简述一下执行计划，首先mysql根据idx_last_upd_date索引扫描cm_log表获得379条记录；然后查表扫描了63727条记录，分为两部分，derived表示构造表，也就是不存在的表，可以简单理解成是一个语句形成的结果集，后面的数字表示语句的ID。derived2表示的是ID = 2的查询构造了虚拟表，并且返回了63727条记录。我们再来看看ID = 2的语句究竟做了写什么返回了这么大量的数据，首先全表扫描employee表13317条记录，然后根据索引emp_certificate_empid关联emp_certificate表，rows = 1表示，每个关联都只锁定了一条记录，效率比较高。获得后，再和cm_log的379条记录根据规则关联。从执行过程上可以看出返回了太多的数据，返回的数据绝大部分cm_log都用不到，因为cm_log只锁定了379条记录。<br>如何优化呢？可以看到我们在运行完后还是要和cm_log做join,那么我们能不能之前和cm_log做join呢？仔细分析语句不难发现，其基本思想是如果cm_log的ref_table是EmpCertificate就关联emp_certificate表，如果ref_table是Employee就关联employee表，我们完全可以拆成两部分，并用union连接起来，注意这里用union，而不用union all是因为原语句有“distinct”来得到唯一的记录，而union恰好具备了这种功能。如果原语句中没有distinct不需要去重，我们就可以直接使用union all了，因为使用union需要去重的动作，会影响SQL性能。<br>优化过的语句如下</derived2></p>
<p>select<br>   emp.id<br>from<br>   cm_log cl<br>inner join<br>   employee emp<br>      on cl.ref_table = ‘Employee’<br>      and cl.ref_oid = emp.id<br>where<br>   cl.last_upd_date &gt;=’2013-11-07 15:03:00’<br>   and cl.last_upd_date&lt;=’2013-11-08 16:00:00’<br>   and emp.is_deleted = 0<br>union<br>select<br>   emp.id<br>from<br>   cm_log cl<br>inner join<br>   emp_certificate ec<br>      on cl.ref_table = ‘EmpCertificate’<br>      and cl.ref_oid = ec.id<br>inner join<br>   employee emp<br>      on emp.id = ec.emp_id<br>where<br>   cl.last_upd_date &gt;=’2013-11-07 15:03:00’<br>   and cl.last_upd_date&lt;=’2013-11-08 16:00:00’<br>   and emp.is_deleted = 0<br>4.不需要了解业务场景，只需要改造的语句和改造之前的语句保持结果一致</p>
<p>5.现有索引可以满足，不需要建索引</p>
<p>6.用改造后的语句实验一下，只需要10ms 降低了近200倍！</p>
<p>+—-+————–+————+——–+———————————+——————-+———+———————–+——+————-+<br>| id | select_type  | table      | type   | possible_keys                   | key               | key_len | ref                   | rows | Extra       |<br>+—-+————–+————+——–+———————————+——————-+———+———————–+——+————-+<br>|  1 | PRIMARY      | cl         | range  | cm_log_cls_id,idx_last_upd_date | idx_last_upd_date | 8       | NULL                  |  379 | Using where |<br>|  1 | PRIMARY      | emp        | eq_ref | PRIMARY                         | PRIMARY           | 4       | meituanorg.cl.ref_oid |    1 | Using where |<br>|  2 | UNION        | cl         | range  | cm_log_cls_id,idx_last_upd_date | idx_last_upd_date | 8       | NULL                  |  379 | Using where |<br>|  2 | UNION        | ec         | eq_ref | PRIMARY,emp_certificate_empid   | PRIMARY           | 4       | meituanorg.cl.ref_oid |    1 |             |<br>|  2 | UNION        | emp        | eq_ref | PRIMARY                         | PRIMARY           | 4       | meituanorg.ec.emp_id  |    1 | Using where |<br>| NULL | UNION RESULT | <union1,2> | ALL    | NULL                            | NULL              | NULL    | NULL                  | NULL |             |<br>+—-+————–+————+——–+———————————+——————-+———+———————–+——+————-+<br>53 rows in set (0.01 sec)<br>明确应用场景<br>举这个例子的目的在于颠覆我们对列的区分度的认知，一般上我们认为区分度越高的列，越容易锁定更少的记录，但在一些特殊的情况下，这种理论是有局限性的</union1,2></p>
<p>select<br>   *<br>from<br>   stage_poi sp<br>where<br>   sp.accurate_result=1<br>   and (<br>      sp.sync_status=0<br>      or sp.sync_status=2<br>      or sp.sync_status=4<br>   );<br>0.先看看运行多长时间,951条数据6.22秒，真的很慢</p>
<p>951 rows in set (6.22 sec)<br>1.先explain，rows达到了361万，type = ALL表明是全表扫描</p>
<p>+—-+————-+——-+——+—————+——+———+——+———+————-+<br>| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows    | Extra       |<br>+—-+————-+——-+——+—————+——+———+——+———+————-+<br>|  1 | SIMPLE      | sp    | ALL  | NULL          | NULL | NULL    | NULL | 3613155 | Using where |<br>+—-+————-+——-+——+—————+——+———+——+———+————-+<br>2.所有字段都应用查询返回记录数，因为是单表查询 0已经做过了951条</p>
<p>3.让explain的rows 尽量逼近951</p>
<p>看一下accurate_result = 1的记录数</p>
<p>select count(<em>),accurate_result from stage_poi  group by accurate_result;<br>+———-+—————–+<br>| count(</em>) | accurate_result |<br>+———-+—————–+<br>|     1023 |              -1 |<br>|  2114655 |               0 |<br>|   972815 |               1 |<br>+———-+—————–+<br>我们看到accurate_result这个字段的区分度非常低，整个表只有-1,0,1三个值，加上索引也无法锁定特别少量的数据</p>
<p>再看一下sync_status字段的情况</p>
<p>select count(<em>),sync_status from stage_poi  group by sync_status;<br>+———-+————-+<br>| count(</em>) | sync_status |<br>+———-+————-+<br>|     3080 |           0 |<br>|  3085413 |           3 |<br>+———-+————-+<br>同样的区分度也很低，根据理论，也不适合建立索引</p>
<p>问题分析到这，好像得出了这个表无法优化的结论，两个列的区分度都很低，即便加上索引也只能适应这种情况，很难做普遍性的优化，比如当sync_status 0、3分布的很平均，那么锁定记录也是百万级别的</p>
<p>4.找业务方去沟通，看看使用场景。业务方是这么来使用这个SQL语句的，每隔五分钟会扫描符合条件的数据，处理完成后把sync_status这个字段变成1,五分钟符合条件的记录数并不会太多，1000个左右。了解了业务方的使用场景后，优化这个SQL就变得简单了，因为业务方保证了数据的不平衡，如果加上索引可以过滤掉绝大部分不需要的数据</p>
<p>5.根据建立索引规则，使用如下语句建立索引</p>
<p>alter table stage_poi add index idx_acc_status(accurate_result,sync_status);<br>6.观察预期结果,发现只需要200ms，快了30多倍。</p>
<p>952 rows in set (0.20 sec)<br>我们再来回顾一下分析问题的过程，单表查询相对来说比较好优化，大部分时候只需要把where条件里面的字段依照规则加上索引就好，如果只是这种“无脑”优化的话，显然一些区分度非常低的列，不应该加索引的列也会被加上索引，这样会对插入、更新性能造成严重的影响，同时也有可能影响其它的查询语句。所以我们第4步调差SQL的使用场景非常关键，我们只有知道这个业务场景，才能更好地辅助我们更好的分析和优化查询语句。</p>
<p>无法优化的语句<br>select<br>   c.id,<br>   c.name,<br>   c.position,<br>   c.sex,<br>   c.phone,<br>   c.office_phone,<br>   c.feature_info,<br>   c.birthday,<br>   c.creator_id,<br>   c.is_keyperson,<br>   c.giveup_reason,<br>   c.status,<br>   c.data_source,<br>   from_unixtime(c.created_time) as created_time,<br>   from_unixtime(c.last_modified) as last_modified,<br>   c.last_modified_user_id<br>from<br>   contact c<br>inner join<br>   contact_branch cb<br>      on  c.id = cb.contact_id<br>inner join<br>   branch_user bu<br>      on  cb.branch_id = bu.branch_id<br>      and bu.status in (<br>         1,<br>      2)<br>   inner join<br>      org_emp_info oei<br>         on  oei.data_id = bu.user_id<br>         and oei.node_left &gt;= 2875<br>         and oei.node_right &lt;= 10802<br>         and oei.org_category = - 1<br>   order by<br>      c.created_time desc  limit 0 ,<br>      10;<br>还是几个步骤<br>0.先看语句运行多长时间，10条记录用了13秒，已经不可忍受</p>
<p>10 rows in set (13.06 sec)<br>1.explain</p>
<p>+—-+————-+——-+——–+————————————-+————————-+———+————————–+——+———————————————-+<br>| id | select_type | table | type   | possible_keys                       | key                     | key_len | ref                      | rows | Extra                                        |<br>+—-+————-+——-+——–+————————————-+————————-+———+————————–+——+———————————————-+<br>|  1 | SIMPLE      | oei   | ref    | idx_category_left_right,idx_data_id | idx_category_left_right | 5       | const                    | 8849 | Using where; Using temporary; Using filesort |<br>|  1 | SIMPLE      | bu    | ref    | PRIMARY,idx_userid_status           | idx_userid_status       | 4       | meituancrm.oei.data_id   |   76 | Using where; Using index                     |<br>|  1 | SIMPLE      | cb    | ref    | idx_branch_id,idx_contact_branch_id | idx_branch_id           | 4       | meituancrm.bu.branch_id  |    1 |                                              |<br>|  1 | SIMPLE      | c     | eq_ref | PRIMARY                             | PRIMARY                 | 108     | meituancrm.cb.contact_id |    1 |                                              |<br>+—-+————-+——-+——–+————————————-+————————-+———+————————–+——+———————————————-+<br>从执行计划上看，mysql先查org_emp_info表扫描8849记录，再用索引idx_userid_status关联branch_user表，再用索引idx_branch_id关联contact_branch表，最后主键关联contact表。<br>rows返回的都非常少，看不到有什么异常情况。我们在看一下语句，发现后面有order by + limit组合，会不会是排序量太大搞的？于是我们简化SQL，去掉后面的order by 和 limit，看看到底用了多少记录来排序</p>
<p>select<br>  count(<em>)<br>from<br>   contact c<br>inner join<br>   contact_branch cb<br>      on  c.id = cb.contact_id<br>inner join<br>   branch_user bu<br>      on  cb.branch_id = bu.branch_id<br>      and bu.status in (<br>         1,<br>      2)<br>   inner join<br>      org_emp_info oei<br>         on  oei.data_id = bu.user_id<br>         and oei.node_left &gt;= 2875<br>         and oei.node_right &lt;= 10802<br>         and oei.org_category = - 1<br>+———-+<br>| count(</em>) |<br>+———-+<br>|   778878 |<br>+———-+<br>1 row in set (5.19 sec)<br>发现排序之前居然锁定了778878条记录，如果针对70万的结果集排序，将是灾难性的，怪不得这么慢，那我们能不能换个思路，先根据contact的created_time排序，再来join会不会比较快呢？<br>于是改造成下面的语句，也可以用straight_join来优化<br>select<br>c.id,<br>c.name,<br>c.position,<br>c.sex,<br>c.phone,<br>c.office_phone,<br>c.feature_info,<br>c.birthday,<br>c.creator_id,<br>c.is_keyperson,<br>c.giveup_reason,<br>c.status,<br>c.data_source,<br>from_unixtime(c.created_time) as created_time,<br>from_unixtime(c.last_modified) as last_modified,<br>c.last_modified_user_id<br>from<br>contact c<br>where<br>exists (<br>select<br>1<br>from<br>contact_branch cb<br>inner join<br>branch_user bu<br>on cb.branch_id = bu.branch_id<br>and bu.status in (<br>1,<br>2)<br>inner join<br>org_emp_info oei<br>on oei.data_id = bu.user_id<br>and oei.node_left &gt;= 2875<br>and oei.node_right &lt;= 10802<br>and oei.org_category = - 1<br>where<br>c.id = cb.contact_id<br>)<br>order by<br>c.created_time desc limit 0 ,<br>10;</p>
<p>验证一下效果 预计在1ms内，提升了13000多倍！<br>```sql<br>10 rows in set (0.00 sec)<br>本以为至此大工告成，但我们在前面的分析中漏了一个细节，先排序再join和先join再排序理论上开销是一样的，为何提升这么多是因为有一个limit！大致执行过程是：mysql先按索引排序得到前10条记录，然后再去join过滤，当发现不够10条的时候，再次去10条，再次join，这显然在内层join过滤的数据非常多的时候，将是灾难的，极端情况，内层一条数据都找不到，mysql还傻乎乎的每次取10条，几乎遍历了这个数据表！<br>用不同参数的SQL试验下</p>
<p>select<br>   sql_no_cache   c.id,<br>   c.name,<br>   c.position,<br>   c.sex,<br>   c.phone,<br>   c.office_phone,<br>   c.feature_info,<br>   c.birthday,<br>   c.creator_id,<br>   c.is_keyperson,<br>   c.giveup_reason,<br>   c.status,<br>   c.data_source,<br>   from_unixtime(c.created_time) as created_time,<br>   from_unixtime(c.last_modified) as last_modified,<br>   c.last_modified_user_id<br>from<br>   contact c<br>where<br>   exists (<br>      select<br>         1<br>      from<br>         contact_branch cb<br>      inner join<br>         branch_user bu<br>            on  cb.branch_id = bu.branch_id<br>            and bu.status in (<br>               1,<br>            2)<br>         inner join<br>            org_emp_info oei<br>               on  oei.data_id = bu.user_id<br>               and oei.node_left &gt;= 2875<br>               and oei.node_right &lt;= 2875<br>               and oei.org_category = - 1<br>         where<br>            c.id = cb.contact_id<br>      )<br>   order by<br>      c.created_time desc  limit 0 ,<br>      10;<br>Empty set (2 min 18.99 sec)<br>2 min 18.99 sec！比之前的情况还糟糕很多。由于mysql的nested loop机制，遇到这种情况，基本是无法优化的。这条语句最终也只能交给应用系统去优化自己的逻辑了。<br>通过这个例子我们可以看到，并不是所有语句都能优化，而往往我们优化时，由于SQL用例回归时落掉一些极端情况，会造成比原来还严重的后果。所以，第一：不要指望所有语句都能通过SQL优化，第二：不要过于自信，只针对具体case来优化，而忽略了更复杂的情况。</p>
<p>慢查询的案例就分析到这儿，以上只是一些比较典型的案例。我们在优化过程中遇到过超过1000行，涉及到16个表join的“垃圾SQL”，也遇到过线上线下数据库差异导致应用直接被慢查询拖死，也遇到过varchar等值比较没有写单引号，还遇到过笛卡尔积查询直接把从库搞死。再多的案例其实也只是一些经验的积累，如果我们熟悉查询优化器、索引的内部原理，那么分析这些案例就变得特别简单了。</p>
<p>写在后面的话<br>本文以一个慢查询案例引入了MySQL索引原理、优化慢查询的一些方法论;并针对遇到的典型案例做了详细的分析。其实做了这么长时间的语句优化后才发现，任何数据库层面的优化都抵不上应用系统的优化，同样是MySQL，可以用来支撑Google/FaceBook/Taobao应用，但可能连你的个人网站都撑不住。套用最近比较流行的话：“查询容易，优化不易，且写且珍惜！”</p>
<p>参考<br>参考文献如下：<br>1.《高性能MySQL》<br>2.《数据结构与算法分析》</p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：</p>
<p>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/mysql-index.html&quot;&gt;NeverMore&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能够更好的使用它，已经成为开发工程师的必修课，我们经常会从职位描述上看到诸如“精通MySQL”、“SQL语句优化”、“了解数据库原理”等要求。我们知道一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，所以查询语句的优化显然是重中之重。&lt;/p&gt;
&lt;p&gt;本人从13年7月份起，一直在美团核心业务系统部做慢查询的优化工作，共计十余个系统，累计解决和积累了上百个慢查询案例。随着业务的复杂性提升，遇到的问题千奇百怪，五花八门，匪夷所思。本文旨在以开发工程师的角度来解释数据库索引的原理和如何优化慢查询。&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Android Support Library的前世今生</title>
    <link href="http://ipcreator.me/2017/02/26/Program/Android/history-of-v4-and-v7/"/>
    <id>http://ipcreator.me/2017/02/26/Program/Android/history-of-v4-and-v7/</id>
    <published>2017-02-26T10:16:06.000Z</published>
    <updated>2017-02-26T10:30:02.284Z</updated>
    
    <content type="html"><![CDATA[<p>原文作者：<a href="http://www.jianshu.com/p/f5f9a4fd22e8" target="_blank" rel="external">都有米</a></p>
<p><img src="http://upload-images.jianshu.io/upload_images/1621638-64e0312fb3d79864.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>在之前的开发经历中经常需要导入一些如v4、v7、v13等Android官方的支持包，遇到这些情况时都是网上搜索一下，按照前人给的示例添加依赖。这么稀里糊涂的使用后代码正常运行了，但心中不免会有一些疑问，如，Android官方为什么要提供支持包，都提供哪些支持包，这些支持包又提供了什么特性，开发者又应该如何选择使用这些支持包？</p>
<p>为了解开这些疑问，周末在家仔细阅读了官方的开发者指导文档的相关内容。这篇文章就是读后整理的读书笔记。</p>
 <a id="more"></a>
<h2 id="Android官方为什么要提供支持包？"><a href="#Android官方为什么要提供支持包？" class="headerlink" title="Android官方为什么要提供支持包？"></a>Android官方为什么要提供支持包？</h2><p>为什么官方向开发者在提供了android sdk之外，还要提供一些零碎的开发支持jar包，全部放在framework中不好吗？恩，不好！因为这不是好不好的问题，这是Android平台快速发展带来的必然产物，这张图罗列了已经发布的Android版本及其对应的开发sdk的级别。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1621638-ab90ba556333d9a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>至于为什么提供支持包官方给出了大致三个原因：</p>
<p><strong>1、向后兼容</strong><br>如，我们开的App需要支持的minSdkVersion=9，targetSdkVersion=11，在程序里使用了android 3.0 (API level 11)提供的ActionBar类，使用compileSdkVersion=11成功编译出apk。在android 3.0的设备上完美运行，但是app在android 2.3的设备就会crash，报找不到ActionBar的错误。这很好理解，因为旧版本上没有新版本里新增的类。为了避免使用了最新功能开发的app只能在最新系统的设备上运行的尴尬，<strong>官方把新版系统framework中新增加的接口提出来放到了Android Support Library（支持包）中，开发者在遇到上面的情况时，就可以使用支持包中具有同样功能的ActionBar类，这个支持包会打包进App里，这样使用了新版本系统上功能的App也可以向后兼容以前的老系统版本设备了。</strong></p>
<p>使用支持包中的类除了让我们免于判断App运行的系统版本外，还可以使App在各个版本保持同样的用户体验。如在5.0以下系统使用material design。</p>
<p>App编译时用的android sdk（android.jar）不会打包进我们的App中。因为App编码是使用android.jar中的接口就是android设备里系统框架层（framework）对外提供的接口。</p>
<p><strong>2、提供不适合打包进framework的功能</strong><br>Android官方对App开发提供了推荐设计，希望Android应用都有相对一致的交互设计来减少用户的使用成本，希望三方App类似系统应用从而完美融入到Android生态系统中。但是这都仅仅是推荐，不要求开发者一定要这样，如果有这种需求就可以使用官方支持包提供的这些功能，避免重复造轮子。如支持包中的DrawerLayout、Snackbar等类都是这种情况。</p>
<p><strong>3、为了支持不同形态的设备</strong><br>通过使用支持包来在不同形态设备上提供功能，如手机、电视、可穿戴设备等。</p>
<h2 id="官方提供了哪些支持包，都有哪些特性？"><a href="#官方提供了哪些支持包，都有哪些特性？" class="headerlink" title="官方提供了哪些支持包，都有哪些特性？"></a>官方提供了哪些支持包，都有哪些特性？</h2><p>现在Android官方发布了下面13类支持库，不同的支持库包含不同特征，适用的Android版本也不相同。通常情况下我们都使用到v4和v7这两个集合库，因为这两个库支持的android系统版本范围比较广，官方推荐的UI设计样式相关类也都在这两集合库中。<br><img src="http://upload-images.jianshu.io/upload_images/1621638-1f66aafb225df824.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>【※】v4 Support Libraries</p>
<p>v4库被设计在Android 2.3 (API level 9)及其以上系统中使用。 Support Library的第1版（２０１１年３月发布）就只包含v4库，当时v4库只是一个库，支持Android 1.6 (API level 4)及其以上版本，这也是v4名字的由来。随着系统的迭代现在Android 1.6设备已经很少了，官方在Support Library的第24.2.0版本（２０１6年8月发布）的时候移除了对Android 2.2 (API level 8)及其以下版本的支持，但是名字依然是v4。v4悠久的历史长期的发展造就了它较大的体积。也是在24.2.0这个版本Goggle将原来的单个v4库拆分成了5个子库，我们在使用的时候可以直接依赖某个子库，从而减少依赖包的大小。下图可见Android 2.2 Froyo占有率约为0.1%。<br><img src="http://upload-images.jianshu.io/upload_images/1621638-8f78827ae6276c1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>Gradle编译脚本中整个v4库的依赖语句如下：</p>
<blockquote>
<p>compile ‘com.android.support:support-v4:24.2.1’</p>
</blockquote>
<p>gradle中jar依赖语句格式如 compile ‘jar文件组（group/命名空间）:jar文件名（name）:jar文件版本（version）’。所以上面的语句意思是依赖Android支持库中第24.2.1版的support-v4库。由于在24.2.0版本support-v4库已经被拆分成5个子库，所以如下图所示依赖24.2.1版本的support-v4库除了导入support-v4库外还会导入它的5个子库，这个版本的support-v4库本身是一个空的包，所有具体的实现都在它依赖的子库中。下面依次看下v4库拆分出来的5个子库。<br><img src="http://upload-images.jianshu.io/upload_images/1621638-e50b38383771e40c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>v4 compat library<br>为一些框架的API提供兼容性包装。如，Context.obtainDrawable()、View.performAccessibilityAction()等。<br>Gradle编译脚本中v4 compat库的依赖语句：</p>
<blockquote>
<p>compile ‘com.android.support:support-compat:24.2.1’</p>
</blockquote>
<p>v4 core-utils library<br>提供了一些工具类。如，AsyncTaskLoader、PermissionChecker等。<br>Gradle编译脚本中v4 core-utils库的依赖语句：</p>
<blockquote>
<p>compile ‘com.android.support:support-core-utils:24.2.1’</p>
</blockquote>
<p>v4 core-ui library<br>提供很多UI相关组件。如，ViewPager、NestedScrollView、ExploreByTouchHelper等。<br>Gradle编译脚本中v4 core-ui库的依赖语句：</p>
<blockquote>
<p>compile ‘com.android.support:support-core-ui:24.2.1’</p>
</blockquote>
<p>v4 media-compat library<br>多媒体框架相关部分。如，MediaBrowser、MediaSession等。<br>Gradle编译脚本中v4 media-compat库的依赖语句：</p>
<blockquote>
<p>compile ‘com.android.support:support-media-compat:24.2.1’</p>
</blockquote>
<p>v4 fragment library<br>跟fragment相关部分。v4这个子库依赖了其他4个子库，所以我们一旦依赖这个库就会自动导入其他4个子库，这跟直接依赖整个support-v4效果类似。关于v4拆分<a href="http://www.trinea.cn/android/android-%E6%9C%80%E6%96%B0-support-v4-%E5%8C%85%E5%A4%A7%E6%8B%86%E5%88%86%E6%9C%89%E7%94%A8%E5%90%97%EF%BC%9F/" target="_blank" rel="external">这篇文章</a>有介绍，有兴趣的可以点过去看看。<br>Gradle编译脚本中v4 fragment 库的依赖语句如下：</p>
<blockquote>
<p>compile ‘com.android.support:support-fragment:24.2.1’</p>
</blockquote>
<p>【※】v7 Support Libraries</p>
<p>注意这里的Library用的也是复数，说明v7库和v4一样也是很多库的集合，不同的是v7各个库不是后来拆分出来的，而是最初发布时就是以各个独立的库的形式发布的，如发布的最早的v7库v7 gridlayout library。这些库的共同之处是发布之初都是支持Android 2.1 (API level 7)及其以上版本，所以把他们统称为v7支持库。需要注意的24.2.0版本以后的v7支持库支持范围也是Android 2.3 (API level 9)及其以上版本了，这是因为v7依赖的v4库支持版本范围改变了，这点在v4支持库小节有介绍。v7库集合里有7个子库，使用时根据需要选择导入哪些库。</p>
<p>v7 appcompat library<br>支持UI设计样式、 material design相关，如ActionBar、AppCompatActivity、Theme等。<br>Gradle编译脚本中v7 appcompat库的依赖语句：</p>
<p>compile ‘com.android.support:appcompat-v7:24.2.1’<br>v7 cardview library<br>支持cardview控件，使用material design语言设计，卡片式的信息展示，在电视App中有广泛的使用。<br>Gradle编译脚本中v7 cardview库的依赖语句：</p>
<p>compile ‘com.android.support:cardview-v7:24.2.1’<br>v7 gridlayout library<br>支持gridlayout布局。<br>Gradle编译脚本中v7 gridlayout库的依赖语句：</p>
<p>compile ‘com.android.support:gridlayout-v7:24.2.1’<br>v7 mediarouter library<br>该库提供了 MediaRouter、MediaRouteProvider等与Google Cast相关的类。<br>Gradle编译脚本中v7 mediarouter库的依赖语句：</p>
<p>compile ‘com.android.support:mediarouter-v7:24.2.1’<br>v7 palette library<br>该库提供了palette类，使用这个类可以很方便提取出图片中主题色。比如在音乐App中，从音乐专辑封面图片中提取出专辑封面图片的主题色，然后将播放界面的背景色设置为封面的主题色，随着播放音乐的改变，播放界面的背景色也会巧妙的跟着改变，从而提供更好的用户体验。<br>Gradle编译脚本中v7 palette库的依赖语句：</p>
<p>compile ‘com.android.support:palette-v7:24.2.1’<br>v7 recyclerview library<br>该库提供了recyclerview类。这个库使用的频率很高，网上有很多文章介绍recyclerview。<br>Gradle编译脚本中v7 recyclerview库的依赖语句：</p>
<p>compile ‘com.android.support:recyclerview-v7:24.2.1’<br>v7 Preference Support library<br>这个库在设置界面常用到。提供了 CheckBoxPreference、ListPreference等类。<br>Gradle编译脚本中v7 preference support库的依赖语句：</p>
<p>compile ‘com.android.support:preference-v7:24.2.1’<br>v8 Support Library</p>
<p>v8支持库支持范围也是Android 2.3 (API level 9)及其以上版本。v8支持库集合中现在只有一个库。</p>
<p>v8 renderscript library<br>这个库支持渲染脚本计算框架。对这个库有兴趣可以看渲染脚本开发指导。<br>使用v8 renderscript库Gradle编译脚本的配置方法：<br>defaultConfig {<br>      renderscriptTargetApi 18<br>      renderscriptSupportModeEnabled true<br>}<br>【※】v13 Support Library</p>
<p>v13支持库适用范围是Android 3.2 (API level 13)及其以上版本。这个库跟v4 fragment library功能基本一样，也是提供兼容fragment相关内容。区别是v4 fragment library需要依赖v4支持库集合里的其它4个子库，而v13 support library依赖的是Android 3.2 (API level 13)及其以上版本framework。也就是说v4支持库除了v4 fragment library以外，其它功能都在Android 3.2 (API level 13)及其以上版本的framework中提供了。所以我们的App如果只需要兼容到Android 3.2，那么fragment部分使用v13 Support Library中的相关类才是明智之举。<br>Gradle编译脚本中v13 support库的依赖语句：</p>
<p>  compile ‘com.android.support:support-v13:24.2.1’<br>v14 Preference Support Library</p>
<p>功能类似v7 Preference Support library，支持Android系统版本不一致，新增部分相关接口。<br>Gradle编译脚本中v 库的依赖语句：</p>
<p>  compile ‘com.android.support:preference-v14:24.2.1’<br>v17 Preference Support Library for TV</p>
<p>功能类似v7 Preference Support library，支持Android系统版本不一致，新增部分相关接口，为电视设备App提供相应的UI。<br>Gradle编译脚本中v 库的依赖语句：</p>
<p>  compile ‘com.android.support:preference-leanback-v17:24.2.1’<br>v17 Leanback Library</p>
<p>这也是在电视设备上使用的库，主要是和YouTube相关的。<br>Gradle编译脚本中v17 Leanback库的依赖语句：</p>
<p>  compile ‘com.android.support:leanback-v17:24.2.1’<br>Annotations Support Library</p>
<p>提供注解相关功能。<br>Gradle编译脚本中Annotations Support库的依赖语句：</p>
<p>  compile ‘com.android.support:support-annotations:24.2.1’<br>【※】Design Support Library</p>
<p>这个库现在使用的也比较多，它提供了material design设计风格的控件。如，navigation drawers、floating action buttons (FAB)、snackbars、tabs等。<br>Gradle编译脚本中Design Support库的依赖语句：</p>
<p>  compile ‘com.android.support:design:24.2.1’<br>【※】Multidex Support Library</p>
<p>Android的单个.dex文件最多能引用65536个方法，在这之后的方法就无法引用了。当我们的方法数超过这个限制后就需要分成多个dex文件，该库就是用来支持多个dex文件构建应用程序的。<br>Gradle编译脚本中Multidex Support库的依赖语句：</p>
<p>compile ‘com.android.support:multidex:1.0.0’<br>【※】Custom Tabs Support Library</p>
<p>这个库有很有意思，提供了一种新的打开网页的方式。以前的App要打开一个网页有两种选择，一个是用webview，这种方式工作量较大，第二种方式是调用浏览器应用来打开网页，这种方式要在两个应用中切换，用户的操作体验是割裂的，都不够理想。这个库提供了第三种选择，具体情况可以点击这篇文章了解。<br>Gradle编译脚本中Custom Tabs Support库的依赖语句：</p>
<p>  compile ‘com.android.support:customtabs:24.2.1’<br>Percent Support Library</p>
<p>百分比支持库提供了如PercentFrameLayout、PercentRelativeLayout布局，在这些布局中子view可以使用百分比来设置大小、位置等。<br>Gradle编译脚本中Percent Support库的依赖语句：</p>
<p>  compile ‘com.android.support:percent:24.2.1’<br>App Recommendation Support Library for TV</p>
<p>这个库是电视设备上用来提供视频内容推荐的。<br>Gradle编译脚本中Recommendation Support库的依赖语句：</p>
<p>  compile ‘com.android.support:recommendation:24.2.1’<br>如何选择使用支持包？</p>
<p>其实在了解了支持包特性之后，这个问题也就迎刃而解了，这里再做下总结。在使用Android Support Library之前我们需要通过sdk manager安装Android Support Repository，然后再在gradle编译脚本中添加如下依赖语句就可以了。</p>
<p>compile ‘com.android.support:support-v4:24.2.1’  //以v4为例<br>前面文章说过gradle中jar依赖语句格式如 compile jar文件组（group/命名空间）:jar文件名（name）:jar文件版本（version）。对于Android Support Library库的依赖语句jar文件名和jar文件版本两部分需要选择确定。</p>
<p>jar文件名：在选择之前要明确两件事，需要使用支持包的哪种特性、需要兼容的最低Android版本，然后就可以确定具体依赖哪个支持库。<br>jar文件版本：支持库的版本需要跟compileSdkVersion保持一致。</p>
<blockquote>
<p>注意：由于依赖的支持库会打包进apk，所以官方推荐开发者在编译时使用ProGuard工具预处理release版本的apk。<strong>ProGuard工具除了混淆源代码外，还会移除那些依赖的支持库中没有使用到的类，达到apk瘦身的效果。</strong></p>
</blockquote>
<h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2><p>以上就是关于Android Support Library全部了，谢谢。如果文章有错误或者有疑问请务必留言告诉我。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文作者：&lt;a href=&quot;http://www.jianshu.com/p/f5f9a4fd22e8&quot;&gt;都有米&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/1621638-64e0312fb3d79864.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在之前的开发经历中经常需要导入一些如v4、v7、v13等Android官方的支持包，遇到这些情况时都是网上搜索一下，按照前人给的示例添加依赖。这么稀里糊涂的使用后代码正常运行了，但心中不免会有一些疑问，如，Android官方为什么要提供支持包，都提供哪些支持包，这些支持包又提供了什么特性，开发者又应该如何选择使用这些支持包？&lt;/p&gt;
&lt;p&gt;为了解开这些疑问，周末在家仔细阅读了官方的开发者指导文档的相关内容。这篇文章就是读后整理的读书笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Android热更新方案Robust</title>
    <link href="http://ipcreator.me/2017/02/26/Program/Android/hot-update-of-android/"/>
    <id>http://ipcreator.me/2017/02/26/Program/Android/hot-update-of-android/</id>
    <published>2017-02-26T01:04:05.000Z</published>
    <updated>2017-02-26T13:19:14.708Z</updated>
    
    <content type="html"><![CDATA[<p>原文作者：<a href="http://tech.meituan.com/android_robust.html" target="_blank" rel="external">吴坤 张梦 定旭 晓阳</a></p>
<p>美团•大众点评是中国最大的O2O交易平台，目前已拥有近6亿用户，合作各类商户达432万，订单峰值突破1150万单。美团App是平台主要的入口之一，O2O交易场景的复杂性决定了App稳定性要达到近乎苛刻的要求。用户到店消费买优惠券时死活下不了单，定外卖一个明显可用的红包怎么点也选不中，上了一个新活动用户一点就Crash……过去发生过的这些画面太美不敢想象。客户端相对Web版最大的短板就是有发版的概念，对线上事故很难有即时生效的解决方式，每次发版都如临深渊如履薄冰，毕竟就算再完善的开发测试流程也无法保证不会将Bug带到线上。</p>
<p>从去年开始，Android平台出现了一些优秀的热更新方案，主要可以分为两类：一类是基于multidex的热更新框架，包括Nuwa、Tinker等；另一类就是native hook方案，如阿里开源的Andfix和Dexposed。这样客户端也有了实时修复线上问题的可能。但经过调研之后，我们发现上述方案或多或少都有一些问题，基于native hook的方案：需要针对dalvik虚拟机和art虚拟机做适配，需要考虑指令集的兼容问题，需要native代码支持，兼容性上会有一定的影响；基于Multidex的方案，需要反射更改DexElements，改变Dex的加载顺序，这使得patch需要在下次启动时才能生效，实时性就受到了影响，同时这种方案在android N [speed-profile]编译模式下可能会有问题，可以参考Android N混合编译与对热补丁影响解析。考虑到美团Android用户机型分布的碎片化，很难有一个方案能覆盖所有机型。</p>
<p>去年底的Android Dev Summit上，Google高调发布了Android Studio 2.0，其中最重要的新特性Instant Run，实现了对代码修改的实时生效（热插拔）。我们在了解Instant Run原理之后，实现了一个兼容性更强的热更新方案，这就是产品化的hotpatch框架－－Robust。</p>
   <a id="more"></a>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>Robust插件对每个产品代码的每个函数都在编译打包阶段自动的插入了一段代码，插入过程对业务开发是完全透明。如State.java的getIndex函数：</p>
<p>public long getIndex() {<br>        return 100;<br>    }<br>被处理成如下的实现：</p>
<p>public static ChangeQuickRedirect changeQuickRedirect;<br>    public long getIndex() {<br>        if(changeQuickRedirect != null) {<br>            //PatchProxy中封装了获取当前className和methodName的逻辑，并在其内部最终调用了changeQuickRedirect的对应函数<br>            if(PatchProxy.isSupport(new Object[0], this, changeQuickRedirect, false)) {<br>                return ((Long)PatchProxy.accessDispatch(new Object[0], this, changeQuickRedirect, false)).longValue();<br>            }<br>        }<br>        return 100L;<br>    }<br>可以看到Robust为每个class增加了个类型为ChangeQuickRedirect的静态成员，而在每个方法前都插入了使用changeQuickRedirect相关的逻辑，当 changeQuickRedirect不为null时，可能会执行到accessDispatch从而替换掉之前老的逻辑，达到fix的目的。<br>如果需将getIndex函数的返回值改为return 106，那么对应生成的patch，主要包含两个class：PatchesInfoImpl.java和StatePatch.java。<br>PatchesInfoImpl.java:</p>
<p>public class PatchesInfoImpl implements PatchesInfo {<br>    public List<patchedclassinfo> getPatchedClassesInfo() {<br>        List<patchedclassinfo> patchedClassesInfos = new ArrayList<patchedclassinfo>();<br>        PatchedClassInfo patchedClass = new PatchedClassInfo(“com.meituan.sample.d”, StatePatch.class.getCanonicalName());<br>        patchedClassesInfos.add(patchedClass);<br>        return patchedClassesInfos;<br>    }<br>}<br>StatePatch.java：</patchedclassinfo></patchedclassinfo></patchedclassinfo></p>
<p>public class StatePatch implements ChangeQuickRedirect {<br>    @Override<br>    public Object accessDispatch(String methodSignature, Object[] paramArrayOfObject) {<br>        String[] signature = methodSignature.split(“:”);<br>        if (TextUtils.equals(signature[1], “a”)) {//long getIndex() -&gt; a<br>            return 106;<br>        }<br>        return null;<br>    }</p>
<pre><code>@Override
public boolean isSupport(String methodSignature, Object[] paramArrayOfObject) {
    String[] signature = methodSignature.split(&quot;:&quot;);
    if (TextUtils.equals(signature[1], &quot;a&quot;)) {//long getIndex() -&gt; a
        return true;
    }
    return false;
}
</code></pre><p>}<br>客户端拿到含有PatchesInfoImpl.java和StatePatch.java的patch.dex后，用DexClassLoader加载patch.dex，反射拿到PatchesInfoImpl.java这个class。拿到后，创建这个class的一个对象。然后通过这个对象的getPatchedClassesInfo函数，知道需要patch的class为com.meituan.sample.d（com.meituan.sample.State混淆后的名字），再反射得到当前运行环境中的com.meituan.sample.d class，将其中的changeQuickRedirect字段赋值为用patch.dex中的StatePatch.java这个class new出来的对象。这就是打patch的主要过程。通过原理分析，其实Robust只是在正常的使用DexClassLoader，所以可以说这套框架是没有兼容性问题的。</p>
<p>大体流程如下：<br><img src="http://tech.meituan.com/img/android_robust/patching.png" alt=""></p>
<p>插件的问题<br>OK，到这里Robust原理就介绍完了。很简单是不是？而且sample这个例子中也验证成功了。难道一切这么顺利？其实现实并不是这样，我们将这套实现用到美团的主App时，问题出现了：</p>
<p>Conversion to Dalvik format failed:Unable to execute dex: method ID not in [0, 0xffff]: 65536<br>居然不能打出包来了！从原理上分析，除了引入的patch过程aar外，我们这套实现是不会增加别的方法的，而且引入的那个aar的方法才100个左右，怎么会造成美团的mainDex超过65536呢？进一步分析，我们一共处理7万多个函数，导致最后方法数总共增加7661个。这是为什么呢？</p>
<p>看下patch前后的dex对比：<br><img src="http://tech.meituan.com/img/android_robust/compare_patch_dex.png" alt=""></p>
<p>针对com.meituan.android.order.adapter.OrderCenterListAdapter.java分析一下，发现进行hotpatch之后增加了如下6个方法：</p>
<p>public boolean isEditMode() {<br>        return isEditMode;<br>    }<br>private int incrementDelCount() {<br>        return delCount.incrementAndGet();<br>    }<br>private boolean isNeedDisplayRemainingTime(OrderData orderData) {<br>        return null != orderData.remindtime &amp;&amp; getRemainingTimeMillis(orderData.remindtime) &gt; 0;<br>    }<br>private boolean isNeedDisplayUnclickableButton(OrderData orderData) {<br>        return null != orderData.remindtime &amp;&amp; getRemainingTimeMillis(orderData.remindtime) &lt;= 0;<br>    }<br>private boolean isNeedDisplayExpiring(boolean expiring) {<br>        return expiring &amp;&amp; isNeedDisplayExpiring;<br>    }<br>private View getViewByTemplate(int template, View convertView, ViewGroup parent) {<br>        View view = null;<br>        switch (template) {<br>            case TEMPLATE_DEFALUT:<br>            default:<br>                view = mInflater.inflate(R.layout.order_center_list_item, null);<br>        }<br>        return view;<br>    }<br>但是这些多出来的函数其实就在原来的产品代码中，为什么没有Robust的情况下不见了，而使用了插件后又出现在最终的class中了呢？只有一个可能，就是ProGuard的内联受到了影响。使用了Robust插件后，原来能被ProGuard内联的函数不能被内联了。看了下ProGuard的Optimizer.java的相关片段：</p>
<p>if (methodInliningUnique) {<br>    // Inline methods that are only invoked once.<br>    programClassPool.classesAccept(<br>        new AllMethodVisitor(<br>        new AllAttributeVisitor(<br>        new MethodInliner(configuration.microEdition,<br>                          configuration.allowAccessModification,<br>                          true,<br>                          methodInliningUniqueCounter))));<br>}<br>if (methodInliningShort) {<br>    // Inline short methods.<br>    programClassPool.classesAccept(<br>        new AllMethodVisitor(<br>        new AllAttributeVisitor(<br>        new MethodInliner(configuration.microEdition,<br>                          configuration.allowAccessModification,<br>                          false,<br>                          methodInliningShortCounter))));<br>}<br>通过注释可以看出，如果只被调用一次或者足够小的函数，都可能被内联。深入分析代码，我们发现确实如此，只被调用了一次的私有函数、只有一行函数体的函数（比如get、set函数等）都极可能内联。前面com.meituan.android.order.adapter.OrderCenterListAdapter.java多出的那6个函数也证明了这一点。知道原因了就能有解决问题的思路。<br>其实仔细思考下，那些可能被内联的只有一行函数体的函数，真的有被插件处理的必要吗？别说一行代码的函数出问题的可能性小，就算出问题了也可以通过patch内联它的那个函数来解决问题，或者patch这一行代码调用的那个函数。只调用了一次的函数其实是一样的。所以通过分析，这样的函数其实是可以不被插件处理的。那么有了这个认识，我们对插件做了处理函数的判断，跳过被ProGuard内联可能性比较大的函数。重新在团购试了一次，这次apk顺利的打包出来了。通过对打出来apk中的dex做分析，发现优化后的插件还是影响了内联效果，不过只导致方法数增加了不到1000个，所以算是临时简单的解决了这个问题。</p>
<h2 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h2><p>原理上，Robust是为每个函数都插入了一段逻辑，为每个class插入了ChangeQuickRedirect的字段，所以最终肯定会增加apk的体积。以美团主App为例，平均一个函数会比原来增加17.47个字节，整个App中我们一共处理了6万多个函数，导致包大小由原来的19.71M增加到了20.73M。有些class没有必要添加ChangeQuickRedirect字段，以后可以通过将这些class过滤掉的方式来做优化。<br>Robust在每个方法前都加上了额外的逻辑，那对性能上有什么影响呢？<br><img src="http://tech.meituan.com/img/android_robust/effectiveness1.png" alt=""><br>从图中可以看到，对一个只有内存运算的函数，处理前后分别执行10万次的时间增加了128ms。这是在华为4A上的测试结果。<br>对启动速度上的影响：<br><img src="http://tech.meituan.com/img/android_robust/effectiveness2.png" alt=""><br>在同一个机器上的结果，处理前后的启动时间相差了5ms。</p>
<p>补丁的问题<br>再来看看补丁本身。要制作出补丁，我们可能会面临如下两个问题：</p>
<ol>
<li>如何解决混淆问题？</li>
<li>被补的函数中使用了super相关的调用怎么办？<br>其实混淆的问题比较好处理。先针对混淆前的代码生成patch.class，然后利用生成release包时对应的mapping文件中的class的映射关系，对patch.class做字符串上的处理，让它使用线上运行环境中混淆的class。<br>被补的函数中使用了super相关的调用怎么办？比如某个Activity的onCreate方法中需要调用super.onCreate，而现在这个bad.Class的badMethod就是这个Activity的onCreate方法，那么在patched.class的patchedMethod中如何通过这个Activity的对象，调用它父类的onCreate方法呢？通过分析Instant Run对这个问题的处理，发现它是在每个class中都添加了一个代理函数，专门来处理super的问题的。为每个class都增加一个函数无疑会增加总的方法数，这样做肯定会遇到65536这个问题。所以直接使用Instant Run的做法显然是不可取的。<br>在Java中super是个关键字，也无法通过别的对象来访问到。看来，想直接在patched.java代码中通过Activity的对象调用到它父类的onCreate方法有点不太可能了。不过通过对class文件做分析，发现普通的函数调用是使用JVM指令集的invokevirtual指令，而super.onCreate的调用使用的是invokesuper指令。那是不是将class文件中这个调用的指令改为invokesuper就好了？看如下的例子：<br>产品代码SuperClass.java：</li>
</ol>
<p>public class SuperClass {<br>    String uuid;<br>    public void setUuid(String id) {<br>        uuid = id;<br>    }<br>    public void thisIsSuper() {<br>        Log.d(“SuperClass”, “thisIsSuper “+uuid);<br>    }<br>}<br>产品代码TestSuperClass.java：</p>
<p>public class TestSuperClass extends SuperClass{<br>    String subUuid;<br>    public void setSubUuid(String id) {<br>        subUuid = id;<br>    }</p>
<pre><code>@Override
public void thisIsSuper() {
    Log.d(&quot;TestSuperClass&quot;, &quot;thisIsSuper no call&quot;);
}
</code></pre><p>}<br>TestSuperPatch.java是DexClassLoader将要加载的代码：</p>
<p>public class TestSuperPatch {<br>    public static void testSuperCall() {<br>        TestSuperClass testSuperClass = new TestSuperClass();<br>        String t = UUID.randomUUID().toString();<br>        Log.d(“TestSuperPatch”, “UUID “ + t);<br>        testSuperClass.setUuid(t);<br>        testSuperClass.thisIsSuper();<br>    }<br>}<br>对TestSuperPatch.class的testSuperClass.thisIsSuper()调用做invokesuper的替换，并且将invokesuper的调用作用在testSuperClass这个对象上，然后加载运行：</p>
<p>Caused by: java.lang.NoSuchMethodError: No super method thisIsSuper()V in class Lcom/meituan/sample/TestSuperClass; or its super classes (declaration of ‘com.meituan.sample.TestSuperClass’ appears in /data/app/com.meituan.robust.sample-3/base.apk)<br>报错信息说在TestSuperClass和TestSuperClass的父类中没有找到thisIsSuper()V函数！但是实际上TestSuperClass和父类中是存在thisIsSuper()V函数的，而且通过apk反编译看也确实存在的，那怎么就找不到呢？分析invokesuper指令的实现，发现系统会在执行指令所在的class的父类中去找需要调用的方法，所以要将TestSuperPatch跟TestSuperClass一样作为SuperClass的子类。修改如下：</p>
<p>public class TestSuperPatch extends SuperClass {<br>    …<br>}<br>然后再做一次尝试：</p>
<p>08-11 09:12:03.012 1787-1787/? D/TestSuperPatch: UUID c5216480-5c3a-4990-896d-58c3696170c5<br>08-11 09:12:03.012 1787-1787/? D/SuperClass: thisIsSuper c5216480-5c3a-4990-896d-58c3696170c5<br>看一下testSuperCall的实现，将UUID.randomUUID().toString()的结果，通过setUuid赋值给了testSuperClass这个对象的父类的uuid字段。从日志可以看出，对testSuperClass.thisIsSuper处理后，确实是调用到了testSuperClass这个对象的super的thisIsSuper函数。OK，super的问题看来解决了，而且这种方式不会增加方法数。</p>
<p>上线后的效果<br>Robust 靠谱吗？<br><img src="http://tech.meituan.com/img/android_robust/result.png" alt=""><br>尝试修个线上的问题，我们是在07.14下午17:00多的时候上线的补丁，我们可以看到接下来的几天一直到07.17号将补丁下线，这个线上问题得到了明显的修复，补丁下线后看到07.18号这个问题又明显上升了。直到07.18号下班前又重新上线补丁。</p>
<p>补丁的兼容性和成功率如何？通过以上的理论分析，可以看到这套实现基本没有兼容性问题，实际上线的数据如下：<br><img src="http://tech.meituan.com/img/android_robust/successRate.png" alt=""></p>
<p>先简单解释下这几个指标：<br>补丁列表拉取成功率=拉取补丁列表成功的用户/尝试拉取补丁列表的用户<br>补丁下载成功率=下载补丁成功的用户/补丁列表拉取成功的用户<br>patch应用成功率=patch成功的用户/补丁下载成功的用户</p>
<p>通过这个表能够看出，我们的patch信息拉取的成功最低，平均97%多，这是因为实际的网络原因，而下载成功后的patch成功率是一直在99.8%以上。而且我们做的是无差别下发，服务端没有做任何针对机型版本的过滤，线上的结果再次证明了Robust的高兼容性。</p>
<p>总结<br>目前业界已有的Android App热更新方案，包括Multidesk和native hook两类，都存在一些兼容性问题。为此我们借鉴Instant Run原理，实现了一个兼容性更强的热更新方案－－Robust。Robust除了高兼容性之外，还有实时生效的优势。so和资源的替换目前暂时未做实现，但是从框架上来说未来是完全有能力支持的。当然，这套方案虽然对开发者是透明的，但毕竟在编译阶段有插件侵入了产品代码，对运行效率、方法数、包体积还是产生了一些副作用。这也是我们下一步努力的方向。</p>
<p>参考文献<br>Instant Run, Android Tools Project Site, <a href="http://tools.android.com/tech-docs/instant-run" target="_blank" rel="external">http://tools.android.com/tech-docs/instant-run</a>.<br>Oracle, The Java Virtual Machine Instruction Set, <a href="https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html" target="_blank" rel="external">https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html</a>.<br>Oracle, ClassLoader, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/ClassLoader.html" target="_blank" rel="external">https://docs.oracle.com/javase/7/docs/api/java/lang/ClassLoader.html</a>).<br>ltshddx, <a href="https://github.com/ltshddx/jaop" target="_blank" rel="external">https://github.com/ltshddx/jaop</a>).<br>w4lle, Android热补丁之AndFix原理解析.<br>shwenzhang, Android N混合编译与对热补丁影响解析.</p>
<p>不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？</p>
<p>请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：<br><img src="http://tech.meituan.com/img/qrcode_for_gh.jpg" alt=""><br>公众号二维码</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文作者：&lt;a href=&quot;http://tech.meituan.com/android_robust.html&quot;&gt;吴坤 张梦 定旭 晓阳&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;美团•大众点评是中国最大的O2O交易平台，目前已拥有近6亿用户，合作各类商户达432万，订单峰值突破1150万单。美团App是平台主要的入口之一，O2O交易场景的复杂性决定了App稳定性要达到近乎苛刻的要求。用户到店消费买优惠券时死活下不了单，定外卖一个明显可用的红包怎么点也选不中，上了一个新活动用户一点就Crash……过去发生过的这些画面太美不敢想象。客户端相对Web版最大的短板就是有发版的概念，对线上事故很难有即时生效的解决方式，每次发版都如临深渊如履薄冰，毕竟就算再完善的开发测试流程也无法保证不会将Bug带到线上。&lt;/p&gt;
&lt;p&gt;从去年开始，Android平台出现了一些优秀的热更新方案，主要可以分为两类：一类是基于multidex的热更新框架，包括Nuwa、Tinker等；另一类就是native hook方案，如阿里开源的Andfix和Dexposed。这样客户端也有了实时修复线上问题的可能。但经过调研之后，我们发现上述方案或多或少都有一些问题，基于native hook的方案：需要针对dalvik虚拟机和art虚拟机做适配，需要考虑指令集的兼容问题，需要native代码支持，兼容性上会有一定的影响；基于Multidex的方案，需要反射更改DexElements，改变Dex的加载顺序，这使得patch需要在下次启动时才能生效，实时性就受到了影响，同时这种方案在android N [speed-profile]编译模式下可能会有问题，可以参考Android N混合编译与对热补丁影响解析。考虑到美团Android用户机型分布的碎片化，很难有一个方案能覆盖所有机型。&lt;/p&gt;
&lt;p&gt;去年底的Android Dev Summit上，Google高调发布了Android Studio 2.0，其中最重要的新特性Instant Run，实现了对代码修改的实时生效（热插拔）。我们在了解Instant Run原理之后，实现了一个兼容性更强的热更新方案，这就是产品化的hotpatch框架－－Robust。&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>GestureDetector</title>
    <link href="http://ipcreator.me/2017/02/25/Program/Android/GestureDetector/"/>
    <id>http://ipcreator.me/2017/02/25/Program/Android/GestureDetector/</id>
    <published>2017-02-25T08:11:06.000Z</published>
    <updated>2017-02-25T14:11:23.598Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GestureDetector"><a href="#GestureDetector" class="headerlink" title="GestureDetector"></a><a href="https://developer.android.com/reference/android/view/GestureDetector.html" target="_blank" rel="external">GestureDetector</a></h2><p><img src="http://okkntqe2h.bkt.clouddn.com/GestureDetector.png" alt=""></p>
<p>public class GestureDetector<br>extends Object</p>
<p>java.lang.Object<br>   ↳    android.view.GestureDetector</p>
<p>Detects various gestures and events using the supplied MotionEvents. The <a href="https://developer.android.com/reference/android/view/GestureDetector.OnGestureListener.html" target="_blank" rel="external">GestureDetector.OnGestureListener</a> callback will notify users when <strong>a particular motion event</strong> has occurred. This class should only be used with <a href="https://developer.android.com/reference/android/view/MotionEvent.html" target="_blank" rel="external">MotionEvents</a> reported via touch (don’t use for trackball events).</p>
<p>To use this class:</p>
<ul>
<li>Create an instance of the GestureDetector for your View</li>
<li>In the onTouchEvent(MotionEvent) method ensure you call onTouchEvent(MotionEvent). The methods defined in your callback will be executed when the events occur.</li>
<li>If listening for onContextClick(MotionEvent) you must call onGenericMotionEvent(MotionEvent) in onGenericMotionEvent(MotionEvent).</li>
</ul>
<p>参考文章：<br><a href="http://blog.csdn.net/ztp800201/article/details/7410503" target="_blank" rel="external">Android - GestureDetector 实现界面左右滑动效果的优化</a><br><a href="http://blog.csdn.net/hzh_csdn/article/details/52317566" target="_blank" rel="external">Android GestureDetector简单手势检测（左右滑动、上下滑动）</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;GestureDetector&quot;&gt;&lt;a href=&quot;#GestureDetector&quot; class=&quot;headerlink&quot; title=&quot;GestureDetector&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://developer.android.com/re
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>名人名言</title>
    <link href="http://ipcreator.me/2017/02/22/MyView/Diary/my-translations/"/>
    <id>http://ipcreator.me/2017/02/22/MyView/Diary/my-translations/</id>
    <published>2017-02-22T00:31:05.000Z</published>
    <updated>2017-02-25T14:30:01.752Z</updated>
    
    <content type="html"><![CDATA[<p>frome <a href="http://www.azquotes.com" target="_blank" rel="external">az quotes</a></p>
<p><img src="http://www.azquotes.com/picture-quotes/quote-a-person-who-never-made-a-mistake-never-tried-anything-new-albert-einstein-8-72-86.jpg" alt=""></p>
<blockquote>
<p>A person who never made a mistake never tried anything new.<br>——Albert Einstein</p>
</blockquote>
<p>从不犯错的人也从不尝试新事物。<br>——艾尔伯特 爱因斯坦</p>
<p><img src="http://www.azquotes.com/picture-quotes/quote-i-didn-t-fail-the-test-i-just-found-100-ways-to-do-it-wrong-benjamin-franklin-10-19-28.jpg" alt=""></p>
<blockquote>
<p>I didn’t fail the test, I just found 100 ways to do it wrong.<br>——Benjamin Franklin</p>
</blockquote>
<p>我并没有失败，只是找到了100种错误的方法。<br>——本杰明 富兰克林</p>
<p><img src="http://www.azquotes.com/picture-quotes/quote-don-t-find-fault-find-a-remedy-henry-ford-9-91-53.jpg" alt=""></p>
<blockquote>
<p>Don’t find fault, find a remedy.<br>——Henry Ford</p>
</blockquote>
<p>不要找错，寻求补救。<br>——亨利 福特</p>
   <a id="more"></a>
<p><img src="http://izquotes.com/quotes-pictures/quote-life-is-not-easy-for-any-of-us-but-what-of-that-we-must-have-perseverance-and-above-all-marie-curie-45454.jpg" alt=""></p>
<blockquote>
<p>“Life is not easy for any of us. But what of that? We must have perseverance and above all confidence in ourselves. We must believe that we are gifted for something and that this thing must be attained.”<br>——Marie Curie</p>
</blockquote>
<p>生活对每人而言均不易，但那又如何？我们对自己必须要坚持不懈和充满信心，我们必须要相信自己在某些方面拥有天赋并且一定能够有所实现。<br>——玛丽·居里</p>
<p><img src="http://izquotes.com/quotes-pictures/quote-it-is-godlike-ever-to-think-on-something-beautiful-and-on-something-new-democritus-49344.jpg" alt=""></p>
<blockquote>
<p>“It is godlike ever to think on something beautiful and on something new.”<br>——Democritus</p>
</blockquote>
<p>思考美丽的事物永远是神圣的，思考新事物也如此。<br> ——德谟克利特（古希腊哲学家）</p>
<p> <img src="http://izquotes.com/quotes-pictures/quote-i-don-t-want-to-be-the-next-michael-jordan-i-only-want-to-be-kobe-bryant-kobe-bryant-26125.jpg" alt=""><br> “I don’t want to be the next Michael Jordan, I only want to be Kobe Bryant.”<br>——Kobe Bryant</p>
<p>我不想成为下一个迈克尔 乔丹，我只想成为科比 布莱恩特<br>——科比 布莱恩特</p>
<p><img src="http://izquotes.com/quotes-pictures/quote-if-somebody-says-no-to-you-or-if-you-get-cut-michael-jordan-was-cut-his-first-year-but-he-came-magic-johnson-95765.jpg" alt=""><br>“If somebody says no to you, or if you get cut, Michael Jordan was cut his first year, but he came back and he was the best ever. That is what you have to have. The attitude that I’m going to show everybody, I’m going to work hard to get better and better.”<br>——Magic Johnson</p>
<p>如果有人拒绝你，或者你遭受打击，迈克尔 乔丹在菜鸟赛季被人欺凌，但是他重返赛场并展现最好状态，这就是你必须要拥有的态度：向每个人表明我会更加努力，使之越来越好！<br>——魔术师 约翰逊</p>
<p> <img src="http://www.azquotes.com/picture-quotes/quote-when-everything-seems-to-be-going-against-you-remember-that-the-airplane-takes-off-against-henry-ford-9-91-57.jpg" alt=""></p>
<blockquote>
<p>When everything seems to be going against you, remember that the airplane takes off against the wind, not with it.<br>  ——Henry Ford</p>
</blockquote>
<p>   当看似一切都在和你作对时，记得飞机就是迎风起飞的，不必在意。<br>   ——亨利 福特</p>
<p> <img src="http://www.azquotes.com/picture-quotes/quote-my-mission-in-life-is-not-merely-to-survive-but-to-thrive-and-to-do-so-with-some-passion-maya-angelou-34-70-30.jpg" alt=""></p>
<blockquote>
<p>My mission in life is not merely to survive, but to thrive; and to do so with some passion, some compassion, some humor, and some style<br>——Maya Angelou</p>
</blockquote>
<p>我的人生使命不只是生存，而是带有激情、同情、幽默和时尚的生活。<br>——玛雅·安吉罗</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;frome &lt;a href=&quot;http://www.azquotes.com&quot;&gt;az quotes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.azquotes.com/picture-quotes/quote-a-person-who-never-made-a-mistake-never-tried-anything-new-albert-einstein-8-72-86.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A person who never made a mistake never tried anything new.&lt;br&gt;——Albert Einstein&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从不犯错的人也从不尝试新事物。&lt;br&gt;——艾尔伯特 爱因斯坦&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.azquotes.com/picture-quotes/quote-i-didn-t-fail-the-test-i-just-found-100-ways-to-do-it-wrong-benjamin-franklin-10-19-28.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I didn’t fail the test, I just found 100 ways to do it wrong.&lt;br&gt;——Benjamin Franklin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我并没有失败，只是找到了100种错误的方法。&lt;br&gt;——本杰明 富兰克林&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.azquotes.com/picture-quotes/quote-don-t-find-fault-find-a-remedy-henry-ford-9-91-53.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don’t find fault, find a remedy.&lt;br&gt;——Henry Ford&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不要找错，寻求补救。&lt;br&gt;——亨利 福特&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="English" scheme="http://ipcreator.me/tags/English/"/>
    
  </entry>
  
  <entry>
    <title>爱句子</title>
    <link href="http://ipcreator.me/2017/02/22/MyView/Diary/love-sentencns/"/>
    <id>http://ipcreator.me/2017/02/22/MyView/Diary/love-sentencns/</id>
    <published>2017-02-22T00:13:05.000Z</published>
    <updated>2017-02-27T01:49:54.249Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://cdn.iciba.com/news/word/big_20160828b.jpg" alt=""></p>
<p>How deep I love you, the moon represents my heart.<br>你问我爱你有多深，月亮代表我的心。</p>
   <a id="more"></a>
<p><a href="http://news.iciba.com/study/oral/1575707.shtml" target="_blank" rel="external">BBC英语教学</a></p>
<p><img src="http://cdn.iciba.com/news/2017/0210/20170210094146362.jpg" alt=""></p>
<p>英国，不同地区的人们会用和动物有关的词汇来称呼他人。这些称呼十分有爱，也很友好。有些人认为这个称呼来源于 duke 公爵。</p>
<p>Feifei<br>‘Hen’ is used in Glasgow – but only when talking to women. 在苏格兰格拉斯哥，人们会用 hen 来称呼女性。</p>
<p>Neil<br>Alright, hen? And then we have ‘pet’…</p>
<p>Feifei<br>‘Pet’ is used in the North East of England. 在英格兰纽卡斯尔，人们会互相称呼 pet。</p>
<p><img src="http://cdn.iciba.com/news/word/big_20170223b.jpg" alt=""></p>
<p>The happiness of life is made up of minute fractions – the little soon forgotten charities of a kiss, a smile, a kind look, a heartfelt compliment.</p>
<p>生活中的快乐是由一些小片断组成——很快被遗忘的亲吻、微笑、关爱的眼神、由衷的赞美等小善举。</p>
<blockquote>
<p>词霸小编: 快乐似蒲公英的种子飘落在任意角落，你需要的只是一双发现它的眼睛……【词汇扩充】heartfelt adj. 衷心的，真诚的。如 heartfelt thanks 由衷的感谢。同义词为：sincere。</p>
</blockquote>
<h2 id="实用口语：与老外见面的10大经典句，有你讲过的吗？"><a href="#实用口语：与老外见面的10大经典句，有你讲过的吗？" class="headerlink" title="实用口语：与老外见面的10大经典句，有你讲过的吗？"></a>实用口语：与老外见面的10大经典句，有你讲过的吗？</h2><p><a href="http://xue.youdao.com/sw/m/1309085?keyfrom=dict2.index" target="_blank" rel="external">lavaFOX看电影学英语</a></p>
<p><img src="https://oimageb6.ydstatic.com/image?id=-2459576666684072041&amp;product=dict&amp;_w=440&amp;_h=440&amp;originWidth=440&amp;originHeight=440" alt=""></p>
<p>1.Welcome to China! Welcome to our city!</p>
<p>欢迎到中国来！欢迎到我们的城市来！</p>
<p>2.I hope you’re enjoying your stay here.</p>
<p>希望你在这里过得愉快。</p>
<p>3.How long have you been in China?</p>
<p>你在中国多长时间了？</p>
<p>4.Is this your first trip to China?</p>
<p>这是你第一次来中国吗？</p>
<p>5.Are you here on business or for pleasure?</p>
<p>你来这里是出差还是游玩？</p>
<p>6.There are many interesting places here. I’d like to show you around.</p>
<p>这儿有很多有趣的地方，我愿意带你去看一看。</p>
<p>7.Please let me know if you need any help.</p>
<p>如果需要帮助，请告诉我。</p>
<p>8.What’s your impression of China so far?</p>
<p>你对中国有印象如何？</p>
<p>9.Are you used to the life here? Does the weather agree with you?</p>
<p>你习惯这里的生活吗？你适应这里的气候吗？</p>
<p>10.How do you like Chinese food? Are you used to the food here? Does the food here agree with you?</p>
<p>你觉得中国菜如何？你习惯这里的食物吗？这里的食物合你口味吗？</p>
<h2 id="实用版家庭日常英语口语"><a href="#实用版家庭日常英语口语" class="headerlink" title="实用版家庭日常英语口语"></a><a href="http://xue.youdao.com/sw/m/1312561?keyfrom=dict2.index" target="_blank" rel="external">实用版家庭日常英语口语</a></h2><p>(1)Sleep and waking up(睡觉/起床)</p>
<p>It’s time to go sleepy-bye.(到睡觉的时间了。)</p>
<p>Sweat dreams.(做个好梦。)</p>
<p>It’s time to go to bed./Time for bed.(该上床了。)</p>
<p>It’s time to have a nap.(该午休了。)</p>
<p>Wake up!(起床。)</p>
<p>Did you sleep well?(睡好了吗？)</p>
<p>Time to get up.(该起床了。)</p>
<p>(2)Getting dressed(穿衣)</p>
<p>It’s time to get dressed(该穿衣服了。)</p>
<p>What do you want to wear today?(今天想穿什么？)</p>
<p>This shirt doesn’t go with those pants.(这件上衣和裤子不搭配。)</p>
<p>Stand still. / sit still.(站好/坐好。)</p>
<p>Now put on your sweater.(现在穿上毛衣。)</p>
<p>Take your clothes off./ Take off your clothes.(脱衣服。)</p>
<p>Pick up your socks, please.(请把袜子捡起来。)</p>
<p>Put on your trousers/shoes/coat/cap.穿上你的裤子/鞋子/外套/帽子。</p>
<p>(3)Meal time(吃饭)</p>
<p>Come sit at the table。(过来坐在桌旁。)</p>
<p>Stop playing with your food。(不要再玩食物了。)</p>
<p>Don’t talk with your mouth full。(嘴里吃着不要说话。)</p>
<p>Help Daddy do the dishes。(帮助爸爸收盘子。)</p>
<p>Help Mommy to set the table。(帮助妈妈放桌子。)</p>
<p>Help us clear off the table。(帮我们收拾桌子。)</p>
<p>(4)Safty and injuries(安全和受伤)</p>
<p>It’s bad for you!(这对你不好。)</p>
<p>I have told you many times not to do that。(我已经告诉你好几遍了不要那样做。)</p>
<p>Don’t sit too close to the TV。(不要坐的离电视太近。)</p>
<p>It’s nothing. It’s just a little cut。(不要紧，只是小伤口)</p>
<p>Don’t touch the electrical outlets。(不要碰电源插座)</p>
<p>Don’t try to plug/put anything in the outlet。(不要试图拔或放任何东西在插座里。)</p>
<p>Don’t touch anything on the stove。(不要碰炉子)</p>
<p>The oven is very hot; you could burn yourself。(炉子很烫，你会烫着自己。)</p>
<p>Those tools are too sharp; they’re only for grownups。(那些工具太锋利了，只有大人能用)</p>
<p>Don’t use others cup; you could catch his cold/germs that way。(不要用别人的杯子，那样会传染病菌)</p>
<p>Don’t play with fire; it’s dangerous。(不要玩火，危险)</p>
<p>Wait for the green light before you cross the street。(等绿灯亮了再过马路)</p>
<p>Always look both side before crossing the street. (过马路前一定看两边。)</p>
<p>(5)Playing toys/games(玩玩具/游戏)</p>
<p>Don’t leave toys on the floor where people will step on them。(不要把玩具放在地板上，别人会踩到它们)</p>
<p>I’m going to count to ten。(我将数到十)</p>
<p>Let’s pick up the toys and put them back。(咱们把玩具捡起来放回去。)</p>
<p>Want to play hide and seek?(玩捉迷藏吗？)</p>
<p>Ready or not, here I come。(准备好了吗？我来了)</p>
<p>Please put the toys/books back on the shelf。(请把玩具/书放回架子上。)</p>
<p>Want to play outside?(想出去玩吗？)</p>
<p>(6)Bathroom talk(卫生间)</p>
<p>Do you need to go potty?(你要去大/小便吗？)</p>
<p>I need to go to the bathroom. (我要上厕所)</p>
<p>Don’t unroll the toilet paper。(不要扯手纸。)</p>
<p>Don’t use too much toilet paper。(不要浪费手纸。)</p>
<p>Don’t pick your nose. / Don’t stick your fingers in your nose。(不要用手挖鼻子。)</p>
<p>Wipe your bottom。(擦擦屁股。)</p>
<p>(7)Washing up(清洁)</p>
<p>Your hands are sticky。(你的手很脏。)</p>
<p>Wash your hands immediately。(马上去洗手。)</p>
<p>Look at the mess you’ve made。(看看你弄的。)</p>
<p>You need to have a bath。(你得洗个澡了。)</p>
<p>(8)Manners(礼貌)</p>
<p>Don’t interrupt daddy/mommy。(不要打断妈/爸说话)</p>
<p>Don’t bother me while I’m on the phone。(我打电话时不要捣乱。)</p>
<p>Are you going to apologize?(你准备道歉吗？)</p>
<p>You need to share your toys with your sister。(你应该与妹妹分享玩具。)</p>
<p>He had that toy first。(他先拿到的玩具。)</p>
<p>This toy doesn’t belong to you。(这个玩具不是你的。)</p>
<p>(9)Finding out(发现问题)</p>
<p>What’s happened?(发生什么事了？)</p>
<p>What’s the matter?(怎么了？)</p>
<p>Why are you crying?(为什么哭？)</p>
<p>Don’t worry。(不要担心。)</p>
<p>Everything’s fine。(一切都会好的。)</p>
<p>There’s nothing to be scared of。(没什么可怕的。)</p>
<p>Are you feeling better now?(你现在感觉好些吗？)</p>
<p>We’re right in the next room。(我们就在旁边的屋子)</p>
<p>(10)Discipline(纪律)</p>
<p>Stop doing that。(停下)</p>
<p>We need to discuss this。(我们需要检讨一下。)</p>
<p>Good girls/boys don’t do/say things like that。(好孩子不那样做(说)。)</p>
<p>You’re part of a family, and you can’t think only about yourself。(你是家庭的一员，你不能只想到自己。)</p>
<p>Don’t argue me about this。(不要再和我争论了。)</p>
<p>I’m going to count to three, and if you don’t have the toys picked up by then …(数到三你不收玩具，我就。。。)</p>
<p>No more discussion, you’re going to bed now。(没有商量的余地，你必须现在上床。)</p>
<p>Don’t raise your voice at me!(不要对我提高嗓门！)</p>
<p>That’s a rude way to speak。(那样说话不礼貌/粗鲁。)</p>
<p>(11)Compliments, encouragement(鼓励，夸奖)</p>
<p>Great job!(太棒了！)</p>
<p>I’m so proud of you。(我真为你骄傲！)</p>
<p>Well done!(干得好！)</p>
<p>You were so brave/great/good!(你真勇敢/棒！)</p>
<p>(12)Restaurants, shopping(饭店，购物)</p>
<p>We can’t eat the food until we pay for it。(这食物在付款之前我们不能吃。)</p>
<p>Don’t run around here; we’re not at home。(不要在这乱跑，我们不是在家里。)</p>
<p>Please don’t knock down all those cans。(请不要把那些罐子碰倒。)</p>
<p>Don’t touch anything here. These things aren’t ours。(不要碰任何东西，这不是我们的。)</p>
<p>You promised me you wouldn’t ask me to buy anything。(你答应我的不买任何东西。)</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://cdn.iciba.com/news/word/big_20160828b.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;How deep I love you, the moon represents my heart.&lt;br&gt;你问我爱你有多深，月亮代表我的心。&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="English" scheme="http://ipcreator.me/tags/English/"/>
    
  </entry>
  
  <entry>
    <title>爱单词</title>
    <link href="http://ipcreator.me/2017/02/22/MyView/Diary/love-words/"/>
    <id>http://ipcreator.me/2017/02/22/MyView/Diary/love-words/</id>
    <published>2017-02-21T23:44:05.000Z</published>
    <updated>2017-03-02T23:24:04.931Z</updated>
    
    <content type="html"><![CDATA[<p>图文来源：<a href="http://xue.youdao.com/sw/m/1309029?keyfrom=dict2.index" target="_blank" rel="external">微信号 我爱背单词</a></p>
<h2 id="predator"><a href="#predator" class="headerlink" title="predator"></a>predator</h2><p>英 [‘predətə]  美 [‘prɛdətɚ]<br>n. [动] 捕食者；[动] 食肉动物；掠夺者</p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/acer-predator-15-17-gaming-laptop-skylake-review-21.jpg" alt=""></p>
<p><strong>词根</strong><br>词根： predator<br>adj.<br>predatory 掠夺的，掠夺成性的；食肉的；捕食生物的<br>n.<br>predation 捕食；掠夺</p>
<p><strong>同近义词</strong><br>n. [动]捕食者；食肉动物；掠夺者<br>carnivore , reiver</p>
   <a id="more"></a>
<p><strong>短语</strong><br>Predator Missile 掠食者导弹 ; 掠夺者导弹 ; 者导弹 ; 捕食者导弹<br>Predator Hunt 终极战士狩猎 ; 终极战士猎杀模式<br>UAV Predator 无人机<br>predator model 掠夺者模式 ; 捕食模型<br>Predator B 捕食者B ; 者B型 ; MQ-9 收割者侦察机<br>Kavu Predator 掠食卡甫 ; 掠食卡普<br>PREDATOR CROUCHLEAP 铁血战士的蹲跳<br>UFO Predator 飞碟掠夺者<br>Predator Chain 捕食食物链 ; 捕食链</p>
<p><strong>双语例句</strong><br>Insane pumpkin carving of the Predator.<br>疯狂的南瓜雕刻——食肉动物。</p>
<p>Some residents and experts said the predator may be a bear, a wayward panther or cougar, or even a wolf because 3-inch paw tracks were found at the scene.<br>一些居民和专家认为这种食肉动物可能是一只熊，一头任性的豹子或狮子，抑或是一头狼，因为在现场发现了3英寸长的爪迹。</p>
<p>But just like Dutch in Predator before the final battle, you have to be able to answer only one question about your target before you start: where they are.<br>但就像一战之前的荷兰掠夺者一样，在开始工作之前你必须能够回答实现目标的唯一问题：他们在哪里？</p>
<h2 id="methodology"><a href="#methodology" class="headerlink" title="methodology"></a>methodology</h2><p>英 [meθə’dɒlədʒɪ]  美 [,mɛθə’dɑlədʒi]<br>n. 方法学，方法论<br>[ 复数 methodologies ]</p>
<p><strong>词根</strong><br> method<br>adj.<br>method 使用体验派表演方法的<br>methodical 有系统的；有方法的<br>methodological 方法的，方法论的<br>adv.<br>methodically 有方法地；有系统地<br>n.<br>method 方法；条理；类函数</p>
<p><strong>短语</strong><br>Survey methodology 社会统计调查 ; 测量方法学 ; 调查方法 ; 进行调研方法<br>Sociological Methodology 社会学方法论 (学术期刊) ; 社会学方法论 ; 社会学方法 ; 社会方法论<br>Research Methodology 研究方法 ; 研究方法论 ; 研究方法学 ; 查找资料方法<br>Political Methodology 政治学方法论 ; 政治方法学 ; 国际政治学 ; 政治方法论<br>simulation methodology 仿真方法学 ; 仿真方法论 ; 模拟方法学 ; 仿真理论方法<br>Qualitative methodology 定性方法论 ; 与质化 ; 质性方法论 ; 定性方法<br>Sales Methodology 销售原则 ; 售准绳 ; 销售方法论<br>instructional methodology 教育方法学 ; 教学方法论体系<br>compaction methodology 充填法</p>
<p><strong>双语例句</strong><br>It is not an either / or methodology.<br>它不仅仅是一个可有可无的方法论。</p>
<p>We turn from methodology and science to politics.<br>我们从方法论和科学转变到政治。</p>
<p>This will help them understand the methodology and decide what portions of it to adopt, in what order, and how quickly.<br>这将帮助他们理解方法论并决定接受新方法的哪一部分，以什么样的顺序，速度多快。</p>
<h2 id="primer"><a href="#primer" class="headerlink" title="primer"></a>primer</h2><p>英 [‘praɪmə]  美 [‘praɪmɚ]<br>n. 初级读本；识字课本；原始物</p>
<p><strong>词根</strong><br>词根： prim<br>adj.<br>primary 主要的；初级的；基本的<br>prime 主要的；最好的；基本的<br>primitive 原始的，远古的；简单的，粗糙的<br>primeval 原始的；初期的（等于primaeval）<br>prim 拘谨的；整洁的；呆板的<br>primal 原始的；主要的；最初的<br>adv.<br>prime 极好地<br>n.<br>primary 原色；最主要者<br>prime 初期；青年；精华；全盛时期<br>primitive 原始人<br>primal 被压抑童年情绪的释放<br>priming 底漆；装雷管；起爆剂；装点火药；装填物<br>primality 原始；首要；根本；素性<br>primitivism 原始主义；尚古主义；原始的风格<br>primness 呆滞；拘谨；一本正经<br>vi.<br>prime 作准备<br>prim 显得一本正经<br>vt.<br>prime 使准备好；填装<br>prim 使显得一本正经；把…打扮得整整齐齐<br>primal 释放（被压抑的童年情绪）</p>
<p><strong>短语</strong><br>Factory primer 工厂底漆 ; 工厂 ; 工厂底漆，工厂防锈漆<br>Epoxy primer 环氧底漆 ; 环氧树脂底漆 ; 环氧底漆<br>shop primer 临时防锈底漆 ; 车间底漆 ; 预涂底漆 ; 防底漆<br>primer lever 起动给油杆 ; 燃油泵上体 ; 起动注油器杆 ; 启动杆<br>forward primer 正向引物 ; 前置引子 ; 计上游引物<br>Foundation Primer 焕颜凝露 ; 妆前霜 ; 妆前乳 ; 经典款<br>Primer Extension 引物延伸 ; 引物延伸法 ; 的有引物延伸法 ; 引物延伸反应<br>metal primer 金属底漆 ; 金属用底补土 ; 金属打底剂<br>finish primer 末道底漆 ; 硝基底漆</p>
<p><strong>双语例句</strong><br>For low-risk pregnancies, sex is considered safe, advises a primer for doctors published this week in the Canadian Medical Association Journal.<br>在这周加拿大医学协会期刊中发布的医生初级读本中建议，低风妊娠中的性生活是安全的。</p>
<p>But Gregory has wisely chosen to reach out to a broader audience by providing a highly accessible primer on the deadly workings of the state that proclaimed itself the workers’ paradise.<br>但格里高利明智地选择面向更广泛的读者，以一部极为通俗易懂的初级读本，来书写这个自称劳动者乐土的国家所行的暴政。</p>
<p>A primer data model with default submission settings could be sent with the form and then edited at each site.<br>可以发送包含默认提交设置的基本数据模型然后在每个站点上进行编辑。</p>
<h2 id="portrait"><a href="#portrait" class="headerlink" title="portrait"></a>portrait</h2><p>英 [‘pɔːtrɪt]  美 [‘pɔrtrɪt]<br>n. 肖像；描写；半身雕塑像<br>n. (Portrait)人名；(法)波特雷</p>
<p><strong>词根</strong><br>portrait<br>n.<br>portrayal 描绘；画像，肖像<br>portraiture 肖像画；肖像绘制；人像摄影<br>portraitist 肖像画家；人像摄影师<br>portrayer 记述者；描画者；肖像画家</p>
<p>Family Portrait 太阳系全家福 ; 全家福 ; 太阳系全家福 ; 四十不惑<br>Self Portrait Self-Portrait ; 自画像 ; 私相簿 ; 白石草衣图<br>Group portrait 群像<br>portrait mode 纵向模式 ; 肖像模式 ; 画像模式 ; 当使用直向显示<br>PORTRAIT PHOTOS 商业拍摄作品 ; 肖像摄影 ; 人像写真作品 ; 写真照<br>portrait management 纵向管理<br>Head portrait 头像 ; 头像表情 ; 头像<br>embroidered portrait 刺绣肖像 ; 绣像<br>portrait lens 人像镜头 ; 像镜头</p>
<p><strong>双语例句</strong><br>Hang the portrait straight.<br>把画像挂端正。</p>
<p>The portrait of some woman.<br>一些女人的肖像。</p>
<p>The artist has reproduced your features very well in this portrait.<br>这位艺术家在这幅画像中把你的容貌重现得维妙维肖。</p>
<h2 id="landscape"><a href="#landscape" class="headerlink" title="landscape"></a>landscape</h2><p>英 [‘læn(d)skeɪp]  美 [‘lænd’skep]<br>n. 风景；风景画；景色；山水画；乡村风景画；地形；（文件的）横向打印格式<br>vt. 对…做景观美化，给…做园林美化；从事庭园设计<br>vi. 美化（环境等），使景色宜人；从事景观美化工作，做庭园设计师</p>
<p><strong>词根</strong><br> landscape<br>n.<br>landscaping 景观美化<br>landscaper 庭园设计家<br>landscapist 风景画家</p>
<p><strong>短语</strong><br>Landscape Design 景观设计 ; 园林设计 ; 风景设计 ; 亚太景观设计<br>cultural landscape 文化景观 ; 人文景观 ; 文化地景 ; 人为景观<br>urban landscape 城市景观 ; 都市景观 ; 城市园林 ; 城市园林绿化<br>landscape plant 园林植物 ; 景观植物 ; 园林植物景观 ; 景观植物<br>landscape lighting 景观照明 ; 景不雅照明 ; 景观灯光 ; 景观亮化<br>Landscape Urbanism 景观都市主义 ; 景观城市主义 ; 城市景观规划 ; 地景都市主义<br>geological landscape 地质景观 ; 广东地质山水酒店 ; 地质地貌<br>hard landscape 硬质景观 ; 设施景观<br>Floating Landscape 恋之风景 ; 恋之风景未剪切版</p>
<p><strong>双语例句</strong><br>Mist often blurs the landscape.<br>薄雾常常使风景暗淡。</p>
<p>The boy painted a landscape on paper.<br>这个男孩子在纸上画了一张风景画。</p>
<p>He thumbtacked the picture of landscape to the wall.<br>他用图钉把那张风景画钉在墙上。</p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/20170302_155150.jpg" alt=""></p>
<p><strong>firework</strong><br>英 [‘faɪəwɜːk]  美 [‘faɪɚwɝk]<br>n. 烟火；激烈情绪</p>
<p><strong>forbid</strong><br>英 [fə’bɪd]  美 [fɚ’bɪd]<br>vt. 禁止；不准；不允许；〈正式〉严禁<br>[ 过去式 forbade 过去分词 forbidden 现在分词 forbidding ]</p>
<p><strong>prohibit</strong><br>英 [prə(ʊ)’hɪbɪt]  美 [prə’hɪbɪt]<br>vt. 阻止，禁止</p>
<p><strong>ban</strong><br>英 [bæn]  美 [bæn]<br>vt. 禁止，取缔<br>n. 禁令，禁忌</p>
<p><strong>discharge</strong><br>英 [dɪs’tʃɑːdʒ]  美 [dɪs’tʃɑrdʒ]<br>vt. 解雇；卸下；放出；免除<br>vi. 排放；卸货；流出<br>n. 排放；卸货；解雇</p>
<p><strong>kindle</strong><br>英 [‘kɪnd(ə)l]  美 [‘kɪndl]<br>vt. 点燃；激起；照亮<br>vi. 发亮；着火；激动起来</p>
<p><strong>admit</strong><br>英 [əd’mɪt]  美 [əd’mɪt]<br>vt. 承认；准许进入；可容纳<br>vi. 承认；容许</p>
<p><strong>shack</strong><br>英 [ʃæk]  美 [ʃæk]<br>n. 棚屋；小室<br>vi. 居住</p>
<p><strong>emergency</strong><br>英 [ɪ’mɜːdʒ(ə)nsɪ]  美 [ɪ’mɝdʒənsi]<br>n. 紧急情况；突发事件；非常时刻<br>adj. 紧急的；备用的</p>
<p>Emergency department 急症室 ; 急诊室 ; 急诊科 ; 急症室<br>EMERGENCY STOP 紧急停止 ; 异常停止 ; 紧急停机 ; 紧急停车<br>emergency switch 紧急开关 ; 应急开关 ; 紧急保险开关 ; 焚急开关<br>Emergency Alarm 紧急报警 ; 紧急呼救设施 ; 急报警 ; 警报装置<br>emergency case 急诊病人 ; 急救盒 ; 急诊病例 ; 急症<br>emergency goods 急需品 ; 紧急用品 ; 救济品 ; 急用品<br>emergency preparedness 应急准备 ; 紧急状况的准备工作 ; 应急准备状态 ; 应急预案<br>Emergency Ladder 逃生梯 ; 紧急避难梯 ; 应急梯<br>Emergency Phone 紧急呼救电话 ; 紧急电话 ; 急救电话 ; 紧急救护电话</p>
<h2 id="accelerate"><a href="#accelerate" class="headerlink" title="accelerate"></a>accelerate</h2><p>英 [ək’seləreɪt]  美 [əkˈsɛləˌret]<br>vt. 使……加快；使……增速<br>vi. 加速；促进；增加<br>[ 过去式 accelerated 过去分词 accelerated 现在分词 accelerating ]</p>
<p><strong>词根</strong><br> accelerate<br>adj.<br>accelerated 加速的；加快的<br>accelerating 促进的，[物] 加速的；催化的<br>accelerative 加速的；促进的；催促的<br>acceleratory 加速的；催促的（等于accelerative）<br>n.<br>acceleration 加速，促进；[物] 加速度<br>accelerator 油门；催化剂；[机] 加速装置<br>accelerometer [航][物] 加速计<br>v.<br>accelerated 加速；促进（accelerate的变形）</p>
<p><strong>同近义词</strong><br>vi. 加速；促进；增加<br>improve , increase speed</p>
<p><strong>短语</strong><br>accelerate increase 加速 ; 加大<br>PC Accelerate 系统加速器<br>Accelerate measures 加快措施<br>accelerate math 渐进数学里<br>accelerate time 加速时间 ; 加速时间<br>Accelerate Events 加速事件<br>table accelerate 工作台导槽<br>accelerate to 加速<br>accelerate card 加速卡</p>
<p><strong>双语例句</strong><br>How do you plan to accelerate the development of these technologies?<br>目前您打算如何加快这方面的技术研发？</p>
<p>At that point, post 2012, the social software market growth will accelerate as will the overall impact of social media on business and society.<br>在这一点上，社区软件市场在2012年以后将加速增长，使得社区媒体对企业和社会产生全面的冲击。</p>
<p>Or you can choose to accelerate your growth and intentionally devour life and all it offers.<br>又或许你可以选择加速自己的成长，故意地挥霍生活及其提供的一切。</p>
<h2 id="anatomy"><a href="#anatomy" class="headerlink" title="anatomy"></a>anatomy</h2><p>英 [ə’nætəmɪ]  美 [ə’nætəmi]<br>n. 解剖；解剖学；剖析；骨骼<br>[ 复数 anatomies ]</p>
<p><strong>词根</strong><br>词根： anatomy<br>adj.<br>anatomical 解剖的；解剖学的；结构上的<br>anatomic 组织的；解剖学上的；结构上的<br>adv.<br>anatomically 结构上；解剖学上<br>n.<br>anatomist 解剖学家；剖析者<br>vt.<br>anatomise 解剖；解析<br>anatomize 解剖；仔细分析</p>
<p><strong>同近义词</strong><br>n. [解剖]解剖；解剖学；剖析；骨骼<br>cadre , dissection</p>
<p><strong>短语</strong><br>Human Anatomy 人体解剖学 ; 人体解剖学 ; 人体解剖高尺寸图片 ; 解剖学<br>plant anatomy 植物解剖学 ; 植物形态解剖学 ; 植物解剖<br>Regional Anatomy 局部解剖学 ; 局部解剖 ; 人体解剖学 ; 解剖学<br>Greys Anatomy 实习医生格蕾 ; 实习女医生葛蕾斯 ; 外科女实习生 ; 实习医生<br>sectional anatomy 断层解剖学 ; 断面解剖 ; 断层解剖 ; 断面解剖学<br>topographic anatomy 局部解剖学 ; 外部解剖学 ; 局部解剖学;局部解剖学<br>System Anatomy 系统分析 ; 系统解剖学 ; 系统剖析 ; 解剖<br>Medical Anatomy 医学解剖 ; 医用解剖学 ; 医学解剖学 ; 医学解剖学<br>imaging anatomy 影像解剖 ; 影像解剖学 ; 影象解剖学 ; 影像解剖学</p>
<p><strong>双语例句</strong><br>A knowledge of anatomy adds to the appreciation of works of art.<br>解剖学知识有助于提高对艺术作品的鉴赏力。</p>
<p>Now that you have seen the anatomy of each component, you can deploy them.<br>您已经了解了对每个组件的剖析，现在可以部署它们了。</p>
<p>I don’t aim to be comprehensive, but to convey something of what continues to fascinate me about the wonderful subject of human anatomy.<br>我的目的不在于广泛全面的介绍身体各部位，而是传达一些一直吸引着我的关于人体解剖学的东西。</p>
<h2 id="Reinvent"><a href="#Reinvent" class="headerlink" title="Reinvent"></a>Reinvent</h2><p>英 [ˌri:ɪnˈvent]  美 [ˌriɪnˈvɛnt]<br>vt. 重新使用；彻底改造；重复发明（在不知他人已发明的情况下）</p>
<p><strong>词根</strong><br>invent</p>
<p><strong>同近义词</strong><br>vt. 重新使用；彻底改造；重复发明（在不知他人已发明的情况下）<br>reemploy</p>
<p><strong>短语</strong><br>REINVENT CONTINUOUSLY 不断创新<br>function reinvent 职能重塑<br>Reinvent Payphones 重塑电话亭<br>reinvent HP 再造惠普<br>Reinvent themselves 重塑自我<br>Reinvent Yourself 重塑自我<br>reinvent oneself 改过自新<br>reinvent government 彻底改造<br>To Reinvent An Industry 产业模式创新</p>
<p><strong>双语例句</strong><br>In short, we need to reinvent the toilet.<br>简而言之，我们需要彻底改造马桶。</p>
<p>I will try my best to reinvent my own life.<br>我愿尽力彻底改造自己的生活。</p>
<p>We need not reinvent ourselves, but only remember who we are when we are at our best.<br>我们无须彻底改变自己，只是在我们到达巅峰时不要忘了我们是谁。</p>
<h2 id="sustainable"><a href="#sustainable" class="headerlink" title="sustainable"></a>sustainable</h2><p>英 [sə’steɪnəb(ə)l]  美 [sə’stenəbl]<br>adj. 可以忍受的；足可支撑的；养得起的；可持续的</p>
<p><strong>词根</strong><br>词根： sustain<br>adj.<br>sustained 持续的；持久的；持久不变的<br>sustentacular 支撑的；支持的<br>n.<br>sustainability 持续性；永续性；能维持性<br>sustainer 支持者，维持者；主发动机；支撑的人物<br>sustentation 支撑，维持；食物<br>v.<br>sustained 维持（sustain的过去式和过去分词）；承受<br>vt.<br>sustain 维持；支撑，承担；忍受；供养；证实</p>
<p><strong>短语</strong><br>Sustainable Agriculture 可持续农业 ; 永续农业 ; 持续农业 ; 持久农业<br>sustainable tourism 可持续旅游 ; 永续旅游 ; 永续观光 ; 第十单元<br>Sustainable Construction 可持续建筑 ; 可持续建设 ; 可持续性建筑管理 ; 永续建筑<br>commercially sustainable 商业化可持续<br>Sustainable Luxury 可持续性奢侈 ; 性奢侈 ; 可继续性朴素<br>Sustainable innovation 持续创新 ; 可持续创新 ; 永续创新 ; 可持续创新<br>Sustainable Urbanization 可持续城市化 ; 可持续城镇化 ; 可持续城市化 ; 可持续的城市化<br>Sustainable Financing 可持续性融资 ; 可持续融资 ; 可持续金融 ; 可持续融资<br>Sustainable Transportation 永续运输 ; 可持续交通 ; 绿色技术 ; 可持续交通运输</p>
<p><strong>双语例句</strong><br>“There is nothing sustainable about it, “ she said.<br>“这里没有什么是可持续的，”她说。</p>
<p>“To make our agriculture sustainable, we have to do this,” he said.”Ninety percent of the country is like this, all hills.<br>“要让我们的农业可持续地发展，我们只能这样做，”他说，“我们的土地百分之九十都是这样，满目皆山。</p>
<p>Working together to provide fresh, sustainable food for the community is one of the hot trends in some community organizations.<br>一起工作，为社区提供新鲜的，可持续的食物，这是一些社区组织热门趋势之一。</p>
<hr>
<h2 id="supple"><a href="#supple" class="headerlink" title="supple"></a>supple</h2><p>supple<br>英 [‘sʌp(ə)l]  美 [‘sʌpl]<br>adj. 柔软的；灵活的；顺从的；易弯曲的；逢迎的<br>vt. 使柔软；使顺从<br>vi. 变柔顺；变柔软<br>n. (Supple)人名；(意、西)苏普莱<br>[ 比较级 suppler 最高级 supplest 过去式 suppled 过去分词 suppled 现在分词 suppling ]</p>
<p><strong>词根</strong><br>词根： supple<br>n.<br>suppleness 柔软；易弯曲；顺从</p>
<p><strong>同近义词</strong><br>adj. 柔软的；灵活的；顺从的；易弯曲的；逢迎的<br>flexible , soft , elastic , tender , ductile<br>vt. 使柔软；使顺从<br>reconcile , conform<br>vi. 变柔顺；变柔软<br>tender , limber up</p>
<p><strong>短语</strong><br>Supple leather 软革 ; 软革<br>SUPPLE BEAR 绵尾熊<br>Supple Round 柔顺圆润<br>supple suede 软山羊皮<br>supple mdinedriing 活性资料<br>SUPPLE MIST 防锈剂<br>Supple Skin 柔软皮肤<br>supple nature 容易适应的本性<br>Ultra supple 超柔</p>
<p><strong>双语例句</strong><br>Cultivating a humorous mindset helps you see yourself and any situation with a more supple mind so that you are not locked into a negative view.<br>培养幽默的心态有助于你了解自己，而且无论在什么状况下都能有一个灵活的头脑，这样就不会局限在消极的观点中无法自拔。</p>
<p>I often do yoga, so I’m quite supple.<br>我常常做瑜伽，所以我的身体很柔软。</p>
<p>Moisturizer is the key to soft, supple skin in winter.<br>在冬季，润肤霜是保持皮肤柔软细滑的密钥。</p>
<h2 id="vigor"><a href="#vigor" class="headerlink" title="vigor"></a>vigor</h2><p>英  美 [‘vɪgɚ]<br>n. [生物] 活力，精力<br>n. (Vigor)人名；(英、法)维戈尔</p>
<p><strong>词根</strong><br>词根： vigor<br>adj.<br>vigorous 有力的；精力充沛的<br>adv.<br>vigorously 精神旺盛地，活泼地<br>n.<br>vigour 活力；气势</p>
<p><strong>同近义词</strong><br>n. [生物]活力，精力<br>energy , vitality , spring , steam , razzamatazz</p>
<p><strong>短语</strong><br>Vigor Bovolenta 博沃伦塔<br>Vigor index 活力指数 ; 活力指数 ; 活力指标<br>Vigor Board 活力板 ; 活力板<br>germination vigor 发芽势 ; 发芽活力 ; 萌发势<br>Hotel Vigor 活力酒店<br>vigor become 成为活力 ; 活力成为<br>Totemic Vigor 图腾活力<br>tree vigor 树势 ; 树木长势<br>lacking vigor 虚弱的</p>
<p><strong>双语例句</strong><br>If you want to retain youthful vigor,you have to take regular exercise.<br>如果你想保持青春活力，你就得经常锻炼。</p>
<p>In fact, the huge inheritance does not do him any good, but tends to undermine his vigor and passion for life.<br>实际上，这么大笔的遗产对他不仅没有什么好处，反而会损害他的活力和对生活的激情。</p>
<p>They would be lying there in the tree like, ‘Oh, just let me just die up here, ‘ because they lacked any kind of vigor.<br>因为它们一点活力都没有, 他们会整天在树下躺着，一付‘噢，实在活不起了，让我死在这里好了’的样子。</p>
<h2 id="temperamental"><a href="#temperamental" class="headerlink" title="temperamental"></a>temperamental</h2><p>英 [,temp(ə)rə’ment(ə)l]  美 [‘tɛmprə’mɛntl]<br>adj. 喜怒无常的；性情的；易兴奋的<br>[ 比较级 more temperamental 最高级 most temperamental ]</p>
<p><strong>词根</strong><br>词根： temper<br>adv.<br>temperamentally 气质地<br>n.<br>temper 脾气；（钢等）回火；性情；倾向<br>temperament 气质，性情，性格；急躁<br>vi.<br>temper 回火；调和<br>vt.<br>temper 使回火；锻炼；调和；使缓和</p>
<p><strong>同近义词</strong><br>adj. 喜怒无常的；性情的；易兴奋的<br>moody , twittery</p>
<p><strong>短语</strong><br>Temperamental Side 气质一面<br>temperamental life 气性生命<br>temperamental weather 变幻无常的天气<br>temperamental characteristics 性格特点<br>temperamental trait 气质特性 ; 以气质特质<br>temperamental fit 性情相投<br>Amante Temperamental 德国摇滚<br>temperamental character 性格特征<br>Temperamental behaviour 情绪起伏大</p>
<p><strong>双语例句</strong><br>What makes them laugh and cry, why are they temperamental, why are they so difficult to get along with, what do they really want?<br>是什么让他们欢笑和哭泣，为什么他们喜怒无常，为什么他们这么难相处，他们到底想要什么？</p>
<p>Stress, such as that found in disrupted families, seems to impair the ability of temperamental children to adapt to their surroundings, the greater the amount of stress, the less well they adapt.<br>压力，比如在破裂家庭中产生的压力，似乎削弱了这些喜怒无常的孩子们适应环境的能力，压力越大，他们适应环境的能力越弱。</p>
<h2 id="Companionship"><a href="#Companionship" class="headerlink" title="Companionship"></a>Companionship</h2><p>companionship<br>英 [kəm’pænjənʃɪp]  美 [kəm’pænjən’ʃɪp]<br>n. 友谊；陪伴；交谊</p>
<p><strong>词根</strong><br>词根： company<br>adj.<br>companionable 好交往的；友善的；适于做朋友的<br>n.<br>company 公司；陪伴，同伴；连队<br>companion 同伴；朋友；指南；手册<br>vi.<br>company 交往<br>vt.<br>company 陪伴<br>companion 陪伴</p>
<p><strong>同近义词</strong><br>n. 友谊；陪伴；交谊<br>friendship , fellowship</p>
<p><strong>短语</strong><br>companionship family 友爱家庭<br>Genuine Companionship 真正友谊<br>And Companionship 和陪伴<br>Peer Companionship 同伴陪同<br>Quiet Companionship 安静相伴<br>Social companionship 社会成员身份<br>Some Companionship 有人陪伴<br>Your Companionship 您一路陪同<br>companionship therapy 友谊疗法 ; 友谊心理治疗</p>
<p><strong>双语例句</strong><br>Don’t ask your friends for advice; ask for companionship and encouragement.<br>不要向你的朋友咨询建议；而是寻求友谊和鼓励。</p>
<p>But people who watched for companionship were most distressed by the loss of their shows.<br>但是那些寻求友谊的人们会因为失去喜欢的电视节目而非常痛苦。</p>
<p>Also, treatment should be voluntary as far as possible, while service users should have plenty of contact and companionship with other service users.<br>另外，应当尽可能做到自愿接受治疗，而且服务使用者应当与使用服务的其他人有广泛的联系和友谊。</p>
<h2 id="conservative"><a href="#conservative" class="headerlink" title="conservative"></a>conservative</h2><p>英 [kən’sɜːvətɪv]  美 [kən’sɝvətɪv]<br>adj. 保守的<br>n. 保守派，守旧者<br>[ 比较级 more conservative 最高级 most conservative ]</p>
<p><strong>词根： conserved</strong><br>adj.<br>conserved 保守的<br>adv.<br>conservatively 谨慎地；保存地；适当地<br>n.<br>conservation 保存，保持；保护<br>conservatism 保守主义；守旧性<br>conservationist 自然资源保护论者<br>v.<br>conserved 保存；保全（conserve的过去式）</p>
<p><strong>同近义词</strong><br>adj. 保守的<br>standpat , backward-looking<br>n. 保守派，守旧者<br>old guard , pontificator</p>
<p><strong>短语</strong><br>Conservative liberalism 保守自由主义 ; 保守自由主义<br>Force conservative 保守力<br>conservative treatment 保守治疗 ; 保守疗法 ; 非手术治疗 ; 保守性治疗<br>conservative recombination 保守重组 ; 保守性重组<br>conservative property 守恒性质 ; 保守性 ; 保守性质<br>conservative replacement 保守替换 ; 保守(性)替换，保存性置换<br>conservative field 保守场 ; 保守力场 ; 守恒场 ; 保守向量场<br>conservative prediction 保守预测 ; 保守预测值<br>Conservative transposition 保守型转座 ; 保守性转座 ; 保守转座 ; 保存型转位</p>
<p><strong>双语例句</strong><br>He listed himself as a conservative.<br>他自称是一个保守主义者。<br>《21世纪大英汉词典》<br>The more conservative politicians were trying to deradicalize the liberation movement.<br>较保守的政治家正试图使解放运动放弃偏激的立场。<br>《21世纪大英汉词典》<br>The young people are the most eager to learn and the least conservative in their thinking.<br>青年人最肯学习，最少保守思想。<br>《新英汉大辞典》<br><img src="https://oimagea2.ydstatic.com/image?id=-7578744340309957593&amp;product=dict&amp;_w=990&amp;_h=3620&amp;originWidth=990&amp;originHeight=3620" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;图文来源：&lt;a href=&quot;http://xue.youdao.com/sw/m/1309029?keyfrom=dict2.index&quot;&gt;微信号 我爱背单词&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;predator&quot;&gt;&lt;a href=&quot;#predator&quot; class=&quot;headerlink&quot; title=&quot;predator&quot;&gt;&lt;/a&gt;predator&lt;/h2&gt;&lt;p&gt;英 [‘predətə]  美 [‘prɛdətɚ]&lt;br&gt;n. [动] 捕食者；[动] 食肉动物；掠夺者&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/acer-predator-15-17-gaming-laptop-skylake-review-21.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;词根&lt;/strong&gt;&lt;br&gt;词根： predator&lt;br&gt;adj.&lt;br&gt;predatory 掠夺的，掠夺成性的；食肉的；捕食生物的&lt;br&gt;n.&lt;br&gt;predation 捕食；掠夺&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同近义词&lt;/strong&gt;&lt;br&gt;n. [动]捕食者；食肉动物；掠夺者&lt;br&gt;carnivore , reiver&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="English" scheme="http://ipcreator.me/tags/English/"/>
    
  </entry>
  
  <entry>
    <title>Beautiful articles of English</title>
    <link href="http://ipcreator.me/2017/02/21/MyView/Diary/beautiful-article-of-english/"/>
    <id>http://ipcreator.me/2017/02/21/MyView/Diary/beautiful-article-of-english/</id>
    <published>2017-02-21T12:25:05.000Z</published>
    <updated>2017-02-23T14:05:29.273Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://okkntqe2h.bkt.clouddn.com/youthDev.jpg" alt=""></p>
<p><a href="http://www.tingclass.net/show-6613-109419-1.html?sid=AZGF5i1d9MuL8E57a0CHYor0" target="_blank" rel="external">Youth</a></p>
<h2 id="001-青春"><a href="#001-青春" class="headerlink" title="001 青春"></a>001 青春</h2><p><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/01-youth.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/01-youth.mp3</a></p>
<p>Youth is not a time of life; it is a state of mind; it is not a matter of rosy cheeks, red lips and supple knees; it is a matter of the will, a quality of the imagination, a vigor of the emotions; it is the freshness of the deep springs of life.</p>
<p>青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志，恢宏的想象，炙热的恋情；青春是生命的深泉在涌流。</p>
<a id="more"></a>
<p>Youth means a temperamental predominance of courage over timidity, of the appetite for adventure over the love of ease. This often exists in a man of 60 more than a boy of 20. <strong>Nobody grows old merely by a number of years. We grow old by deserting our ideals.</strong></p>
<p>青春气贯长虹，勇锐盖过怯弱，进取压倒苟安。如此锐气，二十后生而有之，六旬男子则更多见。年岁有加，并非垂老，理想丢弃，方堕暮年。</p>
<p><strong>Years may wrinkle the skin, but to give up enthusiasm wrinkles the soul.</strong> Worry, fear, self-distrust bows the heart and turns the spirit back to dust.</p>
<p>岁月悠悠，衰微只及肌肤；热忱抛却，颓废必致灵魂忧烦，惶恐，丧失自信，定使心灵扭曲，意气如灰。</p>
<p>Whether 60 or 16, there is in every human being’s heart the lure of wonders, the unfailing child appetite for what’s next and the joy of the game of living. In the center of your heart and my heart, there is a wireless station; so long as it receives messages of beauty, hope, cheer, courage and power from man and from the infinite, so long as you are young.</p>
<p>无论年届花甲，拟或二八芳龄，心中皆有生命之欢乐，奇迹之诱惑，孩童般天真久盛不衰。人人心中皆有一台天线，只要你从天上人间接受美好、希望、欢乐、勇气和力量的信号，你就青春永驻，风华常存。</p>
<p>When your aerials are down, and your spirit is covered with snows of cynicism and the ice of pessimism, then you’ve grown old, even at 20; but as long as your aerials are up, to catch waves of optimism, there’s hope you may die young at 80.</p>
<p>一旦天线下降，锐气便被冰雪覆盖，玩世不恭、自暴自弃油然而生，即使年方二十，实已垂垂老矣；然则只要树起天线，捕捉乐观信号，你就有望在八十高龄告别尘寰时仍觉年轻。</p>
<h2 id="002-Three-Days-to-See-Excerpts-假如给我三天光明-节选"><a href="#002-Three-Days-to-See-Excerpts-假如给我三天光明-节选" class="headerlink" title="002 Three Days to See(Excerpts)假如给我三天光明(节选)"></a>002 Three Days to See(Excerpts)假如给我三天光明(节选)</h2><p> <img src="http://okkntqe2h.bkt.clouddn.com/20091221%E5%81%87%E5%A6%82%E7%BB%99%E6%88%91%E4%B8%89%E5%A4%A9%E5%85%89%E6%98%8E.jpg" alt=""></p>
<p> <a href="http://www.tingclass.net/show-6613-35141-1.html" target="_blank" rel="external">Three Days to See</a><br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/02-three_days_to_see.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/02-three_days_to_see.mp3</a></p>
<p>All of us have read thrilling stories in which the hero had only a limited and specified time to live. Sometimes it was as long as a year, sometimes as short as 24 hours. But always we were interested in discovering just how the doomed hero chose to spend his last days or his last hours. I speak, of course, of free men who have a choice, not condemned criminals whose sphere of activities is strictly delimited.</p>
<p>我们都读过震撼人心的故事，故事中的主人公只能再活一段很有限的时光，有时长达一年，有时却短至一日。但我们总是想要知道，注定要离世人的会选择如何度过自己最后的时光。当然，我说的是那些有选择权利的自由人，而不是那些活动范围受到严格限定的死囚。</p>
<p>Such stories set us thinking, wondering what we should do under similar circumstances. What events, what experiences, what associations should we crowd into those last hours as mortal beings, What happiness should we find in reviewing the past? What regrets?</p>
<p>这样的故事让我们思考，在类似的处境下，我们该做些什么?作为终有一死的人，在临终前的几个小时内我们应该做什么事，经历些什么或做哪些联想?回忆往昔，什么使我们开心快乐?什么又使我们悔恨不已?</p>
<p>Sometimes I have thought it would be an excellent rule to <strong>live each day as if we should die tomorrow</strong>. Such an attitude would emphasize sharply the values of life. We should live each day with gentleness, vigor and a keenness of appreciation which are often lost when time stretches before us in the constant panorama of more days and months and years to come. There are those, of course, who would adopt the Epicurean motto of “Eat, drink, and be merry”. But most people would be chastened by the certainty of impending death.</p>
<p>有时我想，把每天都当作生命中的最后一天来边，也不失为一个极好的生活法则。这种态度会使人格外重视生命的价值。我们每天都应该以优雅的姿态，充沛的精力，抱着感恩之心来生活。但当时间以无休止的日，月和年在我们面前流逝时，我们却常常没有了这种子感觉。当然，也有人奉行“吃，喝，享受”的享乐主义信条，但绝大多数人还是会受到即将到来的死亡的惩罚。</p>
<p>In stories the doomed hero is usually saved at the last minute by some stroke of fortune, but almost always his sense of values is changed. He becomes more appreciative of the meaning of life and its permanent spiritual values. <strong>It has often been noted that those who live, or have lived, in the shadow of death bring a mellow sweetness to everything they do.</strong></p>
<p>在故事中，将死的主人公通常都在最后一刻因突降的幸运而获救，但他的价值观通常都会改变，他变得更加理解生命的意义及其永恒的精神价值。我们常常注意到，那些生活在或曾经生活在死亡阴影下的人无论做什么都会感到幸福。</p>
<p>Most of us, however, take life for granted. We know that one day we must die, but usually we picture that day as far in the future. When we are in buoyant health, death is all but unimaginable. We seldom think of it. The days stretch out in an endless vista. So we go about our petty tasks, hardly aware of our listless attitude toward life.</p>
<p>然而，我们中的大多数人都把生命看成是理所当然的。我们知道有一天我们必将面对死亡，但总认为那一天还在遥远的将来。当我们身强体健之时，死亡简直不可想象，我们很少考虑到它。日子多得好像没有尽头。因此我们一味忙于琐事，几乎意识不到我们对待生活的冷漠态度。</p>
<p>The same lethargy, I am afraid, characterizes the use of all our faculties and senses. <strong>Only the deaf appreciate hearing, only the blind realize the manifold blessings that lie in sight.</strong> Particularly does this observation apply to those who have lost sight and hearing in adult life. But those who have never suffered impairment of sight or hearing seldom make the fullest use of these blessed faculties. Their eyes and ears take in all sights and sounds hazily, without concentration and with little appreciation. <strong>It is the same old story of not being grateful for what we have until we lose it, of not being conscious of health until we are ill.</strong></p>
<p>我担心同样的冷漠也存在于我们对自己官能和意识的运用上。只有聋子才理解听力的重要，只有盲人才明白视觉的可贵，这尤其适用于那些成年后才失去视力或听力之苦的人很少充分利用这些宝贵的能力。他们的眼睛和耳朵模糊地感受着周围的景物与声音，心不在焉，也无所感激。这正好我们只有在失去后才懂得珍惜一样，我们只有在生病后才意识到健康的可贵。</p>
<p>I have often thought it would be a blessing if each human being were stricken blind and deaf for a few days at some time during his early adult life. <strong>Darkness would make him more appreciative of sight; silence would teach him the joys of sound.</strong></p>
<p>我经常想，如果每个人在年轻的时候都有几天失时失聪，也不失为一件幸事。黑暗将使他更加感激光明，寂静将告诉他声音的美妙。</p>
<h2 id="003-Companionship-of-Books-以书为伴"><a href="#003-Companionship-of-Books-以书为伴" class="headerlink" title="003 Companionship of Books 以书为伴"></a>003 Companionship of Books 以书为伴</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/003-quote-my-soul-found-ease-and-rest-in-the-companionship-of-books-pat-conroy-48-40-77.jpg" alt=""></p>
<p>Companionship of Books<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/03-companionship_of_books.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/03-companionship_of_books.mp3</a></p>
<p><strong>A man may usually be known by the books he reads as well as by the company he keeps</strong>; for there is a companionship of books as well as of men; and one should always live in the best company, whether it be of books or of men.</p>
<p>通常看一个读些什么书就可知道他的为人，就像看他同什么人交往就可知道他的为人一样，因为有人以人为伴，也有人以书为伴。无论是书友还是朋友，我们都应该以最好的为伴。</p>
<p><strong>A good book may be among the best of friends.It is the same today that it always was, and it will never change. It is the most patient and cheerful of companions. It does not turn its back upon us in times of adversity or distress. It always receives us with the same kindness; amusing and instructing us in youth, and comforting and consoling us in age.</strong></p>
<p>好书就像是你最好的朋友。它始终不渝，过去如此，现在如此，将来也永远不变。它是最有耐心，最令人愉悦的伴侣。在我们穷愁潦倒，临危遭难时，它也不会抛弃我们，对我们总是一如既往地亲切。在我们年轻时，好书陶冶我们的性情，增长我们的知识；到我们年老时，它又给我们以慰藉和勉励。</p>
<p>Men often discover their affinity to each other by the mutual love they have for a book just as two persons sometimes discover a friend by the admiration which both entertain for a third. There is an old proverb, <strong>‘Love me, love my dog.”</strong> But there is more wisdom in this:” <strong>Love me, love my book.</strong>” The book is a truer and higher bond of union. Men can think, feel, and sympathize with each other through their favorite author. They live in him together, and he in them.</p>
<p>人们常常因为喜欢同一本书而结为知已，就像有时两个人因为敬慕同一个人而成为朋友一样。有句古谚说道：“爱屋及屋。”其实“爱我及书”这句话蕴涵更多的哲理。书是更为真诚而高尚的情谊纽带。人们可以通过共同喜爱的作家沟通思想，交流感情，彼此息息相通，并与自己喜欢的作家思想相通，情感相融。</p>
<p><strong>A good book is often the best urn of a life enshrining the best that life could think out; for the world of a man’s life is, for the most part, but the world of his thoughts.</strong> Thus the best books are treasuries of good words, the golden thoughts, which, remembered and cherished, become our constant companions and comforters.</p>
<p>好书常如最精美的宝器，珍藏着人生的思想的精华，因为人生的境界主要就在于其思想的境界。因此，最好的书是金玉良言和崇高思想的宝库，这些良言和思想若铭记于心并多加珍视，就会成为我们忠实的伴侣和永恒的慰藉。</p>
<p>Books possess an essence of immortality. They are by far the most lasting products of human effort. Temples and statues decay, but books survive. <strong>Time is of no account with great thoughts</strong>, which are as fresh today as when they first passed through their author’s minds, ages ago. What was then said and thought still speaks to us as vividly as ever from the printed page. The only effect of time have been to sift out the bad products; <strong>for nothing in literature can long survive e but what is really good.</strong></p>
<p>书籍具有不朽的本质，是为人类努力创造的最为持久的成果。寺庙会倒坍，神像会朽烂，而书却经久长存。对于伟大的思想来说，时间是无关紧要的。多年前初次闪现于作者脑海的伟大思想今日依然清新如故。时间惟一的作用是淘汰不好的作品，因为只有真正的佳作才能经世长存。</p>
<p>Books introduce us into the best society; they bring us into the presence of the greatest minds that have ever lived. We hear what they said and did; we see the as if they were really alive; we sympathize with them, enjoy with them, grieve with them; their experience becomes ours, and we feel as if we were in a measure actors with them in the scenes which they describe.</p>
<p>书籍介绍我们与最优秀的人为伍，使我们置身于历代伟人巨匠之间，如闻其声，如观其行，如见其人，同他们情感交融，悲喜与共，感同身受。我们觉得自己仿佛在作者所描绘的舞台上和他们一起粉墨登场。</p>
<p>The great and good do not die, even in this world. Embalmed in books, their spirits walk abroad. The book is a living voice. It is an intellect to which on still listens.</p>
<p>即使在人世间，伟大杰出的人物也永生不来。他们的精神被载入书册，传于四海。书是人生至今仍在聆听的智慧之声，永远充满着活力。</p>
<h2 id="004-If-I-Rest-I-Rust-如果我休息，我就会生锈"><a href="#004-If-I-Rest-I-Rust-如果我休息，我就会生锈" class="headerlink" title="004 If I Rest,I Rust 如果我休息，我就会生锈"></a>004 If I Rest,I Rust 如果我休息，我就会生锈</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/004.jpg" alt=""></p>
<p>If I Rest, I Rust<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/04-if_i_rest,i_rust.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/04-if_i_rest,i_rust.mp3</a></p>
<p>The significant inscription found on an old key—“If I rest, I rust”—would be an excellent motto for those who are afflicted with the slightest bit of idleness. Even the most industrious person might adopt it with advantage to serve as a reminder that, if one allows his faculties to rest, like the iron in the unused key, they will soon show signs of rust and, ultimately, cannot do the work required of them.</p>
<p>在一把旧钥匙上发现了一则意义深远的铭文——如果我休息，我就会生锈。对于那些懒散而烦恼的人来说，这将是至理名言。甚至最为勤勉的人也以此作为警示：如果一个人有才能而不用，就像废弃钥匙上的铁一样，这些才能就会很快生锈，并最终无法完成安排给自己的工作。</p>
<p>Those who would attain the heights reached and kept by great men must keep their faculties polished by constant use, so that they may unlock the doors of knowledge, the gate that guard the entrances to the professions, to science, art, literature, agriculture—every department of human endeavor.</p>
<p>有些人想取得伟人所获得并保持的成就，他们就必须不断运用自身才能，以便开启知识的大门，即那些通往人类努力探求的各个领域的大门，这些领域包括各种职业：科学，艺术，文学，农业等。</p>
<p><strong>Industry keeps bright the key that opens the treasury of achievement.</strong> If Hugh Miller, after toiling all day in a quarry, had devoted his evenings to rest and recreation, he would never have become a famous geologist. The celebrated mathematician, Edmund Stone, would never have published a mathematical dictionary, never have found the key to science of mathematics, if he had given his spare moments to idleness, had the little Scotch lad, Ferguson, allowed the busy brain to go to sleep while he tended sheep on the hillside instead of calculating the position of the stars by a string of beads, he would never have become a famous astronomer.</p>
<p>勤奋使开启成功宝库的钥匙保持光亮。如果休·米勒在采石场劳作一天后，晚上的时光用来休息消遣的话，他就不会成为名垂青史的地质学家。著名数学家爱德蒙·斯通如果闲暇时无所事事，就不会出版数学词典，也不会发现开启数学之门的钥匙。如果苏格兰青年弗格森在山坡上放羊时，让他那思维活跃的大脑处于休息状态，而不是借助一串珠子计算星星的位置，他就不会成为著名的天文学家。</p>
<p><strong>Labor vanquishes all—not inconstant, spasmodic, or ill-directed labor; but faithful, unremitting, daily effort toward a well-directed purpose.</strong> Just as truly as eternal vigilance is the price of liberty, so is eternal industry the price of noble and enduring success.</p>
<p>劳动征服一切。这里所指的劳动不是断断续续的，间歇性的或方向偏差的劳动，而是坚定的，不懈的，方向正确的每日劳动。正如要想拥有自由就要时刻保持警惕一样，要想取得伟大的，持久的成功，就必须坚持不懈地努力。</p>
<h2 id="005-Ambition-抱负"><a href="#005-Ambition-抱负" class="headerlink" title="005 Ambition 抱负"></a>005 Ambition 抱负</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/005%20196ul3xois8xwjpg.jpg" alt=""></p>
<p>Ambition<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/05-ambition.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/05-ambition.mp3</a></p>
<p>It is not difficult to imagine a world short of ambition. It would probably be a kinder world: with out demands, without abrasions, without disappointments. People would have time for reflection. Such work as they did would not be for themselves but for the collectivity. Competition would never enter in. conflict would be eliminated, tension become a thing of the past. The stress of creation would be at an end. Art would no longer be troubling, but purely celebratory in its functions. Longevity would be increased, for fewer people would die of heart attack or stroke caused by tumultuous endeavor. Anxiety would be extinct. Time would stretch on and on, with ambition long departed from the human heart.</p>
<p>一个缺乏抱负的世界将会怎样，这不难想象。或许，这将是一个更为友善的世界：没有渴求，没有磨擦，没有失望。人们将有时间进行反思。他们所从事的工作将不是为了他们自身，而是为了整个集体。竞争永远不会介入；冲突将被消除。人们的紧张关系将成为过往云烟。创造的重压将得以终结。艺术将不再惹人费神，其功能将纯粹为了庆典。人的寿命将会更长，因为由激烈拼争引起的心脏病和中风所导致的死亡将越来越少。焦虑将会消失。时光流逝，抱负却早已远离人心。</p>
<p>Ah, how unrelieved boring life would be!</p>
<p> 啊，长此以往人生将变得多么乏味无聊！</p>
<p>There is a strong view that holds that success is a myth, and ambition therefore a sham. Does this mean that success does not really exist? That achievement is at bottom empty? That the efforts of men and women are of no significance alongside the force of movements and events now not all success, <strong>obviously, is worth esteeming, nor all ambition worth cultivating. Which are and which are not is something one soon enough learns on one’s own.</strong> But even the most cynical secretly admit that success exists; that achievement counts for a great deal; and that the true myth is that the actions of men and women are useless. To believe otherwise is to take on a point of view that is likely to be deranging. It is, in its implications, to remove all motives for competence, interest in attainment, and regard for posterity.</p>
<p> 有一种盛行的观点认为，成功是一种神话，因此抱负亦属虚幻。这是不是说实际上并不丰在成功？成就本身就是一场空？与诸多运动和事件的力量相比，男男女女的努力显得微不足？显然，并非所有的成功都值得景仰，也并非所有的抱负都值得追求。对值得和不值得的选择，一个人自然而然很快就能学会。但即使是最为愤世嫉俗的人暗地里也承认，成功确实存在，成就的意义举足轻重，而把世上男男女女的所作所为说成是徒劳无功才是真正的无稽之谈。认为成功不存在的观点很可能造成混乱。这种观点的本意是一笔勾销所有提高能力的动机，求取业绩的兴趣和对子孙后代的关注。</p>
<p>We do not choose to be born. We do not choose our parents. We do not choose our historical epoch, the country of our birth, or the immediate circumstances of our upbringing. We do not, most of us, choose to die; nor do we choose the time or conditions of our death. <strong>But within all this realm of choicelessness, we do choose how we shall live: courageously or in cowardice, honorably or dishonorably, with purpose or in drift. We decide what is important and what is trivial in life. We decide that what makes us significant is either what we do or what we refuse to do. But no matter how indifferent the universe may be to our choices and decisions, these choices and decisions are ours to make. We decide. We choose. And as we decide and choose, so are our lives formed. In the end, forming our own destiny is what ambition is about.</strong></p>
<p>  我们无法选择出生，无法选择父母，无法选择出生的历史时期与国家，或是成长的周遭环境。我们大多数人都无法选择死亡，无法选择死亡的时间或条件。但是在这些无法选择之中，我们的确可以选择自己的生活方式：是勇敢无畏还是胆小怯懦，是光明磊落还是厚颜无耻，是目标坚定还是随波逐流。我们决定生活中哪些至关重要，哪些微不足道。我们决定，用以显示我们自身重要性的，不是我们做了什么，就是我们拒绝做些什么。但是不论世界对我们所做的选择和决定有多么漠不关心，这些选择和决定终究是我们自己做出的。我们决定，我们选择。而当我们决定和选择时，我们的生活便得以形成。最终构筑我们命运的就是抱负之所在。</p>
<h2 id="006-What-I-have-Lived-for-我为何而生"><a href="#006-What-I-have-Lived-for-我为何而生" class="headerlink" title="006 What I have Lived for 我为何而生"></a>006 What I have Lived for 我为何而生</h2><p>  <img src="http://okkntqe2h.bkt.clouddn.com/006%20bertrand-russell-quotes-sayings-meaningful-life-love-cute.jpg" alt=""></p>
<p>  What I Have Lived For<br>  <a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/06-what_i_have_lived_for.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/06-what_i_have_lived_for.mp3</a></p>
<p>Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. These passions, like great winds, have blown me hither and thither, in a wayward course, over a deep ocean of anguish, reaching to the very verge of despair.</p>
<p>我的一生被三种简单却又无比强烈的激情所控制：对爱的渴望，对知识的探索和对人类苦难难以抑制的怜悯。这些激情像狂风，把我恣情吹向四方，掠过苦痛的大海，迫使我濒临绝望的边缘。</p>
<p>I have sought love, first, because it brings ecstasy—ecstasy so great that I would often have sacrificed all the rest of my life for a few hours for this joy. I have sought it, next, because it relieves loneliness—that terrible loneliness in which one shivering consciousness looks over the rim of the world into the cold unfathomable lifeless abyss. I have sought it, finally, because in the union of love I have seen, in a mystic miniature, the prefiguring vision of the heaven that saints and poets have imagined. This is what I sought, and though it might seem too good for human life, this is what—at last—I have found.</p>
<p>我寻求爱，首先因为它使我心为之着迷，这种难以名状的美妙迷醉使我愿意用所有的余生去换取哪怕几个小时这样的幸福。我寻求爱，还因为它能缓解我心理上的孤独中，我感觉心灵的战栗，仿如站在世界的边缘而面前是冰冷，无底的死亡深渊。我寻求爱，因为在我所目睹的结合中，我仿佛看到了圣贤与诗人们所向往的天堂之景。这就是我所寻找的，虽然对人的一生而言似乎有些遥不可及，但至少是我用尽一生所领悟到的。</p>
<p>With equal passion I have sought knowledge. I have wished to understand the hearts of men. I have wished to know why the stars shine. And I have tried to apprehend the Pythagorean power by which number holds sway above the flux. A little of this, but not much, I have achieved.</p>
<p>我用同样的激情去寻求知识。我希望能理解人类的心灵，希望能够知道群星闪烁的缘由。我试图领悟毕达哥拉斯所景仰的“数即万物”的思想。我已经悟出了其中的一点点道理，尽管并不是很多。</p>
<p>Love and knowledge, so far as they were possible, led upward toward the heavens. But always it brought me back to earth. Echoes of cries of pain reverberate in my heart. Children in famine, victims tortured by oppressors, helpless old people a hated burden to their sons, and the whole world of loneliness, poverty, and pain make a mockery of what human life should be. I long to alleviate the evil, but I cannot, and I too suffer.</p>
<p> 爱和知识，用它们的力量把人引向天堂。但是同情却总把人又拽回到尘世中来。痛苦的呼喊声回荡在我的内心。饥饿的孩子，受压迫的难民，贫穷和痛苦的世界，都是对人类所憧憬的美好生活的无情嘲弄。我渴望能够减少邪恶，但是我无能为力，我也难逃其折磨。</p>
<p>This has been my life. I have found it worth living, and would gladly live it again if the chance were offered me.</p>
<p>这就是我的一生。我已经找到它的价值。而且如果有机会，我很愿意能再活它一次。</p>
<h2 id="007-When-Love-Beckons-You-爱的召唤"><a href="#007-When-Love-Beckons-You-爱的召唤" class="headerlink" title="007 When Love Beckons You 爱的召唤"></a>007 When Love Beckons You 爱的召唤</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/007%20quote-when-love-beckons-to-you-follow-him-though-his-ways-are-hard-and-steep-and-when-his-wings-enfold-khalil-gibran-70810.jpg" alt=""></p>
<p>When Love Beckons You<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/07-when_love_beckons_you.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/07-when_love_beckons_you.mp3</a></p>
<p><strong>When love beckons to you, follow him, though his ways are hard and steep. And when his wings enfold you, yield to him, though the sword hidden among his pinions may wound you. And when he speaks to you, believe in him, though his voice may shatter your dreams as the north wind lays waste the garden.</strong></p>
<p> 当爱召唤你时，请追随她，尽管爱的道路艰难险峻。当爱的羽翼拥抱你时，请顺从她，尽管隐藏在其羽翼之下的剑可能会伤到你。当爱向你诉说时，请相信她，尽管她的声音可能打破你的梦想，就如同北风吹落花园里所有的花瓣。</p>
<p>For even as love crowns you so shall he crucify you. Even as he is for your growth so is he for your pruning. Even as he ascends to your height and caresses your tenderest branches that quiver in the sun, so shall he descend to our roots and shake them in their clinging to the earth.</p>
<p>  爱会给你戴上桂冠，也会折磨你。爱会助你成长，也会给你修枝。爱会上升到枝头，抚爱你在阳光下颤动力的嫩枝，也会下潜至根部，撼动力你紧抓泥土的根基。</p>
<p>But if, in your fear, you would seek only love’s peace and love’s pleasure, then it is better for you that you cover  your nakedness and pass out of love’s threshing-floor, into the seasonless world where you shall laugh, but not all of your laughter, and weep, but not all of your tears. Love gives naught but it self and takes naught but from itself. Love possesses not, nor would it be possessed, for love is sufficient unto love.</p>
<p> 但是，如果你在恐惧之中只想寻求爱的平和与快乐，那你就最好掩盖真实的自我，避开爱的考验，进入不分季节的世界，在那里你将欢笑，但并非开怀大笑，你将哭泣，但并非尽情地哭。爱只将自己付出，也只得到自己。爱一无所有，也不会为谁所有，因为爱本身就已自足。</p>
<p>Love has no other desire but to fulfill itself. But if you love and must have desires, let these be your desires:</p>
<p> 爱除了实现自我别无他求。但是如果你爱而又不得不有所求，那就请期望：</p>
<p>To melt and be like a running brook that sings its melody to the night.</p>
<p>将自己融化并像奔流的溪水一般向夜晚吟唱自己优美的曲调。</p>
<p>To know the pain of too much tenderness.</p>
<p>明了过多的温柔所带来的苦痛。</p>
<p>To be wounded by your own understanding of love;</p>
<p>被自己对爱的理解所伤害；</p>
<p>And to bleed willingly and joyfully.</p>
<p>并情愿快乐地悲伤。</p>
<p>To wake at dawn with a winged heart and give thanks for another day of loving;</p>
<p>在黎明带着轻快的心醒来并感谢又一个有家的日子；</p>
<p>To rest at the noon hour and meditate love’s ecstasy;</p>
<p>在中午的小憩时间思考爱的美妙；</p>
<p>To return home at eventide with gratitude;</p>
<p>在黄昏怀着感恩之心回家；</p>
<p>And then to sleep with a payer for the beloved in your heart and a song of praise upon your lips.</p>
<p>然后为内心所爱之人祈祷，吟唱赞美之歌，并带着祷告和歌声入眠。</p>
<h2 id="008-The-Road-to-Success-成功之道"><a href="#008-The-Road-to-Success-成功之道" class="headerlink" title="008 The Road to Success 成功之道"></a>008 The Road to Success 成功之道</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/008%20quote-the-road-to-success-is-through-commitment-will-smith-86-33-32.jpg" alt=""></p>
<p>The Road to Success<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/08-the_road_to_success.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/08-the_road_to_success.mp3</a></p>
<p>It is well that young men should begin at the beginning and occupy the most subordinate positions. Many of the leading businessmen of Pittsburgh had a serious responsibility thrust upon them at the very threshold of their career. They were introduced to the broom, and spent the first hours of their business lives sweeping out the office. I notice we have janitors and janitresses now in offices, and our young men unfortunately miss that salutary branch of business education. But if by chance the professional sweeper is absent any morning, the boy who has the genius of the future partner in him will not hesitate to try his hand at the broom. It does not hurt the newest comer to sweep out the office if necessary. I was one of those sweepers myself.</p>
<p>年轻人创业之初，应该从最底层干起，这是件好事。匹兹保有很多商业巨头，在他们创业之初，都肩负过“重任”：他们以扫帚相伴，以打扫办公室的方式度过了他们商业生涯中最初的时光。我注意到我们现在办公室里都有工友，于是年轻人就不幸错过了商业教育中这个有益的环节。如果碰巧哪天上午专职扫地的工友没有来，某个具有未来合伙人气质的年轻人会毫不犹豫地试着拿起扫帚。在必要时新来的员工扫扫地也无妨，不会因为而有什么损失。我自己就曾经扫过地。</p>
<p>Assuming that you have all obtained employment and are fairly started, my advice to you is “aim high”. I would not give a fig for the young man who does not already see himself the partner or the head of an important firm. Do not rest content for a moment in your thoughts as head clerk, or foreman, or general manager in any concern, no matter how extensive. Say to yourself, “My place is at the top.” <strong>Be king in your dreams.</strong></p>
<p>假如你已经被录用，并且有了一个良好的开端，我对你的建议是：要志存高远。一个年轻人，如果不把自己想象成一家大公司未来的老板或者是合伙人，那我会对他不屑一顾。不论职位有多高，你的内心都不要满足于做一个总管，领班或者总经理。要对自己说：我要迈向顶尖！要做就做你梦想中的国王！</p>
<p><strong>And here is the prime condition of success, the great secret: concentrate your energy, thought, and capital exclusively upon the business in which you are engaged. Having begun in one line, resolve to fight it out on that line, to lead in it, adopt every improvement, have the best machinery, and know the most about it.</strong></p>
<p>成功的首要条件和最大秘诀就是：把你的精力，思想和资本全都集中在你正从事的事业上。一旦开始从事某种职业，就要下定决心在那一领域闯出一片天地来；做这一行的领导人物，采纳每一点改进之心，采用最优良的设备，对专业知识熟稔于心。</p>
<p>The concerns which fail are those which have scattered their capital, which means that they have scattered their brains also. They have investments in this, or that, or the other, here there, and everywhere. “Don’t put all your eggs in one basket.” is all wrong. I tell you to “<strong>put all your eggs in one basket, and then watch that basket.</strong>” Look round you and take notice, men who do that not often fail. It is easy to watch and carry the one basket. It is trying to carry too many baskets that breaks most eggs in this country. He who carries three baskets must put one on his head, which is apt to tumble and trip him up. One fault of the American businessman is lack of concentration.</p>
<p>一些公司的失败就在于他们分散了资金，因为这就意味着分散了他们的精力。他们向这方面投资，又向那方面投资；在这里投资，在那里投资，到处都投资。“不要把所有的鸡蛋放在一个篮子里”的说法大错特错。我要对你说：“把所有的鸡蛋都放在一个篮子里，然后小心地看好那个篮子。”看看你周围，你会注意到：这么做的人其实很少失败。看管和携带一个篮子并不太难。人们总是试图提很多篮子，所以才打破这个国家的大部分鸡蛋。提三个篮子的人，必须把一个顶在头上，而这个篮子很可能倒下来，把他自己绊倒。美国商人的一个缺点就是不够专注。</p>
<p>To summarize what I have said: aim for the highest; never enter a bar room; do not touch liquor, or if at all only at meals; never speculate; never indorse beyond your surplus cash fund; make the firm’s interest yours; break orders always to save owners; concentrate; put all your eggs in one basket, and watch that basket; expenditure always within revenue; lastly, be not impatient, for as Emerson says, “<strong>no one can cheat you out of ultimate success but yourselves.</strong>”</p>
<p> 把我的话归纳一下：要志存高远；不要出入酒吧；要滴酒不沾，或要喝也只在用餐时喝少许；不要做投机买卖；不要寅吃卯粮；要把公司的利益当作自己的利益；取消订货的目的永远是为了挽救货主；要专注；要把所有的鸡蛋放在一个篮子里，然后小心地看好它；要量入为出；最后，要有耐心，正如爱默生所言，“谁都无法阻止你最终成功，除非你自己承认自己失败。”</p>
<h2 id="009-On-Meeting-the-Celebrated-论见名人"><a href="#009-On-Meeting-the-Celebrated-论见名人" class="headerlink" title="009 On Meeting the Celebrated 论见名人"></a>009 On Meeting the Celebrated 论见名人</h2><p> <img src="http://okkntqe2h.bkt.clouddn.com/009%207B2646AE-5967-417B-B130-C09B76E6AE9C_500.jpg" alt=""></p>
<p>On Meeting the Celebrated<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/09-on_meeting_the_celebrated.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/09-on_meeting_the_celebrated.mp3</a></p>
<p>I have always wondered at the passion many people have to meet the celebrated. The prestige you acquire by being able to tell your friends that you know famous men proves only that you are yourself of small account. The celebrated develop a technique to deal with the persons they come across. They show the world a mask, often an impressive on, but take care to conceal their real selves. <strong>They play the part that is expected from them, and with practice learn to play it very well, but you are stupid if you think that this public performance of theirs corresponds with the man within.</strong></p>
<p>许多人热衷于见名人，我始终不得其解。在朋友面前吹嘘自己认识某某名人，同此而来的声望只能证明自己的微不足道。名人个个练就了一套处世高招，无论遇上谁，都能应付自如。他们给世人展现的是一副面具，常常是美好难忘的面具，但他们会小心翼翼地掩盖自己的真相。他们扮演的是大家期待的角色，演得多了，最后都能演得惟妙惟肖。如果你还以为他们在公众面前的表演就是他们的真实自我，那就你傻了。</p>
<p>I have been attached, deeply attached, to a few people; but I have been interested in men in general not for their own sakes, but for the sake of my work. I have not, as Kant enjoined, regarded each man as an end in himself, but as material that might be useful to me as a writer. I have been more concerned with the obscure than with the famous. They are more often themselves. They have had no need to create a figure to protect themselves from the world or to impress it. Their idiosyncrasies have had more chance to develop in the limited circle of their activity, and since they have never been in the public eye it has never occurred to them that they have anything to conceal. They display their oddities because it has never struck them that they are odd. And after all it is with the common run of men that we writers have to deal; kings, dictators, commercial magnates are from our point of view very unsatisfactory. To write about them is a venture that has often tempted writers, but the failure that has attended their efforts shows that such beings are too exceptional to form a proper ground for a work of art. They cannot be made real. The ordinary is the writer’s richer field. Its unexpectedness, its singularity, its infinite variety afford unending material. The great man is too often all of a piece; it is the little man that is a bundle of contradictory elements. He is inexhaustible. You never come to the end of the surprises he has in store for you. For my part I would much sooner spend a month on a desert island with a veterinary surgeon than with a prime minister.</p>
<p>我自己就喜欢一些人，非常喜欢他们。但我对人感兴趣一般不是因为他们自身的缘故，而是出于我工作需求。正如康德劝告的那样，我从来没有把认识某人作为目的，而是将其当作对一个作家有用的创作素材。比之名流显士，我更加关注无名小卒。他们常常显得较为自然真实，他们无须再创造另一个人物形象，用他来保护自己不受世人干扰，或者用他来感动世人。他们的社交圈子有限，自己的种种癖性也就越有可能得到滋长。因为他们从来没有引起公众的关注，也就从来没有想到过要隐瞒什么。他们会表露他们古怪的一面，因为他们从来就没有觉得有何古怪。总之，作家要写的是普通人。在我们看来，国王，独裁者和商界大亨等都是不符合条件的。去撰写这些人物经常是作家们难以抗拒的冒险之举，可为此付出的努力不免以失败告终，这说明这些人物都过于特殊，无法成为一件艺术作品的创作根基，作家也不可能把他们写得真真切切。老百姓才是作家的创作沃土，他们或变幻无常，或难觅其二，各式人物应有尽有，这些都给作家提供了无限的创作素材。大人物经常是千人一面，小人物身上才有一组组矛盾元素，是取之不尽的创作源泉，让你惊喜不断。就我而言，如果在孤岛上度过一个月，我宁愿和一名兽医相守，也不愿同一位首相做伴。</p>
<h2 id="010-The-50-Percent-Theory-of-Life-生活理论半对半"><a href="#010-The-50-Percent-Theory-of-Life-生活理论半对半" class="headerlink" title="010 The 50-Percent Theory of Life 生活理论半对半"></a>010 The 50-Percent Theory of Life 生活理论半对半</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/010%209781427203847.jpg" alt=""></p>
<p>The 50-Percent Theory of Life<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/10-the_50-percent_theory_of_life.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/10-the_50-percent_theory_of_life.mp3</a></p>
<p>I believe in the 50-percent theory. <strong>Half the time things are better than normal; the other half, they re worse. I believe life is a pendulum swing. It takes time and experience to understand what normal is, and that gives me the perspective to deal with the surprises of the future.</strong></p>
<p>我信奉对半理论。生活时而无比顺畅，时而倒霉透顶。我觉得生活就像来回摆的钟摆。读懂生活的常态需要时间和阅历，而读懂它也练就了我面对未来的生活态度。</p>
<p>Let’s benchmark the parameters: yes, I will die. I’ve dealt with the deaths of both parents, a best friend, a beloved boss and cherished pets. Some of these deaths have been violent, before my eyes, or slow and agonizing. Bad stuff, and it belongs at the bottom of the scale.</p>
<p>让我们确定一下好坏的标准：是的，我注定会死去。我已经经历了双亲，一位好友，一位敬爱的老板和心爱宠物的死亡。有些突如其来，近在眼前，有些却缓慢痛苦。这些都是糟糕的事情，它们属于最坏的部分。</p>
<p>Then there are those high points: romance and marriage to the right person; having a child and doing those Dad things like coaching my son’s baseball team, paddling around the creek in the boat while he’s swimming with the dogs, discovering his compassion so deep it manifests even in his kindness to snails, his imagination so vivid he builds a spaceship from a scattered pile of Legos.</p>
<p>生活中也不乏高潮：坠入爱河缔结良缘；身为人父养育幼子，诸如训练指导儿子的棒球队，当他和狗在小河中嬉戏时摇桨划船，感受他如此强烈的同情心-即使对蜗牛也善待有加，发现他如此丰富的想象力-即使用零散的乐高玩具积木也能堆出太空飞船。</p>
<p>But there is a vast meadow of life in the middle, where the bad and the good flip-flop acrobatically. This is what convinces me to believe in the 50-percent theory.</p>
<p>但在生活最好与最坏部分之间有一片巨大的中间地带，其间各种好事坏事像耍杂技一样上下翻滚，轮番出现。这就是让我信服对半理论的原因。</p>
<p>One spring I planted corn too early in a bottomland so flood-prone that neighbors laughed. I felt chagrined at the wasted effort. Summer turned brutal—the worst heat wave and drought in my lifetime. The air-conditioned died; the well went dry; the marriage ended; the job lost; the money gone. I was living lyrics from a country tune—music I loathed. Only a surging Kansas City Royals team buoyed my spirits.</p>
<p>有一年春天，我在一块洼地上过早地种上了玉米。那块地极易遭到水淹，所以邻居们都嘲笑我。我为浪费了精力而感到懊恼。没想到夏天更为残酷-我经历了最糟糕的热浪和干旱。空调坏了，进干了，婚姻破裂了，工作丢了，钱也没有。我正经历着某首乡村歌曲中描绘的情节，我讨厌这种音乐，只有刚出道不久的堪萨斯皇家棒球队能鼓舞我的精神。</p>
<p>Looking back on that horrible summer, I soon understood that all succeeding good things merely offset the bad. Worse than normal wouldn’t last long. I am owed and savor the halcyon times. The reinvigorate me for the next nasty surprise and offer assurance that can thrive. The 50-percent theory even helps me see hope beyond my Royals’ recent slump, a field of struggling rookies sown so that some year soon we can reap an October harvest.</p>
<p>回首那个糟糕的夏天，我很快就明白了，所有后来出现的好事只不过与坏事相互抵消。比一般情况糟糕的境遇不会延宕过久；而太平时光是我应得的，我要尽情享受，它们为我注入活力以应对下一个险情，并确保我可以兴旺发达。对半理论甚至帮助我在堪萨斯皇家棒球队最近的低潮中看到希望-这是一快艰难行进的新手们耕耘的土地，只要播种了，假以时日我们就可以收获十月的金秋。</p>
<p>For that on blistering summer, the ground moisture was just right, planting early allowed pollination before heat withered the tops, and the lack of rain spared the standing corn from floods. That winter my crib overflowed with corn—fat, healthy three-to-a-stalk ears filled with kernels from heel to tip—while my neighbors’ fields yielded only brown, empty husks.</p>
<p>那个夏天天气酷热，地而湿度适宜，提早播种就可以在热浪打蔫植尖之前完成授粉，同于干旱更没有爆发洪水，产在田里的玉米得以保存。因此那个冬天我的粮仓堆满了玉米-丰满，健康，一颗三穗且从头到脚都是饱满的玉米粒的玉米穗-而我的邻居们收获的只是晒黑的空壳。</p>
<p>Although plantings past may have fallen below the 50-percent expectation, and they probably will again in the future, I am still sustained by the crop that flourishes during the drought.</p>
<p>尽管过去的播种可能没有达到50%的收获期望，而且将来也可能是这样，但我仍然能靠着在旱季繁茂生长的庄稼而生存下去。</p>
<h2 id="011-What-is-Your-Recovery-Rate-你的恢复速率是多少？"><a href="#011-What-is-Your-Recovery-Rate-你的恢复速率是多少？" class="headerlink" title="011 What is Your Recovery Rate? 你的恢复速率是多少？"></a>011 What is Your Recovery Rate? 你的恢复速率是多少？</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/011%20slide_7.jpg" alt=""></p>
<p>What is Your Recovery Rate?<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/11-what_is_your_recovery_rate.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/11-what_is_your_recovery_rate.mp3</a></p>
<p>What is your recovery rate? How long does it take you to recover from actions and behaviors that upset you? Minutes? Hours? Days? Weeks? The longer it takes you to recover, the more influence that incident has on your actions, and the less able you are to perform to your personal best. <strong>In a nutshell, the longer it takes you to recover, the weaker you are and the poorer your performance.</strong></p>
<p> 你的恢复速率是多少？你需要多长时间才能从让你烦恼的行为中恢复？几分钟？几小时？几天？几星期？你需要的恢复时间越长，那个事件对你的影响越大，你也就越不能做到最好。简言之，你的恢复时间越长，你就越软弱，你的表现也就越差劲。</p>
<p>You are well aware that you need to exercise to keep the body fit and, no doubt, accept that a reasonable measure of health is the speed in which your heart and respiratory system recovers after exercise. Likewise the faster you let go of an issue that upsets you, the faster you return to an equilibrium, the healthier you will be. The best example of this behavior is found with professional sportspeople. They know that the faster they can forget an incident or missd opportunity and get on with the game, the better their performance. In fact, most measure the time it takes them to overcome and forget an incident in a game and most reckon a recovery rate of 30 seconds is too long!</p>
<p>你充分意识到，要保持身体健康你需要锻炼，并且你无疑会接受，你的心脏和呼吸系统在锻炼后的恢复速度是衡量健康的一个合理尺度。同样，你越快摆脱使你烦恼的问题，越快恢复平静，你就越健康。此类行为的最好典范是专业运动员。他们知道，越快忘记一件事或失去的机会而好好比赛，他们的发挥就越好。实际上，大多数运动员会佰自己克服并忘记比赛中一个事件所需的时间，而且大多数人都认为30秒的恢复时间太长了！</p>
<p>Imagine yourself to be an actor in a play on the stage. Your aim is to play your part to the best of your ability. You have been given a script and at the end of each sentence is a ful stop. Each time you get to the end of the sentence you start a new one and although the next sentence is related to the last it is not affected by it. Your job is to deliver each sentence to the best of your ability.</p>
<p>想象自己是一位站在舞台上的戏剧赏。你的目标是尽全力扮演好你的角色。你已经拿到了剧本，而剧本中的每句话都以句号结尾。每次你念到一个句子的末尾，你就会开始一个新的句子。尽管下一句和上一句有关联，但并不受它的影响。你的工作是尽力说好每句台词。</p>
<p><strong>Don’t live your life in the past! Learn to live in the present, to overcome the past. Stop the past from influencing your daily life. Don’t allow thoughts of the past to reduce your personal best. Stop the past from interfering with your life. Learn to recover quickly.</strong></p>
<p>不要生活在过去！要学会生活在现在，学会克服过去；不要让过去影响你的日常生活；不要让过去的思想妨碍你做到最好；不要让过去干扰你的生活；学会快速恢复。</p>
<p>Remember: <strong>Rome wasn’t built in a day. Reflect on your recovery rate each day. Every day before you go to bed, look at your progress. Don’t lie in bed saying to you, “I did that wrong.” “I should have done better there.” No. look at your day and note when you made an effort to place a full stop after an incident. This is a success. You are taking control of your life. Remember this is a step by step process. This is not a make-over. You are undertaking real change here. Your aim: reduce the time spent in recovery.</strong></p>
<p>记住，罗马不是一日建成的。每天都反思自己的恢复速率；每天上床睡觉前，都看看自己的进步；不要躺在床上对自己说：“我那个做错了。”“我应该做到更好。”不要那样做；回想自己的一天，并注意努力给某个事件画上句号的时刻。这就是一个成功，你在控制自己的生活。记住这是一个循序渐进的过程。这不是简单的修修补补。你正在进行的是真正的改变，你的目标是减少用在恢复上的时间。</p>
<p>The way forward? 将来该怎么做呢？</p>
<p><strong>Live in the present. Not in the precedent.</strong> 生活在现在，而不是从前。</p>
<h2 id="012-Clear-Your-Mental-Space-清理心灵的空间"><a href="#012-Clear-Your-Mental-Space-清理心灵的空间" class="headerlink" title="012 Clear Your Mental Space 清理心灵的空间"></a>012 Clear Your Mental Space 清理心灵的空间</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/012%20Clearing-Mental-Space-w-Button.jpg" alt=""></p>
<p>Clear Your Mental Space<br> <a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/12-clear_your_mental_space.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/12-clear_your_mental_space.mp3</a></p>
<p>Think about the last time you felt a negative emotion—like stress, anger, or frustration. What was going through your mind as you were going through that negativity? Was your mind cluttered with thoughts? Or was it paralyzed, unable to think?</p>
<p>想下你最近一次感受到的消极情绪，例如压力，愤怒或挫折。当你处于那种消极情绪时你在想些什么？是充满了混乱的思绪？还是陷于麻木，无法思考？</p>
<p>The next time you find yourself in the middle of a very stressful time, or you feel angry or frustrated, stop. Yes, that’s right, stop. Whatever you’re doing, stop and sit for one minute. While you’re sitting there, completely immerse yourself in the negative emotion.</p>
<p>下次当你发现自己处于非常紧张的状态时，或是你感到气愤或受挫时，停下来。是的，对，停下来。不管你在做什么，停下来坐上一分钟。坐着的时候，让自己完全沉浸在那种消极情绪之中。</p>
<p>Allow that emotion to consume you. Allow yourself one minute to truly feel that emotion. Don’t cheat yourself here. Take the entire minute—but only one minute—to do nothing else but feel that emotion.</p>
<p>让那种消极情绪吞噬你，给自己一分钟的时间去真切地体会那种情绪，不要欺骗自己。花整整一分钟的时间 – 但只有一分钟 – 去体会那种情绪，别的什么也不要做。</p>
<p>When the minute is over, ask yourself, “Am I wiling to keep holding on to this negative emotion as I go through the rest of the day?”</p>
<p>当一分钟结束时，问自己：“我是否想在今天余下的时间里继续保持这种消极情绪？”</p>
<p>Once you’ve allowed yourself to be totally immersed in the emotion and really fell it, you will be surprised to find that the emotion clears rather quickly.</p>
<p>一旦你允许自己完全沉浸在那种情绪当中并真切体会到它，你就会惊奇地发现那种情绪很快就消失了。</p>
<p>If you feel you need to hold on to the emotion for a little longer, that is OK. Allow yourself another minute to feel the emotion.</p>
<p>如果你觉得还需要点时间来保持那种情绪，没关系，再给自己一分钟的时间去体会它。</p>
<p>When you feel you’ve had enough of the emotion, ask yourself if you’re willing to carry that negativity with you for the rest of the day. If not, take a deep breath. As you exhale, release all that negativity with your breath.</p>
<p>如果你觉得自己已经充分体会了那种情绪，那就问自己是否愿意在今天余下的时间里继续保持这种消极情绪。如果不愿意，那就深呼吸。呼气的时候，把所有的消极情绪都释放出去。</p>
<p><strong>This exercise seems simple—almost too simple. But, it is very effective. By allowing that negative emotion the space to be truly felt, you are dealing with the emotion rather than stuffing it down and trying not to feel it. You are actually taking away the power of the emotion by giving it the space and attention it needs. When you immerse yourself in the emotion, and realize that it is only emotion, it loses its control. You can clear your head and proceed with your task.</strong></p>
<p>这个方法似乎很简单 – 几乎是太过简单了，但却非常有效。通过给自己空间真正体会消极情绪，你是在处理这种情绪，而不是将其压制下去然后尽量不加理会。通过给予消极情绪所需的空间和关注，你实际上是在消解其力量。当你沉浸在那种情绪之中，并且明白它只是一种情绪时，你就摆脱了它的控制。你可以清理头脑并继续做事。</p>
<p>Try it. Next time you’re in the middle of a negative emotion, give yourself the space to feel the emotion and see what happens. Keep a piece of paper with you that says the following:</p>
<p>你下次笼罩消极情绪时，试一下这种做法，给自己一点空间来体会那种情绪并看看会发生什么。随身带一张写着如下字句的纸条：</p>
<p>Stop. Immerse for one minute. Do I want to keep this negativity? Breath deep, exhale, release. Move on!</p>
<p>停下来。沉浸一分钟。我想保持这种消极情绪吗？深吸气，呼气，放松。继续做事！</p>
<p>This will remind you of the steps to the process. Remember; take the time you need to really immerse yourself in the emotion. Then, when you feel you’ve felt it enough, release it—really let go of it. You will be surprised at how quickly you can move on from a negative situation and get to what you really want to do!</p>
<p>这会提醒你该怎样去做。记住，要花你所需要的时间去真正沉浸于那种情绪之中。然后，当你感到自己已经充分体会到了它。你会惊奇地发现，你很快就能摆脱消极情绪，并开始做你真正想做的事情！</p>
<h2 id="013-Be-Happy-快乐"><a href="#013-Be-Happy-快乐" class="headerlink" title="013 Be Happy 快乐"></a>013 Be Happy 快乐</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/013%20quote-the-days-that-make-us-happy-make-us-wise-john-masefield-36-76-95.jpg" alt=""></p>
<p>Be Happy!<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/13-be_happy.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/13-be_happy.mp3</a></p>
<p>“<strong>The days that make us happy make us wise.</strong>”—-John Masefield</p>
<p>“快乐的日子使人睿智。”<br>                      — 约翰·梅斯菲尔德</p>
<p>when I first read this line by England’s Poet Laureate, it startled me. What did Masefield mean? Without thinking about it much, I had always assumed that the opposite was true. But his sober assurance was arresting. I could not forget it.</p>
<p>第一次读到英国桂冠诗人梅斯菲尔德的这行诗时，我感到十分震惊。他想表达什么意思？我以前从未对此仔细考虑，总是认定这行诗反过来才正确。但他冷静而又胸有成竹的表达引起了我的注意，令我无法忘怀。</p>
<p>Finally, I seemed to grasp his meaning and realized that here was a profound observation.<strong>The wisdom that happiness makes possible lies in clear perception, not fogged by anxiety nor dimmed by despair and boredom, and without the blind spots caused by fear.</strong></p>
<p>终于，我似乎领会了他的意思，并意识到这行诗意义深远。快乐带来的睿智存在于敏锐的洞察力之间，不会因忧虑而含混迷惑，也不会因绝望和厌倦而黯然模糊，更不会因恐惧而造成盲点。</p>
<p>Active happiness—not mere satisfaction or contentment —often comes suddenly, like an April shower or the unfolding of a bud. Then you discover what kind of wisdom has accompanied it. The grass is greener; bird songs are sweeter; the shortcomings of your friends are more understandable and more forgivable. <strong>Happiness is like a pair of eyeglasses correcting your spiritual vision.</strong></p>
<p>积极的快乐 – 并非单纯的满意或知足 – 通常不期而至，就像四月里突然下起的春雨，或是花蕾的突然绽放。然后，你就会发觉与快乐结伴而来的究竟是何种智慧。草地更为青翠，鸟吟更为甜美，朋友的缺点也变得更能让人理解，宽容。快乐就像是一副眼镜，可以矫正你的精神视力。</p>
<p>Nor are the insights of happiness limited to what is near around you. Unhappy, with your thoughts turned in upon your emotional woes, your vision is cut short as though by a wall. Happy, the wall crumbles.</p>
<p>快乐的视野并不仅限于你周围的事物。当你不快乐时，你的思维陷入情感上的悲哀，你的眼界就像是被一道墙给阻隔了，而当你快乐时，这道墙就会砰然倒塌。</p>
<p>The long vista is there for the seeing. The ground at your feet, the world about you—-people, thoughts, emotions, pressures—are now fitted into the larger scene. Everything assumes a fairer proportion. And here is the beginning of wisdom.</p>
<p>你的眼界变得更为宽广。你脚下的大地，你身边的世界，包括人，思想，情感和压力，现在都融入了更为广阔的景象之中，其间每件事物 的比例都更加合理。而这就是睿智的起始。</p>
<h2 id="014-The-Goodness-of-life-生命的美好"><a href="#014-The-Goodness-of-life-生命的美好" class="headerlink" title="014 The Goodness of life 生命的美好"></a>014 The Goodness of life 生命的美好</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/014%20rise-above-the-storm-and-you-will-find-the-sunshine-quote-quotes-about-life-goodness-930x697.jpg" alt=""></p>
<p>The Goodness of Life<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/14-the_goodness_of_life.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/14-the_goodness_of_life.mp3</a></p>
<p>Though there is much to be concerned about, there is far, far more for which to be thankful. Though life’s goodness can at times be overshadowed, it is never outweighed.</p>
<p>尽管有很多事让人忧虑，但相比而言，值得感激的事要多得多。尽管生命的美好有时被蒙上阴影，但它却永远不会被埋没。</p>
<p>For every single act that is senselessly destructive, there are thousands more small, quiet acts of love, kindness and compassion. For every person who seeks to hurt, there are many, many more who devote their lives to helping and to healing.</p>
<p>相对于每一个无谓的破坏行为而言，都有更多数以千计更为微小的，包含着爱，友善和同情的举动静静地上演着。相对于每一个试图伤害他人的人而言，都有更多的人致力于帮助他人，治愈他人的创伤。</p>
<p>There is goodness to life that cannot be denied. 生命的美好不能否认。</p>
<p>In the most magnificent vistas and in the smallest details, look closely, for that goodness always comes shining through.</p>
<p>在最为壮观的前景和最为琐碎的细节中，请仔细观察，因为美好的事物总是散发着耀眼的光芒闪亮登场。</p>
<p>There si no limit to the goodness of life. It grows more abundant with each new encounter. <strong>The more you experience and appreciate the goodness of life, the more there is to be lived.</strong></p>
<p>生命的美好没有界限。每一次相遇都会使这美好变得越发丰富。你经历得越多，越能欣赏生命的美好，生命中的美好就会变得越多。</p>
<p>Even when the cold winds blow and the world seems to be cov ered in foggy shadows, the goodness of life lives on. Open your eyes, open your heart, and you will see that goodness is everywhere.</p>
<p>即使当寒风袭来，整个世界似乎被雾气掩盖之时，生命的美好仍会存在。睁开双眼，打开心扉，你就会发现这美好无处不在。</p>
<p>Though the goodness of life seems at times to suffer setbacks, it always endures. <strong>For in the darkest moment it becomes vividly clear that life is a priceless treasure. And so the goodness of life is made even stronger by the very things that would oppose it.</strong></p>
<p>尽管生命的美好有时似乎遭受挫折，但它总会挺过来。因为，在最黑暗的时刻，有一点变得格外清楚，那就是，生命是无价的财富。因此，正是与生命的美好相对立的事物使其越发强大。</p>
<p><strong>Time and time again when you feared it was gone forever you found that the goodness of life was really only a moment away. Around the next corner, inside every moment, the goodness of life is there to surprise and delight you.</strong></p>
<p>无数次地，当你担心这美好已经远离之时，你会发现生命的美好其实只与你相隔须臾。它就在下一角落，存在于每个时刻之间，等着给你惊喜。</p>
<p><strong>Take a moment to let the goodness of life touch your spirit and calm your thoughts. Then, share your good fortune with another. For the goodness of life grows more and more magnificent each time it is given away.</strong></p>
<p>花些时间让生命的美好感动自己的灵魂，放松自己的思绪。然后，把你的幸运与他人分享。因为生命的美好会在每次给予之间变得越来越壮观。</p>
<p>Though the problems constantly scream for attention and the conflicts appear to rage ever stronger, the goodness of life grows stronger still, quietly, peacefully, with more purpose and meaning than ever before.</p>
<p>尽管总是有问题让你去关注，冲突也似乎愈演愈烈，但生命的美好却总是静静地，平和地，带着比以往更强的意志和更多的价值变得更加强大。</p>
<h2 id="015-Facing-the-Enemies-Within-直面内在的敌人"><a href="#015-Facing-the-Enemies-Within-直面内在的敌人" class="headerlink" title="015 Facing the Enemies Within 直面内在的敌人"></a>015 Facing the Enemies Within 直面内在的敌人</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/015%20quote-when-there-is-no-enemy-within-the-enemies-outside-cannot-hurt-you-winston-churchill-40-49-02.jpg" alt=""></p>
<p>Facing the Enemies Within<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/15-facing_the_enemies_within.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/15-facing_the_enemies_within.mp3</a></p>
<p>We are not born with courage, but neither are we born with fear. Maybe some of our fears are brought on by your own experiences, by what someone has told you, by what you’ve read in the papers. Some fears are valid, like walking alone in a bad part of town at two o’clock in the morning. But once you learn to avoid that situation, you won’t need to live in fear of it.</p>
<p>我们的勇气并不是与生俱来的，我们的恐惧也不是。也许有些恐惧来自你的亲身经历，别人告诉你的故事，或你在报纸上读到的东西。有些恐惧可以理解，例如在凌晨两点独自走在城里不安全的地段。但是一旦你学会避免那种情况，你就不必生活在恐惧之中。</p>
<p>Fears, even the most basic ones, can totally destroy our ambitions. Fear can destroy fortunes. Fear can destroy relationships. Fear, if left unchecked, can destroy our lives. <strong>Fear is one of the many enemies lurking inside us.</strong></p>
<p>恐惧，哪怕是最基本的恐惧，也可能彻底粉碎我们的抱负。恐惧可能摧毁财富，也可能摧毁一段感情。如果不加以控制，恐惧还可能摧毁我们的生活。恐惧是潜伏于我们内心的众多敌人之一。</p>
<p>Let me tell you about five of the other enemies we face from within. 让我来告诉你我们面临的其他五个内在敌人。</p>
<p>The first enemy that you’ve got to destroy before it destroys you is indifference. What a tragic disease this is! “Ho-hum, let it slide. I’ll just drift along.” Here’s one problem with drifting: you can’t drift your way to the to of the mountain.</p>
<p>第一个你要在它袭击你之前将其击败的敌人是冷漠。打着哈欠说：“随它去吧，我就随波逐流吧。”这是多么可悲的疾病啊！随波逐流的问题是：你不可能漂流到山顶去。</p>
<p>The second enemy we face is indecision. Indecision is the thief of opportunity and enterprise. It will steal your chances for a better future. Take a sword to this enemy.</p>
<p>我们面临的第二个敌人是优柔寡断。它是窃取机会和事业的贼，它还会偷去你实现更美好未来的机会。向这个敌人出剑吧！</p>
<p>The third enemy inside is doubt. Sure, there’s room for healthy skepticism. You can’t believe everything. But you also can’t let doubt take over. Many people doubt the past, doubt the future, doubt each other, doubt the government, doubt the possibilities nad doubt the opportunities. Worse of all, they doubt themselves. I’m telling you, <strong>doubt will destroy your life and your chances of success. It will empty both your bank account and  your heart. Doubt is an enemy. Go after it. Get rid of it.</strong></p>
<p>第三个内在的敌人是怀疑。当然，正常的怀疑还是有一席之地的，你不能相信一切。但是你也不能让怀疑掌管一切。许多人怀疑过去，怀疑未来，怀疑彼此，怀疑政府，怀疑可能性，并怀疑机会。最糟糕的是，他们怀疑自己。我告诉你，怀疑会毁掉你的生活和你成功的机会，它会耗尽你的存款，留给你干涸的心灵。怀疑是敌人，追赶它，消灭它。</p>
<p>The fourth enemy within is worry. We’ve all got to worry some. Just don’t let conquer you. Instead, let it alarm you. Worry can be useful. If you step off the curb in New York City and a taxi is coming, you’ve got to worry. But you can’t let worry loose like a mad dog that drives you into a small corner. Here’s what you’ve got to do with your worries: drive them into a small corner. Whatever is out to get you, you’ve got to get it. Whatever is pushing on you, you’ve got to push back.</p>
<p>第四个内在的敌人是担忧。我们都会有些担忧，不过千万不要让担忧征服你。相反，让它来警醒你。担忧也许能派上用场。当你在纽约走上人行道时有一辆出租车向你驶来，你就得担忧。但你不能让担忧像疯狗一样失控，将你逼至死角。你应该这样对付自己的担忧：把担忧驱至死角。不管是什么来打击你，你都要打击它。不管什么攻击你，你都要反击。</p>
<p>The fifth interior enemy is overcaution. It is the timid approach to life. Timidity is not a virtue; it’s an illness. If you let it go, it’ll conquer you. Timid people don’t get promoted. They don’t advance and grow and become powerful in the marketplace. You’ve got to avoid overcaution.</p>
<p>第五个内在的敌人是过分谨慎。那是胆小的生活方式。胆怯不是美德，而是一种疾病。如果你不理会它，它就会将你征服。胆怯的人不会得到提拔，他们在市场中不会前进，不会成长，不会变得强大。你要避免过分谨慎。</p>
<p>Do battle with the enemy. Do battle with your fears. Build your courage to fight what’s holding ou back, what’s keeping you from your goals and dreams. <strong>Be courageous in your life and in your pursuit of the things you want and the person you want to become.</strong></p>
<p>一定要向这引起敌人开战。一定要向恐惧开战。鼓起勇气抗击阻挡你的事物，与阻止你实现目标和梦想的事物作斗争。要勇敢地生活，勇敢地追求你想要的事物并勇敢地成为你想成为的人。</p>
<h2 id="016-Abundance-is-a-Life-Style-富足的生活方式"><a href="#016-Abundance-is-a-Life-Style-富足的生活方式" class="headerlink" title="016 Abundance is a Life Style 富足的生活方式"></a>016 Abundance is a Life Style 富足的生活方式</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/016%202119c1d35a4b4ef5ed55f81be7e16b27.jpg" alt=""></p>
<p>Abundance is a Life Style<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/16-abundance_is_a_life_style.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/16-abundance_is_a_life_style.mp3</a></p>
<p>Abundance is a life style, a way of living your life. It isn’t something you buy now and then or pull down from the cupboard, dust off and use once or twice, and then return to the cupboard.</p>
<p>富足是一种生活方式。它不是你偶尔买来，从架子上拿下来，抹去灰尘用上一两次然后又放回到架子上的东西。</p>
<p>Abundance is a philosophy; it appears in your physiology, your value system, and carries its own set of beliefs. You walk with it, sleep with it, bath with it, feel with it, and need to maintain and take care of it as well.</p>
<p>富足是一种哲学，它体现于你的生理机能和价值观之中，并带有自己的一套信仰。无论走路，睡觉，洗澡你都会感受到它，你还要维护并照顾它。</p>
<p><strong>Abundance doesn’t always require money. Many people live with all that money can buy yet live empty inside. Abundance begins inside with some main self-ingredients, like love, care, kindness and gentleness, thoughtfulness and compassion. Abundance is a state of being. It radiates outward. It shines like the sun among the many moons in the world.</strong></p>
<p>富足并不一定需要金钱。许多人拥有金钱所能买到的一切，但却内心空虚。富足源自内心，其中包含一些重要的自我成分，比如爱，关心，善良和温柔，体贴与同情。富足是一种存在状态，它向处发散，像处于众多星球之间的太阳那样发光发亮。</p>
<p>Being from the brightness of abundance doesn’t allow the darkness to appear or be in the path unless a choice to allow it to. The true state of abundance doesn’t have room for lies or games normally played. The space is too full of abundance. This may be a challenge because we still need to shine for other to see.</p>
<p>来自富足的光亮不允许黑暗的出现或存在，除非选择允许它存在。真正的富足不给谎言或通常玩的游戏留有空间，因为富足已经把空间填得太满了。这可能是一个挑战，因为我们仍然需要为了让别人看见而发光。</p>
<p>Abundance is seeing people for their gifts and not what they lack or could be. Seeing all things for their gifts and not what they lack.</p>
<p>富足是看到人们的天赋，而不是他的缺陷。所有的事物都要看其天赋而不是缺陷。</p>
<p>Start by knowing what your abundances are, fill that space with you, and be fully present from that state of being. Your profession of choice is telling you of knowing and possibilities. That is their gift. Consultants and customer service professionals have the ministrative assistants and virtual assistants have an abundance of coordination and time management. Abundance is all around you, and all within. See what it is; <strong>love yourself for what it is, not what you’re missing, or what that can be better, but  for what it is at this present moment.</strong></p>
<p>从知道自己的富足是什么时开始，填写满空间，全身心投入生活。你的选择已经告诉你。例如：教练能够了解队员并激发其潜力，那是他们的天赋；顾问和客服专业人士通常能够提供很多成功且很具实用性的案例；行政助理和虚拟助理熟识直辖市配合和时间管理的技巧。富足充盈于你的四周以及你的内心。明白富足的内容，爱本色的自己，不要为自己缺少的或是能变得更好的方面爱自己，而是为此时此刻的富足而爱自己。</p>
<p>Be in a state of abundance of what you already have. I guarantee they are there; it always is buried but there. Breathe them in as if they are the air you breathe because they are yours. Let go of anything that isn’t abundant for the time being. Name the shoe boxes in your closet with your gifts of abundance; pull from them every morning if needed. Know they are there.</p>
<p>要处于你已经拥有的事物的富足状态。我保证它们就在那儿，深藏不露却从未远离。将其看成空气，吸入体内，因为它们是你的。放开暂并不富足的东西。把你富足的所有天赋写在橱柜里的鞋盒子上，如果需要就每天早晨拉开橱柜，知道你的天赋都在那儿。</p>
<p>Learning to trust in your own abundance is required. When you begin to be within your own space of abundance, whatever you need will appear whenever you need it. That’s just the way the higher powers set this universe up to work. Trust the universal energy. The knowing of it all will humble you to its power yet let the brightness of you shine everywhere it needs to. Just by being from a state of abundance, it is being you.</p>
<p>你需要学会信任自己的富足。当你开始处在自己富足的空间之内时，你需要的东西都会在你需要的时刻出现。这就是更高的力量设置这个宇宙动转的方式。要相信宇宙的能量。知道这一点会让你在其力量面前保持谦卑，但也会让你的光亮闪耀在所有需要的地方。只要处于富足的状态，就是做你自己。</p>
<h2 id="017-Human-Life-a-Poem-人生如诗"><a href="#017-Human-Life-a-Poem-人生如诗" class="headerlink" title="017 Human Life a Poem 人生如诗"></a>017 Human Life a Poem 人生如诗</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/017%20quote-human-life-without-some-form-of-poetry-is-not-human-life-but-animal-existence-randall-jarrell-240276.jpg" alt=""></p>
<p>Human Life a Poem<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/17-human_life_a_poem.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/17-human_life_a_poem.mp3</a></p>
<p>I think that, from a biological standpoint, <strong>human life almost reads like a poem. It has its own rhythm and beat, its internal cycles of growth and decay. It begins with innocent childhood, followed by awkward adolescence trying awkwardly to adapt itself to mature society, with its young passions and follies, its ideals and ambitions; then it reaches a manhood of intense activities, profiting from experience and learning more about society and human nature; at middle age, there is a slight easing of tension, a mellowing of character like the ripening of fruit or the mellowing of good wine, and the gradual acquiring of a more tolerant, more cynical and at the same time a kindlier view of life; then In the sunset of our life, the endocrine glands decrease their activity, and if we have a true philosophy of old age and have ordered our life pattern according to it, it is for us the age of peace and security and leisure and contentment; finally, life flickers out and one goes into eternal sleep, never to wake up again.</strong></p>
<p>我以为，从生物学角度看，人的一生恰如诗歌。人生自有其韵律和节奏，自有内在的生成与衰亡。人生始于无邪的童年，经过少年的青涩，带着激情与无知，理想与雄心，笨拙而努力地走向成熟；后来人到壮年，经历渐广，阅人渐多，涉世渐深，收益也渐大；及至中年，人生的紧张得以舒缓，人的性格日渐成熟，如芳馥之果实，如醇美之佳酿，更具容忍之心，处世虽更悲观，但对人生的态度趋于和善；再后来就是人生迟暮，内分泌系统活动减少，若此时吾辈已经悟得老年真谛，并据此安排残年，那生活将和平，宁静，安详而知足；终于，生命之烛摇曳而终熄灭，人开始永恒的长眠，不再醒来。</p>
<p><strong>One should be able to sense the beauty of this rhythm of life, to appreciate, as we do in grand symphonies, its main theme, its strains of conflict and the final resolution. The movements of these cycles are very much the same in a normal life, but the music must be provided by the individual himself.</strong></p>
<p>人们当学会感受生命韵律之美，像听交响乐一样，欣赏其主旋律、激昂的高潮和舒缓的尾声。这些反复的乐章对于我们的生命都大同小异，但个人的乐曲却要自己去谱写。</p>
<p>In some souls, the discordant note becomes harsher and harsher and finally overwhelms or submerges the main melody. Sometimes the discordant note gains so much power that the music can no longer go on, and the individual shoots himself with a pistol or jump into a river.<br> But that is because his original leitmotif has been hopelessly over-showed through the lack of a good self-education. Otherwise the normal human life runs to its normal end in kind of dignified movement and procession. There are sometimes in many of us too many staccatos or impetuosos, and because the tempo is wrong, the music is not pleasing to the ear; we might have more of the grand rhythm and majestic tempo o the Ganges, flowing slowly and eternally into the sea.</p>
<p>在某些人心中，不和谐音会越来越刺耳，最终竟然能掩盖主曲；有时不和谐音会积蓄巨大的能量，令乐曲不能继续，这时人们或举枪自杀或投河自尽。 这是他最初的主题被无望地遮蔽，只因他缺少自我教育。否则，常人将以体面的运动和进程走向既定的终点。在我们多数人胸中常常会有太多的断奏或强音，那是因为节奏错了，生命的乐曲因此而不再悦耳。我们应该如恒河，学她气势恢弘而豪迈地缓缓流向大海。</p>
<p><strong>No one can say that life with childhood, manhood and old age is not a beautiful arrangement; the day has its morning, noon and sunset, and the year has its seasons, and it is good that it is so. There is no good or bad in life, except what is good according to its own season. And if we take this biological view of life and try to live according to the seasons, no one but a conceited fool or an impossible idealist can deny that human life can be lived like a poem.</strong> Shakespeare has expressed this idea more graphically in his passage about the seven stages of life, and a good many Chinese writers have said about the same thing. It is curious that Shakespeare was never very religious, or very much concerned with religion. I think this was his greatness; he took human life largely as it was, and intruded himself as little upon the general scheme of things as he did upon the characters of his plays. <strong>Shakespeare was like Nature itself, and that is the greatest compliment we can pay to a writer or thinker. He merely lived, observed life and went away.</strong></p>
<p>人生有童年、少年和老年，谁也不能否认这是一种美好的安排，一天要有清晨、正午和日落，一年要有四季之分，如此才好。人生本无好坏之分，只是各个季节有各自的好处。如若我们持此种生物学的观点，并循着季节去生活，除了狂妄自大的傻瓜和无可救药的理想主义者，谁能说人生不能像诗一般度过呢。莎翁在他的一段话中形象地阐述了人生分七个阶段的观点，很多中国作家也说过类似的话。奇怪的是，莎士比亚并不是虔诚的宗教徒，也不怎么关心宗教。我想这正是他的伟大之处，他对人生秉着顺其自然的态度，他对生活之事的干涉和改动很少，正如他对戏剧人物那样。莎翁就像自然一样，这是我们能给作家或思想家的最高褒奖。对人生，他只是一路经历着，观察着，离我们远去了。</p>
<h2 id="018-Solitude-独处"><a href="#018-Solitude-独处" class="headerlink" title="018 Solitude 独处"></a>018 Solitude 独处</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/018%20maysarton1.jpg" alt=""></p>
<p>Solitude<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/18-solitude.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/18-solitude.mp3</a></p>
<p>I find it wholesome to be alone the greater part of the time. To be in company, even with the best, is soon wearisome and dissipating. I love to be alone. I never found the companion that was so companionable as solitude. We are for the most part more lonely when we go abroad among men than when we stay in our chambers. A man thinking or working is always alone, let him be where he will. Solitude is not measured by the miles of space that intervene between a man and his fellows. The really diligent student in one of the crowded hives of Cambridge College is as solitary as a dervish in the desert. The farmer can work alone in the field or the woods all day, hoeing or chopping, and not feel lonesome, because he is employed; but when he comes home at night he cannot sit down in a room alone, at the mercy of his thoughts, but must be where he can :see the folks,:” and recreate, and, as he thinks, remunerate himself for his day’s solitude; and hence he wonders how the student can sit alone in the house all night and most of the day without ennui and :the blues:; but he does not realize that the student, though in the house, is still at work in his field, and chopping in his woods, as the farmer in his, and in turn seeks the same recreation and society that the latter does, though it may be a more condensed form of it.</p>
<p>我发现人若大部分时间用于独处，将有益身心。与人为伴，即使是挚友，也很快会有厌烦或虚度光阴的感觉。我爱独处，我发现没有比独处更好的伴侣了。出国，身在熙攘人群中，要比退守陋室更让人寂寞。心有所想，身有所系的人总是孤身一人，不论他身处何地。独处与否也不是由人与人之间的距离来确定。在剑桥苦读的学子虽身处蜂巢般拥挤的教室，实际上却和沙漠中的苦行僧一样，是在独处。家人终日耕于田间，伐于山野，此时他虽孤单但并不寂寞，因他专心于工作；但待到他日暮而息，却未必能忍受形影相吊，空有思绪做伴的时光，他必到“可以看见大伙儿”的去处去找乐子，如他所认为的那样以补偿白日里的孤独；因此他无法理解学子如何能竟夜终日独坐而不心生厌倦或倍感凄凉；然而他没意识到，学子虽身在学堂，但心系劳作，但是耕于心田，伐于学林，这正和农人一样，学子在寻求的无非是和他一样的快乐与陪伴，只是形式更简洁罢了。</p>
<p>Society is commonly too cheap. We meet at very short intervals, not having had time to acquire any new value for each other. We meet at meals three times a day, and give each other a new taste of that old musty cheese that we are. We have had to agree on a certain set of rules, called etiquette and politeness, to make this frequent meeting tolerable and that we need not come to open war. We meet at the post-office, and at the sociable, and about the fireside every night; we live thick and are in each other’s way, and stumble over one another, and I think that we thus lose some respect for one another. Certainly less frequency would suffice for all important and hearty communications. Consider the girls in a factory—never alone, hardly in their dreams. It would be better if there were but one inhabitant to a square mile, as where I live. <strong>The value of a man is not in his skin, that we should touch him.</strong></p>
<p>与人交往通常都因唾手可得而毫无价值，在频繁的相处中，我们无暇从彼此获取新价值。我们每日三餐相聚，反复让彼此重新审视的也是依旧故我，并无新奇之处。为此我们要循规蹈矩，称其为懂礼仪，讲礼貌，以便在这些频繁的接触中相安无事，无须论战而有辱斯文。我们相遇在邮局，邂逅在社交场所，围坐在夜晚的炉火旁，交情甚笃，彼此干扰着，纠缠着；实际上我认为这样我们都或多或少失去了对彼此的尊重。对于所有重要的倾心交流，相见不必过频。想想工厂里的女孩，她们虽从不落单，但也少有梦想。像这样方圆一英里仅一人居住，那情况会更好。人的价值非在肌肤相亲，而在心有灵犀。</p>
<p>I have a great deal of company in my house; especially in the morning, when nobody calls. Let me suggest a few comparisons, that some one may convey an idea of my situation. I am no more lonely than the loon in the pond that laughs so loud, or than Walden Pond itself. What company has that lonely lake, I pray?And yet it has not the blue devils, but the blue angels in it, in the azure tint of its waters. The sun is alone, except in thick weather, when there sometimes appear to be two, but one is a mock sun. <strong>god is alone—but the devil, he is far from being alone; he sees a great deal of company; he is legion.</strong> I am no more lonely than a single mullein or dandelion in a pasture, or a bean leaf, or sorrel, or a horse-fly, or a bumblebee. I am no more lonely than the Millbrook, or a weathercock, or the north star, or the south wind, or an April shower, or a January thaw, or the first spider in a new house.</p>
<p>我的房子里有很多伙伴，尤其在无人造访的清晨。我把自己和周围事物对比一下，你或许能窥见我生活的一斑。比起那湖中长笑的潜鸟，还有那湖，我并不比它们孤独多少。你看：这孤单的湖又何以为伴呢？然而它那一湾天蓝的湖水里有的却是天使的纯净，而非魔鬼的忧郁。太阳是孤独的，虽然时而在阴郁的天气里会出现两个太阳，但其中之一为幻日；上帝是孤独的 – 魔鬼才从不孤单，他永远不乏伙伴，因从他都甚众。比起牧场上的一朵毛蕊花，一支蒲公英，一片豆叶，一束酢浆草，一只牛虻或大黄蜂来，我并不孤单多少；比想密尔溪，风标，北极星，南风，四月春雨，正月融雪，或者新房中的第一只蜘蛛，我也并不更加孤单。</p>
<h2 id="019-Giving-Life-Meaning-给生命以意义"><a href="#019-Giving-Life-Meaning-给生命以意义" class="headerlink" title="019 Giving Life Meaning 给生命以意义"></a>019 Giving Life Meaning 给生命以意义</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/019%20quote-the-meaning-of-life-is-to-give-life-meaning-ken-hudgins-344710.jpg" alt=""></p>
<p>Giving Life Meaning<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/19-giving_life_meaning.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/19-giving_life_meaning.mp3</a></p>
<p>Have you thought about what you want people to say about you after you’re gone? Can you hear the voice saying, “He was a great man.” Or “She really will be missed.” What else do they say?</p>
<p>你有没有想过，你希望人们在你死后怎样评论你？你能否听到这样的说，“他是个伟大的人”或“人们的确会怀念她”，他们还会说些什么？</p>
<p>One of the strangest phenomena of life is to engage in a work that will last long after death. Isn’t that a lot like investing all your money so that future generations can bare interest on it? Perhaps, <strong>yet if you look deep in your own heart, you’ll find something drives you to make this kind of contribution—something drives every human being to find a purpose that lives on after death.</strong></p>
<p>人生最奇异的现象之一就是，你从事的事业在你死后仍将长久存在。这和你用所的钱进行投资以便后人能从中获益不是如出一辙吗？也许，如果你审视自己的内心深处，你就会发现促使你做出这种贡献的驱动力-一种驱使每个人寻找在自己死后仍能继续存在的事业的驱动力。</p>
<p>Do you hope to memorialize your name? Have a name that is whispered with reverent awe? Do you hope to have your face carved upon 50 ft of granite rock? Is the answer really that simple? Is the purpose of lifetime contribution an ego-driven desire for a mortal being to have an immortal name or is it something more?</p>
<p>你希望自己的名字被人记住吗？你希望别人提起你的名字时心怀敬畏吗？你希望自己的面容被雕刻在50英尺高的花岗岩上吗？答案真的那么简单吗？贡献一生的目的难道终将一死之人想要获得不朽名声的自我鞭策的欲望？抑或是其他更伟大的事物？</p>
<p>A child alive today will die tomorrow. A baby that had the potential to be the next Einstein will die from complication is at birth. The circumstances of life are not set in stone. We are not all meant to live life through to old age. We’ve grown to perceive life3 as a full cycle with a certain number of years in between. If all of those years aren’t lived out, it’s a tragedy. A tragedy because a human’s potential was never realized. A tragedy because a spark was snuffed out before it ever became a flame.</p>
<p>今天活着的孩子明天就会死去。一个有可能成为下一个爱因斯坦的婴儿会死于出生并发症。生命的情形并不是固定不变的。我们并没有注定都要活到老年。我们已经认识到，生命是一个周期，其时间长度是特定的。如果这些时间没有被充分利用，那就是个悲剧，因为人的潜能还未实现，因为火花还没形成火焰就被补灭。</p>
<p>By virtue of inhabiting a body we accept these risks. We expose our mortal flesh to the laws of the physical environment around us. The trade off isn’t so bad when you think about it. The problem comes when we construct mortal fantasies of what life should be like. When life doesn’t conform to our fantasy we grow upset, frustrated, or depressed.</p>
<p>由于存在于肉体之中，所以我们接受这些风险。我们使易朽的肉体服从周围物理环境的法则。你仔细想一想就会发现，这种交易并不是那么糟糕。当我们幻想生命应该如何时，问题就来了。当生命和我们的幻想不一致时，我们就变得烦恼，无奈或沮丧。</p>
<p><strong>We are alive; let us live. We have the ability to experience; let us experience. We have the ability to learn; let us learn. The meaning of life can be grasped in a moment. A moment so brief it often evades our perception.</strong></p>
<p>我们活着，那我们就要活得精彩；我们有能力体验，那我们就要体验人生甘苦；我们有能力学习，那我们就要在学海徜徉。生命的意义可以在一瞬间抓住-一个经常被我们忽略的短暂瞬间。</p>
<p>What meaning stands behind the dramatic unfolding of life? What single truth can we grasp and hang onto for dear life when all other truths around us seem to fade with time?</p>
<p>当生命戏剧般地一幕幕拉开时，其中隐含的意义是什么？当我们周围所有其他都似乎随着时间而消逝时，我们能够掌握哪个真理并依靠它来生活呢？</p>
<p><strong>These moments are strung together in a series we call events. These events are strung together in a series we call life.When we seize the moment and bend it according to our will, a will driven by the spirit deep inside us, then we have discovered the meaning of life, a meaning for us that shall go on long after we depart this Earth.</strong></p>
<p>这些瞬间串联在一起，我们称之为事件。这些事件串联系在一起， 我们称之为生活。当我们抓住那个瞬间并按照我们的意志来改变它-这意志受到我们内心深处的精神的驱使，我们就发现了生命的意义-这意义将在我们离开地球之后长久存在。</p>
<h2 id="020-Relish-the-Moment-品位现在"><a href="#020-Relish-the-Moment-品位现在" class="headerlink" title="020 Relish the Moment 品位现在"></a>020 Relish the Moment 品位现在</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/020%20think-big-thoughts-but-relish-small-pleasures-quote-1.jpg" alt=""></p>
<p>Relish the Moment<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/20-relish_the_moment.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/20-relish_the_moment.mp3</a></p>
<p>Tucked away in our subconsciousness is an idyllic vision. We see ourselves on a long trip that spans the moment. We are traveling by train. Out the windows, we drink in the passing scene of cars on nearby highways, of children waving at a crossing, of cattle grazing on a distant hillside, of smoke pouring from a power plant, of row upon row of corn ad wheat, of flatlands and valleys, of mountains and rolling hillsides, of city skylines and village halls.</p>
<p>我们的潜意识里藏着一派田园诗般的风光! 我们仿佛身处一次横贯大陆的漫漫旅程之中! 乘着火车, 我们领略着窗外流动的景色：附近高速公路上奔驰的汽车、十字路口处招手的孩童、远山上吃草的牛群、源源不断地从电厂排放出的烟尘、一片片的玉米和小麦、平原与山谷、群山与绵延的丘陵、天空映衬下城市的轮廓, 以及乡间的庄园宅第!</p>
<p>But uppermost in our minds is the final destination. On a certain day at a certain hour, we will pull into the station. Bands will be playing and flags waving. Once we get there, so many wonderful dreams will come true and the pieces of our lives will fit together like a completed jigsaw puzzle. How restlessly we pace the aisles, damning the minutes for loitering—waiting, waiting, waiting for the station.</p>
<p> 然而我们心里想得最多的却是最终的目的地! 在某一天的某一时刻, 我们将会抵达进站! 迎接我们的将是乐队和飘舞的彩旗! 一旦到了那儿, 多少美梦将成为现实, 我们的生活也将变得完整, 如同一块理好了的拼图! 可是我们现在在过道里不耐烦地踱来踱去, 咒骂火车的拖拖拉拉! 我们期待着, 期待着, 期待着火车进站的那一刻!</p>
<p>“When we reach the station, that will be it!” we cry. “When I’m 18.” “When I buy a new 450SL Mercedes Benz!” “When I put the last kid through college.” “When I have paid off the mortgage!” “When I get a promotion.” “When I reach the age of retirement, I shall live happily ever after!”</p>
<p>“当我们到站的时候, 一切就都好了! “我们呼喊着! “当我18岁的时候! “”当我有了一辆新450SL奔驰的时候! “”当我供最小的孩子念完大学的时候! “”当我偿清贷款的时候! “”当我官升高任的时候! “”当我到了退休的时候, 就可以从此过上幸福的生活啦! “</p>
<p>Sooner or later, we must realize there is no station, no one place to arrive at once and for all. <strong>The true joy of life is the trip. The station is only a dream. It constantly outdistances us.</strong></p>
<p> 可是我们终究会认识到人生的旅途中并没有车站, 也没有能够”一到永逸”的地方!生活的真正乐趣在于旅行的过程, 而车站不过是个梦, 它始终遥遥领先于我们!</p>
<p><strong>It isn’t the burdens of today that drive men mad. It is the regrets over yesterday and the fear of tomorrow. Regret and fear are twin thieves who rob us of today.</strong></p>
<p>真正令人发疯的不是今日的负担, 而是对昨日的悔恨及对明日的恐惧! 悔恨与恐惧是一对孪生窃贼, 将今天从你我身边偷走!</p>
<p>So stop pacing the aisles and counting the miles. Instead, climb more mountains, eat more ice cream, go barefoot more often, swim more rivers, watch more sunsets, laugh more, cry less. Life must be lived as we go along. The station will come soon enough.</p>
<p>那么就不要在过道里徘徊吧, 别老惦记着你离车站还有多远! 何不换一种活法, 将更多的高山攀爬, 多吃点儿冰淇淋甜甜嘴巴, 经常光着脚板儿溜达, 在更多的河流里畅游, 多看看夕阳西下, 多点欢笑哈哈, 少让泪水滴答! 生活得一边过一边瞧! 车站就会很快到达!</p>
<h2 id="021-The-Love-of-Beauty-爱美"><a href="#021-The-Love-of-Beauty-爱美" class="headerlink" title="021 The Love of Beauty 爱美"></a>021 The Love of Beauty 爱美</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/021%200787a35ee8b6482a2da72214a405aa42.jpg" alt=""></p>
<p>The Love of Beauty<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/21-the_love_of_beauty.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/21-the_love_of_beauty.mp3</a></p>
<p>The love of beauty is an essential part of all healthy human nature. It is a moral quality. The absence of it is not an assured ground of condemnation, but the presence of it is an invariable sign of goodness of heart. <strong>In proportion to the degree in which it is felt will probably be the degree in which nobleness and beauty of character will be attained.</strong></p>
<p>爱美及是整个健全人性不可或缺之一部分。它是一种道德品质。缺乏这种品质并不能作为受到责难的充分理由，但是拥有这种品质则是心灵美好的永恒标志。品德的高尚与美好所达到的程度可能与对美的感受程度成正比。</p>
<p>Natural beauty is an all-pervading presence. The universe is its temple. It unfolds into the numberless flowers of spring. It waves in the branches of trees and the green blades of grass. It haunts the depths of the earth and the sea. It gleams from the hues of the shell and the precious stone. And not only these minute objects but the oceans, the mountains, the clouds, the stars, the rising and the setting sun—all overflow with beauty. This beauty is so precious, and so congenial to our tenderest and noblest feelings, that <strong>it is painful to think of the multitude of people living in the midst of it and yet remaining almost blind to it.</strong></p>
<p>大自然的美无处不在，整个宇宙就是美的殿堂。美，在春日百花中绽放；美，在绿叶嫩枝间摇曳；美，在深海幽谷里游弋；美，在奇石与贝壳的缤纷色彩中闪烁。不只是这些细微之物，还有海洋，山川，云彩，繁星，日升日落 – 一切都是洋溢着美。这样的美是如此珍贵，与我们最温柔，最高尚的情愫是如此相宜。然而，想到很多人置身于美之中，却几乎对它熟视无睹，真是令人痛心不已。</p>
<p>All persons should seek to become acquainted with the beauty in nature. There is not a worm we tread upon, nor a leaf that dances merrily as it falls before the autumn winds, but calls for our study and admiration. <strong>The power to appreciated beauty not merely increases our sources of happiness—it enlarges our moral nature, too. Beauty calms our restlessness and dispels our cares. Go into the fields or the woods, spend a summer day by the sea or the mountains, and all your little perplexities and anxieties will vanish. Listen to sweet music, and your foolish fears and petty jealousies will pass away. The beauty of the world helps us to seek and find the beauty of goodness.</strong></p>
<p>所有的人都应该去认识大自然之美。没有一条我们踩过的小虫，没有一片在秋风拂掠之际飞舞的树叶不值得我们研究与赞赏。欣赏美的能力不仅增加了我们快乐的来源，也加强了我们德性的修养。美使我们不安的心平静下来，也驱散了我们的忧虑。到田野或森林去，在夏日的海边或山上呆上一天，那么你所有微不足道的困惑与焦虑都会烟消云散。倾听悦耳的音乐，你那愚蠢的恐惧与狭隘的嫉妒都会过去。世界之美将有助于我们找到为善之美。</p>
<h2 id="022-The-Happy-Door-快乐之门"><a href="#022-The-Happy-Door-快乐之门" class="headerlink" title="022 The Happy Door 快乐之门"></a>022 The Happy Door 快乐之门</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/022%20ddeb6bd8f7ed6598b165c7a200256265.jpg" alt=""></p>
<p>The Happy door<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/22-the_happy_door.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/22-the_happy_door.mp3</a></p>
<p><strong>Happiness is like a pebble dropped into a pool to set in motion an ever-widening circle of ripples. As Stevenson has said, being happy is a duty.</strong></p>
<p>快乐就像一块为了激起阵阵涟漪而丢进池塘的小石头。正好史蒂文森所说，快乐是一种责任。</p>
<p>There is no exact definition of the word happiness. Happy people are happy for all sorts of reasons. The key is not wealth or physical well-being, since we find beggars, invalids and so-called failures, who are extremely happy.</p>
<p>快乐这个词并没有确切的定义，快乐的人快乐的理由多种多样。快乐的关键并不是财富或身体健康，因为我们发现有些乞丐，残疾人和所谓的失败者也都非常快乐。</p>
<p>Being happy is a sort of unexpected dividend. But staying happy is an accomplishment, a triumph of soul and character. It is not selfish to strive for it. It is, indeed, a duty to ourselves and others.</p>
<p>快乐是一种意外的收获，但保持快乐却是一种成就，一种灵性的胜利。努力追寻快乐并不自私，实际上，这是我们对自己和他人应尽的责任。</p>
<p>Being unhappy is like an infectious disease. It causes people to shrink away from the sufferer. He soon finds himself alone, miserable and embittered. There is, however, a cure so simple as to seem, at first glance, ridiculous; if you don’t feel happy, pretend to be!</p>
<p>不快乐就像传染病，它使得人们都躲避不快乐的人。不快乐的人很快就会发现自己处于孤独，悲惨，痛苦的境地。然而，有一种简单得看似荒谬的治病良方：如果你不快乐，就假装你很快乐！</p>
<p>It works. Before long you will find that instead of repelling people, you attract them. You discover how deeply rewarding it is to be the center of wider and wider circles of good will.</p>
<p>这很有效。不久你就会发现，别人不再躲着你了，相反，你开始吸引别人了。你会发觉，做一块能激起好意涟漪的小石头有多么值得。</p>
<p>Then the make-believe becomes a reality. You possess the secret of peace of mind, and can forget yourself in being of service to others.</p>
<p>然后假装就变成了现实。你拥有了使心灵平静的秘密，会因帮助他人而忘我。</p>
<p>Being happy, once it is realized as a duty and established as a habit, opens doors into unimaginable gardens thronged with grateful friends.</p>
<p>一旦你认识到快乐是一种责任并使快乐成为习惯，通向不可思议的乐园的大门就会向你敞开，那里满是感激你的朋友。</p>
<h2 id="023-Born-to-Win-生而为赢"><a href="#023-Born-to-Win-生而为赢" class="headerlink" title="023 Born to Win 生而为赢"></a>023 Born to Win 生而为赢</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/023%20zig-ziglar-author-quote-you-were-born-to-win-but-to-be-a-winner-you.jpg" alt=""></p>
<p>Born to Win<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/23-born_to_win.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/23-born_to_win.mp3</a></p>
<p>Each human being is born as something new, something that never existed before. Each is born with the capacity to win at life. Each person has a unique way of seeing, hearing, touching, tasting and thinking. Each has his or her own unique potentials—capabilities and limitations. Each can be a significant, thinking, aware, and creative being—a productive person, a winner.</p>
<p>人皆生而为新，为前所未有之所存在；人皆生而能赢。人皆有其特立独行之方式去审视，聆听，触摸，品味及思考，因而都具备独特潜质-能力和局限。人皆能举足轻重，思虑明达，洞察秋毫，富有创意，成就功业。</p>
<p>The word “winner” and “loser” have many meanings. When we refer to a person as a winner, we do not mean one who makes someone else lose. To us, a <strong>winner is one who responds authentically by being credible, trustworthy, responsive, and genuine, both as an individual and as a member of a society.</strong></p>
<p>“成者”与“败者”含义颇多。谈及成者我们并非指令他人失意之人。对我们而言，成者必为人守信，值得信赖，有求必应，态度诚恳，或为个人，或为社会一员皆能以真诚回应他人。</p>
<p>Winners do not dedicated their lives to a concept of what they imagine they should be; rather, they are themselves and as such do not use their energy putting on a performance, maintaining pretence and manipulating others. They are aware that there is a difference between being loving and acting loving, between being stupid and acting stupid, between being knowledgeable and acting knowledgeable. <strong>Winners do not need to hide behind a mask.</strong></p>
<p>成者行事并不拘泥于某种信条，即便是他们认为应为其奉献一生的理念；而是本色行事，所以并不把精力用来表演，保持伪装或操控他人。他们明了爱与装爱，愚蠢与装傻，博学与卖弄之间迥然有别。成者无须藏于面具之后。</p>
<p><strong>Winners are not afraid to do their own thinking and to use their own knowledge. They can separate facts from opinions and don’t pretend to have all the answers. They listen to others, evaluate what they say, but come to their own conclusions. Although winners can admire and respect other people, they are not totally defined, demolished, bound, or awed by them.</strong></p>
<p>成者敢于利用所学，独立思考，区分事实与观点，且并不佯装通晓所有答案。他们倾听，权衡他人意见，但能得出自己的结论。尽管他们尊重，敬佩他们，但并不为他们所局限，所推翻，所束缚，也不对他人敬若神灵。</p>
<p>Winners do not play “helpless”, nor do they play the blaming game. Instead, they assume responsibility for their own lives. They don’t give others a false authority over them. <strong>Winners are their own bosses and know it.</strong></p>
<p>成者既不佯装“无助”，亦不抱怨他人。相反，他们对人生总是独担责任，也不以权威姿态凌驾他人之上。他们主宰自己，而且能意识到这点。</p>
<p>A winner’s timing is right. Winners respond appropriately to the situation. Their responses are related to the message sent and preserve the significance, worth, well-being, and dignity of the people involved. <strong>Winners know that for everything there is a season and for every activity a time.</strong></p>
<p>成者善于审时度势，随机应变。他们对所接受的信息做出回应，维护当事人的利益，康乐和尊严。成者深知成一事要看好时节，行一事要把握时机。</p>
<p><strong>Although winners can freely enjoy themselves, they can also postpone enjoyment, can discipline themselves in the present to enhance their enjoyment in the future. Winners are not afraid to go after what he wants, but they do so in proper ways. Winners do not get their security by controlling others. They do not set themselves up to lose.</strong></p>
<p>尽管成者可以自由享乐，但他更知如何推迟享乐，适时自律，以期将来乐趣更盛。成者并不忌惮追求所想，但取之有道，也并不靠控制他们而获取安然之感。他们总是使自己立于不败。</p>
<p>A winner cares about the world and its peoples. A winner is not isolated from the general problems of society, but is concerned, compassionate, and committed to improving the quality of life. Even in the face of national and international adversity, a winner’s self-image is not one of a powerless individual. <strong>A winner works to make the world a better place.</strong></p>
<p>成者心忧天下，并不孤立尘世弊病之外，而是置身事内，满腔热情，致力于改善民生。即使面对民族，国家之危亡，成者亦非无力回天之个体。他总是努力令世界更好。</p>
<h2 id="024-Work-and-Pleasure-工作和娱乐"><a href="#024-Work-and-Pleasure-工作和娱乐" class="headerlink" title="024 Work and Pleasure 工作和娱乐"></a>024 Work and Pleasure 工作和娱乐</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/024%20quote-if-you-re-interested-in-balancing-work-and-pleasure-stop-trying-to-balance-them-instead-donald-trump-29-74-41.jpg" alt=""></p>
<p>Work and Pleasure<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/24-work_and_pleasure.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/24-work_and_pleasure.mp3</a></p>
<p>To be really happy and really safe, one ought to have at least two or three hobbies, and they must all be real. It is no use starting late in life to say: “I will take an interest in this or that.” Such an attempt only aggravates the strain of mental effort. A man may acquire great knowledge of topics unconnected with his daily work, and yet hardly get any benefit or relief. It is no use doing what you like; you have got to like what you do. Broadly speaking, human being may be divided into three classes: those who are toiled to death, those who are worried to death, and those who are bored to death. It is no use offering the manual laborer, tired out with a hard week’s sweat and effort, the chance of playing a game of football or baseball on Saturday afternoon. It is no use inviting the politician or the professional or business man, who has been working or worrying about serious things for six days, to work or worry about trifling things at the weekend.</p>
<p>要想真正生活得幸福和平安，一个人至少应该有两三种业余爱好，而且必须是真正的爱好。到了晚年才开始说“我要培养这个或那个兴趣”是毫无用处的，种这种尝试只会增加精神上的负担。在与自己日常工作无关的领域中，一个人可以获得渊博的知识，但却很难有所收益或得到放松。做自己喜欢的事是无益的，你得喜欢自己所做的事。广言之，人可以分为三个类别：劳累而死的人，忧虑而死的人和无聊而死的人。对于那些体力劳动者来说，一周辛苦的工作使他们精疾力竭，因此在周六下午给他们提供踢足球或者打棒球的机会是没有意义的。对于政界人士，专业人士或者商人来说，他们已经为棘手的事务操劳或者烦恼了六天，因此在周末请他们为琐事劳神同样毫无意义。</p>
<p>It may also be said that rational, industrious, useful human beings are divided into two classes: first, those whose work is work and whose pleasure is pleasure; and secondly, those whose work and pleasure are one. Of these the former are the majority. They have their compensations. The long hours in the office or the factory bring with them as their reward, not only the means of sustenance, but a keen appetite for pleasure even in its simplest and most modest forms. But Fortune’s favored children belong to the second class. Their life is a natural harmony. For them the working hours are never long enough. Each day is a holiday, and ordinary holidays when they come are grudged as enforced interruptions in an absorbing vacation. Yet to both classes the need of an alternative outlook, of a change of atmosphere, of a diversion of effort, is essential. Indeed, it may well be that those whose work is their pleasure are those who most need the means of banishing it at intervals from their minds.</p>
<p>或者可以这么说，理智的，勤奋的，有用的人可以分为两类：对第一类人而言，工作就是工作，娱乐就是娱乐；对于第二类人而言，工作和娱乐是合二为一的。很大一部分人属于前者。他们可以得到相应的补偿。在办公室或工厂里长时间的工作，不仅带给他们维持生计的金钱，还带给他们一种渴求娱乐的强烈欲望，哪怕这种娱乐消遣是以最简单，最淳朴的方式进行的。而第二类人则是命运的宠儿。他们的生活自然而和谐。在他们看来，工作时间永远不够多，每天都是假期；而当正常的假日到来时，他们总会抱怨自己有趣的休假被强行中断。然而，有一些东西对于这两类人来说都十分必要，那就是变换一下视角，改变一下氛围，尝试做点不同的事情。事实上，那些把工作看作娱乐的人可能是需要以某种方式将工作不时地驱赶出自己的大脑。</p>
<h2 id="025-Mirror-Mirror–What-do-I-see镜子-镜子-告诉我"><a href="#025-Mirror-Mirror–What-do-I-see镜子-镜子-告诉我" class="headerlink" title="025 Mirror, Mirror–What do I see镜子,镜子,告诉我"></a>025 Mirror, Mirror–What do I see镜子,镜子,告诉我</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/025%20quote-when-you-look-in-the-mirror-what-do-you-see-do-you-see-the-real-you-or-what-you-have-david-icke-14-5-0540.jpg" alt=""></p>
<p>Mirror, Mirror—What do I See?<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/25-mirror_mirror__what_do_i_see.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/25-mirror_mirror__what_do_i_see.mp3</a></p>
<p><strong>A loving person lives in a loving world. A hostile person lives in a hostile world. Everyone you meet is your mirror.</strong></p>
<p>充满爱意人的生活在充满爱意的世界里，充满敌意的人则生活在充满敌意的世界里。你所遇到的每一个人都是你的镜子。</p>
<p>Mirrors have a very particular function. They reflect the image in front of them. <strong>Just as a physical mirror serves as the vehicle to reflection, so do all of the people in our lives.</strong></p>
<p>镜子里有一个非常独特的功能，那就是映射出在其前面的影像。就像真正的镜子具有反射功能一样，我们生活中的所有人也都能映射出他人的影子。</p>
<p>When we see something beautiful such as a flower garden, that garden serves as a reflection. In order to see the beauty in front of us, we must be able to see the beauty inside of ourselves. When we love someone, it’s a reflection of loving ourselves. When we love someone, it’s a reflection of loving ourselves. We have often heard things like “<strong>I love how I am when I’m with that person.</strong>” That simply translates into “I’m able to love me when I love that other person.” Oftentimes, when we meet someone new, we feel as though we “click”. Sometimes it’s as if we’ve known each other for a long time. That feeling can come from sharing similarities.</p>
<p>当我们看到美丽的事物时，例如一座花园，那这花园就起到了反射作用。为了发现我们面前美好的事物，我们必须能发现在自己内在的美。我们爱某个人，也正是我们爱自己的表现。我们经常听到这样的话：“当我和那个人在一起的时候，我爱那时的自己。”这句话也可以简单地说成：“在我爱那个人的同时，我也能爱我自己。”有时，我们遇见一个陌生人，感觉仿佛是一见如故，就好像我们已经相识甚久。这种熟悉感可能来自于彼此身上的共同点。</p>
<p>Just as the “mirror” or other person can be a positive reflection, it is more likely that we’ll notice it when it has a negative connotation. For example, it’s easy to remember times when we have met someone we’re not particularly crazy about. We may have some criticism in our mind about the person. This is especially true when we get to know someone with whom we would rather spend less time.</p>
<p>就像“镜子”或他人能映射出我们积极的一面一样，我们更有可能注意到映射出自己消极方面的“镜子”。例如，我们很容易就能记住我们碰到自己不太喜欢的人的时刻。我们可能在心里对那个人有些反感。当我们认识自己不喜欢与之相处的人时，这种情况就更为明显。</p>
<p>Frequently, <strong>when we dislike qualities in other people, ironically, it’s usually the mirror that’s speaking to us.</strong></p>
<p>具有讽刺意味着的是，通常当我们讨厌别人身上的某些特质时，那就说明你其实讨厌自己身上相类似的特质。</p>
<p>I began questioning myself further each time I encountered someone that I didn’t particularly like. Each time, I asked myself, “What is it about that person that I don’t like?” and then “Is there something similar in me?” in every instance, I could see a piece of that quality in me, and sometimes I had to really get very introspective. So what did that mean?</p>
<p>每次，当我遇到不太喜欢的人时，我就开始进一步质问自己。我会扪心自问：“我不喜欢那个人的哪些方面？”然后还会问：“我是不是有和他相似的地方？”每次，我都能在自己身上看到一些令我厌恶的特质。我有时不得不深刻地反省自己。那这意味着什么呢？</p>
<p>It means that just as I can get annoyed or disturbed when I notice that aspect in someone else, I better reexamine my qualities and consider making some changes. Even if I’m not willing to make a drastic change, at least I consider how I might modify some of the things that I’m doing.</p>
<p>这意味着，就像我会对其他人身上令我厌恶的特质感到恼怒或不安一样，我应该更好地重新审视自己的特质，并考虑做一些改变。即使我不想做大的改变，至少我会考虑该如何修正自己正在做的一些事情。</p>
<p>At times we meet someone new and feel distant, disconnected, or disgusted. Although we don’t want to believe it, and it’s not easy or desirable to look further, it can be a great learning lesson to figure out what part of the person is being reflected in you. It’s simply just another way to create more self-awareness.</p>
<p>我们时常会遇到陌生人，并感到疏远或厌恶。尽管我们不想去相信，不容易也不想去深究，但是弄清楚别人的哪些特质在自己身上有所体现是非常有意义的一课，这也正是增强自我意识的另一个途径。</p>
<h2 id="026-On-Motes-and-Beams-微尘与栋梁"><a href="#026-On-Motes-and-Beams-微尘与栋梁" class="headerlink" title="026 On Motes and Beams 微尘与栋梁"></a>026 On Motes and Beams 微尘与栋梁</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/026%20quote-why-beholdest-thou-the-mote-that-is-in-thy-brother-s-eye-but-considerest-not-the-beam-that-is-in-bible-303549.jpg" alt=""></p>
<p>On Motes and Beams<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/26-on_motes_and_beams.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/26-on_motes_and_beams.mp3</a></p>
<p><strong>It is curious that our own offenses should seem so much less heinous than the offenses of others. I suppose the reason is that we know all the circumstances that have occasioned them and so manage to excuse in ourselves what we cannot excuse in others. We turn our attention away from our own defects, and when we are forced by untoward events to consider them, find it easy to condone them. For all I know we are right to do this; they are part of us and we must accept the good and bad in ourselves together.</strong></p>
<p>让人奇怪的是，和别人的过错比起来，我们自身的过错往往不是那样的可恶。我想，其原因应该是我们知晓一切导致自己犯错的情况，因此能够设法谅解自己的错误，而别人的错误却不能谅解。我们对自己的缺点不甚关注，即便是深陷困境而不得不正视它们的时候，我们也会很容易就宽恕自己。据我所知，我们这样做是正确的。缺点是我们自身的一部分，我们必须接纳自己的好和坏。</p>
<p>But when we come to judge others, it is not by ourselves as we really are that we judge them, but by an image that we have formed of ourselves fro which we have left out everything that offends our vanity or would discredit us in the eyes of the world. <strong>To take a trivial instance: how scornful we are when we catch someone out telling a lie; but who can say that he has never told not one, but a hundred?</strong></p>
<p>但是当我们评判别人的时候，情况就不同了。我们不是通过真实的自我来评判别人，而是用一种自我形象来评判，这种自我形象完全摒弃了在任何世人眼中会伤害到自己的虚荣或者体面的东西。举一个小例子来说：当觉察到别人说谎时，我们是多么地蔑视他啊！但是，谁能够说自从未说过谎？可能还不止一百次呢。</p>
<p>There is not much to choose between men. They are all a hotchpotch of greatness and littleness, of virtue and vice, of nobility and baseness. Some have more strength of character, or more opportunity, and so in one direction or another give their instincts freer play, but potentially they are the same. For my part, I do not think I am any better or any worse than most people, but I know that if I set down every action in my life and every thought that has crossed my mind, the world would consider me a monster of depravity. The knowledge that these reveries are common to all men should inspire one with tolerance to oneself as well as to others. It is well also if they enable us to look upon our fellows, even the most eminent and respectable, with humor, and if they lead us to take ourselves not too seriously.</p>
<p>人和人之间没什么大的差别。他们皆是伟大与渺小，善良与邪恶，高尚与低俗的混合体。有的人性格比较坚毅，机会也比较多，因而达个或那个方面，能够更自由地发挥自己的禀赋，但是人类的潜能却都是相同的。至于我自己，我认为自己并不比大多数人更好或者更差，但是我知道，假如我记下我生命中每一次举动和每一个掠过我脑海的想法的话，世界就会将我视为一个邪恶的怪物。每个人都会有这样的怪念头，这样的认识应当能够启发我们宽容自己，也宽容他人。同时，假如因此我们得以用幽默的态度看待他人，即使是天下最优秀最令人尊敬的人，而且假如我们也因此不把自己看得过于重要，那是很有裨益的。</p>
<h2 id="027-An-October-Sunrise-十月的日出"><a href="#027-An-October-Sunrise-十月的日出" class="headerlink" title="027 An October Sunrise 十月的日出"></a>027 An October Sunrise 十月的日出</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/027%20b126c5834e46c4e0f5f5679ba8c5c012.jpg" alt=""></p>
<p>An October Sunrise<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/27-an_october_sunrise.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/27-an_october_sunrise.mp3</a></p>
<p>I was up the next morning be fore the October sunrise, and away through the wild and the woodland. The rising of the sun was noble in the cold and warmth of it peeping down the spread of light, he raised his shoulder heavily over the edge of grey mountain and wavering length of upland. Beneath his gaze the dew-fogs dipped, and crept to crept to the hollow places; then stole away in line and column, holding skirts, and clinging subtly at the sheltering corners where rock hung over grassland, while the brave lines of the hills came forth, one beyond other gliding.</p>
<p>第二天凌晨，在十月的太阳升起之前，我已经起身并穿过了旷野和丛林。十月的清晨乍寒还暖，日出的景象非常壮观。透过一片晨曦，朝日从朦胧的山冈和起伏连绵的高地过际，沉重地抬起肩头。在它的逼视下，蒙蒙的雾气向下沉降，落到洼地里去，接着一丝丝一缕缕地悄悄飘散，而在草地之上悬岩之下的那些隐秘角落里，雾气却还不愿散去，同时群山的雄姿接二连三地显现出来。</p>
<p>The woods arose in folds, like drapery of awakened mountains, stately with a depth of awe, and memory of the tempests. Autumn’s mellow hand was upon them, as they owned already, touched with gold and red and olive, and their joy towards the sun was less to a bridegroom than a father.</p>
<p>森林也层层叠叠地显现，宛若刚刚苏醒的山峦的斗篷，端庄威严，并带着狂风暴雨的回忆。秋天成熟的手已经在抚摸这些山林，因为它们的颜色已经改变，染上了金黄，丹红和橄榄绿。它们对朝日所怀的一片喜悦，像是要奉献给一个新郎，更像是要奉献给一位父亲。</p>
<p>Yet before the floating impress of the woods could clear it self, suddenly the gladsome light leaped over hill and valley, casting amber, blue, and purple, and a tint of rich red rose; according to the scene they lit on, and the curtain flung around; yet all alike dispelling fear and the cloven hoof of darkness, all on the wings of hope advancing, and proclaiming, “God is here!” then life and joy sprang reassured from every crouching hollow; every flower, and bud and bird had a fluttering sense of them; and all the flashing of God’s gaze merged into soft beneficence.</p>
<p>然而，在树林那流动的景色逝去之前，欢悦的晨光突然跃出了峰峦和山谷，光线所及，把照到的地方和周围的森林分别染成青色，紫色，琥珀色和富丽的红玫瑰色。光线照到哪里，那里就如同一幅幕布被掀开。而所有的一切都同样在驱散恐惧和黑暗的魔影；所有的一切都展开希望的翅膀，向前习翔，并大声宣告：“上帝在这里！”于是生命和欢乐从每一个蜷伏的洞穴里信心十足地欣然跃出；一切花朵，蓓蕾和鸟雀都感到了生命和欢乐而抖动起来；上帝的凝视汇合成温柔的恩泽。</p>
<p>So, perhaps, shall break upon us that eternal morning, when crag and chasm shall be no more, neither hill and valley, nor great unvintaged ocean; but all things shall arise, and shine in the light of the Father’s countenance, because itself is risen.</p>
<p>也许，那永恒的晨光就会这样降临人间，那时不再有险崖沟壑，不再有峰峦山谷，也不再有浩瀚无际的海洋；万物都将踊跃升腾，在造物主慈爱的光芒中生辉，因为太阳已经升起。</p>
<h2 id="028-To-Be-or-Not-to-Be-生存还是毁灭"><a href="#028-To-Be-or-Not-to-Be-生存还是毁灭" class="headerlink" title="028 To Be or Not to Be 生存还是毁灭"></a>028 To Be or Not to Be 生存还是毁灭</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/028%20quote-to-be-or-not-to-be-that-is-the-question-william-shakespeare-168147.jpg" alt=""></p>
<p>To be or not to be<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/28-to_be_or_not_to_be.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/28-to_be_or_not_to_be.mp3</a></p>
<p>Outside the Bible, these six words are the most famous in all the literature of the world. They were spoken by Hamlet when he was thinking aloud, and they are the most famous words in Shakespeare because Hamlet was speaking not only for himself but also for every thinking man and woman. <strong>To be or not to be, to live or not to live, to live richly and abundantly and eagerly, or to live dully and meanly and scarcely.</strong> A philosopher once wanted to know whether he was alive or not, which is a good question for everyone to put to himself occasionally. He answered it by saying: “I think, therefore am.”</p>
<p>“生存还是毁灭。”如果把《圣经》除外，这六个字便是整个世界文学中最有名的六个字了。这六个字是哈姆雷特一次喃喃自语时说的，而这六个字也就成了莎士比亚作品中最有名的几个字了，因为这里哈姆雷特不仅道出了他自己的心声，同时也代表了一切有思想的男男女女。是活还是不活——是要生活还是不要生活，是要生活得丰满充实，兴致勃勃，还是只是活得枯燥委琐，贫乏无味。一位哲人一次曾想弄清他自己是否是在活着，这个问题我们每个人也大可不时地问问我们自己。这位哲学家对此的答案是： “我思故我在。”</p>
<p>But the best definition of existence ever saw did another philosopher who said: “<strong>To be is to be in relations.</strong>“ If this true, then <strong>the more relations a living thing has, the more it is alive</strong>. To live abundantly means simply to increase the range and intensity of our relations. Unfortunately we are so constituted that we get to love our routine. But apart from our regular occupation how much are we alive? If you are interest-ed only in your regular occupation, you are alive only to that extent. So far as other things are concerned–poetry and prose, music, pictures, sports, unselfish friendships, politics, international affairs–you are dead.</p>
<p>但是关于生存我所见过的一条最好的定义却是另一位哲学家下的：“生活即是联系。”如果这话不假的话，那么一个有生命者的联系越多，它也就越有生气。所谓要活得丰富充实也即是要扩大和加强我们的各种联系。不幸的是，我们往往会因为天性不够丰厚而容易陷入自己的陈规旧套。试问除去我们的日常工作，我们的真正生活又有多少?如果你只是对你的日常工作才有兴趣，那你的生趣也就很有限了。至于在其它事物方面，比如诗歌、散文、音乐、美术、体育、无私的友谊、政治与国际事务，等等——你只是死人一个。</p>
<p>Contrariwise, it is true that every time you acquire a new interest–even more, a new accomplishment–you increase your power of life. <strong>No one who is deeply interested in a large variety of subjects can remain unhappy; the real pessimist is the person who has lost interest.</strong></p>
<p>但反过来说，每当你获得一种新的兴趣——甚至一项新的造诣——你就增长了你的生活本领。一个能对许许多多事物都深感兴趣的人是不可能总不愉快的，真正的悲观者只能是那些丧失兴趣的人。</p>
<p>Bacon said that a man dies as often as he loses a friend. But we gain new life by contacts, new friends. <strong>What is supremely true of living objects is only less true of ideas, which are also alive. Where your thoughts are, there will your live be also. If your thoughts are confined only to your business, only to your physical welfare, only to the narrow circle of the town in which you live, then you live in a narrow cir-conscribed life.</strong> But if you are interested in what is going on in China, then you are living in China~ if you’re interested in the characters of a good novel, then you are living with those highly interesting people, if you listen intently to fine music, you are away from your immediate surroundings and living in a world of passion and imagination.</p>
<p>培根曾讲过，一个人失去朋友即是死亡。但是凭着交往，凭着新朋，我们就能获得再生。这条对于活人可谓千真万确的道理在一定程度上也完全适用于人的思想，它们也都是活的。你的思想所在，你的生命便也在那里。如果你的思想不出你的业务范围，不出你的物质利益，不出你所在城镇的狭隘圈子，那么你的一生便也只是多方受着局限的狭隘的一生。但是如果你对当前中国那里所发生的种种感到兴趣，那么你便可说也活在中国；如果你对一本佳妙小说中的人物感到兴趣，你便是活在一批极有趣的人们中间；如果你能全神贯注地听点好的音乐，你就会超脱出你的周围环境而活在一个充满激情与想象的神奇世界之中。</p>
<p><strong>To be or not to be–to live intensely and richly, merely to exist, that depends on ourselves. Let widen and intensify our relations. While we live, let live!</strong></p>
<p>生存还是毁灭——活得热烈活得丰富，还是只是简单存在，这就全在我们自己。但愿我们都能不断扩展和增强我们的各种联系。只要一天我们活着，就要一天是在活着。</p>
<h2 id="029-Gettysburg-Address-葛底斯堡演说"><a href="#029-Gettysburg-Address-葛底斯堡演说" class="headerlink" title="029 Gettysburg Address 葛底斯堡演说"></a>029 Gettysburg Address 葛底斯堡演说</h2><p><img src="http://okkntqe2h.bkt.clouddn.com/029%20summary-gettysburg-address_cbf403733088963f.jpg" alt=""></p>
<p>Gettysburg Address<br><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/29-gettysburg_address.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/29-gettysburg_address.mp3</a></p>
<p>Fourscore and seven years ago, our fathers brought forth upon this continent a new nation, conceived in liberty and dedicated to the proposition that all men are created equal.</p>
<p>87年前，我们的先辈们在这个大陆上创立了一个新国家，它孕育于自由之中，奉行一切人生来平等的原则。</p>
<p>Now, we are engaged in a great civil war, testing whether that nation or any nation so conceived and so dedicated, can long endure. We are met on a great battlefield of that war. We have come to dedicate a portion of that field as a final resting-place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.</p>
<p>现在我们正从事一场伟大的内战，以考验这个国家，或者任何一个孕育于自由和奉行上述原则的国家是否能够长久存在下去。我们在这场战争中的一个伟大战场上集会。烈士们为使这个国家能够生存下去而献出了自己的生命，我们来到这里，是要把这个战场的一部分奉献给他们作为最后安息之所。我们这样做是完全应该而且是非常恰当的。</p>
<p>But, in a larger sense, we cannot dedicate, we cannot consecrate, we cannot hallow this ground. The brave men, living and dead, who struggled here, have consecrated it far above our poor power to add or detract. The world will little note nor long remember what we say here, but it can never forget what they did here. It is for us, the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion; that we here highly resolve that these dead shall not have died in vain; <strong>that this nation, under God, shall have a new birth of freedom; and that government of the people, by the people, and for the people, shall not perish from the earth.</strong></p>
<p>但是，从更广泛的意义上来说，这块土地我们不能够奉献，不能够圣化，不能够神化。那些曾在这里战斗过的勇士们，活着的和去世的，已经把这块土地圣化了，这远不是我们微薄的力量所能增减的。我们今天在这里所说的话，全世界不大会注意，也不会长久地记住，但勇士们在这里所做过的事，全世界却永远不会忘记。毋宁说，倒是我们这些还活着的人，应该在这里把自己奉献于勇士们已经如此崇高地向前推进但尚未完成的事业。倒是我们应该在这里把自己奉献于仍然留在我们面前的伟大任务——我们要从这些光荣的死者身上汲取更多的献身精神，来完成他们已经完全彻底为之献身的事业；我们要在这里下定最大的决心，不让这些死者白白牺牲；我们要使国家在上帝福佑下得到自由的新生，要使这个民有、民治、民享的政府永世长存。</p>
<h2 id="030-First-Inaugural-Address"><a href="#030-First-Inaugural-Address" class="headerlink" title="030 First Inaugural Address"></a>030 First Inaugural Address</h2><p>就职演讲(节选)</p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/030%20jfk-inauguration_31390.jpg" alt=""></p>
<p><a href="http://down010702.tingclass.net/lesson/shi0529/0001/1613/30-first_inaugural_address_.mp3" target="_blank" rel="external">http://down010702.tingclass.net/lesson/shi0529/0001/1613/30-first_inaugural_address_.mp3</a></p>
<p>We observe today not a victory of party, but a celebration of freedom, symbolizing an end, as well as a beginning; signifying renewal, as well as change. For I have sworn before you and Almighty God the same solemn oath our forebears prescribed nearly a century and three quarters ago.</p>
<p>今天我们庆祝的不是政党的胜利，而是自由的胜利。这象征着一个结束，也象征着一个开端;意味着延续也意味看变革。因为我已在你们和全能的上帝面前，宣读了我们的先辈在170多年前拟定的庄严誓言。</p>
<p>In your hands, my fellow citizens, more than in mine, will rest the final success or failure of our course. Since this country was founded, each generation of Americans has been summoned to give testimony to its national loyalty. The graves of young Americans who answered the call to service surround the globe.</p>
<p>公民们，我们方针的最终成败与其说掌握在我手中，不如说掌握在你们手中。自从合众国建立以来，每一代美国人都曾受到召唤去证明他们对国家的忠诚。响应召唤而献身的美国青年的坟墓遍及全球。</p>
<p>Now the trumpet summons us again, not as a call to bear arms, though arms we need; not as a call to battle, though embattled we are; but a call to bear the burden of a long twilight struggle, year in and year out, “rejoicing in hope; patient in tribulation”, a struggle against the common enemies of man: tyranny, poverty, disease, and war itself.</p>
<p>现在，号角已再次吹响—不是召唤我们拿起武器，虽然我们需要武器;不是召唤我们去作战，虽然我们严阵以待。它召唤我们为迎接黎明而肩负起漫长斗争的重任，年复一年，从希望中得到欢乐，在磨难中保持耐性，对付人类共同的敌人—专制、社团、疾病和战争本身。</p>
<p>Can we forge against these enemies a grand and global alliance, North and South, East and West, that can assure a more fruitful life for all mankind? Will you join in that historic effort?</p>
<p>为反对这些敌人，确保人类更为丰裕的生活，我们能够组成一个包括东西南北各方的全球大联盟吗?你们愿意参加这一历史性的努力吗?</p>
<p>In the long history of the world, only a few generations have been granted the role of defending freedom in its hour of maximum danger. I do not shrink from this responsibility. I welcome it. I do not believe that any of us would exchange places with any other people or any other generation. The energy, the faith, the devotion which we bring to this endeavor will light our country and all who serve it. And the glow from that fire can truly light the world.</p>
<p>在漫长的世界历史中，只有少数几代人在自由处于最危急的时刻被赋予保卫自由的责任。我不会推卸这一责任，我欢迎这一责任。我不相信我们中间有人想同其他人或其他时代的人交换位置。我们为这一努力所奉献的精力、信念和忠诚，将照亮我们的国家和所有为国效劳的人，而这火焰发出的光芒定能照亮全世界。</p>
<p><strong>And so, my fellow Americans, ask not what your country can do for you, ask what you can do for your country.</strong></p>
<p>因此，美国同胞们，不要问国家能为你们做些什么、而要问你们能为国家做些什么。</p>
<p>My fellow citizens of the world, <strong>ask not what America will do for you, but what together we can do for the freedom of man.</strong></p>
<p>全世界的公民们，不要问美国将为你们做些计人，而要问我们共同能为人类的自由做些什么。</p>
<p>Finally, whether you are citizens of America or citizens of the world, ask of us here the same high standards of strength and sacrifice which we ask of you. <strong>With a good conscience our only sure reward, with history the final judge of our deeds,</strong> let us go forth to lead the land we love, asking His blessing and His help, but knowing that here on earth, God’s work must truly be our own.</p>
<p>最后，不论你们是美国公民还是其他国家的公民，你们应要求我们献出我们同样要求于你们的高度力量和牺牲。问心无愧是我们唯一可靠的奖赏，历史是我们行动的最终裁判，让我们走向前去，引导我们所热爱的国家。我们祈求上帝的福佑和帮助，但我们知道，确切地说，上帝在尘世的工作必定是我们自己的工作。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/youthDev.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.tingclass.net/show-6613-109419-1.html?sid=AZGF5i1d9MuL8E57a0CHYor0&quot;&gt;Youth&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;001-青春&quot;&gt;&lt;a href=&quot;#001-青春&quot; class=&quot;headerlink&quot; title=&quot;001 青春&quot;&gt;&lt;/a&gt;001 青春&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://down010702.tingclass.net/lesson/shi0529/0001/1613/01-youth.mp3&quot;&gt;http://down010702.tingclass.net/lesson/shi0529/0001/1613/01-youth.mp3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Youth is not a time of life; it is a state of mind; it is not a matter of rosy cheeks, red lips and supple knees; it is a matter of the will, a quality of the imagination, a vigor of the emotions; it is the freshness of the deep springs of life.&lt;/p&gt;
&lt;p&gt;青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志，恢宏的想象，炙热的恋情；青春是生命的深泉在涌流。&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="English" scheme="http://ipcreator.me/tags/English/"/>
    
  </entry>
  
  <entry>
    <title>VirtualAPK 滴滴 Android 插件化的实践之路</title>
    <link href="http://ipcreator.me/2017/02/20/Program/Android/virtual-apk/"/>
    <id>http://ipcreator.me/2017/02/20/Program/Android/virtual-apk/</id>
    <published>2017-02-20T12:06:06.000Z</published>
    <updated>2017-02-21T12:38:49.253Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://mp.weixin.qq.com/s?__biz=MzIyNjcxODc3MA==&amp;mid=2247483684&amp;idx=1&amp;sn=c705424482f13941a9bcd6a5d6c24ed5&amp;chksm=e86d6479df1aed6f2f101a58ec7a5f839074b0209ce30c0f2d9d4e7bd2ac22937745b295c0d8#rd" target="_blank" rel="external">singwhatiwanna DDApp</a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在Android插件化技术日新月异的今天，开发并落地一款插件化框架到底是简单还是困难，这个问题不同人会有不同的答案。但是我相信，完成一个插件化框架的demo并不是多难的事，但是要开发一款完善的插件化框架却不是一件容易的事，尤其在国内，各大Rom厂商都对Android系统做了一定程度的定制，这进一步加剧了Android本身的碎片化问题。</p>
<p>滴滴出行在插件化上的探索起步较晚，由于滴滴业务发展较快，业务迭代占据了大量的时间，这使得我们在2016年才开始研究这方面的技术。经过半年的开发、测试、适配和线上验证，目前我们推出了一款比较完善的插件化框架：VirtualAPK。之所以现在推出来，是因为VirtualAPK在我们内部已经得到了很好的验证，我们在迭代过程中不断地做机型适配和细节特性的支持，目前已经达到一个非常稳定的状况，足以支撑滴滴部分乃至全部业务的动态发版需求。目前滴滴出行最新版本（v5.0.4）上面，小巴和接送机业务均为插件，大家可以去体验。</p>
<a id="more"></a>
<h2 id="插件化的现状"><a href="#插件化的现状" class="headerlink" title="插件化的现状"></a>插件化的现状</h2><p>到目前为止，业界已经有很多优秀的开源项目，比如早期的基于静态代理思想的DynamicLoadApk，随后的基于占坑思想的DynamicApk、Small，还有360手机助手的DroidPlugin。他们都是优秀的开源项目，他们很大程度上促进了国内插件化技术的发展。</p>
<p>尽管有如此多的优秀框架存在，但是兼容性问题仍然是制约插件化发展的一个难题。一款插件化框架，也许可以在一款手机上完美运行，但是在数以千万的设备上却总是容易存在这样那样的兼容性问题。我相信上线过插件化的工程师应该深有体会。滴滴为什么还要自研一款新的插件化框架？因为我们需要一款功能完备的、兼容性优秀的、适用于滴滴业务的插件化框架，目前市面上的开源不能满足我们的需求，所以我们必须重新造轮子，于是VirtualAPK诞生了。</p>
<h2 id="VirtualAPK的诞生"><a href="#VirtualAPK的诞生" class="headerlink" title="VirtualAPK的诞生"></a>VirtualAPK的诞生</h2><p>VirtualAPK是滴滴出行自研的一款优秀的插件化框架，主要有如下几个特性。</p>
<p>功能完备</p>
<p>支持几乎所有的Android特性；<br>四大组件方面<br>四大组件均不需要在宿主manifest中预注册，每个组件都有完整的生命周期。<br>Activity：支持显示和隐式调用，支持Activity的theme和LaunchMode，支持透明主题；<br>Service：支持显示和隐式调用，支持Service的start、stop、bind和unbind，并支持跨进程bind插件中的Service；<br>Receiver：支持静态注册和动态注册的Receiver；<br>ContentProvider：支持provider的所有操作，包括CRUD和call方法等，支持跨进程访问插件中的Provider。<br>自定义View：支持自定义View，支持自定义属性和style，支持动画；<br>PendingIntent：支持PendingIntent以及和其相关的Alarm、Notification和AppWidget；<br>支持插件Application以及插件manifest中的meta-data；<br>支持插件中的so。<br>优秀的兼容性</p>
<p>兼容市面上几乎所有的Android手机，这一点已经在滴滴出行客户端中得到验证；<br>资源方面适配小米、Vivo、Nubia等，对未知机型采用自适应适配方案；<br>极少的Binder Hook，目前仅仅hook了两个Binder：AMS和IContentProvider，Hook过程做了充分的兼容性适配；<br>插件运行逻辑和宿主隔离，确保框架的任何问题都不会影响宿主的正常运行。<br>入侵性极低</p>
<p>插件开发等同于原生开发，四大组件无需继承特定的基类；<br>精简的插件包，插件可以依赖宿主中的代码和资源，也可以不依赖；<br>插件的构建过程简单，通过Gradle插件来完成插件的构建，整个过程对开发者透明。</p>
<h2 id="VirtualAPK的工作过程"><a href="#VirtualAPK的工作过程" class="headerlink" title="VirtualAPK的工作过程"></a>VirtualAPK的工作过程</h2><p>VirtualAPK对插件没有额外的约束，原生的apk即可作为插件。插件工程编译生成apk后，即可通过宿主App加载，每个插件apk被加载后，都会在宿主中创建一个单独的LoadedPlugin对象。如下图所示，通过这些LoadedPlugin对象，VirtualAPK就可以管理插件并赋予插件新的意义，使其可以像手机中安装过的App一样运行。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlX2a8cELyOyZM3wjMvSu3kZIrwlF0ZUicLia6VviacLv68NRFOrC6FEcg0w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""><br>VirtualAPK的运行形态</p>
<p>我们计划赋予VirtualAPK两种工作形态，耦合形态和独立形态。目前VirtualAPK对耦合形态已经有了很好的支持，我们接下来将计划支持独立形态。<br>耦合形态<br>插件对宿主可以有代码或者资源的依赖，也可以没有依赖。这种模式下，插件中的类不能和宿主重复，资源id也不能和宿主冲突。这是VirtualAPK的默认形态，也是适用于大多数业务的形态。<br>独立形态<br>插件对宿主没有代码或者资源的依赖。这种模式下，插件和宿主没有任何关系，所以插件中的类和资源均可以和宿主重复。这种形态的主要作用是用于运行一些第三方apk。</p>
<p>如何使用</p>
<p>第一步： 初始化插件引擎</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlX43Yuk4KbNQjYuetsdSdgB8ubgIxnaxrMkkJpdTm1Owk8XlDdLBib0jw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>第二步：加载插件</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXd4cfRibnogsOkEBNkzamCBuzKR7Arw2kwt2bw3yyrRNX5zib7kmdC39Q/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>我们对上述加载过程进行了一些封装，通过如下方式即可异步地去加载一个插件。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXLtmuq4Tog3Bia0Mj29RUmnicx6c6ObWpIicgmibL0NDQib6icRjdttkvgcqw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>当插件入口被调用后，插件的后续逻辑均不需要宿主干预，均走原生的Android流程。<br>比如，在插件内部，如下代码将正确执行：<br><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXYmKLcqRy1uvSLTbOXsAEq4Cibb2hCRV35WojIiaX4j42PsjQ23QOfXhQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<h2 id="探究原理"><a href="#探究原理" class="headerlink" title="探究原理"></a>探究原理</h2><p>基本原理</p>
<p>合并宿主和插件的ClassLoader<br>需要注意的是，插件中的类不可以和宿主重复<br>合并插件和宿主的资源<br>重设插件资源的packageId，将插件资源和宿主资源合并<br>去除插件包对宿主的引用<br>构建时通过Gradle插件去除插件对宿主的代码以及资源的引用</p>
<p>四大组件的实现原理</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXK535TSRFy32jhI4V9JqcXRtco5XJDuaovGsIgH0B4c6yx2PtHDmeXw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>Activity<br>采用宿主manifest中占坑的方式来绕过系统校验，然后再加载真正的activity；<br>Service<br>动态代理AMS，拦截service相关的请求，将其中转给一个虚拟空间（Matrix）去处理，Matrix会接管系统的所有操作；<br>Receiver<br>将插件中静态注册的receiver重新注册一遍；<br>ContentProvider<br>动态代理IContentProvider，拦截provider相关的请求，将其中转给一个虚拟空间（Matrix）去处理，Matrix会接管系统的所有操作。</p>
<p>如下是VirtualAPK的整体结构图。<br><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXWUuGgyPG2ZicHDicgezMZgrL3TiaEvMYyf10t0c61qjzbKVDNnbZDFphA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<h2 id="填坑之路"><a href="#填坑之路" class="headerlink" title="填坑之路"></a>填坑之路</h2><p>在实践中我们遇到了很多很多的问题，比如机型适配、API版本适配、Binder hook的稳定性保证等问题，这里拿一个典型的资源适配问题来说明。</p>
<p>其实这是一个很无奈的问题，由于国内各大Rom厂商喜欢深度定制Android系统，所以就出现了这种适配问题。<br>正常情况下我们通过如下代码去创建插件的Resources对象：<br><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXt8B7OictQSCXgVUHnrWHmdSeqlxwzbicHOvTX5269YtcFicR7EP8XsKpQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>然后在Vivo手机上，竟然出现了如下的类型转换错误，看起来是Vivo自己派生了Resources的子类。<br><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXcYOXAGPZLqpLiaRGhpszf8Du7ooBdmGqOfKPSZl0DTVOebPGfOmNBqA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>于是反编译了下Vivo的framework代码，果不其然，在如下代码中进行了类型转换，所以在加载插件资源的时候就报错了。<br><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXWLQ6X5D9INZdzEuPJ4OeR6TjQtqMFnSqKqV5qibO75WSDCyfltQVasw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>为了解决这个问题，我们分析了VivoResources的代码实现，然后在创建插件资源的时候，采用了如下的代码。<br><img src="http://mmbiz.qpic.cn/mmbiz_png/1L1nVegtlrnWLvXiaict17k3Nbib0rIvwlXiaXMyPTTBpjyagSeg3JcpOv2icVjZqu5vev7Q30ib2TameqWCGIVbjGcA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>除了Vivo以外，有类似问题的还有MiUI、Nubia以及其它不知名的机型。而且在Vivo手机上，除了类型转换错误的问题，还有其他很坑的问题。</p>
<p>事实上我们还处理了很多其他的坑，这里无法一一说明，所以说如何保证插件化的稳定性是一件很有技术挑战的事情。</p>
<p>一些暂时不支持的特性</p>
<p>由于种种原因，VirtualAPK目前未能支持所有的Android的特性，如下是已知的几点。</p>
<p>不支持Activity的部分属性，比如process、configChanges等；<br>暂不支持overridePendingTransition(int enterAnim, int exitAnim)这种形式的转场动画；<br>插件中弹通知，不能使用插件中的资源，比如图片。<br>开源计划</p>
<p>我们的目标是打造一款功能完备的插件化框架，使得各个业务线都能以插件的形式集成，从而实现Android App的热更新能力。</p>
<p>目前VirtualAPK还有一些特性需要进一步完善，待完善后，将会有开源计划。我们期望VirtualAPK开源后，可以让其他App能够无缝集成，无需考虑细节实现和兼容性问题即可轻松拥有热更新能力。</p>
<p>请关注滴滴 App 开发技术微信公众号 DDApp，我们会在上面发布 VirtualAPK的最新进展，也将会把滴滴 iOS 和 Android 开发的干货技术文章分享给大家：<br><img src="http://mmbiz.qpic.cn/mmbiz_jpg/1L1nVegtlrnjM0ibYic8Qib9g7aSuSz8mJEvFBE9KnX1sSDcIjV2fpPJrlWgbyRfRJ3EGXqeACKBcLfSmOTncHqibw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIyNjcxODc3MA==&amp;amp;mid=2247483684&amp;amp;idx=1&amp;amp;sn=c705424482f13941a9bcd6a5d6c24ed5&amp;amp;chksm=e86d6479df1aed6f2f101a58ec7a5f839074b0209ce30c0f2d9d4e7bd2ac22937745b295c0d8#rd&quot;&gt;singwhatiwanna DDApp&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在Android插件化技术日新月异的今天，开发并落地一款插件化框架到底是简单还是困难，这个问题不同人会有不同的答案。但是我相信，完成一个插件化框架的demo并不是多难的事，但是要开发一款完善的插件化框架却不是一件容易的事，尤其在国内，各大Rom厂商都对Android系统做了一定程度的定制，这进一步加剧了Android本身的碎片化问题。&lt;/p&gt;
&lt;p&gt;滴滴出行在插件化上的探索起步较晚，由于滴滴业务发展较快，业务迭代占据了大量的时间，这使得我们在2016年才开始研究这方面的技术。经过半年的开发、测试、适配和线上验证，目前我们推出了一款比较完善的插件化框架：VirtualAPK。之所以现在推出来，是因为VirtualAPK在我们内部已经得到了很好的验证，我们在迭代过程中不断地做机型适配和细节特性的支持，目前已经达到一个非常稳定的状况，足以支撑滴滴部分乃至全部业务的动态发版需求。目前滴滴出行最新版本（v5.0.4）上面，小巴和接送机业务均为插件，大家可以去体验。&lt;/p&gt;
    
    </summary>
    
      <category term="个人" scheme="http://ipcreator.me/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="VirtualAPK" scheme="http://ipcreator.me/tags/VirtualAPK/"/>
    
  </entry>
  
  <entry>
    <title>Coding心得</title>
    <link href="http://ipcreator.me/2017/02/20/MyView/Diary/my-views-of-learning-program/"/>
    <id>http://ipcreator.me/2017/02/20/MyView/Diary/my-views-of-learning-program/</id>
    <published>2017-02-20T03:28:06.000Z</published>
    <updated>2017-02-28T23:19:40.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://okkntqe2h.bkt.clouddn.com/Hello%20World%20Program%20in%20Eight%20Different%20Popular%20Programming%20Languages.jpg" alt=""></p>
<p>作者：<a href="http://ipcreator.me">IPCreator</a></p>
<h2 id="Skill-is-acquired-through-correct-and-repetitive-practice-and-practice-makes-perfect"><a href="#Skill-is-acquired-through-correct-and-repetitive-practice-and-practice-makes-perfect" class="headerlink" title="Skill is acquired through correct and repetitive practice, and practice makes perfect."></a>Skill is acquired through correct and repetitive practice, and practice makes perfect.</h2><blockquote>
<ol>
<li>不放过任何一个err，每成功解决一个error就意味着自己的经验库又append一个案例；</li>
<li>理不顺想不通的时候，成长的时刻到了，坚持、坚持再坚持，成就感与困难度成正比；</li>
<li>官网+stackflow+github+google还解决不了的时候，暂时放一放，持续关注思考，直至惊喜发生；</li>
<li>换位常识思考，如果你是设计者，你会怎么设计，为什么这样设计？</li>
<li>尽量不要复制粘贴，要逐字阅读，逐个输入，对开发而言，thinking与coding相辅相成，缺一不可；</li>
<li>知其然还要知其所以然，不要浮于表面，浅尝则止，运行/部署成功不等于你掌握了每个环节的原理；</li>
<li>慢工出细活，慢就是快，防火胜于救火，先打好基础（概念、框架、原理等），高手都重视内功；</li>
<li>专而精，精而深，通过一个突破口（语言、框架、平台），抓住本质量（通俗易懂，能重建和迁移），再融会贯通，一通百通；</li>
<li>coding只是解决问题的一种方式，不要重复发明轮子，要open和share，不要敝扫自珍，因为每个人都能掌握相应的技能，只是时间早晚而已；</li>
<li>创新整合也是一种行之有效的商业途径，不要为了技术而技术，为了创新而创新，商业思维很重要；</li>
<li>从战略上来说，我们大部分都只是用别人开发出来的工具（类似于厨具）开发产品（类似于菜品）而已；</li>
<li>阅读代码（类似于品尝他人菜品）、模仿创新（借鉴改造）、原创分享（晋级高级厨师）；</li>
<li>道理都懂，为什么难以坚持？没有尝到甜头或者没有吃到苦头，又或者只是懒惰；</li>
<li>35岁以后能否再编程？取决于：以前的编程模式是否健康可持续？是否为自己实现创新产品和服务(而不只是为了挣钱)；</li>
<li>程序员人生的梦想和快乐简单易实现，成为其中一员才能真正感同身受…</li>
<li>有劲、有趣和有用，正常可持续，Kick-off &amp; Keep-going</li>
</ol>
</blockquote>
 <a id="more"></a>
<blockquote>
<p>Dreams cann’t measured by S/A/B/C/D degree、money and position.<br>Great mind thinks alike.<br>RTFC Read the fucking code.<br>RTFM Read the fucking manual.<br>STFW Search the fucking Web.<br>Read  the article word by word.<br>Code can talk, let the code talk.<br>A good name tells the truth.<br>Keep code  simple and reusable.<br>Keep hungry, Keep foolish.<br>Keep healthy and sustainable.<br>Less  is  more, slow is quick.<br>Don’t Reinvent the Wheel.<br>Use is the best way of learning English , so is programming.<br>Master the essence of  things, including languages (English/C/C++/JAVA/PYTHON/JS…)，<br>platforms(Arena/Android/Tensor…)，tools(gcc/make/gradle/git…),etc<br>We make good habits first, then habits make us.<br>Success is a habit, so is happiness.</p>
</blockquote>
<h2 id="The-true-joy-of-life-is-the-trip"><a href="#The-true-joy-of-life-is-the-trip" class="headerlink" title="The true joy of life is the trip."></a>The true joy of life is the trip.</h2><h2 id="The-station-is-only-a-dream-It-constantly-outdistances-us"><a href="#The-station-is-only-a-dream-It-constantly-outdistances-us" class="headerlink" title="The station is only a dream. It constantly outdistances us."></a>The station is only a dream. It constantly outdistances us.</h2><blockquote>
<p>Happy is a duty.</p>
</blockquote>
<ul>
<li><strong>做自己，过自己的人生，为自己的梦想而拼搏</strong></li>
<li><strong>任何选择都会有风险，不选择就是最大的风险</strong></li>
<li><strong>任何选择都会有得失，值不值在于在于如何衡量人生</strong></li>
<li><strong>有得必有失，反之亦然，有失必有得，得失平衡</strong></li>
<li><strong>快不快乐，首要是：弄清楚自己想要什么</strong></li>
<li><strong>充不充实，关键是：是否朝着既定目标前行</strong></li>
<li><strong>成与不成，秘诀是：自知自胜、贵在坚持</strong></li>
<li><strong>幸不幸福，基础是：健康、家人、事业</strong></li>
<li><strong>先让自己变得有价值，做出有价值的产品，再谈其它</strong></li>
<li><strong>先提高审美和技能，再欣赏、模仿和创新</strong></li>
</ul>
<blockquote>
<p><strong>很多恐惧和担忧来自想象，源自眼界/无知和缺乏目标/信念/经验/技能…</strong><br>Success is a habit, so do failure. The way leading to success is commitment.<br>-Q:这么做有用吗？ 这么坚持有意义吗？…<br>-A:你做了没有？坚持了没有？为什么没用？为什么没坚持？…<br><strong>成长的人从自身找原因，为成功找方法</strong><br><strong>逃避的人从外界找理由，为失败找借口</strong></p>
</blockquote>
<h2 id="Hello-World-Program-in-Eight-Different-Popular-Programming-Languages"><a href="#Hello-World-Program-in-Eight-Different-Popular-Programming-Languages" class="headerlink" title="Hello World Program in Eight Different Popular Programming Languages"></a><a href="http://www.thecrazyprogrammer.com/2014/07/hello-world-program-in-eight-different-popular-programming-languages.html" target="_blank" rel="external">Hello World Program in Eight Different Popular Programming Languages</a></h2><p>This fact is true that Hello World program is the first program that a programmer writes when he/she start learning a new programming language. Today I thought that I should share the hello world program in different languages. A video is also added for easy understanding of the programs. Let’s take a look on these programs.</p>
<p><strong>Hello World Program in Java</strong></p>
<figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">HelloWorld</span></div><div class="line">&#123;  </div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span>(<span class="params">String args[]</span>)</span></div><div class="line">        &#123;</div><div class="line">           System.<span class="keyword">out</span>.println(“Hello World”);</div><div class="line">        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>Hello World Program in C</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line">main()</div><div class="line">&#123;</div><div class="line">    <span class="built_in">printf</span>(“Hello World”);</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>Hello World Program in C++</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; “Hello, world”;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>Hello World Program in Javascript</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></div><div class="line"><span class="built_in">window</span>.onload = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span></div><div class="line">&#123;</div><div class="line">     <span class="built_in">document</span>.getElementById(‘result’).innerHTML = “Hello World”;</div><div class="line">&#125;</div><div class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">”result</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p><strong>Hello World Program in HTML</strong><br><code>&lt;p&gt;Hello World&lt;/p&gt;</code></p>
<p><strong>Hello World Program in Python</strong><br><code>print “Hello World</code></p>
<p><strong>Hello World Program in Perl</strong><br><code>print “Hello World</code></p>
<p><strong>Hello World Program in Ruby</strong><br><code>puts “Hello World</code></p>
<p>Source: <a href="http://blog.learntoprogram.tv/hello-world-eight-languages/" target="_blank" rel="external">http://blog.learntoprogram.tv/hello-world-eight-languages/</a></p>
<h1 id="太用力的人跑不远"><a href="#太用力的人跑不远" class="headerlink" title="太用力的人跑不远"></a><a href="http://blog.csdn.net/jdsjlzx/article/details/51034003" target="_blank" rel="external">太用力的人跑不远</a></h1><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>有阶段的自己，会用蛮力去学习一些东西，就是这东西不管是否适合目前自己的知识体系， 觉得学了之后会更牛逼就去学，但是这样的东西往往学了记不住。 学习的过程越用力反而显得越吃力， 太吃力的事情，自然就无法有恒心， 这就是很多人会觉得自己做事总是无法持之以恒的原因。</p>
<blockquote>
<p>努力不应该是某种需要被时常觉知的东西，意志力是短期内会用完的精神能量。<br>真正坚持到最后的人靠的不是激情，而是恰到好处的喜欢和投入。</p>
</blockquote>
<p>太用力的人更容易产生期望落差，更不愿接受自己找错了方向的事实——没有什么比这样的“失落”更能让人心寒的了，太用力的人大多都因心累而倒在了半途中。</p>
<p>精神上的用力并不会让你跑得更快，但是精神上的疲惫却可以让你停下。</p>
<p>人越用力，就会越想要得到及时的良好刺激。越用力的人对于正刺激的需求就越高，越不能忍受暂时的负反馈。遗憾的是，人生常常是没有下文的考卷，这种刺激来得太慢、太不稳定。</p>
<blockquote>
<p>真正的坚持归于平静，靠的是温和的发力，而不是时时刻刻的刺激。</p>
<p>太用力的人增加了执行的功耗。纠结，是太用力的一种表现，造成内部的运转处于空转的状态——意识与行动的主观脱节；从心所欲，就是把运转效率最大化后的结果——所想即所为。执行阶段最大的敌人，是纠结，是埋怨，是内心的冲突——太用力，就是心理额外动作太多。想好之后就只管去做。</p>
</blockquote>
<p>我一直告诫自己不要用力过猛，以保持自己对困难的顿感和不顺的接受程度。<br>短期的过度用力极容易造成身体和心理上的挫伤。哪怕你在做的事情非常重要，也要保证基本的休息和放松。</p>
<p>不论是以后的工作还是将来的创业，都要保持一颗平常心。你需要更多的“寸劲”而不是“用力感”。在找到受力点“all in”之前，一切都要顺势而行，自然随和。</p>
<p>人在学习的过程会经历一系列的过程，先是笨拙期，再是熟练期——这两个过程他虽然能运用出技能，但是头脑中仍然能感受到使用时的提取感。这两个阶段都需要用力，但是用力的程度却大幅度减小。</p>
<p>技能掌握的最后阶段是运用自如期，就是张三丰把太极拳的形态全部都忘了的阶段。这个时候头脑中已经能下意识地去进行活动，达到了能耗最低的理想阶段。</p>
<p>从用力感，到毫无感觉，是一种技能掌握上的纯熟。年轻的时候太认真是件好事，或许只有用力过了，才能体会从心所欲、顺其自然的难得。</p>
<h2 id="IT人员怎么用力"><a href="#IT人员怎么用力" class="headerlink" title="IT人员怎么用力"></a>IT人员怎么用力</h2><p>总有在校的学生问我现在 X,Y,Z… 技术很火热，应该学哪个？ 我看他列出的那些准备学习的选项中，其实前景和热门程度都差不多。 这让他陷入了选择焦虑症，不管做什么决定都怕「一失足成千古恨」。</p>
<p>对技术发展趋势关心是好事，就像之前那篇「不要总是选择困难模式」里面说的那样。 但是其实在「不要总是选择困难模式」里面忽略了很重要的一点，就是你个人的兴趣。 比如有的人对苹果的东西有天生的热爱，所以选择「iOS开发」对他来说就更容易做好。 尽可能选择会让自己 Enjoy 的技术方向，路还很长，不享受过程的话容易半途而废。</p>
<h2 id="太用力的人跑不远-1"><a href="#太用力的人跑不远-1" class="headerlink" title="太用力的人跑不远"></a>太用力的人跑不远</h2><p>记得之前本科的时候喜欢和舍友一起打Dota，打Dota开局之前一般要等人齐， 等人的这段时间我有时候会切出来写写代码，叫舍友开局了告诉我一声。 然后别人看到我在打Dota间隙都在写代码，就觉得我有多努力多努力，给人了一种非常「刻苦」的印象。 以至于上次和一个本科同学吃饭他还说起这个事情，觉得我能做到这样非常「牛逼」。</p>
<p>但是其实这样的事情，如果对于真的对写代码有经历过热爱的人，是不会觉得有多么刻苦的事情。 这是自然而然的事情，甚至其实有些代码，那种满足好奇心的快感，是比打游戏有意思的多， 是件很Enjoy的事情，而不是所谓的「刻苦」。</p>
<h2 id="就像跑步，「太用力的人跑不远」。"><a href="#就像跑步，「太用力的人跑不远」。" class="headerlink" title="就像跑步，「太用力的人跑不远」。"></a>就像跑步，「太用力的人跑不远」。</h2><p>不要用蛮力去学编程</p>
<p>记得当年初学 C++ 的同学，听别人说 C++ 很基础也很重要的一个知识点就是STL， 然后听说要学好 STL 就应该去看看侯捷的「STL源码剖析」。 然后就买了书硬啃，然后没啃几天就放弃了，觉得太讳莫如深了没法理解。</p>
<p>但是如果换个学习的方式， 先假设现在没有STL这个标准库， 让你用已有的C++语法知识去自己写一个仿造STL标准库的功能， 哪怕是最最简单的 vector 。 你在编写的时候就会自然而然得体会到内存动态扩展的一些缺点和潜在的坑。 会知道为什么适当使用 reserve 和 swap 能非常明显的提高性能。</p>
<p>然后在自己思考的过程中会提出很多相关的疑惑， 带着疑惑再去翻看「STL源码剖析」， 就会让你对一个个数据结构恍然大悟知根知底。 自然而然你的看书体验会非常的 Enjoy， 而不是觉得苦涩难咽。</p>
<p><strong>编程和求知本身是一件愉悦身心的事情， 如果只是为了高薪，而用蛮力去写代码，只会让自己疲惫不堪。</strong></p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>希望对在学习编程的路上很挣扎的朋友有所帮助。 毕竟工作是生活的很大一部分， 如果工作不开心，生活怎么办。</p>
<h1 id="不是人人都懂的学习要点"><a href="#不是人人都懂的学习要点" class="headerlink" title="不是人人都懂的学习要点"></a>不是人人都懂的学习要点</h1><p>学习是一种基础性的能力。然而，“吾生也有涯，而知也无涯。”，如果学习不注意方法，则会“以有涯随无涯，殆矣”。</p>
<h2 id="一．学习也是一种能力"><a href="#一．学习也是一种能力" class="headerlink" title="一．学习也是一种能力"></a>一．学习也是一种能力</h2><p>看到这个标题，有人会说：“学习，谁不会？”的确，学习就像吃饭睡觉一样，是人的一种本能，人人都有学习的能力。我们在刚出生的时候，什么也不知道，是一张真正的白纸，我们靠学习的本能，学会了走路、说话、穿衣服…后来，我们上学了，老师把书本上的知识一点一点灌输到我们的脑子里，我们掌握的知识越来越多，与此同时，我们学习能力却好像越来越差了，习惯了被别人喂饱，似乎忘记了怎么来喂自己了。</p>
<p>学习本来只是一种本能，算不上什么能力，然而，经过二十多年的不断学习，学习反而成为了一种真正的能力，因为我们慢慢失去了它，它就更显得珍贵。</p>
<p>在学校里我们基本上被动式学习，然而走出了象牙塔之后，不会再有人对你负责，不会有人主动教你，我们需要主动的学习。所谓的学习能力，其实就是自主学习的能力。</p>
<p>几年前，曾有一本风靡管理界的书，叫《第五项修炼》，这本书倡导建立学习型组织，因为从长远来看，一个组织唯一可持续的竞争优秀，就是比竞争对手更快更好的学习能力。</p>
<p>一个公司如此，一个人又何尝不是如此？众所周知现在是一个知识爆炸的时候代，知识更新非常快。据说，一个大学毕业生所学习到的知识，在毕业之后的2年内，有效的不过剩下5%，更何况我们的学校与社会需要严重脱轨。我们赖以立足的，不在于我们现在掌握了多少知识，而是我们有多强的学习能力！</p>
<p>学习不但是一种能力，而且是一种至关重要的能力，而这种能力的核心，就是学习的方法和心态。</p>
<h2 id="二．买书是最划算的投资"><a href="#二．买书是最划算的投资" class="headerlink" title="二．买书是最划算的投资"></a>二．买书是最划算的投资</h2><p>古人云：“书中自有黄金屋，书中自有颜如玉。”这说明先贤们早就认识到，买书是最划算的投资了。</p>
<p>当我刚出道的时候，拿着非常微薄的工资，有一次我向主管抱怨道：“现在的书真贵啊，这点工资连饭都吃不起，更别说买书了！”主管对我说：“不要吝惜买书的钱，宁可忍着不吃饭，也不要忍着不买书，因为买书是回报率的最高的投资了。”</p>
<p>主管的话让我非常震动。后来，我看到喜欢的书时，再有没有手软过。我不断的学习，开发能力也不断的提高，工资水平也获得了大幅度的提高。一年后，我一个月工资的涨幅，就足够买两年的书了。你说，还有比这更划算的投资吗?</p>
<p>一本书，哪怕只有一页纸是有用的，它将所产生的潜在价值，也会远远超过书本身的价格。当然，书不在多，能踏踏实实消化掉一本好书，可能比泛泛而读10本普通书，要更有价值得多。</p>
<h2 id="三．多读经典书"><a href="#三．多读经典书" class="headerlink" title="三．多读经典书"></a>三．多读经典书</h2><p>十年前，我刚进入IT行业的时候，真是求知渴，每星期都要往购书中心跑，可惜的是，那时给程序员看的书不像现在这么多，高质量的书就更少了。当时我印象中比较经典的书籍就是《Windows程序设计》、《COM本质论》、《Java编程思想》，还有就是谭浩强的《C语言程序设计》。其它充斥书架的，就是类似于《21天精通XXX》、《XXX从入门到精通》、《XX宝典》这样的书籍。</p>
<p>回首往昔，令我比较郁闷的一件事就是在我最有学习动力的时候，看的高质量的书籍太少，就好像是在长身体的时候，天天吃的是没营养的泡面。当然，这跟没有人指导也有很大的关系，独自一个人学习，让我走了很多的弯路。</p>
<p>软件开发方面的书籍，我大致将其分为三类：</p>
<p>（1）浅显的入门类书籍。</p>
<p>这类书的标题往往是《XX天精通XXX》、《XXX从入门到精通》、《XX开发实战》等，这类书往往从软件的安装讲起，喜欢翻译帮助文件。有人批评这类书为烂书、毫无价值，这并不公平。至少我本人，也曾从这些书中学到一些东西。即使是21天系列书，也有适合看的人群，只不过，它一般也就只能看21天而已，过后就可以扔到垃圾堆。这类书只适于还没有入门的初学者，从中学到一些入门的招式。这种书在刚起步的时候一般买上一本就可以了。如果你善于使用搜索引擎，这一本书也可以省了。</p>
<p>（2）国内外高手写的实战类书籍。</p>
<p>这类书实战性很强，把技术及原理讲得很透彻。比如《windows环境下32位汇编语言程序设计》、《深入解析MFC》、《Delphi深度探索》、《深入浅出WPF》、《深入剖析Asp.NET组件设计》等。以前这类书都是从国外翻译或从台湾引进，现在国内高手越来越多，出自国内作者的也越来越多。这类书如果在你学习的每个方向看个两三本，并且通过实践消化掉，那么毫无疑问，你会成为一个优秀的程序员。</p>
<p>（3）国外大牛写的、揭露本质、有丰富思想的书。</p>
<p>这类书就是所谓的经典书了，例如《代码大全》、《编程珠玑》、《设计模式》、《重构》、《代码整洁之道》等。经典书就像一个有深度、有思想的朋友，他会给你启发、每次阅读都会有新的收获，这类书具有真正的收藏价值。看经典书永远是正确的选择，它绝不会浪费你的时间，因为经典书是无数人沙里淘金、帮你挑选过的结果。</p>
<p>然而，阅读这类书并不是一件容易的事情，读者需要有丰富的开发经验，才能与作者产生共鸣。真正能消化经典书的人其实不多，这就好像饮酒，一个新手无论如何也品不出葡萄美酒的醇香。在酒桌上，人人都把杯中酒一饮而尽，当有人点评“这个酒不错”的时候，我只能无奈的苦笑一番，真的是甘苦自知。</p>
<p>如果一本经典书你看得很辛苦，很有可能就是因为你功力未够，这种情况下不要着急，慢点来，不妨先将其先束之高阁，多看看第二类实战型书籍，过一段时间再回头来看，也许你会有新的惊喜。</p>
<h2 id="四．不要在上班时间看书"><a href="#四．不要在上班时间看书" class="headerlink" title="四．不要在上班时间看书"></a>四．不要在上班时间看书</h2><p>一个善于学习的人，首先要善于利用一切时间来学习。不知是伟大的雷锋叔叔还是鲁迅爷爷曾经说过：“时间就像海绵里的水，只要愿挤，总还是有的。”然而，当我们从上班时间中挤时间学习时，就千万要注意了，不要在上班时间看书！</p>
<p>上班时间看书不但是一件很敏感的事情，而且非常吸引眼球，很快就会引起周遭的不爽。首先老板心里不爽，他想：“我给你钱是让你来工作的，不是来学习的！”；其次同事们也不爽：“我们工作都做不完，瞧，这小子真闲哪！”用不了多久，你就会成为被众人排斥的异类。</p>
<p> 当然，你可能会说，“我工作已经做完了，经理没有安排，当然可以学习了”，其实不然。你完成了一件事情，不等于所有的事情都完成了。一个优秀的员工，应该是主动要工作，而不是被动的等工作。工作完成以后，你至少还可以：</p>
<p>（1）主动汇报给你的经理，请他来检查你的成果，并安排新的任务；<br>（2）如果公司这一段时间确实比较闲，没有什么具体的任务，可以进行代码重构、优化；<br>（3）你还可以主动请缨，承担额外的工作或更艰巨的任务。<br>（4）如果一定要学习，也只能对着电脑屏幕来学习，纸质书最多只能拿来翻阅一下，而不能一直捧着，以免影响到其他人的情绪。</p>
<h2 id="五、只学习与工作相关的东西"><a href="#五、只学习与工作相关的东西" class="headerlink" title="五、只学习与工作相关的东西"></a>五、只学习与工作相关的东西</h2><p>我曾发现不少程序员在学习方面找不到方向，一会学学C#，一会学学Java，看了最新的编程语言排行榜，又觉得该学C++。这样左抓抓，右挠挠，只会让你觉得更痒。</p>
<p>学习最忌三心二意。俗话说：“伤其十指不如断其一指”，每门都学一点，还不如专心学好一个方向。这个道理谁都懂，可是又该学哪个方向呢？难道只能跟着感觉走吗？</p>
<p>不！最实际的方向，应该跟着工作走，工作需要什么，我们就学什么，把工作需要的技能熟练掌握。我们为什么要学习和工作弱相关的东西呢？是为了转行或跳槽吗？可是，如果我们连现在本职工作都不能做好，又怎么能保证到新的岗位、用新学的技能就可以做得更好呢？</p>
<p>学习与工作需要的的东西，有很多好处：</p>
<p>首先，可以集中精力，在某一方面钻研得更加深入。所谓“百招会不如一招绝”，有了绝招，你还怕不能在“武林”立足吗？《天龙八部》中的慕容复武功博学无比，最后还不是被只会一招六脉神剑的段誉打得落花流水？</p>
<p>其次，可以学得更快、更深入，因为学习更具有针对性，而且可以立即在工作中运用，可以马上检验出学习的效果，对存在的问题可以进行深入的研究，因此掌握的知识也会更加的牢固。</p>
<p>第三，学习与工作结合在一起，工作时间也就成了学习时间，这样突破了三个8小时的限制。有人说，我们每天所有拥有的时间可以分为三个8小时，工作8小时，睡觉8小时，另外还有8小时自己可以自由支配的时间。工作和睡觉的两个8小时大家都一样，决定人生高度的是另外这个8小时。当我们把学习的焦点放到与工作相关的知识上时，工作时间中的很大一部分，同时也就成了宝贵的学习时间，这真是一举两得的美事啊。</p>
<h2 id="六．织网式的学习"><a href="#六．织网式的学习" class="headerlink" title="六．织网式的学习"></a>六．织网式的学习</h2><p>知识的广度和深度都很重要。作为一个程序员，深入把握技术细节，是写出优质代码的保证。但对于一个项目经理而言，知识的广度更显重要。项目中碰到的问题往往是综合性的，只有具有广博的知识，才能快速的对问题进行分析和定位。在程序员通往项目经理的道路上，我们必须有意识的扩大自己的知识面，形成更完善的知识体系。</p>
<p>每个人的知识体系就好比是一张网，我们学习其实就是要织这样一张网。 我曾看过渔网的编织过程，渔网虽大，也是一个结点起步，一个点一个点的编出来的，编织的过程中，始终只有一根主线。</p>
<p>学习又何尝不是这样，知识体系的大网也是由许多小的结点组成，要结这样一张网，只能由一个点起步。牵住一条主线，织出一个个的点，由点带出面，最后才能形成这张大网。</p>
<p>我曾经编写过一个网络信息采集软件，这个软件可以从具有列表页网站中按字段设置采集信息，支持自定义字段、页面多级关联、下载附件、支持多种数据库、可视化定义等特性。刚开始时，觉得这个软件也是一个比较大的功能点而已，后来发现这个不起眼的功能关联着大量的知识点，在开发过程中， 我顺藤摸瓜，各个击破，对很多知识点进行了细致的学习研究，软件开发完成后，个人的知识体系网也进一步得到了补充和完善。</p>
<p><img src="http://images.cnblogs.com/cnblogs_com/watsonyin/416065/%E7%9F%A5%E8%AF%86%E7%BD%91.png" alt=""><br>图1 由知识点形成知识网</p>
<h2 id="七．问题是最好的学习机会"><a href="#七．问题是最好的学习机会" class="headerlink" title="七．问题是最好的学习机会"></a>七．问题是最好的学习机会</h2><p>日本经营之神松下幸之助曾经说过：“工作就是不断发现问题、分析问题、最终解决问题的一个过程，晋升之门将永远为那些随时解决问题的人敞开着。”可见，工作过程中有问题是正常，没有问题那才是真正的问题。在发生问题能时，能勇于面对问题、解决问题的人，才是公司真正的核心骨干。</p>
<p>现实中，很多人总是千方百计回避问题，当上司安排一项艰巨的任务时，也是想尽办法推托。殊不知，对于个人而言，其实问题是最好的学习机会。往往那些愿意接受困难工作的人，能力会变得越来越强，那就是因为他们在克服困难的过程中取得了巨大的进步。</p>
<p>有一次，一位项目经理对我说：“有一个问题，客户有一台HP服务器要装磁盘阵列，没人会做，怎么办啊？”</p>
<p>“可以学啊，没有人愿意去吗？”</p>
<p>“我都问了，没人想去。”</p>
<p>“哦，正好明天我有时间，我也没装过磁盘阵列，那我明天去学着弄一下。”我说的是真心话。</p>
<p>第二天早上，当我准备出发时，项目经理告诉我不用我去了，因为项目组好几个同事都想去“学着弄一下”。</p>
<p>结果服务器很快就装好了，远远没有之前大家想像的那么困难嘛。更重要的是，在解决这个问题的过程中，大家都学会了怎么装磁盘阵列。</p>
<p><strong>碰到困难时，迎难而上吧，千万不要拒绝这个最好的学习机会！</strong></p>
<h2 id="八．经常思考总结"><a href="#八．经常思考总结" class="headerlink" title="八．经常思考总结"></a>八．经常思考总结</h2><p>子曰：“学而不思则罔”。只学习不思考，就会迷惑，难以把握事情的本质。这就好比一个学武之人，只习得其形，而未得其神，难以成为真正的高手。</p>
<p>一个程序员从入门，到成为高手的过程中，往往要经过几次顿悟。顿悟会让你跳出知识的丛林，一切豁然开朗，仿佛打通了全身的奇经八脉一般奇妙。记得我有一次，顿悟到了一个很简单的结论：“原来高级编程语言中的类库是封装了Windows API来实现的。”后来碰到一些自带类库无法实现的功能时，我就会想到，其实可以通过调用Windows API来实现。利用这个思路，我解决了一些看起来很难的问题，得到老板的赏识，从而很快获得提升。</p>
<p>顿悟非常可贵，然而它不是随便发生的，而是经过一次次苦苦思索之后、灵光闪现的结果。思考的过程，其实就是将外在的知识内化为自己的知识的过程，而顿悟，则是批量的实现这种内化，将无数个知识点连接在一起，达到融会贯通的境界。</p>
<h2 id="九、克服“高原现象”"><a href="#九、克服“高原现象”" class="headerlink" title="九、克服“高原现象”"></a>九、克服“高原现象”</h2><p>爱学习的人都会有这样的经历，学习持续了一段时间之后，往往会有一个瓶颈期，长时间似乎很久没有什么进步，于是内心非常着急。</p>
<p>这种情况实际上这是由人的学习规律决定的一种“高原现象”。据研究，学习者在刚开始进步快，随后有一个明显的或长或短的进步停顿期，后期进步慢，中间的停顿期叫高原期。</p>
<p> <img src="http://images.cnblogs.com/cnblogs_com/watsonyin/416065/%E9%AB%98%E5%8E%9F%E6%9C%9F.png" alt=""><br>图2 技能学习练习曲线</p>
<p>在我看来，<strong>高原期实质是一个消化期，由于前期的学习积累了太多的知识点，这些知识点在大脑中乱作一团，还没有形成一个知识体系。这时需要一定的时间来消化它，将它融会贯通，经常思考总结可以快速帮你跨过高原期。</strong></p>
<p>在处于高原期的时候，还可以换一个相关的方向来学习，例如编程语言学不下去了，你可以学习一下设计模式，设计模式也学不下去了，再换成数据库。通过学习这些相关的知识，不但补齐了知识体系中的短板，而且各个知识点之间可以互相启发，帮助你实现顿悟，跨过高原期。</p>
<h2 id="十、学习要有好心态"><a href="#十、学习要有好心态" class="headerlink" title="十、学习要有好心态"></a>十、学习要有好心态</h2><p>（1）学习要静心</p>
<p>急于求成是学习过程中普遍存在的一种心态。这可以理解，毕竟作为一个程序员，要学的东西实在太多了，而社会又是那样的浮躁，让人觉得一切都是那样的不安全、不确定，似乎只有学得快一点，才能跟上社会的脚步。</p>
<p>可是“欲速则不达”，想快快的学，往往会形成东一榔头、西一棒槌的学习方式，每一个点都没有吃透。心沉不下去，知识也会沉不下去。要想成为真正的高手，只能静下心来，一步一个脚印的攀登。</p>
<p>（2）学习是一个持续一生的过程</p>
<p>人生的过程，就是一个自我完善过程。</p>
<p>孔子曾经说：“吾十有五而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲，不逾矩。”可见孔子也不是天生的圣人，也在不停的学习、进步，从“志于学”到最后“从心所欲，不逾矩”，孔子一共花了55年的时间。</p>
<p>作为一个程序员，更是需要不断更新自己的知识。我们所知道的东西，就像一个白色的圆圈，圈外则是黑暗的未知的世界。当圆圈越大，所接触到的黑暗部分就越多。我们只有不停的学习，打破更多的黑暗，找到更多光明。</p>
<p>（3）保持饥饿，保持愚蠢</p>
<p>看了《乔布斯传》之后，我最喜欢的一句话是“求知若饥，虚心若愚”（Stay Hungry,Stay Foolish），其实我更喜欢它更原生态的翻译“保持饥饿，保持愚蠢”。我们只有认识到自己还很饥饿和愚蠢，才会像没吃饱一样，由衷的需要学习、爱上学习。</p>
<p> 当然，知易行难，知行合一才是学习的最高境界。我也始终是一个学习者，一直在路上。</p>
<h1 id="关于App程序员泡沫"><a href="#关于App程序员泡沫" class="headerlink" title="关于App程序员泡沫"></a><a href="http://blog.csdn.net/itachi85/article/details/50364043" target="_blank" rel="external">关于App程序员泡沫</a></h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p> 做开发快七年了，对于程序员，外行人总有着数不完的讽刺和误解，但是我都懒得去解释，代码搬运工人也好，民工也罢，随他们去说吧。但是网上最近流传的程序员泡沫,尤其是APP程序员泡沫的文章导致很多我们的年轻的同行产生了疑惑,所以我这个隐藏了很久的能言善辩的老程序员出山来聊一聊这个APP程序员泡沫的话题。<br> 笔者是2010年从事安卓开发，此前做J2ee,对于安卓我有很深的感情，此前也是有意学了iOS，但是还是决定在安卓这条路上一直走到黑，在2010年一个好的安卓开发苗子工资可以过万，工作经验也就1年那样子，基本上你会点安卓都可以接近1W。想想最近某些文章中提到现在安卓开发新手动不动就要过万的工资相比，我觉得现在的新手做法并不为过：第一，以现在的北京物价房价对比2010年来说，开发的工资其实并没有涨反倒是跌了。第二，现在的开发比2010年的新手安卓开发要厉害一些，那个时候网上资料很少，书也很少，大多数安卓开发自学起来很痛苦。现在网上资料多，也有很多高水品的技术书，也有很完善的培训机制。<br> 当然现在很多APP开发存在漫天要价的现象，但是作为企业的HR,技术经理甚至老板你可以选择不要他啊。这篇文章只讨论一般的APP开发，脑残的APP开发不在此文范畴。</p>
<h2 id="1-大环境"><a href="#1-大环境" class="headerlink" title="1.大环境"></a>1.大环境</h2><p> 首先我们说说大环境，现在是互联网时代，你别跟我说什么资本寒冬，在2008年经济危机时，也没见哪个程序员饿死了。资本寒冬只是暂时的，从2010年到现在死的互联网公司多了去了，又会有无数的互联网公司站起来。人们已经离不开互联网和手机了，做为必需品你觉得会破灭吗？就如同北上广的房子一样，08年说泡沫，现在这么多年过去了，谁还会相信这是泡沫呢？</p>
<h2 id="2-App开发"><a href="#2-App开发" class="headerlink" title="2.App开发"></a>2.App开发</h2><p> 接下来我们说一说安卓开发和iOS开发，windowsphone我们暂且不谈，这家伙10年就说要干掉安卓，也就过过嘴瘾。<br> 我现在引用一篇文章的看法:”泡沫，毕竟是泡沫，终有爆破的那一天。这个时间不会很长，3到5年。随着新技术慢慢变旧（当Android和iOS变成和C语言一样老），随着大批量的人才涌入和一些公司退出（十万开发者面对一千岗位），随着很多老板慢慢发现原理和真相（APP真的只是个终端）。” 一看就外行人写的，还说当Android和iOS变成和C语言一样老，现在写C，C++赚的不比App少，Java老不老呢？2010年做Javaweb的优秀开发月薪2W+，再说Android和iOS不是语言不能和C语言比较，我牙都笑掉了。在此我们只能看到这是外行人眼红App开发工资比他高，他又转不了开发罢了，和windowsphone一样也就过过嘴瘾。</p>
<h2 id="3-安卓和ios灭亡"><a href="#3-安卓和ios灭亡" class="headerlink" title="3.安卓和ios灭亡"></a>3.安卓和ios灭亡</h2><p> 有不少眼红的人希望Android和iOS灭亡，就像塞班一样，看Android和iOS灭亡了你们怎么办？笔者的同学以前做塞班的，塞班灭亡了他转做iOS，现在一样很牛逼，因为人家C++强，转iOS有优势。同样如果安卓灭亡了，安卓开发可以转Java，iOS。其实年轻的App开发不用担心这些，当你的技术达到一定层次，语言已经不是阻碍我们的脚步了，笔者1周就学会obj-c,写iOS代码了。同时也给年轻的App开发建议就是要注重基础，安卓和iOS只是武学招式，真正使他们发挥威力是你的内功，也就是你的基础。</p>
<h2 id="4-互联网职位稀缺性"><a href="#4-互联网职位稀缺性" class="headerlink" title="4.互联网职位稀缺性"></a>4.互联网职位稀缺性</h2><p> 一个优秀的程序员是十分难求，他不是去熬年头就能得到的，他需要付出很多，阅读很多书籍，看过很多技术文章，敲过很多高质量的代码，无数个Bug折磨过的，一步步才培养起来的，反观其他的互联网职业我就不便多说什么了，优秀的是有，但更多的是熬年头拼学历，他们所付出的努力远远没有优秀程序员付出的多，他们所创造的价值也未必有他们想象的大。现在有产品思维能言善辩的App开发越来越多，他们可以去抢产品经理的饭碗，但产品经理很难抢程序员的饭碗，这也说明了优秀App程序员的稀缺性。现在我在招聘网上找一个3年以上经验的安卓开发都很难，就算找到了也很容易被别的公司抢走。现在市场上最多的是1到2年的App开发，还有一些从别的行业转过来的App开发，靠谱的很少。</p>
<h2 id="5-提升自己让别人去喷吧"><a href="#5-提升自己让别人去喷吧" class="headerlink" title="5.提升自己让别人去喷吧"></a>5.提升自己让别人去喷吧</h2><p> 我们中国人的一大劣根性就是见不得人好，这是正常现象，那么怎么提高自己使得自己更强，让别人更眼红呢？</p>
<p> <strong>看清自己并尽早规划职业生涯</strong></p>
<p> 早看清自己的人早确定方向，看到自己的优点避开缺点，如果你热爱开发你就继续干开发成为App架构师。如果你能言善辩，组织能力强又敲的一手好代码，那就去做技术经理。如果你只是为了钱而不喜欢代码，那你得想办法尽快脱离这个行业。<br> 如果闷头去敲代码这显然是大部分程序员都能做到的，但是你有没有想过程序员这个职业可以做一辈子嘛，早做打算并且要对自己的职业生涯负责，找到自己的本性和擅长并发掘自己的潜力，从而决定自己是做个技术经理、架构师还是个什么其他相关的职业，工作多年如果还是和刚入行的干一样的活这显然不会提升自身的价值也迟早会被这个行当所淘汰。</p>
<p> <strong>做有产品思维的程序员</strong></p>
<p> 平常多看看其他的App是怎样的，和自己的对比下，每做一个需求要考虑它是否是必须的，能为用户带来什么，而不是产品经理让做什么就做什么想都不想。</p>
<p>  <strong>业余多看书，多写代码，写技术博客，找到适合自己的学习方法</strong></p>
<p> 想要脱颖而出你不付出努力又怎么能行，平常可以写一些自己想写的代码，把他写到博客上或者建立自己的代码库，写博客可以提高自己的写作能力同时也检验你的技术的掌握程度，你会发现你为了写一篇技术文章会查很多资料看很多书，遇到很多的坑，这是你去看别人的技术文章所得不到的。技术首先要做到先精，再做到广，什么叫做精，至少我现在的也不敢说精通Android，不会的实在是太多了。而我现在看到的就是很多开发什么都想搞，结果什么都搞不明白，今天学了Android，明天看看iOS，后天H5和RN火了又都去学，结果什么都不专什么都不精，知道慕容复嘛，会的再多也打不过专精一门武学的乔峰吧。只有你先精一门的前提下再去深入的研究其他的技术这才是对的。不要跟我说什么全栈工程师才是未来的大势所趋，才是王道，跟我说这个首先要明确什么是全栈工程师？全栈工程师至少要精通一门，会一堆技术结果全是半吊子也好意思说自己是全栈？作为Android开发多看看底层的源码，Java的基础，设计模式和算法以及iOS的基本知识。更重要的是在学习的过程中找到适合自己的学习方法，比如我就是多看书，然后敲一敲自己喜欢的代码，写博客总结归纳。关于书，我建议大家还是多多宜善，不仅仅限于专业的。古时文人为了一本书可以受饿攒钱去买，但现在的大多数人，在吃穿玩上花了很多的钱，唯独在书上却斤斤计较，希望大家都能养成爱读书、读好书的好习惯。</p>
<p> <strong>提高自身形象，培养软实力</strong></p>
<p> App程序员同时也需要跟别人打交道，至少要穿的得体干净，别自己舒服却让别人不舒服。多培养自己沟通的能力，多想想其他人是怎么想的，培养自己的同理心，管理好自己的情绪，学会什么时候该发火，什么时候该淡然一笑，学会对着那些令人无比生厌的小人报以自然的微笑。网上讨论什么牛逼的人应该脾气好，但我不这么认为，该霸气时就应该霸气。如果我们程序员能言善辩，精通业务，人际关系好，人脉广，并且还能敲的一手好代码，这绝对非常恐怖。</p>
<p>  <strong>保持良好的技术敏锐度和前瞻性</strong></p>
<p> 作为一个开发，技术的敏锐度和前瞻性是极其重要的。做技术难免会遇到技术的更新和新技术的出现，如何去选择变得极为重要，因为人的精力有限，这一点选择远远要比努力重要。首先要选择自己擅长的那门技术相关的新技术来进行学习，接下来再考虑其他的新技术。说到其他”新”技术，不得不提到H5和RN，作为一个移动开发者和一个手机用户，并不看好这两门”新”技术。从用户的角度来看，我们更追求高品质和最好的体验，显然H5和RN都无法达到这一点，另外想想PC端也出现了很多web应用，但至今都不温不火的，因为体验太屎了，我宁可下个客户端也不会在web应用上做操作。总结一句，就是H5难成大器。作为一个开发者，H5只适合一些商城或者广告类的界面，它只是一种解决方案，想要拿它做App那太扯了。有人在2011年就说H5是趋势是潮流，过了5年还在说，是不是等我退休了你们还在说H8是趋势呢。至于RN，可能未来会有一些进展，国人太喜欢炒作也太浮躁，Android和iOS都有自己的成熟的开发框架，非要在此之上罩上一层去写js，感觉就像是不脱裤子拉屎一样（我实在找不到很好的形容）。用你们的脑子想想，未来人们追求的是什么，是极致和高品质，为了所谓的商业模式来应付用户群体必定走不远，当然想捞一票就跑的可以忽略极致和高品质这个问题，用户不会关心你用了什么技术，他们只关心好不好用。不好用的直接扔垃圾箱里，好用的就算时常让他们下载新版本也会有人用。总结一句，RN可能就是一个搅屎棍，它的出现可能会让很多人趟浑水并且浪费很多时间。对于RN现在我也是持观望态度，因为我发现真正重要，能让我走的更远的是基础和深度，而不是这些前途不明的潮流框架。总之，对于新技术要有自己的判断，不要听风就是雨。</p>
<p>  <strong>选择好平台，不要计较一时得失</strong></p>
<p> 在好的平台才能得到最大的利益，才会发挥自己最大的能力，相反在差的平台以及不适合自己的岗位上就算再努力也白费，除了你手里那点钱什么都得不到，还会赔上最有价值的青春。有时要学会放弃，面对不好的平台、不适合自己的岗位当断则断，计较一时的金钱得失可能会葬送自己整个人生。就好比金子扔进茅坑它永远不会发光，一个铝片放在舞台上却能够闪光，不管我们是金子还是铝片一定要区分茅坑和舞台。既要活在当下同时眼光也要放远。</p>
<p>  <strong>去做去行动</strong></p>
<p> <strong>大道理很多人都懂，为何脱颖而出的就那么几个人，因为他们不只懂而且也去做了</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/Hello%20World%20Program%20in%20Eight%20Different%20Popular%20Programming%20Languages.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;http://ipcreator.me&quot;&gt;IPCreator&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Skill-is-acquired-through-correct-and-repetitive-practice-and-practice-makes-perfect&quot;&gt;&lt;a href=&quot;#Skill-is-acquired-through-correct-and-repetitive-practice-and-practice-makes-perfect&quot; class=&quot;headerlink&quot; title=&quot;Skill is acquired through correct and repetitive practice, and practice makes perfect.&quot;&gt;&lt;/a&gt;Skill is acquired through correct and repetitive practice, and practice makes perfect.&lt;/h2&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;不放过任何一个err，每成功解决一个error就意味着自己的经验库又append一个案例；&lt;/li&gt;
&lt;li&gt;理不顺想不通的时候，成长的时刻到了，坚持、坚持再坚持，成就感与困难度成正比；&lt;/li&gt;
&lt;li&gt;官网+stackflow+github+google还解决不了的时候，暂时放一放，持续关注思考，直至惊喜发生；&lt;/li&gt;
&lt;li&gt;换位常识思考，如果你是设计者，你会怎么设计，为什么这样设计？&lt;/li&gt;
&lt;li&gt;尽量不要复制粘贴，要逐字阅读，逐个输入，对开发而言，thinking与coding相辅相成，缺一不可；&lt;/li&gt;
&lt;li&gt;知其然还要知其所以然，不要浮于表面，浅尝则止，运行/部署成功不等于你掌握了每个环节的原理；&lt;/li&gt;
&lt;li&gt;慢工出细活，慢就是快，防火胜于救火，先打好基础（概念、框架、原理等），高手都重视内功；&lt;/li&gt;
&lt;li&gt;专而精，精而深，通过一个突破口（语言、框架、平台），抓住本质量（通俗易懂，能重建和迁移），再融会贯通，一通百通；&lt;/li&gt;
&lt;li&gt;coding只是解决问题的一种方式，不要重复发明轮子，要open和share，不要敝扫自珍，因为每个人都能掌握相应的技能，只是时间早晚而已；&lt;/li&gt;
&lt;li&gt;创新整合也是一种行之有效的商业途径，不要为了技术而技术，为了创新而创新，商业思维很重要；&lt;/li&gt;
&lt;li&gt;从战略上来说，我们大部分都只是用别人开发出来的工具（类似于厨具）开发产品（类似于菜品）而已；&lt;/li&gt;
&lt;li&gt;阅读代码（类似于品尝他人菜品）、模仿创新（借鉴改造）、原创分享（晋级高级厨师）；&lt;/li&gt;
&lt;li&gt;道理都懂，为什么难以坚持？没有尝到甜头或者没有吃到苦头，又或者只是懒惰；&lt;/li&gt;
&lt;li&gt;35岁以后能否再编程？取决于：以前的编程模式是否健康可持续？是否为自己实现创新产品和服务(而不只是为了挣钱)；&lt;/li&gt;
&lt;li&gt;程序员人生的梦想和快乐简单易实现，成为其中一员才能真正感同身受…&lt;/li&gt;
&lt;li&gt;有劲、有趣和有用，正常可持续，Kick-off &amp;amp; Keep-going&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Programming" scheme="http://ipcreator.me/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript教程</title>
    <link href="http://ipcreator.me/2017/02/20/Program/Concepts/learn-journey-of-javascript/"/>
    <id>http://ipcreator.me/2017/02/20/Program/Concepts/learn-journey-of-javascript/</id>
    <published>2017-02-19T22:53:06.000Z</published>
    <updated>2017-02-22T06:31:57.155Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://www.liaoxuefeng.com/files/attachments/0014355670304100cdaa4e7e651474d9672ed73797378bd000/l" alt=""></p>
<p>作者：<a href="http://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000" target="_blank" rel="external">廖雪峰</a></p>
<p>这是小白的零基础JavaScript全栈教程。</p>
<p>JavaScript是世界上最流行的脚本语言，因为你在电脑、手机、平板上浏览的所有的网页，以及无数基于HTML5的手机App，交互逻辑都是由JavaScript驱动的。</p>
<p>简单地说，<strong>JavaScript是一种运行在浏览器中的解释型的编程语言。</strong></p>
<p>那么问题来了，为什么我们要学JavaScript？尤其是当你已经掌握了某些其他编程语言如Java、C++的情况下。</p>
<p>简单粗暴的回答就是：因为你没有选择。<strong>在Web世界里，只有JavaScript能跨平台、跨浏览器驱动网页，与用户交互。</strong></p>
<p>Flash背后的ActionScript曾经流行过一阵子，不过随着移动应用的兴起，没有人用Flash开发手机App，所以它目前已经边缘化了。相反，随着HTML5在PC和移动端越来越流行，JavaScript变得更加重要了。并且，<strong>新兴的Node.js把JavaScript引入到了服务器端，JavaScript已经变成了全能型选手。</strong></p>
<p>JavaScript一度被认为是一种玩具编程语言，它有很多缺陷，所以不被大多数后端开发人员所重视。很多人认为，写JavaScript代码很简单，并且JavaScript只是为了在网页上添加一点交互和动画效果。</p>
<p>但这是完全错误的理解。JavaScript确实很容易上手，但其精髓却不为大多数开发人员所熟知。编写高质量的JavaScript代码更是难上加难。</p>
<p>一个合格的开发人员应该精通JavaScript和其他编程语言。如果你已经掌握了其他编程语言，或者你还什么都不会，请立刻开始学习JavaScript，不要被Web时代所淘汰。</p>
<p>等等，你会问道，现在有这么多在线JavaScript教程和各种从入门到精通的JavaScript书籍，为什么我要选择这个教程？</p>
<p>原因是，这个教程：</p>
<p>是JavaScript全栈教程！</p>
<p>可以在线免费学习！</p>
<p>可以在线编写JavaScript代码并直接运行！</p>
<p>不要再犹豫了，立刻从现在开始，零基础迈向全栈开发工程师！</p>
 <a id="more"></a>
<p> 关于作者</p>
<p>廖雪峰，十年软件开发经验，业余产品经理，精通Java/Python/Ruby/Visual Basic/Objective C等，对开源框架有深入研究，著有《Spring 2.0核心技术与最佳实践》一书，多个业余开源项目托管在GitHub，欢迎微博交流：</p>
<p><img src="http://service.t.sina.com.cn/widget/qmd/1658384301/078cedea/2.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://www.liaoxuefeng.com/files/attachments/0014355670304100cdaa4e7e651474d9672ed73797378bd000/l&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000&quot;&gt;廖雪峰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是小白的零基础JavaScript全栈教程。&lt;/p&gt;
&lt;p&gt;JavaScript是世界上最流行的脚本语言，因为你在电脑、手机、平板上浏览的所有的网页，以及无数基于HTML5的手机App，交互逻辑都是由JavaScript驱动的。&lt;/p&gt;
&lt;p&gt;简单地说，&lt;strong&gt;JavaScript是一种运行在浏览器中的解释型的编程语言。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;那么问题来了，为什么我们要学JavaScript？尤其是当你已经掌握了某些其他编程语言如Java、C++的情况下。&lt;/p&gt;
&lt;p&gt;简单粗暴的回答就是：因为你没有选择。&lt;strong&gt;在Web世界里，只有JavaScript能跨平台、跨浏览器驱动网页，与用户交互。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Flash背后的ActionScript曾经流行过一阵子，不过随着移动应用的兴起，没有人用Flash开发手机App，所以它目前已经边缘化了。相反，随着HTML5在PC和移动端越来越流行，JavaScript变得更加重要了。并且，&lt;strong&gt;新兴的Node.js把JavaScript引入到了服务器端，JavaScript已经变成了全能型选手。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;JavaScript一度被认为是一种玩具编程语言，它有很多缺陷，所以不被大多数后端开发人员所重视。很多人认为，写JavaScript代码很简单，并且JavaScript只是为了在网页上添加一点交互和动画效果。&lt;/p&gt;
&lt;p&gt;但这是完全错误的理解。JavaScript确实很容易上手，但其精髓却不为大多数开发人员所熟知。编写高质量的JavaScript代码更是难上加难。&lt;/p&gt;
&lt;p&gt;一个合格的开发人员应该精通JavaScript和其他编程语言。如果你已经掌握了其他编程语言，或者你还什么都不会，请立刻开始学习JavaScript，不要被Web时代所淘汰。&lt;/p&gt;
&lt;p&gt;等等，你会问道，现在有这么多在线JavaScript教程和各种从入门到精通的JavaScript书籍，为什么我要选择这个教程？&lt;/p&gt;
&lt;p&gt;原因是，这个教程：&lt;/p&gt;
&lt;p&gt;是JavaScript全栈教程！&lt;/p&gt;
&lt;p&gt;可以在线免费学习！&lt;/p&gt;
&lt;p&gt;可以在线编写JavaScript代码并直接运行！&lt;/p&gt;
&lt;p&gt;不要再犹豫了，立刻从现在开始，零基础迈向全栈开发工程师！&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Java Script" scheme="http://ipcreator.me/tags/Java-Script/"/>
    
  </entry>
  
  <entry>
    <title>猎豹CEO傅盛：关于深度学习的五个思考</title>
    <link href="http://ipcreator.me/2017/02/19/BusinessAI/some-thoughts-of-fusheng/"/>
    <id>http://ipcreator.me/2017/02/19/BusinessAI/some-thoughts-of-fusheng/</id>
    <published>2017-02-19T15:59:59.000Z</published>
    <updated>2017-02-27T03:43:44.623Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.36dsj.com/archives/61885" target="_blank" rel="external">来源：36大数据</a></p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/fusheng.jpg" alt=""></p>
<p>作者：傅盛</p>
<p>任何一场革命，绝不是以敲锣打鼓的方式，来到你的身边。等到某一天，你忽然发现快要天翻地覆时，再去看，发现自己已被别人抛弃了。<br>过去以端为中心的技术革命，不能说结束了，但已不再是时代的风口。</p>
<h2 id="技术，进入了一场以数据为驱动的革命。"><a href="#技术，进入了一场以数据为驱动的革命。" class="headerlink" title="技术，进入了一场以数据为驱动的革命。"></a>技术，进入了一场以数据为驱动的革命。</h2><p>互联网不再只是一张虚拟的网，而更像是一个大数据库。大量的数据，沉甸甸，就在那里。没有人知道，怎么把这些数据，更加完整清晰的表达出来。<br>我们需要重新思考技术的致胜点。</p>
<p>怎么思考呢?我讲几个关键点。</p>
<a id="more"></a>
<h2 id="1、数据和运算能力，变得越来越重要。"><a href="#1、数据和运算能力，变得越来越重要。" class="headerlink" title="1、数据和运算能力，变得越来越重要。"></a>1、数据和运算能力，变得越来越重要。</h2><p>孔子说过一句话：“学而不思则罔，思而不学则殆”。</p>
<p>先说，学而不思则罔。你拿了很多知识，不深度学习，不行。如果你没有运算能力，有了一堆数据，算不出来，没用。不是深度越深，效果越好。<br>这是个复杂的问题。需要不停算，不停实验。</p>
<p>今天，整个深度学习的理论，还不够成熟，依然落后于实践。更多时候，只能靠试。此时，运算能力，就变得非常关键。</p>
<p>假如，别人做一次运算，要两个礼拜，而你只需要一天或2个小时。同样时间内，你可以做更多实验，积累更多宝贵经验，迭代速度也更快。</p>
<p>这就好像，两个人起点一样，但由于迭代速度不同，导致了最后成就的千差万别。每一次迭代，相当于你的一次翻版。你是一天迭代一次，还是一年迭代一次。你对自己翻版本的速度有多快，决定你最后以多大的成果超过对手。</p>
<p>思而不学则殆呢?简单说，如果你没有数据，一点用都没有。</p>
<p>这个时代越来越需要海量数据。数据量越大越好。甚至于，我们以前被认为不是很关键的数据，都有可能灌进去，再看效果。</p>
<p>这才有了一句流行语——Welcome to the GPU world.</p>
<p>GPU最早为快速满足增长的图形计算需求而设计。它不同于CPU，在多核多线程处理上浮点性能更佳，使得它在图形界的并行运算，变得超强。</p>
<p>早期，谷歌发表了一篇论文说——深度学习的结果，要跑在英伟达的GPU上。很快，做芯片起家的英伟达，其公司股价开始蹭蹭蹭一路上涨，涨了好几十块。</p>
<p>然而，如果今天，你还以为英伟达是个显卡公司，那就大错特错了。如今汽车的防撞系统，警告系统，以及无人驾驶采用的双目视觉图像处理，英伟达是第一大提供商。它其实变成了一家人工智能公司。</p>
<p>说到这，大家可能也会奇怪——今天关于无人驾驶，辅助驾驶的新闻越来越多，也有越来越多的公司在做，为啥呢?</p>
<p>核心就在于，深度学习极大降低了这一门槛。只要你能拿到足够数据，就可能实现对物体的各种判断。</p>
<p>本质也带来了一个技术上弯道超车的好机会。很多公司辛苦积累的软件技术直接作废了。包括IBM做了语音输入好多年，上来就被深度学习超越了。尤其当谷歌进入语音输入时，一下就超越了IBM多年的技术积累。与此同时，谷歌还有足够多的数据，以及足够多的语音样本，不停输入。</p>
<p><strong>算法为核心的竞争力，正转换成数据为核心竞争力。</strong></p>
<p>我个人觉得，甚至有些算法会消失掉。但，并不是说算法不重要。<strong>只是神经网络的核心算法，提升起来太难。</strong></p>
<p>现在大家都把专注度放在了数据和运算。尤其在深度学习里，获取足够多的数据，就有机会产生更好的结果。神经网络本身差异不会很大，关键比的是——谁能把这些数据用好，并快速计算。</p>
<p>数据变得越来越重要。尤其在深度学习里，获取足够多的数据，就有机会产生更好的结果。神经网络本身差异不会很大，关键比的是——谁能把这些数据用好，并快速计算。</p>
<h2 id="2、公司研发结构会发生很多改变，数据获取和数据标注会变得非常重要。"><a href="#2、公司研发结构会发生很多改变，数据获取和数据标注会变得非常重要。" class="headerlink" title="2、公司研发结构会发生很多改变，数据获取和数据标注会变得非常重要。"></a>2、公司研发结构会发生很多改变，数据获取和数据标注会变得非常重要。</h2><p>中国在这场竞争中，还是有很大机会。能够轻易获取的互联网数据，以及低成本的众包劳动，将为中国公司带来训练所需的计算和人力资源。</p>
<p>第一，数据获取的量级。尽管美国整个技术的前沿性很好，问题在于——硅谷一家小公司拿到的数据，和一家中国高速发展的互联网公司拿到的数据，不可同日而语。</p>
<p>第二，数据标注的成本。在美国，要搞数据标注，肯定很累，多贵啊!但在中国，到珠海或成都随便找300个人，去帮你标注，成本很低。ImageNet图像分类大赛，中国人取得的成绩明显突出。国外，微软或谷歌参赛，都是几个人去做图像标注和算法验证。而中国可以组织足够多的人去做标注。<br>我认为，ImageNet大赛，未来的世界冠军都会来自中国。</p>
<h2 id="3、并行异构计算的人才，变成核心竞争力。"><a href="#3、并行异构计算的人才，变成核心竞争力。" class="headerlink" title="3、并行异构计算的人才，变成核心竞争力。"></a>3、并行异构计算的人才，变成核心竞争力。</h2><p>过去计算领域都是以CPU为中心的计算模式。深度学习要将CPU和GPU两个加起来。这是两个技术的计算模型，是异构的模型。</p>
<p>为什么要异构?</p>
<p>因为GPU是并行的。它需要用来显示。为了让你的屏幕刷新保持更快更流畅，就要把GPU分成很多个小的运算单元。每一个运算单元，负责屏幕某一块具体区域的刷新。而大量这样的运算单元都包含在一个GPU当中。要想跑得快，就得把计算逻辑放在CPU中，同时再把你准备好的数据拷贝到GPU中。然后呢?GPU再用并行的方式，计算准备好的这些数据。这就是异构的模型。</p>
<p>这个模型，是计算体系，也是硬件体系的一次革命，是真正的技术革命。</p>
<p>举个例子。现在要完成一个复杂的大型任务，需分割在100台机器，让它们分开跑，又同时共同执行同一个全局任务，需要一个数学上严格的方法来完成。这意味着，每一次计算更新的时候，都要把大数据刷一遍，刷几千遍是何其难的事情。几十亿个参数的深度学习模型，每一次迭代都要把参数刷一遍。尤其数据量足够大时，这是很难的。</p>
<p>因此，能否调动大量的运算资源，就会成为核心竞争力。我的判断是，未来整个研发结构——重数据，重运算，这两点，必然出现。</p>
<h2 id="4、语音和视觉，将成为下一代交互模式。"><a href="#4、语音和视觉，将成为下一代交互模式。" class="headerlink" title="4、语音和视觉，将成为下一代交互模式。"></a>4、语音和视觉，将成为下一代交互模式。</h2><p>可能大家没有注意一个数据，谷歌已经有20%的搜索来自语音。这是很可怕的一个趋势。<br>我认为，语音和视觉会是下一代的交互模式。<br>过去我们从PC时代的十指模式(电脑键盘)，走到今天的拇指模式(手机)，未来一定是自然模式(语音和视觉)。<br>因为，太多的交互都会变得很简单。有多简单呢?只会用接触的方式去完成。今天之所以还没有大规模到来，其实是技术不够成熟。<br>亚马逊发布Echo时，为什么谷歌那么在意?我觉得很重要的一点，就是它通过300万台的设备，不停地拿数据——用户的每一次说话，都是一次新的数据。这个数据足够多，又反过来加深它的语音能力。<br>交互模式的变化，不仅改变了产品，也影响了数据方式。</p>
<h2 id="5、深度学习在各个领域产生的变革才刚刚开始。"><a href="#5、深度学习在各个领域产生的变革才刚刚开始。" class="headerlink" title="5、深度学习在各个领域产生的变革才刚刚开始。"></a>5、深度学习在各个领域产生的变革才刚刚开始。</h2><p>无论是现阶段的内容个性化推荐，还是未来输入方式的改变，还有太多地方，可以被深度学习改变。<br>比如人脸识别。今天你用支付宝，或招商银行客户端，都会让你扫一扫，准确率已经相当高了。高到什么程度呢?有一家公司专门为海关提供人脸识别服务。以前用人工查看，看两个小时后就会出错，加上深度学习算法的系统，极大降低了人脸识别的出错率。</p>
<p>我认为，只要需求越多，它就会越来越准。</p>
<p>比如小米手机出了面孔功能。根据人脸识别进行照片分类。已经可以达到92%的准确率了。包括猎豹。我们在全球有6亿月度活跃用户，一旦建立起深度学习的核心技术能力，猎豹向很多领域的扩展和应用结合就会变成可能。</p>
<p><strong>如果你把深度学习看成一种“工具”，就会发现——它有很多和其它领域，包括传统行业相互结合的机会。</strong></p>
<p>漫漫长路，才刚刚开始。<br>End.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.36dsj.com/archives/61885&quot;&gt;来源：36大数据&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/fusheng.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：傅盛&lt;/p&gt;
&lt;p&gt;任何一场革命，绝不是以敲锣打鼓的方式，来到你的身边。等到某一天，你忽然发现快要天翻地覆时，再去看，发现自己已被别人抛弃了。&lt;br&gt;过去以端为中心的技术革命，不能说结束了，但已不再是时代的风口。&lt;/p&gt;
&lt;h2 id=&quot;技术，进入了一场以数据为驱动的革命。&quot;&gt;&lt;a href=&quot;#技术，进入了一场以数据为驱动的革命。&quot; class=&quot;headerlink&quot; title=&quot;技术，进入了一场以数据为驱动的革命。&quot;&gt;&lt;/a&gt;技术，进入了一场以数据为驱动的革命。&lt;/h2&gt;&lt;p&gt;互联网不再只是一张虚拟的网，而更像是一个大数据库。大量的数据，沉甸甸，就在那里。没有人知道，怎么把这些数据，更加完整清晰的表达出来。&lt;br&gt;我们需要重新思考技术的致胜点。&lt;/p&gt;
&lt;p&gt;怎么思考呢?我讲几个关键点。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
      <category term="Business" scheme="http://ipcreator.me/tags/Business/"/>
    
  </entry>
  
  <entry>
    <title>人工智能的黄金时代</title>
    <link href="http://ipcreator.me/2017/02/19/BusinessAI/golden-age-of-artificial-intelligence/"/>
    <id>http://ipcreator.me/2017/02/19/BusinessAI/golden-age-of-artificial-intelligence/</id>
    <published>2017-02-19T15:59:59.000Z</published>
    <updated>2017-02-27T03:43:28.012Z</updated>
    
    <content type="html"><![CDATA[<p><strong><a href="http://gelonghui.com/p/101767.html" target="_blank" rel="external">“人工智能时代，将是一个比移动互联时代大十倍的市场 —-李开复”</a></strong></p>
<blockquote>
<p>10年后，人工智能能将取代世界上90%的翻译/记者/助理/保安/司机/销售/客服/交易员/会计/保姆。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181329333.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>人工智能也就是这样几个事情，感知、决策、反馈。</p>
</blockquote>
<a id="more"></a>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181341826.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>人工智能发展的主要里程碑。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181350807.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>近年最大的突破：深度学习<br>深度学习是什么？你丢一大堆数据给它，然后问它，我应该买什么股票？这个人的保险该付多少钱？这个想贷款的该不该贷？这个信用卡的交易是否有欺诈的嫌疑？你还可以问他，这么多的男人你应该找哪一个为对象？你也可以问他，今天晚上这么多好吃的，我应该吃哪些？它都会告诉你一个答案。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181427566.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>深度学习之后还有更新的技术</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181446333.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>什么领域适合人工智能<br>海量的数据，清晰领域界限，顶尖的AI科学家，还有自动标注数据，以及超大的计算量。<br>科学家的创业时代来临了，而不是三个小朋友的创业时代。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181532708.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>机器学习在很多领域超越人类、创造巨大价值<br>左上角代表的是在图像识别领域机器超越人类，左下角是语音识别领域机器的错误率低于人类。<br>当人脸识别超越了人类，我们还需要保安吗？当语音识别超越了人类，我们还需要客服吗？还需要打电话推销吗？<br>当自动驾驶超越人类，我们还需要司机吗？当传内容，写新闻，金融稿件的能力超越了人类我们还需要金融界记者吗？<br>90%的金融领域的报道都是传出来的，这些报道以后绝对不是人写的，人写是会犯错的，机器不会犯错，只有深度的报道才需要人写。<br>那到底哪些领域可以做人工智能，可以挣钱呢？实在太多了，这里随便列了三十多个领域，在任何一个领域就是一个商业计划书，如果你能找到一个该领域的超级的<strong>商业专家</strong>，<strong>销售专家</strong>，再搭配一个<strong>人工智能的科学家</strong>，那就是一个黄金创业团队。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181551193.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong> 简单来说，谁能做人工智能的创业 </strong></p>
<blockquote>
<p>第一种，谁手中拥有互联网数据的这个是最了不起的，也就是BAT、滴滴、美图等等，他们手中有数据，而且已经标注，只要有科学家就可以产生价值。</p>
<p>第二种是传统企业，比如说股票的数据，比如说保险业、银行业，各种金融的。我觉得数据非常的丰富，而且是非常的狭窄领域，不用跨领域的理解，而且可以快速产生商业价值。再往下医学，如何看片子，看MRI，看CT，看各种人的健康记录一定是超过医生的，现在至少有3种重要的病症人工智能已经超越了医生的平均水平，而且你像这个是要花多少临床的时间，现在三种可能再过5年就是300种，再过10年可能就是3000种。然后90%的医生就都不需要了，至少被机器取代。那这些医生就要做更高等的工作，更深入的工作，去发掘新的医药的工作，或者是做更心理医疗的工作。面对病人，机器还是冷冰冰的，可能还需要一个人脸对着病人，但是90%的医生，在10年以后应该都打不过我们机器的诊断能力了。这对人类是有很大意义的，教育的数据也是很多的，就不多细讲。</p>
<p>最右边是无人驾驶。这是我们特别看好的领域，它是最大颠覆量的，以后都不需要人开车了。再加上电动车和共享经济，以后我们出门的时候，一辆坐一人的车就会出现在我们面前，它带我们去要去的地方，节能低碳，减少雾霾，而且这还会影响整个经济。如果大家谁有投资停车场的，十年以后就没有停车场了。所以，这些都有巨大的颠覆性。如果你们觉得听起来像是天方夜谭，像是科幻小说，那么你们也可以想一想，2009年当我告诉所有人移动互联网时代来临的时候，大部分人也是这样想的。甚至当时的BAT听了移动互联网的预测之后，他们总是认为没有PC大，没有PC赚钱，成长的会很慢。但现在你看他们一个个也都追上来了。所以人工智能是一个特别巨大的领域和机会。</p>
</blockquote>
<p><strong> 我们到底该和谁学人工智能呢？ </strong></p>
<blockquote>
<p>世界上最懂人工智能的绝对是谷歌这个公司了。在一年前他就宣布了要做Alphabet这个母公司。<br>什么是Alphabet呢？其实它就是把谷歌里面做搜索提炼出来的人工智能做成谷歌大脑，然后把它用到各种领域。用在围棋就成了AlphaGo，我们已经看到它的威力有多大了，用在汽车就是Google car，用在健康就是Google house用在基因检测就是Google genetics，所以在Alphabet上面，谷歌的野心就是要把一个谷歌的成功变成26个，这是一个特别有野心的人工智能的公司。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181605872.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>谷歌公司内部也是在用刚才所说的深度学习。这个图是来自谷歌的一个科学家，他对外演讲用的我们可以看到也是在这4年，他们才领悟了人工智能的价值和谷歌大脑的价值，收购了Deep Mind这样的公司。所以很明确的就是，谷歌的Alphabet这样的一个动作，绝对是它看到了机器学习可以进入各种领域的机会，这也是它所进行的一个很有野心的探索。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181625889.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong> 到底人工智能如何克服挑战产生竞争壁垒呢？ </strong></p>
<blockquote>
<p>第一，就是要寻找行业里面有特别大的大数据，然后是垄断性和闭环的。<br>第二是买很多机器，尤其是CPU＋GPU。<br>第三是有很厉害的深度学习的科学家。<br>第四，虽然这些顶尖科学家很有价值，同样的小朋友也有价值。不过小朋友还不能创业，需要培训。<br>人工智能很大的一个特色是速成，他不像是你去找一个化学科学家，或者说生物科技或者甚至是计算机领域的这个Networking 、Database之类的，非常难学。人工智能不一样，它很好学，前提是你一定要是一个数学天才。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181638460.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong>怎么样让人工智能快速商业化</strong></p>
<blockquote>
<p>第一是做助手，而非取代人。<br>第二是界面要用好，给很多结果，而不只是一个结果。<br>第三草船借箭，要用户提供数据，如果你的数据不够。<br>第四局限你的领域，不要做一个特别伟大的超级的技术。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181650526.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong>中国的独特人工智能机会</strong></p>
<blockquote>
<p>中国在人工智能领域比移动互联网领域还适合创造世界顶尖的公司。<br>第一个理由就是，中国人很适合做人工智能。<br>第二，训练小朋友非常快速<br>第三，传统企业的人工智能技术非常的弱<br>第四个理由，因为中国市场大，互联网公司多，很多非AI的公司到了一定的规模，就开始需要AI。<br>第五点，美国人工智能现在是绝对领先中国的，但是他们进不了中国，中国上面有各种理由。<br>最后一点是中国对人工智能各方面的约束较少。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181716797.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong>创新工场对人工智能有一个很完整的投资蓝图</strong></p>
<blockquote>
<p>第一个重点是大数据的机会<br>第二个是语言方面<br>第三呢，是传感器的降价非常的重要。<br>最后是自动驾驶</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181751895.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong>创新工场在人工智能领域在做什么呢？</strong></p>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181804383.!wm" width="693" height="521" alt="personal photo"><br></div>

<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181815148.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>wonder workshop，它是一个人工智能的玩具。它可以跟着小朋友，就像现在的这个大疆新的机型，可以让它跟着你一样。甚至两个机器可以在一块玩等等，很有趣的。它是一个没有眼睛、耳朵、手与脚只是几个小轮子做的这样的一个机器人，我们认为这个领域也像Echo音响一样是有机会的。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181825280.!wm" width="693" height="521" alt="personal photo"><br></div>

<blockquote>
<p>找一批专家带一批学生，买大量的数据，数据也包括了金融交易的数据。<br>AI时代的创业呢，都是科学家。</p>
</blockquote>
<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181838477.!wm" width="693" height="521" alt="personal photo"><br></div>

<div align="center"><br><img src="http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181857526.!wm" width="693" height="521" alt="personal photo"><br></div>

<p><strong>如何去做早期公司的投资</strong></p>
<blockquote>
<p>第一个怎么投资公司。刚才我已经说过了，要衡量它有没有大数据，然后有没有独特的大数据，不是买来的大数据，有没有科学家，有没有闭环，有没有很多机器。然后他做的这个领域，是不是可以产生商业价值的领域，还是一批科学家在瞎搞。这是第一个。看这些项目要小心，还有看机器人的项目，有眼睛耳朵手与脚的就千万不要再听了，虽然听起来很酷。无人驾驶可以去想想怎么去参与。</p>
<p>这是投公司的，投基金呢？投创新工场和真格基金就可以了。</p>
<p>至于买股票呢？我是美图的董事，可能下面不适合说，但是你应该知道我要说什么，我们看好美图，认可美图。</p>
<p>刚才也分享了，量化AI在国内的投资应该机会特别大，这不是一个人工智能投资，这是一个真的二级市场的投资，当然要避免一些法律所不允许的事情，但是机会还是很多。那么我们现在也在专门看这个量化AI投资，对于这些呢，如果有兴趣的我们也可以一起以后在别的机会一起探索。</p>
<p>我也给大家说了，过去两年，我所有的资产基本都是在创新工场里，除了一栋房子，创新工场，我所有的资产基本上都是交给机器人管理，都是用AI量化来管理。这个也就是告诉你我对这个领域是多么看好和认可。当然三年后这个领域可能就是红海了，只是说现在的机会是非常好的。当然我还有一支股票是例外的，是我孩子决定要投资的。就像如果说在移动互联网时代，二级市场最好的投资标的是ARM，人工智能的时代是什么？大家确实可以看一看NVIDIA。</p>
</blockquote>
<h2 id="报告称：被机器人取代的不止低端行业-中产阶级也有风险"><a href="#报告称：被机器人取代的不止低端行业-中产阶级也有风险" class="headerlink" title="报告称：被机器人取代的不止低端行业 中产阶级也有风险"></a>报告称：被机器人取代的不止低端行业 中产阶级也有风险</h2><p>　　【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】<br><img src="http://dingyue.nosdn.127.net/3IFkYAKGDQzQXK=bEHBM022fQJyG1L9UmXjIx7KnnuDFf1486458479643compressflag.jpg" alt=""><br>　　【网易智能讯 2月7日消息】 该研究分析了在技术发展情况下高薪工作被自动化设备取代的风险。</p>
<p>　　研究指出，<strong>房地产经纪人和信贷分析师</strong> 等中产阶级职业被自动化设备取代的风险高达97%，而包括侦探、法官和治安官被取代的风险偏向中等，包括牙医、医生和消防员等职业被自动化取代的风险较低。</p>
<p>　　总体来说，技术的进步很快就会使几十个中产阶级工作岗位变得岌岌可危。</p>
<p>　　该研究的作者Carl Frey是牛津大学的一名校长，他之前曾发表过一份研究报告，认为英国有35%的工作处于被机器人取代的危险之中。其主要工作是分析今后哪些收入更高的工作可能会消失。</p>
<p>　　通过对诸多年薪超过4万美元的工作进行深入调查分析，Frey编制了一份风险清单，显示了哪些工作最容易被自动化所替代，同时哪些工作最有可能存续下去。</p>
<p>　　研究指出，由于计算机技术的不断发展，保险公司和房地产中介等高收入中产阶级正在面临被取代的风险。该类工作有97%的概率将会被计算机所替代，也会引发相关中产阶级的担忧。</p>
<p>　　Frey告诉《时代周刊》，“在未来几十年内，对专业技能要求较低的工作岗位自动化程度会越来越高，但中等收入的工作岗位同样面临会面临着被自动化取代的风险。”</p>
<p><img src="http://dingyue.nosdn.127.net/s2XflidlZQs1gBZwIjupdCQbQaoLYdjsX55LYVl0jHjpg1486458479644compressflag.jpg" alt=""></p>
<p>　　信用分析师也被归于Frey的高风险列表，其职位有97%的概率会被机器人所取代。邮政服务工作者岗位被取代的概率是95%，而实验室技术人员的风险为89%。</p>
<p>　　此外，研究指出，地铁或有轨电车的工作人员有93%的概率被自动化。</p>
<p>　　这些数据表明了一项客观的评估，即科技如何取代人类完成工作和任务的交互，并不是说在不久的将来人类工作将变得多余。另一方面，这项研究也表明各类工作有被自动化的风险。</p>
<p><img src="http://dingyue.nosdn.127.net/D4TCAoTQVkxj9k=HRL=HunYqpf5ytPtwE8JgLNw8cpzMx1486458479645compressflag.jpg" alt=""></p>
<p>　　研究人员称，消防员、牙医和医生等专业岗位被自动化的概率不到1%。这项研究也表明，长期来看此类工作相对安全。其中包括诸如牙医、精神病医生和营养师等医疗保健岗位。总体来看，整个医疗保健行业的岗位普遍“低风险”。此外还包括营养师、营养学家、精神病医生、足疗医生和药剂师等职位。</p>
<p>　　根据这项研究，包括侦探、法官和地方官员等岗位属于中期内安全职业——这或许表明，虽然理论上这些工作可以自动化，但技术的复杂性还无法满足现实需求。</p>
<p>　　长期以来，人们认为传统的低技能工作将逐渐被淘汰，因为随着经济的发展计算机技术的应用更加具备成本效益，技术的发展将使那些看似脆弱的工作岗位变得更加脆弱。</p>
<p>　　尽管这项研究分析的是美国岗位，但Frey指出，由于行业相似，发展阶段相同，这项研究也适用于英国。</p>
<p>　　（英文来源：每日邮报编译：机器小易 校对：晗冰）。</p>
<p>　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
<h2 id="停车库、浏览器、提款机、十字路口与办公室，都将由AI控制"><a href="#停车库、浏览器、提款机、十字路口与办公室，都将由AI控制" class="headerlink" title="停车库、浏览器、提款机、十字路口与办公室，都将由AI控制"></a>停车库、浏览器、提款机、十字路口与办公室，都将由AI控制</h2><p>　　<img src="http://dingyue.nosdn.127.net/dDV3pyoNd1ThSYdY9R2fcimuJbmlAMwQt6uHqQiuJ9NA81486354973879compressflag.jpg" alt=""></p>
<p>　　【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】</p>
<p>　　网易智能讯 2月6日消息，如果人工智能（AI）真的在改变我们的日常生活，它会如何改变?仔细想想，你就会发现，像人类这样处理信息的技术依然处于早期阶段，但它已经出现在聊天机器人和像亚马逊Echo这样的扬声器上。然而，我们每天使用的许多服务仍未获得AI支持，这是多么糟糕！</p>
<p>　　<strong>1.AI停车库</strong></p>
<p>　　目前正在进行的许多尝试，都希望让泊车变得更容易，其中包括福特的汽车，你可以使用应用来预订停车位，并支付停车费。但我希望的是更先进的方案。</p>
<p>　　当你驾车到来时，由AI支持的停车库可以识别出你的车，然后查阅你的账户。当它发现你是老顾客时，头顶的扬声器系统就会与你聊天，并引导你到空旷的地方，向你展示你的奥迪的“夜生活”，然后让你自动付款。当你离开时，如果有任何问题，都可以在出口处跟机器人协商处理。</p>
<p>　　<strong>2.网络浏览器</strong></p>
<p>　　网络浏览器如何能从人工智能中获益呢?这听起来似乎显得有些牵强，但当你在网页上搜索特定主题，比如新的打印机时，AI助理会注意到，并提供最佳选择的链接。它会帮你记住这些网站——不仅仅是把它们放在书签或收藏在浏览历史中，还可以把它们保存在知识库中。</p>
<p>　　你不需要搜索那个档案——AI可以提醒你这些事实和链接。它可能会关注你在社交媒体上发布的信息，甚至建议你不要和一个在Twitter上攻击别人的人打交道。而且，它可能还可帮助我们进行标签管理，调整我们正在使用的标签宽度，或者提供我们昨天就没有触碰过的标签。</p>
<p>　　<strong>3.自动提款机</strong></p>
<p>　　这些愚蠢的终端可能会变得更聪明。当然，我们主要需要它们进行存款和提取现金。有些最受欢迎的银行ATM可以记住你通常使用的选项，比如最喜欢的账户。人工智能会更了解你，提醒你(如果你启用了这个功能)关于到期的账单等。</p>
<p>　　最重要的是，它会使用生物识别技术来识别你，知道你总是在特定的日期存取款。它还可了解你的其他习惯，以使这个过程变得更快、更容易。</p>
<p>　　<strong>4.道路交叉路口</strong></p>
<p>　　我知道现在正努力让公路变得更加智能化——在不久的将来，我们的汽车将会知道什么时候交通灯会变绿。然而，人工智能将能够随时识别汽车和卡车的确切位置。它可以与信号灯进行交流，以调整交通流量。</p>
<p>　　如果人工智能可以进行干预(如果我们允许的话)，汽车本身知道如何避免在十字路口发生碰撞，并调整两辆车的方向盘和刹车，其中包括由傻瓜驾驶的汽车。</p>
<p>　　<strong>5.办公桌椅</strong></p>
<p>　　这看起来可能有些奇怪，但它的确能从AI中受益。假设你的办公器具都有AI支持。你的椅子可以调整，以便符合你的骨骼结构或任何医疗条件。</p>
<p>　　你的站立式办公桌可以根据你的身高和体重(以及打字风格)来调整，以符合最佳的人体工程学。当你坐得太久时，桌子可能会建议你站立15分钟。如果你没精打采地坐着，椅子可能会轻轻地推你一把。</p>
<p>　　（英文来源/venturebeat，编译/机器小易，校对/小小 ）</p>
<p>　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://gelonghui.com/p/101767.html&quot;&gt;“人工智能时代，将是一个比移动互联时代大十倍的市场 —-李开复”&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;10年后，人工智能能将取代世界上90%的翻译/记者/助理/保安/司机/销售/客服/交易员/会计/保姆。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://glhsns.img-cn-hangzhou.aliyuncs.com/201611/p20161129181329333.!wm&quot; width = &quot;693&quot; height = &quot;521&quot; alt=&quot;personal photo&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;人工智能也就是这样几个事情，感知、决策、反馈。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>李开复：AI 创业的十个真相</title>
    <link href="http://ipcreator.me/2017/02/19/BusinessAI/ten-truths-of-ai-star-up-firm/"/>
    <id>http://ipcreator.me/2017/02/19/BusinessAI/ten-truths-of-ai-star-up-firm/</id>
    <published>2017-02-19T15:59:58.000Z</published>
    <updated>2017-02-19T06:03:00.878Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201701/OHG9MiEiL6cmJxCD.html" target="_blank" rel="external">史中</a></p>
<p>“重仓”人工智能，是李开复和创新工场未来几年的方向。但是，他面临一个很重要的问题：现在的 AI 创业，核心是 AI 科学家，而“文能起笔安天下，武能上马定乾坤”的 AI 科学家凤毛麟角，用他的话说“该创业的都创业了”。</p>
<p>这时，产业在面临一步棋。那就是：如何把一个普通的 AI 科学家变成“创业英雄”。</p>
<p>作为三十年前就开始研究人工智能的李开复，觉得自己“技术范儿”的创新工场有能力推动这步棋，并且在这一步棋中获得稳固的战略优势。</p>
<p>李开复告诉雷锋网(公众号：雷锋网)，<strong>AI 创业现在是科学家的天下，之后是数学家的天下，将来是普通人的天下。</strong></p>
  <a id="more"></a>
<p>以下是李开复在《创新工场人工智能战略白皮书》发布会上的闭门分享，雷锋网将其整理成为《李开复：AI 创业的十个真相》，呈现给读者。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5874f3b5678bf.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<h2 id="AI-科学家都是超级宅男"><a href="#AI-科学家都是超级宅男" class="headerlink" title="AI 科学家都是超级宅男"></a>AI 科学家都是超级宅男</h2><p>创新工场本身主营的机构是投资和投后的机构，我们当然是看项目，看创始人，他们有 idea、方向，我们就会用基金投资它。</p>
<p>过去的互联网创业模式，已经非常经典地被《精益创业》描述：</p>
<p>几个小朋友随便做个产品上去，能融资就融资，不能融资就拉倒。怎么样去惠及用户，迭代产品，之后变现，成为经典的模式。<br>这个创业的模式，它的红利时代已经过去了。当然以后还会有，但是不会像以前那么多。创业的门槛大大提高了，因为人工智能是下一批创业方向，而人工智能创业里面很核心的人物其实是 AI 科学家， AI 的公司没有 AI 科学家是没戏的。</p>
<p>但是AI科学家往往都是超级宅男，自己宅在房间里面，整天做实验，突然你把他丢到一个残酷野蛮可怕的世界里，他自己创业成功率不是很高。</p>
<p>很多 AI 科学家一般这辈子从来没想过创业，现在突然想创业了，然后发现自己长板特别长，短板特别短：</p>
<p>他也许技术很牛，但是也许执行不够；<br>也许他的产品演示起来很好，但是一做起来都是Bug；<br>也可能他产品做得很不错，但是不懂市场；<br>或者懂市场但是不知道怎么去卖。<br>尤其 AI 本身又是一个 ToB 的业务，所以不是那么容易自己攒一个局。所以 <strong>AI 科学家需要懂商业的人，懂 ToB 的人，他需要工程师。</strong></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5874f3bc38fe1.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<h2 id="AI-创业“不美好”"><a href="#AI-创业“不美好”" class="headerlink" title="AI 创业“不美好”"></a>AI 创业“不美好”</h2><p>我们平时都会把 AI 创业讲得很美好，今天我就跟大家讲讲 AI 不美好的地方。</p>
<p>第一个就是：AI 科学家有短板。<br>这一点刚才已经说了，我们要想怎么帮“宅男”补足短板。</p>
<p>第二个就是：AI 创业很贵。<br>刚才讲的“精益创业”很便宜，因为几个小朋友不拿薪水，用零元就可以把第一个 App 推出去。<br>我们刚投资一家公司，投了一个月以后钱就用完了。我说你们不就八个人怎么钱就用完了，给了你好几百万。但他们说，光买机器就用了三百万。</p>
<p>第三个就是：<strong>AI 需要数据。</strong><br>识别一张图片，最少需要几十万张样本数据，甚至几百上千万。谁给你弄数据？<br>所以做人工智能投资有一个非常头大的地方：一下顶尖的人就投完了。</p>
<p>过去这两年我们就到处去扫，从最厉害的团队出来的无人驾驶公司投了两个，没投两个。然后就再也找不到团队了，因为有资格的人就那么多。</p>
<p>我们做互联网金融，扫完了以后大概投了三个，然后可能有一两个错过了机会，一两个没投，然后就没有了。</p>
<p>因为AI科学家就那么多，能够创业把事情打造到一个地步的就那么多。</p>
<p><strong>AI 的现状是“僧多粥少”。大家都去抢那几棵树，已经把树拱到天价了。我觉得 AI 这片土地需要“施肥”，而不是抢那些非常少的农作物。</strong></p>
<p>所以我们成立了“人工智能工程院”。我们可能花几千万把机器搞定，然后帮助十家二十家创业公司；我们从各种渠道拿到数据，AI 科学家可以做试验；我们试着让更多有潜力的 AI 科学家，能够考虑来创业这条路，帮他们把可能 95% 的失败率降低到 40%，这样的话我们就能够产生自己的价值。</p>
<p>当然，投靠创新工场，我们帮你解决所有问题，也要求自己的回报。本来可能五百万占股 10%，现在也许给我们 15%，我们觉得这样的话也就足够了。以后如果可以打造出独角兽，我们是有很多回报的。</p>
<p>这个工程院在得到金钱回报的话，至少得花掉两亿元人民币。但如果是我们施肥的，想必相比那些“农作物”会喜欢我们。</p>
<h2 id="两三年之后，AI-会像-Android-一样普及"><a href="#两三年之后，AI-会像-Android-一样普及" class="headerlink" title="两三年之后，AI 会像 Android 一样普及"></a><strong>两三年之后，AI 会像 Android 一样普及</strong></h2><p>长期来说，真的是永远只能由 AI 科学家来创业吗？其实不一定。</p>
<p>任何技术都有一条发展路径，一个很好的例子就是 Android。当年我们跟 CSDN 的蒋涛一起做移动开发者的大会。第一次大会的时候，我问现场观众：有多少人看好Android？大概有5个手。我问有多少人看好 Symbian？五百个手举起来。</p>
<p>但当时我们坚决相信 Android 才是未来的道路。只是因为平台不够。现在大学里面的 Android、 iOS 培训课程非常普及。你如果是一个计算机的学生，你自己自学也好，去做培训课也好，几个月之内你就可以开始做 Android 了。</p>
<p>AI 也是这样的状态。</p>
<p>要多久时间呢？我们大胆的假设两三年吧。这两三年里，我们工程院孵化科学家会是一个非常独特而有价值的方法。<strong>三年以后平台出来了，很多聪明的大学生可以自学。平台、工具越来越多，AI 会变得越来越容易用了。</strong></p>
<p>以后年轻人来创业，我觉得可能比现在的科学家创业更能成功。因为 <strong>创业需要有动机，有狼性，愿意拼命。本来就要把自己名声，身家全部赌进去的。</strong></p>
<p>有资格的人六个月就能成为 AI 工程师，有资格的人是指：数学天才</p>
<p>一位老教授，用三十年的功力弄出来一个新算法。这种可能性是存在的。<br>但真正能发力的其实还是年轻人。很多年轻人只是苦于没有一个平台。<br>我告诉大家一个秘密。</p>
<p>如果你是一个有资格的年轻人，我们只需要六个月就可以把你培训成为一个 AI 工程师。绝对不是你想象的二十年，三十年。这不像一个材料科学家、火箭专家——这种专家真的是需要三十年的功力。</p>
<p>那么，什么是有资格呢？</p>
<p>很不幸，不是所有的人。“有资格”简单来说就是：数学天才。</p>
<p>当然，这其中也涵盖了 <strong>统计、自动化、计算机</strong>。中国人口这么多，光是数学天才我们应该一年都要产生个几十万了。</p>
<p>假设有十万个数学小天才，那里面对AI有兴趣的可能就会有五万。（因为中国学生是特别愿意去追最热门的东西，最热门的定义是什么呢？很酷，能赚很多钱的。）<br>里面有两万个接触到了一些培训平台，花了六个月去做，这两万人里可能又有两千个是适合的领军人物。比如说他是AI领域的雷军、傅盛等等这些人。<br>这两千人最终才是我们最好的投资对象。我们的工作就是让这些人出现。<br>所以短期我们是抓着科学家来，再过三四年我们要把这些年轻人都培训出来。让他们认知这是创业最好的时机。所以这秘密就是：我们要挖掘中国所有的数学小天才，然后引导他们进入AI创业。</p>
<p>AI 接管人类？我们的问题是科幻小说看多了</p>
<p>我们应该怎样看待 AI 呢？</p>
<p>有人看到阿法狗战胜了李世石，瞬间就联想到了 AI 要接管人类。实际上，这其中还差十万八千里。</p>
<p><strong>AI里最难的问题之一，是跨领域的自然语言理解。要做到这一点，需要上下文的理解，需要跨领域的知识，还需要人类的“Common Sense”。</strong></p>
<p>例如我突然和你说：“中午还好没吃汉堡，麦当劳不好吃。”这句话所有人都明白什么意思，但是机器很难读懂。它可以把每一个字都识别正确，但仍然无法“理解”。</p>
<p>再例如：熨斗打开的不能去摸，沾了水的手不能碰电。这些东西不用讲我们都知道。但是计算机怎么会知道这些事情呢？<br>你怎么去教一个计算机跨领域的知识？你怎么教会它七情六欲？你怎么教会它什么是美？什么是爱？什么是宗教？什么是信仰？这些东西差得还非常远。</p>
<p>揣测可能发生的事情跟确信一定会发生的事情，这两个还是要分辨得很清楚的。任何刚才讲的 AI 不能做的事情，我们都无法揣测多久会被突破。有人说五年，有人说五十年，也有人说永远不会。</p>
<p>我觉得我们真正应该讨论的事情是 <strong>怎么用AI来创造价值</strong>，怎么让人类能够没有饥饿和寒冷，让每一个人都能有尊严的活着。</p>
<p>例如，未来很多蓝领和白领的工作都会被取代，也包括了记者。当然有些深度文章机器可能五十年也写的出来。但是如果你从网上攒一些资料，例如科大讯飞发布财报，产品多了30%，分析师说股票怎么样，未来人工智能被看好什么的，这种东西机器已经在写了。</p>
<p><strong>当机器能够把简单的工作取代的时候，当经过五秒以内思考的事情人都不用做的时候</strong>，当这么多人将可能失业的时候，这些失业者应该怎么做？我们如何去重新训练他们？孩子的教育是什么样的？怎么让人类继续的去寻找应该做的事情？也许造物者是不希望我们做这种无聊的工作，让我们都做有意义的事情，所以才用机器取代了我们。</p>
<p>刚才讲的这些事情都是十年内会发生的。</p>
<p>当然未来也可能是 AI 养活了全世界，我们也许都成为 AI 的宠物，在家里戴着 VR 头盔玩游戏。机器会不会有自我意识，会不会取代人，会不会成为物种，虽然未必不可能，但这些是未知的。</p>
<p>很不幸的是：我们科幻小说看多了。</p>
<p>“AI 新物种”“取代”“奴役”，这些当然可以被想象，但有更多必然的有意思的问题，更值得我们去思考。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5874f3bb17ac3.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>AI “低处的果实”还没摘完</p>
<p>人工智能有很多学派。符号学派、连接学派等等。但是除了深度学习以外的方法，经过多年被验证，是不太有发展的。</p>
<p>模拟人的分析方法，希望把它变成一个规律和专家系统，过去五十年已经证明了这个思路是不行的。当然也许某一天会有一个突破，但是直到那一天为止应该是不行的。</p>
<p>就我自己的背景来说。在1988年，我就开始做语音识别。当年第一套系统就是用完全机器学习的方法来做的非特定人的语音识别。</p>
<p>现在看起来这是一个特别小的方法：世界上有一个人能够从纸上读出语音，我的导师就要把这套方法变成一套专家系统。<br>当年就让我很坚定地认为：机器的构造跟人脑，跟人的思维方式其实是不一样的。我们硬要把A放到B其实是很困难的，就像我们不能逼自己去变成一个深度学习者，去分析事情——我们脑子思维就不是那样的，是不自然的。</p>
<p>用脑科学的方法制造人工智能，是一个未知的领域。未知的东西有它的魅力，你要做研究就要做未知，你要有了突破那就是创新。在学术领域你做每一件事情的衡量标准是：我要做别人从来没做过的东西。我们可以假设脑科学跟未来的 AI 是相关的，我们可以去证明这是或不是。但是从投资的角度来讲，押注的风险就太大了。</p>
<p>当年深度学习也是因为数据的不足，碰到了一些瓶颈。但近年我们看到有好几个特别大的变化：</p>
<p>第一个就是特别大量的数据在某些领域开始产生，而且我觉得我们目前还没有被用完。<br>第二个就是 GPU 的使用让我们能够更高效地、非常快速地做深度学习。<br>现在我觉得，所谓的深度学习的果实还远远没有被摘完。<strong>人工智能的应用来说百花齐放，一个一个大果实就在你面前。在这种情况下，你还要去种花，何必呢？</strong></p>
<p>我们把 GPU 和海量数据在全世界扫一遍，应该还够我们 VC 界吃个五年，所以从投资的角度这是非常清晰的事情。</p>
<p>再往下走，我觉得我们 AI 肯定不可以是只有深度学习。例如现在还有增强学习的方法，也在被探索。AlphaGo 里面也不是只存在一个方法。所以我觉得学术界其实应该开始帮助和探索更多的可能性，当我们把这两年的粮食吃完之后也许还有更好的机会。</p>
<p>我没有 AI 宗教信仰</p>
<p>当然未来 AI 也可能没有进一步的突破了。</p>
<p>如果没有的话，那就说明 AI 的黄金时代过去了。下面就是物联网或者其他什么的。作为投资机构，我们并没有一种 AI 宗教信仰，我们还是要把控灵活度。</p>
<p>就像移动互联网时代，当时我们应该是在业界最高调的移动互联网 VC。但是随后我们根据情况做了调整。</p>
<p>如果学术界跟产业界有一个合理的分工，我对未来五年投资界和产生价值非常乐观，对于所谓AI的泡沫我认为不会发生。当然有个别的案例会有泡沫，但是我认为能吃的粮食实在是太多了。</p>
<p>学术跟产业它的分工大概是这样：</p>
<p>一方面是一个很天然有机的分工；<br>另外一方面又是有一点羡慕嫉妒恨在里面。<br>一般来说学术界是看不起工业界的，但是在某一个时刻突然工业界的一个技术成熟了，在这个技术上学术界就做不到工业界的成就了。于是学术界就被逼的去做新的东西。例如：现在再去做人脸识别，学术界就已经打不过工业界了。所以在人工智能领域，很少见到一个老教授一生只研究一个命题。</p>
<p>AlphaGo 本身没有商业价值</p>
<p>AI 会带给我们什么价值呢？</p>
<p>我想先说说 AlphaGo。之所以 AlphaGo 如此引人注目，很大程度上是因为我们这样的专家把它讲得太悬。</p>
<p>之前我觉得围棋比国际象棋至少难十年或十五年，但后来结果证明我是过于悲观了。我过于悲观其实有很多理由。我当时认为围棋要比国际象棋难了一个天文数字，但天文数字也是数字。</p>
<p>在AlphaGo之前最好的人工智能棋手达到了业余五段。而 AlphaGo 最新的 Master 和职业九段之间的差距，大致相当于职业九段和业余九段的差距。这确实是很大的跳跃。</p>
<p>那为什么会有这样的现象呢？也就是说，为什么下围棋的人工智能进步幅度这么大呢？</p>
<p>其实有一个非常现实的理由，就是想挣钱的人不会去做围棋。你看 AlphaGo 的专家队伍也没那么了不起，就是二十个很厉害的机器学习专家。在谷歌里面可能有两千个这样的人，在微软里有一千个这样的人。原因在于微软和谷歌过去没有想拿两千个专家的力量打败围棋手，他们的更多时间都在做语音识别、人脸识别这些有价值的事情。</p>
<p>在这个没有价值的事情上 ，能用二十个专家就不错了。</p>
<h2 id="金融、医疗是有商业价值的-AI"><a href="#金融、医疗是有商业价值的-AI" class="headerlink" title="金融、医疗是有商业价值的 AI"></a>金融、医疗是有商业价值的 AI</h2><p>有商业价值的 AI，影响就巨大了。</p>
<p>AI 在数据量大的领域最易应用。这些数据最好被准确标注，自动化标注。</p>
<p>AI 在无摩擦的领域最容易应用。一个领域里面如果有制造、测试、物流这类摩擦，那就麻烦了。无摩擦的领域是什么？医疗是无摩擦，金融是无摩擦。</p>
<p>AI 在挣钱最多的领域容易应用。毫无疑问，最挣钱的又是金融。<br>所以 <strong>金融毫无疑问会是AI最快征服的领域。因为你的算法可以很快就变成钱。</strong></p>
<p>医疗也是一个特别巨大的领域。而且医疗相对传统，能产生增值的机会很大。而且它不是基于大数据的。<strong>最好的医生是什么，就是他自己是一个深度学习的机器，根据他的经验做了好多好多次。</strong></p>
<p>假设他判断了五千个病人，判对了很多，判错了一些，下面他的判断就会非常精准了。但一个好医生可能最多也就判断过五千个病人，但我们的数据是五千万的病人的级别。所以 <strong>医疗超越医生应该是一个非常必然的，全球性的趋势。</strong></p>
<p>但是AI 医疗需要突破一些隐私问题，可能会有一些挑战。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5874f3ba0cb62.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>机器人世界的大门，要靠智能驾驶来敲开</p>
<p>除了大数据应用之外，还有就是科幻型的应用了。包括机器人，无人驾驶这类领域。</p>
<p>目前看得非常清晰，而且全球达到共识就是无人驾驶。有时候你要做一个科幻型的东西，需要万事俱备，天时地利人和才能推动。但是一旦开始动它就不得了。就像以前我们的移动互联网改造了整个产业链，以前的 SP、诺基亚之类。这样的产业变革来临，基本旧的企业全部会死掉，换成一批新的。</p>
<p>出行就会是下一个产业。我们非常幸运，目前有了共享经济，还有电动车。这两个领域已经在推动了，可推动的过程中遇到了一些阻力。</p>
<p>现在无人驾驶一来，就会改变世界的经济格局。我相信，世界经济10%是和出行和运输相关的。<strong>虽然真正的无人驾驶到来可能还要十年，但是有些其他的事情可以更快地被做好。</strong></p>
<p>比如景区游览车，比如运输卡车。<br>你可能会问，如果自动驾驶技术暂时还不成熟，卡车下了高速公路怎么办？没问题，我们把仓库全停在高速公路旁边不就是了。</p>
<p>万一卡车看错路怎么办？那我们就重新修路，在路上放很多标志和传感器，这也不是很困难。</p>
<p>所以我们未来三五年我们就可以打很多补丁，让无人驾驶能够在很多有限的环境之下被使用，所以千万不要认为自动驾驶还有十年才来，现在跟我们无关。</p>
<p>我们很少看到有一个产业从头到尾全部都“投降”了。</p>
<p>哪一家汽车公司还敢不说无人驾驶？每一家都在拼命想办法去解决，整个产业力量都进来了。<br>资本的力量在全球都在投资无人驾驶的公司。<br>最新最酷的创业者，很多都在无人驾驶领域创业。<br>这是一个不可逆的必然趋势，会对各个行业做全新的布局。</p>
<p>例如，所有的司机该怎么办？没有车会停下来，停车场该怎么办？以后的汽车该什么样子？道路要提供什么传感器？哪些领域是最快能够赚最多钱的？</p>
<p>这些我们其实都不必太担心，因为那些最有商业嗅觉的人和最有科技能力的人已经在每天在推敲这个事情。他们，或者说我们一定会找到解决方案。</p>
<p>当一辆无人驾驶汽车可以在路上运行的时候，汽车之间就可以对话了。例如前面发生了车祸，我的车要做出避让。今天我的主人着急上班，你给我让路，我给你两毛钱行不行？</p>
<p>在这种情况下机器人就变得可行了。与其期待家里的机器人用陪小孩玩的方式进化，还不如期待无人驾驶汽车促进机器人的进化。</p>
<p>更多人工智能相关内容，请关注雷锋网。</p>
<p>雷锋网原创文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201701/OHG9MiEiL6cmJxCD.html&quot;&gt;史中&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“重仓”人工智能，是李开复和创新工场未来几年的方向。但是，他面临一个很重要的问题：现在的 AI 创业，核心是 AI 科学家，而“文能起笔安天下，武能上马定乾坤”的 AI 科学家凤毛麟角，用他的话说“该创业的都创业了”。&lt;/p&gt;
&lt;p&gt;这时，产业在面临一步棋。那就是：如何把一个普通的 AI 科学家变成“创业英雄”。&lt;/p&gt;
&lt;p&gt;作为三十年前就开始研究人工智能的李开复，觉得自己“技术范儿”的创新工场有能力推动这步棋，并且在这一步棋中获得稳固的战略优势。&lt;/p&gt;
&lt;p&gt;李开复告诉雷锋网(公众号：雷锋网)，&lt;strong&gt;AI 创业现在是科学家的天下，之后是数学家的天下，将来是普通人的天下。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Business" scheme="http://ipcreator.me/tags/Business/"/>
    
  </entry>
  
  <entry>
    <title>谷歌发布全新轻型机器学习架构：可直接载于设备端的AI系统</title>
    <link href="http://ipcreator.me/2017/02/19/BusinessAI/ai-on-terminal-of-google/"/>
    <id>http://ipcreator.me/2017/02/19/BusinessAI/ai-on-terminal-of-google/</id>
    <published>2017-02-19T15:59:56.000Z</published>
    <updated>2017-02-19T06:03:00.876Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201702/YHWql6D0Higks9mE.html" target="_blank" rel="external">雷锋网 亚萌</a></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589d9707291a6.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>雷锋网(公众号：雷锋网)消息，谷歌近日发布了全新应用于可穿戴设备的Android Wear 2.0系统和相关设备，而这一批系统和设备，将具有一项新技能：运行谷歌全新的“设备端”机器学习技术。下面是对该项技术的介绍，原文载于Googleblog，由雷锋网编译整理。</p>
  <a id="more"></a>
<h2 id="设备端的机器智能"><a href="#设备端的机器智能" class="headerlink" title="设备端的机器智能"></a>设备端的机器智能</h2><p>为了打造会话理解和图像识别领域领先的技术，我们通常将多种先进的机器学习技术（比如深度神经网络和基于图的机器学习）结合起来使用。然而，以上提到的机器学习系统往往需要大量的计算能力和存储空间。可是，如果想 <strong>要在不论是否连接到的云端的情况下，个人手机、智能手表和IoT设备都能运行机器智能</strong>，又要怎么办呢？</p>
<p>昨天，我们发布了Android Wear 2.0系统和全新的可穿戴设备，这些设备将会运行 <strong>谷歌首个完全“设备端”（on-device）的机器学习技术</strong>，首先用于“智能回复”（<strong>Smart Reply</strong>）这一功能上。这个“设备端”机器学习系统由谷歌Expander研发团队开发，在不需要接入云端的情况下，将“智能回复”功能应用于各第三方的讯息App上。所以现在，你若在手表上收到了一条信息，轻敲回复选项就可以了。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589d94d13f236.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>这个系统的研发从去年开始，当时我们的团队正在为Allo和Inbox里的会话理解开发相应的机器学习系统。 Android Wear团队找到我们，并询问将“智能回复”直接应用在智能设备上的可能性。因为智能设备的计算和存储量都是有限的，我们很快就判断这种移植根本不可能。</p>
<p>但我们的产品经理Patrick McGregor意识到这对于Expander团队来说是个独特的挑战和机会，可以从头开始 <strong>设计一个全新的、轻型机器学习架构</strong>，这不仅让“智能回复”应用于Android Wear系统，还应用于其它众多设备端的移动应用程序。于是，我们与Android Wear团队的Tom Rudick、Nathan Beach等同事一起，开始着手建立这个全新的系统。</p>
<h2 id="与“投影”一起进行学习"><a href="#与“投影”一起进行学习" class="headerlink" title="与“投影”一起进行学习"></a>与“投影”一起进行学习</h2><p>建立轻型会话理解模型的一个简单策略，就是在设备上 <strong>创建一个小型的包含一般规则的字典（输入—&gt;回复映射），并且在推理阶段，使用一个朴素的查找策略。</strong> 这个可以执行简单的预测任务，包括使用一些特征进行分类 （比如对文本里的情感进行二元分类，例如“我爱这部电影”传递出一种积极的情感，而“演员的表演很糟糕”则传达一种消极情感）。但是，它的规模并没有大到去执行包含丰富词汇和语言变化的复杂自然语言任务。</p>
<p>另一方面，<strong>机器学习模型，比如RNN（如LSTM），结合图学习（graph learning），已经被证明是用于自然语言理解的复杂序列学习里极强悍的工具，包括“智能回复”。</strong> 然而，为了适应设备存储空间而将这么丰富的模型进行压缩，并在低计算成本的情况下产生鲁棒的预测（快速按需），这是非常具有挑战性的。在我们的早期实验里，受到限制的模型仅仅预测一小批回复语句，我们还使用其他包括量化（quantization）、字母级别模型等技术，并不能产生有用的结果。</p>
<p>所以，我们为设备端机器学习系统建立了一种不同的解决方法，我们一开始使用了一个快速、有效的机制，<strong>将相似的传入讯息聚集起来，并将他们投影到相似的（附近的）位向量表征里。虽然执行这个投影步骤有几种方法，比如使用单词嵌入（word embeddings）或者编码网络（encoder networks），我们应用了局部敏感哈希算法（locality sensitive hashing ，LSH) 的修改版本来降低维度，把数百万个独特的单词转换为短小的、固定长度的位序列。</strong></p>
<p>这允许我们为一条传入讯息的投影进行非常 <strong>快速、即时（on-the-fly）</strong> 的计算，占用很少的内存，由于我们并不需要存储传入讯息、单词嵌入甚至是用来训练的整个模型。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589d94fcf1367.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>投影步骤：相似讯息组合在一起，投射到邻近向量里。比如，“hey, how’s it going?”与 “How’s it going buddy?” 这两条讯息内容是相似的，或许会投射到同样的向量 11100011。另一条相似的讯息“Howdy, everything going well?”被映射到一个附近的向量11100110，与前两条相差2位。</p>
<p>接下来，使用我们的 <strong>半监督图学习框架</strong> ，我们的系统把传入讯息和投影结合在一起，<strong>共同训练一个“讯息投入模型”</strong>，学习预测可能的回复语句。图学习框架能够训练一个鲁棒的模型，通过从各种资源里找出的语义关系——讯息/回复互动、单词/短语相似性、语义集群信息——学习有用的投影操作，来映射良好的回复语句预测。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589d94fd9b2ec.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>学习步骤：（顶部）的讯息、投射和相应回复语句一起，在一个机器学习框架里，同步学习一个“讯息投射模型”。（底部）讯息投射模型学习，将回复语句与相应传入讯息的投射联系在一起。比如，模型投射两种不同的讯息“Howdy, everything going well?”和“How’s it going buddy?”投射到附近的位向量里，并且学习着将其映射成相关的回复语句（底部左图）。</p>
<p>值得注意的是，就像我们前面提到的，<strong>尽管“讯息投影模型”用复杂的机器学习架构和云计算进行训练，但是模型本身在设备上存在和运行。</strong> 设备上的App可以传递用户的传入讯息，并从设备端模型上接受回复语句预测选项，而不需要离开设备去获得数据。这个模型也可以适应用户书写风格和个人偏好，从而提供一种个性化的体验。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589d94fe518d7.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>推理步骤：模型将学习好的映射应用于一条传入讯息（或讯息序列）里，并且推荐相关的多条回复语句。推理过程在设备上运行，使得模型适应用户数据和个性化书写风格。</p>
<p>为了得到开箱即用的设备端系统，我们必须要进行一些额外的改进，比如优化设备上的计算速度、从模型中生成丰富多样的回复语句等等。不久之后，我们将进行一些科学发表，介绍更多设备端机器学习系统工作的细节。</p>
<p>与你的手腕交谈</p>
<p>当我们踏上从无到有打造这项技术的旅程时，一开始我们并不确定，这些模型的预测结果质量是否合格。我们非常惊讶地发现，它能在非常有限的计算能力和存储资源的情况下，在安卓的可穿戴设备上工作良好，对此我们非常兴奋。我们期待继续改善模型，为用户提供共更加愉悦的会话体验，我们将会提升这个设备端的机器学习平台，接下来的几个月里将其应用于新的领域。</p>
<p>现在，你可以在你的Google手表或任何运行Android Wear 2.0系统的手表上使用这一功能。这一功能已经可以在Google Hangouts、Google Messenger和众多第三方App上使用。我们也 <strong>会为第三方穿戴设备App的开发者提供API接口。</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201702/YHWql6D0Higks9mE.html&quot;&gt;雷锋网 亚萌&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201702/589d9707291a6.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;雷锋网(公众号：雷锋网)消息，谷歌近日发布了全新应用于可穿戴设备的Android Wear 2.0系统和相关设备，而这一批系统和设备，将具有一项新技能：运行谷歌全新的“设备端”机器学习技术。下面是对该项技术的介绍，原文载于Googleblog，由雷锋网编译整理。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Google" scheme="http://ipcreator.me/tags/Google/"/>
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>智能手机 + 机器学习 = 个人终端的未来</title>
    <link href="http://ipcreator.me/2017/02/19/BusinessAI/the-future-of-personal-terminal/"/>
    <id>http://ipcreator.me/2017/02/19/BusinessAI/the-future-of-personal-terminal/</id>
    <published>2017-02-19T15:58:06.000Z</published>
    <updated>2017-02-19T06:03:00.876Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201609/SjAa50u2XrpIj2zx.html" target="_blank" rel="external">陈杨英杰</a></p>
<p>今天是 iPhone 7 发布的日子，无论你是不是果粉，无论是主动关注还是被动接受，所有人的信息焦点只有一个，那就是苹果。作为技术创新的长期领导者，苹果已经一次又一次给我们带来各种意想不到的新体验，今天的 iPhone 7 更是如此。那么，就让我们从小小的智能手机开始聊一聊机器学习将如何改变个人终端的未来。</p>
<p>尽管新的产品、新的功能层出不穷，但人们不禁好奇，究竟是什么因素在将不可能变为可能。</p>
<p>答案大概可以归结为四个字：“机器学习”。<br><img src="http://static.leiphone.com/uploads/new/article/740_740/201609/57d12cea58d53.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
  <a id="more"></a>
<p>iPhone 7 发布会</p>
<p>无论我们是否真的意识到，机器学习已经在我们的日常生活中应用很长时间了。事实上，我们没有注意到它的存在反而意味着这个技术非常有效，因为每天当着用户面处理学习如此大量的实时数据却不被察觉，显然这种方式是可以令人接受的。然而，最近这个词频频出现在各种商业和大众媒体上，在人工智能的专业技术人员和消费者中间引发了大量深入的讨论。</p>
<p>苹果公司早就在人工智能领域奠定了坚实的基础。在史蒂文·李维（Steven Levi）发表在 iBrain 上的文章中，其深入剖析了苹果错综复杂的机器学习技术。尽管很大程度上 Siri 只是苹果在机器学习方面的“门面”，但毋庸置疑的是，苹果在这方面的研发并不止于此，<strong>机器学习技术已经被应用到苹果的各类设备和应用中。例如，滑动屏幕会出现你想要打开的应用名单，或是指出你预订的酒店在地图的位置。</strong> 这个直接面向消费者的人工智能应用，在科技行业树立了一个标杆，不仅成功提升了品牌价值，也让消费者对数字体验有了更高的期待。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201609/57d191fada760.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>Siri</p>
<p>尽管 Siri 是一个非常受欢迎的人工智能应用，但她也不是没有竞争对手。虚拟助手 Cortana（微软小娜）的出现加剧了科技公司之间的竞争，现在鹿死谁手还未可知。这给苹果带来了巨大的压力，苹果很快意识到了问题，并开始不断采取措施加强他们的机器学习部门，目的就是为了在这一领域保持一个领先地位，尤其是要赶在新产品发布之前。最近的例子就是苹果收购了专注于机器学习的人工智能公司 Turi 。此外，苹果公司还宣布，除了已经搭载了 Siri 功能的苹果手机，他们还准备将 Siri 背后的深度学习技术集成到苹果的笔记本电脑、手表和电视上。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201609/57d13dd2cb45b.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>iWatch</p>
<p>更深远的影响在于，这些努力是为了把机器学习运用到苹果的整个产品链中，此举标志着苹果的品牌和零售将开始一种全方位的个性化体验服务。<br>用户已经开始期待基于深度学习其实时行为反应的高级定制化内容。苹果公司已经意识了只有机器学习才能满足如此大规模的用户需求。<strong>苹果通过增强型机器学习算法提高内容准确性和时效性，为用户提供了一对一的个性化体验服务</strong>，这些最终将转化为公司的品牌忠诚度，并为公司增加营收。</p>
<p>消费者对个性化体验服务的期望只会不断增加，而苹果公司已经明确表示他们正在想方设法满足这些需求。这也意味着面对竞争，需要不断努力加强自身的深度学习技术，才能跟上发展。这不仅适用于苹果的竞争对手，也对其合作伙伴提出了更高要求。</p>
<p>通过把机器学习集成到苹果的产品中，品牌和零售商就能轻松地为消费者提供他们一直期待的购物体验。</p>
<p>那些不敢冒险的人终将会被时代所淘汰。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201609/57d1930691a2a.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>GPU 芯片</p>
<p>具体来说，对于计算机中的神经网络和机器学习中的其他方法的研究自 70 年代就开始了。深度学习是机器学习的一部分，通过算法对数据进行关联和分类。深度学习系统通常需要使用复杂的神经网络和大量的计算资源。GPU芯片是一种专门用于图像计算的芯片，在带有屏幕的个人终端设备上十分常见，神经网络大都在GPU上运行。</p>
<p>麻省理工学院的研究团队研发出了一款名为 Eyeriss 的芯片，将能耗减少到了 GPU 平均水平的 1/10。因此，<strong>这为智能手机上的应用打开了新的可能性，可以直接在移动设备上执行强大的人工智能算法，而不需要将数据上传到互联网进行云计算。</strong> 这款专为深度学习而优化的计算机芯片，能够让人工智能变得更为流行。</p>
<p>MIT 研发的这款168核的芯片能够识别人脸、其他物体，甚至是声音。该芯片可适用于智能手机、自动驾驶汽车、机器人、无人机和其他设备。普通 GPU 芯片一般是很多处理单元共享一个内存条，而Eyeriss芯片每个处理单元都有自己的内存，而且它可以在向处理单元发送数据前对数据进行压缩。Eyeriss的每个处理单元都可以直接与相邻的处理单元进行交流，如果需要共享数据，不需要将数据传送到主内存。　</p>
<p>配备这种新芯片后，未来的智能手机不仅能够更好地执行日常任务，还可以进行原本需要外部资源投入的人工智能和深度学习任务。而 <strong>一个内置 Eyeriss 芯片的智能手机可以执行更多的基本任务，诸如追踪用户的偏好、时间表和使用模式，能更好地优化移动体验，这意味着一种截然不同的绝佳用户体验。</strong></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201609/57d193dccf307.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>AI助理（配图：《钢铁侠》）</p>
<p>我们对普通用户每天的 <strong>应用场景进行归类</strong> 后，搭载了 AI 助理的智能手机可以 <strong>清楚的判断用户的各种使用情况</strong>，是在应用商店下载了游戏，还是对已安装的应用进行更新，都一目了然。芯片会查看一些手机信息，比如应用程序的大小，代码特点，用户使用量的统计数据，线上意见等，并向用户 <strong>推荐一些可能感兴趣的内容</strong>。例如，某个用户在市中心闲逛时突然想找去酒吧玩儿，他们也许对机载 AI 助理说：“推荐一个我没去过的好酒吧。”此时，AI 就会开始查询银行对账单，判断用户多长时间去一次酒吧，每次平均花费多少钱，然后找到评论这些酒吧的关键词，诸如“氛围好”或这“啤酒好”等，最后找到一个附近的新酒吧推荐给用户。目前，所有这些计算都是由异地的服务器统一处理后传回用户的手机，很难将其他数据和应用整合到设备上，并有效管理用户数据。</p>
<p>机载 AI 助理将彻底改变个人终端计算设备的发展，首当其冲的就是智能手机。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201609/SjAa50u2XrpIj2zx.html&quot;&gt;陈杨英杰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;今天是 iPhone 7 发布的日子，无论你是不是果粉，无论是主动关注还是被动接受，所有人的信息焦点只有一个，那就是苹果。作为技术创新的长期领导者，苹果已经一次又一次给我们带来各种意想不到的新体验，今天的 iPhone 7 更是如此。那么，就让我们从小小的智能手机开始聊一聊机器学习将如何改变个人终端的未来。&lt;/p&gt;
&lt;p&gt;尽管新的产品、新的功能层出不穷，但人们不禁好奇，究竟是什么因素在将不可能变为可能。&lt;/p&gt;
&lt;p&gt;答案大概可以归结为四个字：“机器学习”。&lt;br&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201609/57d12cea58d53.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Smart Phone" scheme="http://ipcreator.me/tags/Smart-Phone/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>深度学习框架太抽象？其实不外乎这五大核心组件</title>
    <link href="http://ipcreator.me/2017/02/19/Program/TensorFlow/core-components-from-deep-learning-framework/"/>
    <id>http://ipcreator.me/2017/02/19/Program/TensorFlow/core-components-from-deep-learning-framework/</id>
    <published>2017-02-19T15:57:20.000Z</published>
    <updated>2017-02-19T06:03:00.878Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.leiphone.com/news/201701/DZeAwe2qgx8JhbU8.html" target="_blank" rel="external">本文作者：恒亮</a></p>
<p>许多初学者觉得深度学习框架抽象，虽然调用了几个函数/方法，计算了几个数学难题，但始终不能理解这些框架的全貌。<br>为了更好地认识深度学习框架，也为了给一些想要自己亲手搭建深度学习框架的朋友提供一些基础性的指导，日前来自苏黎世联邦理工学院计算机科学系的硕士研究生Gokula Krishnan Santhanam在博客上撰文，概括了大部分深度学习框架都会包含的五大核心组件，为我们详细剖析了深度学习框架一般性的内部组织结构。以下由雷锋网(公众号：雷锋网)编译。</p>
<p>Gokula Krishnan Santhanam认为，大部分深度学习框架都包含以下五个核心组件：<br>&gt;</p>
<ol>
<li>张量（Tensor）</li>
<li>基于张量的各种操作</li>
<li>计算图（Computation Graph）</li>
<li>自动微分（Automatic Differentiation）工具</li>
<li><p>BLAS、cuBLAS、cuDNN等拓展包</p>
<a id="more"></a>
<h2 id="1-张量（Tensor）"><a href="#1-张量（Tensor）" class="headerlink" title="1. 张量（Tensor）"></a>1. 张量（Tensor）</h2><p> 张量是所有深度学习框架中最核心的组件，因为后续的所有运算和优化算法都是基于张量进行的。几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将 <strong>标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。</strong></p>
<p> 举例来说，我们可以将任意一张RGB彩色图片表示成一个三阶张量（三个维度分别是图片的高度、宽度和色彩数据）。如下图所示是一张普通的水果图片，按照RGB三原色表示，其可以拆分为三张红色、绿色和蓝色的灰度图片，如果将这种表示方法用张量的形式写出来，就是图中最下方的那张表格。</p>
<p> <img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5880dff2d8158.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p> <img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5880dff3b7b49.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p> <img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5880dff1dcf2b.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p> 图中只显示了前5行、320列的数据，每个方格代表一个像素点，其中的数据[1.0, 1.0, 1.0]即为颜色。假设用[1.0, 0, 0]表示红色，[0, 1.0, 0]表示绿色，[0, 0, 1.0]表示蓝色，那么如图所示，前面5行的数据则全是白色。</p>
<p> 将这一定义进行扩展，我们也可以用四阶张量表示一个包含多张图片的数据集，其中的四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。</p>
<p> 将各种各样的数据抽象成张量表示，然后再输入神经网络模型进行后续处理是一种非常必要且高效的策略。因为如果没有这一步骤，我们就需要根据各种不同类型的数据组织形式定义各种不同类型的数据操作，这会浪费大量的开发者精力。更关键的是，当数据处理完成后，我们还可以方便地将张量再转换回想要的格式。例如Python NumPy包中numpy.imread和numpy.imsave两个方法，分别用来将图片转换成张量对象（即代码中的Tensor对象），和将张量再转换成图片保存起来。</p>
<h2 id="2-基于张量的各种操作"><a href="#2-基于张量的各种操作" class="headerlink" title="2. 基于张量的各种操作"></a>2. 基于张量的各种操作</h2><p> <img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5880e0a603465.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p> 有了张量对象之后，下面一步就是一系列针对这一对象的数学运算和处理过程。</p>
<p> 其实，整个神经网络都可以简单视为为了达到某种目的，针对输入张量进行的一系列操作过程。而所谓的“学习”就是不断纠正神经网络的实际输出结果和预期结果之间误差的过程。这里的一系列操作包含的范围很宽，可以是简单的矩阵乘法，也可以是卷积、池化和LSTM等稍复杂的运算。而且各框架支持的张量操作通常也不尽相同，详细情况可以查看其官方文档（如下为NumPy、Theano和TensorFlow的说明文档）。</p>
<p> NumPy：<a href="http://www.scipy-lectures.org/intro/numpy/operations.html" target="_blank" rel="external">http://www.scipy-lectures.org/intro/numpy/operations.html</a><br> Theano：<a href="http://deeplearning.net/software/theano/library/tensor/basic.html" target="_blank" rel="external">http://deeplearning.net/software/theano/library/tensor/basic.html</a><br> TensorFlow：<a href="https://www.tensorflow.org/api_docs/python/math_ops/" target="_blank" rel="external">https://www.tensorflow.org/api_docs/python/math_ops/</a></p>
<p> 需要指出的是，大部分的张量操作都是基于类实现的（而且是抽象类），而并不是函数（这一点可能要归功于 <strong>大部分的深度学习框架都是用面向对象的编程语言实现的</strong>）。这种实现思路一方面允许开发者将各种类似的操作汇总在一起，方便组织管理。另一方面也保证了整个代码的复用性、扩展性和对外接口的统一。总体上让整个框架更灵活和易于扩展，为将来的发展预留了空间。</p>
<h2 id="3-计算图（Computation-Graph）"><a href="#3-计算图（Computation-Graph）" class="headerlink" title="3. 计算图（Computation Graph）"></a>3. 计算图（Computation Graph）</h2><p> 有了张量和基于张量的各种操作之后，下一步就是将各种操作整合起来，输出我们需要的结果。</p>
<p> 但不幸的是，随着操作种类和数量的增多，有可能引发各种意想不到的问题，包括多个操作之间应该并行还是顺次执行，如何协同各种不同的底层设备，以及如何避免各种类型的冗余操作等等。这些问题有可能拉低整个深度学习网络的运行效率或者引入不必要的Bug，而计算图正是为解决这一问题产生的。</p>
<p> 据雷锋网了解，计算图首次被引入人工智能领域是在2009年的论文《Learning Deep Architectures for AI》。当时的图片如下所示，作者用不同的占位符（*，+，sin）构成操作结点，以字母x、a、b构成变量结点，再以有向线段将这些结点连接起来，组成一个表征运算逻辑关系的清晰明了的“图”型数据结构，这就是最初的计算图。</p>
<p> <img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5880e0965f90a.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p> 后来随着技术的不断演进，加上脚本语言和低级语言各自不同的特点（概括地说，脚本语言建模方便但执行缓慢，低级语言则正好相反），因此业界逐渐形成了这样的一种开发框架： <strong> 前端用Python等脚本语言建模，后端用C++等低级语言执行（这里低级是就应用层而言），以此综合了两者的优点。</strong> 可以看到，这种开发框架大大降低了传统框架做跨设备计算时的代码耦合度，也避免了每次后端变动都需要修改前端的维护开销。而这里，在前端和后端之间起到关键耦合作用的就是计算图。</p>
<p> <strong>将计算图作为前后端之间的中间表示（Intermediate Representations）可以带来良好的交互性</strong>，开发者可以将Tensor对象作为数据结构，函数/方法作为操作类型，将特定的操作类型应用于特定的数据结构，从而定义出类似MATLAB的强大建模语言。</p>
<p> 需要注意的是，通常情况下开发者不会将用于中间表示得到的计算图直接用于模型构造，因为这样的计算图通常包含了大量的冗余求解目标，也没有提取共享变量，因而通常都会经过依赖性剪枝、符号融合、内存共享等方法对计算图进行优化。</p>
<p> 目前，各个框架对于计算图的实现机制和侧重点各不相同。例如Theano和MXNet都是以隐式处理的方式在编译中由表达式向计算图过渡。而Caffe则比较直接，可以创建一个Graph对象，然后以类似Graph.Operator(xxx)的方式显示调用。</p>
<p> <strong>因为计算图的引入，开发者得以从宏观上俯瞰整个神经网络的内部结构，就好像编译器可以从整个代码的角度决定如何分配寄存器那样，计算图也可以从宏观上决定代码运行时的GPU内存分配，以及分布式环境中不同底层设备间的相互协作方式。</strong> 除此之外，现在也有许多深度学习框架将计算图应用于模型调试，可以实时输出当前某一操作类型的文本描述。</p>
<h2 id="4-自动微分（Automatic-Differentiation）工具"><a href="#4-自动微分（Automatic-Differentiation）工具" class="headerlink" title="4. 自动微分（Automatic Differentiation）工具"></a>4. 自动微分（Automatic Differentiation）工具</h2><p> <strong>计算图带来的另一个好处是让模型训练阶段的梯度计算变得模块化且更为便捷，也就是自动微分法。</strong></p>
<p> 正如前面提到的，因为我们可以将神经网络视为由许多非线性过程组成的一个复杂的函数体，而计算图则以模块化的方式完整表征了这一函数体的内部逻辑关系，因此微分这一复杂函数体，即求取模型梯度的方法就变成了在计算图中简单地从输入到输出进行一次完整遍历的过程。与自动微分对应，业内更传统的做法是符号微分。</p>
<p> <strong>符号微分即常见的求导分析。针对一些非线性过程（如修正线性单元ReLU）或者大规模的问题，使用符号微分法的成本往往非常高昂，有时甚至不可行（即不可微）。因此，以上述迭代式的自动微分法求解模型梯度已经被广泛采用。并且由于自动微分可以成功应对一些符号微分不适用的场景，目前许多计算图程序包（例如Computation Graph Toolkit）都已经预先实现了自动微分。</strong></p>
<p> 另外，由于每个节点处的导数只能相对于其相邻节点计算，因此实现了自动微分的模块一般都可以直接加入任意的操作类中，当然也可以被上层的微分大模块直接调用。</p>
<h2 id="5-BLAS、cuBLAS、cuDNN等拓展包"><a href="#5-BLAS、cuBLAS、cuDNN等拓展包" class="headerlink" title="5. BLAS、cuBLAS、cuDNN等拓展包"></a>5. BLAS、cuBLAS、cuDNN等拓展包</h2><p> 现在，通过上述所有模块，我们已经可以搭建一个全功能的深度学习框架：<strong>将待处理数据转换为张量，针对张量施加各种需要的操作，通过自动微分对模型展开训练，然后得到输出结果开始测试。这时还缺什么呢？答案是运算效率。</strong></p>
<p> 由于此前的大部分实现都是基于高级语言的（如Java、Python、Lua等），而即使是执行最简单的操作，高级语言也会比低级语言消耗更多的CPU周期，更何况是结构复杂的深度神经网络，因此运算缓慢就成了高级语言的一个天然的缺陷。</p>
<p> 目前针对这一问题有两种解决方案。</p>
<p> 第一种方法是模拟传统的编译器。就好像传统编译器会把高级语言编译成特定平台的汇编语言实现高效运行一样，这种方法将高级语言转换为C语言，然后在C语言基础上编译、执行。为了实现这种转换，每一种张量操作的实现代码都会预先加入C语言的转换部分，然后由编译器在编译阶段将这些由C语言实现的张量操作综合在一起。目前pyCUDA和Cython等编译器都已经实现了这一功能。</p>
<p> 第二种方法就是前文提到的，利用脚本语言实现前端建模，用低级语言如C++实现后端运行，这意味着高级语言和低级语言之间的交互都发生在框架内部，因此每次的后端变动都不需要修改前端，也不需要完整编译（只需要通过修改编译参数进行部分编译），因此整体速度也就更快。</p>
<p> 除此之外，由于低级语言的最优化编程难度很高，而且大部分的基础操作其实也都有公开的最优解决方案，因此另一个显著的加速手段就是利用现成的扩展包。例如最初用Fortran实现的BLAS（基础线性代数子程序），就是一个非常优秀的基本矩阵（张量）运算库，此外还有英特尔的MKL（Math Kernel Library）等，开发者可以根据个人喜好灵活选择。</p>
<p> <img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5880e27618064.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p> 值得一提的是，一般的BLAS库只是针对普通的CPU场景进行了优化，但目前大部分的深度学习模型都已经开始采用并行GPU的运算模式，因此 <strong>利用诸如NVIDIA推出的针对GPU优化的cuBLAS和cuDNN等更据针对性的库可能是更好的选择。</strong></p>
<p> 运算速度对于深度学习框架来说至关重要，例如同样训练一个神经网络，不加速需要4天的时间，加速的话可能只要4小时。在快速发展的人工智能领域，特别是对那些成立不久的人工智能初创公司而言，这种差别可能就会决定谁是先驱者，而谁是追随者。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p> 原文作者在文末指出：<strong>为了向开发者提供尽量简单的接口，大部分深度学习框架通常都会将普通的概念抽象化</strong>，这可能是造成许多用户感知不到上述五点核心组件的重要原因。</p>
<p> 而这也正是作者写本文的初衷：他希望开发者能够通过了解不同框架之间的一些相似特性，更好地认识和使用一个深度学习框架。另一方面，对于那些不仅对学会使用深度学习框架感兴趣，还打算亲手搭建一个深度框架的朋友，作者认为了解各框架的内部组成和一些共性的特征也是迈向成功的重要一步。他真诚地相信，<strong>一个优秀的工程师不仅应该“知其然”，更应该“知其所以然”</strong>。</p>
<p> 来源：<a href="http://www.leiphone.com/news/201701/DZeAwe2qgx8JhbU8.html" target="_blank" rel="external">medium</a>，雷锋网编译<br> 雷锋网版权文章，未经授权禁止转载。详情见转载须知。</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.leiphone.com/news/201701/DZeAwe2qgx8JhbU8.html&quot;&gt;本文作者：恒亮&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;许多初学者觉得深度学习框架抽象，虽然调用了几个函数/方法，计算了几个数学难题，但始终不能理解这些框架的全貌。&lt;br&gt;为了更好地认识深度学习框架，也为了给一些想要自己亲手搭建深度学习框架的朋友提供一些基础性的指导，日前来自苏黎世联邦理工学院计算机科学系的硕士研究生Gokula Krishnan Santhanam在博客上撰文，概括了大部分深度学习框架都会包含的五大核心组件，为我们详细剖析了深度学习框架一般性的内部组织结构。以下由雷锋网(公众号：雷锋网)编译。&lt;/p&gt;
&lt;p&gt;Gokula Krishnan Santhanam认为，大部分深度学习框架都包含以下五个核心组件：&lt;br&gt;&amp;gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;张量（Tensor）&lt;/li&gt;
&lt;li&gt;基于张量的各种操作&lt;/li&gt;
&lt;li&gt;计算图（Computation Graph）&lt;/li&gt;
&lt;li&gt;自动微分（Automatic Differentiation）工具&lt;/li&gt;
&lt;li&gt;&lt;p&gt;BLAS、cuBLAS、cuDNN等拓展包&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>技术大牛带你走向机器学习“正道”</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Concepts/right-way-of-master-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Concepts/right-way-of-master-machine-learning/</id>
    <published>2017-02-19T15:57:06.000Z</published>
    <updated>2017-02-19T06:03:00.876Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201701/mY1HbudReeTtJHw4.html" target="_blank" rel="external">雷锋网 亚峰</a></p>
<p>导语：现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉。</p>
<p>雷锋网按：“算法”这两字在人工智能圈已然成为“高大上”的代名词，由于不少在校生和职场新人对它的过度迷恋，多名 AI 资深人士均对这一现象表示担忧。李开复曾这样说到：</p>
<p>现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉，更缺乏解决实际问题所必须的数据资源。<br>随着开源框架层出不穷，人工智能产品化和商业化进程不断加速，使得算法的门槛逐渐降低，但对工程的要求不断在提高。这种情况下，实际应用和工程能力基础扎实的技术人才变得异常抢手。</p>
<p>其实 AI 新人们在进入职场后也愈发意识到这个问题，那他们该如何提升自己的实战能力？</p>
<p>雷锋网特邀王刚为大家讲述机器学习的实战与应用，王刚根据工程、产品、业务等多个维度帮大家梳理如何系统地去学习机器学习。</p>
  <a id="more"></a>
<p>嘉宾介绍：</p>
<p>王刚，前乐视大数据总监，现任某电商平台大数据总监。10 年大数据领域工作经验，具有 Hadoop 和 Spark 生态相关技术的实际应用经验。目前专注于机器学习，搜索和推荐系统的设计和开发。</p>
<p>以下为王刚所撰写的正文：</p>
<p>机器学习对很多初学者来说，最大的学习困难和障碍就是模型、算法、“眼花缭乱”的数学公式所带来的抽象感，无法有效的建立起直觉上的理解。所以本文的目的是尝试给初学者具体的学习方式建议，以帮助初学者打通机器学习的任督二脉，然后通过不断的学习和实践，使得自己在机器学习领域的专业能力持续提升。</p>
<p>机器学习与人工智能、深度学习之间的关系</p>
<p>当前被提及的高频词语是“AI人工智能”、“机器学习”、“深度学习”。那这些词语背后所代表的技术之间到底是什么关系呢？充分的理解这个关系，有利于建立起更加系统的专业学习框架。</p>
<p>首先，我们要搞明白机器学习到底学习的是什么，答案是模型“参数”，比如Y=AX+B是个机器学习的模型，通过样本数据，可以学习出参数A和B的确定值。然后基于这两个参数，对模型进行泛化，即对给定的X对Y进行预测。明白了机器学习到底是学习什么之后，我们一起看看下图来搞清楚机器学习与人工智能和深度学习之间的关系。</p>
<p>技术大牛带你走向机器学习“正道”：小朋友才迷信算法，大人们更重视工程实践</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/58888f9bedd1f.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>如上图所示，人工智能是最大的一个范畴，人工智能的实现目前看主要有两种途径：一种是基于脑科学的方式来实现智能。另一种是基于机器学习的方式来实现智能，这种方式的假设是当学习的数据足够充分，就可以大概率的逼近事实。</p>
<p>再回到公式Y=AX+B，我们可以看到机器学习是通过X和Y来学习出参数A和B，而在机器学习中，X是人工构造的特征，Y是人工进行标注的标签。一句话，机器学习就是通过构造X和Y来学习参数A和B。但通常情况下，构造X和标注Y需要耗用大量的人力和时间。所以，对于如何更智能的构造X和标注Y是机器学习很重要的研究方向。深度学习的一个重要作用就是能够更智能的构造X，即进行更好的特征表示。所以深度学习是机器学习的一个子集。那如何更好的标注Y呢，当前流行的对抗生成网络（GAN）就是一种解决方案。</p>
<p>机器学习需要的基础知识体系</p>
<p>机器学习的三个关键要素是模型、策略、算法。模型指的是具体的机器学习模型，比如决策树、SVM、神经网络、LDA等具体模型。策略指的是最小化模型结构性风险的手段，即避免模型欠拟合和过拟合的应对策略，在这里专指正则化（Regularization）。算法指的是建立好模型之后，如何对模型中的参数进行学习。也即最优化的方法。所以，初学者需要掌握的基础知识为：</p>
<p>1.导数与微积分，以及还需要对泰勒展开式、拉格朗日等定理和公式有充分的掌握。这是进行算法推导的基础中的基础。</p>
<p>2.线性代数，矩阵运算等要做到熟练掌握，因为机器学习的最优化算法中涉及到的复杂计算需要线性代数好矩阵运算的内容。</p>
<p>3.概率论，概率论的基础知识是理解像极大似然、最大熵、EM算法、贝叶斯网络、概率图模型的基础。</p>
<p>4.最优化，机器学习中的模型训练是通过对模型中参数的学习来进行泛化推广。如何对模型中的参数进行学习是最优化要解决的问题。比如线性优化、非线性优化的各种主要方法（比如梯度下降法、牛顿和拟牛顿法等）要有充分的理解。</p>
<p>5.机器学习模型的思想和具体实现方式要理解透彻。</p>
<p>机器学习的应用实践</p>
<p>特征工程，如上面所说就是造X，机器学习实践中大部分的实践都在处理特征工程上。所以真正有机器学习实践经验的人都知道机器学习更多的时间不是高大上的算法，而是苦逼特征工程。工程师每天更多的是基于对业务的深刻理解，通过构建“更好”的特征，持续提升模型的准确度。</p>
<p>推荐系统与搜索系统</p>
<p>当推荐和搜索这些字眼出现在网页中，专业书籍中，或是大部分的培训课程中，更多的是与机器学习和算法关联起来。这种情况的原因可能是为了迎合机器学习在大部分人认知中的“高大上”吧。</p>
<p>在实际的产品设计和开发中，推荐系统和搜索系统是有着一个更大概念的系统架构，绝非仅仅是只有机器学习和算法。其中UI/UE的重要性占比为40%，业务理解重要性占比为30%，数据重要性占比为20%，模型重要性占比为10%。</p>
<p>以推荐系统举例，整个推荐系统的框架应当如下图所示：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/58888fc4b17f9.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>下图是电商平台上推荐系统的框架</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/58888fd1d31a4.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>所以，建议的推荐系统知识学习体系为：</p>
<p>一、推荐系统之整体架构</p>
<p>1.推荐系统的本质、目标及价值</p>
<p>2.一个好的推荐系统的相貌</p>
<p>3.线下零售的促销员与电商平台的推荐系统的关系</p>
<p>3.推荐系统与搜索的关系</p>
<p>4.主流电商平台上的推荐系统学习</p>
<p>5.推荐系统的整体架构图以及如何学习推荐系统</p>
<p>二、推荐系统之策略及模型</p>
<ol>
<li><p>基于规则的推荐算法</p>
</li>
<li><p>基于内容(Content-Based)的推荐算法</p>
</li>
<li><p>基于协同过滤（CF)的推荐算法</p>
</li>
<li><p>基于隐因子（SVD/SVD++/MF/FM/FFM/PLSA/LDA）的推荐算法</p>
</li>
<li><p>推荐结果的排序模型（GBDT+LR，LTR）</p>
</li>
<li><p>数学基础及典型最优化算法</p>
</li>
</ol>
<p>7.不同场景下的推荐策略（如在电商平台上，首页、详情页、购物车页、搜索结果页等不同场景下的推荐策略）</p>
<p>8.推荐系统评估</p>
<p>如何评估线下模型，如何评估线上效果</p>
<p>三、推荐系统之特征工程</p>
<p>1.用户画像如何构建</p>
<p>2.特征工程如何构建，以及如何进行特征分析</p>
<p>四、推荐系统之交互体验</p>
<p>如何向用户展示推荐系统的权威性、取得用户的信任、如何帮助用户决策、如何获取用户反馈。</p>
<p>如何开始机器学习</p>
<p>对于大多数人来说，如果以抽象的方式开始学习一项内容肯定不是最好的方式。相反，先建立起直觉，然后建立具体到抽象的映射，再深入学习抽象部分完成对细节部分的掌握，最后循环到具体的应用是适合大多数人的学习方式。所以对于机器学习初学者建议的学习路径为：</p>
<p>步骤一：先选择一门实战性非常强的机器学习及其应用课程进行学习。目标是通过足够多具体的应用，能够深刻理解机器学习的实际使用方式，从而建立起直觉。</p>
<p>步骤二：学习机器学习的理论课程，包括具体的模型算法，最优化方法，以及相关的公式推导。过了这一关，就完成了对机器学习细节的更好掌控。</p>
<p>步骤三：如果能够立刻参与到机器学习的实际项目中是最好不过了。如果不能，可以去完成Kaggle中的一些比赛项目。</p>
<p>最后，也是最最重要的建议，如果要想“更快速”“更高效”的掌握机器学习，找到合适的培训课程进行学习是最合适的方式。用钱买时间，买别人的经验，以更高效的方式掌握机器学习后，这些付出的费用可能仅仅是你工作之后月薪的很小的一部分。</p>
<p>在任督二脉打通之后，可以适当的对分布式存储和计算相关体系的内容进行学习。即靠的是个人的持续修行，在理论与实践循环提升中，成长为真正的专家。</p>
<p>PS：为了推动 AI 人才全面化，雷锋网将为大家提供一个业界顶级的专业 AI 技术培训平台：1024MOOC 。其中王刚老师也会在1024MOOC 开展系统的机器学习实战培训课程，具体开课时间在年后一周左右，请大家持续关注雷锋网(公众号：雷锋网)信息。</p>
<p>雷锋网原创文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201701/mY1HbudReeTtJHw4.html&quot;&gt;雷锋网 亚峰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;导语：现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉。&lt;/p&gt;
&lt;p&gt;雷锋网按：“算法”这两字在人工智能圈已然成为“高大上”的代名词，由于不少在校生和职场新人对它的过度迷恋，多名 AI 资深人士均对这一现象表示担忧。李开复曾这样说到：&lt;/p&gt;
&lt;p&gt;现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉，更缺乏解决实际问题所必须的数据资源。&lt;br&gt;随着开源框架层出不穷，人工智能产品化和商业化进程不断加速，使得算法的门槛逐渐降低，但对工程的要求不断在提高。这种情况下，实际应用和工程能力基础扎实的技术人才变得异常抢手。&lt;/p&gt;
&lt;p&gt;其实 AI 新人们在进入职场后也愈发意识到这个问题，那他们该如何提升自己的实战能力？&lt;/p&gt;
&lt;p&gt;雷锋网特邀王刚为大家讲述机器学习的实战与应用，王刚根据工程、产品、业务等多个维度帮大家梳理如何系统地去学习机器学习。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习年度 20 大开源项目花落谁家？（Python 版）</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Resources/20-open-source-projects-of-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Resources/20-open-source-projects-of-machine-learning/</id>
    <published>2017-02-19T15:57:06.000Z</published>
    <updated>2017-02-19T06:03:00.878Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201612/PEyfFyUxtTVLHKx6.html" target="_blank" rel="external">雷锋网 小东</a></p>
<p>如今，开源已经成为创新与技术发展的核心。在本文中，雷锋网(公众号：雷锋网)将介绍 2016 Python 前20大机器学习开源项目。</p>
<p>去年 KDnuggets 评选了前 20 大机器学习开源项目（Python版），今年的评选结果与去年相比，名单中出现了一些新的面孔，有13个新开源项目入围了这个名单。作者 Prasad Pore 将具体介绍这些开源项目，雷锋网编译，未经许可不得转载。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fb955274ac.png?imageMogr2/format/jpg/quality/90" alt=""></p>
  <a id="more"></a>
<p>  第一名：Scikit-learn</p>
<p>  Scikit-learn可以说是一款简单而高效的数据挖掘与分析工具，大家可以免费下载安装，使用它处理各种数据，使用时需引入 NumPy, SciPy, and matplotlib这些第三方开源模块。</p>
<p>  提交: 21486    贡献: 736    Github URL: Scikit-learn</p>
<p>  第二名：Tensorflow</p>
<p>  Tensorflow是由谷歌大脑与谷歌人工智能实验室的科研人员研发而成的，这个系统用于机器学习的研究，可以简单、快速的实现研究人员的想法。前段时间恰逢Tensorflow一周年，雷锋网也做过报道和回顾。</p>
<p>  提交: 10466    贡献: 493    Github URL: Tensorflow</p>
<p>  第三名：Theano</p>
<p>  Theano可以对那些高维数组数学表达式进行定义、优化与评估。</p>
<p>  提交: 24108    贡献: 263    Github URL: Theano</p>
<p>  第四名：Caffe</p>
<p>  Caffe是一款具有表达、加速、模块化思想的深度学习框架，由 Berkeley Vision and Learning Center (BVLC)于社区志愿者共同开发维护。</p>
<p>  提交: 3801    贡献: 215    Github URL: Caffe</p>
<p>  第五名：Gensim</p>
<p>  Gensim是一个免费的Python库，这个库可以实现文本的情感倾向判断，相似文本检索等功能。</p>
<p>  提交: 2702    贡献: 145    Github URL: Gensim</p>
<p>  第六名：Pylearn2</p>
<p>  Pylearn2 也是一个机器学习的开源库，但它是一个基于Theano的库，所以它有一些Theano的特点，你可以使用数学表达式来写Pylearn2插件，Theano会自动对你写的表达式进行优化，按照你的选择（用CPU或GPU）对这些表达式进行编译。</p>
<p>  提交: 7100    贡献: 115    Github URL: Pylearn2</p>
<p>  第七名：Statsmodels</p>
<p>  Statsmodels是一款Python开源工具，可以实现数据探究、统计模型评价、性能测试等功能，扩展性能良好，可对各种类型的数据进行各种处理，例如描述统计、统计测试、绘图、结果统计等等。</p>
<p>  提交: 8664    贡献: 108    Github URL: Statsmodels</p>
<p>  第八名：Shogun</p>
<p>  Shogun是一款机器学习工具，其包含了各种机器学习方法。它可以简单的实现多种数据表示、多种算法的无缝融合。</p>
<p>  提交: 15172    贡献: 105    Github URL: Shogun</p>
<p>  第九名：Chainer</p>
<p>  Chainer是一个基于Python的开源深度学习框架，它可以让你以一种灵活、简单、快速的方式实现多种深度学习模型，包括RNN与各种自编码。</p>
<p>  提交: 6298    贡献: 84    Github URL: Chainer</p>
<p>  第十名：NuPIC</p>
<p>  NuPIC是一个基于Hierarchical Temporal Memory理论的开源项目，目前Hierarchical Temporal Memory这个理论中的部分功能已经实现，并进行了测试与应用，其它部分正在完善中。</p>
<p>  提交: 6088    贡献: 76    Github URL: NuPIC</p>
<p>  第十一名：Neon</p>
<p>  Neon是一款深度学习第三方库，在进行高性能计算时它具有简单易用的特点。</p>
<p>  提交: 875    贡献: 47    Github URL: Neon</p>
<p>  第十二名：NiLearn</p>
<p>  NiLearn主要用于处理医学图像数据，具有简单、快速的特点。它通过调用scikit-learn进行多元统计分析（例如：预测模型、分类、解码、关联分析）。</p>
<p>  提交: 5254    贡献: 46    Github URL: NiLearn</p>
<p>  第十三名：Orange3</p>
<p>  Orange3是一款机器学习与数据可视化开源工具，可以对数据进行各种交互分析。</p>
<p>  提交: 6356    贡献: 40    Github URL: Orange3</p>
<p>  第十四名：Pymc</p>
<p>  Pymc是一个贝叶斯统计模型（包括马尔科夫链）库，具有灵活、扩展性能好的特点。</p>
<p>  提交: 2701    贡献: 37    Github URL: Pymc</p>
<p>  第十五名：PyBrain：</p>
<p>  PyBrain是一个机器学习库，它的目标是让算法的实现变的简单、灵活、高效。同时使得在特定环境下对算法的测试与比较也变的简单、灵活、高效。</p>
<p>  提交: 984    贡献: 31    Github URL: PyBrain</p>
<p>  第十六名：Fuel</p>
<p>  Fuel主要用于算法与输入数据之间的衔接。它将被Blocks and Pylearn2这两个Python库使用。</p>
<p>  提交: 1053    贡献: 29    Github URL: Fuel</p>
<p>  第十七名： PyMVPA</p>
<p>  PyMVPA 适用于大规模的数据集，具有扩展性能好优点，提供多种算法（分类、回归、特征选择、数据导入、数据导出等）接口。</p>
<p>  提交: 9258    贡献: 26    Github URL: PyMVPA</p>
<p>  第十八名：Annoy</p>
<p>  Annoy是一个Python可调用的C++库，主要用来对给定数据进行搜索。它可以生成大量的基于文档的可读数据结构，这种数据结构与内存相对应，从而使数据被共享。</p>
<p>  提交: 365    贡献: 24    Github URL: Annoy</p>
<p>  第十九名：Deap</p>
<p>  Deap是一款新的计算框架，它使得算法实现与数据结构变得简单明了。它采用的是并行处理机制。</p>
<p>  提交: 1854    贡献: 21    Github URL: Deap</p>
<p>  第二十名：Pattern</p>
<p>  Pattern是一款web信息挖掘工具，它集成了各种工具。这些工具可以用来进行数据挖掘、自然语言处理、机器学习、网络分析。</p>
<p>  提交: 943    贡献: 20    Github URL: Pattern</p>
<p>  如下图所示，PyMVPA的社区贡献率最高，而排名第一的Scikit-learn社区贡献率却很低，究其原因是PyMVPA是还是一个比较新的开源项目，还有一些地方需要完善、修复。而Scikit-learn则是一个相对来说比较成熟的项目，需要修改、完善的地方比较少。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fb913396be.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>  当我们对2015与2016的结果进行对比（下图），我们发现Pattern, PyBrain and Pylearn2这三个项目的贡献人数与提交数均没有变化。贡献的人增加了，提交的次数也才跟着增加，这就是开源社区的神奇所在。这些新增的贡献者与其提交内容导致了新的思想、新的软件的产生。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fb933e626e.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>  基于2016年20大机器学习开源项目的贡献人数与提交数，以上是雷锋网整理的简单分析。不知道到明年的评选上，又有怎样的开源平台会登上这个榜单呢？</p>
<p>  via <a href="http://www.kdnuggets.com/2016/11/top-20-python-machine-learning-open-source-updated.html" target="_blank" rel="external">Top 20 Python Machine Learning Open Source Project</a></p>
<p>  五个鲜为人知，但又不可不知的机器学习开源项目<br>  本文作者：恒亮    2017-02-09 14:14<br>  导语：本文将介绍的这五个小众项目来自不同的生态系统和编程语言，并且版本更新活跃，具有一定的学习价值。<br>  五个鲜为人知，但又不可不知的机器学习开源项目</p>
<p>  借着人工智能的热潮，各种机器学习项目也迎来了一个爆发期。其中有一些因为背后的巨头支持或者稳定可靠的性能而广为人知，例如Tensorflow、Caffe和Theano等。但实际上，有为数更多的项目却并不为人所知。在这些相对小众的项目中，是否隐藏着一些版本迭代积极，且具有一定参考价值的项目？答案显然是肯定的。</p>
<p>  本文将介绍的这五个小众项目来自不同的生态系统和编程语言，并且版本更新活跃，具有一定的参考价值。或许你会觉得了解这些小众的项目并没有太多实际意义，但本文的原作者Matthew Mayo，一位资深的数据科学家和无监督学习领域的大牛认为，仔细学习这些项目的实现细节和编码方式，将帮助开发者对他们自己的项目产生一些具有积极意义的想法，因此仍然是大有裨益的。</p>
<p>  原文来自KDnuggets，以下项目排名不分先后，雷锋网(公众号：雷锋网)编译。</p>
<ol>
<li><p>Hyperopt-sklearn</p>
<p>Hyperopt-sklearn是基于scikit-learn项目的一个子集，其全称是：Hyper-parameter optimization for scikit-learn，即针对scikit-learn项目的超级参数优化工具。由于scikit-learn是基于Python的机器学习开源框架，因此Hyperopt-sklearn也基于Python语言。</p>
<p>Hyperopt-sklearn的文档称：对于开发者而言，针对不同的训练数据挑选一个合适的分类器（classifier）通常是困难的。而且即使选好了分类器，后面的参数调试过程也相当乏味和耗时。更严重的是，还有许多情况是开发者好不容易调试好了选定的分类器，却发现一开始的选择本身就是错误的，这本身就浪费了大量的精力和时间。针对该问题，Hyperopt-sklearn提供了一种解决方案。</p>
<p>Hyperopt-sklearn支持各种不同的搜索算法（包括随机搜索、Tree of Parzen Estimators、Annealing等），可以搜索所有支持的分类器（KNeightborsClassifier、KNeightborsClassifier、SGDClassifier等）或者在给定的分类器下搜索所有可能的参数配置，并评估最优选择。并且Hyperopt-sklearn还支持多种预处理流程，包括TfidfVectorizer，Normalzier和OneHotEncoder等。</p>
<p>那么Hyperopt-sklearn的实际效果究竟如何？下表分别展示了使用scikit-learn默认参数和Hyperopt-sklearn优化参数运行的分类器的F-score分数，数据源来自20个不同的新闻组稿件。可以看到，经过优化的分类器的平均得分都要高于默认参数的情况。</p>
</li>
</ol>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589c005bb09b9.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>  另外，Hyperopt-sklearn的编码量也很小，并且维护团队还提供了丰富的参考样例。</p>
<p>  主页：<a href="http://hyperopt.github.io/hyperopt-sklearn/" target="_blank" rel="external">http://hyperopt.github.io/hyperopt-sklearn/</a></p>
<ol>
<li>Dlib</li>
</ol>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589c0065df911.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>  Dlib的目标用户并没有Hyperopt-sklearn细分，它是一个基于C++语言的通用的机器学习和数据分析库。值得一提的是，虽然Dlib的确是由C++实现的，但它却提供了针对Python语言的API。</p>
<p>  Dlib的官网称：Dlib是一个现代的C++工具包，实现了大量机器学习的相关算法和工具，可用于在C++环境下创建复杂的软件来解决现实问题。目前，Dlib在工业界和学术界都得到了广泛的应用，包括机器人，嵌入式设备，移动电话和大规模的高性能计算环境等。</p>
<p>  Dlib的帮助文档非常规范，针对每个API接口的解释也相当全面，而且Dlib还提供了非常详细的入门参考。更为难能可贵的是，Dlib的博客更新也非常频繁，官方人员经常通过博客分享基于Dlib实现的有趣的应用项目。实际上，Dlib也并非随着近两年的人工智能热潮才发起的项目，相对而言，它的历史非常悠久，早在2002年，Dlib的维护团队就已经开始着手开发了。</p>
<p>  鉴于Dlib包含了为数众多的算法实现，因此原文作者认为Dlib的运行效率应该与scikit-learn接近，甚至有可能超越后者。</p>
<p>  主页：<a href="http://dlib.net/" target="_blank" rel="external">http://dlib.net/</a></p>
<ol>
<li><p>N++</p>
<p>N++同样基于C++环境，相对其他项目而言，它是一个非常小巧易用的神经网络实现库。这一点主要体现在，N++并不需要复杂的安装过程，使用时只需要在C++代码中通过#include语句对所需的库文件做一个声明就可以了。</p>
<p>其官网称：N++是一个简短、自包含（self-contained）、易于使用的基于C++环境的神经网络工具包。它实现了包括神经网络和基本线性代数运算在内的一些矩阵类。该项目的主要目的是为了相互学习和交流，但基于MNIST数据库的一些初步测试结果却表明N++在某些实际应用项目中的表现同样出色。</p>
<p>N++的配套文档并不多，但它却对矩阵类的相关用法进行了详细解释。另外，N++官方还公布了一些对神经网络进行设置和查询的代码片段，而且由于这些代码相对其他实现都非常简短，因此N++特别适合于那些想要了解简单的神经网络实现或者刚从其他编程语言转到C++环境的开发者。</p>
<p>主页：<a href="https://github.com/stagadish/NNplusplus" target="_blank" rel="external">https://github.com/stagadish/NNplusplus</a></p>
</li>
<li><p>LightGBM</p>
<p>LightGBM是基于微软DMTK（Microsoft Distributed Machine Learning Toolkit）开源项目的一个子集，它的全称是：Light Gradient Boosting Machine，专注于各种梯度提升（Gradient Boosting）算法的实现，包括GBDT，GBRT，GBM和MART等。</p>
</li>
</ol>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589c00872d9de.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>  官网描述称：基于公开数据集的测试结果表明，LightGBM无论在模型训练的速度、准确性还是内存消耗等各方面都要优于其他的梯度提升算法实现。此外，LightGBM还可以通过在特定设置中使用多台机器进行并行训练的方式来实现线性加速（linear speed-up）。</p>
<p>  LightGBM本身由C++和Python两种语言实现，微软为开发者提供了完整的帮助文档和入门参考。背靠科技巨头微软的鼎力支持，LightGBM自然也是一个非常值得关注的项目。</p>
<p>  主页：<a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="external">https://github.com/Microsoft/LightGBM</a></p>
<ol>
<li>Sklearn-pandas</li>
</ol>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589c017ac3f8c.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>  与前面的几个项目不同，Sklearn-pandas既可以视为一个通用型的机器学习工具包，也可是视为一些特定算法的实现。它在具体的机器学习任务中主要充当支持者的角色。</p>
<p>  这里所谓支持者的角色，按照其官网的解释即是说：Sklearn-pandas在Scikit-Learn和pandas之间提供了一个互通的桥梁（这一点从项目的名称也能看出）。Scikit-Learn上文已经提过，这里pandas是指一个开源的基于Python实现的数据分析工具。</p>
<p>  具体的说，Sklearn-pandas的桥梁作用主要体现在以下两个方面：</p>
<p>  1) 提供将DataFrame列映射到transformations的方法，这些列此后还可以重新组合成特征（features）；</p>
<p>  2) 以pandas DataFrame为输入，为scikit-learn旧版本的管道交叉验证（cross-validate a pipeline）提供兼容性支持。</p>
<p>  Sklearn-pandas的版本更新活跃，也是一个非常值得关注的开源项目。</p>
<p>  主页：<a href="https://github.com/paulgb/sklearn-pandas" target="_blank" rel="external">https://github.com/paulgb/sklearn-pandas</a></p>
<p>  来源：<a href="http://www.kdnuggets.com/2017/01/five-machine-learning-projects-cant-overlook-january.html" target="_blank" rel="external">kdnuggets</a>，雷锋网编译</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201612/PEyfFyUxtTVLHKx6.html&quot;&gt;雷锋网 小东&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如今，开源已经成为创新与技术发展的核心。在本文中，雷锋网(公众号：雷锋网)将介绍 2016 Python 前20大机器学习开源项目。&lt;/p&gt;
&lt;p&gt;去年 KDnuggets 评选了前 20 大机器学习开源项目（Python版），今年的评选结果与去年相比，名单中出现了一些新的面孔，有13个新开源项目入围了这个名单。作者 Prasad Pore 将具体介绍这些开源项目，雷锋网编译，未经许可不得转载。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201612/584fb955274ac.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
  </entry>
  
  <entry>
    <title>28款 GitHub 最流行的开源机器学习项目：TensorFlow 排榜首</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Resources/28-open-source-projects-of-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Resources/28-open-source-projects-of-machine-learning/</id>
    <published>2017-02-19T15:57:05.000Z</published>
    <updated>2017-02-19T06:03:00.879Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://yq.aliyun.com/articles/30794?spm=5176.100239.blogcont30796.7.1WRiYX" target="_blank" rel="external">云栖社区 readygo </a></p>
<p>现在机器学习逐渐成为行业热门，经过二十几年的发展，机器学习得到了十分广泛的应用，如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、DNA序列测序、战略游戏和机器人等方面。 云栖社区特意翻译整理了目前GitHub上最受欢迎的28款开源的机器学习项目，以供开参考使用。</p>
<p><img src="https://oss.aliyuncs.com/yqfiles/f7ee0537b3263e5874f6d0533a46422c61508308.png" alt=""></p>
  <a id="more"></a>
<h2 id="1-TensorFlow"><a href="#1-TensorFlow" class="headerlink" title="1. TensorFlow"></a>1. TensorFlow</h2><p>TensorFlow 是谷歌发布的第二代机器学习系统。据谷歌宣称，在部分基准测试中，TensorFlow的处理速度比第一代的DistBelief加快了2倍之多。<br>具体的讲，TensorFlow是一个利用数据流图（Data Flow Graphs）进行数值计算的开源软件库：<strong>图中的节点（ Nodes）代表数学运算操作，同时图中的边（Edges）表示节点之间相互流通的多维数组，即张量（Tensors）。</strong> 这种灵活的架构可以让使用者在多样化的将计算部署在台式机、服务器或者移动设备的一个或多个CPU上，而且无需重写代码；同时任一基于梯度的机器学习算法均可够借鉴TensorFlow的自动分化（Auto-differentiation）；此外通过灵活的Python接口，要在TensorFlow中表达想法也变得更为简单。</p>
<p>TensorFlow最初由Google Brain小组（该小组隶属于Google’s Machine Intelligence研究机构）的研究员和工程师开发出来的，开发目的是用于进行机器学习和深度神经网络的研究。但该系统的通用性足以使其广泛用于其他计算领域。</p>
<p>目前Google 内部已在大量使用 AI 技术，包括 Google App 的语音识别、Gmail 的自动回复功能、Google Photos 的图片搜索等都在使用 TensorFlow 。</p>
<p>开发语言：C++<br>许可协议：Apache License 2.0<br>GitHub项目地址：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">https://github.com/tensorflow/tensorflow</a></p>
<h2 id="2-Scikit-Learn"><a href="#2-Scikit-Learn" class="headerlink" title="2. Scikit-Learn"></a>2. Scikit-Learn</h2><p>Scikit-Learn是用于机器学习的Python 模块，它建立在SciPy之上。该项目由David Cournapeau 于2007年创立，当时项目名为Google Summer of Code，自此之后，众多志愿者都为此做出了贡献。</p>
<p>主要特点：<br>操作简单、高效的数据挖掘和数据分析<br>无访问限制，在任何情况下可重新使用<br>建立在NumPy、SciPy 和 matplotlib基础上</p>
<p>Scikit-Learn的基本功能主要被分为六个部分：<strong>分类、回归、聚类、数据降维、模型选择、数据预处理</strong>，具体可以参考官方网站上的文档。经过测试，Scikit-Learn可在 Python 2.6、Python 2.7 和 Python 3.5上运行。除此之外，它也应该可在Python 3.3和Python 3.4上运行。<br>注：Scikit-Learn以前被称为Scikits.Learn。</p>
<p>开发语言：Python<br>许可协议:3-Clause BSD license<br>GitHub项目地址: <a href="https://github.com/scikit-learn/scikit-learn" target="_blank" rel="external">https://github.com/scikit-learn/scikit-learn</a></p>
<h2 id="3-Caffe"><a href="#3-Caffe" class="headerlink" title="3.Caffe"></a>3.Caffe</h2><p>Caffe 是由神经网络中的表达式、速度、及模块化产生的深度学习框架。后来它通过伯克利视觉与学习中心（(BVLC）和社区参与者的贡献，得以发展形成了以一个伯克利主导，然后加之Github和Caffe-users邮件所组成的一个比较松散和自由的社区。</p>
<p>Caffe是一个基于C++/CUDA架构框架，开发者能够利用它自由的组织网络，目前支持卷积神经网络和全连接神经网络（人工神经网络）。在Linux上，C++可以通过命令行来操作接口，对于MATLAB、Python也有专门的接口，运算上支持CPU和GPU直接无缝切换。</p>
<p>Caffe的特点</p>
<p>易用性：Caffe的模型与相应优化都是以文本形式而非代码形式给出， Caffe给出了模型的定义、最优化设置以及预训练的权重，方便快速使用；<br>速度快：能够运行最棒的模型与海量的数据；Caffe可与cuDNN结合使用，可用于测试AlexNet模型，在K40上处理一张图片只需要1.17ms；<br>模块化：便于扩展到新的任务和设置上；<br>使用者可通过Caffe提供的各层类型来定义自己的模型；<br>目前Caffe应用实践主要有数据整理、设计网络结构、训练结果、基于现有训练模型，使用Caffe直接识别。</p>
<p>开发语言：C++<br>许可协议： BSD 2-Clause license<br>GitHub项目地址: <a href="https://github.com/BVLC/caffe" target="_blank" rel="external">https://github.com/BVLC/caffe</a></p>
<h2 id="4-PredictionIO"><a href="#4-PredictionIO" class="headerlink" title="4. PredictionIO"></a>4. PredictionIO</h2><p>PredictionIO 是面向开发人员和数据科学家的开源机器学习服务器。它支持事件采集、算法调度、评估，以及经由REST APIs的预测结果查询。使用者可以通过PredictionIO做一些预测，比如个性化推荐、发现内容等。PredictionIO 提供20个预设算法，开发者可以直接将它们运行于自己的数据上。几乎任何应用与PredictionIO集成都可以变得更“聪明”。其主要特点如下所示：</p>
<p>基于已有数据可预测用户行为；<br>使用者可选择你自己的机器学习算法；<br>无需担心可扩展性，扩展性好。<br>PredictionIO 基于 REST API（应用程序接口）标准，不过它还包含 Ruby、Python、Scala、Java 等编程语言的 SDK（软件开发工具包）。其开发语言是Scala语言，数据库方面使用的是MongoDB数据库，计算系统采用Hadoop系统架构。</p>
<p>开发语言：Scala<br>许可协议： Apache License 2.0<br>GitHub项目地址: <a href="https://github.com/PredictionIO/PredictionIO" target="_blank" rel="external">https://github.com/PredictionIO/PredictionIO</a></p>
<h2 id="5-Brain"><a href="#5-Brain" class="headerlink" title="5. Brain"></a>5. Brain</h2><p>Brain是 JavaScript 中的 神经网络库。以下例子说明使用Brain来近似 XOR 功能：</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> net = <span class="keyword">new</span> brain<span class="variable">.NeuralNetwork</span>();</div><div class="line"></div><div class="line">net<span class="variable">.train</span>([&#123;<span class="keyword">input</span>: [<span class="number">0</span>, <span class="number">0</span>], <span class="keyword">output</span>: [<span class="number">0</span>]&#125;,</div><div class="line"></div><div class="line">           &#123;<span class="keyword">input</span>: [<span class="number">0</span>, <span class="number">1</span>], <span class="keyword">output</span>: [<span class="number">1</span>]&#125;,</div><div class="line"></div><div class="line">           &#123;<span class="keyword">input</span>: [<span class="number">1</span>, <span class="number">0</span>], <span class="keyword">output</span>: [<span class="number">1</span>]&#125;,</div><div class="line"></div><div class="line">           &#123;<span class="keyword">input</span>: [<span class="number">1</span>, <span class="number">1</span>], <span class="keyword">output</span>: [<span class="number">0</span>]&#125;]);</div><div class="line"></div><div class="line"><span class="keyword">var</span> <span class="keyword">output</span> = net<span class="variable">.run</span>([<span class="number">1</span>, <span class="number">0</span>]);  <span class="comment">// [0.987]</span></div></pre></td></tr></table></figure>
<p>当 brain 用于节点中，可使用npm安装：<br>npm install brain<br>当 brain 用于浏览器，下载最新的 brain.js 文件。训练计算代价比较昂贵，所以应该离线训练网络（或者在 Worker 上），并使用 toFunction() 或者 toJSON()选项，以便将预训练网络插入到网站中。</p>
<p>开发语言：JavaScript<br>GitHub项目地址: <a href="https://github.com/harthur/brain" target="_blank" rel="external">https://github.com/harthur/brain</a></p>
<h2 id="6-Keras"><a href="#6-Keras" class="headerlink" title="6. Keras"></a>6. Keras</h2><p>Keras是极其精简并高度模块化的神经网络库，在TensorFlow 或 Theano 上都能够运行，是一个高度模块化的神经网络库，支持GPU和CPU运算。Keras可以说是Python版的Torch7，对于快速构建CNN模型非常方便，同时也包含了一些最新文献的算法，比如Batch Noramlize，文档教程也很全，在官网上作者都是直接给例子浅显易懂。Keras也支持保存训练好的参数，然后加载已经训练好的参数，进行继续训练。</p>
<p>Keras侧重于开发快速实验，用可能最少延迟实现从理念到结果的转变，即为做好一项研究的关键。<br>当需要如下要求的深度学习的库时，就可以考虑使用Keras：</p>
<p>考虑到简单快速的原型法（通过总体模块性、精简性以及可扩展性）；<br>同时支持卷积网络和递归网络，以及两者之间的组合；<br>支持任意连接方案（包括多输入多输出训练）；<br>可在CPU 和 GPU 上无缝运行。<br>Keras目前支持 Python 2.7-3.5。</p>
<p>开发语言：Python<br>GitHub项目地址:<a href="https://github.com/fchollet/keras" target="_blank" rel="external">https://github.com/fchollet/keras</a></p>
<h2 id="7-CNTK"><a href="#7-CNTK" class="headerlink" title="7. CNTK"></a>7. CNTK</h2><p>CNTK（Computational Network Toolkit ）是一个统一的深度学习工具包，该工具包通过一个有向图将神经网络描述为一系列计算步骤。在有向图中，叶节点表示输入值或网络参数，其他节点表示该节点输入之上的矩阵运算。</p>
<p>CNTK 使得实现和组合如前馈型神经网络DNN、卷积神经网络（CNN）和循环神经网络(RNNs/LSTMs)等流行模式变得非常容易。同时它实现了跨多GPU 和服务器自动分化和并行化的随机梯度下降（SGD，误差反向传播）学习。</p>
<p>下图将CNTK的处理速度（每秒处理的帧数）和其他四个知名的工具包做了比较了。配置采用的是四层全连接的神经网络（参见基准测试脚本）和一个大小是8192 的高效mini batch。在相同的硬件和相应的最新公共软件版本（2015.12.3前的版本）的基础上得到如下结果：</p>
<p><img src="https://oss.aliyuncs.com/yqfiles/d0f55e30bdd8e597ef341850b060593a3f339f7a.png" alt=""></p>
<p>CNTK自2015年四月就已开源。</p>
<p>开发语言：C++<br>GitHub项目地址:<a href="https://github.com/Microsoft/CNTK" target="_blank" rel="external">https://github.com/Microsoft/CNTK</a></p>
<h2 id="8-Convnetjs"><a href="#8-Convnetjs" class="headerlink" title="8. Convnetjs"></a>8. Convnetjs</h2><p>ConvNetJS是利用Javascript实现的神经网络，同时还具有非常不错的基于浏览器的Demo。它最重要的用途是帮助深度学习初学者更快、更直观的理解算法。</p>
<p>它目前支持：<br>常见的神经网络模块（全连接层，非线性）；<br>分类（SVM/ SOFTMAX）和回归（L2）的成本函数；<br>指定和训练图像处理的卷积网络；<br>基于Deep Q Learning的实验强化学习模型。</p>
<p>一些在线示例：<br><a href="http://cs.stanford.edu/~karpathy/convnetjs/demo/mnist.html?spm=5176.100239.blogcont30794.16.HFv9Ay" target="_blank" rel="external">Convolutional Neural Network on MNIST digits</a><br><a href="http://cs.stanford.edu/~karpathy/convnetjs/demo/cifar10.html?spm=5176.100239.blogcont30794.17.HFv9Ay" target="_blank" rel="external">Convolutional Neural Network on CIFAR-10</a><br><a href="http://cs.stanford.edu/~karpathy/convnetjs/demo/classify2d.html?spm=5176.100239.blogcont30794.18.HFv9Ay" target="_blank" rel="external">Toy 2D data</a><br><a href="http://cs.stanford.edu/~karpathy/convnetjs/demo/regression.html?spm=5176.100239.blogcont30794.19.HFv9Ay" target="_blank" rel="external">Toy 1D regression</a><br><a href="http://cs.stanford.edu/~karpathy/convnetjs/demo/autoencoder.html?spm=5176.100239.blogcont30794.20.HFv9Ay" target="_blank" rel="external">Training an Autoencoder on MNIST digits</a><br><a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html?spm=5176.100239.blogcont30794.21.HFv9Ay" target="_blank" rel="external">Deep Q Learning Reinforcement Learning demo</a> +<a href="http://cs.stanford.edu/~karpathy/convnetjs/demo/image_regression.html?spm=5176.100239.blogcont30794.22.HFv9Ay" target="_blank" rel="external">Image Regression (“Painting”)</a> +<a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/trainers.html?spm=5176.100239.blogcont30794.23.HFv9Ay" target="_blank" rel="external">Comparison of SGD/Adagrad/Adadelta on MNIST</a></p>
<p>开发语言：Javascript<br>许可协议：MIT License<br>GitHub项目地址:<a href="https://github.com/karpathy/convnetjs" target="_blank" rel="external">https://github.com/karpathy/convnetjs</a></p>
<h2 id="9-Pattern"><a href="#9-Pattern" class="headerlink" title="9. Pattern"></a>9. Pattern</h2><p><img src="https://oss.aliyuncs.com/yqfiles/882aed302fb92c9d7e4e798613414af50384c686.png" alt=""></p>
<p>Pattern是Python的一个Web挖掘模块。拥有以下工具：<br>数据挖掘：网络服务（Google、Twitter、Wikipedia）、网络爬虫、HTML DOM解析；<br>自然语言处理：词性标注工具(Part-Of-Speech Tagger)、N元搜索(n-gram search)、情感分析(sentiment analysis)、WordNet；<br>机器学习：向量空间模型、聚类、分类（KNN、SVM、 Perceptron）；<br>网络分析：图形中心性和可视化。<br>其文档完善，目前拥有50多个案例和350多个单元测试。 Pattern目前只支持Python 2.5+（尚不支持Python 3），该模块除了在Pattern.vector模块中使用LSA外没有其他任何外部要求，因此只需安装 NumPy （仅在Mac OS X上默认安装）。</p>
<p>开发语言：Python<br>许可协议：BSD license<br>GitHub项目地址:<a href="https://github.com/clips/pattern" target="_blank" rel="external">https://github.com/clips/pattern</a></p>
<h2 id="10-NuPIC"><a href="#10-NuPIC" class="headerlink" title="10. NuPIC"></a>10. NuPIC</h2><p><img src="https://oss.aliyuncs.com/yqfiles/9bbe47e26491efc15764f20948c315b49cdca4dd.png" alt=""></p>
<p>NuPIC是一个实现了HTM学习算法的机器智能平台。HTM是一个关于新（大脑）皮质（Neocortex）的详细人工智能算法。HTM的核心是基于时间的连续学习算法，该算法可以存储和调用时间和空间两种模式。NuPIC可以适用于解决各类问题，尤其是异常检测和流数据源预测方面。<br>NuPIC Binaries文件目前可用于：<br>Linux x86 64bit<br>OS X 10.9<br>OS X 10.10<br>Windows 64bit<br>NuPIC 有自己的独特之处。许多机器学习算法无法适应新模式，而NuPIC的运作接近于人脑，当模式变化的时候，它会忘掉旧模式，记忆新模式。</p>
<p>开发语言：Python<br>GitHub项目地址：<a href="https://github.com/numenta/nupic" target="_blank" rel="external">https://github.com/numenta/nupic</a></p>
<ol>
<li>Theano</li>
</ol>
<p>Theano是一个Python库，它允许使用者有效地定义、优化和评估涉及多维数组的数学表达式，同时支持GPUs和高效符号分化操作。Theano具有以下特点：<br>与NumPy紧密相关–在Theano的编译功能中使用了Numpy.ndarray ；<br>透明地使用GPU–执行数据密集型计算比CPU快了140多倍（针对Float32）；<br>高效符号分化–Theano将函数的导数分为一个或多个不同的输入；<br>速度和稳定性的优化–即使输入的x非常小也可以得到log(1+x)正确结果；<br>动态生成 C代码–表达式计算更快；<br>广泛的单元测试和自我验证–多种错误类型的检测和判定。<br>自2007年起，Theano一直致力于大型密集型科学计算研究，但它目前也很被广泛应用在课堂之上（ 如Montreal大学的深度学习/机器学习课程）。</p>
<p>开发语言：Python<br>GitHub项目地址：<a href="https://github.com/Theano/Theano" target="_blank" rel="external">https://github.com/Theano/Theano</a></p>
<h2 id="12-MXNet"><a href="#12-MXNet" class="headerlink" title="12. MXNet"></a>12. MXNet</h2><p><img src="https://oss.aliyuncs.com/yqfiles/40be41256ad5c8718ee17d339b2ce5ba25e8507e.png" alt=""></p>
<p>MXNet是一个兼具效率和灵活性的深度学习框架。它允许使用者将符号编程和命令式编程相结合，以追求效率和生产力的最大化。其核心是动态依赖调度程序，该程序可以动态自动进行并行化符号和命令的操作。其中部署的图形优化层使得符号操作更快和内存利用率更高。该库轻量且便携带，并且可扩展到多个GPU和多台主机上。</p>
<p>主要特点：<br>其设计说明提供了有用的见解，可以被重新应用到其他DL项目中；<br>任意计算图的灵活配置；<br>整合了各种编程方法的优势最大限度地提高灵活性和效率；<br>轻量、高效的内存以及支持便携式的智能设备；<br>多GPU扩展和分布式的自动并行化设置；<br>支持Python、R、C++和 Julia；<br>对“云计算”友好，直接兼容S3、HDFS和Azure。<br>MXNet不仅仅是一个深度学习项目，它更是一个建立深度学习系统的蓝图、指导方针以及黑客们对深度学习系统独特见解的结合体。</p>
<p>开发语言：Jupyter Notebook<br>开源许可：Apache-2.0 license<br>GitHub项目地址：<a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">https://github.com/dmlc/mxnet</a></p>
<h2 id="13-Vowpal-Wabbit"><a href="#13-Vowpal-Wabbit" class="headerlink" title="13. Vowpal Wabbit"></a>13. Vowpal Wabbit</h2><p>Vowpal Wabbit是一个机器学习系统，该系统推动了如在线、散列、Allreduce、Learning2search、等方面机器学习前沿技术的发展。 其训练速度很快，在20亿条训练样本，每个训练样本大概100个非零特征的情况下：如果特征的总位数为一万时，训练时间为20分钟；特征总位数为1000万时，训练时间为2个小时。Vowpal Wabbit支持分类、 回归、矩阵分解和LDA。</p>
<p>当在Hadoop上运行Vowpal Wabbit时，有以下优化机制：<br>懒惰初始化：在进行All Reduce之前，可将全部数据加载到内存中并进行缓存。即使某一节点出现了错误，也可以通过在另外一个节点上使用错误节点的数据（通过缓存来获取）来继续训练。<br>Speculative Execution：在大规模集群当中，一两个很慢的Mapper会影响整个Job的性能。Speculative Execution的思想是当大部分节点的任务完成时，Hadoop可以将剩余节点上的任务拷贝到其他节点完成。</p>
<p>开发语言：C++<br>GitHub项目地址：<a href="https://github.com/JohnLangford/vowpal_wabbit" target="_blank" rel="external">https://github.com/JohnLangford/vowpal_wabbit</a></p>
<h2 id="14-Ruby-Warrior"><a href="#14-Ruby-Warrior" class="headerlink" title="14. Ruby Warrior"></a>14. Ruby Warrior</h2><p>通过设计了一个游戏使得Ruby语言和人工智能学习更加有乐趣和互动起来。<br>使用者扮演了一个勇士通过爬上一座高塔，到达顶层获取珍贵的红宝石（Ruby）。在每一层，需要写一个Ruby脚本指导战士打败敌人、营救俘虏、到达楼梯。使用者对每一层都有一些认识，但是你永远都不知道每层具体会发生什么情况。你必须给战士足够的人工智能，以便让其自行寻找应对的方式。</p>
<p>勇士的动作相关API：<br>Warrior.walk： 用来控制勇士的移动，默认方向是往前；<br>warrior.feel：使用勇士来感知前方的情况，比如是空格，还是有怪物；<br>Warrior.attack：让勇士对怪物进行攻击；<br>Warrior.health：获取勇士当前的生命值；<br>Warrior.rest：让勇士休息一回合，恢复最大生命值的10%。</p>
<p>勇士的感知API:<br>Space.empty：感知前方是否是空格；<br>Space.stairs：感知前方是否是楼梯；<br>Space.enemy： 感知前方是否有怪物；<br>Space.captive：感知前方是否有俘虏；<br>Space.wall：感知前方是否是墙壁。</p>
<p>开发语言：Ruby<br>GitHub项目地址：<a href="https://github.com/ryanb/ruby-warrior" target="_blank" rel="external">https://github.com/ryanb/ruby-warrior</a></p>
<h2 id="15-XGBoost"><a href="#15-XGBoost" class="headerlink" title="15. XGBoost"></a>15. XGBoost</h2><p>XGBoot是设计为高效、灵活、可移植的优化分布式梯度 Boosting库。它实现了 Gradient Boosting 框架下的机器学习算法。XGBoost通过提供并行树Boosting（也被称为GBDT、GBM），以一种快速且准确的方式解决了许多数据科学问题。相同的代码可以运行在大型分布式环境如Hadoop、SGE、MP上。它类似于梯度上升框架，但是更加高效。它兼具线性模型求解器和树学习算法。</p>
<p>XGBoot至少比现有的梯度上升实现有至少10倍的提升，同时还提供了多种目标函数，包括回归、分类和排序。由于它在预测性能上的强大，XGBoot成为很多比赛的理想选择，其还具有做交叉验证和发现关键变量的额外功能。</p>
<p>值得注意的是：XGBoost仅适用于数值型向量，因此在使用时需要将所有其他形式的数据转换为数值型向量；在优化模型时，这个算法还有非常多的参数需要调整。</p>
<p>开发语言：C++<br>开源许可：Apache-2.0 license<br>GitHub项目地址：<a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">https://github.com/dmlc/xgboost</a></p>
<h2 id="16-GoLearn"><a href="#16-GoLearn" class="headerlink" title="16. GoLearn"></a>16. GoLearn</h2><p>GoLearn 是Go 语言中“功能齐全”的机器学习库，简单性及自定义性是其开发目标。</p>
<p>在安装 GoLearn 时，数据作为实例被加载，然后可以在其上操作矩阵，并将操作值传递给估计值。GoLearn 实现了Fit/Predict的Scikit-Learn界面，因此用户可轻松地通过反复试验置换出估计值。此外，GoLearn还包括用于数据的辅助功能，例如交叉验证、训练以及爆裂测试。</p>
<p>开发语言：Go<br>GitHub项目地址: <a href="https://github.com/sjwhitworth/golearn" target="_blank" rel="external">https://github.com/sjwhitworth/golearn</a></p>
<h2 id="17-ML-for-Hackers"><a href="#17-ML-for-Hackers" class="headerlink" title="17. ML_for_Hackers"></a>17. ML_for_Hackers</h2><p>ML_for_Hackers 是针对黑客机器学习的代码库，该库包含了所有针对黑客的机器学习的代码示例（2012）。该代码可能和文中出现的并不完全相同，因为自出版以来，可能又添加了附加的注释和修改部分。<br>所有代码均为R语言，依靠众多的R程序包，涉及主题包括分类(Classification)、排行(Ranking)、以及回归(Regression)的所有常见的任务和主成分分析(PCA)和多维尺度(Multi-dimenstional Scaling)等统计方法。</p>
<p>开发语言：R<br>开源许可：Simplified BSD License<br>GitHub项目地址: <a href="https://github.com/johnmyleswhite/ML_for_Hackers" target="_blank" rel="external">https://github.com/johnmyleswhite/ML_for_Hackers</a></p>
<h2 id="18-H2O-2"><a href="#18-H2O-2" class="headerlink" title="18. H2O-2"></a>18. H2O-2</h2><p>H2O使得Hadoop能够做数学运算！它可以通过大数据衡量统计数据、机器学习和数学。H2O是可扩展的，用户可以在核心区域使用简单的数学模型构建模块。H2O保留着与R、Excel 和JSON等相类似的熟悉的界面，使得大数据爱好者及专家们可通过使用一系列由简单到高级的算法来对数据集进行探索、变换、建模及评分。采集数据很简单，但判决难度却很大，而H2O却通过更快捷、更优化的预测模型，能够更加简单迅速地从数据中获得深刻见解。<br>0xdata H2O的算法是面向业务流程——欺诈或趋势预测。Hadoop专家可以使用Java与H2O相互作用，但框架还提供了对Python、R以及Scala的捆绑。</p>
<p>开发语言：Java<br>GitHub项目地址: <a href="https://github.com/h2oai/h2o-2" target="_blank" rel="external">https://github.com/h2oai/h2o-2</a></p>
<h2 id="19-neon"><a href="#19-neon" class="headerlink" title="19. neon"></a>19. neon</h2><p>neon 是 Nervana 基于 Python 语言的深度学习框架，在诸多常见的深层神经网络中都能够获得较高的性能，比如AlexNet、VGG 或者GoogLeNet。在设计 neon 时，开发者充分考虑了如下功能：</p>
<p>支持常用的模型及实例，例如 Convnets、 MLPs、 RNNs、LSTMs、Autoencoders 等，其中许多预训练的实现都可以在模型库中发现；<br>与麦克斯韦GPU中fp16 和 fp32(基准) 的nervanagpu 内核紧密集成；<br>在Titan X（1 GPU ~ 32 hrs上可完整运行）的AlexNet上为3s/macrobatch（3072图像）；<br>快速影像字幕模型（速度比基于 NeuralTalk 的CPU 快200倍）。<br>支持基本自动微分；<br>框架可视化；<br>可交换式硬盘后端：一次编写代码，然后配置到 CPU、GPU、或者 Nervana 硬盘。<br>在 Nervana中，neon被用来解决客户在多个域间存在的各种问题。</p>
<p>开发语言：Python<br>开源许可：Apache-2.0 license<br>GitHub项目地址: <a href="https://github.com/NervanaSystems/neon" target="_blank" rel="external">https://github.com/NervanaSystems/neon</a></p>
<h2 id="20-Oryx-2"><a href="#20-Oryx-2" class="headerlink" title="20. Oryx 2"></a>20. Oryx 2</h2><p><strong>开源项目Oryx提供了简单且实时的大规模机器学习、预测分析的基础设施。它可实现一些常用于商业应用的算法类：协作式过滤/推荐、分类/回归、集群等。</strong> 此外，Oryx 可利用 Apache Hadoop 在大规模数据流中建立模型，还可以通过HTTP REST API 为这些模型提供实时查询，同时随着新的数据不断流入，可以近似地自动更新模型。这种包括了计算层和服务层的双重设计，能够分别实现一个Lambda 架构。模型在PMML格式交换。</p>
<p><img src="https://oss.aliyuncs.com/yqfiles/c00167f81913b02beffd3ce3bb6e0539bc33de61.png" alt=""></p>
<p>Oryx本质上只做两件事：建模和为模型服务，这就是计算层和服务层两个独立的部分各自的职责。计算层是离线、批量的过程，可从输入数据中建立机器学习模型，它的经营收益在于“代”，即可利用某一点处输入值的快照建模，结果就是随着连续输入的累加，随时间生成一系列输出；服务层也是一个基于Java长期运行的服务器进程，它公开了REST API。使用者可从浏览器中访问，也可利用任何能够发送HTTP请求的语言或工具进行访问。</p>
<p>Oryx的定位不是机器学习算法的程序库，Owen关注的重点有四个：<strong>回归、分类、集群和协作式过滤（也就是推荐）。</strong> 其中推荐系统非常热门，Owen正在与几个Cloudera的客户合作，帮他们使用Oryx部署推荐系统。</p>
<p>开发语言：Java<br>GitHub项目地址: <a href="https://github.com/cloudera/oryx" target="_blank" rel="external">https://github.com/cloudera/oryx</a></p>
<h2 id="21-Shogun"><a href="#21-Shogun" class="headerlink" title="21. Shogun"></a>21. Shogun</h2><p>Shogun是一个机器学习工具箱，由Soeren Sonnenburg 和Gunnar Raetsch（创建，其重点是大尺度上的内核学习方法，特别是支持向量机（SVM，Support Vector Machines）的学习工具箱。它提供了一个通用的连接到几个不同的SVM实现方式中的SVM对象接口，目前发展最先进的LIBSVM和SVMlight 也位于其中，每个SVM都可以与各种内核相结合。工具箱不仅为常用的内核程序（如线性、多项式、高斯和S型核函数）提供了高效的实现途径，还自带了一些近期的字符串内核函数，例如局部性的改进、Fischer、TOP、Spectrum、加权度内核与移位，后来有效的LINADD优化内核函数也已经实现。</p>
<p>此外，Shogun还提供了使用自定义预计算内核工作的自由，其中一个重要特征就是可以通过多个子内核的加权线性组合来构造的组合核，每个子内核无需工作在同一个域中。通过使用多内核学习可知最优子内核的加权。</p>
<p>目前Shogun可以解决SVM 2类的分类和回归问题。此外Shogun也添加了了像线性判别分析（LDA）、线性规划（LPM）、（内核）感知等大量线性方法和一些用于训练隐马尔可夫模型的算法。</p>
<p>开发语言：C/C++、Python<br>许可协议：GPLv3<br>GitHub项目地址: <a href="https://github.com/shogun-toolbox/shogun" target="_blank" rel="external">https://github.com/shogun-toolbox/shogun</a></p>
<h2 id="22-HLearn"><a href="#22-HLearn" class="headerlink" title="22. HLearn"></a>22. HLearn</h2><p>HLearn是由Haskell语言编写的高性能机器学习库，目前它对任意维度空间有着最快最近邻的实现算法。</p>
<p>HLearn同样也是一个研究型项目。该项目的研究目标是为机器学习发掘“最佳可能”的接口。这就涉及到了两个相互冲突的要求：该库应该像由C/C++/Fortran/Assembly开发的底层库那样运行快速；同时也应该像由Python/R/Matlab开发的高级库那样灵活多变。Julia在这个方向上取得了惊人的进步，但是 HLearn“野心”更大。更值得注意的是，HLearn的目标是比低级语言速度更快，比高级语言更加灵活。</p>
<p>为了实现这一目标，HLearn采用了与标准学习库完全不同的接口。在HLearn中H代表着三个不同的概念，这三个概念也是HLearn设计的基本要求：<br>H代表Haskell。机器学习是从数据中预测函数，所以功能性编程语言适应机器学习是完全说的通的。但功能性编程语言并没广泛应用于机器学习，这是因为它们固来缺乏支持学习算法的快速数值计算能力。HLearn通过采用Haskell中的SubHask库获得了快速数值计算能力；</p>
<p>H同时代表着Homomorphisms。Homomorphisms是抽象代数的基本概念，HLearn将该代数结构用于学习系统中；</p>
<p>H还代表着History monad。在开发新的学习算法过程中，最为困难的任务之一就是调试优化过程。在此之前，是没有办法减轻调试过程的工作量的，但History monad正在试图解决该问题。它可以让你在整个线程优化代码的过程中无需修改原代码。此外，使用该技术时没有增加其他的运行开销。</p>
<p>开发语言：Haskell<br>GitHub项目地址:<a href="https://github.com/mikeizbicki/HLearn" target="_blank" rel="external">https://github.com/mikeizbicki/HLearn</a></p>
<h2 id="23-MLPNeuralNet"><a href="#23-MLPNeuralNet" class="headerlink" title="23. MLPNeuralNet"></a>23. MLPNeuralNet</h2><p>MLPNeuralNet是一个针对iOS和Mac OS系统的快速多层感知神经网络库，可通过已训练的神经网络预测新实例。它利用了向量运算和硬盘加速功能（如果可用），其建立在苹果公司的加速框架之上。</p>
<p><img src="https://oss.aliyuncs.com/yqfiles/682d99f3480a87a17b03a9986c8e13bed6abde79.png" alt=""></p>
<p>若你已经用Matlab（Python或R）设计了一个预测模型，并希望在iOS应用程序加以应用。在这种情况下，正好需要MLP NeuralNet，而MLP NeuralNet只能加载和运行前向传播方式的模型。MLP NeuralNet 有如下几个特点：</p>
<p>分类、多类分类以及回归输出；<br>向量化实现形式；<br>双精度；<br>多重隐含层数或空（此时相当于逻辑学/线性回归）。</p>
<p>开发语言：Objective-C<br>许可协议：BSD license<br>GitHub项目地址: <a href="https://github.com/nikolaypavlov/MLPNeuralNet" target="_blank" rel="external">https://github.com/nikolaypavlov/MLPNeuralNet</a></p>
<h2 id="24-Apache-Mahout"><a href="#24-Apache-Mahout" class="headerlink" title="24. Apache Mahout"></a>24. Apache Mahout</h2><p>Mahout 是Apache Software Foundation（ASF） 旗下的一个开源项目，<strong>提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。Apache Mahout项目的目标是建立一个能够快速创建可扩展、高性能机器学习应用的环境。</strong></p>
<p>虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：<br>Taste CF，Taste是Sean Owen在SourceForge上发起的一个针对CF的开源项目，并在2008年被赠予Mahout；<br>一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift；<br>Distributed Naive Bayes 和 Complementary Naive Bayes 分类实现；<br>针对进化编程的分布式适用性功能；<br>Matrix 和矢量库。<br>使用 Mahout 还可实现内容分类。Mahout 目前支持两种根据贝氏统计来实现内容分类的方法：第一种方法是使用简单的支持 Map-Reduce 的 Naive Bayes 分类器；第二种方法是 Complementary Naive Bayes，它会尝试纠正Naive Bayes方法中的一些问题，同时仍然能够维持简单性和速度。</p>
<p>开发语言：Java<br>许可协议：Apache<br>GitHub项目地址: <a href="https://github.com/apache/mahout" target="_blank" rel="external">https://github.com/apache/mahout</a></p>
<h2 id="25-Seldon-Server"><a href="#25-Seldon-Server" class="headerlink" title="25. Seldon Server"></a>25. Seldon Server</h2><p>Seldon是一个开放式的预测平台，提供内容建议和一般的功能性预测。它在Kubernetes集群内运行，因此可以调配到Kubernetes范围内的任一地址：内部部署或云部署（例如，AWS、谷歌云平台、Azure）。另外，它还可以衡量大型企业安装的需求。</p>
<p>开发语言：Java<br>GitHub项目地址: <a href="https://github.com/SeldonIO/seldon-server" target="_blank" rel="external">https://github.com/SeldonIO/seldon-server</a></p>
<h2 id="26-Datumbox-Framework"><a href="#26-Datumbox-Framework" class="headerlink" title="26. Datumbox - Framework"></a>26. Datumbox - Framework</h2><p>Datumbox机器学习框架是用Java编写的一个开源框架，该框架的涵盖大量的机器学习算法和统计方法，并能够处理大尺寸的数据集。</p>
<p><strong>Datumbox API提供了海量的分类器和自然语言处理服务，能够被应用在很多领域的应用，包括了情感分析、话题分类、语言检测、主观分析、垃圾邮件检测、阅读评估、关键词和文本提取等等。目前，Datumbox所有的机器学习服务都能够通过API获取，该框架能够让用户迅速地开发自己的智能应用。目前，基于GPL3.0的Datumbox机器学习框架已经开源并且可以从GitHub上进行下载。</strong></p>
<p>Datumbox的机器学习平台很大程度上已经能够取代普通的智能应用。它具有如下几个显著的优点：</p>
<p>强大并且开源。Datumbox API使用了强大的开源机器学习框架Datumbox，使用其高度精确的算法能够迅速地构建创新的应用；<br>易于使用。平台API十分易于使用，它使用了REST&amp;JSON的技术，对于所有的分类器；<br>迅速使用。Datumbox去掉了那些很花时间的复杂机器学习训练模型。用户能够通过平台直接使用分类器。</p>
<p>Datumbox主要可以应用在四个方面：<br>一个是社交媒体的监视，评估用户观点能够通过机器学习解决，Datumbox能够帮助用户构建自己的社交媒体监视工具；<br>第二是搜索引擎优化，其中非常有效的方法就是文档中重要术语的定位和优化；<br>第三点是质量评估，在在线通讯中，评估用户产生内容的质量对于去除垃圾邮件是非常重要的，Datumbox能够自动的评分并且审核这些内容；<br>最后是文本分析，自然语言处理和文本分析工具推动了网上大量应用的产生，平台API能够很轻松地帮助用户进行这些分析。</p>
<p>开发语言：Java<br>许可协议：Apache License 2.0<br>GitHub项目地址: <a href="https://github.com/datumbox/datumbox-framework" target="_blank" rel="external">https://github.com/datumbox/datumbox-framework</a></p>
<h2 id="27-Jubatus"><a href="#27-Jubatus" class="headerlink" title="27. Jubatus"></a>27. Jubatus</h2><p>Jubatus库是一个运行在分布式环境中的在线机器学习框架，即面向大数据数据流的开源框架。它和Storm有些类似，但能够提供更多的功能，主要功能如下：<br>在线机器学习库：包括分类、聚合和推荐；<br>Fv_converter: 数据预处理（用自然语言）；<br>在线机器学习框架，支持容错。</p>
<p>Jubatus认为未来的数据分析平台应该同时向三个方向展开：处理更大的数据，深层次的分析和实时处理。于是Jubatus将在线机器学习，分布式计算和随机算法等的优势结合在一起用于机器学习，并支持分类、回归、推荐等基本元素。根据其设计目的，Jubatus有如下的特点： </p>
<p>可扩展：支持可扩展的机器学习处理。在普通硬件集群上处理数据速度高达100000条/秒； ＋实时计算：实时分析数据和更新模型；<br>深层次的数据分析：支持各种分析计算：分类、回归、统计、推荐等。<br>如果有基于流数据的机器学习方面的需求，Jubatus值得关注。</p>
<p>开发语言：C/C++<br>许可协议：LGPL<br>GitHub项目地址: <a href="https://github.com/jubatus/jubatus" target="_blank" rel="external">https://github.com/jubatus/jubatus</a></p>
<h2 id="28-Decider"><a href="#28-Decider" class="headerlink" title="28. Decider"></a>28. Decider</h2><p>Decider 是另一个 Ruby 机器学习库，兼具灵活性和可扩展性。Decider内置了对纯文本和URI、填充词汇、停止词删除、字格等的支持，以上这些都可以很容易地在选项中组合。Decider 可支持Ruby中任何可用的存储机制。如果你喜欢，可以保存到数据库中，实现分布式分类。<br>Decider有几个基准，也兼作集成测试。这些都是定期运行并用于查明CPU和RAM的瓶颈。Decider可以进行大量数学运算，计算相当密集，所以对速度的要求比较高。这是经常使用Ruby1.9和JRuby测试其计算速度。此外，用户的数据集应该完全在内存中，否则将会遇到麻烦。</p>
<p>开发语言：Ruby<br>GitHub项目地址: <a href="https://github.com/danielsdeleo/Decider" target="_blank" rel="external">https://github.com/danielsdeleo/Decider</a></p>
<p>编译自：<a href="https://github.com/showcases/machine-learning" target="_blank" rel="external">https://github.com/showcases/machine-learning</a><br>译者：刘崇鑫 校对：王殿进</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://yq.aliyun.com/articles/30794?spm=5176.100239.blogcont30796.7.1WRiYX&quot;&gt;云栖社区 readygo &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;现在机器学习逐渐成为行业热门，经过二十几年的发展，机器学习得到了十分广泛的应用，如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、DNA序列测序、战略游戏和机器人等方面。 云栖社区特意翻译整理了目前GitHub上最受欢迎的28款开源的机器学习项目，以供开参考使用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://oss.aliyuncs.com/yqfiles/f7ee0537b3263e5874f6d0533a46422c61508308.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
  </entry>
  
  <entry>
    <title>谷歌机器学习白皮书全解析43条黄金法则</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Concepts/white-paper-of-google-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Concepts/white-paper-of-google-machine-learning/</id>
    <published>2017-02-19T15:57:00.000Z</published>
    <updated>2017-02-19T06:03:00.880Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201701/FmC6Z2X6UeCvgGEV.html" target="_blank" rel="external">雷锋网</a></p>
<p>谷歌白皮书原文地址：<a href="http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf" target="_blank" rel="external">http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf</a></p>
<p>编者按：此白皮书为谷歌总结的机器学习（ML）最优实践方法，浓缩了其多年技术积累与经验，尤其是 Youtube、Google Play 和 Google+ 等平台背后的 ML 算法开发、维护经历。谷歌于白皮书中总结了四十三条 ML 黄金法则，旨在帮助已经掌握了基础知识的开发者少走弯路。鉴于其珍贵程度与技术性，雷锋网逐条做了严格尊重原文的翻译。若你已学习过机器学习课程，抑或有开发 ML 模型的经验，那么应当具备足够的背景知识理解这篇文章。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/58878244a09a3.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
  <a id="more"></a>
<p>  术语</p>
<p>以下是对文中反复出现的术语的解释。</p>
<p>实例（ Instance）：做预测的对象。比如说，实例可以是一个网页，你想要把它分类为“关于猫”或者“与猫不相关”。</p>
<p>标记（Label）：预测任务的答案。它既可以是机器学习系统生成的答案，也可以是训练数据中提供的正确答案（雷锋网注：比如监督学习中的人工标记）。举例来说，一个网页的标记可以是“关于猫”。</p>
<p>特征（Feature）：预测任务中实例的属性。比如说，某网页可能有“包含关键词‘猫’”的特征</p>
<p>特征栏 （Feature Column）:这是谷歌自创的术语，意为关联特征的集合。比如说，用户的所有可能居住国家的集合。一个样例的特征栏可以有一个或多个特征。特征栏可被看作是 VW 系统（微软、雅虎所用）中的命名空间，或者场（ field）。</p>
<p>样例（Example）：有标记的实例（具备特征）。</p>
<p>模型（Model）：对预测任务的统计表达。你用样例训练模型，然后用模型做预测。</p>
<p>指标（Metric）：你在意的数字。可被直接优化过，也可没有。</p>
<p>目标（Objective）：你的算法试图优化的指标。</p>
<p>流水线（Pipeline）：机器学习算法的基础设施；包括从前端收集数据，把它放入训练数据文档，训练一个或多个模型，以及把模型输出、产品化。</p>
<p>概览：</p>
<p>为了开发出好产品：</p>
<p>做机器学习这一行首先要摆正心态，你是一名（优秀的）工程师，不要拿专家的标准来要求自己。</p>
<p>事实上，你将要面对的大多数难题是工程问题（engineering problems）。即便是一个杰出的ML 专家，坐拥该级别才有的资源，其大多数收获也来自于特征而不是 ML 算法。所以，ML 开发的基本路线是：</p>
<p>保证可靠的端到端流水线</p>
<p>从制定合理的目标着手</p>
<p>用简单的方式，加入符合常识的特征</p>
<p>确保流水线始终可靠</p>
<p>该方法能帮你赚钱养家，并且让很多人满意。只有当无路可走、简单的技巧无法再起作用时，你才需要偏离该路线。但注意，提高复杂度会拖慢将来的产品发布。另外，当你穷尽了简单技巧，或许就到了登堂入室、探索 ML 最前沿技术的时候了。具体请看本文机器学习第三阶。</p>
<p>本文分为四个部分：</p>
<p>第一部分“1.0 做机器学习之前”，会帮你搞清楚，你创建机器学习系统的时机是否已经成熟。</p>
<p>第二部分“2.0 机器学习第一阶”是关于设置你的第一个流水线。</p>
<p>第三部分“3.0 机器学习第二阶”，关乎启动和重复，同时向流水线加入新特征。</p>
<p>最后一部分“4.0 机器学习第三阶”是关于达到瓶颈后怎么办。</p>
<p>43 条黄金法则列表：</p>
<ol>
<li><p>对发布一个不含 ML 技术的产品，不要有顾虑</p>
</li>
<li><p>首先要设计和贯彻指标</p>
</li>
<li><p>在机器学习和复杂启发算法之间，选择前者</p>
</li>
<li><p>第一个模型要简单，把基础设施弄好</p>
</li>
<li><p>测试基础设施要与 ML 测试分开</p>
</li>
<li><p>复制流水线时当心数据遗落</p>
</li>
<li><p>把启发式（heuristics）变为特征，不然就对它们做外部处理</p>
</li>
<li><p>了解系统的时效性</p>
</li>
<li><p>在输出模型之前发现问题</p>
</li>
<li><p>于无声处听惊雷：注意没表现出来的故障</p>
</li>
<li><p>注意特征栏的维护者和文件</p>
</li>
<li><p>选择直接优化哪个目标时，不需要想太多</p>
</li>
<li><p>选择一个简单、可观察并且可归属（attributable）的指标来作为第一个目标</p>
</li>
<li><p>用可解释的模型开头，修补漏洞会更简单</p>
</li>
<li><p>用 policy layer（规则层）把垃圾信息过滤和质量排序分来</p>
</li>
<li><p>做好模型被推倒和重建的准备</p>
</li>
<li><p>直接以观察到的或报告的特征开始训练，而不是经过学习的特征</p>
</li>
<li><p>从不同的上下文环境中提取特征</p>
</li>
<li><p>尽量选择更具体的特征</p>
</li>
<li><p>以合理的方式组合、修改现有特征</p>
</li>
<li><p>通过线性模型学到的特征权重的数目，大致与数据量成正比</p>
</li>
<li><p>清理不需要的特征</p>
</li>
<li><p>你并不是一个典型的用户</p>
</li>
<li><p>版本之间存在对等差分（symmetric difference）</p>
</li>
<li><p>选择模型时，性能胜过预测能力</p>
</li>
<li><p>从误差中查找新模式、创建新特征</p>
</li>
<li><p>尝试量化观察到的异常行为</p>
</li>
<li><p>注意短期行为和长期行为的差别</p>
</li>
<li><p>确保训练和服务一样好的最直接办法是：保存服务时使用的特征，然后将这些特征导入日志，以便在训练中使用。</p>
</li>
<li><p>重视采样数据</p>
</li>
<li><p>注意表格中的数据可能改变</p>
</li>
<li><p>尽量在训练和服务流水线中复用代码</p>
</li>
<li><p>训练和测试的数据不能相同</p>
</li>
<li><p>在二进制分类过滤的应用场景中（例如垃圾邮件检测），不要为了纯净的数据做太大的性能牺牲</p>
</li>
<li><p>注意排序问题的固有偏差</p>
</li>
<li><p>避免具有位置特征的反馈回路</p>
</li>
<li><p>测量训练/服务偏差</p>
</li>
<li><p>如果目标之间不搭，并成为问题，就不要在新特征上浪费时间</p>
</li>
<li><p>模型发布决策是长期产品目标的代理</p>
</li>
<li><p>保证集成模型（ensemble）的简洁</p>
</li>
<li><p>当性能达到瓶颈，相比精炼现存信号，不如寻找新性质的信息源</p>
</li>
<li><p>不要期望多样性、个性化、相关性和受欢迎程度之间有紧密联系</p>
</li>
<li><p>不同产品中，你的朋友总是那一个，你的兴趣不会如此</p>
</li>
</ol>
<h2 id="1-0-做机器学习之前"><a href="#1-0-做机器学习之前" class="headerlink" title="1.0 做机器学习之前"></a>1.0 做机器学习之前</h2><ol>
<li>对发布一个不含 ML 技术的产品，不要有顾虑</li>
</ol>
<p>机器学习很酷，但要有数据。理论上，你可以把另一个相近课题的数据拿来用，调整下模型变成一个新产品。但这么做的实际效果，通常比简单的启发式算法（heuristics）还差。如果你认为机器学习能完成任务的 100%。那么启发式算法能帮你完成 50%。</p>
<p>比如说，若你为应用商店进行 app 排名，不妨直接利用下载率和装机量写个简单算法；若你在检测垃圾邮件，可以先把发送过垃圾邮件的地址过滤掉。也不要在人工编辑上有顾虑。如果机器学习对于你的产品不是必需的，那么在获得数据之前不要用它。</p>
<ol>
<li>首先要设计和贯彻指标</li>
</ol>
<p>在定义你的 ML 系统要做什么之前，要尽可能多得追踪你当前的系统。这出于以下原因：</p>
<p>在早期，获得系统用户的许可相对容易。</p>
<p>如果你认为有些东西在将来需要考虑，最好从现在起就收集历史数据。</p>
<p>如果你设计系统时考虑了指标的工具化（ metric instrumentation），会省下将来的许多力气。你绝对不想为了指标而查找日志字符串。</p>
<p>有些东西会改变，有些不会。比如说，假设你想要直接优化每日活跃用户。但是，在你对系统的早期操作中，你也许会发现用户体验的大幅变化并不会显著改变这个指标。</p>
<p>Google+ 团队会衡量每次阅读的扩展数（expands per read）、分享、点赞、评论，以及每用户评论数、分享等等。然后他们利用这些数据计算发布消息的质量。另外要注意，能通过试验把用户分组并整合数据的试验框架非常重要，参考第 12 条。</p>
<p>通过更灵活地收集指标，你能用更大的视角观察系统。发现一个问题？添加一个指标来追踪它！对上一个发布版本的量化变动很兴奋？添加指标来追踪!</p>
<ol>
<li>在机器学习和复杂启发算法之间，选择前者</li>
</ol>
<p>一个简单的启发算法能帮助产品走向市场，而复杂启发算法难以维护。一旦你有了数据以及需要实现的目标的蓝图，就可以转去开发 ML。在大多数软件工程任务中，开发者需要不停更新开发方式，不管是启发式算法还是 ML 模型。你会发现后者更加容易更新维护（参考第 16 条）。</p>
<h2 id="2-0-机器学习第一阶"><a href="#2-0-机器学习第一阶" class="headerlink" title="2.0 机器学习第一阶"></a>2.0 机器学习第一阶</h2><p>2.1 你的第一条流水线</p>
<p>对于第一条流水线，关注你的系统基础设施。虽然，设想你将要做的种种 ML 应用很有趣；但如果你无法信任自己的流水线，你会很难搞清楚状况。</p>
<ol>
<li>第一个模型要简单，把基础设施弄好</li>
</ol>
<p>第一个模型为你的产品提供了最大的助力，所以它不需要花哨。而且你会遇到许多想象之外的基础设施问题。在你的新 ML 系统诞生之前，你需要决定：</p>
<p>如何获取学习算法的样例</p>
<p>对于你的系统，“好”、“坏”的定义是什么</p>
<p>如何把模型整合入应用。你可以实时应用模型，也可以在线下预计算模型，并把结果保存好。比如对网页预分类，然后在表格里保存结果。但有的任务可能需要对实时聊天信息进行分类。</p>
<p>选择简单的特征更容易保证：</p>
<p>这些特征正确应用于学习算法</p>
<p>模型学会合理的权重。</p>
<p>这些特征正确应用于服务器模型。</p>
<p>当你有了能可靠做到上述三点的系统，大部分的工作就已完成。简单模型提供给你基础的指标和行为，然后你可以用它们来测试更复杂的模型。有些团队把目标定为“中性”的首发——故意在首次发布不那么重视机器学习成果，以避免分心。</p>
<ol>
<li>测试基础设施要与 ML 测试分开</li>
</ol>
<p>要确保基础设施可测试，而且系统的学习部分都被包含在内，使得你能够测试所有相关物。特别是：</p>
<p>测试把数据导入算法。检查可填充的特征栏是不是空的。若条件允许，手工检查训练算法的输入。若可能，把流水线数据与其他地方作比较，比如 RASTA。</p>
<p>测试把数据导出训练算法。确保训练环境的模型与服务环境（serving environment）的模型产生同样的得分（详见第 37 条）。</p>
<p>ML 有不可预测的因素。所以一定要对生成训练、服务样例的代码进行测试；这样你可以在服务中载入、使用固定模型。另外，理解你的数据也十分重要。</p>
<ol>
<li>复制流水线时当心数据遗落</li>
</ol>
<p>我们经常复制现成的流水线来创建新流水线（例如 cargo cult 编程），但有时旧流水线遗落了新流水线需要的数据。举个例子， Google Plus What’s Hot（雷锋网按：社交软件 Google+ 的热门新闻版块） 的流水线会遗落旧帖子（因为它试图为新帖子排名）。我们复制该流水线，用于 Google Plus Stream（Google+ 流）。对于后者，旧帖子仍然有意义，但新流水线仍然会丢掉数据。</p>
<p>另一个常见的模式是只记录用户看过的数据。因此，当你需要对为什么用户没有看到某个信息进行建模，该数据完全没用——因为所有反例已经被丢掉了。Google Play 发生过一个类似的问题：当我们开发 Google Play 应用商城主页时，创建出的新流水线包含另外两个登录页面（Play Games Home and Play Home Home，游戏主页和家庭主页）的样例。但是，并没有能够对“样例来自于哪个主页”加以区分的特征。</p>
<ol>
<li>把启发式（heuristics）变为特征，不然就对它们做外部处理</li>
</ol>
<p>通常来讲，ML 试图解决的问题并不是什么新问题——一般有现成的排名、分类等各种系统。这意味着有一大堆规则和启发式算法可用。这些启发式能在你调整 ML 时起到帮助。你应该压榨出启发式算法的所有信息，这有两个原因：1. 到 ML 系统的过渡会更顺畅。2. 这些规则通常包含一大堆关于系统的直觉信息，你绝对不想把它们扔掉。有四种利用现成启发式算法的途径：</p>
<p>使用启发式算法预处理。如果该特征非常棒，那么这就是一个选择。举个垃圾邮件过滤器的例子，若发件人已经被加入黑名单，不要试图重新学习“加入黑名单”是啥意思。直接拦截该信息。该方法最适用于二分类任务。</p>
<p>创建特征。直接用启发式创建特征相当棒。比如说，如果你用启发式计算一个问题结果的相关度分值，你可以把该得分作为特征值。之后，你或许想用 ML 技术来操作数值（比如把数值转化为有限个独立值集合，或与其他特征合并），但却拿启发式生成的原始数值来开头。</p>
<p>挖掘启发式的原始输入。如果有面向 APP 的启发式把装机量、文字中字母数目和日期组合到一起，就得考虑把它们分开——把这些输入分开来学习。有些应用于整体的技巧可用在这里（详见第 40 条）。</p>
<p>修正标记。当你发现启发式抓取了标记中未包含的信息时，这是一个选择。举个例子，如果你试图最大化下载量，但却仍然想要高品质内容，那么或许最好的方案是把标记与 APP 的平均星星得分相乘。这里有很大的余地。请参考“2.3 你的第一个目标”部分。</p>
<p>请注意启发式为 ML 系统加入的复杂度。在新 ML 算法中加入旧启发式有助于平滑地过渡，但你需要考虑是否更简单的实现方式。</p>
<p>2.2 监测</p>
<p>总的来讲，养成处理警告（alerts）的好习惯，比如对每个提醒付诸行动，并且建立一个仪表页面（dashboard page）。</p>
<ol>
<li>了解系统的时效性</li>
</ol>
<p>当你的模型已经开发出来一天、一周、一季度了，它的效果分别会降低多少？该信息能帮助你理解维护任务的优先级。假设模型一天没更新，你就要损失 10% 的收入。那么你或许要考虑雇佣专人每天维护。许多广告服务系统每天都有需要处理的新广告，因此必须每日更新。再举一个例子，如果 Google Play 的搜索 ML 模型停止更新，一个月内就会造成很大的损失。Google+ What’s Hot（雷锋网注：热门推荐）的一些模型，并没有针对发布信息的身份确认机制，所以不需要频繁导出这些模型。但有身份确认机制的模型就需要非常频繁地更新。另外需注意，时效性会随时间而变化，尤其是为模型添加或移除特征栏的时候。</p>
<ol>
<li>在输出模型之前发现问题</li>
</ol>
<p>许多 ML 系统包含该步骤：输出模型到服务端。如果输出的模型有问题，会直接让用户们遇上。而这个环节之前的问题只是训练问题，不会影响用户体验。</p>
<p>在导出模型之前一定要检查，尤其要确保模型在给定数据上有合理的效果。另外，若你对数据有顾虑，不要输出该模型。许多开发团队会在模型输出前检查 ROC 曲线 (或 AUC) 下的区域。未输出的模型存在问题，可能只需要一封 email 提醒一下。但用户端模型出了问题，很可能需要你向上司、同事解释一整页。所以最好多花点时间，在影响到用户之前做到胸有成竹。</p>
<ol>
<li>于无声处听惊雷：注意没表现出来的故障</li>
</ol>
<p>这是一个多见于机器学习、而少见于其他系统的问题。设想一个不再更新的特定表格：机器学习系统会调整，其行为仍会有合理表现，但逐渐退化。有时候开发者会发现过期几个月的表格——这时，一个简单的更新所提高的性能，比该季度的所有发布新版本都要高。举个例子，对一个特征的取舍会因为执行情况的变化而变化：覆盖 90% 样例的特征栏可能突然降低到只覆盖 60%。Google Play 曾经就有一个过期了六个月的表格，单单更新那个表格就带来了 2% 的安装率提升。如果你对统计数据进行跟踪，并偶尔人工检查，就能减少这类失误。</p>
<ol>
<li>注意特征栏的维护者和文件</li>
</ol>
<p>如果系统很大、有许多特征栏，你需要知道谁创立、维护了每一个特征栏。如果你发现懂得特征栏的那个人要跳槽了，一定要确保团队里有还有人知道这些信息。虽然许多特征栏有描述名称，你仍然需要更详细的解释，知道它是什么、从哪里来、起什么作用。</p>
<p>2.3 你的第一个目标</p>
<p>你有许多关心的系统指标或度量，但 ML 算法通常只需要一个目标——算法试图优化的某个数字。这里，我要区别目标（objectives）和指标（metrics）：指标是系统报告的任何数字，或许重要，或许不重要。详见第二条。</p>
<ol>
<li>选择直接优化哪个目标时，不需要想太多</li>
</ol>
<p>你想要赚钱，让用户满意，并且让地球更美好。有许多你关心的指标，你应该全部都去测量（见第二条）。但在 ML 初期，你会注意到它们全都有提升，即便是那些没有直接优化的也是如此。举个例子，假设你关注点击数、浏览时间和每日活跃用户。如果你优化点击数，你会看到浏览时间也在上升。</p>
<p>所以简简单单就好。当你能轻易地提高所有指标，不需要在不同指标之间的平衡上想太多。但也不要误解这条建议：别把目标与系统最终的健康混为一谈（详见第 39 条）。另外，如果你增加了直接优化的指标，但决定不予发布，或许有必要重新修订目标。</p>
<ol>
<li>选择一个简单、可观察并且可归属（attributable）的指标来作为第一个目标</li>
</ol>
<p>很多情况下你不知道真正的目标是什么——你以为你知道。但当你仔细观察数据，以及对旧系统和新 ML 系统进行分析，你意识到自己其实想要对原定目标进行修改。团队不同成员也经常无法在真正的目标上取得一致意见。ML 目标应当易于测量，并可作为“真正”目标的代理。所以最好采用简单的 ML 目标训练，然后考虑在这之上设一个 “policy layer”（规则层），允许你加入额外的逻辑（但愿是简单的逻辑）来做最终排名。</p>
<p>最容易建模的是，能被直接观察到、并且可归属于系统中某个行动的用户行为：</p>
<p>这个排名链接被点击了吗?</p>
<p>这个排名对象被下载了吗？</p>
<p>这个排名对象被 转发/回复/发 email 了吗？</p>
<p>这个排名对象被打分了吗？</p>
<p>这个显示的对象被标记为垃圾邮件/色情信息/侮辱性信息了吗？</p>
<p>一开始要避免对间接作用建模：</p>
<p>用户在第二天访问了吗？</p>
<p>用户的访问时间是多长？</p>
<p>每日活跃用户都是谁？</p>
<p>其实，间接作用是非常不错的指标，并且可在 A/B 测试和发布决定中使用。</p>
<p>最后，不要试图让 ML 搞懂：</p>
<p>用户对使用该产品满意吗?</p>
<p>用户对体验满意吗？</p>
<p>产品提升了用户的福祉了吗？</p>
<p>这如何影响公司的整体健康？</p>
<p>这些都很重要，但是极度困难。你应该用代理来替代：如果用户感到开心，他们会在页面停留更长时间。如果用户满意，他明天会再次访问。目前，当涉及到福祉和公司健康状态，把 ML 目标与产品本质和商业计划之间做关联需要人的判断。</p>
<ol>
<li>用可解释的模型开头，修补漏洞会更简单</li>
</ol>
<p>线性回归、逻辑回归、泊松回归（Poisson regression）直接被概率模型驱动，每个预测都可作为概率或期望值解释。这使得相比使用了目标、直接优化分类精度或排序效果的模型（zero­one 损失、各种 hinge 损失等等），它们修补漏洞更加简单。如果通过对比或检查产品系统，发现训练里的概率偏离了预测概率，就可能存在问题。</p>
<p>比如说，在线性回归、逻辑回归、泊松回归之中，有的数据子集里平均预期和平均标签相等（1-­moment 校准，或者普通校准 ）。对于一个值要么是 0 要么是 1 的特征，三个特征值为 1 的样例集就会被校准。同样地，若某特征下所有样例的特征值都是 1，它们都会被校准。</p>
<p>对于简单的模型，处理反馈回路（ feedback loops ）更加容易。我们经常用这些概率预期来做决定：比如以期望值（点击概率/下载量等）为标准对发布消息进行降序排列。但要记住，当决定采用那个模型的时候，你的决定比给定模型数据的可能性（ the likelihood of the data given the model ）更加重要（参考第 21 条）。</p>
<ol>
<li>用 policy layer（规则层）把垃圾信息过滤和质量排序分来</li>
</ol>
<p>质量排序是一门高雅的艺术，而垃圾信息过滤是一场战争。对于使用你系统的人，你用来判断高质量消息的信号十分显而易见。然后，他们会据此调整他们的发布信息来获得这些属性。因此，你的质量排序应当专注于有信誉的内容——不应该让质量排序学习器退化到给垃圾信息高排名。同样的，重口味内容应当与质量排序分开。而垃圾信息过滤是另一回事了。你需要创建的特征会不断变化，对此要有心理准备。通常，你加入系统里的规则有些很显而易见（比如，若一个发布信息得到超过三个“垃圾信息”票数，不要恢复它）。任何学习到的模型需要至少每天更新。内容生产者的名誉会起到相当大的作用。</p>
<p>在某个层级，这两个系统的输出需要整合在一起。需要注意的是，在搜索结果里过滤垃圾信息，比过滤垃圾邮件要更加强力。 为了高质量的分类器而去除训练数据中的垃圾，已是行业标准。</p>
<h2 id="3-0-机器学习第二阶段"><a href="#3-0-机器学习第二阶段" class="headerlink" title="3.0 机器学习第二阶段"></a>3.0 机器学习第二阶段</h2><p>3.1 特征工程</p>
<p>在进行机器学习相关实践的第一阶段，你要关注的主要问题包括以下三个方面：一是将训练数据导入系统，二是确定系统的重点关注指标，三是保证底层基础设施的稳定可靠。当这三个问题都确认无误，即已经搭建了一个端到端的可稳定运行的系统，并且针对系统本身和其中的每个单元都经过了严格测试，这时就可以进入第二阶段了。</p>
<p>应该说，第二阶段将更容易取得成绩。这一阶段会有许多显著的特征（feature）被导入系统，因此，导入并以直观的方式组合这些特征，将是本阶段涉及的主要任务。另外，本阶段也更适合多位工程师协同工作，共同对此前导入的训练数据进行整合和处理，推动所有的指标（metric）在本阶段取得持续性的上升。</p>
<ol>
<li>做好模型被推倒和重建的准备</li>
</ol>
<p>不要指望从头到尾只使用一个模型，也不要指望着某一结点之后就不用重建模型了，模型的推倒和重建是机器学习过程中的必修课。另外，每加入一个新特性都必须考虑是否会拉低模型的运行效率。目前，许多团队每三个月或一年就会新建一个模型。这里我们总结了一般情况下引发模型重建的三大原因：</p>
<p>1) 增加新的特征</p>
<p>2) 打算重组旧的特征，或对旧模型正则化</p>
<p>3) 修订建模目标</p>
<p>无论如何，创建模型时多想想并没有什么坏处：例如检查训练数据是否有更合理的组织形式，考虑当前的建模方式是否便于特征的修改和重组，当前的机器学习流水线（pipeline）是否便于创建副本并检验其正确率，以及是否可以创建两到三个副本并行运行等等。最后需要指出的是，并不一定非要在一个机器学习流水线中覆盖所有特征，在下一个版本中实现也是可行的。</p>
<ol>
<li>直接以观察到的或报告的特征开始训练，而不是经过学习的特征</li>
</ol>
<p>这一点建议或许存在一些争议，但的确能避免许多潜在的问题。这里经过学习的特征（learned feature）是指由外部系统（例如无监督的聚类系统）或模型本身（例如通过深度学习和因子模型）产生的特征。这两种情况虽然的确可以使用，但并不适合系统的第一个模型。</p>
<p>首先，在使用外部系统创建特征时必须要格外小心。因为外部系统的目标可能与当前系统并不相符，而且从外部系统更新当前系统的特征，其特定的含义也可能改变。</p>
<p>另一方面，因子模型和深度模型的主要问题是它们是非凸的（non-convex），因此它们无法保证可以最终找到或近似找到最优解，它们在每次迭代中产生的局部最小值都可能变化，而且目前无法评估这种变化对系统的影响是有益的还是有害的。通过创建没有深度特征的模型，你就可以获得很好的基准性能。在实现这一基准性能之后，你可以尝试更高阶的方法。</p>
<ol>
<li>从不同的上下文环境中提取特征</li>
</ol>
<p>通常情况下，机器学习只占到一个大系统中的很小一部分，因此你必须要试着从不同角度审视一个用户行为。比如热门推荐这一场景，一般情况下论坛里“热门推荐”里的帖子都会有许多评论、分享和阅读量，如果利用这些统计数据对模型展开训练，然后对一个新帖子进行优化，就有可能使其成为热门帖子。另一方面，YouTube上自动播放的下一个视频也有许多选择，例如可以根据大部分用户的观看顺序推荐，或者根据用户评分推荐等。总之，如果你将一个用户行为用作模型的标记（label），那么在不同的上下文条件下审视这一行为，可能会得到更丰富的特征（feature），也就更利于模型的训练。需要注意的是这与个性化不同：个性化是确定用户是否在特定的上下文环境中喜欢某一内容，并发现哪些用户喜欢，喜欢的程度如何。</p>
<ol>
<li>尽量选择更具体的特征</li>
</ol>
<p>在海量数据的支持下，即使学习数百万个简单的特征也比仅仅学习几个复杂的特征要容易实现。由于被检索的文本标识与规范化的查询并不会提供太多的归一化信息，只会调整头部查询中的标记排序。因此你不必担心虽然整体的数据覆盖率高达90%以上，但针对每个特征组里的单一特征却没有多少训练数据可用的情况。另外，你也可以尝试正则化的方法来增加每个特征所对应的样例数。</p>
<ol>
<li>以合理的方式组合、修改现有的特征</li>
</ol>
<p>目前有多种方法组合、修改现有的特征，由于本文以Google工具为背景，因此在这里推荐两种TensorFlow框架已实现好的方法：“离散化”（discretizations）和“交叉”（crosses）。</p>
<p>离散化主要包含提取连续特征和从连续特征中创建离散特征两个部分。比如对于年龄这一连续的特征，你就可以创建这样的离散特征：当年龄小于18时结果为1，或者当年龄介于18-35之间时为1，等等。另外，不要过分考虑直方图中基本分位数的问题。</p>
<p>在TensorFlow的术语中，特征栏是一组相似的特征，比如{男性，女性}，{美国，加拿大，墨西哥}等。这里的交叉是指将两个或多个特征栏合并，例如{男性，女性}×{美国，加拿大，墨西哥}的结果就是一个交叉（a cross），也就构成了一个新的特征栏。假设你利用TensorFlow框架创建了这样一个交叉，其中也就包含了{男性，加拿大}的特征，因此这一特征也就会出现在男性加拿大人的样例中。需要注意的是，交叉方法中合并的特征栏越多，所需要的训练数据量就越大。</p>
<p>如果通过交叉法生成的特征栏特别庞大，那么就可能引起过拟合。例如，假设你正在进行某种搜索，并且在查询请求和文档中都具有一个包含关键字的特征栏。那么假如你选择用交叉法组合这两个特征栏，这样得到的新特征栏就会非常庞大，它内部包含了许多特征。当这种情况发生在文本搜索场景时，有两种可行的应对方法。最常用的是点乘法（dot produc），点乘法最常见的处理方式就是统计查询请求和文档中共同的所有特征词，然后对特征离散化。另一个方法是交集（intersection），比如当且仅当关键词同时出现在文档和查询结果中时，我们才能获取所需的特征。</p>
<ol>
<li>通过线性模型学到的特征权重的数目，大致与数据量成正比</li>
</ol>
<p>许多人都认为从一千个样例中并不能得到什么可靠的训练结果，或者由于选择了某种特定的模型，就必须获取一百万个样例，否则就没法展开模型训练。这里需要指出的是，数据量的大小是和需要训练的特征数是正相关的：</p>
<p>1) 假如你在处理一个搜索排名问题，文档和查询请求中包含了数百万个不同的关键词，并且有一千个被标记的样例，那么你应该用上文提到的点乘法处理这些特征。这样就能得到一千个样例，对应了十几个特征。</p>
<p>2) 如你有一百万个样例，那么通过正则化和特征选择的方式就可以交叉处理文档和查询请求中的特征栏，这可能会产生数百万的特征数，但再次使用正则化可以大大减少冗余特征。这样就可能得到一千万个样例，对应了十万个特征。</p>
<p>3) 如果你有数十亿或数百亿个样例，那同样可以通过特征选择或正则化的方法交叉处理文档和查询请求中的特征栏。这样就可能得到十亿个样例，对应了一千万个特征。</p>
<p>对特征数和样例来说，这些统计学上的结论并不能给出一个具体的比例关系，但却可以从数量级上给出一些指导。另外，这里推荐用户依照第28条建议来选择具体使用哪些特征。</p>
<ol>
<li>清理不需要的特征</li>
</ol>
<p>如果你发现有些特征并没有在使用，而且将其与其他特征相结合之后也无法使用的话，就应该清理这些特征。应该保持系统的清洁，这样才能尽快尝试那些最有希望出结果的特征。而且，如果有必要，被删除的特征也可以随时找人加回来。</p>
<p>在考虑增删一个特征时，应该仔细排查其覆盖范围。例如你有一些个性化的特征，但只有大约8%的用户使用了该特征，那么删掉或添加这个特征就不会有太大影响。</p>
<p>另一方面，增删特征时也要考虑其对应的数据量。例如你有一个只覆盖了1%数据的特征，但有90%的包含这一特征的样例都通过了训练，那么这就是一个很好的特征，应该添加。</p>
<p>3.2 对系统的人工分析</p>
<p>在进入机器学习实践的第三阶段之前，关注一些课堂上不曾教授的问题也同样至关重要，比如如何检查一个模型并改进它。要说这一点是一门科学，反而不如说它是一种艺术，这里我们介绍几点反面模式（anti-patterns）。</p>
<ol>
<li>你并不是一个典型的用户</li>
</ol>
<p>这可能是让一个团队陷入困境的最简单的方法。虽然fishfooding（只在团队内部使用原型）和dogfooding（只在公司内部使用原型）都有许多优点，但无论哪一种，开发者都应该首先确认这种方式是否符合性能要求。另一方面，应该尽量避免不好的变化，但任何看起来合理的产品策略都应该被进一步验证，例如通过非专业人士在众包平台上的问卷调查，或者请目标用户来实测。</p>
<p>走外部验证渠道的原因来自两个方面：一是作为开发者，你太熟悉代码。例如你可能正在分析数据的某一方面而非全局，或者投入了太多的个人感情色彩，从而引发一些偏见。二是几位工程师开一个小时的讨论会议得到的评估结果，可能远比不上直接交给众包平台来得简单和有效。</p>
<p>如果你真的想要获取用户反馈，那么应该采用用户体验法（user experience methodologies）。 在流程早期创建用户角色（详情见Bill Buxton的《Designing User Experiences》一书），然后进行可用性测试（详情见Steve Krug的《Do not Make Me Think》一书）。这里的用户角色涉及创建假想用户。例如，假设你的团队成员都是男性，现在要针对35岁女性用户研发一款产品，那么基于目标群体创建一个假想角色，肯定比几位25-40岁的男性开发者闭门造车的效果要好。当然，让用户实测产品并观察他们的反应也是很不错的方法。</p>
<ol>
<li>版本之间存在对等差分（symmetric difference）</li>
</ol>
<p>将产品交付至用户之前，有时候最简单有效的做法就是评估当前版本与交付版本的差异。例如面对排名问题，你可以在两个版本间利用同一组样例进行测试，然后对比其结果。如果差异很小，那么意味着这个版本没问题。如果差异很大，那么就需要确认进行了哪些修改，为什么进行这些修改。通过查看哪些测试样例造成了这一差异，也有助于定性了解修改具体是怎样的。总之，目标是确保不同版本的模型之间的对等差分做到最小。</p>
<ol>
<li>选择模型时，性能胜过预测能力</li>
</ol>
<p>你的模型可能会被用来预测点击率，但更关键问题是：这种预测是应用在什么场景的。如果你用它来排列文档，那么最终排名的质量显然比预测本身更重要。如果你用它来排查垃圾邮件，那么识别精度显然更重要。大多数情况下，这两类功能应该是一致的，如果他们存在不一致，则意味着系统可能存在某种小增益。因此，假如一个改进措施可以解决日志丢失的问题，但却造成了系统性能的下降，那就不要采用它。当这种情况频繁发生时，通常应该重新审视你的建模目标。</p>
<ol>
<li>从误差中查找新模式、创建新特征</li>
</ol>
<p>假设你的模型在某个样例中预测错误。在分类任务中，这可能是误报或漏报。在排名任务中，这可能是一个正向判断弱于逆向判断的组。但更重要的是，在这个样例中机器学习系统知道它错了，需要修正。如果你此时给模型一个允许它修复的特征，那么模型将尝试自行修复这个错误。</p>
<p>另一方面，如果你尝试基于未出错的样例创建特征，那么该特征将很可能被系统忽略。例如，假设在谷歌Play商店的应用搜索中，有人搜索“免费游戏”，但其中一个排名靠前的搜索结果却是一款其他App，所以你为其他App创建了一个特征。但如果你将其他App的安装数最大化，即人们在搜索免费游戏时安装了其他App，那么这个其他App的特征就不会产生其应有的效果。</p>
<p>所以，正确的做法是一旦出现样例错误，那么应该在当前的特征集之外寻找解决方案。例如，如果你的系统降低了内容较长的帖子的排名，那就应该普遍增加帖子的长度。而且也不要拘泥于太具体的细节。例如你要增加帖子的长度，就不要猜测长度的具体含义，而应该直接添加几个相关的特征，交给模型自行处理，这才是最简单有效的方法。</p>
<ol>
<li>尝试量化观察到的异常行为</li>
</ol>
<p>有时候团队成员会对一些没有被现有的损失函数覆盖的系统属性感到无能为力，但这时抱怨是没用的，而是应该尽一切努力将抱怨转换成实实在在的数字。例如，当有些开发者认为在谷歌Play商店的搜索结果中显示了过多的其他App，就可以选择人工识别的方法剔除这些App（这时是可以选择人工标记数据的，因为相对较小的App查询可能占了很大一部分流量）。首先要确认你的问题是可量化的，然后才可以根据这些问题创建新的特征（features）、目标（objectives）或者指标（metrics）。总之规则是：先量化，再优化。</p>
<ol>
<li>注意短期行为和长期行为的差别</li>
</ol>
<p>假设你有一个新系统，它可以查看每个doc_id和exact_query，然后根据每个文档的每次查询行为计算其点击率。你发现它的行为几乎与当前系统的并行和A/B测试结果完全相同，而且它很简单，于是你启动了这个系统。但却没有新的应用显示，为什么？由于你的系统只基于自己的历史查询记录显示文档，所以不知道应该显示一个新的文档。</p>
<p>要了解一个系统在长期行为中如何工作的唯一办法，就是让它只基于当前的模型数据展开训练。这一点非常困难。</p>
<p>3.3 训练服务的偏差（Training­-Serving Skew）</p>
<p>这里训练服务偏差是指系统在训练时的性能表现和服务中的性能表现出现差别。造成这种差别的原因可能有如下三个方面：</p>
<p>1) 在训练和服务中的数据处理流水线不同；</p>
<p>2) 在训练和服务中使用了不同的数据；</p>
<p>3) 模型和算法间的反馈回路引起。</p>
<p>我们注意到谷歌的机器学习系统也存在训练服务偏差，而且会对性能产生负面影响。这里需要说明的是：最好的解决办法就是明确地监视它，使系统和数据的改变不至于引发潜在的偏差。</p>
<ol>
<li>确保训练和服务一样好的最直接办法是：保存服务时使用的特征，然后将这些特征导入日志，以便在训练中使用</li>
</ol>
<p>即使你不能对每个样例都这样做，做一小部分也比什么也不做好，这样你就可以验证服务和训练之间的一致性（见规则37）。在谷歌采取了这项措施的团队有时候会对其效果感到惊讶。比如YouTube主页在服务时会切换到日志记录特征，这不仅大大提高了服务质量，而且减少了代码复杂度。目前有许多团队都已经在其基础设施上采用了这种策略。</p>
<ol>
<li>重视采样数据</li>
</ol>
<p>当数据太多时，有些团队可能会选择丢弃一部分以减轻负担。这是一个明显的错误：历史经验证明在训练过程中丢弃数据将引发一系列问题（详见规则6）。当然，有时候的确可以丢弃数据，比如那些从未向用户显示过的，但重要性加权却是更好的选择。重要性加权意味着，如果你决定以30%的概率对样例X进行抽样，则权重应该是3/10。值得一提的是，使用重要性加权并不影响规则14中讨论的校准属性。</p>
<ol>
<li>注意表格中的数据可能改变</li>
</ol>
<p>假设你通过包含文件特征的表格（表格中还可能包含评论或点击的次数）加入文件的ID信息，那么需要注意表格中的特征可能会在训练和服务的不同时间点发生一些变化，造成模型对同一文档的预测也跟着改变。避免此类问题的最简单方法是在服务时记录特征（请参阅规则32）。如果表格的变化足够缓慢的话，你可以每天或每小时都记录一次表格以获得非常接近的数据，但需要注意的是，这并不能完全解决问题。</p>
<ol>
<li>尽量在训练和服务流水线中复用代码</li>
</ol>
<p>首先需要明确的一点是：批处理与在线处理不同。在线处理中，你必须在每个请求到达时及时处理（例如必须为每个查询单独查找）；而在批处理中，你可以组合任务（例如建立联结）。类似的，可以将服务视为在线处理过程，而训练视为批处理过程，而其中有许多代码是可以复用的。比如说，你可以创建特定于系统的对象，其中的所有联结和查询结果都以人类可读的方式存储，错误也可以被简单地测试。然后，一旦在服务或训练期间收集了所有信息，你就可以通过一种通用方法在这个特定对象和机器学习系统需要的格式之间形成互通，训练和服务的偏差也得以消除。另外，由此推知：最好不要在训练和服务期间使用不同的编程语言（因为不同的语言间几乎无法复用）。</p>
<ol>
<li>训练和测试的数据不能相同</li>
</ol>
<p>一般来说，最好用不同的数据对模型进行训练和测试，例如你用1月5日之前的数据训练了一个模型，那么最好用1月6日之后的数据对模型展开测试。可能模型对新数据的性能表现不如训练数据，但也不会太糟。由于可能会产生每日效应（daily effects），因此你可能无法预测平均点击率或转化率，但曲线下方的面积（表示正面样例的分数高于反面样例的可能性）应该是接近的。</p>
<ol>
<li>在二进制分类过滤的应用场景中（例如垃圾邮件检测），不要为了纯净的数据做太大的性能牺牲</li>
</ol>
<p>一般在过滤应用场景中，反面样例并不会对用户展示。不过假如你的过滤器在服务过程中阻止了75%的反面样例，那么你可能需要从向用户显示的实例中提取额外的训练数据并展开训练。比如说，用户将系统认可的邮件标记为垃圾邮件，那么你可能就需要从中学习。</p>
<p>但这种方法同时也引入了采样偏差。如果改为在服务期间将所有流量的1%标记为“暂停”，并将所有这样的样例发送给用户，那你就能收集更纯净的数据。现在你的过滤器阻止了至少74％的反面样例，这些样例可以成为训练数据。</p>
<p>需要注意的是，如果你的过滤器阻止了95%或更多的反面样例，那这种方法可能就不太适用。不过即使如此，如果你想衡量服务的性能，可以选择做出更细致的采样（例如0.1%或0.001%），一万个例子足以准确地估计性能。</p>
<ol>
<li>注意排序问题的固有偏差</li>
</ol>
<p>当你彻底改变排序算法时，一方面会引起完全不同的排序结果，另一方面也可能在很大程度上改变算法未来可能要处理的数据。这会引入一些固有偏差，因此你必须事先充分认识到这一点。以下这些方法可以有效帮你优化训练数据。</p>
<p>1) 对涵盖更多查询的特征进行更高的正则化，而不是那些只覆盖单一查询的特征。这样，模型将偏好于那些基于一个或几个特定查询的特征，而不是所有的特征。这种方式可以有效防止那些最常见的查询结果泄漏到不相关的查询中。需要注意的是，这与一条更传统的建议相左：更多地正则化一些具有单一值的特征栏。</p>
<p>2) 只允许特征具有正向权重，这样一来就能保证任何好特征都会比未知特征合适。</p>
<p>3) 不要选择那些只处理文档数据的特征。例如，不管搜索请求是什么，即使一个给定的应用程序是当前的热门下载，你也不会想在所有地方都显示它。没有文档特征的话，这一点会很容易做到。</p>
<ol>
<li>避免具有位置特征的反馈回路</li>
</ol>
<p>内容的位置会显著影响用户与它交互的可能性。很明显，如果你把一个App置顶，那它一定会更频繁地被点击。处理这类问题的一个有效方法是加入位置特征，即关于页面中的内容的位置特征。假如你用正向特征来训练模型，那模型就会更偏向“1st-position”这类的特征。因而模型对其他因素的权重就会相应地减小，例如对“1st-position = true”这种样例。在服务的时候，你可以选择不提供任何位置特征的实例，或者为所有位置特征设置相同的初始值，因为在决定以怎样的顺序显示它们之前，你具有决策权。</p>
<p>需要注意的是，因为训练和测试的不对称性，所以最好在一些位置特征和模型之间保持一定的分离性，这一点很重要。让模型成为位置特征函数和其他特征函数的和，是理想的状态。比如说，最好不要交叉任何文档特征和位置特征。</p>
<ol>
<li>测量训练/服务偏差</li>
</ol>
<p>许多情况都会引起偏差，但它们大多可以分为如下三类：</p>
<p>1) 训练数据和测试数据的性能之间的差异。一般来说，这总是存在的，但并不会太严重。</p>
<p>2) 测试数据的性能与“第二天数据”（next-day data）之间的差异。同样，这也会一直存在。你可以不同程度地正则化以最大限度地提高第二天的性能（next-day performance）。然而，如果在测试数据和第二天数据之间存在很大的性能下降，这有可能意味着某些特征是时间敏感的，而且整个模型的性能也会跟着下降。</p>
<p>3) “第二天数据”和实时数据的性能之间的差异。如果你将模型应用于训练数据的样例，也应用于相同的服务样例，则它们应该给出完全相同的结果（详见规则5）。因此，这里的差异可能是指工程误差。</p>
<h2 id="4-0-机器学习第三阶"><a href="#4-0-机器学习第三阶" class="headerlink" title="4.0 机器学习第三阶"></a>4.0 机器学习第三阶</h2><p>4.1 减慢的增速，精细优化和复杂模型</p>
<p>第二阶段将要结束的时候，一定会有些信号。首先，你每月的收益开始降低。你开始要在指标之间做牺牲：一些试验中有的上升有的下降。从此情况变得更有趣。由于更难产生效益，机器学习不得不变得更复杂。</p>
<p>警告：这部分有许多开放式的实践法则。我们亲眼看着很多团队走过第一阶段和第二阶段的幸福期——一旦到达第三阶段，开发团队就不得不找出他们自己的路。</p>
<ol>
<li>如果目标之间不搭，并成为问题，就不要在新特征上浪费时间</li>
</ol>
<p>当达到度量瓶颈，你的团队开始关注 ML 系统目标范围之外的问题。如同之前提到的，如果产品目标没有包括在算法目标之内，你就得修改其中一个。比如说，你也许优化的是点击数、点赞或者下载量，但发布决策部分依赖于人类评估者。</p>
<ol>
<li>模型发布决策是长期产品目标的代理</li>
</ol>
<p>（雷锋网注：谷歌工程师在这里举了个例子）Alice 有一个关于降低安装预测的逻辑损失的想法。她加入一个特征。逻辑损失下降。当她实时测试时，安装量上升了。但在公司的发布会议上，有人指出每日活跃用户数降低了 5%。团队决定不发布该模型。Alice 很失望，但意识到发布决策取决于多个标准，其中只有一部分能够被 ML 直接优化。</p>
<p>事实是，现实世界并不是网络游戏：没有“攻击值”和“血量”来衡量产品的健康。团队需要利用收集的数据，来试图预测将来系统的表现会怎样。他们需要操心用户黏性、每日活跃用户、每月活跃用户、收入和广告主的收益。这些 A/B 测试中的指标，实际上只是长期目标的代理：让用户满意、增加用户、让合作方满意还有利润；即便这时你还可以考虑高品质、有使用价值的产品的代理，以及五年后一个繁荣的企业的代理。</p>
<p>做出发布决策变得容易的唯一一种情况是：所有指标都变好了（起码没有变差的）。如果团队在复杂 ML 算法和简单启发式算法之间有的选择；如果简单的启发式算法在这些指标上做得更好；那么应当选择后者。另外，所有指标数值并没有明确的排序。更具体的，考虑以下两种情形：</p>
<p>谷歌机器学习白皮书全解析 43条黄金法则（四）</p>
<p>雷锋网注：标题栏（自左至右）为试验，每日活跃用户以及每日收入</p>
<p>如果现有系统是 A ，团队不会想要转移到 B。如果现有系统是 B，团队也不会想要转到 A。这看起来与理性决策相抵触：但是，对指标变化的预期情形或许会发生，或许不会。因此任意一种改变都有相当大的风险。每一个指标覆盖了一些团队所关注的风险。但没有指标能覆盖团队的首要关切——“我的产品在五年后会怎样？”</p>
<p>另一方面，个体倾向于选择能直接优化的目标。大多数 ML 工具喜欢这样的环境。这样的环境下，一个能快速创建新特征的工程师能稳定输出一系列产品发布。有一种叫“多目标学习”（multi­objective learning）的机器学习开始解决这一问题。比如说，可以制定一个在每个指标上有下限的约束满意度问题（constraint satisfaction problem），然后优化指标的一些线性组合。但即便那时，也不是所有指标都能轻易表达为 ML 目标：如果一个文件被点击，或者 APP 被安装，这是因为有内容被展示出来。但搞清楚用户为什么访问你的页面就更加难了。如何预测一个页面在将来是否成功，是一项 AI­-complete 问题（雷锋网注：意味着完成它的难度相当于解决 AI 问题），与计算机视觉和自然语言处理一样难。</p>
<ol>
<li>保证集成模型（ensemble）的简洁</li>
</ol>
<p>接收原始特征、直接对内容排序的统一模型，是最容易理解、最容易修补漏洞的模型。但是，一个集成模型（一个把其他模型得分组合在一起的“模型”）的效果会更好。为保持简洁，每个模型应该要么是一个只接收其他模型的输入的集成模型，要么是一个有多种特征的基础模型，但不能两者皆是。如果你有单独训练、基于其它模型的模型，把它们组合到一起会导致不好的行为。</p>
<p>只用简单模型来集成：那些只把基础模型的输入作为输出、进行接收的模型。你或许想要为这些集成模型强加上属性。比如，基础模型生成得分的提高，不应该降低集成模型的分数。另外，如果连入模型在语义上可解释（比如校准了的）会更好，这样其下层模型不会与集成模型混淆。再者，强行让下层分类器预测的概率升高，不会降低集成模型的预测概率。</p>
<ol>
<li>当性能达到瓶颈，相比精炼现存信号，不如寻找新性质（qualitatively）的信息源</li>
</ol>
<p>你已经加入了一些关于用户的人口统计信息，还有文件中的词语。你经历了模板探索，和正则化（regularization）调参。但连续几个季度的发布，你都没有看到核心指标有超过 1% 的提升。现在怎么办？</p>
<p>你已经到了为不同寻常（雷锋网注：很不一样）的特征，创建基础设施的时候了。比如用户昨天、上周、去年检索的文档，或是另一种属性的数据。为你的公司使用维基数据（wikidata）实体或者一些内部的东西（比如谷歌的知识图，Google’s knowledge graph）。你或许需要使用深度学习。开始调整你对投资回报的期望，并作出相应努力。如同所有工程项目，你需要平衡新增加的特征与提高的复杂度。</p>
<ol>
<li>不要期望多样性、个性化、相关性和受欢迎程度之间有紧密联系</li>
</ol>
<p>一系列内容的多样性能意味着许多东西，内容来源的多样性最为普遍。个性化意味着每个用户得到属于他们自己的结果。相关性意味着一个特定检索的结果，对应它比对应其他检索更合适。因此，这三个属性的定义都有别于“标准”。</p>
<p>但标准更难被打败。</p>
<p>注意：如果你的系统在统计点击量、耗费时间、浏览数、点赞数、分享数等等，你事实上在衡量内容的受欢迎程度。有团队试图学习具备多样性的个性化模型。为个性化，他们加入允许系统进行个性化的特征（有的特征代表用户兴趣），或者加入多样性（表示该文档与其它返回文档有相同特征的特征，比如作者和内容），然后发现这些特征比他们预想的得到更低的权重（有时是不同的信号）。</p>
<p>这不意味着多样性、个性化和相关性就不重要。如同上个法则所指出的，你可以通过后处理来提高多样性或相关性。如果你看到长期目标的进步，那么你可以宣布在受欢迎程度之外，多样性和相关性是有价值的。你可以继续采用后处理，或者直接根据多样性或相关性修改目标。</p>
<ol>
<li>不同产品中，你的朋友总是同一个，你的兴趣不会如此</li>
</ol>
<p>谷歌的 ML 团队  常常把一个预测某产品联系紧密程度（the closeness of a connection in one product）的模型，应用在另一个产品上，然后发现效果很好。另一方面，我见过好几个在产品线的个性化特征上苦苦挣扎的团队。是的，之前看起来它应该能奏效。但现在看来它不会了。有时候起作用的是——用某属性的原始数据来预测另一个属性的行为。即便知道某用户存在另一个属性能凑效的历史，也要记住这一点。比如说，两个产品上用户活动的存在或许就自身说明了问题。</p>
<p>全文结束。感谢您对雷锋网(公众号：雷锋网)的支持。</p>
<p>雷锋网版权文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201701/FmC6Z2X6UeCvgGEV.html&quot;&gt;雷锋网&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;谷歌白皮书原文地址：&lt;a href=&quot;http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf&quot;&gt;http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;编者按：此白皮书为谷歌总结的机器学习（ML）最优实践方法，浓缩了其多年技术积累与经验，尤其是 Youtube、Google Play 和 Google+ 等平台背后的 ML 算法开发、维护经历。谷歌于白皮书中总结了四十三条 ML 黄金法则，旨在帮助已经掌握了基础知识的开发者少走弯路。鉴于其珍贵程度与技术性，雷锋网逐条做了严格尊重原文的翻译。若你已学习过机器学习课程，抑或有开发 ML 模型的经验，那么应当具备足够的背景知识理解这篇文章。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201701/58878244a09a3.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Google" scheme="http://ipcreator.me/tags/Google/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Awesome Machine Learning</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Resources/awesome-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Resources/awesome-machine-learning/</id>
    <published>2017-02-19T15:56:06.000Z</published>
    <updated>2017-02-19T06:03:00.883Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://github.com/josephmisiti/awesome-machine-learning" target="_blank" rel="external">Joseph Misiti/josephmisiti</a></p>
<p>A curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by awesome-php.</p>

<p>If you want to contribute to this list (please do), send me a pull request or contact me <a href="https://twitter.com/josephmisiti" target="_blank" rel="external">@josephmisiti</a><br>Also, a listed repository should be deprecated if:</p>

<ul><br><li>Repository’s owner explicitly say that “this library is not maintained”.</li><br><li>Not committed for long time (2~3 years).</li><br></ul>

<p>For a list of free machine learning books available for download, go <a href="https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md" target="_blank" rel="external">here</a>.</p>

<p>For a list of free-to-attend meetups and local events, go <a href="https://github.com/josephmisiti/awesome-machine-learning/blob/master/meetups.md" target="_blank" rel="external">here</a>.</p>

<a id="more"></a>
<h2><a id="user-content-table-of-contents" class="anchor" href="#table-of-contents" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Table of Contents</h2>



<ul><br><li><a href="#apl">APL</a><br><br><ul><br><li><a href="#apl-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#c">C</a><br><br><ul><br><li><a href="#c-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#c-cv">Computer Vision</a></li><br></ul></li><br><li><a href="#cpp">C++</a><br><br><ul><br><li><a href="#cpp-cv">Computer Vision</a></li><br><li><a href="#cpp-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#cpp-nlp">Natural Language Processing</a></li><br><li><a href="#cpp-sequence">Sequence Analysis</a></li><br><li><a href="#cpp-gestures">Gesture Recognition</a></li><br></ul></li><br><li><a href="#common-lisp">Common Lisp</a><br><br><ul><br><li><a href="#common-lisp-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#clojure">Clojure</a><br><br><ul><br><li><a href="#clojure-nlp">Natural Language Processing</a></li><br><li><a href="#clojure-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#clojure-data-analysis">Data Analysis / Data Visualization</a></li><br></ul></li><br><li><a href="#elixir">Elixir</a><br><br><ul><br><li><a href="#elixir-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#elixir-nlp">Natural Language Processing</a></li><br></ul></li><br><li><a href="#erlang">Erlang</a><br><br><ul><br><li><a href="#erlang-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#go">Go</a><br><br><ul><br><li><a href="#go-nlp">Natural Language Processing</a></li><br><li><a href="#go-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#go-data-analysis">Data Analysis / Data Visualization</a></li><br></ul></li><br><li><a href="#haskell">Haskell</a><br><br><ul><br><li><a href="#haskell-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#java">Java</a><br><br><ul><br><li><a href="#java-nlp">Natural Language Processing</a></li><br><li><a href="#java-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#java-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#java-deep-learning">Deep Learning</a></li><br></ul></li><br><li><a href="#javascript">Javascript</a><br><br><ul><br><li><a href="#javascript-nlp">Natural Language Processing</a></li><br><li><a href="#javascript-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#javascript-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#javascript-misc">Misc</a></li><br></ul></li><br><li><a href="#julia">Julia</a><br><br><ul><br><li><a href="#julia-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#julia-nlp">Natural Language Processing</a></li><br><li><a href="#julia-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#julia-misc">Misc Stuff / Presentations</a></li><br></ul></li><br><li><a href="#lua">Lua</a><br><br><ul><br><li><a href="#lua-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#lua-demos">Demos and Scripts</a></li><br></ul></li><br><li><a href="#matlab">Matlab</a><br><br><ul><br><li><a href="#matlab-cv">Computer Vision</a></li><br><li><a href="#matlab-nlp">Natural Language Processing</a></li><br><li><a href="#matlab-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#matlab-data-analysis">Data Analysis / Data Visualization</a></li><br></ul></li><br><li><a href="#net">.NET</a><br><br><ul><br><li><a href="#net-cv">Computer Vision</a></li><br><li><a href="#net-nlp">Natural Language Processing</a></li><br><li><a href="#net-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#net-data-analysis">Data Analysis / Data Visualization</a></li><br></ul></li><br><li><a href="#objectivec">Objective C</a><br><br><ul><br><li><a href="#objectivec-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#ocaml">OCaml</a><br><br><ul><br><li><a href="#ocaml-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#php">PHP</a><br><br><ul><br><li><a href="#php-nlp">Natural Language Processing</a></li><br><li><a href="#php-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#python">Python</a><br><br><ul><br><li><a href="#python-cv">Computer Vision</a></li><br><li><a href="#python-nlp">Natural Language Processing</a></li><br><li><a href="#python-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#python-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#python-misc">Misc Scripts / iPython Notebooks / Codebases</a></li><br><li><a href="#python-kaggle">Kaggle Competition Source Code</a></li><br><li><a href="#python-neural%20networks">Neural networks</a></li><br></ul></li><br><li><a href="#ruby">Ruby</a><br><br><ul><br><li><a href="#ruby-nlp">Natural Language Processing</a></li><br><li><a href="#ruby-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#ruby-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#ruby-misc">Misc</a></li><br></ul></li><br><li><a href="#rust">Rust</a><br><br><ul><br><li><a href="#rust-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#r">R</a><br><br><ul><br><li><a href="#r-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#r-data-analysis">Data Analysis / Data Visualization</a></li><br></ul></li><br><li><a href="#sas">SAS</a><br><br><ul><br><li><a href="#sas-general-purpose">General-Purpose Machine Learning</a></li><br><li><a href="#sas-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#sas-mpp">High Performance Machine Learning (MPP)</a></li><br><li><a href="#sas-nlp">Natural Language Processing</a></li><br><li><a href="#sas-demos">Demos and Scripts</a></li><br></ul></li><br><li><a href="#scala">Scala</a><br><br><ul><br><li><a href="#scala-nlp">Natural Language Processing</a></li><br><li><a href="#scala-data-analysis">Data Analysis / Data Visualization</a></li><br><li><a href="#scala-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#swift">Swift</a><br><br><ul><br><li><a href="#swift-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#tensor">TensorFlow</a><br><br><ul><br><li><a href="#tensor-general-purpose">General-Purpose Machine Learning</a></li><br></ul></li><br><li><a href="#credits">Credits</a></li><br></ul>



<p></p><p><a name="user-content-apl"></a></p><a name="user-content-apl"><p></p>
<h2><a id="user-content-apl" class="anchor" href="#apl" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>APL</h2>

<p></p></a><p><a name="user-content-apl"></a><a name="user-content-apl-general-purpose"></a></p><a name="user-content-apl-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning" class="anchor" href="#general-purpose-machine-learning" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-apl-general-purpose"><br></a><li><a name="user-content-apl-general-purpose"></a><a href="https://github.com/mattcunningham/naive-apl" target="_blank" rel="external">naive-apl</a> - Naive Bayesian Classifier implementation in APL</li><br></ul><p></p>
<p></p><p><a name="user-content-c"></a></p><a name="user-content-c"><p></p>
<h2><a id="user-content-c" class="anchor" href="#c" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>C</h2>

<p></p></a><p><a name="user-content-c"></a><a name="user-content-c-general-purpose"></a></p><a name="user-content-c-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-1" class="anchor" href="#general-purpose-machine-learning-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-c-general-purpose"><br></a><li><a name="user-content-c-general-purpose"></a><a href="https://github.com/pjreddie/darknet" target="_blank" rel="external">Darknet</a> - Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation.</li><p></p>
<p><li><a href="https://github.com/GHamrouni/Recommender" target="_blank" rel="external">Recommender</a> - A C library for product recommendations/suggestions using collaborative filtering (CF).</li></p>
<p><li><a href="https://github.com/SeniorSA/hybrid-rs-trainner" target="_blank" rel="external">Hybrid Recommender System</a> - A hybrid recomender system based upon scikit-learn algorithms.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-c-cv"></a></p><a name="user-content-c-cv"><p></p>
<h4><a id="user-content-computer-vision" class="anchor" href="#computer-vision" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Computer Vision</h4>

<p></p></a><ul><a name="user-content-c-cv"><br></a><li><a name="user-content-c-cv"></a><a href="https://github.com/liuliu/ccv" target="_blank" rel="external">CCV</a> - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library</li><p></p>
<p><li><a href="http://www.vlfeat.org/" target="_blank" rel="external">VLFeat</a> - VLFeat is an open and portable library of computer vision algorithms, which has Matlab toolbox</li><br></p></ul><p></p>
<h3><a id="user-content-speech-recognition" class="anchor" href="#speech-recognition" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Speech Recognition</h3>

<ul><br><li><a href="http://htk.eng.cam.ac.uk/" target="_blank" rel="external">HTK</a> -The Hidden Markov Model Toolkit (HTK) is a portable toolkit for building and manipulating hidden Markov models.</li><br></ul>

<p></p><p><a name="user-content-cpp"></a></p><a name="user-content-cpp"><p></p>
<h2><a id="user-content-c-1" class="anchor" href="#c-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>C++</h2>

<p></p></a><p><a name="user-content-cpp"></a><a name="user-content-cpp-cv"></a></p><a name="user-content-cpp-cv"><p></p>
<h4><a id="user-content-computer-vision-1" class="anchor" href="#computer-vision-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Computer Vision</h4>

<p></p></a><ul><a name="user-content-cpp-cv"><br></a><li><a name="user-content-cpp-cv"></a><a href="http://dlib.net/imaging.html" target="_blank" rel="external">DLib</a> - DLib has C++ and Python interfaces for face detection and training general object detectors.</li><p></p>
<p><li><a href="http://eblearn.sourceforge.net/" target="_blank" rel="external">EBLearn</a> - Eblearn is an object-oriented C++ library that implements various machine learning models</li></p>
<p><li><a href="http://opencv.org" target="_blank" rel="external">OpenCV</a> - OpenCV has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS.</li></p>
<p><li><a href="https://github.com/ukoethe/vigra" target="_blank" rel="external">VIGRA</a> - VIGRA is a generic cross-platform C++ computer vision and machine learning library for volumes of arbitrary dimensionality with Python bindings.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-cpp-general-purpose"></a></p><a name="user-content-cpp-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-2" class="anchor" href="#general-purpose-machine-learning-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-cpp-general-purpose"><br></a><li><a name="user-content-cpp-general-purpose"></a><a href="https://github.com/jkomiyama/banditlib" target="_blank" rel="external">BanditLib</a> - A simple Multi-armed Bandit library.</li><p></p>
<p><li><a href="http://caffe.berkeleyvision.org" target="_blank" rel="external">Caffe</a>  - A deep learning framework developed with cleanliness, readability, and speed in mind. [DEEP LEARNING]</li></p>
<p><li><a href="https://github.com/Microsoft/CNTK" target="_blank" rel="external">CNTK</a> - The Computational Network Toolkit (CNTK) by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph.</li></p>
<p><li><a href="https://code.google.com/p/cuda-convnet/" target="_blank" rel="external">CUDA</a> - This is a fast C++/CUDA implementation of convolutional [DEEP LEARNING]</li></p>
<p><li><a href="https://github.com/antinucleon/cxxnet" target="_blank" rel="external">CXXNET</a> - Yet another deep learning framework with less than 1000 lines core code [DEEP LEARNING]</li></p>
<p><li><a href="https://github.com/beniz/deepdetect" target="_blank" rel="external">DeepDetect</a> - A machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications.</li></p>
<p><li><a href="http://www.dmtk.io/" target="_blank" rel="external">Disrtibuted Machine learning Tool Kit (DMTK)</a> - A distributed machine learning (parameter server) framework by Microsoft. Enables training models on large data sets across multiple machines. Current tools bundled with it include: LightLDA and Distributed (Multisense) Word Embedding.</li></p>
<p><li><a href="http://dlib.net/ml.html" target="_blank" rel="external">DLib</a> - A suite of ML tools designed to be easy to imbed in other applications</li></p>
<p><li><a href="https://github.com/amznlabs/amazon-dsstne" target="_blank" rel="external">DSSTNE</a> - A software library created by Amazon for training and deploying deep neural networks using GPUs which emphasizes speed and scale over experimental flexibility.</li></p>
<p><li><a href="https://github.com/clab/dynet" target="_blank" rel="external">DyNet</a> - A dynamic neural network library working well with networks that have dynamic structures that change for every training instance. Written in C++ with bindings in Python.</li></p>
<p><li><a href="https://code.google.com/p/encog-cpp/" target="_blank" rel="external">encog-cpp</a></li></p>
<p><li><a href="https://github.com/FidoProject/Fido" target="_blank" rel="external">Fido</a> - A highly-modular C++ machine learning library for embedded electronics and robotics.</li></p>
<p><li><a href="http://igraph.org/c/" target="_blank" rel="external">igraph</a> - General purpose graph library</li></p>
<p><li><a href="https://github.com/01org/daal" target="_blank" rel="external">Intel(R) DAAL</a> - A high performance software library developed by Intel and optimized for Intel’s architectures. Library provides algorithmic building blocks for all stages of data analytics and allows to process data in batch, online and distributed modes.</li></p>
<p><li><a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="external">LightGBM</a> - Microsoft’s fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks.</li></p>
<p><li><a href="http://mldb.ai" target="_blank" rel="external">MLDB</a> - The Machine Learning Database is a database designed for machine learning. Send it commands over a RESTful API to store data, explore it using SQL, then train machine learning models and expose them as APIs.</li></p>
<p><li><a href="http://www.mlpack.org/" target="_blank" rel="external">mlpack</a> - A scalable C++ machine learning library</li></p>
<p><li><a href="http://stat.rutgers.edu/home/tzhang/software/rgf/" target="_blank" rel="external">Regularized Greedy Forest</a> - Regularized greedy forest (RGF) tree ensemble learning method.</li></p>
<p><li><a href="https://root.cern.ch" target="_blank" rel="external">ROOT</a> - A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualization and storage.</li></p>
<p><li><a href="http://image.diku.dk/shark/sphinx_pages/build/html/index.html" target="_blank" rel="external">shark</a> - A fast, modular, feature-rich open-source C++ machine learning library.</li></p>
<p><li><a href="https://github.com/shogun-toolbox/shogun" target="_blank" rel="external">Shogun</a> - The Shogun Machine Learning Toolbox</li></p>
<p><li><a href="https://code.google.com/p/sofia-ml/" target="_blank" rel="external">sofia-ml</a> - Suite of fast incremental algorithms.</li></p>
<p><li><a href="http://mc-stan.org/" target="_blank" rel="external">Stan</a> - A probabilistic programming language implementing full Bayesian statistical inference with Hamiltonian Monte Carlo sampling</li></p>
<p><li><a href="http://ilk.uvt.nl/timbl/" target="_blank" rel="external">Timbl</a> - A software package/C++ library implementing several memory-based learning algorithms, among which IB1-IG, an implementation of k-nearest neighbor classification, and IGTree, a decision-tree approximation of IB1-IG. Commonly used for NLP.</li></p>
<p><li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki" target="_blank" rel="external">Vowpal Wabbit (VW)</a> - A fast out-of-core learning system.</li></p>
<p><li><a href="https://github.com/baidu-research/warp-ctc" target="_blank" rel="external">Warp-CTC</a> - A fast parallel implementation of Connectionist Temporal Classification (CTC), on both CPU and GPU.</li></p>
<p><li><a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">XGBoost</a> - A parallelized optimized general purpose gradient boosting library.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-cpp-nlp"></a></p><a name="user-content-cpp-nlp"><p></p>
<h4><a id="user-content-natural-language-processing" class="anchor" href="#natural-language-processing" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-cpp-nlp"><br></a><li><a name="user-content-cpp-nlp"></a><a href="https://github.com/BLLIP/bllip-parser" target="_blank" rel="external">BLLIP Parser</a> - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser)</li><p></p>
<p><li><a href="https://github.com/proycon/colibri-core" target="_blank" rel="external">colibri-core</a> - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.</li></p>
<p><li><a href="https://taku910.github.io/crfpp/" target="_blank" rel="external">CRF++</a> - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data &amp; other Natural Language Processing tasks.</li></p>
<p><li><a href="http://www.chokkan.org/software/crfsuite/" target="_blank" rel="external">CRFsuite</a> - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data.</li></p>
<p><li><a href="https://github.com/proycon/frog" target="_blank" rel="external">frog</a> - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer.</li></p>
<p><li><a href="https://github.com/proycon/libfolia" target="_blank" rel="external">libfolia</a> - C++ library for the <a href="http://proycon.github.io/folia/" target="_blank" rel="external">FoLiA format</a></li></p>
<p><li><a href="https://github.com/meta-toolkit/meta" target="_blank" rel="external">MeTA</a> - <a href="https://meta-toolkit.org/" target="_blank" rel="external">MeTA : ModErn Text Analysis</a> is a C++ Data Sciences Toolkit that facilitates mining big text data.</li></p>
<p><li><a href="https://github.com/mit-nlp/MITIE" target="_blank" rel="external">MIT Information Extraction Toolkit</a> - C, C++, and Python tools for named entity recognition and relation extraction</li></p>
<p><li><a href="https://github.com/proycon/ucto" target="_blank" rel="external">ucto</a> - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format.</li><br></p></ul><p></p>
<h4><a id="user-content-speech-recognition-1" class="anchor" href="#speech-recognition-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Speech Recognition</h4>

<ul><br><li><a href="http://kaldi.sourceforge.net/" target="_blank" rel="external">Kaldi</a> - Kaldi is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.</li><br></ul>

<p></p><p><a name="user-content-cpp-sequence"></a></p><a name="user-content-cpp-sequence"><p></p>
<h4><a id="user-content-sequence-analysis" class="anchor" href="#sequence-analysis" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Sequence Analysis</h4>

<p></p></a><ul><a name="user-content-cpp-sequence"><br></a><li><a name="user-content-cpp-sequence"></a><a href="https://github.com/ayoshiaki/tops" target="_blank" rel="external">ToPS</a> - This is an objected-oriented framework that facilitates the integration of probabilistic models for sequences over a user defined alphabet.</li><br></ul><p></p>
<p></p><p><a name="user-content-cpp-gestures"></a></p><a name="user-content-cpp-gestures"><p></p>
<h4><a id="user-content-gesture-detection" class="anchor" href="#gesture-detection" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Gesture Detection</h4>

<p></p></a><ul><a name="user-content-cpp-gestures"><br></a><li><a name="user-content-cpp-gestures"></a><a href="https://github.com/nickgillian/grt" target="_blank" rel="external">grt</a> - The Gesture Recognition Toolkit (GRT) is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition.</li><br></ul><p></p>
<p></p><p><a name="user-content-common-lisp"></a></p><a name="user-content-common-lisp"><p></p>
<h2><a id="user-content-common-lisp" class="anchor" href="#common-lisp" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Common Lisp</h2>

<p></p></a><p><a name="user-content-common-lisp"></a><a name="user-content-common-lisp-general-purpose"></a></p><a name="user-content-common-lisp-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-3" class="anchor" href="#general-purpose-machine-learning-3" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-common-lisp-general-purpose"><br></a><li><a name="user-content-common-lisp-general-purpose"></a><a href="https://github.com/melisgl/mgl/" target="_blank" rel="external">mgl</a> - Neural networks  (boltzmann machines, feed-forward and recurrent nets), Gaussian Processes</li><p></p>
<p><li><a href="https://github.com/melisgl/mgl-gpr/" target="_blank" rel="external">mgl-gpr</a> - Evolutionary algorithms</li></p>
<p><li><a href="https://github.com/melisgl/cl-libsvm/" target="_blank" rel="external">cl-libsvm</a> - Wrapper for the libsvm support vector machine library</li><br></p></ul><p></p>
<p></p><p><a name="user-content-clojure"></a></p><a name="user-content-clojure"><p></p>
<h2><a id="user-content-clojure" class="anchor" href="#clojure" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Clojure</h2>

<p></p></a><p><a name="user-content-clojure"></a><a name="user-content-clojure-nlp"></a></p><a name="user-content-clojure-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-1" class="anchor" href="#natural-language-processing-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-clojure-nlp"><br></a><li><a name="user-content-clojure-nlp"></a><a href="https://github.com/dakrone/clojure-opennlp" target="_blank" rel="external">Clojure-openNLP</a> - Natural Language Processing in Clojure (opennlp)</li><p></p>
<p><li><a href="https://github.com/r0man/inflections-clj" target="_blank" rel="external">Infections-clj</a> - Rails-like inflection library for Clojure and ClojureScript</li><br></p></ul><p></p>
<p></p><p><a name="user-content-clojure-general-purpose"></a></p><a name="user-content-clojure-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-4" class="anchor" href="#general-purpose-machine-learning-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-clojure-general-purpose"><br></a><li><a name="user-content-clojure-general-purpose"></a><a href="https://github.com/ptaoussanis/touchstone" target="_blank" rel="external">Touchstone</a> - Clojure A/B testing library</li><p></p>
<p><li><a href="https://github.com/lspector/Clojush" target="_blank" rel="external">Clojush</a> -  The Push programming language and the PushGP genetic programming system implemented in Clojure</li></p>
<p><li><a href="https://github.com/aria42/infer" target="_blank" rel="external">Infer</a> - Inference and machine learning in clojure</li></p>
<p><li><a href="https://github.com/antoniogarrote/clj-ml" target="_blank" rel="external">Clj-ML</a> - A machine learning library for Clojure built on top of Weka and friends</li></p>
<p><li><a href="https://github.com/jimpil/enclog" target="_blank" rel="external">Encog</a> - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets)</li></p>
<p><li><a href="https://github.com/vollmerm/fungp" target="_blank" rel="external">Fungp</a> - A genetic programming library for Clojure</li></p>
<p><li><a href="https://github.com/clojurewerkz/statistiker" target="_blank" rel="external">Statistiker</a> - Basic Machine Learning algorithms in Clojure.</li></p>
<p><li><a href="https://github.com/nupic-community/clortex" target="_blank" rel="external">clortex</a> - General Machine Learning library using Numenta’s Cortical Learning Algorithm</li></p>
<p><li><a href="https://github.com/nupic-community/comportex" target="_blank" rel="external">comportex</a> - Functionally composable Machine Learning library using Numenta’s Cortical Learning Algorithm</li></p>
<p><li><a href="https://github.com/thinktopic/cortex" target="_blank" rel="external">cortex</a> - Neural networks, regression and feature learning in Clojure.</li></p>
<p><li><a href="https://github.com/cloudkj/lambda-ml" target="_blank" rel="external">lambda-ml</a> - Simple, concise implementations of machine learning techniques and utilities in Clojure.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-clojure-data-analysis"></a></p><a name="user-content-clojure-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization" class="anchor" href="#data-analysis--data-visualization" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-clojure-data-analysis"><br></a><li><a name="user-content-clojure-data-analysis"></a><a href="http://incanter.org/" target="_blank" rel="external">Incanter</a> - Incanter is a Clojure-based, R-like platform for statistical computing and graphics.</li><p></p>
<p><li><a href="https://github.com/Netflix/PigPen" target="_blank" rel="external">PigPen</a> - Map-Reduce for Clojure.</li></p>
<p><li><a href="https://github.com/clojurewerkz/envision" target="_blank" rel="external">Envision</a> - Clojure Data Visualisation library, based on Statistiker and D3</li><br></p></ul><p></p>
<p></p><p><a name="user-content-elixir"></a></p><a name="user-content-elixir"><p></p>
<h2><a id="user-content-elixir" class="anchor" href="#elixir" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Elixir</h2>

<p></p></a><p><a name="user-content-elixir"></a><a name="user-content-elixir-general-purpose"></a></p><a name="user-content-elixir-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-5" class="anchor" href="#general-purpose-machine-learning-5" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-elixir-general-purpose"><br></a><li><a name="user-content-elixir-general-purpose"></a><a href="https://github.com/fredwu/simple_bayes" target="_blank" rel="external">Simple Bayes</a> - A Simple Bayes / Naive Bayes implementation in Elixir.</li><br></ul><p></p>
<p></p><p><a name="user-content-elixir-nlp"></a></p><a name="user-content-elixir-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-2" class="anchor" href="#natural-language-processing-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-elixir-nlp"><br></a><li><a name="user-content-elixir-nlp"></a><a href="https://github.com/fredwu/stemmer" target="_blank" rel="external">Stemmer</a> - An English (Porter2) stemming implementation in Elixir.</li><br></ul><p></p>
<p></p><p><a name="user-content-erlang"></a></p><a name="user-content-erlang"><p></p>
<h2><a id="user-content-erlang" class="anchor" href="#erlang" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Erlang</h2>

<p></p></a><p><a name="user-content-erlang"></a><a name="user-content-erlang-general-purpose"></a></p><a name="user-content-erlang-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-6" class="anchor" href="#general-purpose-machine-learning-6" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-erlang-general-purpose"><br></a><li><a name="user-content-erlang-general-purpose"></a><a href="https://github.com/discoproject/disco/" target="_blank" rel="external">Disco</a> - Map Reduce in Erlang</li><br></ul><p></p>
<p></p><p><a name="user-content-go"></a></p><a name="user-content-go"><p></p>
<h2><a id="user-content-go" class="anchor" href="#go" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Go</h2>

<p></p></a><p><a name="user-content-go"></a><a name="user-content-go-nlp"></a></p><a name="user-content-go-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-3" class="anchor" href="#natural-language-processing-3" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-go-nlp"><br></a><li><a name="user-content-go-nlp"></a><a href="https://github.com/reiver/go-porterstemmer" target="_blank" rel="external">go-porterstemmer</a> - A native Go clean room implementation of the Porter Stemming algorithm.</li><p></p>
<p><li><a href="https://github.com/Rookii/paicehusk" target="_blank" rel="external">paicehusk</a> - Golang implementation of the Paice/Husk Stemming Algorithm.</li></p>
<p><li><a href="https://github.com/tebeka/snowball" target="_blank" rel="external">snowball</a> - Snowball Stemmer for Go.</li></p>
<p><li><a href="https://github.com/Lazin/go-ngram" target="_blank" rel="external">go-ngram</a> - In-memory n-gram index with compression.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-go-general-purpose"></a></p><a name="user-content-go-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-7" class="anchor" href="#general-purpose-machine-learning-7" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-go-general-purpose"><br></a><li><a name="user-content-go-general-purpose"></a><a href="https://github.com/MaxHalford/gago" target="_blank" rel="external">gago</a> - Multi-population, flexible, parallel genetic algorithm.</li><p></p>
<p><li><a href="https://github.com/sjwhitworth/golearn" target="_blank" rel="external">Go Learn</a> - Machine Learning for Go</li></p>
<p><li><a href="https://github.com/daviddengcn/go-pr" target="_blank" rel="external">go-pr</a> - Pattern recognition package in Go lang.</li></p>
<p><li><a href="https://github.com/alonsovidales/go_ml" target="_blank" rel="external">go-ml</a> - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution</li></p>
<p><li><a href="https://github.com/jbrukh/bayesian" target="_blank" rel="external">bayesian</a> - Naive Bayesian Classification for Golang.</li></p>
<p><li><a href="https://github.com/thoj/go-galib" target="_blank" rel="external">go-galib</a> - Genetic Algorithms library written in Go / golang</li></p>
<p><li><a href="https://github.com/ryanbressler/CloudForest" target="_blank" rel="external">Cloudforest</a> - Ensembles of decision trees in go/golang.</li></p>
<p><li><a href="https://github.com/goml/gobrain" target="_blank" rel="external">gobrain</a> - Neural Networks written in go</li></p>
<p><li><a href="https://github.com/fxsjy/gonn" target="_blank" rel="external">GoNN</a> - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN</li></p>
<p><li><a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">MXNet</a> - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.</li></p>
<p><li><a href="https://github.com/songtianyi/go-mxnet-predictor" target="_blank" rel="external">go-mxnet-predictor</a> - Go binding for MXNet c_predict_api to do inference with pre-trained model</li><br></p></ul><p></p>
<p></p><p><a name="user-content-go-data-analysis"></a></p><a name="user-content-go-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-1" class="anchor" href="#data-analysis--data-visualization-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-go-data-analysis"><br></a><li><a name="user-content-go-data-analysis"></a><a href="https://github.com/StepLg/go-graph" target="_blank" rel="external">go-graph</a> - Graph library for Go/golang language.</li><p></p>
<p><li><a href="http://www.svgopen.org/2011/papers/34-SVGo_a_Go_Library_for_SVG_generation/" target="_blank" rel="external">SVGo</a> - The Go Language library for SVG generation</li></p>
<p><li><a href="https://github.com/fxsjy/RF.go" target="_blank" rel="external">RF</a> - Random forests implementation in Go</li><br></p></ul><p></p>
<p></p><p><a name="user-content-haskell"></a></p><a name="user-content-haskell"><p></p>
<h2><a id="user-content-haskell" class="anchor" href="#haskell" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Haskell</h2>

<p></p></a><p><a name="user-content-haskell"></a><a name="user-content-haskell-general-purpose"></a></p><a name="user-content-haskell-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-8" class="anchor" href="#general-purpose-machine-learning-8" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-haskell-general-purpose"><br></a><li><a name="user-content-haskell-general-purpose"></a><a href="https://github.com/ajtulloch/haskell-ml" target="_blank" rel="external">haskell-ml</a> - Haskell implementations of various ML algorithms.</li><p></p>
<p><li><a href="https://github.com/mikeizbicki/HLearn" target="_blank" rel="external">HLearn</a> - a suite of libraries for interpreting machine learning models according to their algebraic structure.</li></p>
<p><li><a href="https://wiki.haskell.org/HNN" target="_blank" rel="external">hnn</a> - Haskell Neural Network library.</li></p>
<p><li><a href="https://github.com/ajtulloch/hopfield-networks" target="_blank" rel="external">hopfield-networks</a> - Hopfield Networks for unsupervised learning in Haskell.</li></p>
<p><li><a href="https://github.com/ajtulloch/dnngraph" target="_blank" rel="external">caffegraph</a> - A DSL for deep neural networks</li></p>
<p><li><a href="https://github.com/jbarrow/LambdaNet" target="_blank" rel="external">LambdaNet</a> - Configurable Neural Networks in Haskell</li><br></p></ul><p></p>
<p></p><p><a name="user-content-java"></a></p><a name="user-content-java"><p></p>
<h2><a id="user-content-java" class="anchor" href="#java" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Java</h2>

<p></p></a><p><a name="user-content-java"></a><a name="user-content-java-nlp"></a></p><a name="user-content-java-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-4" class="anchor" href="#natural-language-processing-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-java-nlp"><br></a><li><a name="user-content-java-nlp"></a><a href="http://www.cortical.io/" target="_blank" rel="external">Cortical.io</a> - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc…) as quickly and intuitively as the brain.</li><p></p>
<p><li><a href="http://nlp.stanford.edu/software/corenlp.shtml" target="_blank" rel="external">CoreNLP</a> - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words</li></p>
<p><li><a href="http://nlp.stanford.edu/software/lex-parser.shtml" target="_blank" rel="external">Stanford Parser</a> - A natural language parser is a program that works out the grammatical structure of sentences</li></p>
<p><li><a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank" rel="external">Stanford POS Tagger</a> - A Part-Of-Speech Tagger (POS Tagger</li></p>
<p><li><a href="http://nlp.stanford.edu/software/CRF-NER.shtml" target="_blank" rel="external">Stanford Name Entity Recognizer</a> - Stanford NER is a Java implementation of a Named Entity Recognizer.</li></p>
<p><li><a href="http://nlp.stanford.edu/software/segmenter.shtml" target="_blank" rel="external">Stanford Word Segmenter</a> - Tokenization of raw text is a standard pre-processing step for many NLP tasks.</li></p>
<p><li><a href="http://nlp.stanford.edu/software/tregex.shtml" target="_blank" rel="external">Tregex, Tsurgeon and Semgrex</a> - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for “tree regular expressions”).</li></p>
<p><li><a href="http://nlp.stanford.edu/software/phrasal/" target="_blank" rel="external">Stanford Phrasal: A Phrase-Based Translation System</a></li></p>
<p><li><a href="http://nlp.stanford.edu/software/tokenizer.shtml" target="_blank" rel="external">Stanford English Tokenizer</a> - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java.</li></p>
<p><li><a href="http://nlp.stanford.edu/software/tokensregex.shtml" target="_blank" rel="external">Stanford Tokens Regex</a> - A tokenizer divides text into a sequence of tokens, which roughly correspond to “words”</li></p>
<p><li><a href="http://nlp.stanford.edu/software/sutime.shtml" target="_blank" rel="external">Stanford Temporal Tagger</a> - SUTime is a library for recognizing and normalizing time expressions.</li></p>
<p><li><a href="http://nlp.stanford.edu/software/patternslearning.shtml" target="_blank" rel="external">Stanford SPIED</a> - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion</li></p>
<p><li><a href="http://nlp.stanford.edu/software/tmt/tmt-0.4/" target="_blank" rel="external">Stanford Topic Modeling Toolbox</a> - Topic modeling tools to social scientists and others who wish to perform analysis on datasets</li></p>
<p><li><a href="https://github.com/twitter/twitter-text-java" target="_blank" rel="external">Twitter Text Java</a> - A Java implementation of Twitter’s text processing library</li></p>
<p><li><a href="http://mallet.cs.umass.edu/" target="_blank" rel="external">MALLET</a> - A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.</li></p>
<p><li><a href="https://opennlp.apache.org/" target="_blank" rel="external">OpenNLP</a> - a machine learning based toolkit for the processing of natural language text.</li></p>
<p><li><a href="http://alias-i.com/lingpipe/index.html" target="_blank" rel="external">LingPipe</a> - A tool kit for processing text using computational linguistics.</li></p>
<p><li><a href="https://code.google.com/p/cleartk/" target="_blank" rel="external">ClearTK</a> - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA.</li></p>
<p><li><a href="http://ctakes.apache.org/" target="_blank" rel="external">Apache cTAKES</a> - Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text.</li></p>
<p><li><a href="http://www.clearnlp.com" target="_blank" rel="external">ClearNLP</a> - The ClearNLP project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. This project is under the Apache 2 license.</li></p>
<p><li><a href="https://github.com/IllinoisCogComp/illinois-cogcomp-nlp" target="_blank" rel="external">CogcompNLP</a> - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois’ Cognitive Computation Group, for example <code>illinois-core-utilities</code> which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, <code>illinois-edison</code> a library for feature extraction from illinois-core-utilities data structures and many other packages.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-java-general-purpose"></a></p><a name="user-content-java-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-9" class="anchor" href="#general-purpose-machine-learning-9" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-java-general-purpose"><br></a><li><a name="user-content-java-general-purpose"></a><a href="https://github.com/airbnb/aerosolve" target="_blank" rel="external">aerosolve</a> - A machine learning library by Airbnb designed from the ground up to be human friendly.</li><p></p>
<p><li><a href="https://github.com/datumbox/datumbox-framework" target="_blank" rel="external">Datumbox</a> - Machine Learning framework for rapid development of Machine Learning and Statistical applications</li></p>
<p><li><a href="http://elki.dbs.ifi.lmu.de/" target="_blank" rel="external">ELKI</a> - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.)</li></p>
<p><li><a href="https://github.com/encog/encog-java-core" target="_blank" rel="external">Encog</a> - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.</li></p>
<p><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/batch/libs/ml/index.html" target="_blank" rel="external">FlinkML in Apache Flink</a> - Distributed machine learning library in Flink</li></p>
<p><li><a href="https://github.com/h2oai/h2o-3" target="_blank" rel="external">H2O</a> - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON.</li></p>
<p><li><a href="https://github.com/numenta/htm.java" target="_blank" rel="external">htm.java</a> - General Machine Learning library using Numenta’s Cortical Learning Algorithm</li></p>
<p><li><a href="https://github.com/deeplearning4j/deeplearning4j" target="_blank" rel="external">java-deeplearning</a> - Distributed Deep Learning Platform for Java, Clojure,Scala</li></p>
<p><li><a href="https://github.com/apache/mahout" target="_blank" rel="external">Mahout</a> - Distributed machine learning</li></p>
<p><li><a href="http://meka.sourceforge.net/" target="_blank" rel="external">Meka</a> - An open source implementation of methods for multi-label classification and evaluation (extension to Weka).</li></p>
<p><li><a href="http://spark.apache.org/docs/latest/mllib-guide.html" target="_blank" rel="external">MLlib in Apache Spark</a> - Distributed machine learning library in Spark</li></p>
<p><li><a href="https://github.com/Hydrospheredata/mist" target="_blank" rel="external">Hydrosphere Mist</a> - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.</li></p>
<p><li><a href="http://neuroph.sourceforge.net/" target="_blank" rel="external">Neuroph</a> - Neuroph is lightweight Java neural network framework</li></p>
<p><li><a href="https://github.com/oryxproject/oryx" target="_blank" rel="external">ORYX</a> - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning.</li></p>
<p><li><a href="https://samoa.incubator.apache.org/" target="_blank" rel="external">Samoa</a> SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms.</li></p>
<p><li><a href="http://sourceforge.net/p/lemur/wiki/RankLib/" target="_blank" rel="external">RankLib</a> - RankLib is a library of learning to rank algorithms</li></p>
<p><li><a href="https://github.com/padreati/rapaio" target="_blank" rel="external">rapaio</a> - statistics, data mining and machine learning toolbox in Java</li></p>
<p><li><a href="http://rapid-i.com/wiki/index.php?title=Integrating_RapidMiner_into_your_application" target="_blank" rel="external">RapidMiner</a> - RapidMiner integration into Java code</li></p>
<p><li><a href="http://nlp.stanford.edu/software/classifier.shtml" target="_blank" rel="external">Stanford Classifier</a> - A classifier is a machine learning tool that will take data items and place them into one of k classes.</li></p>
<p><li><a href="https://github.com/haifengl/smile" target="_blank" rel="external">SmileMiner</a> - Statistical Machine Intelligence &amp; Learning Engine</li></p>
<p><li><a href="https://github.com/apache/incubator-systemml" target="_blank" rel="external">SystemML</a> - flexible, scalable machine learning (ML) language.</li></p>
<p><li><a href="https://github.com/WalnutiQ/WalnutiQ" target="_blank" rel="external">WalnutiQ</a> - object oriented model of the human brain</li></p>
<p><li><a href="http://www.cs.waikato.ac.nz/ml/weka/" target="_blank" rel="external">Weka</a> - Weka is a collection of machine learning algorithms for data mining tasks</li></p>
<p><li><a href="https://github.com/IllinoisCogComp/lbjava/" target="_blank" rel="external">LBJava</a> - Learning Based Java is a modeling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer’s application.</li><br></p></ul><p></p>
<h4><a id="user-content-speech-recognition-2" class="anchor" href="#speech-recognition-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Speech Recognition</h4>

<ul><br><li><a href="http://cmusphinx.sourceforge.net/" target="_blank" rel="external">CMU Sphinx</a> - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library.</li><br></ul>

<p></p><p><a name="user-content-java-data-analysis"></a></p><a name="user-content-java-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-2" class="anchor" href="#data-analysis--data-visualization-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-java-data-analysis"><br></a><li><a name="user-content-java-data-analysis"></a><a href="http://flink.apache.org/" target="_blank" rel="external">Flink</a> - Open source platform for distributed stream and batch data processing.</li><p></p>
<p><li><a href="https://github.com/apache/hadoop-mapreduce" target="_blank" rel="external">Hadoop</a> - Hadoop/HDFS</li></p>
<p><li><a href="https://github.com/apache/spark" target="_blank" rel="external">Spark</a> - Spark is a fast and general engine for large-scale data processing.</li></p>
<p><li><a href="http://storm.apache.org/" target="_blank" rel="external">Storm</a> - Storm is a distributed realtime computation system.</li></p>
<p><li><a href="https://github.com/cloudera/impala" target="_blank" rel="external">Impala</a> - Real-time Query for Hadoop</li></p>
<p><li><a href="http://jwork.org/dmelt/" target="_blank" rel="external">DataMelt</a> - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization.</li></p>
<p><li><a href="http://www.ee.ucl.ac.uk/%7Emflanaga/java/" target="_blank" rel="external">Dr. Michael Thomas Flanagan’s Java Scientific Library</a></li><br></p></ul><p></p>
<p></p><p><a name="user-content-java-deep-learning"></a></p><a name="user-content-java-deep-learning"><p></p>
<h4><a id="user-content-deep-learning" class="anchor" href="#deep-learning" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Deep Learning</h4>

<p></p></a><ul><a name="user-content-java-deep-learning"><br></a><li><a name="user-content-java-deep-learning"></a><a href="https://github.com/deeplearning4j/deeplearning4j" target="_blank" rel="external">Deeplearning4j</a> - Scalable deep learning for industry with parallel GPUs</li><br></ul><p></p>
<p></p><p><a name="user-content-javascript"></a></p><a name="user-content-javascript"><p></p>
<h2><a id="user-content-javascript" class="anchor" href="#javascript" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Javascript</h2>

<p></p></a><p><a name="user-content-javascript"></a><a name="user-content-javascript-nlp"></a></p><a name="user-content-javascript-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-5" class="anchor" href="#natural-language-processing-5" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-javascript-nlp"><br></a><li><a name="user-content-javascript-nlp"></a><a href="https://github.com/twitter/twitter-text" target="_blank" rel="external">Twitter-text</a> - A JavaScript implementation of Twitter’s text processing library</li><p></p>
<p><li><a href="https://github.com/nicktesla/nlpjs" target="_blank" rel="external">NLP.js</a> - NLP utilities in javascript and coffeescript</li></p>
<p><li><a href="https://github.com/NaturalNode/natural" target="_blank" rel="external">natural</a> - General natural language facilities for node</li></p>
<p><li><a href="https://github.com/loadfive/Knwl.js" target="_blank" rel="external">Knwl.js</a> - A Natural Language Processor in JS</li></p>
<p><li><a href="https://github.com/wooorm/retext" target="_blank" rel="external">Retext</a> - Extensible system for analyzing and manipulating natural language</li></p>
<p><li><a href="https://www.mashape.com/japerk/text-processing/support" target="_blank" rel="external">TextProcessing</a> - Sentiment analysis, stemming and lemmatization, part-of-speech tagging and chunking, phrase extraction and named entity recognition.</li></p>
<p><li><a href="https://github.com/spencermountain/nlp_compromise" target="_blank" rel="external">NLP Compromise</a> - Natural Language processing in the browser</li><br></p></ul><p></p>
<p></p><p><a name="user-content-javascript-data-analysis"></a></p><a name="user-content-javascript-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-3" class="anchor" href="#data-analysis--data-visualization-3" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-javascript-data-analysis"><br></a><li><a name="user-content-javascript-data-analysis"></a><a href="http://d3js.org/" target="_blank" rel="external">D3.js</a></li><p></p>
<p><li><a href="http://www.highcharts.com/" target="_blank" rel="external">High Charts</a></li></p>
<p><li><a href="http://nvd3.org/" target="_blank" rel="external">NVD3.js</a></li></p>
<p><li><a href="http://dc-js.github.io/dc.js/" target="_blank" rel="external">dc.js</a></li></p>
<p><li><a href="http://www.chartjs.org/" target="_blank" rel="external">chartjs</a></li></p>
<p><li><a href="http://dimplejs.org/" target="_blank" rel="external">dimple</a></li></p>
<p><li><a href="http://www.amcharts.com/" target="_blank" rel="external">amCharts</a></li></p>
<p><li><a href="https://github.com/NathanEpstein/D3xter" target="_blank" rel="external">D3xter</a> - Straight forward plotting built on D3</li></p>
<p><li><a href="https://github.com/rigtorp/statkit" target="_blank" rel="external">statkit</a> - Statistics kit for JavaScript</li></p>
<p><li><a href="https://github.com/nathanepstein/datakit" target="_blank" rel="external">datakit</a> - A lightweight framework for data analysis in JavaScript</li></p>
<p><li><a href="https://github.com/jasondavies/science.js/" target="_blank" rel="external">science.js</a> - Scientific and statistical computing in JavaScript.</li></p>
<p><li><a href="https://github.com/NathanEpstein/Z3d" target="_blank" rel="external">Z3d</a> - Easily make interactive 3d plots built on Three.js</li></p>
<p><li><a href="http://sigmajs.org/" target="_blank" rel="external">Sigma.js</a> - JavaScript library dedicated to graph drawing.</li></p>
<p><li><a href="http://c3js.org/" target="_blank" rel="external">C3.js</a>- customizable library based on D3.js for easy chart drawing.</li></p>
<p><li><a href="http://datamaps.github.io/" target="_blank" rel="external">Datamaps</a>- Customizable SVG map/geo visualizations using D3.js.</li></p>
<p><li><a href="http://www.zingchart.com/" target="_blank" rel="external">ZingChart</a>- library written on Vanilla JS for big data visualization.</li></p>
<p><li><a href="http://www.cheminfo.org/" target="_blank" rel="external">cheminfo</a> - Platform for data visualization and analysis, using the <a href="https://github.com/npellet/visualizer" target="_blank" rel="external">visualizer</a> project.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-javascript-general-purpose"></a></p><a name="user-content-javascript-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-10" class="anchor" href="#general-purpose-machine-learning-10" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-javascript-general-purpose"><br></a><li><a name="user-content-javascript-general-purpose"></a><a href="http://cs.stanford.edu/people/karpathy/convnetjs/" target="_blank" rel="external">Convnet.js</a> - ConvNetJS is a Javascript library for training Deep Learning models[DEEP LEARNING]</li><p></p>
<p><li><a href="http://harthur.github.io/clusterfck/" target="_blank" rel="external">Clusterfck</a> - Agglomerative hierarchical clustering implemented in Javascript for Node.js and the browser</li></p>
<p><li><a href="https://github.com/emilbayes/clustering.js" target="_blank" rel="external">Clustering.js</a> - Clustering algorithms implemented in Javascript for Node.js and the browser</li></p>
<p><li><a href="https://github.com/serendipious/nodejs-decision-tree-id3" target="_blank" rel="external">Decision Trees</a> - NodeJS Implementation of Decision Tree using ID3 Algorithm</li></p>
<p><li><a href="https://github.com/dn2a/dn2a-javascript" target="_blank" rel="external">DN2A</a> - Digital Neural Networks Architecture</li></p>
<p><li><a href="http://code.google.com/p/figue/" target="_blank" rel="external">figue</a> - K-means, fuzzy c-means and agglomerative clustering</li></p>
<p><li><a href="https://github.com/rlidwka/node-fann" target="_blank" rel="external">Node-fann</a> - FANN (Fast Artificial Neural Network Library) bindings for Node.js</li></p>
<p><li><a href="https://github.com/emilbayes/kMeans.js" target="_blank" rel="external">Kmeans.js</a> - Simple Javascript implementation of the k-means algorithm, for node.js and the browser</li></p>
<p><li><a href="https://github.com/primaryobjects/lda" target="_blank" rel="external">LDA.js</a> - LDA topic modeling for node.js</li></p>
<p><li><a href="https://github.com/yandongliu/learningjs" target="_blank" rel="external">Learning.js</a> - Javascript implementation of logistic regression/c4.5 decision tree</li></p>
<p><li><a href="http://joonku.com/project/machine_learning" target="_blank" rel="external">Machine Learning</a> - Machine learning library for Node.js</li></p>
<p><li><a href="https://github.com/ClimbsRocks/machineJS" target="_blank" rel="external">machineJS</a> - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file!</li></p>
<p><li><a href="https://github.com/mil-tokyo" target="_blank" rel="external">mil-tokyo</a> - List of several machine learning libraries</li></p>
<p><li><a href="https://github.com/nicolaspanel/node-svm" target="_blank" rel="external">Node-SVM</a> - Support Vector Machine for nodejs</li></p>
<p><li><a href="https://github.com/harthur/brain" target="_blank" rel="external">Brain</a> - Neural networks in JavaScript <strong>[Deprecated]</strong></li></p>
<p><li><a href="https://github.com/omphalos/bayesian-bandit.js" target="_blank" rel="external">Bayesian-Bandit</a> - Bayesian bandit implementation for Node and the browser.</li></p>
<p><li><a href="https://github.com/cazala/synaptic" target="_blank" rel="external">Synaptic</a> - Architecture-free neural network library for node.js and the browser</li></p>
<p><li><a href="https://github.com/NathanEpstein/kNear" target="_blank" rel="external">kNear</a> - JavaScript implementation of the k nearest neighbors algorithm for supervised learning</li></p>
<p><li><a href="https://github.com/totemstech/neuraln" target="_blank" rel="external">NeuralN</a> - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training.</li></p>
<p><li><a href="https://github.com/itamarwe/kalman" target="_blank" rel="external">kalman</a> - Kalman filter for Javascript.</li></p>
<p><li><a href="https://github.com/dambalah/shaman" target="_blank" rel="external">shaman</a> - node.js library with support for both simple and multiple linear regression.</li></p>
<p><li><a href="https://github.com/mljs/ml" target="_blank" rel="external">ml.js</a> - Machine learning and numerical analysis tools for Node.js and the Browser!</li></p>
<p><li><a href="https://github.com/NathanEpstein/Pavlov.js" target="_blank" rel="external">Pavlov.js</a> - Reinforcement learning using Markov Decision Processes</li></p>
<p><li><a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">MXNet</a> - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-javascript-misc"></a></p><a name="user-content-javascript-misc"><p></p>
<h4><a id="user-content-misc" class="anchor" href="#misc" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Misc</h4>

<p></p></a><ul><a name="user-content-javascript-misc"><br></a><li><a name="user-content-javascript-misc"></a><a href="https://github.com/jcoglan/sylvester" target="_blank" rel="external">sylvester</a> - Vector and Matrix math for JavaScript.</li><p></p>
<p><li><a href="https://github.com/simple-statistics/simple-statistics" target="_blank" rel="external">simple-statistics</a> - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in node.js.</li></p>
<p><li><a href="https://github.com/Tom-Alexander/regression-js" target="_blank" rel="external">regression-js</a> - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data.</li></p>
<p><li><a href="https://github.com/flurry/Lyric" target="_blank" rel="external">Lyric</a> - Linear Regression library.</li></p>
<p><li><a href="https://github.com/mwgg/GreatCircle" target="_blank" rel="external">GreatCircle</a> - Library for calculating great circle distance.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-julia"></a></p><a name="user-content-julia"><p></p>
<h2><a id="user-content-julia" class="anchor" href="#julia" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Julia</h2>

<p></p></a><p><a name="user-content-julia"></a><a name="user-content-julia-general-purpose"></a></p><a name="user-content-julia-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-11" class="anchor" href="#general-purpose-machine-learning-11" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-julia-general-purpose"><br></a><li><a name="user-content-julia-general-purpose"></a><a href="https://github.com/benhamner/MachineLearning.jl" target="_blank" rel="external">MachineLearning</a> - Julia Machine Learning library</li><p></p>
<p><li><a href="https://github.com/JuliaStats/MLBase.jl" target="_blank" rel="external">MLBase</a> - A set of functions to support the development of machine learning algorithms</li></p>
<p><li><a href="https://github.com/JuliaStats/PGM.jl" target="_blank" rel="external">PGM</a> - A Julia framework for probabilistic graphical models.</li></p>
<p><li><a href="https://github.com/trthatcher/DiscriminantAnalysis.jl" target="_blank" rel="external">DA</a> - Julia package for Regularized Discriminant Analysis</li></p>
<p><li><a href="https://github.com/lindahua/Regression.jl" target="_blank" rel="external">Regression</a> - Algorithms for regression analysis (e.g. linear regression and logistic regression)</li></p>
<p><li><a href="https://github.com/dcjones/Loess.jl" target="_blank" rel="external">Local Regression</a> - Local regression, so smooooth!</li></p>
<p><li><a href="https://github.com/nutsiepully/NaiveBayes.jl" target="_blank" rel="external">Naive Bayes</a> - Simple Naive Bayes implementation in Julia</li></p>
<p><li><a href="https://github.com/dmbates/MixedModels.jl" target="_blank" rel="external">Mixed Models</a> - A Julia package for fitting (statistical) mixed-effects models</li></p>
<p><li><a href="https://github.com/fredo-dedup/SimpleMCMC.jl" target="_blank" rel="external">Simple MCMC</a> - basic mcmc sampler implemented in Julia</li></p>
<p><li><a href="https://github.com/JuliaStats/Distance.jl" target="_blank" rel="external">Distance</a> - Julia module for Distance evaluation</li></p>
<p><li><a href="https://github.com/bensadeghi/DecisionTree.jl" target="_blank" rel="external">Decision Tree</a> - Decision Tree Classifier and Regressor</li></p>
<p><li><a href="https://github.com/compressed/BackpropNeuralNet.jl" target="_blank" rel="external">Neural</a> - A neural network in Julia</li></p>
<p><li><a href="https://github.com/doobwa/MCMC.jl" target="_blank" rel="external">MCMC</a> - MCMC tools for Julia</li></p>
<p><li><a href="https://github.com/brian-j-smith/Mamba.jl" target="_blank" rel="external">Mamba</a> - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia</li></p>
<p><li><a href="https://github.com/JuliaStats/GLM.jl" target="_blank" rel="external">GLM</a> - Generalized linear models in Julia</li></p>
<p><li><a href="https://github.com/lendle/OnlineLearning.jl" target="_blank" rel="external">Online Learning</a></li></p>
<p><li><a href="https://github.com/simonster/GLMNet.jl" target="_blank" rel="external">GLMNet</a> - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet</li></p>
<p><li><a href="https://github.com/JuliaStats/Clustering.jl" target="_blank" rel="external">Clustering</a> - Basic functions for clustering data: k-means, dp-means, etc.</li></p>
<p><li><a href="https://github.com/JuliaStats/SVM.jl" target="_blank" rel="external">SVM</a> - SVM’s for Julia</li></p>
<p><li><a href="https://github.com/JuliaStats/KernelDensity.jl" target="_blank" rel="external">Kernal Density</a> - Kernel density estimators for julia</li></p>
<p><li><a href="https://github.com/JuliaStats/DimensionalityReduction.jl" target="_blank" rel="external">Dimensionality Reduction</a> - Methods for dimensionality reduction</li></p>
<p><li><a href="https://github.com/JuliaStats/NMF.jl" target="_blank" rel="external">NMF</a> - A Julia package for non-negative matrix factorization</li></p>
<p><li><a href="https://github.com/EricChiang/ANN.jl" target="_blank" rel="external">ANN</a> - Julia artificial neural networks</li></p>
<p><li><a href="https://github.com/pluskid/Mocha.jl" target="_blank" rel="external">Mocha</a> - Deep Learning framework for Julia inspired by Caffe</li></p>
<p><li><a href="https://github.com/dmlc/XGBoost.jl" target="_blank" rel="external">XGBoost</a> - eXtreme Gradient Boosting Package in Julia</li></p>
<p><li><a href="https://github.com/wildart/ManifoldLearning.jl" target="_blank" rel="external">ManifoldLearning</a> - A Julia package for manifold learning and nonlinear dimensionality reduction</li></p>
<p><li><a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">MXNet</a> - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.</li></p>
<p><li><a href="https://github.com/hshindo/Merlin.jl" target="_blank" rel="external">Merlin</a> - Flexible Deep Learning Framework in Julia</li></p>
<p><li><a href="https://github.com/davidavdav/ROCAnalysis.jl" target="_blank" rel="external">ROCAnalysis</a> - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers</li></p>
<p><li><a href="https://github.com/davidavdav/GaussianMixtures.jl" target="_blank" rel="external">GaussianMixtures</a> - Large scale Gaussian Mixture Models</li></p>
<p><li><a href="https://github.com/cstjean/ScikitLearn.jl" target="_blank" rel="external">ScikitLearn</a> - Julia implementation of the scikit-learn API</li></p>
<p><li><a href="https://github.com/denizyuret/Knet.jl" target="_blank" rel="external">Knet</a> - Koç University Deep Learning Framework</li><br></p></ul><p></p>
<p></p><p><a name="user-content-julia-nlp"></a></p><a name="user-content-julia-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-6" class="anchor" href="#natural-language-processing-6" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-julia-nlp"><br></a><li><a name="user-content-julia-nlp"></a><a href="https://github.com/slycoder/TopicModels.jl" target="_blank" rel="external">Topic Models</a> - TopicModels for Julia</li><p></p>
<p><li><a href="https://github.com/johnmyleswhite/TextAnalysis.jl" target="_blank" rel="external">Text Analysis</a> - Julia package for text analysis</li><br></p></ul><p></p>
<p></p><p><a name="user-content-julia-data-analysis"></a></p><a name="user-content-julia-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-4" class="anchor" href="#data-analysis--data-visualization-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-julia-data-analysis"><br></a><li><a name="user-content-julia-data-analysis"></a><a href="https://github.com/IainNZ/GraphLayout.jl" target="_blank" rel="external">Graph Layout</a> - Graph layout algorithms in pure Julia</li><p></p>
<p><li><a href="https://github.com/JuliaStats/DataFramesMeta.jl" target="_blank" rel="external">Data Frames Meta</a> - Metaprogramming tools for DataFrames</li></p>
<p><li><a href="https://github.com/nfoti/JuliaData" target="_blank" rel="external">Julia Data</a> - library for working with tabular data in Julia</li></p>
<p><li><a href="https://github.com/WizardMac/DataRead.jl" target="_blank" rel="external">Data Read</a> - Read files from Stata, SAS, and SPSS</li></p>
<p><li><a href="https://github.com/JuliaStats/HypothesisTests.jl" target="_blank" rel="external">Hypothesis Tests</a> - Hypothesis tests for Julia</li></p>
<p><li><a href="https://github.com/dcjones/Gadfly.jl" target="_blank" rel="external">Gadfly</a> - Crafty statistical graphics for Julia.</li></p>
<p><li><p><a href="https://github.com/JuliaStats/Stats.jl" target="_blank" rel="external">Stats</a> - Statistical tests for Julia</p></li></p>
<p><li><p><a href="https://github.com/johnmyleswhite/RDatasets.jl" target="_blank" rel="external">RDataSets</a> - Julia package for loading many of the data sets available in R</p></li></p>
<p><li><a href="https://github.com/JuliaStats/DataFrames.jl" target="_blank" rel="external">DataFrames</a> - library for working with tabular data in Julia</li></p>
<p><li><a href="https://github.com/JuliaStats/Distributions.jl" target="_blank" rel="external">Distributions</a> - A Julia package for probability distributions and associated functions.</li></p>
<p><li><a href="https://github.com/JuliaStats/DataArrays.jl" target="_blank" rel="external">Data Arrays</a> - Data structures that allow missing values</li></p>
<p><li><a href="https://github.com/JuliaStats/TimeSeries.jl" target="_blank" rel="external">Time Series</a> - Time series toolkit for Julia</li></p>
<p><li><a href="https://github.com/lindahua/Sampling.jl" target="_blank" rel="external">Sampling</a> - Basic sampling algorithms for Julia</li><br></p></ul><p></p>
<p></p><p><a name="user-content-julia-misc"></a></p><a name="user-content-julia-misc"><p></p>
<h4><a id="user-content-misc-stuff--presentations" class="anchor" href="#misc-stuff--presentations" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Misc Stuff / Presentations</h4>

<p></p></a><ul><a name="user-content-julia-misc"><br></a><li><a name="user-content-julia-misc"></a><a href="https://github.com/JuliaDSP/DSP.jl" target="_blank" rel="external">DSP</a> - Digital Signal Processing (filtering, periodograms, spectrograms, window functions).</li><p></p>
<p><li><a href="https://github.com/JuliaCon/presentations" target="_blank" rel="external">JuliaCon Presentations</a> - Presentations for JuliaCon</li></p>
<p><li><a href="https://github.com/davidavdav/SignalProcessing.jl" target="_blank" rel="external">SignalProcessing</a> - Signal Processing tools for Julia</li></p>
<p><li><a href="https://github.com/timholy/Images.jl" target="_blank" rel="external">Images</a> - An image library for Julia</li><br></p></ul><p></p>
<p></p><p><a name="user-content-lua"></a></p><a name="user-content-lua"><p></p>
<h2><a id="user-content-lua" class="anchor" href="#lua" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Lua</h2>

<p></p></a><p><a name="user-content-lua"></a><a name="user-content-lua-general-purpose"></a></p><a name="user-content-lua-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-12" class="anchor" href="#general-purpose-machine-learning-12" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-lua-general-purpose"><br></a><li><a name="user-content-lua-general-purpose"></a><a href="http://torch.ch/" target="_blank" rel="external">Torch7</a><p></p>
<ul><br><li><a href="http://jucor.github.io/torch-cephes" target="_blank" rel="external">cephes</a> - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy.</li><br><li><a href="https://github.com/twitter/torch-autograd" target="_blank" rel="external">autograd</a> - Autograd automatically differentiates native Torch code. Inspired by the original Python version.</li><br><li><a href="https://github.com/torch/graph" target="_blank" rel="external">graph</a> - Graph package for Torch</li><br><li><a href="http://jucor.github.io/torch-randomkit/" target="_blank" rel="external">randomkit</a> - Numpy’s randomkit, wrapped for Torch</li><br><li><a href="http://soumith.ch/torch-signal/signal/" target="_blank" rel="external">signal</a> - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stft</li><br><li><a href="https://github.com/torch/nn" target="_blank" rel="external">nn</a> - Neural Network package for Torch</li><br><li><a href="https://github.com/torchnet/torchnet" target="_blank" rel="external">torchnet</a> - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programming</li><br><li><a href="https://github.com/torch/nngraph" target="_blank" rel="external">nngraph</a> - This package provides graphical computation for nn library in Torch7.</li><br><li><a href="https://github.com/clementfarabet/lua---nnx" target="_blank" rel="external">nnx</a> - A completely unstable and experimental package that extends Torch’s builtin nn library</li><br><li><a href="https://github.com/Element-Research/rnn" target="_blank" rel="external">rnn</a> - A Recurrent Neural Network library that extends Torch’s nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.</li><br><li><a href="https://github.com/Element-Research/dpnn" target="_blank" rel="external">dpnn</a> - Many useful features that aren’t part of the main nn package.</li><br><li><a href="https://github.com/nicholas-leonard/dp" target="_blank" rel="external">dp</a> - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns.</li><br><li><a href="https://github.com/torch/optim" target="_blank" rel="external">optim</a> - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.</li><br><li><a href="https://github.com/koraykv/unsup" target="_blank" rel="external">unsup</a> - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, …), and self-contained algorithms (k-means, PCA).</li><br><li><a href="https://github.com/clementfarabet/manifold" target="_blank" rel="external">manifold</a> - A package to manipulate manifolds</li><br><li><a href="https://github.com/koraykv/torch-svm" target="_blank" rel="external">svm</a> - Torch-SVM library</li><br><li><a href="https://github.com/clementfarabet/lbfgs" target="_blank" rel="external">lbfgs</a> - FFI Wrapper for liblbfgs</li><br><li><a href="https://github.com/clementfarabet/vowpal_wabbit" target="_blank" rel="external">vowpalwabbit</a> - An old vowpalwabbit interface to torch.</li><br><li><a href="https://github.com/clementfarabet/lua---opengm" target="_blank" rel="external">OpenGM</a> - OpenGM is a C++ library for graphical modeling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM.</li><br><li><a href="https://github.com/MichaelMathieu/lua---spaghetti" target="_blank" rel="external">sphagetti</a> - Spaghetti (sparse linear) module for torch7 by @MichaelMathieu</li><br><li><a href="https://github.com/ocallaco/LuaSHkit" target="_blank" rel="external">LuaSHKit</a> - A lua wrapper around the Locality sensitive hashing library SHKit</li><br><li><a href="https://github.com/rlowrance/kernel-smoothers" target="_blank" rel="external">kernel smoothing</a> - KNN, kernel-weighted average, local linear regression smoothers</li><br><li><a href="https://github.com/torch/cutorch" target="_blank" rel="external">cutorch</a> - Torch CUDA Implementation</li><br><li><a href="https://github.com/torch/cunn" target="_blank" rel="external">cunn</a> - Torch CUDA Neural Network Implementation</li><br><li><a href="https://github.com/clementfarabet/lua---imgraph" target="_blank" rel="external">imgraph</a> - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images.</li><br><li><a href="https://github.com/clementfarabet/videograph" target="_blank" rel="external">videograph</a> - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos.</li><br><li><a href="https://github.com/marcoscoffier/torch-saliency" target="_blank" rel="external">saliency</a> - code and tools around integral images. A library for finding interest points based on fast integral histograms.</li><br><li><a href="https://github.com/marcoscoffier/lua---stitch" target="_blank" rel="external">stitch</a> - allows us to use hugin to stitch images and apply same stitching to a video sequence</li><br><li><a href="https://github.com/marcoscoffier/lua---sfm" target="_blank" rel="external">sfm</a> - A bundle adjustment/structure from motion package</li><br><li><a href="https://github.com/koraykv/fex" target="_blank" rel="external">fex</a> - A package for feature extraction in Torch. Provides SIFT and dSIFT modules.</li><br><li><a href="https://github.com/sermanet/OverFeat" target="_blank" rel="external">OverFeat</a> - A state-of-the-art generic dense feature extractor</li><br></ul></li><br><li><a href="http://numlua.luaforge.net/" target="_blank" rel="external">Numeric Lua</a></li><br><li><a href="http://labix.org/lunatic-python" target="_blank" rel="external">Lunatic Python</a></li><br><li><a href="http://www.scilua.org/" target="_blank" rel="external">SciLua</a></li><br><li><a href="https://bitbucket.org/lucashnegri/lna" target="_blank" rel="external">Lua - Numerical Algorithms</a></li><br><li><a href="http://zrake.webfactional.com/projects/lunum" target="_blank" rel="external">Lunum</a></li><br></ul>

<p></p><p><a name="user-content-lua-demos"></a></p><a name="user-content-lua-demos"><p></p>
<h4><a id="user-content-demos-and-scripts" class="anchor" href="#demos-and-scripts" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Demos and Scripts</h4>

<p></p></a><ul><a name="user-content-lua-demos"><br></a><li><a name="user-content-lua-demos"></a><a href="https://github.com/e-lab/torch7-demos" target="_blank" rel="external">Core torch7 demos repository</a>.<p></p>
<ul><br><li>linear-regression, logistic-regression</li><br><li>face detector (training and detection as separate demos)</li><br><li>mst-based-segmenter</li><br><li>train-a-digit-classifier</li><br><li>train-autoencoder</li><br><li>optical flow demo</li><br><li>train-on-housenumbers</li><br><li>train-on-cifar</li><br><li>tracking with deep nets</li><br><li>kinect demo</li><br><li>filter-bank visualization</li><br><li>saliency-networks</li><br></ul></li><br><li><a href="https://github.com/soumith/galaxyzoo" target="_blank" rel="external">Training a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)</a></li><br><li><a href="https://github.com/mbhenaff/MusicTagging" target="_blank" rel="external">Music Tagging</a> - Music Tagging scripts for torch7</li><br><li><a href="https://github.com/rosejn/torch-datasets" target="_blank" rel="external">torch-datasets</a> - Scripts to load several popular datasets including:<br><br><ul><br><li>BSR 500</li><br><li>CIFAR-10</li><br><li>COIL</li><br><li>Street View House Numbers</li><br><li>MNIST</li><br><li>NORB</li><br></ul></li><br><li><a href="https://github.com/fidlej/aledataset" target="_blank" rel="external">Atari2600</a> - Scripts to generate a dataset with static frames from the Arcade Learning Environment</li><br></ul>

<p></p><p><a name="user-content-matlab"></a></p><a name="user-content-matlab"><p></p>
<h2><a id="user-content-matlab" class="anchor" href="#matlab" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Matlab</h2>

<p></p></a><p><a name="user-content-matlab"></a><a name="user-content-matlab-cv"></a></p><a name="user-content-matlab-cv"><p></p>
<h4><a id="user-content-computer-vision-2" class="anchor" href="#computer-vision-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Computer Vision</h4>

<p></p></a><ul><a name="user-content-matlab-cv"><br></a><li><a name="user-content-matlab-cv"></a><a href="http://www.ifp.illinois.edu/%7Eminhdo/software/contourlet_toolbox.tar" target="_blank" rel="external">Contourlets</a> - MATLAB source code that implements the contourlet transform and its utility functions.</li><p></p>
<p><li><a href="http://www.shearlab.org/index_software.html" target="_blank" rel="external">Shearlets</a> - MATLAB code for shearlet transform</li></p>
<p><li><a href="http://www.curvelet.org/software.html" target="_blank" rel="external">Curvelets</a> - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles.</li></p>
<p><li><a href="http://www.cmap.polytechnique.fr/%7Epeyre/download/" target="_blank" rel="external">Bandlets</a> - MATLAB code for bandlet transform</li></p>
<p><li><a href="http://kyamagu.github.io/mexopencv/" target="_blank" rel="external">mexopencv</a> - Collection and a development kit of MATLAB mex functions for OpenCV library</li><br></p></ul><p></p>
<p></p><p><a name="user-content-matlab-nlp"></a></p><a name="user-content-matlab-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-7" class="anchor" href="#natural-language-processing-7" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-matlab-nlp"><br></a><li><a name="user-content-matlab-nlp"></a><a href="https://amplab.cs.berkeley.edu/2012/05/05/an-nlp-library-for-matlab/" target="_blank" rel="external">NLP</a> - An NLP library for Matlab</li><br></ul><p></p>
<p></p><p><a name="user-content-matlab-general-purpose"></a></p><a name="user-content-matlab-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-13" class="anchor" href="#general-purpose-machine-learning-13" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-matlab-general-purpose"><br></a><li><a name="user-content-matlab-general-purpose"></a><a href="http://www.cs.toronto.edu/%7Ehinton/MatlabForSciencePaper.html" target="_blank" rel="external">Training a deep autoencoder or a classifier<br>on MNIST digits</a> - Training a deep autoencoder or a classifier<br>on MNIST digits[DEEP LEARNING]</li><p></p>
<p><li><a href="http://www.socher.org/index.php/Main/Convolutional-RecursiveDeepLearningFor3DObjectClassification" target="_blank" rel="external">Convolutional-Recursive Deep Learning for 3D Object Classification</a> - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING]</li></p>
<p><li><a href="http://homepage.tudelft.nl/19j49/t-SNE.html" target="_blank" rel="external">t-Distributed Stochastic Neighbor Embedding</a> - t-Distributed Stochastic Neighbor Embedding (t-SNE) is a (prize-winning) technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets.</li></p>
<p><li><a href="http://people.kyb.tuebingen.mpg.de/spider/" target="_blank" rel="external">Spider</a> - The spider is intended to be a complete object orientated environment for machine learning in Matlab.</li></p>
<p><li><a href="http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/#matlab" target="_blank" rel="external">LibSVM</a> - A Library for Support Vector Machines</li></p>
<p><li><a href="http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear/#download" target="_blank" rel="external">LibLinear</a> - A Library for Large Linear Classification</li></p>
<p><li><a href="https://github.com/josephmisiti/machine-learning-module" target="_blank" rel="external">Machine Learning Module</a> - Class on machine w/ PDF,lectures,code</li></p>
<p><li><a href="http://caffe.berkeleyvision.org" target="_blank" rel="external">Caffe</a>  - A deep learning framework developed with cleanliness, readability, and speed in mind.</li></p>
<p><li><a href="https://github.com/newfolder/PRT" target="_blank" rel="external">Pattern Recognition Toolbox</a>  - A complete object-oriented environment for machine learning in Matlab.</li></p>
<p><li><a href="https://github.com/PRML/PRMLT" target="_blank" rel="external">Pattern Recognition and Machine Learning</a> - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop.</li></p>
<p><li><a href="http://docs.optunity.net" target="_blank" rel="external">Optunity</a> - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-matlab-data-analysis"></a></p><a name="user-content-matlab-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-5" class="anchor" href="#data-analysis--data-visualization-5" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-matlab-data-analysis"><br></a><li><a name="user-content-matlab-data-analysis"></a><a href="https://www.cs.purdue.edu/homes/dgleich/packages/matlab_bgl/" target="_blank" rel="external">matlab_gbl</a> - MatlabBGL is a Matlab package for working with graphs.</li><p></p>
<p><li><a href="http://www.mathworks.com/matlabcentral/fileexchange/24134-gaimc---graph-algorithms-in-matlab-code" target="_blank" rel="external">gamic</a> - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL’s mex functions.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-net"></a></p><a name="user-content-net"><p></p>
<h2><a id="user-content-net" class="anchor" href="#net" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>.NET</h2>

<p></p></a><p><a name="user-content-net"></a><a name="user-content-net-cv"></a></p><a name="user-content-net-cv"><p></p>
<h4><a id="user-content-computer-vision-3" class="anchor" href="#computer-vision-3" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Computer Vision</h4>

<p></p></a><ul><a name="user-content-net-cv"><br></a><li><a name="user-content-net-cv"></a><a href="https://code.google.com/p/opencvdotnet/" target="_blank" rel="external">OpenCVDotNet</a> - A wrapper for the OpenCV project to be used with .NET applications.</li><p></p>
<p><li><a href="http://www.emgu.com/wiki/index.php/Main_Page" target="_blank" rel="external">Emgu CV</a> - Cross platform wrapper of OpenCV which can be compiled in Mono to e run on Windows, Linus, Mac OS X, iOS, and Android.</li></p>
<p><li><a href="http://www.aforgenet.com/framework/" target="_blank" rel="external">AForge.NET</a> - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub.</li></p>
<p><li><a href="http://accord-framework.net" target="_blank" rel="external">Accord.NET</a> - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-net-nlp"></a></p><a name="user-content-net-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-8" class="anchor" href="#natural-language-processing-8" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-net-nlp"><br></a><li><a name="user-content-net-nlp"></a><a href="https://github.com/sergey-tihon/Stanford.NLP.NET/" target="_blank" rel="external">Stanford.NLP for .NET</a> - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package.</li><br></ul><p></p>
<p></p><p><a name="user-content-net-general-purpose"></a></p><a name="user-content-net-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-14" class="anchor" href="#general-purpose-machine-learning-14" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-net-general-purpose"><br></a><li><a name="user-content-net-general-purpose"></a><a href="http://accord-framework.net/" target="_blank" rel="external">Accord-Framework</a> -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications.</li><p></p>
<p><li><a href="http://www.nuget.org/packages/Accord.MachineLearning/" target="_blank" rel="external">Accord.MachineLearning</a> - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework.</li></p>
<p><li><a href="http://diffsharp.github.io/DiffSharp/" target="_blank" rel="external">DiffSharp</a> - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization.</li></p>
<p><li><a href="https://github.com/fsprojects/Vulpes" target="_blank" rel="external">Vulpes</a> - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase.</li></p>
<p><li><a href="http://www.nuget.org/packages/encog-dotnet-core/" target="_blank" rel="external">Encog</a> -  An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.</li></p>
<p><li><a href="http://bragisoft.com/" target="_blank" rel="external">Neural Network Designer</a> - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feed back.  The chat bots can even scrape the internet for information to return in their output as well as to use for learning.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-net-data-analysis"></a></p><a name="user-content-net-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-6" class="anchor" href="#data-analysis--data-visualization-6" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-net-data-analysis"><br></a><li><a name="user-content-net-data-analysis"></a><a href="http://www.nuget.org/packages/numl/" target="_blank" rel="external">numl</a> - numl is a machine learning library intended to ease the use of using standard modeling techniques for both prediction and clustering.</li><p></p>
<p><li><a href="http://www.nuget.org/packages/MathNet.Numerics/" target="_blank" rel="external">Math.NET Numerics</a> - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and every day use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin.</li></p>
<p><li><a href="http://research.microsoft.com/en-us/projects/sho/" target="_blank" rel="external">Sho</a> - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-objectivec"></a></p><a name="user-content-objectivec"><p></p>
<h2><a id="user-content-objective-c" class="anchor" href="#objective-c" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Objective C</h2>

<p></p></a><p><a name="user-content-objectivec"></a><a name="user-content-objectivec-general-purpose"></a></p><a name="user-content-objectivec-general-purpose"><p></p>
<h3><a id="user-content-general-purpose-machine-learning-15" class="anchor" href="#general-purpose-machine-learning-15" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h3>

<p></p></a><ul><a name="user-content-objectivec-general-purpose"><br></a><li><a name="user-content-objectivec-general-purpose"></a><a href="https://github.com/yconst/YCML" target="_blank" rel="external">YCML</a> - A Machine Learning framework for Objective-C and Swift (OS X / iOS).</li><p></p>
<p><li><a href="https://github.com/nikolaypavlov/MLPNeuralNet" target="_blank" rel="external">MLPNeuralNet</a> - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural network. It is built on top of the Apple’s Accelerate Framework, using vectorized operations and hardware acceleration if available.</li></p>
<p><li><a href="https://github.com/gianlucabertani/MAChineLearning" target="_blank" rel="external">MAChineLearning</a> - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it’s 20 times faster than its Java equivalent. Includes sample code for use from Swift.</li></p>
<p><li><a href="https://github.com/Kalvar/ios-BPN-NeuralNetwork" target="_blank" rel="external">BPN-NeuralNetwork</a> - It implemented 3 layers neural network ( Input Layer, Hidden Layer and Output Layer ) and it named Back Propagation Neural Network (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis.</li></p>
<p><li><a href="https://github.com/Kalvar/ios-Multi-Perceptron-NeuralNetwork" target="_blank" rel="external">Multi-Perceptron-NeuralNetwork</a> - it implemented multi-perceptrons neural network (ニューラルネットワーク) based on Back Propagation Neural Network (BPN) and designed unlimited-hidden-layers.</li></p>
<p><li><a href="https://github.com/Kalvar/ios-KRHebbian-Algorithm" target="_blank" rel="external">KRHebbian-Algorithm</a> - It is a non-supervisor and self-learning algorithm (adjust the weights) in neural network of Machine Learning.</li></p>
<p><li><a href="https://github.com/Kalvar/ios-KRKmeans-Algorithm" target="_blank" rel="external">KRKmeans-Algorithm</a> - It implemented K-Means the clustering and classification algorithm. It could be used in data mining and image compression.</li></p>
<p><li><a href="https://github.com/Kalvar/ios-KRFuzzyCMeans-Algorithm" target="_blank" rel="external">KRFuzzyCMeans-Algorithm</a> - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-ocaml"></a></p><a name="user-content-ocaml"><p></p>
<h2><a id="user-content-ocaml" class="anchor" href="#ocaml" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>OCaml</h2>

<p></p></a><p><a name="user-content-ocaml"></a><a name="user-content-ocaml-general-purpose"></a></p><a name="user-content-ocaml-general-purpose"><p></p>
<h3><a id="user-content-general-purpose-machine-learning-16" class="anchor" href="#general-purpose-machine-learning-16" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h3>

<p></p></a><ul><a name="user-content-ocaml-general-purpose"><br></a><li><a name="user-content-ocaml-general-purpose"></a><a href="https://github.com/hammerlab/oml/" target="_blank" rel="external">Oml</a> - A general statistics and machine learning library.</li><p></p>
<p><li><a href="http://mmottl.github.io/gpr" target="_blank" rel="external">GPR</a> - Efficient Gaussian Process Regression in OCaml.</li></p>
<p><li><a href="http://libra.cs.uoregon.edu" target="_blank" rel="external">Libra-Tk</a> - Algorithms for learning and inference with discrete probabilistic models.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-php"></a></p><a name="user-content-php"><p></p>
<h2><a id="user-content-php" class="anchor" href="#php" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>PHP</h2>

<p></p></a><p><a name="user-content-php"></a><a name="user-content-php-nlp"></a></p><a name="user-content-php-nlp"><p></p>
<h3><a id="user-content-natural-language-processing-9" class="anchor" href="#natural-language-processing-9" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h3>

<p></p></a><ul><a name="user-content-php-nlp"><br></a><li><a name="user-content-php-nlp"></a><a href="https://github.com/fukuball/jieba-php" target="_blank" rel="external">jieba-php</a> - Chinese Words Segmentation Utilities.</li><br></ul><p></p>
<p></p><p><a name="user-content-php-general-purpose"></a></p><a name="user-content-php-general-purpose"><p></p>
<h3><a id="user-content-general-purpose-machine-learning-17" class="anchor" href="#general-purpose-machine-learning-17" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h3>

<p></p></a><ul><a name="user-content-php-general-purpose"><br></a><li><a name="user-content-php-general-purpose"></a><a href="https://github.com/php-ai/php-ml" target="_blank" rel="external">PHP-ML</a> - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library.</li><p></p>
<p><li><a href="https://github.com/denissimon/prediction-builder" target="_blank" rel="external">PredictionBuilder</a> - A library for machine learning that builds predictions using a linear regression.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-python"></a></p><a name="user-content-python"><p></p>
<h2><a id="user-content-python" class="anchor" href="#python" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Python</h2>

<p></p></a><p><a name="user-content-python"></a><a name="user-content-python-cv"></a></p><a name="user-content-python-cv"><p></p>
<h4><a id="user-content-computer-vision-4" class="anchor" href="#computer-vision-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Computer Vision</h4>

<p></p></a><ul><a name="user-content-python-cv"><br></a><li><a name="user-content-python-cv"></a><a href="https://github.com/scikit-image/scikit-image" target="_blank" rel="external">Scikit-Image</a> - A collection of algorithms for image processing in Python.</li><p></p>
<p><li><a href="http://simplecv.org/" target="_blank" rel="external">SimpleCV</a> - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux.</li></p>
<p><li><a href="https://github.com/ukoethe/vigra" target="_blank" rel="external">Vigranumpy</a> - Python bindings for the VIGRA C++ computer vision library.</li></p>
<p><li><a href="https://cmusatyalab.github.io/openface/" target="_blank" rel="external">OpenFace</a> - Free and open source face recognition with deep neural networks.</li></p>
<p><li><a href="https://github.com/jesolem/PCV" target="_blank" rel="external">PCV</a> - Open source Python module for computer vision</li><br></p></ul><p></p>
<p></p><p><a name="user-content-python-nlp"></a></p><a name="user-content-python-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-10" class="anchor" href="#natural-language-processing-10" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-python-nlp"><br></a><li><a name="user-content-python-nlp"></a><a href="http://www.nltk.org/" target="_blank" rel="external">NLTK</a> - A leading platform for building Python programs to work with human language data.</li><p></p>
<p><li><a href="http://www.clips.ua.ac.be/pattern" target="_blank" rel="external">Pattern</a> - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others.</li></p>
<p><li><a href="https://github.com/machinalis/quepy" target="_blank" rel="external">Quepy</a> - A python framework to transform natural language questions to queries in a database query language</li></p>
<p><li><a href="http://textblob.readthedocs.org/" target="_blank" rel="external">TextBlob</a> - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both.</li></p>
<p><li><a href="https://github.com/machinalis/yalign" target="_blank" rel="external">YAlign</a> - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora.</li></p>
<p><li><a href="https://github.com/fxsjy/jieba#jieba-1" target="_blank" rel="external">jieba</a> - Chinese Words Segmentation Utilities.</li></p>
<p><li><a href="https://github.com/isnowfy/snownlp" target="_blank" rel="external">SnowNLP</a> - A library for processing Chinese text.</li></p>
<p><li><a href="https://github.com/prodicus/spammy" target="_blank" rel="external">spammy</a> - A library for email Spam filtering built on top of nltk</li></p>
<p><li><a href="https://github.com/victorlin/loso" target="_blank" rel="external">loso</a> - Another Chinese segmentation library.</li></p>
<p><li><a href="https://github.com/duanhongyi/genius" target="_blank" rel="external">genius</a> - A Chinese segment base on Conditional Random Field.</li></p>
<p><li><a href="http://konlpy.org" target="_blank" rel="external">KoNLPy</a> - A Python package for Korean natural language processing.</li></p>
<p><li><a href="https://github.com/pprett/nut" target="_blank" rel="external">nut</a> - Natural language Understanding Toolkit</li></p>
<p><li><a href="https://github.com/columbia-applied-data-science/rosetta" target="_blank" rel="external">Rosetta</a> - Text processing tools and wrappers (e.g. Vowpal Wabbit)</li></p>
<p><li><a href="https://pypi.python.org/pypi/bllipparser/" target="_blank" rel="external">BLLIP Parser</a> - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser)</li></p>
<p><li><a href="https://github.com/proycon/pynlpl" target="_blank" rel="external">PyNLPl</a> - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for <a href="http://proycon.github.io/folia/" target="_blank" rel="external">FoLiA</a>, but also ARPA language models, Moses phrasetables, GIZA++ alignments.</li></p>
<p><li><a href="https://github.com/proycon/python-ucto" target="_blank" rel="external">python-ucto</a> - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages)</li></p>
<p><li><a href="https://github.com/proycon/python-frog" target="_blank" rel="external">python-frog</a> - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER)</li></p>
<p><li><a href="https://github.com/EducationalTestingService/python-zpar" target="_blank" rel="external">python-zpar</a> - Python bindings for <a href="https://github.com/frcchang/zpar" target="_blank" rel="external">ZPar</a>, a statistical part-of-speech-tagger, constiuency parser, and dependency parser for English.</li></p>
<p><li><a href="https://github.com/proycon/colibri-core" target="_blank" rel="external">colibri-core</a> - Python binding to C++ library for extracting and working with with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.</li></p>
<p><li><a href="https://github.com/honnibal/spaCy/" target="_blank" rel="external">spaCy</a> - Industrial strength NLP with Python and Cython.</li></p>
<p><li><a href="https://github.com/dmcc/PyStanfordDependencies" target="_blank" rel="external">PyStanfordDependencies</a> - Python interface for converting Penn Treebank trees to Stanford Dependencies.</li></p>
<p><li><a href="https://github.com/doukremt/distance" target="_blank" rel="external">Distance</a> - Levenshtein and Hamming distance computation</li></p>
<p><li><a href="https://github.com/seatgeek/fuzzywuzzy" target="_blank" rel="external">Fuzzy Wuzzy</a> - Fuzzy String Matching in Python</li></p>
<p><li><a href="https://github.com/jamesturk/jellyfish" target="_blank" rel="external">jellyfish</a> - a python library for doing approximate and phonetic matching of strings.</li></p>
<p><li><a href="https://pypi.python.org/pypi/editdistance" target="_blank" rel="external">editdistance</a> - fast implementation of edit distance</li></p>
<p><li><a href="https://github.com/chartbeat-labs/textacy" target="_blank" rel="external">textacy</a> - higher-level NLP built on Spacy</li></p>
<p><li><a href="https://github.com/dasmith/stanford-corenlp-python" target="_blank" rel="external">stanford-corenlp-python</a> - Python wrapper for <a href="https://github.com/stanfordnlp/CoreNLP" target="_blank" rel="external">Stanford CoreNLP</a></li><br></p></ul><p></p>
<p></p><p><a name="user-content-python-general-purpose"></a></p><a name="user-content-python-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-18" class="anchor" href="#general-purpose-machine-learning-18" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-python-general-purpose"><br></a><li><a name="user-content-python-general-purpose"></a><a href="https://github.com/ClimbsRocks/auto_ml" target="_blank" rel="external">auto_ml</a> - Automated machine learning pipelines for analytics and production. Handles some standard feature engineering, feature selection, model selection, model tuning, ensembling, and advanced scoring, in addition to logging output for analysts trying to understand their datasets.</li><p></p>
<p><li><a href="https://github.com/jeff1evesque/machine-learning" target="_blank" rel="external">machine learning</a> - automated build consisting of a <a href="https://github.com/jeff1evesque/machine-learning#web-interface" target="_blank" rel="external">web-interface</a>, and set of <a href="https://github.com/jeff1evesque/machine-learning#programmatic-interface" target="_blank" rel="external">programmatic-interface</a> API, for support vector machines.  Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore.</li></p>
<p><li><a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">XGBoost</a> - Python bindings for eXtreme Gradient Boosting (Tree) Library</li></p>
<p><li><a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" target="_blank" rel="external">Bayesian Methods for Hackers</a> - Book/iPython notebooks on Probabilistic Programming in Python</li></p>
<p><li><a href="https://github.com/machinalis/featureforge" target="_blank" rel="external">Featureforge</a> A set of tools for creating and testing machine learning features, with a scikit-learn compatible API</li></p>
<p><li><a href="http://spark.apache.org/docs/latest/mllib-guide.html" target="_blank" rel="external">MLlib in Apache Spark</a> - Distributed machine learning library in Spark</li></p>
<p><li><a href="https://github.com/Hydrospheredata/mist" target="_blank" rel="external">Hydrosphere Mist</a> - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.</li></p>
<p><li><a href="http://scikit-learn.org/" target="_blank" rel="external">scikit-learn</a> - A Python module for machine learning built on top of SciPy.</li></p>
<p><li><a href="https://github.com/all-umass/metric-learn" target="_blank" rel="external">metric-learn</a> - A Python module for metric learning.</li></p>
<p><li><a href="http://github.com/simpleai-team/simpleai" target="_blank" rel="external">SimpleAI</a> Python implementation of many of the artificial intelligence algorithms described on the book “Artificial Intelligence, a Modern Approach”. It focuses on providing an easy to use, well documented and tested library.</li></p>
<p><li><a href="http://www.astroml.org/" target="_blank" rel="external">astroML</a> - Machine Learning and Data Mining for Astronomy.</li></p>
<p><li><a href="http://graphlab.com/products/create/docs/" target="_blank" rel="external">graphlab-create</a> - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame.</li></p>
<p><li><a href="https://bigml.com" target="_blank" rel="external">BigML</a> - A library that contacts external servers.</li></p>
<p><li><a href="https://github.com/clips/pattern" target="_blank" rel="external">pattern</a> - Web mining module for Python.</li></p>
<p><li><a href="https://github.com/numenta/nupic" target="_blank" rel="external">NuPIC</a> - Numenta Platform for Intelligent Computing.</li></p>
<p><li><a href="https://github.com/lisa-lab/pylearn2" target="_blank" rel="external">Pylearn2</a> - A Machine Learning library based on <a href="https://github.com/Theano/Theano" target="_blank" rel="external">Theano</a>.</li></p>
<p><li><a href="https://github.com/fchollet/keras" target="_blank" rel="external">keras</a> - Modular neural network library based on <a href="https://github.com/Theano/Theano" target="_blank" rel="external">Theano</a>.</li></p>
<p><li><a href="https://github.com/Lasagne/Lasagne" target="_blank" rel="external">Lasagne</a> - Lightweight library to build and train neural networks in Theano.</li></p>
<p><li><a href="https://github.com/hannes-brt/hebel" target="_blank" rel="external">hebel</a> - GPU-Accelerated Deep Learning Library in Python.</li></p>
<p><li><a href="https://github.com/pfnet/chainer" target="_blank" rel="external">Chainer</a> - Flexible neural network framework</li></p>
<p><li><a href="https://github.com/piskvorky/gensim" target="_blank" rel="external">gensim</a> - Topic Modelling for Humans.</li></p>
<p><li><a href="https://github.com/ContinuumIO/topik" target="_blank" rel="external">topik</a> - Topic modelling toolkit</li></p>
<p><li><a href="https://github.com/pybrain/pybrain" target="_blank" rel="external">PyBrain</a> - Another Python Machine Learning Library.</li></p>
<p><li><a href="https://github.com/IDSIA/brainstorm" target="_blank" rel="external">Brainstorm</a> - Fast, flexible and fun neural networks. This is the successor of PyBrain.</li></p>
<p><li><a href="https://github.com/muricoca/crab" target="_blank" rel="external">Crab</a> - A ﬂexible, fast recommender engine.</li></p>
<p><li><a href="https://github.com/ocelma/python-recsys" target="_blank" rel="external">python-recsys</a> - A Python library for implementing a Recommender System.</li></p>
<p><li><a href="https://github.com/AllenDowney/ThinkBayes" target="_blank" rel="external">thinking bayes</a> - Book on Bayesian Analysis</li></p>
<p><li><a href="https://github.com/echen/restricted-boltzmann-machines" target="_blank" rel="external">Restricted Boltzmann Machines</a> -Restricted Boltzmann Machines in Python. [DEEP LEARNING]</li></p>
<p><li><a href="https://github.com/pprett/bolt" target="_blank" rel="external">Bolt</a> - Bolt Online Learning Toolbox</li></p>
<p><li><a href="https://github.com/patvarilly/CoverTree" target="_blank" rel="external">CoverTree</a> - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree</li></p>
<p><li><a href="https://github.com/nilearn/nilearn" target="_blank" rel="external">nilearn</a> - Machine learning for NeuroImaging in Python</li></p>
<p><li><a href="http://contrib.scikit-learn.org/imbalanced-learn/" target="_blank" rel="external">imbalanced-learn</a> - Python module to perform under sampling and over sampling with various techniques.</li></p>
<p><li><a href="https://github.com/shogun-toolbox/shogun" target="_blank" rel="external">Shogun</a> - The Shogun Machine Learning Toolbox</li></p>
<p><li><a href="https://github.com/perone/Pyevolve" target="_blank" rel="external">Pyevolve</a> - Genetic algorithm framework.</li></p>
<p><li><a href="http://caffe.berkeleyvision.org" target="_blank" rel="external">Caffe</a>  - A deep learning framework developed with cleanliness, readability, and speed in mind.</li></p>
<p><li><a href="https://github.com/breze-no-salt/breze" target="_blank" rel="external">breze</a> - Theano based library for deep and recurrent neural networks</li></p>
<p><li><a href="https://github.com/mattjj/pyhsmm" target="_blank" rel="external">pyhsmm</a> - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations.</li></p>
<p><li><a href="https://pythonhosted.org/mrjob/" target="_blank" rel="external">mrjob</a> - A library to let Python program run on Hadoop.</li></p>
<p><li><a href="https://github.com/EducationalTestingService/skll" target="_blank" rel="external">SKLL</a> - A wrapper around scikit-learn that makes it simpler to conduct experiments.</li></p>
<p><li><a href="https://github.com/zueve/neurolab" target="_blank" rel="external">neurolab</a> - <a href="https://github.com/zueve/neurolab" target="_blank" rel="external">https://github.com/zueve/neurolab</a></li></p>
<p><li><a href="https://github.com/JasperSnoek/spearmint" target="_blank" rel="external">Spearmint</a> - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012.</li></p>
<p><li><a href="https://github.com/abhik/pebl/" target="_blank" rel="external">Pebl</a> - Python Environment for Bayesian Learning</li></p>
<p><li><a href="https://github.com/Theano/Theano/" target="_blank" rel="external">Theano</a> - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python</li></p>
<p><li><a href="https://github.com/tensorflow/tensorflow/" target="_blank" rel="external">TensorFlow</a> - Open source software library for numerical computation using data flow graphs</li></p>
<p><li><a href="https://github.com/jmschrei/yahmm/" target="_blank" rel="external">yahmm</a> - Hidden Markov Models for Python, implemented in Cython for speed and efficiency.</li></p>
<p><li><a href="https://github.com/proycon/python-timbl" target="_blank" rel="external">python-timbl</a> - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit.</li></p>
<p><li><a href="https://github.com/deap/deap" target="_blank" rel="external">deap</a> - Evolutionary algorithm framework.</li></p>
<p><li><a href="https://github.com/andersbll/deeppy" target="_blank" rel="external">pydeep</a> - Deep Learning In Python</li></p>
<p><li><a href="https://github.com/rasbt/mlxtend" target="_blank" rel="external">mlxtend</a> - A library consisting of useful tools for data science and machine learning tasks.</li></p>
<p><li><a href="https://github.com/NervanaSystems/neon" target="_blank" rel="external">neon</a> - Nervana’s <a href="https://github.com/soumith/convnet-benchmarks" target="_blank" rel="external">high-performance</a> Python-based Deep Learning framework [DEEP LEARNING]</li></p>
<p><li><a href="http://docs.optunity.net" target="_blank" rel="external">Optunity</a> - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search.</li></p>
<p><li><a href="https://github.com/mnielsen/neural-networks-and-deep-learning" target="_blank" rel="external">Neural Networks and Deep Learning</a> - Code samples for my book “Neural Networks and Deep Learning” [DEEP LEARNING]</li></p>
<p><li><a href="https://github.com/spotify/annoy" target="_blank" rel="external">Annoy</a> - Approximate nearest neighbours implementation</li></p>
<p><li><a href="https://github.com/google/skflow" target="_blank" rel="external">skflow</a> - Simplified interface for TensorFlow, mimicking Scikit Learn.</li></p>
<p><li><a href="https://github.com/rhiever/tpot" target="_blank" rel="external">TPOT</a> - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning.</li></p>
<p><li><a href="https://github.com/pgmpy/pgmpy" target="_blank" rel="external">pgmpy</a> A python library for working with Probabilistic Graphical Models.</li></p>
<p><li><a href="https://github.com/NVIDIA/DIGITS" target="_blank" rel="external">DIGITS</a> - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models.</li></p>
<p><li><a href="http://orange.biolab.si/" target="_blank" rel="external">Orange</a> - Open source data visualization and data analysis for novices and experts.</li></p>
<p><li><a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">MXNet</a> - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.</li></p>
<p><li><a href="https://github.com/luispedro/milk" target="_blank" rel="external">milk</a> - Machine learning toolkit focused on supervised classification.</li></p>
<p><li><a href="https://github.com/tflearn/tflearn" target="_blank" rel="external">TFLearn</a> - Deep learning library featuring a higher-level API for TensorFlow.</li></p>
<p><li><a href="https://github.com/yandex/rep" target="_blank" rel="external">REP</a> - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience.</li></p>
<p><li><a href="https://github.com/fukatani/rgf_python" target="_blank" rel="external">rgf_python</a> - Python bindings for Regularized Greedy Forest (Tree) Library.</li></p>
<p><li><a href="https://github.com/openai/gym" target="_blank" rel="external">gym</a> - OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms.</li></p>
<p><li><a href="https://github.com/AmazaspShumik/sklearn-bayes" target="_blank" rel="external">skbayes</a> - Python package for Bayesian Machine Learning with scikit-learn API</li><br></p></ul><p></p>
<p></p><p><a name="user-content-python-data-analysis"></a></p><a name="user-content-python-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-7" class="anchor" href="#data-analysis--data-visualization-7" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-python-data-analysis"><br></a><li><a name="user-content-python-data-analysis"></a><a href="http://www.scipy.org/" target="_blank" rel="external">SciPy</a> - A Python-based ecosystem of open-source software for mathematics, science, and engineering.</li><p></p>
<p><li><a href="http://www.numpy.org/" target="_blank" rel="external">NumPy</a> - A fundamental package for scientific computing with Python.</li></p>
<p><li><a href="http://numba.pydata.org/" target="_blank" rel="external">Numba</a> - Python JIT (just in time) complier to LLVM aimed at scientific Python by the developers of Cython and NumPy.</li></p>
<p><li><a href="https://networkx.github.io/" target="_blank" rel="external">NetworkX</a> - A high-productivity software for complex networks.</li></p>
<p><li><a href="http://igraph.org/python/" target="_blank" rel="external">igraph</a> - binding to igraph library - General purpose graph library</li></p>
<p><li><a href="http://pandas.pydata.org/" target="_blank" rel="external">Pandas</a> - A library providing high-performance, easy-to-use data structures and data analysis tools.</li></p>
<p><li><a href="https://github.com/avelino/mining" target="_blank" rel="external">Open Mining</a> - Business Intelligence (BI) in Python (Pandas web interface)</li></p>
<p><li><a href="https://github.com/pymc-devs/pymc" target="_blank" rel="external">PyMC</a> - Markov Chain Monte Carlo sampling toolkit.</li></p>
<p><li><a href="https://github.com/quantopian/zipline" target="_blank" rel="external">zipline</a> - A Pythonic algorithmic trading library.</li></p>
<p><li><a href="https://pydy.org/" target="_blank" rel="external">PyDy</a> - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib.</li></p>
<p><li><a href="https://github.com/sympy/sympy" target="_blank" rel="external">SymPy</a> - A Python library for symbolic mathematics.</li></p>
<p><li><a href="https://github.com/statsmodels/statsmodels" target="_blank" rel="external">statsmodels</a> - Statistical modeling and econometrics in Python.</li></p>
<p><li><a href="http://www.astropy.org/" target="_blank" rel="external">astropy</a> - A community Python library for Astronomy.</li></p>
<p><li><a href="http://matplotlib.org/" target="_blank" rel="external">matplotlib</a> - A Python 2D plotting library.</li></p>
<p><li><a href="https://github.com/bokeh/bokeh" target="_blank" rel="external">bokeh</a> - Interactive Web Plotting for Python.</li></p>
<p><li><a href="https://plot.ly/python/" target="_blank" rel="external">plotly</a> - Collaborative web plotting for Python and matplotlib.</li></p>
<p><li><a href="https://github.com/wrobstory/vincent" target="_blank" rel="external">vincent</a> - A Python to Vega translator.</li></p>
<p><li><a href="https://github.com/mikedewar/d3py" target="_blank" rel="external">d3py</a> - A plotting library for Python, based on <a href="http://d3js.org/" target="_blank" rel="external">D3.js</a>.</li></p>
<p><li><a href="https://github.com/D3xterjs/pydexter" target="_blank" rel="external">PyDexter</a> - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser.</li></p>
<p><li><a href="https://github.com/yhat/ggplot" target="_blank" rel="external">ggplot</a> - Same API as ggplot2 for R.</li></p>
<p><li><a href="https://github.com/sinhrks/ggfortify" target="_blank" rel="external">ggfortify</a> - Unified interface to ggplot2 popular R packages.</li></p>
<p><li><a href="https://github.com/kartograph/kartograph.py" target="_blank" rel="external">Kartograph.py</a> - Rendering beautiful SVG maps in Python.</li></p>
<p><li><a href="http://pygal.org/" target="_blank" rel="external">pygal</a> - A Python SVG Charts Creator.</li></p>
<p><li><a href="https://github.com/pyqtgraph/pyqtgraph" target="_blank" rel="external">PyQtGraph</a> - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy.</li></p>
<p><li><a href="https://github.com/twitter/pycascading" target="_blank" rel="external">pycascading</a></li></p>
<p><li><a href="https://github.com/AirSage/Petrel" target="_blank" rel="external">Petrel</a> - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python.</li></p>
<p><li><a href="https://github.com/blaze/blaze" target="_blank" rel="external">Blaze</a> - NumPy and Pandas interface to Big Data.</li></p>
<p><li><a href="https://github.com/dfm/emcee" target="_blank" rel="external">emcee</a> - The Python ensemble sampling toolkit for affine-invariant MCMC.</li></p>
<p><li><a href="http://www.windml.org" target="_blank" rel="external">windML</a> - A Python Framework for Wind Energy Analysis and Prediction</li></p>
<p><li><a href="https://github.com/vispy/vispy" target="_blank" rel="external">vispy</a> - GPU-based high-performance interactive OpenGL 2D/3D data visualization library</li></p>
<p><li><a href="https://github.com/numenta/nupic.cerebro2" target="_blank" rel="external">cerebro2</a> A web-based visualization and debugging platform for NuPIC.</li></p>
<p><li><a href="https://github.com/nupic-community/nupic.studio" target="_blank" rel="external">NuPIC Studio</a> An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool!</li></p>
<p><li><a href="https://github.com/sparklingpandas/sparklingpandas" target="_blank" rel="external">SparklingPandas</a> Pandas on PySpark (POPS)</li></p>
<p><li><a href="http://stanford.edu/%7Emwaskom/software/seaborn/" target="_blank" rel="external">Seaborn</a> - A python visualization library based on matplotlib</li></p>
<p><li><a href="https://github.com/bloomberg/bqplot" target="_blank" rel="external">bqplot</a> - An API for plotting in Jupyter (IPython)</li></p>
<p><li><a href="https://github.com/rewonc/pastalog" target="_blank" rel="external">pastalog</a> - Simple, realtime visualization of neural network training performance.</li></p>
<p><li><a href="https://github.com/airbnb/caravel" target="_blank" rel="external">caravel</a> - A data exploration platform designed to be visual, intuitive, and interactive.</li></p>
<p><li><a href="https://github.com/nathanepstein/dora" target="_blank" rel="external">Dora</a> - Tools for exploratory data analysis in Python.</li></p>
<p><li><a href="http://www.ruffus.org.uk" target="_blank" rel="external">Ruffus</a> - Computation Pipeline library for python.</li></p>
<p><li><a href="https://github.com/sevamoo/SOMPY" target="_blank" rel="external">SOMPY</a> - Self Organizing Map written in Python (Uses neural networks for data analysis).</li></p>
<p><li><a href="https://github.com/peterwittek/somoclu" target="_blank" rel="external">somoclu</a> Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API.</li></p>
<p><li><a href="https://github.com/lmcinnes/hdbscan" target="_blank" rel="external">HDBScan</a> - implementation of the hdbscan algorithm in Python - used for clustering</li></p>
<p><li><a href="https://github.com/ayush1997/visualize_ML" target="_blank" rel="external">visualize_ML</a> - A python package for data exploration and data analysis.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-python-misc"></a></p><a name="user-content-python-misc"><p></p>
<h4><a id="user-content-misc-scripts--ipython-notebooks--codebases" class="anchor" href="#misc-scripts--ipython-notebooks--codebases" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Misc Scripts / iPython Notebooks / Codebases</h4>

<p></p></a><ul><a name="user-content-python-misc"><br></a><li><a name="user-content-python-misc"></a><a href="https://github.com/jaredmichaelsmith/BioPy" target="_blank" rel="external">BioPy</a> - Biologically-Inspired and Machine Learning Algorithms in Python.</li><p></p>
<p><li><a href="https://github.com/rasbt/pattern_classification" target="_blank" rel="external">pattern_classification</a></li></p>
<p><li><a href="https://github.com/Wavelets/ThinkStats2" target="_blank" rel="external">thinking stats 2</a></li></p>
<p><li><a href="https://github.com/hyperopt/hyperopt-sklearn" target="_blank" rel="external">hyperopt</a></li></p>
<p><li><a href="https://github.com/numenta/nupic" target="_blank" rel="external">numpic</a></li></p>
<p><li><a href="https://github.com/dib-lab/2012-paper-diginorm" target="_blank" rel="external">2012-paper-diginorm</a></li></p>
<p><li><a href="https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks" target="_blank" rel="external">A gallery of interesting IPython notebooks</a></li></p>
<p><li><a href="https://github.com/ogrisel/notebooks" target="_blank" rel="external">ipython-notebooks</a></li></p>
<p><li><a href="https://github.com/donnemartin/data-science-ipython-notebooks" target="_blank" rel="external">data-science-ipython-notebooks</a> - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.</li></p>
<p><li><a href="https://github.com/CamDavidsonPilon/decision-weights" target="_blank" rel="external">decision-weights</a></li></p>
<p><li><a href="https://github.com/Wavelets/sarah-palin-lda" target="_blank" rel="external">Sarah Palin LDA</a> - Topic Modeling the Sarah Palin emails.</li></p>
<p><li><a href="https://github.com/Wavelets/diffusion-segmentation" target="_blank" rel="external">Diffusion Segmentation</a> - A collection of image segmentation algorithms based on diffusion methods</li></p>
<p><li><a href="https://github.com/Wavelets/scipy-tutorials" target="_blank" rel="external">Scipy Tutorials</a> - SciPy tutorials. This is outdated, check out scipy-lecture-notes</li></p>
<p><li><a href="https://github.com/marcelcaraciolo/crab" target="_blank" rel="external">Crab</a> - A recommendation engine library for Python</li></p>
<p><li><a href="https://github.com/maxsklar/BayesPy" target="_blank" rel="external">BayesPy</a> - Bayesian Inference Tools in Python</li></p>
<p><li><a href="https://github.com/GaelVaroquaux/scikit-learn-tutorial" target="_blank" rel="external">scikit-learn tutorials</a> - Series of notebooks for learning scikit-learn</li></p>
<p><li><a href="https://github.com/madhusudancs/sentiment-analyzer" target="_blank" rel="external">sentiment-analyzer</a> - Tweets Sentiment Analyzer</li></p>
<p><li><a href="https://github.com/kevincobain2000/sentiment_classifier" target="_blank" rel="external">sentiment_classifier</a> - Sentiment classifier using word sense disambiguation.</li></p>
<p><li><a href="https://github.com/fabianp/group_lasso" target="_blank" rel="external">group-lasso</a> - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model</li></p>
<p><li><a href="https://github.com/kevincobain2000/jProcessing" target="_blank" rel="external">jProcessing</a> - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary &amp; parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO–8859-1 configured) in Python.</li></p>
<p><li><a href="https://github.com/mne-tools/mne-python-notebooks" target="_blank" rel="external">mne-python-notebooks</a> - IPython notebooks for EEG/MEG data processing using mne-python</li></p>
<p><li><a href="https://github.com/NervanaSystems/neon_course" target="_blank" rel="external">Neon Course</a> - IPython notebooks for a complete course around understanding Nervana’s Neon</li></p>
<p><li><a href="https://github.com/jvns/pandas-cookbook" target="_blank" rel="external">pandas cookbook</a> - Recipes for using Python’s pandas library</li></p>
<p><li><a href="https://github.com/BRML/climin" target="_blank" rel="external">climin</a> - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others</li></p>
<p><li><a href="https://github.com/AllenDowney/DataScience" target="_blank" rel="external">Allen Downey’s Data Science Course</a> - Code for Data Science at Olin College, Spring 2014.</li></p>
<p><li><a href="https://github.com/AllenDowney/ThinkBayes" target="_blank" rel="external">Allen Downey’s Think Bayes Code</a> - Code repository for Think Bayes.</li></p>
<p><li><a href="https://github.com/AllenDowney/ThinkComplexity" target="_blank" rel="external">Allen Downey’s Think Complexity Code</a> - Code for Allen Downey’s book Think Complexity.</li></p>
<p><li><a href="https://github.com/AllenDowney/ThinkOS" target="_blank" rel="external">Allen Downey’s Think OS Code</a> - Text and supporting code for Think OS: A Brief Introduction to Operating Systems.</li></p>
<p><li><a href="http://fbkarsdorp.github.io/python-course/" target="_blank" rel="external">Python Programming for the Humanities</a> - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP.</li></p>
<p><li><a href="https://github.com/mwgg/GreatCircle" target="_blank" rel="external">GreatCircle</a> - Library for calculating great circle distance.</li></p>
<p><li><a href="http://docs.optunity.net/notebooks/index.html" target="_blank" rel="external">Optunity examples</a> - Examples demonstrating how to use Optunity in synergy with machine learning libraries.</li></p>
<p><li><a href="https://github.com/hangtwenty/dive-into-machine-learning" target="_blank" rel="external">Dive into Machine Learning  with Python Jupyter notebook and scikit-learn</a> - “I learned Python by hacking first, and getting serious <em>later.</em> I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.”</li></p>
<p><li><a href="https://github.com/ericjang/tdb" target="_blank" rel="external">TDB</a> - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow.</li></p>
<p><li><a href="https://github.com/kendricktan/suiron/" target="_blank" rel="external">Suiron</a> - Machine Learning for RC Cars.</li></p>
<p><li><a href="https://github.com/justmarkham/scikit-learn-videos" target="_blank" rel="external">Introduction to machine learning with scikit-learn</a> - IPython notebooks from Data School’s video tutorials on scikit-learn.</li></p>
<p><li><a href="http://education.parrotprediction.teachable.com/courses/practical-xgboost-in-python" target="_blank" rel="external">Practical XGBoost in Python</a> - comprehensive online course about using XGBoost in Python</li><br></p></ul><p></p>
<p></p><p><a name="user-content-python-neural networks"></a></p><a name="user-content-python-neural networks"><p></p>
<h4><a id="user-content-neural-networks" class="anchor" href="#neural-networks" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Neural networks</h4>

<p></p></a><ul><a name="user-content-python-neural networks"><br></a><li><a name="user-content-python-neural networks"></a><a href="https://github.com/karpathy/neuraltalk" target="_blank" rel="external">Neural networks</a> - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.</li><p></p>
<p><li><a href="https://github.com/molcik/Neuron" target="_blank" rel="external">Neuron</a> - Neuron is simple class for time series predictions. It’s utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg–Marquardt algorithm.</li></p>
<p><li><a href="https://github.com/atmb4u/data-driven-code" target="_blank" rel="external">Data Driven Code</a> - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-python-kaggle"></a></p><a name="user-content-python-kaggle"><p></p>
<h4><a id="user-content-kaggle-competition-source-code" class="anchor" href="#kaggle-competition-source-code" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Kaggle Competition Source Code</h4>

<p></p></a><ul><a name="user-content-python-kaggle"><br></a><li><a name="user-content-python-kaggle"></a><a href="https://github.com/hammer/wikichallenge" target="_blank" rel="external">wiki challenge</a> - An implementation of Dell Zhang’s solution to Wikipedia’s Participation Challenge on Kaggle</li><p></p>
<p><li><a href="https://github.com/amueller/kaggle_insults" target="_blank" rel="external">kaggle insults</a> - Kaggle Submission for “Detecting Insults in Social Commentary”</li></p>
<p><li><a href="https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge" target="_blank" rel="external">kaggle_acquire-valued-shoppers-challenge</a> - Code for the Kaggle acquire valued shoppers challenge</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-cifar" target="_blank" rel="external">kaggle-cifar</a> - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-blackbox" target="_blank" rel="external">kaggle-blackbox</a> - Deep learning made easy</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-accelerometer" target="_blank" rel="external">kaggle-accelerometer</a> - Code for Accelerometer Biometric Competition at Kaggle</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-advertised-salaries" target="_blank" rel="external">kaggle-advertised-salaries</a> - Predicting job salaries from ads - a Kaggle competition</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-amazon" target="_blank" rel="external">kaggle amazon</a> - Amazon access control challenge</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-bestbuy_big" target="_blank" rel="external">kaggle-bestbuy_big</a> - Code for the Best Buy competition at Kaggle</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-bestbuy_small" target="_blank" rel="external">kaggle-bestbuy_small</a></li></p>
<p><li><a href="https://github.com/kastnerkyle/kaggle-dogs-vs-cats" target="_blank" rel="external">Kaggle Dogs vs. Cats</a> - Code for Kaggle Dogs vs. Cats competition</li></p>
<p><li><a href="https://github.com/benanne/kaggle-galaxies" target="_blank" rel="external">Kaggle Galaxy Challenge</a> - Winning solution for the Galaxy Challenge on Kaggle</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-gender" target="_blank" rel="external">Kaggle Gender</a> - A Kaggle competition: discriminate gender based on handwriting</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-merck" target="_blank" rel="external">Kaggle Merck</a> - Merck challenge at Kaggle</li></p>
<p><li><a href="https://github.com/zygmuntz/kaggle-stackoverflow" target="_blank" rel="external">Kaggle Stackoverflow</a> - Predicting closed questions on Stack Overflow</li></p>
<p><li><a href="https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge" target="_blank" rel="external">kaggle_acquire-valued-shoppers-challenge</a> - Code for the Kaggle acquire valued shoppers challenge</li></p>
<p><li><a href="https://github.com/zygmuntz/wine-quality" target="_blank" rel="external">wine-quality</a> - Predicting wine quality</li><br></p></ul><p></p>
<p></p><p><a name="user-content-ruby"></a></p><a name="user-content-ruby"><p></p>
<h2><a id="user-content-ruby" class="anchor" href="#ruby" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Ruby</h2>

<p></p></a><p><a name="user-content-ruby"></a><a name="user-content-ruby-nlp"></a></p><a name="user-content-ruby-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-11" class="anchor" href="#natural-language-processing-11" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-ruby-nlp"><br></a><li><a name="user-content-ruby-nlp"></a><a href="https://github.com/louismullie/treat" target="_blank" rel="external">Treat</a> -  Text REtrieval and Annotation Toolkit, definitely the most comprehensive toolkit I’ve encountered so far for Ruby</li><p></p>
<p><li><a href="http://www.deveiate.org/projects/Linguistics/" target="_blank" rel="external">Ruby Linguistics</a> -  Linguistics is a framework for building linguistic utilities for Ruby objects in any language. It includes a generic language-independent front end, a module for mapping language codes into language names, and a module which contains various English-language utilities.</li></p>
<p><li><a href="https://github.com/aurelian/ruby-stemmer" target="_blank" rel="external">Stemmer</a> - Expose libstemmer_c to Ruby</li></p>
<p><li><a href="http://www.deveiate.org/projects/Ruby-WordNet/" target="_blank" rel="external">Ruby Wordnet</a> - This library is a Ruby interface to WordNet</li></p>
<p><li><a href="http://sourceforge.net/projects/raspell/" target="_blank" rel="external">Raspel</a> - raspell is an interface binding for ruby</li></p>
<p><li><a href="https://github.com/ealdent/uea-stemmer" target="_blank" rel="external">UEA Stemmer</a> - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing</li></p>
<p><li><a href="https://github.com/twitter/twitter-text-rb" target="_blank" rel="external">Twitter-text-rb</a> - A library that does auto linking and extraction of usernames, lists and hashtags in tweets</li><br></p></ul><p></p>
<p></p><p><a name="user-content-ruby-general-purpose"></a></p><a name="user-content-ruby-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-19" class="anchor" href="#general-purpose-machine-learning-19" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-ruby-general-purpose"><br></a><li><a name="user-content-ruby-general-purpose"></a><a href="https://github.com/tsycho/ruby-machine-learning" target="_blank" rel="external">Ruby Machine Learning</a> - Some Machine Learning algorithms, implemented in Ruby</li><p></p>
<p><li><a href="https://github.com/mizoR/machine-learning-ruby" target="_blank" rel="external">Machine Learning Ruby</a></li></p>
<p><li><a href="https://github.com/vasinov/jruby_mahout" target="_blank" rel="external">jRuby Mahout</a> - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby.</li></p>
<p><li><a href="https://github.com/cardmagic/classifier" target="_blank" rel="external">CardMagic-Classifier</a> - A general classifier module to allow Bayesian and other types of classifications.</li></p>
<p><li><a href="https://github.com/febeling/rb-libsvm" target="_blank" rel="external">rb-libsvm</a> - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines</li><br></p></ul><p></p>
<p></p><p><a name="user-content-ruby-data-analysis"></a></p><a name="user-content-ruby-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-8" class="anchor" href="#data-analysis--data-visualization-8" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-ruby-data-analysis"><br></a><li><a name="user-content-ruby-data-analysis"></a><a href="https://github.com/alexgutteridge/rsruby" target="_blank" rel="external">rsruby</a> - Ruby - R bridge</li><p></p>
<p><li><a href="https://github.com/chrislo/data_visualisation_ruby" target="_blank" rel="external">data-visualization-ruby</a> - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby</li></p>
<p><li><a href="https://www.ruby-toolbox.com/projects/ruby-plot" target="_blank" rel="external">ruby-plot</a> - gnuplot wrapper for ruby, especially for plotting roc curves into svg files</li></p>
<p><li><a href="https://github.com/zuhao/plotrb" target="_blank" rel="external">plot-rb</a> - A plotting library in Ruby built on top of Vega and D3.</li></p>
<p><li><a href="http://www.rubyinside.com/scruffy-a-beautiful-graphing-toolkit-for-ruby-194.html" target="_blank" rel="external">scruffy</a> - A beautiful graphing toolkit for Ruby</li></p>
<p><li><a href="http://sciruby.com/" target="_blank" rel="external">SciRuby</a></li></p>
<p><li><a href="https://github.com/glean/glean" target="_blank" rel="external">Glean</a> - A data management tool for humans</li></p>
<p><li><a href="https://github.com/bioruby/bioruby" target="_blank" rel="external">Bioruby</a></li></p>
<p><li><a href="https://github.com/nkallen/arel" target="_blank" rel="external">Arel</a></li><br></p></ul><p></p>
<p></p><p><a name="user-content-ruby-misc"></a></p><a name="user-content-ruby-misc"><p></p>
<h4><a id="user-content-misc-1" class="anchor" href="#misc-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Misc</h4>

<p></p></a><ul><a name="user-content-ruby-misc"><br></a><li><a name="user-content-ruby-misc"></a><a href="https://github.com/infochimps-labs/big_data_for_chimps" target="_blank" rel="external">Big Data For Chimps</a></li><p></p>
<p><li><a href="https://github.com/kevincobain2000/listof" target="_blank" rel="external">Listof</a> - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, json or hash. <a href="http://listof.herokuapp.com/" target="_blank" rel="external">Demo/Search for a list</a></li><br></p></ul><p></p>
<p></p><p><a name="user-content-rust"></a></p><a name="user-content-rust"><p></p>
<h2><a id="user-content-rust" class="anchor" href="#rust" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Rust</h2>

<p></p></a><p><a name="user-content-rust"></a><a name="user-content-rust-general-purpose"></a></p><a name="user-content-rust-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-20" class="anchor" href="#general-purpose-machine-learning-20" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-rust-general-purpose"><br></a><li><a name="user-content-rust-general-purpose"></a><a href="https://github.com/tedsta/deeplearn-rs" target="_blank" rel="external">deeplearn-rs</a> - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license.</li><p></p>
<p><li><a href="https://github.com/maciejkula/rustlearn" target="_blank" rel="external">rustlearn</a> - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests.</li></p>
<p><li><a href="https://github.com/AtheMathmo/rusty-machine" target="_blank" rel="external">rusty-machine</a> - a pure-rust machine learning library.</li></p>
<p><li><a href="https://github.com/autumnai/leaf" target="_blank" rel="external">leaf</a> - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe.  Available under the MIT license. <a href="https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb#.s0a3uy4cc" target="_blank" rel="external"><strong>[Deprecated]</strong></a></li></p>
<p><li><a href="https://github.com/jackm321/RustNN" target="_blank" rel="external">RustNN</a> - RustNN is a feedforward neural network library.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-r"></a></p><a name="user-content-r"><p></p>
<h2><a id="user-content-r" class="anchor" href="#r" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>R</h2>

<p></p></a><p><a name="user-content-r"></a><a name="user-content-r-general-purpose"></a></p><a name="user-content-r-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-21" class="anchor" href="#general-purpose-machine-learning-21" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-r-general-purpose"><br></a><li><a name="user-content-r-general-purpose"></a><a href="http://cran.r-project.org/web/packages/ahaz/index.html" target="_blank" rel="external">ahaz</a> - ahaz: Regularization for semiparametric additive hazards regression</li><p></p>
<p><li><a href="http://cran.r-project.org/web/packages/arules/index.html" target="_blank" rel="external">arules</a> - arules: Mining Association Rules and Frequent Itemsets</li></p>
<p><li><a href="https://cran.r-project.org/web/packages/biglasso/index.html" target="_blank" rel="external">biglasso</a> - biglasso: Extending Lasso Model Fitting to Big Data in R</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/bigrf/index.html" target="_blank" rel="external">bigrf</a> - bigrf: Big Random Forests: Classification and Regression Forests for Large Data Sets</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/bigRR/index.html" target="_blank" rel="external">bigRR</a> - bigRR: Generalized Ridge Regression (with special advantage for p &gt;&gt; n cases)</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/bmrm/index.html" target="_blank" rel="external">bmrm</a> - bmrm: Bundle Methods for Regularized Risk Minimization Package</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/Boruta/index.html" target="_blank" rel="external">Boruta</a> - Boruta: A wrapper algorithm for all-relevant feature selection</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/bst/index.html" target="_blank" rel="external">bst</a> - bst: Gradient Boosting</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/C50/index.html" target="_blank" rel="external">C50</a> - C50: C5.0 Decision Trees and Rule-Based Models</li></p>
<p><li><a href="http://caret.r-forge.r-project.org/" target="_blank" rel="external">caret</a> - Classification and Regression Training: Unified interface to ~150 ML algorithms in R.</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/caretEnsemble/index.html" target="_blank" rel="external">caretEnsemble</a> - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models.</li></p>
<p><li><a href="https://github.com/jbrownlee/CleverAlgorithmsMachineLearning" target="_blank" rel="external">Clever Algorithms For Machine Learning</a></li></p>
<p><li><a href="http://cran.r-project.org/web/packages/CORElearn/index.html" target="_blank" rel="external">CORElearn</a> - CORElearn: Classification, regression, feature evaluation and ordinal evaluation</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/CoxBoost/index.html" target="_blank" rel="external">CoxBoost</a> - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/Cubist/index.html" target="_blank" rel="external">Cubist</a> - Cubist: Rule- and Instance-Based Regression Modeling</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/e1071/index.html" target="_blank" rel="external">e1071</a> - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/earth/index.html" target="_blank" rel="external">earth</a> - earth: Multivariate Adaptive Regression Spline Models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/elasticnet/index.html" target="_blank" rel="external">elasticnet</a> - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/ElemStatLearn/index.html" target="_blank" rel="external">ElemStatLearn</a> - ElemStatLearn: Data sets, functions and examples from the book: “The Elements of Statistical Learning, Data Mining, Inference, and Prediction” by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction” by Trevor Hastie, Robert Tibshirani and Jerome Friedman</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/evtree/index.html" target="_blank" rel="external">evtree</a> - evtree: Evolutionary Learning of Globally Optimal Trees</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/forecast/index.html" target="_blank" rel="external">forecast</a> - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/forecastHybrid/index.html" target="_blank" rel="external">forecastHybrid</a> - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the “forecast” package</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/fpc/index.html" target="_blank" rel="external">fpc</a> - fpc: Flexible procedures for clustering</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/frbs/index.html" target="_blank" rel="external">frbs</a> - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/GAMBoost/index.html" target="_blank" rel="external">GAMBoost</a> - GAMBoost: Generalized linear and additive models by likelihood based boosting</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/gamboostLSS/index.html" target="_blank" rel="external">gamboostLSS</a> - gamboostLSS: Boosting Methods for GAMLSS</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/gbm/index.html" target="_blank" rel="external">gbm</a> - gbm: Generalized Boosted Regression Models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/glmnet/index.html" target="_blank" rel="external">glmnet</a> - glmnet: Lasso and elastic-net regularized generalized linear models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/glmpath/index.html" target="_blank" rel="external">glmpath</a> - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/GMMBoost/index.html" target="_blank" rel="external">GMMBoost</a> - GMMBoost: Likelihood-based Boosting for Generalized mixed models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/grplasso/index.html" target="_blank" rel="external">grplasso</a> - grplasso: Fitting user specified models with Group Lasso penalty</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/grpreg/index.html" target="_blank" rel="external">grpreg</a> - grpreg: Regularization paths for regression models with grouped covariates</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/h2o/index.html" target="_blank" rel="external">h2o</a> - A framework for fast, parallel, and distributed machine learning algorithms at scale – Deeplearning, Random forests, GBM, KMeans, PCA, GLM</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/hda/index.html" target="_blank" rel="external">hda</a> - hda: Heteroscedastic Discriminant Analysis</li></p>
<p><li><a href="http://www-bcf.usc.edu/%7Egareth/ISL/" target="_blank" rel="external">Introduction to Statistical Learning</a></li></p>
<p><li><a href="http://cran.r-project.org/web/packages/ipred/index.html" target="_blank" rel="external">ipred</a> - ipred: Improved Predictors</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/kernlab/index.html" target="_blank" rel="external">kernlab</a> - kernlab: Kernel-based Machine Learning Lab</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/klaR/index.html" target="_blank" rel="external">klaR</a> - klaR: Classification and visualization</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/lars/index.html" target="_blank" rel="external">lars</a> - lars: Least Angle Regression, Lasso and Forward Stagewise</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/lasso2/index.html" target="_blank" rel="external">lasso2</a> - lasso2: L1 constrained estimation aka ‘lasso’</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/LiblineaR/index.html" target="_blank" rel="external">LiblineaR</a> - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/LogicReg/index.html" target="_blank" rel="external">LogicReg</a> - LogicReg: Logic Regression</li></p>
<p><li><a href="https://github.com/johnmyleswhite/ML_for_Hackers" target="_blank" rel="external">Machine Learning For Hackers</a></li></p>
<p><li><a href="http://cran.r-project.org/web/packages/maptree/index.html" target="_blank" rel="external">maptree</a> - maptree: Mapping, pruning, and graphing tree models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/mboost/index.html" target="_blank" rel="external">mboost</a> - mboost: Model-Based Boosting</li></p>
<p><li><a href="https://www.kaggle.com/forums/f/15/kaggle-forum/t/3661/medley-a-new-r-package-for-blending-regression-models/21278" target="_blank" rel="external">medley</a> - medley: Blending regression models, using a greedy stepwise approach</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/mlr/index.html" target="_blank" rel="external">mlr</a> - mlr: Machine Learning in R</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/mvpart/index.html" target="_blank" rel="external">mvpart</a> - mvpart: Multivariate partitioning</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/ncvreg/index.html" target="_blank" rel="external">ncvreg</a> - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/nnet/index.html" target="_blank" rel="external">nnet</a> - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/oblique.tree/index.html" target="_blank" rel="external">oblique.tree</a> - oblique.tree: Oblique Trees for Classification Data</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/pamr/index.html" target="_blank" rel="external">pamr</a> - pamr: Pam: prediction analysis for microarrays</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/party/index.html" target="_blank" rel="external">party</a> - party: A Laboratory for Recursive Partytioning</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/partykit/index.html" target="_blank" rel="external">partykit</a> - partykit: A Toolkit for Recursive Partytioning</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/penalized/index.html" target="_blank" rel="external">penalized</a> - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/penalizedLDA/index.html" target="_blank" rel="external">penalizedLDA</a> - penalizedLDA: Penalized classification using Fisher’s linear discriminant</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/penalizedSVM/index.html" target="_blank" rel="external">penalizedSVM</a> - penalizedSVM: Feature Selection SVM using penalty functions</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/quantregForest/index.html" target="_blank" rel="external">quantregForest</a> - quantregForest: Quantile Regression Forests</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/randomForest/index.html" target="_blank" rel="external">randomForest</a> - randomForest: Breiman and Cutler’s random forests for classification and regression</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/randomForestSRC/index.html" target="_blank" rel="external">randomForestSRC</a> - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC)</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rattle/index.html" target="_blank" rel="external">rattle</a> - rattle: Graphical user interface for data mining in R</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rda/index.html" target="_blank" rel="external">rda</a> - rda: Shrunken Centroids Regularized Discriminant Analysis</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rdetools/index.html" target="_blank" rel="external">rdetools</a> - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/REEMtree/index.html" target="_blank" rel="external">REEMtree</a> - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/relaxo/index.html" target="_blank" rel="external">relaxo</a> - relaxo: Relaxed Lasso</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rgenoud/index.html" target="_blank" rel="external">rgenoud</a> - rgenoud: R version of GENetic Optimization Using Derivatives</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rgp/index.html" target="_blank" rel="external">rgp</a> - rgp: R genetic programming framework</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/Rmalschains/index.html" target="_blank" rel="external">Rmalschains</a> - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rminer/index.html" target="_blank" rel="external">rminer</a> - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/ROCR/index.html" target="_blank" rel="external">ROCR</a> - ROCR: Visualizing the performance of scoring classifiers</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/RoughSets/index.html" target="_blank" rel="external">RoughSets</a> - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/rpart/index.html" target="_blank" rel="external">rpart</a> - rpart: Recursive Partitioning and Regression Trees</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/RPMM/index.html" target="_blank" rel="external">RPMM</a> - RPMM: Recursively Partitioned Mixture Model</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/RSNNS/index.html" target="_blank" rel="external">RSNNS</a> - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS)</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/RWeka/index.html" target="_blank" rel="external">RWeka</a> - RWeka: R/Weka interface</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/RXshrink/index.html" target="_blank" rel="external">RXshrink</a> - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/sda/index.html" target="_blank" rel="external">sda</a> - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/SDDA/index.html" target="_blank" rel="external">SDDA</a> - SDDA: Stepwise Diagonal Discriminant Analysis</li></p>
<p><li><a href="https://github.com/ecpolley/SuperLearner" target="_blank" rel="external">SuperLearner</a> and <a href="http://cran.r-project.org/web/packages/subsemble/index.html" target="_blank" rel="external">subsemble</a> - Multi-algorithm ensemble learning packages.</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/svmpath/index.html" target="_blank" rel="external">svmpath</a> - svmpath: svmpath: the SVM Path algorithm</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/tgp/index.html" target="_blank" rel="external">tgp</a> - tgp: Bayesian treed Gaussian process models</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/tree/index.html" target="_blank" rel="external">tree</a> - tree: Classification and regression trees</li></p>
<p><li><a href="http://cran.r-project.org/web/packages/varSelRF/index.html" target="_blank" rel="external">varSelRF</a> - varSelRF: Variable selection using random forests</li></p>
<p><li><a href="https://github.com/tqchen/xgboost/tree/master/R-package" target="_blank" rel="external">XGBoost.R</a> - R binding for eXtreme Gradient Boosting (Tree) Library</li></p>
<p><li><a href="http://docs.optunity.net" target="_blank" rel="external">Optunity</a> - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R.</li></p>
<p><li><a href="http://igraph.org/r/" target="_blank" rel="external">igraph</a> - binding to igraph library - General purpose graph library</li></p>
<p><li><a href="https://github.com/dmlc/mxnet" target="_blank" rel="external">MXNet</a> - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.</li></p>
<p><li><a href="https://github.com/Azure/Azure-TDSP-Utilities" target="_blank" rel="external">TDSP-Utilities</a> - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modeling and Reporting (AMR).</li><br></p></ul><p></p>
<p></p><p><a name="user-content-r-data-analysis"></a></p><a name="user-content-r-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-9" class="anchor" href="#data-analysis--data-visualization-9" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-r-data-analysis"><br></a><li><a name="user-content-r-data-analysis"></a><a href="http://ggplot2.org/" target="_blank" rel="external">ggplot2</a> - A data visualization package based on the grammar of graphics.</li><br></ul><p></p>
<p></p><p><a name="user-content-sas"></a></p><a name="user-content-sas"><p></p>
<h2><a id="user-content-sas" class="anchor" href="#sas" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>SAS</h2>

<p></p></a><p><a name="user-content-sas"></a><a name="user-content-sas-general-purpose"></a></p><a name="user-content-sas-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-22" class="anchor" href="#general-purpose-machine-learning-22" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-sas-general-purpose"><br></a><li><a name="user-content-sas-general-purpose"></a><a href="http://www.sas.com/en_us/software/analytics/enterprise-miner.html" target="_blank" rel="external">Enterprise Miner</a> - Data mining and machine learning that creates deployable models using a GUI or code.</li><p></p>
<p><li><a href="http://www.sas.com/en_us/software/analytics/factory-miner.html" target="_blank" rel="external">Factory Miner</a> - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-sas-data-analysis"></a></p><a name="user-content-sas-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-10" class="anchor" href="#data-analysis--data-visualization-10" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-sas-data-analysis"><br></a><li><a name="user-content-sas-data-analysis"></a><a href="http://www.sas.com/en_us/software/analytics/stat.html" target="_blank" rel="external">SAS/STAT</a> - For conducting advanced statistical analysis.</li><p></p>
<p><li><a href="http://www.sas.com/en_us/software/university-edition.html" target="_blank" rel="external">University Edition</a> - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-sas-mpp"></a></p><a name="user-content-sas-mpp"><p></p>
<h4><a id="user-content-high-performance-machine-learning" class="anchor" href="#high-performance-machine-learning" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>High Performance Machine Learning</h4>

<p></p></a><ul><a name="user-content-sas-mpp"><br></a><li><a name="user-content-sas-mpp"></a><a href="http://www.sas.com/en_us/software/analytics/high-performance-data-mining.html" target="_blank" rel="external">High Performance Data Mining</a> - Data mining and machine learning that creates deployable models using a GUI or code in an MPP environment, including Hadoop.</li><p></p>
<p><li><a href="http://www.sas.com/en_us/software/analytics/high-performance-text-mining.html" target="_blank" rel="external">High Performance Text Mining</a> - Text mining using a GUI or code in an MPP environment, including Hadoop.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-sas-nlp"></a></p><a name="user-content-sas-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-12" class="anchor" href="#natural-language-processing-12" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-sas-nlp"><br></a><li><a name="user-content-sas-nlp"></a><a href="http://www.sas.com/en_us/software/analytics/contextual-analysis.html" target="_blank" rel="external">Contextual Analysis</a> - Add structure to unstructured text using a GUI.</li><p></p>
<p><li><a href="http://www.sas.com/en_us/software/analytics/sentiment-analysis.html" target="_blank" rel="external">Sentiment Analysis</a> - Extract sentiment from text using a GUI.</li></p>
<p><li><a href="http://www.sas.com/en_us/software/analytics/text-miner.html" target="_blank" rel="external">Text Miner</a> - Text mining using a GUI or code.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-sas-demos"></a></p><a name="user-content-sas-demos"><p></p>
<h4><a id="user-content-demos-and-scripts-1" class="anchor" href="#demos-and-scripts-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Demos and Scripts</h4>

<p></p></a><ul><a name="user-content-sas-demos"><br></a><li><a name="user-content-sas-demos"></a><a href="https://github.com/sassoftware/enlighten-apply/tree/master/ML_tables" target="_blank" rel="external">ML_Tables</a> - Concise cheat sheets containing machine learning best practices.</li><p></p>
<p><li><a href="https://github.com/sassoftware/enlighten-apply" target="_blank" rel="external">enlighten-apply</a> - Example code and materials that illustrate applications of SAS machine learning techniques.</li></p>
<p><li><a href="https://github.com/sassoftware/enlighten-integration" target="_blank" rel="external">enlighten-integration</a> - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R.</li></p>
<p><li><a href="https://github.com/sassoftware/enlighten-deep" target="_blank" rel="external">enlighten-deep</a> - Example code and materials that illustrate using neural networks with several hidden layers in SAS.</li></p>
<p><li><a href="https://github.com/sassoftware/dm-flow" target="_blank" rel="external">dm-flow</a> - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-scala"></a></p><a name="user-content-scala"><p></p>
<h2><a id="user-content-scala" class="anchor" href="#scala" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Scala</h2>

<p></p></a><p><a name="user-content-scala"></a><a name="user-content-scala-nlp"></a></p><a name="user-content-scala-nlp"><p></p>
<h4><a id="user-content-natural-language-processing-13" class="anchor" href="#natural-language-processing-13" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Natural Language Processing</h4>

<p></p></a><ul><a name="user-content-scala-nlp"><br></a><li><a name="user-content-scala-nlp"></a><a href="http://www.scalanlp.org/" target="_blank" rel="external">ScalaNLP</a> - ScalaNLP is a suite of machine learning and numerical computing libraries.</li><p></p>
<p><li><a href="https://github.com/scalanlp/breeze" target="_blank" rel="external">Breeze</a> - Breeze is a numerical processing library for Scala.</li></p>
<p><li><a href="https://github.com/scalanlp/chalk" target="_blank" rel="external">Chalk</a> - Chalk is a natural language processing library.</li></p>
<p><li><a href="https://github.com/factorie/factorie" target="_blank" rel="external">FACTORIE</a> - FACTORIE is a toolkit for deployable probabilistic modeling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-scala-data-analysis"></a></p><a name="user-content-scala-data-analysis"><p></p>
<h4><a id="user-content-data-analysis--data-visualization-11" class="anchor" href="#data-analysis--data-visualization-11" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Data Analysis / Data Visualization</h4>

<p></p></a><ul><a name="user-content-scala-data-analysis"><br></a><li><a name="user-content-scala-data-analysis"></a><a href="http://spark.apache.org/docs/latest/mllib-guide.html" target="_blank" rel="external">MLlib in Apache Spark</a> - Distributed machine learning library in Spark</li><p></p>
<p><li><a href="https://github.com/Hydrospheredata/mist" target="_blank" rel="external">Hydrosphere Mist</a> - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.</li></p>
<p><li><a href="https://github.com/twitter/scalding" target="_blank" rel="external">Scalding</a> - A Scala API for Cascading</li></p>
<p><li><a href="https://github.com/twitter/summingbird" target="_blank" rel="external">Summing Bird</a> - Streaming MapReduce with Scalding and Storm</li></p>
<p><li><a href="https://github.com/twitter/algebird" target="_blank" rel="external">Algebird</a> - Abstract Algebra for Scala</li></p>
<p><li><a href="https://github.com/xerial/xerial" target="_blank" rel="external">xerial</a> - Data management utilities for Scala</li></p>
<p><li><a href="https://github.com/avibryant/simmer" target="_blank" rel="external">simmer</a> - Reduce your data. A unix filter for algebird-powered aggregation.</li></p>
<p><li><a href="https://github.com/PredictionIO/PredictionIO" target="_blank" rel="external">PredictionIO</a> - PredictionIO, a machine learning server for software developers and data engineers.</li></p>
<p><li><a href="https://github.com/BIDData/BIDMat" target="_blank" rel="external">BIDMat</a> - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis.</li></p>
<p><li><a href="http://www.wolfe.ml/" target="_blank" rel="external">Wolfe</a> Declarative Machine Learning</li></p>
<p><li><a href="http://flink.apache.org/" target="_blank" rel="external">Flink</a> - Open source platform for distributed stream and batch data processing.</li></p>
<p><li><a href="http://spark-notebook.io" target="_blank" rel="external">Spark Notebook</a> - Interactive and Reactive Data Science using Scala and Spark.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-scala-general-purpose"></a></p><a name="user-content-scala-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-23" class="anchor" href="#general-purpose-machine-learning-23" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-scala-general-purpose"><br></a><li><a name="user-content-scala-general-purpose"></a><a href="https://github.com/etsy/Conjecture" target="_blank" rel="external">Conjecture</a> - Scalable Machine Learning in Scalding</li><p></p>
<p><li><a href="https://github.com/stripe/brushfire" target="_blank" rel="external">brushfire</a> - Distributed decision tree ensemble learning in Scala</li></p>
<p><li><a href="https://github.com/tresata/ganitha" target="_blank" rel="external">ganitha</a> - scalding powered machine learning</li></p>
<p><li><a href="https://github.com/bigdatagenomics/adam" target="_blank" rel="external">adam</a> - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed.</li></p>
<p><li><a href="https://github.com/bioscala/bioscala" target="_blank" rel="external">bioscala</a> - Bioinformatics for the Scala programming language</li></p>
<p><li><a href="https://github.com/BIDData/BIDMach" target="_blank" rel="external">BIDMach</a> - CPU and GPU-accelerated Machine Learning Library.</li></p>
<p><li><a href="https://github.com/p2t2/figaro" target="_blank" rel="external">Figaro</a> - a Scala library for constructing probabilistic models.</li></p>
<p><li><a href="https://github.com/h2oai/sparkling-water" target="_blank" rel="external">H2O Sparkling Water</a> - H2O and Spark interoperability.</li></p>
<p><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/batch/libs/ml/index.html" target="_blank" rel="external">FlinkML in Apache Flink</a> - Distributed machine learning library in Flink</li></p>
<p><li><a href="https://github.com/transcendent-ai-labs/DynaML" target="_blank" rel="external">DynaML</a> - Scala Library/REPL for Machine Learning Research</li></p>
<p><li><a href="https://github.com/IllinoisCogComp/saul/" target="_blank" rel="external">Saul</a> - Flexible Declarative Learning-Based Programming.</li></p>
<p><li><a href="https://github.com/valdanylchuk/swiftlearner/" target="_blank" rel="external">SwiftLearner</a> - Simply written algorithms to help study ML or write your own implementations.</li><br></p></ul><p></p>
<p></p><p><a name="user-content-swift"></a></p><a name="user-content-swift"><p></p>
<h2><a id="user-content-swift" class="anchor" href="#swift" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Swift</h2>

<p></p></a><p><a name="user-content-swift"></a><a name="user-content-swift-general-purpose"></a></p><a name="user-content-swift-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-24" class="anchor" href="#general-purpose-machine-learning-24" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-swift-general-purpose"><br></a><li><a name="user-content-swift-general-purpose"></a><a href="https://github.com/collinhundley/Swift-AI" target="_blank" rel="external">Swift AI</a> - Highly optimized artificial intelligence and machine learning library written in Swift.</li><p></p>
<p><li><a href="https://github.com/aleph7/BrainCore" target="_blank" rel="external">BrainCore</a> - The iOS and OS X neural network framework</li></p>
<p><li><a href="https://github.com/scottsievert/swix" target="_blank" rel="external">swix</a> - A bare bones library that<br>includes a general matrix language and wraps some OpenCV for iOS development.</li></p>
<p><li><a href="http://deeplearningkit.org/" target="_blank" rel="external">DeepLearningKit</a> an Open Source Deep Learning Framework for Apple’s iOS, OS X and tvOS.<br>It currently allows using deep convolutional neural network models trained in Caffe on Apple operating systems.</li></p>
<p><li><a href="https://github.com/KevinCoble/AIToolbox" target="_blank" rel="external">AIToolbox</a> - A toolbox framework of AI modules written in Swift:  Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians.</li></p>
<p><li><a href="https://github.com/Somnibyte/MLKit" target="_blank" rel="external">MLKit</a> - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression.</li></p>
<p><li><a href="https://github.com/vlall/Swift-Brain" target="_blank" rel="external">Swift Brain</a> - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc..</li><br></p></ul><p></p>
<p></p><p><a name="user-content-tensor"></a></p><a name="user-content-tensor"><p></p>
<h2><a id="user-content-tensorflow" class="anchor" href="#tensorflow" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>TensorFlow</h2>

<p></p></a><p><a name="user-content-tensor"></a><a name="user-content-tensor-general-purpose"></a></p><a name="user-content-tensor-general-purpose"><p></p>
<h4><a id="user-content-general-purpose-machine-learning-25" class="anchor" href="#general-purpose-machine-learning-25" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>General-Purpose Machine Learning</h4>

<p></p></a><ul><a name="user-content-tensor-general-purpose"><br></a><li><a name="user-content-tensor-general-purpose"></a><a href="https://github.com/jtoy/awesome-tensorflow" target="_blank" rel="external">Awesome TensorFlow</a> - A list of all things related to TensorFlow</li><br></ul><p></p>
<p></p><p><a name="user-content-credits"></a></p><a name="user-content-credits"><p></p>
<h2><a id="user-content-credits" class="anchor" href="#credits" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Credits</h2>

<p></p></a><ul><a name="user-content-credits"><br></a><li><a name="user-content-credits">Some of the python libraries were cut-and-pasted from </a><a href="https://github.com/vinta/awesome-python" target="_blank" rel="external">vinta</a></li><p></p>
<p><li>The few go reference I found where pulled from <a href="https://code.google.com/p/go-wiki/wiki/Projects#Machine_Learning" target="_blank" rel="external">this page</a></li><br></p></ul><br><br>  <p></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://github.com/josephmisiti/awesome-machine-learning&quot;&gt;Joseph Misiti/josephmisiti&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by awesome-php.&lt;/p&gt;

&lt;p&gt;If you want to contribute to this list (please do), send me a pull request or contact me &lt;a href=&quot;https://twitter.com/josephmisiti&quot;&gt;@josephmisiti&lt;/a&gt;&lt;br&gt;Also, a listed repository should be deprecated if:&lt;/p&gt;

&lt;ul&gt;&lt;br&gt;&lt;li&gt;Repository’s owner explicitly say that “this library is not maintained”.&lt;/li&gt;&lt;br&gt;&lt;li&gt;Not committed for long time (2~3 years).&lt;/li&gt;&lt;br&gt;&lt;/ul&gt;

&lt;p&gt;For a list of free machine learning books available for download, go &lt;a href=&quot;https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For a list of free-to-attend meetups and local events, go &lt;a href=&quot;https://github.com/josephmisiti/awesome-machine-learning/blob/master/meetups.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Awesome Deep Learning</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Resources/awesome-deep-learning/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Resources/awesome-deep-learning/</id>
    <published>2017-02-19T15:56:00.000Z</published>
    <updated>2017-02-19T06:03:00.878Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://github.com/josephmisiti/awesome-deep-learning" target="_blank" rel="external">Joseph Misiti/josephmisiti</a></p>
<html lang="en" class=" is-u2f-enabled"><br><br>A curated list of awesome Deep Learning tutorials, projects and communities.<br><br>  <div id="readme" class="readme blob instapaper_body"><br>    <article class="markdown-body entry-content" itemprop="text"><h3><a id="user-content-free-online-books" class="anchor" href="#free-online-books" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Free Online Books</h3><br><br><ol><br><li> <a href="http://www.iro.umontreal.ca/%7Ebengioy/dlbook/" target="_blank" rel="external">Deep Learning</a> by Yoshua Bengio, Ian Goodfellow and Aaron Courville  (01/01/2015)</li><br><li> <a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="external">Neural Networks and Deep Learning</a> by  Michael Nielsen (Dec 2014)</li><br><li> <a href="http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf" target="_blank" rel="external">Deep Learning</a> by Microsoft Research (2013) </li><br><li> <a href="http://deeplearning.net/tutorial/deeplearning.pdf" target="_blank" rel="external">Deep Learning Tutorial</a> by LISA lab, University of Montreal (Jan 6 2015)</li><br></ol><br><br><a id="more"></a><br><br><h3><a id="user-content-courses" class="anchor" href="#courses" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Courses</h3><br><br><ol><br><li> <a href="https://class.coursera.org/ml-005" target="_blank" rel="external">Machine Learning - Stanford</a> by Andrew Ng in Coursera (2010-2014)</li><br><li> <a href="http://work.caltech.edu/lectures.html" target="_blank" rel="external">Machine Learning - Caltech</a> by Yaser Abu-Mostafa (2012-2014)</li><br><li> <a href="http://www.cs.cmu.edu/%7Etom/10701_sp11/lectures.shtml" target="_blank" rel="external">Machine Learning - Carnegie Mellon</a> by Tom Mitchell (Spring 2011)</li><br><li> <a href="https://class.coursera.org/neuralnets-2012-001" target="_blank" rel="external">Neural Networks for Machine Learning</a> by Geoffrey Hinton in Coursera (2012)</li><br><li> <a href="https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH" target="_blank" rel="external">Neural networks class</a> by Hugo Larochelle from Université de Sherbrooke (2013)</li><br><li> <a href="http://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start" target="_blank" rel="external">Deep Learning Course</a> by CILVR lab @ NYU (2014)</li><br><li> <a href="https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/" target="_blank" rel="external">A.I - Berkeley</a> by Dan Klein and Pieter Abbeel (2013)</li><br><li> <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/" target="_blank" rel="external">A.I - MIT</a> by Patrick Henry Winston (2010)</li><br><li> <a href="http://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html" target="_blank" rel="external">Vision and learning - computers and brains</a> by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)</li><br></ol><br><br><h3><a id="user-content-video-and-lectures" class="anchor" href="#video-and-lectures" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Video and Lectures</h3><br><br><ol><br><li> <a href="https://www.youtube.com/watch?v=RIkxVci-R4k" target="_blank" rel="external">How To Create A Mind</a> By Ray Kurzweil</li><br><li> <a href="https://www.youtube.com/watch?v=n1ViNeWhC24" target="_blank" rel="external">Deep Learning, Self-Taught Learning and Unsupervised Feature Learning</a> By Andrew Ng</li><br><li> <a href="https://www.youtube.com/watch?v=vShMxxqtDDs&amp;amp;index=3&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT" target="_blank" rel="external">Recent Developments in Deep Learning</a> By Geoff Hinton</li><br><li> <a href="https://www.youtube.com/watch?v=sc-KbuZqGkI" target="_blank" rel="external">The Unreasonable Effectiveness of Deep Learning</a> by Yann LeCun</li><br><li> <a href="https://www.youtube.com/watch?v=4xsVFLnHC_0" target="_blank" rel="external">Deep Learning of Representations</a> by Yoshua bengio</li><br><li> <a href="https://www.youtube.com/watch?v=6ufPpZDmPKA" target="_blank" rel="external">Principles of Hierarchical Temporal Memory</a> by Jeff Hawkins</li><br><li> <a href="https://www.youtube.com/watch?v=2QJi0ArLq7s&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT" target="_blank" rel="external">Machine Learning Discussion Group - Deep Learning w/ Stanford AI Lab</a> by Adam Coates</li><br><li> <a href="http://vimeo.com/80821560" target="_blank" rel="external">Making Sense of the World with Deep Learning</a> By Adam Coates </li><br><li> <a href="https://www.youtube.com/watch?v=wZfVBwOO0-k" target="_blank" rel="external">Demystifying Unsupervised Feature Learning </a> By Adam Coates</li><br><li> <a href="https://www.youtube.com/watch?v=3boKlkPBckA" target="_blank" rel="external">Visual Perception with Deep Learning</a> By Yann LeCun</li><br><li> <a href="https://www.youtube.com/watch?v=AyzOUbkUf3M" target="_blank" rel="external">The Next Generation of Neural Networks</a> By Geoffrey Hinton at GoogleTechTalks</li><br><li> <a href="http://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn" target="_blank" rel="external">The wonderful and terrifying implications of computers that can learn</a> By Jeremy Howard at TEDxBrussels</li><br></ol><br><br><h3><a id="user-content-papers" class="anchor" href="#papers" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Papers</h3><br><br><ol><br><li> <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">ImageNet Classification with Deep Convolutional Neural Networks</a></li><br><li> <a href="http://www.cs.toronto.edu/%7Ehinton/absps/esann-deep-final.pdf" target="_blank" rel="external">Using Very Deep Autoencoders for Content Based Image Retrieval</a></li><br><li> <a href="http://www.iro.umontreal.ca/%7Elisa/pointeurs/TR1312.pdf" target="_blank" rel="external">Learning Deep Architectures for AI</a></li><br><li> <a href="http://deeplearning.cs.cmu.edu/" target="_blank" rel="external">CMU’s list of papers</a></li><br></ol><br><br><h3><a id="user-content-tutorials" class="anchor" href="#tutorials" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Tutorials</h3><br><br><ol><br><li> <a href="http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial" target="_blank" rel="external">UFLDL Tutorial 1</a></li><br><li> <a href="http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/" target="_blank" rel="external">UFLDL Tutorial 2</a></li><br><li> <a href="http://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial" target="_blank" rel="external">Deep Learning for NLP (without Magic)</a></li><br><li> <a href="http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks" target="_blank" rel="external">A Deep Learning Tutorial: From Perceptrons to Deep Networks</a></li><br><li> <a href="http://www.metacademy.org/roadmaps/rgrosse/deep_learning" target="_blank" rel="external">Deep Learning from the Bottom up</a></li><br></ol><br><br><h3><a id="user-content-websites" class="anchor" href="#websites" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>WebSites</h3><br><br><ol><br><li> <a href="http://deeplearning.net/" target="_blank" rel="external">deeplearning.net</a></li><br><li> <a href="http://deeplearning.stanford.edu/" target="_blank" rel="external">deeplearning.stanford.edu</a></li><br></ol><br><br><h3><a id="user-content-datasets" class="anchor" href="#datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Datasets</h3><br><br><ol><br><li> <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">MNIST</a> Handwritten digits</li><br><li> <a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="external">Google House Numbers</a> from street view</li><br><li> <a href="http://www.cs.toronto.edu/%7Ekriz/cifar.html" target="_blank" rel="external">CIFAR-10 and CIFAR-100</a>4.<br></li><br><li> <a href="http://www.image-net.org/" target="_blank" rel="external">IMAGENET</a></li><br><li> <a href="http://groups.csail.mit.edu/vision/TinyImages/" target="_blank" rel="external">Tiny Images</a> 80 Million tiny images6.<br></li><br><li> <a href="http://yahoolabs.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images" target="_blank" rel="external">Flickr Data</a> 100 Million Yahoo dataset</li><br><li> <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/" target="_blank" rel="external">Berkeley Segmentation Dataset 500</a></li><br></ol><br><br><h3><a id="user-content-frameworks" class="anchor" href="#frameworks" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Frameworks</h3><br><br><ol><br><li> <a href="http://caffe.berkeleyvision.org/" target="_blank" rel="external">Caffe</a><br></li><br><li> <a href="http://torch.ch/" target="_blank" rel="external">Torch7</a></li><br><li> <a href="http://deeplearning.net/software/theano/" target="_blank" rel="external">Theano</a></li><br><li> <a href="https://code.google.com/p/cuda-convnet2/" target="_blank" rel="external">cuda-convnet</a></li><br><li> <a href="http://libccv.org/doc/doc-convnet/" target="_blank" rel="external">Ccv</a></li><br><li> <a href="http://numenta.org/nupic.html" target="_blank" rel="external">NuPIC</a></li><br><li> <a href="http://deeplearning4j.org/" target="_blank" rel="external">DeepLearning4J</a></li><br><li> <a href="https://github.com/harthur/brain" target="_blank" rel="external">Brain</a></li><br></ol><br><br><h3><a id="user-content-miscellaneous" class="anchor" href="#miscellaneous" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Miscellaneous</h3><br><br><ol><br><li> <a href="https://plus.google.com/communities/112866381580457264725" target="_blank" rel="external">Google Plus - Deep Learning Community</a></li><br><li> <a href="http://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=shelhamer&amp;amp;searchItems=&amp;amp;sessionTopic=&amp;amp;sessionEvent=4&amp;amp;sessionYear=2014&amp;amp;sessionFormat=&amp;amp;submit=&amp;amp;select=+" target="_blank" rel="external">Caffe Webinar</a></li><br><li> <a href="http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/" target="_blank" rel="external">100 Best Github Resources in Github for DL</a></li><br><li> <a href="https://code.google.com/p/word2vec/" target="_blank" rel="external">Word2Vec</a></li><br><li> <a href="https://registry.hub.docker.com/u/tleyden5iwx/caffe/" target="_blank" rel="external">Caffe DockerFile</a></li><br><li> <a href="https://github.com/TorontoDeepLearning/convnet" target="_blank" rel="external">TorontoDeepLEarning convnet</a></li><br><li> <a href="http://www.cs.cmu.edu/%7Ecil/v-images.html" target="_blank" rel="external">Vision data sets</a></li><br><li> <a href="http://code.cogbits.com/wiki/doku.php" target="_blank" rel="external">Fantastic Torch Tutorial</a></li><br><li> <a href="https://github.com/clementfarabet/gfx.js" target="_blank" rel="external">gfx.js</a></li><br><li><a href="https://github.com/torch/torch7/wiki/Cheatsheet" target="_blank" rel="external">Torch7 Cheat sheet</a></li><br><li><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-864-advanced-natural-language-processing-fall-2005/" target="_blank" rel="external">Misc from MIT’s ‘Advanced Natural Language Processing’ course</a></li><br><li><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/lecture-notes/" target="_blank" rel="external">Misc from MIT’s ‘Machine Learning’ course</a></li><br><li><a href="http://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-520-a-networks-for-learning-regression-and-classification-spring-2001/" target="_blank" rel="external">Misc from MIT’s ‘Networks for Learning: Regression and Classification’ course</a></li><br><li><a href="http://ocw.mit.edu/courses/health-sciences-and-technology/hst-723j-neural-coding-and-perception-of-sound-spring-2005/index.htm" target="_blank" rel="external">Misc from MIT’s ‘Neural Coding and Perception of Sound’ course</a></li><br><li><a href="http://www.datasciencecentral.com/profiles/blogs/implementing-a-distributed-deep-learning-network-over-spark" target="_blank" rel="external">Implementing a Distributed Deep Learning Network over Spark</a></li><br></ol><br><br><hr><br><br><h3><a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Contributing</h3><br><br><p>Have anything in mind that you think is awesome and would fit in this list? Feel free to send a <a href="https://github.com/ashara12/awesome-deeplearning/pulls" target="_blank" rel="external">pull request</a>. </p><br></article><br>  </div><br><br><br><br>  <br></html>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://github.com/josephmisiti/awesome-deep-learning&quot;&gt;Joseph Misiti/josephmisiti&lt;/a&gt;&lt;/p&gt;
&lt;html lang=&quot;en&quot; class=&quot; is-u2f-enabled&quot;&gt;&lt;br&gt;&lt;br&gt;A curated list of awesome Deep Learning tutorials, projects and communities.&lt;br&gt;&lt;br&gt;  &lt;div id=&quot;readme&quot; class=&quot;readme blob instapaper_body&quot;&gt;&lt;br&gt;    &lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;&lt;h3&gt;&lt;a id=&quot;user-content-free-online-books&quot; class=&quot;anchor&quot; href=&quot;#free-online-books&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Free Online Books&lt;/h3&gt;&lt;br&gt;&lt;br&gt;&lt;ol&gt;&lt;br&gt;&lt;li&gt; &lt;a href=&quot;http://www.iro.umontreal.ca/%7Ebengioy/dlbook/&quot;&gt;Deep Learning&lt;/a&gt; by Yoshua Bengio, Ian Goodfellow and Aaron Courville  (01/01/2015)&lt;/li&gt;&lt;br&gt;&lt;li&gt; &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/&quot;&gt;Neural Networks and Deep Learning&lt;/a&gt; by  Michael Nielsen (Dec 2014)&lt;/li&gt;&lt;br&gt;&lt;li&gt; &lt;a href=&quot;http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf&quot;&gt;Deep Learning&lt;/a&gt; by Microsoft Research (2013) &lt;/li&gt;&lt;br&gt;&lt;li&gt; &lt;a href=&quot;http://deeplearning.net/tutorial/deeplearning.pdf&quot;&gt;Deep Learning Tutorial&lt;/a&gt; by LISA lab, University of Montreal (Jan 6 2015)&lt;/li&gt;&lt;br&gt;&lt;/ol&gt;&lt;br&gt;&lt;br&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>25个Java机器学习工具&amp;库</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Resources/25-open-source-projects-of-machine-learning-java/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Resources/25-open-source-projects-of-machine-learning-java/</id>
    <published>2017-02-19T15:50:06.000Z</published>
    <updated>2017-02-19T06:03:00.878Z</updated>
    
    <content type="html"><![CDATA[<p>转自：<a href="http://blog.csdn.net/xiexingshishu/article/details/50405531" target="_blank" rel="external">CSDN</a></p>
<p>本列表总结了25个Java机器学习工具&amp;库</p>
<a id="more"></a>
<div id="article_content" class="article_content"><br><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>本列表总结了25个Java机器学习工具&amp;库：</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>1.&nbsp;<a target="_blank" href="http://www.cs.waikato.ac.nz/ml/weka/" style="color:rgb(0,102,204); text-decoration:none">Weka</a>集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>2.<a target="_blank" href="http://moa.cms.waikato.ac.nz/" style="color:rgb(0,102,204); text-decoration:none">Massive&nbsp;Online&nbsp;Analysis</a>（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>3.<a target="_blank" href="http://meka.sourceforge.net/" style="color:rgb(0,102,204); text-decoration:none">MEKA</a>项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>4.&nbsp;<a target="_blank" href="https://adams.cms.waikato.ac.nz/" style="color:rgb(0,102,204); text-decoration:none">Advanced&nbsp;Data&nbsp;mining&nbsp;And&nbsp;Machine&nbsp;learning&nbsp;System</a>（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>5.&nbsp;<a target="_blank" href="http://elki.dbs.ifi.lmu.de/" style="color:rgb(0,102,204); text-decoration:none">Environment&nbsp;for&nbsp;Developing&nbsp;KDD-Applications&nbsp;Supported&nbsp;by&nbsp;Index-Structure</a>（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>6.&nbsp;<a target="_blank" href="http://mallet.cs.umass.edu/" style="color:rgb(0,102,204); text-decoration:none">Mallet</a>是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>7.&nbsp;<a target="_blank" href="http://www.heatonresearch.com/encog" style="color:rgb(0,102,204); text-decoration:none">Encog</a>是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>8.&nbsp;<a target="_blank" href="http://www.datumbox.com/" style="color:rgb(0,102,204); text-decoration:none">Datumbox</a>机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>9.&nbsp;<a target="_blank" href="http://deeplearning4j.org/" style="color:rgb(0,102,204); text-decoration:none">Deeplearning4j</a>是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>10.&nbsp;<a target="_blank" href="http://mahout.apache.org/" style="color:rgb(0,102,204); text-decoration:none">Mahout</a>是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>11.<a target="_blank" href="https://rapidminer.com/" style="color:rgb(0,102,204); text-decoration:none">Rapid&nbsp;Miner</a>是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java&nbsp;API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>12.&nbsp;<a target="_blank" href="http://samoa.incubator.apache.org/" style="color:rgb(0,102,204); text-decoration:none">Apache&nbsp;SAMOA</a>是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache&nbsp;Storm、Apache&nbsp;S4和Apache&nbsp;samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>13.&nbsp;<a target="_blank" href="http://neuroph.sourceforge.net/" style="color:rgb(0,102,204); text-decoration:none">Neuroph</a>通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>14.&nbsp;<a target="_blank" href="http://oryx.io/" style="color:rgb(0,102,204); text-decoration:none">Oryx&nbsp;2</a>是一个建立在Apache&nbsp;Spark和Apache&nbsp;Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>15.&nbsp;<a target="_blank" href="http://nlp.stanford.edu/software/classifier.shtml" style="color:rgb(0,102,204); text-decoration:none">Stanford&nbsp;Classifier</a>是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>16.<a target="_blank" href="http://www.cortical.io/" style="color:rgb(0,102,204); text-decoration:none">io</a>是一个Retina&nbsp;API，有着快速精确的类&#20284;大脑的自然语言处理算法。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>17.<a target="_blank" href="https://github.com/EdwardRaff/JSAT/tree/master" style="color:rgb(0,102,204); text-decoration:none">JSAT</a>是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>18.&nbsp;<a target="_blank" href="http://nd4j.org/" style="color:rgb(0,102,204); text-decoration:none">N-Dimensional&nbsp;Arrays&nbsp;for&nbsp;Java</a>(ND4J)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>19.&nbsp;<a target="_blank" href="https://www.openhub.net/p/8582" style="color:rgb(0,102,204); text-decoration:none">Java&nbsp;Machine&nbsp;Learning&nbsp;Library</a>（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>20.&nbsp;<a target="_blank" href="http://java-ml.sourceforge.net/" style="color:rgb(0,102,204); text-decoration:none">Java-ML</a>是一个使用Java编写的一系列机器学习算法的Java&nbsp;API。它只提供了一个标准的算法接口。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>21.&nbsp;<a target="_blank" href="http://spark.apache.org/mllib/" style="color:rgb(0,102,204); text-decoration:none">MLlib&nbsp;(Spark)</a>是Apache&nbsp;Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>22.&nbsp;<a target="_blank" href="https://github.com/h2oai/h2o-3" style="color:rgb(0,102,204); text-decoration:none">H2O</a>是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>23.&nbsp;<a target="_blank" href="https://github.com/WalnutiQ/wAlnut" style="color:rgb(0,102,204); text-decoration:none">WalnutiQ</a>是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>24.&nbsp;<a target="_blank" href="http://sourceforge.net/p/lemur/wiki/RankLib/" style="color:rgb(0,102,204); text-decoration:none">RankLib</a>是一个排名学习算法库。目前已经实现八种流行的算法。</p><br><p style="margin-top:0px; margin-bottom:1.5em; padding-top:0px; padding-bottom:0px; list-style:none; color:rgb(51,51,51); font-family:Helvetica,Tahoma,Arial,sans-serif; font-size:14px; line-height:24px"><br>25.&nbsp;<a target="_blank" href="https://github.com/numenta/htm.java" style="color:rgb(0,102,204); text-decoration:none">htm.java</a>（基于Java的Hierarchical&nbsp;Temporal&nbsp;Memory算法实现）是一个面向智能计算的Numenta平台的Java接口</p><br><br></div>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转自：&lt;a href=&quot;http://blog.csdn.net/xiexingshishu/article/details/50405531&quot;&gt;CSDN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本列表总结了25个Java机器学习工具&amp;amp;库&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
      <category term="Java" scheme="http://ipcreator.me/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Python教程</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Concepts/learn-journey-of-python/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Concepts/learn-journey-of-python/</id>
    <published>2017-02-19T06:14:06.000Z</published>
    <updated>2017-02-19T10:19:58.441Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.python.org/static/img/python-logo@2x.png" alt=""></p>
<p>作者：<a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">廖雪峰</a></p>
<p>这是小白的Python新手教程，具有如下特点：</p>
<p><strong>中文，免费，零起点，完整示例，基于最新的Python 3版本。</strong></p>
<p>Python是一种计算机程序设计语言。你可能已经听说过很多种流行的编程语言，比如非常难学的C语言，非常流行的Java语言，适合初学者的Basic语言，适合网页编程的JavaScript语言等等。</p>
<p>那Python是一种什么语言？</p>
<p>首先，我们普及一下编程语言的基础知识。用任何编程语言来开发程序，都是为了让计算机干活，比如下载一个MP3，编写一个文档等等，而计算机干活的CPU只认识机器指令，所以，尽管不同的编程语言差异极大，最后都得“翻译”成CPU可以执行的机器指令。而不同的编程语言，干同一个活，编写的代码量，差距也很大。</p>
<p>比如，完成同一个任务，C语言要写1000行代码，Java只需要写100行，而Python可能只要20行。</p>
<p>所以Python是一种相当高级的语言。</p>
<p>你也许会问，代码少还不好？代码少的代价是运行速度慢，C程序运行1秒钟，Java程序可能需要2秒，而Python程序可能就需要10秒。</p>
<p>那是不是越低级的程序越难学，越高级的程序越简单？表面上来说，是的，但是，在非常高的抽象计算中，高级的Python程序设计也是非常难学的，所以，高级程序语言不等于简单。</p>
<p>但是，对于初学者和完成普通任务，Python语言是非常简单易用的。连Google都在大规模使用Python，你就不用担心学了会没用。</p>
<p>用Python可以做什么？可以做日常任务，比如自动备份你的MP3；可以做网站，很多著名的网站包括YouTube就是Python写的；可以做网络游戏的后台，很多在线游戏的后台都是Python开发的。总之就是能干很多很多事啦。</p>
<p>Python当然也有不能干的事情，比如写操作系统，这个只能用C语言写；写手机应用，只能用Swift/Objective-C（针对iPhone）和Java（针对Android）；写3D游戏，最好用C或C++。</p>
<p>如果你是小白用户，满足以下条件：</p>
<p>会使用电脑，但从来没写过程序；<br>还记得初中数学学的方程式和一点点代数知识；<br>想从编程小白变成专业的软件架构师；<br>每天能抽出半个小时学习。<br>不要再犹豫了，这个教程就是为你准备的！</p>
<p>准备好了吗？</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/00138676512923004999ceca5614eb2afc5c0efdd2e4640000/0" alt=""></p>
 <a id="more"></a>
<p> 关于作者</p>
<p>廖雪峰，十年软件开发经验，业余产品经理，精通Java/Python/Ruby/Visual Basic/Objective C等，对开源框架有深入研究，著有《Spring 2.0核心技术与最佳实践》一书，多个业余开源项目托管在GitHub，欢迎微博交流：</p>
<p><img src="http://service.t.sina.com.cn/widget/qmd/1658384301/078cedea/2.png" alt=""></p>
<p>Python是一种计算机编程语言。计算机编程语言和我们日常使用的自然语言有所不同，最大的区别就是，自然语言在不同的语境下有不同的理解，而计算机要根据编程语言执行任务，就必须保证编程语言写出的程序决不能有歧义，所以，<strong>任何一种编程语言都有自己的一套语法，编译器或者解释器就是负责把符合语法的程序代码转换成CPU能够执行的机器码，然后执行。Python也不例外。</strong></p>
<p>Python的语法比较简单，采用缩进方式，写出来的代码就像下面的样子：</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print absolute value of an integer:</span></div><div class="line"><span class="keyword">a</span> = <span class="number">100</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">a</span> &gt;= <span class="number">0</span>:</div><div class="line">        print(<span class="keyword">a</span>)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">        print(-<span class="keyword">a</span>)</div></pre></td></tr></table></figure>
<p>以#开头的语句是注释，注释是给人看的，可以是任意内容，解释器会忽略掉注释。其他每一行都是一个语句，<strong>当语句以冒号:结尾时，缩进的语句视为代码块。</strong></p>
<p>缩进有利有弊。好处是强迫你写出格式化的代码，但没有规定缩进是几个空格还是Tab。按照约定俗成的管理，应该始终坚持使用4个空格的缩进。</p>
<p>缩进的另一个好处是强迫你写出缩进较少的代码，你会倾向于把一段很长的代码拆分成若干函数，从而得到缩进较少的代码。</p>
<p>缩进的坏处就是“复制－粘贴”功能失效了，这是最坑爹的地方。当你重构代码时，粘贴过去的代码必须重新检查缩进是否正确。此外，IDE很难像格式化Java代码那样格式化Python代码。</p>
<p>最后，请务必注意，<strong>Python程序是大小写敏感的</strong>，如果写错了大小写，程序会报错。</p>
<p>在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，例如：</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">a</span> = <span class="number">123</span> <span class="comment"># a是整数</span></div><div class="line">print(<span class="keyword">a</span>)</div><div class="line"><span class="keyword">a</span> = <span class="string">'ABC'</span> <span class="comment"># a变为字符串</span></div><div class="line">print(<span class="keyword">a</span>)</div></pre></td></tr></table></figure>
<p>这种变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言。静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。Java是静态语言，和静态语言相比，动态语言更灵活，就是这个原因。</p>
<p>下面的代码：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">a</span> = <span class="string">'ABC'</span></div><div class="line"><span class="selector-tag">b</span> = <span class="selector-tag">a</span></div><div class="line"><span class="selector-tag">a</span> = <span class="string">'XYZ'</span></div><div class="line"><span class="function"><span class="title">print</span><span class="params">(b)</span></span></div></pre></td></tr></table></figure></p>
<p>执行a = ‘ABC’，解释器创建了字符串’ABC’和变量a，并把a指向’ABC’：<br><img src="http://www.liaoxuefeng.com/files/attachments/0013871830933164ebea9bff3e24a64a1d36c0a6c7d368f000/0" alt=""></p>
<p>执行b = a，解释器创建了变量b，并把b指向a指向的字符串’ABC’：<br><img src="http://www.liaoxuefeng.com/files/attachments/0013871831797715367a9e297944ca88f362ea3b01efaf7000/0" alt=""></p>
<p>执行a = ‘XYZ’，解释器创建了字符串’XYZ’，并把a的指向改为’XYZ’，但b并没有更改：<br><img src="http://www.liaoxuefeng.com/files/attachments/00138718324379052e7366c983442ac971699da163cacc7000/0" alt=""></p>
<p>Python支持多种数据类型，在计算机内部，可以把任何数据都看成一个“对象”，而变量就是在程序中用来指向这些数据对象的，对变量赋值就是把数据和变量给关联起来。</p>
<p>注意：Python的整数没有大小限制，而某些语言的整数根据其存储长度是有大小限制的，例如Java对32位整数的范围限制在-2147483648-2147483647。</p>
<p>Python的浮点数也没有大小限制，但是超出一定范围就直接表示为inf（无限大）。</p>
<h2 id="字符编码"><a href="#字符编码" class="headerlink" title="字符编码"></a>字符编码</h2><p>我们已经讲过了，字符串也是一种数据类型，但是，字符串比较特殊的是还有一个编码问题。</p>
<p>因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），如果要表示更大的整数，就必须用更多的字节。比如两个字节可以表示的最大整数是65535，4个字节可以表示的最大整数是4294967295。</p>
<p>由于计算机是美国人发明的，因此，最早只有127个字母被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码，比如大写字母A的编码是65，小写字母z的编码是122。</p>
<p>但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。</p>
<p>你可以想得到的是，全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/0013872491802084161ec9ef7d143a897e1584819535656000/0" alt=""></p>
<p>因此，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。</p>
<p>Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。</p>
<p>现在，捋一捋ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。</p>
<p>字母A用ASCII编码是十进制的65，二进制的01000001；</p>
<p>字符0用ASCII编码是十进制的48，二进制的00110000，注意字符’0’和整数0是不同的；</p>
<p>汉字中已经超出了ASCII编码的范围，用Unicode编码是十进制的20013，二进制的01001110 00101101。</p>
<p>你可以猜测，如果把ASCII编码的A用Unicode编码，只需要在前面补0就可以，因此，A的Unicode编码是00000000 01000001。</p>
<p>新的问题又出现了：如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。</p>
<p>所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间：</p>
<p>字符    ASCII    Unicode    UTF-8<br>A    01000001    00000000 01000001    01000001<br>中    x    01001110 00101101    11100100 10111000 10101101<br>从上面的表格还可以发现，UTF-8编码有一个额外的好处，就是ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作。</p>
<p>搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：</p>
<p>在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。</p>
<p>用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001387245992536e2ba28125cf04f5c8985dbc94a02245e000/0" alt=""></p>
<p>浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001387245979827634fd6204f9346a1ae6358d9ed051666000/0" alt=""></p>
<p>所以你看到很多网页的源码上会有类似<meta charset="UTF-8">的信息，表示该网页正是用的UTF-8编码。</p>
<p>由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上这两行：</p>
<figure class="highlight d"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/usr/bin/env python3</span></div><div class="line"># -*- coding: utf-<span class="number">8</span> -*-</div></pre></td></tr></table></figure>
<p>第一行注释是为了告诉Linux/OS X系统，这是一个Python可执行程序，Windows系统会忽略这个注释；</p>
<p>第二行注释是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。</p>
<p>申明了UTF-8编码并不意味着你的.py文件就是UTF-8编码的，必须并且要确保文本编辑器正在使用UTF-8 without BOM编码：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001427719248811c5f9fd37acf54f6f93d7affbd80dd79b000" alt=""></p>
<p>如果.py文件本身使用UTF-8编码，并且也申明了# -<em>- coding: utf-8 -</em>-，打开命令提示符测试就可以正常显示中文：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/0014277193240041efdda5a5de14f58a0879d8d4efcee66000" alt=""></p>
<h2 id="格式化"><a href="#格式化" class="headerlink" title="格式化"></a>格式化</h2><p>在Python中，采用的格式化方式和C语言是一致的，用%实现</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001389579690189985ca83044bd4aa7a80c47f9296a5c4e000/0" alt=""></p>
<p>%运算符就是用来格式化字符串的。在字符串内部，%s表示用字符串替换，%d表示用整数替换，有几个%?占位符，后面就跟几个变量或者值，顺序要对应好。如果只有一个%?，括号可以省略。</p>
<p>常见的占位符有：</p>
<p>%d    整数<br>%f    浮点数<br>%s    字符串<br>%x    十六进制整数</p>
<p>有些时候，字符串里面的%是一个普通字符怎么办？这个时候就需要转义，用%%来表示一个%</p>
<p>Python内置的一种数据类型是列表：list。list是一种有序的集合，可以随时添加和删除其中的元素。<br>classmates = [‘Michael’, ‘Bob’, ‘Tracy’]<br>另一种有序列表叫元组：tuple。tuple和list非常类似，但是tuple一旦初始化就不能修改，比如同样是列出同学的名字<br>classmates = (‘Michael’, ‘Bob’, ‘Tracy’)<br>不可变的tuple有什么意义？因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。<br>只有1个元素的tuple定义时必须加一个逗号,，来消除歧义<br>Python在显示只有1个元素的tuple时，也会加一个逗号,，以免你误解成数学计算意义上的括号。</p>
<p>最后来看一个“可变的”tuple：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; t = ('a', 'b', ['A', 'B'])</div><div class="line">&gt;&gt;&gt; t[<span class="string">2</span>][<span class="symbol">0</span>] = 'X'</div><div class="line">&gt;&gt;&gt; t[<span class="string">2</span>][<span class="symbol">1</span>] = 'Y'</div><div class="line">&gt;&gt;&gt; t</div><div class="line">('a', 'b', ['X', 'Y'])</div></pre></td></tr></table></figure>
<p>这个tuple定义的时候有3个元素，分别是’a’，’b’和一个list。不是说tuple一旦定义后就不可变了吗？怎么后来又变了？</p>
<p>别急，我们先看看定义的时候tuple包含的3个元素：<br><img src="http://www.liaoxuefeng.com/files/attachments/001387269705541ad608276b6f7426ca59b8c2b19947243000/0" alt=""></p>
<p>当我们把list的元素’A’和’B’修改为’X’和’Y’后，tuple变为：<br><img src="http://www.liaoxuefeng.com/files/attachments/001387269768140c7d5ca167342402989dfc75343fe900b000/0" alt=""><br>表面上看，tuple的元素确实变了，但其实变的不是tuple的元素，而是list的元素。tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！</p>
<p>理解了“指向不变”后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。</p>
<p>如果要计算1-100的整数之和，从1写到100有点困难，幸好Python提供一个range()函数，可以生成一个整数序列，再通过list()函数可以转换为list。比如range(5)生成的序列是从0开始小于5的整数：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; <span class="type">list</span>(range(<span class="number">5</span>))</div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div></pre></td></tr></table></figure></p>
<p>循环是让计算机做重复任务的有效的方法。</p>
<p>break语句可以在循环过程中直接退出循环，而continue语句可以提前结束本轮循环，并直接开始下一轮循环。这两个语句通常都必须配合if语句使用。</p>
<p>要特别注意，不要滥用break和continue语句。break和continue会造成代码执行逻辑分叉过多，容易出错。大多数循环并不需要用到break和continue语句，上面的两个例子，都可以通过改写循环条件或者修改循环逻辑，去掉break和continue语句。</p>
<p>有些时候，如果代码写得有问题，会让程序陷入“死循环”，也就是永远循环下去。这时可以用Ctrl+C退出程序，或者强制结束Python进程。</p>
<h2 id="使用dict和set"><a href="#使用dict和set" class="headerlink" title="使用dict和set"></a>使用dict和set</h2><p>Python内置了字典：dict的支持，dict全称dictionary，<strong>在其他语言中也称为map</strong>，使用键-值（key-value）存储，具有极快的查找速度。<br>如果用dict实现，只需要一个“名字”-“成绩”的对照表，直接根据名字查找成绩，无论这个表有多大，查找速度都不会变慢。</p>
<p>用Python写一个dict如下：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; d = &#123;<span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Bob'</span>: <span class="number">75</span>, <span class="string">'Tracy'</span>: <span class="number">85</span>&#125;</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; d[<span class="string">'Michael'</span>]</div><div class="line"><span class="number">95</span></div></pre></td></tr></table></figure></p>
<p>为什么dict查找速度这么快？因为dict的实现原理和查字典是一样的。假设字典包含了1万个汉字，我们要查某一个字，一个办法是把字典从第一页往后翻，直到找到我们想要的字为止，这种方法就是在list中查找元素的方法，list越大，查找越慢。</p>
<p>第二种方法是先在字典的索引表里（比如部首表）查这个字对应的页码，然后直接翻到该页，找到这个字。无论找哪个字，这种查找速度都非常快，不会随着字典大小的增加而变慢。</p>
<p>dict就是第二种实现方式，给定一个名字，比如’Michael’，dict在内部就可以直接计算出Michael对应的存放成绩的“页码”，也就是95这个数字存放的内存地址，直接取出来，所以速度非常快。</p>
<p>你可以猜到，这种key-value存储方式，在放进去的时候，必须根据key算出value的存放位置，这样，取的时候才能根据key直接拿到value。<br>请务必注意，dict内部存放的顺序和key放入的顺序是没有关系的。<br>和list比较，dict有以下几个特点：</p>
<ol>
<li>查找和插入的速度极快，不会随着key的增加而变慢；</li>
<li><p>需要占用大量的内存，内存浪费多。<br>而list相反：</p>
</li>
<li><p>查找和插入的时间随着元素的增加而增加；</p>
</li>
<li>占用空间小，浪费内存很少。<br>所以，<strong>dict是用空间来换取时间的一种方法</strong>。</li>
</ol>
<p>dict可以用在需要高速查找的很多地方，在Python代码中几乎无处不在，正确使用dict非常重要，需要牢记的第一条就是dict的key必须是不可变对象。</p>
<p>这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这个 <strong>通过key计算位置的算法称为哈希算法（Hash）</strong>。</p>
<p>要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key</p>
<p><strong>set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。</strong><br>set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：<br><strong>set和dict的唯一区别仅在于没有存储对应的value</strong>，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。</p>
<h2 id="再议不可变对象"><a href="#再议不可变对象" class="headerlink" title="再议不可变对象"></a>再议不可变对象</h2><p>str是不变对象，而list是可变对象。</p>
<p>对于可变对象，比如list，对list进行操作，list内部的内容是会变化的，比如：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; a = [<span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>]</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; a.sort()</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; a</div><div class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</div></pre></td></tr></table></figure></p>
<p>而对于不可变对象，比如str，对str进行操作呢：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; a = <span class="string">'abc'</span></div><div class="line"><span class="meta">&gt;&gt;</span>&gt; a.replace(<span class="string">'a'</span>, <span class="string">'A'</span>)</div><div class="line"><span class="string">'Abc'</span></div><div class="line"><span class="meta">&gt;&gt;</span>&gt; a</div><div class="line"><span class="string">'abc'</span></div></pre></td></tr></table></figure></p>
<p>虽然字符串有个replace()方法，也确实变出了’Abc’，但变量a最后仍是’abc’，应该怎么理解呢？</p>
<p>我们先把代码改成下面这样：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; <span class="selector-tag">a</span> = <span class="string">'abc'</span></div><div class="line">&gt;&gt;&gt; <span class="selector-tag">b</span> = <span class="selector-tag">a</span>.replace(<span class="string">'a'</span>, <span class="string">'A'</span>)</div><div class="line">&gt;&gt;&gt; <span class="selector-tag">b</span></div><div class="line"><span class="string">'Abc'</span></div><div class="line">&gt;&gt;&gt; <span class="selector-tag">a</span></div><div class="line"><span class="string">'abc'</span></div></pre></td></tr></table></figure></p>
<p>要始终牢记的是，a是变量，而’abc’才是字符串对象！有些时候，我们经常说，对象a的内容是’abc’，但其实是指，a本身是一个变量，它指向的对象的内容才是’abc’：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001389580505217f87b492b060b4b0ea60c8e5e70a1b53c000/0" alt=""></p>
<p>当我们调用a.replace(‘a’, ‘A’)时，实际上调用方法replace是作用在字符串对象’abc’上的，而这个方法虽然名字叫replace，但却没有改变字符串’abc’的内容。相反，replace方法创建了一个新字符串’Abc’并返回，如果我们用变量b指向该新字符串，就容易理解了，变量a仍指向原有的字符串’abc’，但变量b却指向新字符串’Abc’了：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001389580620829061e426d429640ddb1d17174a82a7244000/0" alt=""></p>
<p>所以，对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。</p>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>基本上所有的高级语言都支持函数，Python也不例外。Python不但能非常灵活地定义函数，而且本身内置了很多有用的函数，可以直接调用。</p>
<p>抽象是数学中非常常见的概念。举个例子：</p>
<p>计算数列的和，比如：1 + 2 + 3 + … + 100，写起来十分不方便，于是数学家发明了求和符号∑，可以把1 + 2 + 3 + … + 100记作：</p>
<p>100</p>
<p>∑n</p>
<p>n=1</p>
<p>这种抽象记法非常强大，因为我们看到 ∑ 就可以理解成求和，而不是还原成低级的加法运算。</p>
<p>而且，这种抽象记法是可扩展的，比如：</p>
<p>100</p>
<p>∑(n2+1)</p>
<p>n=1</p>
<p>还原成加法运算就变成了：</p>
<p>(1 x 1 + 1) + (2 x 2 + 1) + (3 x 3 + 1) + … + (100 x 100 + 1)</p>
<p>可见，借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。</p>
<p>写计算机程序也是一样，<strong>函数就是最基本的一种代码抽象的方式</strong>。<br>函数名其实就是指向一个函数对象的引用，完全可以把函数名赋给一个变量，相当于给这个函数起了一个“别名”<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; a = abs <span class="comment"># 变量a指向abs函数</span></div><div class="line"><span class="meta">&gt;&gt;</span>&gt; a(-<span class="number">1</span>) <span class="comment"># 所以也可以通过a调用abs函数</span></div><div class="line"><span class="number">1</span></div></pre></td></tr></table></figure></p>
<p>在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用return语句返回。<br>我们以自定义一个求绝对值的my_abs函数为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_abs</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">if</span> x &gt;= <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> x</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> -x</div></pre></td></tr></table></figure></p>
<p>如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。</p>
<p>return None可以简写为return。</p>
<p>如果想定义一个什么事也不做的空函数，可以用pass语句：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nop</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<p>pass语句什么都不做，那有什么用？实际上pass可以用来作为占位符，比如现在还没想好怎么写函数的代码，就可以先放一个pass，让代码能运行起来。</p>
<p>pass还可以用在其他语句里，比如：<br><figure class="highlight fortran"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> age &gt;= <span class="number">18</span>:</div><div class="line">    <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<p>缺少了pass，代码运行就会有语法错误。</p>
<p>Python的函数返回多值其实就是返回一个tuple，但写起来更方便。</p>
<p>定义函数时，需要确定函数名和参数个数；<br>如果有必要，可以先对参数的数据类型做检查；<br>函数体内部可以用return随时返回函数结果；<br>函数执行完毕也没有return语句时，自动return None。<br>函数可以同时返回多个值，但其实就是一个tuple。</p>
<h2 id="函数的参数"><a href="#函数的参数" class="headerlink" title="函数的参数"></a>函数的参数</h2><p>定义函数的时候，我们把参数的名字和位置确定下来，函数的接口定义就完成了。对于函数的调用者来说，只需要知道如何传递正确的参数，以及函数将返回什么样的值就够了，函数内部的复杂逻辑被封装起来，调用者无需了解。</p>
<p>Python的函数定义非常简单，但灵活度却非常大。除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，使得函数定义出来的接口，不但能处理复杂的参数，还可以简化调用者的代码。</p>
<p>位置参数</p>
<p>我们先写一个计算x2的函数：</p>
<p>def power(x):<br>    return x * x<br>对于power(x)函数，参数x就是一个位置参数。</p>
<p>当我们调用power函数时，必须传入有且仅有的一个参数x：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; power(<span class="number">5</span>)</div><div class="line"><span class="number">25</span></div><div class="line"><span class="meta">&gt;&gt;</span>&gt; power(<span class="number">15</span>)</div><div class="line"><span class="number">225</span></div></pre></td></tr></table></figure></p>
<p>现在，如果我们要计算x3怎么办？可以再定义一个power3函数，但是如果要计算x4、x5……怎么办？我们不可能定义无限多个函数。</p>
<p>你也许想到了，可以把power(x)修改为power(x, n)，用来计算xn，说干就干：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">power</span><span class="params">(x, n)</span></span>:</div><div class="line">    s = <span class="number">1</span></div><div class="line">    <span class="keyword">while</span> n &gt; <span class="number">0</span>:</div><div class="line">        n = n - <span class="number">1</span></div><div class="line">        s = s * x</div><div class="line">    <span class="keyword">return</span> s</div></pre></td></tr></table></figure></p>
<p>对于这个修改后的power(x, n)函数，可以计算任意n次方：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; power(<span class="number">5</span>, <span class="number">2</span>)</div><div class="line"><span class="number">25</span></div><div class="line">&gt;&gt;&gt; power(<span class="number">5</span>, <span class="number">3</span>)</div><div class="line"><span class="number">125</span></div></pre></td></tr></table></figure></p>
<p>修改后的power(x, n)函数有两个参数：x和n，这两个参数都是位置参数，调用函数时，传入的两个值按照位置顺序依次赋给参数x和n。</p>
<p><strong>默认参数</strong></p>
<p>新的power(x, n)函数定义没有问题，但是，<strong>旧的调用代码失败了，原因是我们增加了一个参数，导致旧的代码因为缺少一个参数而无法正常调用</strong>：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; power(<span class="number">5</span>)</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;<span class="class"><span class="keyword">module</span>&gt;</span></div><div class="line"><span class="symbol">TypeError:</span> power() missing <span class="number">1</span> required positional <span class="symbol">argument:</span> <span class="string">'n'</span></div></pre></td></tr></table></figure></p>
<p>Python的错误信息很明确：调用函数power()缺少了一个位置参数n。</p>
<p>这个时候，默认参数就排上用场了。由于我们经常计算x2，所以，完全可以把第二个参数n的默认值设定为2：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">power</span><span class="params">(x, n=<span class="number">2</span>)</span></span>:</div><div class="line">    s = <span class="number">1</span></div><div class="line">    <span class="keyword">while</span> n &gt; <span class="number">0</span>:</div><div class="line">        n = n - <span class="number">1</span></div><div class="line">        s = s * x</div><div class="line">    <span class="keyword">return</span> s</div></pre></td></tr></table></figure></p>
<p>这样，当我们调用power(5)时，相当于调用power(5, 2)：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; power(<span class="number">5</span>)</div><div class="line"><span class="number">25</span></div><div class="line">&gt;&gt;&gt; power(<span class="number">5</span>, <span class="number">2</span>)</div><div class="line"><span class="number">25</span></div></pre></td></tr></table></figure></p>
<p>而对于n &gt; 2的其他情况，就必须明确地传入n，比如power(5, 3)。</p>
<p>从上面的例子可以看出，默认参数可以简化函数的调用。设置默认参数时，有几点要注意：</p>
<p>一是必选参数在前，默认参数在后，否则Python的解释器会报错（思考一下为什么默认参数不能放在必选参数前面）；<br>二是如何设置默认参数。<br>当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数。<br><strong>使用默认参数有什么好处？最大的好处是能降低调用函数的难度。</strong><br>定义默认参数要牢记一点：默认参数必须指向不变对象！</p>
<p>在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。</p>
<p><strong>可变参数</strong></p>
<p>在Python函数中，还可以定义可变参数。顾名思义，可变参数就是传入的参数个数是可变的，可以是1个、2个到任意个，还可以是0个。</p>
<p>定义可变参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此，函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数。</p>
<p>Python允许你在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; calc(*nums)</div><div class="line"><span class="number">14</span></div></pre></td></tr></table></figure></p>
<p>*nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。</p>
<p>参数组合</p>
<p>在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。</p>
<p><strong>对于任意函数，都可以通过类似func(*args, </strong>kw)的形式调用它，无论它的参数是如何定义的。**</p>
<p><strong>小结</strong></p>
<p>Python的函数具有非常灵活的参数形态，既可以实现简单的调用，又可以传入非常复杂的参数。</p>
<p>默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！</p>
<p>要注意定义可变参数和关键字参数的语法：</p>
<p>*args是可变参数，args接收的是一个tuple；</p>
<p>**kw是关键字参数，kw接收的是一个dict。</p>
<p>以及调用函数时如何传入可变参数和关键字参数的语法：</p>
<p>可变参数既可以直接传入：func(1, 2, 3)，又可以先组装list或tuple，再通过<em>args传入：func(</em>(1, 2, 3))；</p>
<p>关键字参数既可以直接传入：func(a=1, b=2)，又可以先组装dict，再通过<strong>kw传入：func(</strong>{‘a’: 1, ‘b’: 2})。</p>
<p>使用<em>args和*</em>kw是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。</p>
<p>命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。</p>
<p>定义命名的关键字参数在没有可变参数的情况下不要忘了写分隔符*，否则定义的将是位置参数。</p>
<p><strong>递归函数</strong></p>
<p>在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。<br>递归函数的优点是定义简单，逻辑清晰。理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。<br>解决递归调用栈溢出的方法是通过尾递归优化，事实上尾递归和循环的效果是一样的，所以，把循环看成是一种特殊的尾递归函数也是可以的。<br><strong>尾递归是指，在函数返回的时候，调用自身本身，并且，return语句不能包含表达式。这样，编译器或者解释器就可以把尾递归做优化，使递归本身无论调用多少次，都只占用一个栈帧，不会出现栈溢出的情况。</strong></p>
<p>fact(n)用递归的方式写出来就是：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fact</span><span class="params">(n)</span></span>:</div><div class="line">    <span class="keyword">if</span> n==<span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">return</span> n * fact(n - <span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>改成尾递归方式，需要多一点代码，主要是要把每一步的乘积传入到递归函数中：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def fact(n):</div><div class="line">    <span class="built_in">return</span> fact_iter(n, <span class="number">1</span>)</div><div class="line"></div><div class="line">def fact_iter(<span class="built_in">num</span>, <span class="built_in">product</span>):</div><div class="line">    <span class="keyword">if</span> <span class="built_in">num</span> == <span class="number">1</span>:</div><div class="line">        <span class="built_in">return</span> <span class="built_in">product</span></div><div class="line">    <span class="built_in">return</span> fact_iter(<span class="built_in">num</span> - <span class="number">1</span>, <span class="built_in">num</span> * <span class="built_in">product</span>)</div></pre></td></tr></table></figure></p>
<p>可以看到，return fact_iter(num - 1, num <em> product)仅返回递归函数本身，num - 1和num </em> product在函数调用前就会被计算，不影响函数调用。</p>
<p>尾递归调用时，如果做了优化，栈不会增长，因此，无论多少次调用也不会导致栈溢出。<br>遗憾的是，大多数编程语言没有针对尾递归做优化，Python解释器也没有做优化，所以，即使把上面的fact(n)函数改成尾递归方式，也会导致栈溢出。</p>
<p><strong>小结</strong></p>
<p>使用递归函数的优点是逻辑简单清晰，缺点是过深的调用会导致栈溢出。</p>
<p>针对尾递归优化的语言可以通过尾递归防止栈溢出。尾递归事实上和循环是等价的，没有循环语句的编程语言只能通过尾递归实现循环。</p>
<p>Python标准的解释器没有针对尾递归做优化，任何递归函数都存在栈溢出的问题。</p>
<h2 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h2><p>在Python中，代码不是越多越好，而是越少越好。代码不是越复杂越好，而是越简单越好。<br>1行代码能实现的功能，决不写5行代码。请始终牢记，代码越少，开发效率越高。</p>
<p><strong>切片</strong><br>在很多编程语言中，针对字符串提供了很多各种截取函数（例如，substring），其实目的就是对字符串切片。Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。</p>
<p>有了切片操作，很多地方循环就不再需要了。Python的切片非常灵活，一行代码就可以实现很多行循环才能完成的操作。</p>
<p><strong>迭代</strong><br>如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代（Iteration）。<br>在Python中，迭代是通过for … in来完成的，而很多语言比如C或者Java，迭代list是通过下标完成的<br>Python的for循环抽象程度要高于Java的for循环，因为Python的for循环不仅可以用在list或tuple上，还可以作用在其他可迭代对象上。<br>list这种数据类型虽然有下标，但很多其他数据类型是没有下标的，但是，只要是可迭代对象，无论有无下标，都可以迭代，比如dict就可以迭代<br>因为dict的存储不是按照list的方式顺序排列，所以，迭代出的结果顺序很可能不一样。<br>默认情况下，dict迭代的是key。如果要迭代value，可以用for value in d.values()，如果要同时迭代key和value，可以用for k, v in d.items()。<br>由于字符串也是可迭代对象，因此，也可以作用于for循环：</p>
<p>如何判断一个对象是可迭代对象呢？方法是通过collections模块的Iterable类型判断：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterable</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(<span class="string">'abc'</span>, Iterable) <span class="comment"># str是否可迭代</span></div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], Iterable) <span class="comment"># list是否可迭代</span></div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(<span class="number">123</span>, Iterable) <span class="comment"># 整数是否可迭代</span></div><div class="line"><span class="keyword">False</span></div></pre></td></tr></table></figure></p>
<p>如果要对list实现类似Java那样的下标循环怎么办？Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; <span class="keyword">for</span> <span class="selector-tag">i</span>, value <span class="keyword">in</span> enumerate([<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>]):</div><div class="line">...     print(<span class="selector-tag">i</span>, value)</div><div class="line">...</div><div class="line"><span class="number">0</span> A</div><div class="line"><span class="number">1</span> B</div><div class="line"><span class="number">2</span> C</div></pre></td></tr></table></figure></p>
<p>上面的for循环里，同时引用了两个变量，在Python里是很常见的，比如下面的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> x, y <span class="keyword">in</span> [(<span class="number">1</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">4</span>), (<span class="number">3</span>, <span class="number">9</span>)]:</div><div class="line"><span class="meta">... </span>    print(x, y)</div><div class="line">...</div><div class="line"><span class="number">1</span> <span class="number">1</span></div><div class="line"><span class="number">2</span> <span class="number">4</span></div><div class="line"><span class="number">3</span> <span class="number">9</span></div></pre></td></tr></table></figure></p>
<p><strong>小结</strong></p>
<p>任何可迭代对象都可以作用于for循环，包括我们自定义的数据类型，只要符合迭代条件，就可以使用for循环。</p>
<p><strong>列表生成式</strong></p>
<p>写列表生成式时，把要生成的元素x * x放到前面，后面跟for循环，就可以把list创建出来，十分有用，多写几次，很快就可以熟悉这种语法。<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="keyword">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</div></pre></td></tr></table></figure></p>
<p>for循环后面还可以加上if判断，这样我们就可以筛选出仅偶数的平方：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; [x * x for x in range(<span class="number">1</span>, <span class="number">11</span>) if x % <span class="number">2</span> == <span class="number">0</span>]</div><div class="line">[<span class="number">4</span>, <span class="number">16</span>, <span class="number">36</span>, <span class="number">64</span>, <span class="number">100</span>]</div></pre></td></tr></table></figure></p>
<p>还可以使用两层循环，可以生成全排列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[m + n <span class="keyword">for</span> m <span class="keyword">in</span> <span class="string">'ABC'</span> <span class="keyword">for</span> n <span class="keyword">in</span> <span class="string">'XYZ'</span>]</div><div class="line">[<span class="string">'AX'</span>, <span class="string">'AY'</span>, <span class="string">'AZ'</span>, <span class="string">'BX'</span>, <span class="string">'BY'</span>, <span class="string">'BZ'</span>, <span class="string">'CX'</span>, <span class="string">'CY'</span>, <span class="string">'CZ'</span>]</div></pre></td></tr></table></figure></p>
<p>运用列表生成式，可以写出非常简洁的代码。例如，列出当前目录下的所有文件和目录名，可以通过一行代码实现：<br><figure class="highlight moonscript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; <span class="keyword">import</span> <span class="built_in">os</span> # 导入<span class="built_in">os</span>模块，模块的概念后面讲到</div><div class="line">&gt;&gt;&gt; [d <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">os</span>.listdir(<span class="string">'.'</span>)] # <span class="built_in">os</span>.listdir可以列出文件和目录</div><div class="line">[<span class="string">'.emacs.d'</span>, <span class="string">'.ssh'</span>, <span class="string">'.Trash'</span>, <span class="string">'Adlm'</span>, <span class="string">'Applications'</span>, <span class="string">'Desktop'</span>, <span class="string">'Documents'</span>, <span class="string">'Downloads'</span>, <span class="string">'Library'</span>, <span class="string">'Movies'</span>, <span class="string">'Music'</span>, <span class="string">'Pictures'</span>, <span class="string">'Public'</span>, <span class="string">'VirtualBox VMs'</span>, <span class="string">'Workspace'</span>, <span class="string">'XCode'</span>]</div></pre></td></tr></table></figure></p>
<p>for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>d = &#123;<span class="string">'x'</span>: <span class="string">'A'</span>, <span class="string">'y'</span>: <span class="string">'B'</span>, <span class="string">'z'</span>: <span class="string">'C'</span> &#125;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> k, v <span class="keyword">in</span> d.items():</div><div class="line"><span class="meta">... </span>    print(k, <span class="string">'='</span>, v)</div><div class="line">...</div><div class="line">y = B</div><div class="line">x = A</div><div class="line">z = C</div></pre></td></tr></table></figure></p>
<p>因此，列表生成式也可以使用两个变量来生成list：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; d = &#123;<span class="string">'x'</span>: <span class="string">'A'</span>, <span class="string">'y'</span>: <span class="string">'B'</span>, <span class="string">'z'</span>: <span class="string">'C'</span> &#125;</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; [k + <span class="string">'='</span> + v for k, v in d.items()]</div><div class="line">[<span class="string">'y=B'</span>, <span class="string">'x=A'</span>, <span class="string">'z=C'</span>]</div></pre></td></tr></table></figure></p>
<p>最后把一个list中所有的字符串变成小写：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; L = [<span class="string">'Hello'</span>, <span class="string">'World'</span>, <span class="string">'IBM'</span>, <span class="string">'Apple'</span>]</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; [s.lower() for s in L]</div><div class="line">[<span class="string">'hello'</span>, <span class="string">'world'</span>, <span class="string">'ibm'</span>, <span class="string">'apple'</span>]</div></pre></td></tr></table></figure></p>
<p><strong>运用列表生成式，可以快速生成list，可以通过一个list推导出另一个list，而代码却十分简洁。</strong></p>
<h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。</p>
<p>所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。<strong>在Python中，这种一边循环一边计算的机制，称为生成器：generator。</strong><br>要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; L = [x * x for x in range(<span class="number">10</span>)]</div><div class="line">&gt;&gt;&gt; L</div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>, <span class="number">49</span>, <span class="number">64</span>, <span class="number">81</span>]</div><div class="line">&gt;&gt;&gt; g = (x * x for x in range(<span class="number">10</span>))</div><div class="line">&gt;&gt;&gt; g</div><div class="line">&lt;generator object &lt;genexpr&gt; at <span class="number">0x1022ef630</span>&gt;</div></pre></td></tr></table></figure></p>
<p><strong>创建L和g的区别仅在于最外层的[]和()，L是一个list，而g是一个generator。</strong></p>
<p>我们可以直接打印出list的每一个元素，但我们怎么打印出generator的每一个元素呢？</p>
<p>如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值：<br><strong>generator保存的是算法</strong>，每次调用next(g)，就计算出g的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。<br>我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，并且不需要关心StopIteration的错误。</p>
<p>generator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。</p>
<p>如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator<br>最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。</p>
<p><strong>小结</strong></p>
<p>generator是非常强大的工具，在Python中，可以简单地把列表生成式改成generator，也可以通过函数实现复杂逻辑的generator。</p>
<p>要理解generator的工作原理，它是在for循环的过程中不断计算出下一个元素，并在适当的条件结束for循环。对于函数改成的generator来说，遇到return语句或者执行到函数体最后一行语句，就是结束generator的指令，for循环随之结束。</p>
<p>请注意区分普通函数和generator函数，普通函数调用直接返回结果：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; r = abs(<span class="number">6</span>)</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; r</div><div class="line"><span class="number">6</span></div></pre></td></tr></table></figure></p>
<p>generator函数的“调用”实际返回一个generator对象：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; g = fib(<span class="number">6</span>)</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; g</div><div class="line">&lt;generator object fib at <span class="number">0x1022ef948</span>&gt;</div></pre></td></tr></table></figure>
<h2 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h2><p>我们已经知道，可以直接作用于for循环的数据类型有以下几种：</p>
<p>一类是集合数据类型，如list、tuple、dict、set、str等；</p>
<p>一类是generator，包括生成器和带yield的generator function。</p>
<p>这些可以直接作用于for循环的对象统称为可迭代对象：Iterable。</p>
<p>可以使用isinstance()判断一个对象是否是Iterable对象：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterable</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance([], Iterable)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(&#123;&#125;, Iterable)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(<span class="string">'abc'</span>, Iterable)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance((x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>)), Iterable)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(<span class="number">100</span>, Iterable)</div><div class="line"><span class="keyword">False</span></div></pre></td></tr></table></figure></p>
<p>而生成器不但可以作用于for循环，还可以被next()函数不断调用并返回下一个值，直到最后抛出StopIteration错误表示无法继续返回下一个值了。</p>
<p>可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。</p>
<p>可以使用isinstance()判断一个对象是否是Iterator对象：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterator</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance((x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>)), Iterator)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance([], Iterator)</div><div class="line"><span class="keyword">False</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(&#123;&#125;, Iterator)</div><div class="line"><span class="keyword">False</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(<span class="string">'abc'</span>, Iterator)</div><div class="line"><span class="keyword">False</span></div></pre></td></tr></table></figure></p>
<p>生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。</p>
<p>把list、dict、str等Iterable变成Iterator可以使用iter()函数：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; isinstance(<span class="name">iter</span>([]), Iterator)</div><div class="line">True</div><div class="line">&gt;&gt;&gt; isinstance(<span class="name">iter</span>('abc'), Iterator)</div><div class="line">True</div></pre></td></tr></table></figure></p>
<p>你可能会问，为什么list、dict、str等数据类型不是Iterator？</p>
<p>这是因为Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。</p>
<p>Iterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list是永远不可能存储全体自然数的。</p>
<p>小结</p>
<p>凡是可作用于for循环的对象都是Iterable类型；</p>
<p>凡是可作用于next()函数的对象都是Iterator类型，它们表示一个惰性计算的序列；</p>
<p>集合数据类型如list、dict、str等是Iterable但不是Iterator，不过可以通过iter()函数获得一个Iterator对象。</p>
<p>Python的for循环本质上就是通过不断调用next()函数实现的，例如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]:</div><div class="line">    <span class="keyword">pass</span></div><div class="line">实际上完全等价于：</div><div class="line"></div><div class="line"><span class="comment"># 首先获得Iterator对象:</span></div><div class="line">it = iter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</div><div class="line"><span class="comment"># 循环:</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="comment"># 获得下一个值:</span></div><div class="line">        x = next(it)</div><div class="line">    <span class="keyword">except</span> StopIteration:</div><div class="line">        <span class="comment"># 遇到StopIteration就退出循环</span></div><div class="line">        <span class="keyword">break</span></div></pre></td></tr></table></figure></p>
<h1 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h1><p>函数是Python内建支持的一种封装，我们通过把大段代码拆成函数，通过一层一层的函数调用，就可以把复杂任务分解成简单的任务，这种分解可以称之为面向过程的程序设计。函数就是面向过程的程序设计的基本单元。</p>
<p>而函数式编程（请注意多了一个“式”字）——Functional Programming，虽然也可以归结到面向过程的程序设计，但其思想更接近数学计算。</p>
<p>我们首先要搞明白计算机（Computer）和计算（Compute）的概念。</p>
<p>在计算机的层次上，CPU执行的是加减乘除的指令代码，以及各种条件判断和跳转指令，所以，汇编语言是最贴近计算机的语言。</p>
<p>而计算则指数学意义上的计算，越是抽象的计算，离计算机硬件越远。</p>
<p>对应到编程语言，就是越低级的语言，越贴近计算机，抽象程度低，执行效率高，比如C语言；越高级的语言，越贴近计算，抽象程度高，执行效率低，比如Lisp语言。</p>
<p>函数式编程就是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量，因此，任意一个函数，只要输入是确定的，输出就是确定的，这种纯函数我们称之为没有副作用。而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，同样的输入，可能得到不同的输出，因此，这种函数是有副作用的。</p>
<p>函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数！</p>
<p>Python对函数式编程提供部分支持。由于Python允许使用变量，因此，Python不是纯函数式编程语言。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.python.org/static/img/python-logo@2x.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000&quot;&gt;廖雪峰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是小白的Python新手教程，具有如下特点：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;中文，免费，零起点，完整示例，基于最新的Python 3版本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Python是一种计算机程序设计语言。你可能已经听说过很多种流行的编程语言，比如非常难学的C语言，非常流行的Java语言，适合初学者的Basic语言，适合网页编程的JavaScript语言等等。&lt;/p&gt;
&lt;p&gt;那Python是一种什么语言？&lt;/p&gt;
&lt;p&gt;首先，我们普及一下编程语言的基础知识。用任何编程语言来开发程序，都是为了让计算机干活，比如下载一个MP3，编写一个文档等等，而计算机干活的CPU只认识机器指令，所以，尽管不同的编程语言差异极大，最后都得“翻译”成CPU可以执行的机器指令。而不同的编程语言，干同一个活，编写的代码量，差距也很大。&lt;/p&gt;
&lt;p&gt;比如，完成同一个任务，C语言要写1000行代码，Java只需要写100行，而Python可能只要20行。&lt;/p&gt;
&lt;p&gt;所以Python是一种相当高级的语言。&lt;/p&gt;
&lt;p&gt;你也许会问，代码少还不好？代码少的代价是运行速度慢，C程序运行1秒钟，Java程序可能需要2秒，而Python程序可能就需要10秒。&lt;/p&gt;
&lt;p&gt;那是不是越低级的程序越难学，越高级的程序越简单？表面上来说，是的，但是，在非常高的抽象计算中，高级的Python程序设计也是非常难学的，所以，高级程序语言不等于简单。&lt;/p&gt;
&lt;p&gt;但是，对于初学者和完成普通任务，Python语言是非常简单易用的。连Google都在大规模使用Python，你就不用担心学了会没用。&lt;/p&gt;
&lt;p&gt;用Python可以做什么？可以做日常任务，比如自动备份你的MP3；可以做网站，很多著名的网站包括YouTube就是Python写的；可以做网络游戏的后台，很多在线游戏的后台都是Python开发的。总之就是能干很多很多事啦。&lt;/p&gt;
&lt;p&gt;Python当然也有不能干的事情，比如写操作系统，这个只能用C语言写；写手机应用，只能用Swift/Objective-C（针对iPhone）和Java（针对Android）；写3D游戏，最好用C或C++。&lt;/p&gt;
&lt;p&gt;如果你是小白用户，满足以下条件：&lt;/p&gt;
&lt;p&gt;会使用电脑，但从来没写过程序；&lt;br&gt;还记得初中数学学的方程式和一点点代数知识；&lt;br&gt;想从编程小白变成专业的软件架构师；&lt;br&gt;每天能抽出半个小时学习。&lt;br&gt;不要再犹豫了，这个教程就是为你准备的！&lt;/p&gt;
&lt;p&gt;准备好了吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.liaoxuefeng.com/files/attachments/00138676512923004999ceca5614eb2afc5c0efdd2e4640000/0&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Python" scheme="http://ipcreator.me/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Git教程</title>
    <link href="http://ipcreator.me/2017/02/19/Program/Concepts/learn-journey-of-git/"/>
    <id>http://ipcreator.me/2017/02/19/Program/Concepts/learn-journey-of-git/</id>
    <published>2017-02-19T06:09:06.000Z</published>
    <updated>2017-03-01T11:06:58.928Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://okkntqe2h.bkt.clouddn.com/git-workflow-release-cycle-2feature.png" alt=""></p>
<p>作者：<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="external">廖雪峰</a></p>
<p>史上最浅显易懂的Git教程！</p>
<p>为什么要编写这个教程？因为我在学习Git的过程中，买过书，也在网上Google了一堆Git相关的文章和教程，但令人失望的是，这些教程不是难得令人发指，就是简单得一笔带过，或者，只支离破碎地介绍Git的某几个命令，还有直接从Git手册粘贴帮助文档的，总之，初学者很难找到一个由浅入深，学完后能立刻上手的Git教程。</p>
<p>既然号称史上最浅显易懂的Git教程，那这个教程有什么让你怦然心动的特点呢？</p>
<p>首先，本教程绝对面向初学者，没有接触过版本控制概念的读者也可以轻松入门，不必担心起步难度；</p>
<p>其次，本教程实用性超强，边学边练，一点也不觉得枯燥。而且，你所学的Git命令是“充分且必要”的，掌握了这些东西，你就可以通过Git轻松地完成你的工作。</p>
<p>文字+图片还看不明白？有视频！！！</p>
<p>本教程只会让你成为Git用户，不会让你成为Git专家。很多Git命令只有那些专家才明白（事实上我也不明白，因为我不是Git专家），但我保证这些命令可能你一辈子都不会用到。既然Git是一个工具，就没必要把时间浪费在那些“高级”但几乎永远不会用到的命令上。一旦你真的非用不可了，到时候再自行Google或者请教专家也未迟。</p>
<p>如果你是一个开发人员，想用上这个世界上目前最先进的分布式版本控制系统，那么，赶快开始学习吧！</p>
 <a id="more"></a>
<p> 关于作者</p>
<p>廖雪峰，十年软件开发经验，业余产品经理，精通Java/Python/Ruby/Visual Basic/Objective C等，对开源框架有深入研究，著有《Spring 2.0核心技术与最佳实践》一书，多个业余开源项目托管在GitHub，欢迎微博交流：</p>
<p><img src="http://service.t.sina.com.cn/widget/qmd/1658384301/078cedea/2.png" alt=""></p>
<h2 id="读书笔记"><a href="#读书笔记" class="headerlink" title="读书笔记"></a>读书笔记</h2><p>集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。<br><img src="http://www.liaoxuefeng.com/files/attachments/001384860735706fd4c70aa2ce24b45a8ade85109b0222b000/0" alt=""></p>
<p>分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。<br><img src="http://www.liaoxuefeng.com/files/attachments/0013848607465969378d7e6d5e6452d8161cf472f835523000/0" alt=""></p>
<p>通过git init命令把这个目录变成Git可以管理的仓库：</p>
<blockquote>
<p>$ git init</p>
</blockquote>
<p>当前目录下多了一个.git的隐藏目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。</p>
<p><strong>所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。</strong></p>
<p>使用Windows的童鞋要特别注意：</p>
<p>千万不要使用Windows自带的记事本编辑任何文本文件。原因是Microsoft开发记事本的团队使用了一个非常弱智的行为来保存UTF-8编码的文件，他们自作聪明地在每个文件开头添加了0xefbbbf（十六进制）的字符，你会遇到很多不可思议的问题，比如，网页第一行可能会显示一个“?”，明明正确的程序一编译就报语法错误，等等，都是由记事本的弱智行为带来的。建议你下载Notepad++代替记事本，不但功能强大，而且免费！记得把Notepad++的默认编码设置为UTF-8 without BOM即可：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384907170801199e153159cc4a438bed8d255edf157a000/0" alt=""></p>
<p>用命令git add告诉Git，把文件添加到仓库：</p>
<blockquote>
<p>$ git add readme.txt</p>
</blockquote>
<p>执行上面的命令，没有任何显示，这就对了，<strong>Unix的哲学是“没有消息就是好消息”</strong>，说明添加成功。</p>
<p>用命令git commit告诉Git，把文件提交到仓库：</p>
<blockquote>
<p>$ git commit -m “wrote a readme file”</p>
</blockquote>
<p>为什么Git添加文件需要add，commit一共两步呢？因为commit可以一次提交很多文件，所以你可以多次add不同的文件，比如：</p>
<blockquote>
<p>$ git add file1.txt<br>$ git add file2.txt file3.txt<br>$ git commit -m “add 3 files.”</p>
</blockquote>
<p>git status命令可以让我们时刻掌握仓库当前的状态<br>git diff顾名思义就是查看difference</p>
<blockquote>
<p>$ git diff readme.txt</p>
</blockquote>
<p>每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为commit。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个commit恢复，然后继续工作</p>
<p>版本控制系统肯定有某个命令可以告诉我们历史记录，在Git中，我们用git log命令查看：如果嫌输出信息太多，看得眼花缭乱的，可以试试加上–pretty=oneline参数</p>
<blockquote>
<p>$ git log –pretty=oneline</p>
</blockquote>
<p>为什么commit id需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。</p>
<p>在Git中，用HEAD表示当前版本<br>Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384907584977fc9d4b96c99f4b5f8e448fbd8589d0b2000/0" alt=""><br>改为指向add distributed：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384907594057a873c79f14184b45a1a66b1509f90b7a000/0" alt=""><br>然后顺便把工作区的文件更新了。所以你让HEAD指向哪个版本号，你就把当前版本定位在哪。<br>Git提供了一个命令git reflog用来记录你的每一次命令：</p>
<p>Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。<br><img src="http://www.liaoxuefeng.com/files/attachments/001384907702917346729e9afbf4127b6dfbae9207af016000/0" alt=""></p>
<p>我们把文件往Git版本库里添加的时候，是分两步执行的：<br>第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；<br>第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。<br>因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。<br>你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001384907720458e56751df1c474485b697575073c40ae9000/0" alt=""><br>git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/0013849077337835a877df2d26742b88dd7f56a6ace3ecf000/0" alt=""></p>
<p>Git会告诉你，git checkout – file可以丢弃工作区的修改<br>就是让这个文件回到最近一次git commit或git add时的状态。<br>一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；<br>一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</p>
<blockquote>
<p>$ git checkout – readme.txt</p>
</blockquote>
<p>git checkout – file命令中的–很重要，没有–，就变成了“切换到另一个分支”的命令,git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。</p>
<p>用命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区：</p>
<blockquote>
<p>$ git reset HEAD readme.txt</p>
</blockquote>
<p>git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。</p>
<p>确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit：</p>
<blockquote>
<p>$ git rm test.txt<br>$ git commit -m “remove test.txt”</p>
</blockquote>
<p>在本地的learngit仓库下运行命令：</p>
<blockquote>
<p>$ git remote add origin git@github.com:michaelliao/learngit.git</p>
</blockquote>
<p>请千万注意，把上面的michaelliao替换成你自己的GitHub账户名，否则，你在本地关联的就是我的远程库，关联没有问题，但是你以后推送是推不上去的，因为你的SSH Key公钥不在我的账户列表中。</p>
<p>添加后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库。</p>
<p>下一步，就可以把本地库的所有内容推送到远程库上：</p>
<blockquote>
<p>$ git push -u origin master</p>
</blockquote>
<p>把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。</p>
<p>从现在起，只要本地作了提交，就可以通过命令：</p>
<blockquote>
<p>$ git push origin master</p>
</blockquote>
<p>登陆GitHub，创建一个新的仓库，名字叫gitskills：我们勾选Initialize this repository with a README，这样GitHub会自动为我们创建一个README.md文件。创建完毕后，可以看到README.md文件：现在，远程库已经准备好了，下一步是用命令git clone克隆一个本地库：</p>
<blockquote>
<p>$ git clone git@github.com:michaelliao/gitskills.git</p>
</blockquote>
<p>GitHub给出的地址不止一个，还可以用<a href="https://github.com/michaelliao/gitskills.git这样的地址。实际上，Git支持多种协议，默认的git://使用ssh，但也可以使用https等其他协议。" target="_blank" rel="external">https://github.com/michaelliao/gitskills.git这样的地址。实际上，Git支持多种协议，默认的git://使用ssh，但也可以使用https等其他协议。</a></p>
<p>使用https除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用ssh协议而只能用https。</p>
<p>每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。</p>
<p>一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点：每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长：<br><img src="http://www.liaoxuefeng.com/files/attachments/0013849087937492135fbf4bbd24dfcbc18349a8a59d36d000/0" alt=""></p>
<p>当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384908811773187a597e2d844eefb11f5cf5d56135ca000/0" alt=""></p>
<p>你看，Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！</p>
<p>不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变：<br><img src="http://www.liaoxuefeng.com/files/attachments/0013849088235627813efe7649b4f008900e5365bb72323000/0" alt=""></p>
<p>假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并：<br><img src="http://www.liaoxuefeng.com/files/attachments/00138490883510324231a837e5d4aee844d3e4692ba50f5000/0" alt=""></p>
<p>所以Git合并分支也很快！就改改指针，工作区内容也不变！</p>
<p>合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384908867187c83ca970bf0f46efa19badad99c40235000/0" alt=""></p>
<p>创建dev分支，然后切换到dev分支：</p>
<blockquote>
<p>$ git checkout -b dev</p>
</blockquote>
<p>git checkout命令加上-b参数表示创建并切换，相当于以下两条命令：</p>
<blockquote>
<p>$ git branch dev<br>$ git checkout dev</p>
</blockquote>
<p>用git branch命令查看当前分支：git branch命令会列出所有分支，当前分支前面会标一个*号。</p>
<blockquote>
<p>$ git branch</p>
</blockquote>
<p>dev分支的工作完成，我们就可以切换回master分支：</p>
<blockquote>
<p>$ git checkout master</p>
</blockquote>
<p>切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384908892295909f96758654469cad60dc50edfa9abd000/0" alt=""></p>
<p>我们把dev分支的工作成果合并到master分支上：git merge命令用于合并指定分支到当前分支。</p>
<blockquote>
<p>$ git merge dev</p>
</blockquote>
<p>合并完成后，就可以放心地删除dev分支了：</p>
<blockquote>
<p>$ git branch -d dev</p>
</blockquote>
<p>因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在master分支上工作效果是一样的，但过程更安全。</p>
<p>master分支和feature1分支各自都分别有新的提交，变成了这样：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384909115478645b93e2b5ae4dc78da049a0d1704a41000/0" alt=""></p>
<p>Git告诉我们，readme.txt文件存在冲突，必须手动解决冲突后再提交。git status也可以告诉我们冲突的文件：<br>Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容</p>
<p>修改后保存，再提交：</p>
<p>$ git add readme.txt<br>$ git commit -m “conflict fixed”<br>[master 59bc1cb] conflict fixed<br>现在，master分支和feature1分支变成了下图所示：<br><img src="http://www.liaoxuefeng.com/files/attachments/00138490913052149c4b2cd9702422aa387ac024943921b000/0" alt=""></p>
<p>用带参数的git log也可以看到分支的合并情况：<br>$ git log –graph –pretty=oneline –abbrev-commit</p>
<p>合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。<br>如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。</p>
<p>准备合并dev分支，请注意–no-ff参数，表示禁用Fast forward：</p>
<blockquote>
<p>$ git merge –no-ff -m “merge with no-ff” dev</p>
</blockquote>
<p>不使用Fast forward模式，merge后就像这样：<br><img src="http://www.liaoxuefeng.com/files/attachments/001384909222841acf964ec9e6a4629a35a7a30588281bb000/0" alt=""></p>
<p>分支策略</p>
<p>在实际开发中，我们应该按照几个基本原则进行分支管理：</p>
<p>首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活；</p>
<p>那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本；</p>
<p>你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。</p>
<p>所以，团队合作的分支看起来就像这样：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001384909239390d355eb07d9d64305b6322aaf4edac1e3000/0" alt=""></p>
<p>Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：</p>
<blockquote>
<p>$ git stash</p>
</blockquote>
<p>刚才的工作现场存到哪去了？用git stash list命令看看：</p>
<blockquote>
<p>$ git stash list</p>
</blockquote>
<p>一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除；<br>另一种方式是用git stash pop，恢复的同时把stash内容也删了：</p>
<blockquote>
<p>$ git stash pop</p>
</blockquote>
<p>你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令：</p>
<blockquote>
<p>$ git stash apply stash@{0}</p>
</blockquote>
<p>软件开发中，总有无穷无尽的新的功能要不断添加进来。</p>
<p>添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。</p>
<p>当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。</p>
<p>要查看远程库的信息，用git remote：或者，用git remote -v显示更详细的信息：</p>
<blockquote>
<p>$ git remote<br>$ git remote -v<br>origin  git@github.com:michaelliao/learngit.git (fetch)<br>origin  git@github.com:michaelliao/learngit.git (push)</p>
</blockquote>
<p>上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。</p>
<p>推送分支</p>
<p>推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上：</p>
<blockquote>
<p>$ git push origin master<br>如果要推送其他分支，比如dev，就改成：</p>
<p>$ git push origin dev</p>
</blockquote>
<p>master分支是主分支，因此要时刻与远程同步；<br>dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步；<br>bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug；<br>feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。</p>
<p>当你的小伙伴从远程库clone时，默认情况下，你的小伙伴只能看到本地的master分支。现在，你的小伙伴要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支：</p>
<blockquote>
<p>$ git checkout -b dev origin/dev<br>现在，他就可以在dev上继续修改，然后，时不时地把dev分支push到远程：</p>
</blockquote>
<p>你的小伙伴的最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送：</p>
<p>git pull也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接：</p>
<blockquote>
<p>$ git branch –set-upstream dev origin/dev<br>Branch dev set up to track remote branch dev from origin.</p>
</blockquote>
<p>再pull：$ git pull</p>
<p>多人协作的工作模式通常是这样：</p>
<p>首先，可以试图用git push origin branch-name推送自己的修改；<br>如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并；<br>如果合并有冲突，则解决冲突，并在本地提交；<br>没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功！<br>如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch –set-upstream branch-name origin/branch-name。</p>
<p><strong>tag就是一个让人容易记住的有意义的名字，它跟某个commit绑在一起。</strong></p>
<p>在Git中打标签非常简单，首先，切换到需要打标签的分支上：</p>
<p>$ git branch</p>
<p>然后，敲命令git tag <name>就可以打一个新标签：</name></p>
<p>$ git tag v1.0<br>可以用命令git tag查看所有标签：标签不是按时间顺序列出，而是按字母排序的。可以用git show <tagname>查看标签信息, 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字：还可以通过-s用私钥签名一个标签：签名采用PGP签名，因此，必须首先安装gpg（GnuPG），如果没有找到gpg，或者没有gpg密钥对，就会报错, 如果报错，请参考GnuPG帮助文档配置Key。用命令git show <tagname>可以看到PGP签名信息,用PGP签名的标签是不可伪造的，因为可以验证PGP签名。</tagname></tagname></p>
<p>$ git tag -a v0.1 -m “version 0.1 released” 3628164</p>
<p>$ git tag</p>
<p>默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？</p>
<p>方法是找到历史提交的commit id，然后打上就可以了：</p>
<p>$ git log –pretty=oneline –abbrev-commit</p>
<p>比方说要对add merge这次提交打标签，它对应的commit id是6224937，敲入命令：</p>
<p>$ git tag v0.9 6224937</p>
<p>如果标签打错了，也可以删除：</p>
<p>$ git tag -d v0.1</p>
<p>如果要推送某个标签到远程，使用命令git push origin <tagname>：</tagname></p>
<p>$ git push origin v1.0</p>
<p>一次性推送全部尚未推送到远程的本地标签：</p>
<p>$ git push origin –tags</p>
<p>如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除：</p>
<p>$ git tag -d v0.9</p>
<p>然后，从远程删除。删除命令也是push，但是格式如下：</p>
<p>$ git push origin :refs/tags/v0.9</p>
<p>如何参与一个开源项目呢？比如人气极高的bootstrap项目，这是一个非常强大的CSS框架，你可以访问它的项目主页<a href="https://github.com/twbs/bootstrap，点“Fork”就在自己的账号下克隆了一个bootstrap仓库，然后，从自己的账号下clone：" target="_blank" rel="external">https://github.com/twbs/bootstrap，点“Fork”就在自己的账号下克隆了一个bootstrap仓库，然后，从自己的账号下clone：</a></p>
<p>git clone git@github.com:michaelliao/bootstrap.git<br>一定要从自己的账号下clone仓库，这样你才能推送修改。如果从bootstrap的作者的仓库地址git@github.com:twbs/bootstrap.git克隆，因为没有权限，你将不能推送修改。</p>
<p>Bootstrap的官方仓库twbs/bootstrap、你在GitHub上克隆的仓库my/bootstrap，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样：</p>
<p><img src="http://www.liaoxuefeng.com/files/attachments/001384926554932eb5e65df912341c1a48045bc274ba4bf000/0" alt=""></p>
<p>如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送。</p>
<p>如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了。</p>
<p>在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。</p>
<p>忽略文件的原则是：</p>
<p>忽略操作系统自动生成的文件，比如缩略图等；<br>忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件；<br>忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。</p>
<p>检验.gitignore的标准是git status命令是不是说working directory clean。<br>如果你在资源管理器里新建一个.gitignore文件，它会非常弱智地提示你必须输入文件名，但是在文本编辑器里“保存”或者“另存为”就可以把文件保存为.gitignore了。</p>
<p>你想添加一个文件到Git，但发现添加不了，原因是这个文件被.gitignore忽略了：</p>
<p>$ git add App.class<br>The following paths are ignored by one of your .gitignore files:<br>App.class<br>Use -f if you really want to add them.<br>如果你确实想添加该文件，可以用-f强制添加到Git：</p>
<p>$ git add -f App.class<br>或者你发现，可能是.gitignore写得有问题，需要找出来到底哪个规则写错了，可以用git check-ignore命令检查：</p>
<blockquote>
<p>$ git check-ignore -v App.class<br>.gitignore:3:.class    App.class</p>
</blockquote>
<p>Git会告诉我们，.gitignore的第3行规则忽略了该文件，于是我们就可以知道应该修订哪个规则。</p>
<p>给Git配置好别名，就可以输入命令时偷个懒。我们鼓励偷懒。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>初始化一个Git仓库，使用git init命令。<br>添加文件到Git仓库，分两步：<br>第一步，使用命令git add <file>，注意，可反复多次使用，添加多个文件；<br>第二步，使用命令git commit，完成。</file></p>
<p>要随时掌握工作区的状态，使用git status命令。<br>如果git status告诉你有文件被修改过，用git diff可以查看修改内容。</p>
<p>HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset –hard commit_id。<br>穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。<br>要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。</p>
<p>每次修改，如果不add到暂存区，那就不会加入到commit中。</p>
<p>场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。<br>场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。<br>场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。</p>
<p>命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。</p>
<p>要关联一个远程库，使用命令git remote add origin git@server-name:path/repo-name.git；</p>
<p>关联后，使用命令git push -u origin master第一次推送master分支的所有内容；</p>
<p>此后，每次本地提交后，只要有必要，就可以使用命令git push origin master推送最新修改；</p>
<p>分布式版本系统的最大好处之一是在本地工作完全不需要考虑远程库的存在，也就是有没有联网都可以正常工作，而SVN在没有联网的时候是拒绝干活的！当有网络的时候，再把本地提交推送一下就完成了同步，真是太方便了！</p>
<p>要克隆一个仓库，首先必须知道仓库的地址，然后使用git clone命令克隆。</p>
<p>Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快。</p>
<p>Git鼓励大量使用分支：</p>
<ul>
<li>查看分支：git branch</li>
<li>创建分支：git branch <name></name></li>
<li>切换分支：git checkout <name></name></li>
<li>创建+切换分支：git checkout -b <name></name></li>
<li>合并某分支到当前分支：git merge <name></name></li>
<li>删除分支：git branch -d <name></name></li>
</ul>
<p>当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。<br>用git log –graph命令可以看到分支合并图。</p>
<p>Git分支十分强大，在团队开发中应该充分应用。</p>
<p>合并分支时，加上–no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。</p>
<p>修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；</p>
<p>当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场。</p>
<p>开发一个新feature，最好新建一个分支；</p>
<p>如果要丢弃一个没有被合并过的分支，可以通过git branch -D <name>强行删除。</name></p>
<p>查看远程库信息，使用git remote -v；</p>
<p>本地新建的分支如果不推送到远程，对其他人就是不可见的；</p>
<p>从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交；</p>
<p>在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致；</p>
<p>建立本地分支和远程分支的关联，使用git branch –set-upstream branch-name origin/branch-name；</p>
<p>从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。</p>
<p>命令git tag <name>用于新建一个标签，默认为HEAD，也可以指定一个commit id；</name></p>
<p>git tag -a <tagname> -m “blablabla…”可以指定标签信息；</tagname></p>
<p>git tag -s <tagname> -m “blablabla…”可以用PGP签名标签；</tagname></p>
<p>命令git tag可以查看所有标签。</p>
<p>命令git push origin <tagname>可以推送一个本地标签；<br>命令git push origin –tags可以推送全部未推送过的本地标签；<br>命令git tag -d <tagname>可以删除一个本地标签；<br>命令git push origin :refs/tags/<tagname>可以删除一个远程标签。</tagname></tagname></tagname></p>
<p>在GitHub上，可以任意Fork开源仓库；<br>自己拥有Fork后的仓库的读写权限；<br>可以推送pull request给官方仓库来贡献代码。</p>
<p>忽略某些文件时，需要编写.gitignore；<br>.gitignore文件本身要放到版本库里，并且可以对.gitignore做版本管理！</p>
<h2 id="配置别名"><a href="#配置别名" class="headerlink" title="配置别名"></a>配置别名</h2><p>如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。我们只需要敲一行命令，告诉Git，以后st就表示status：</p>
<blockquote>
<p>$ git config –global alias.st status</p>
</blockquote>
<p>当然还有别的命令可以简写，很多人都用co表示checkout，ci表示commit，br表示branch：</p>
<blockquote>
<p>$ git config –global alias.co checkout<br>$ git config –global alias.ci commit<br>$ git config –global alias.br branch</p>
</blockquote>
<p>–global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名：</p>
<p>$ git config –global alias.unstage ‘reset HEAD’</p>
<p>配置一个git last，让其显示最后一次提交信息：</p>
<p>$ git config –global alias.last ‘log -1’<br>这样，用git last就能显示最近一次的提交：</p>
<p>$ git last</p>
<p>甚至还有人丧心病狂地把lg配置成了：</p>
<p>git config –global alias.lg “log –color –graph –pretty=format:’%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit”</p>
<p>配置Git的时候，加上–global是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。</p>
<p>配置文件放哪了？每个仓库的Git配置文件都放在.git/config文件中：<br>而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中：</p>
<p>搭建Git服务器非常简单，通常10分钟即可完成；<br>要方便管理公钥，用Gitosis；<br>要像SVN那样变态地控制权限，用Gitolite。</p>
<p>Git虽然极其强大，命令繁多，但常用的就那么十来个，掌握好这十几个常用命令，你已经可以得心应手地使用Git了。</p>
<p>友情附赠国外网友制作的Git Cheat Sheet，建议打印出来备用：</p>
<p><a href="https://pan.baidu.com/s/1kU5OCOB#path=%252Fpub%252Fgit" target="_blank" rel="external">Git Cheat Sheet</a></p>
<h2 id="Practice-in-Action"><a href="#Practice-in-Action" class="headerlink" title="Practice in Action"></a>Practice in Action</h2><p>$ git init<br>Reinitialized existing Git repository in D:/IPCreatorBlog/themes/yilia/.git/</p>
<p>$ git remote add yilia git@github.com:ipcreator/hexo-theme-yilia.git</p>
<p>$ git push -u yilia master<br>Branch master set up to track remote branch master from yilia.<br>Everything up-to-date</p>
<p>$ git status<br>On branch master<br>Your branch is up-to-date with ‘yilia/master’.<br>Changes not staged for commit:<br>  (use “git add <file>…” to update what will be committed)<br>  (use “git checkout – <file>…” to discard changes in working directory)</file></file></p>
<pre><code>modified:   _config.yml
modified:   layout/_partial/after-footer.ejs
modified:   layout/_partial/footer.ejs
modified:   layout/_partial/left-col.ejs
modified:   source-src/css/article-main.scss
modified:   source-src/css/fonts/iconfont.svg
modified:   source-src/js/mobile.js
modified:   source/fonts/iconfont.dba24b.svg
</code></pre><p>Untracked files:<br>  (use “git add <file>…” to include in what will be committed)</file></p>
<pre><code>source/main.0d8e3c.css
source/main.0d8e3c.js
source/mobile.0b1d99.js
source/slider.fa3fc2.js
</code></pre><p>no changes added to commit (use “git add” and/or “git commit -a”)</p>
<p>$ git branch</p>
<ul>
<li>master</li>
</ul>
<p>$ git add _config.yml</p>
<p>$ git status<br>On branch master<br>Your branch is up-to-date with ‘yilia/master’.<br>Changes to be committed:<br>  (use “git reset HEAD <file>…” to unstage)</file></p>
<pre><code>modified:   _config.yml
</code></pre><p>Changes not staged for commit:<br>  (use “git add <file>…” to update what will be committed)<br>  (use “git checkout – <file>…” to discard changes in working directory)</file></file></p>
<pre><code>modified:   layout/_partial/after-footer.ejs
modified:   layout/_partial/footer.ejs
modified:   layout/_partial/left-col.ejs
modified:   source-src/css/article-main.scss
modified:   source-src/css/fonts/iconfont.svg
modified:   source-src/js/mobile.js
modified:   source/fonts/iconfont.dba24b.svg
</code></pre><p>Untracked files:<br>  (use “git add <file>…” to include in what will be committed)</file></p>
<pre><code>source/main.0d8e3c.css
source/main.0d8e3c.js
source/mobile.0b1d99.js
source/slider.fa3fc2.js
</code></pre><p>$ git add layout/_partial/after-footer.ejs<br>$ git add layout/_partial/footer.ejs<br>$ git add layout/_partial/left-col.ejs<br>$ git add source-src/css/article-main.scss<br>$ git add source-src/css/fonts/iconfont.svg<br>warning: LF will be replaced by CRLF in source-src/css/fonts/iconfont.svg.<br>The file will have its original line endings in your working directory.</p>
<p>$ git add  source-src/js/mobile.js<br>$ git add source/fonts/iconfont.dba24b.svg<br>warning: LF will be replaced by CRLF in source/fonts/iconfont.dba24b.svg.<br>The file will have its original line endings in your working directory.</p>
<p>$ git add  source/main.0d8e3c.css<br>$ git add source/main.0d8e3c.js<br>warning: LF will be replaced by CRLF in source/main.0d8e3c.js.<br>The file will have its original line endings in your working directory.</p>
<p>$ git add source/mobile.0b1d99.js<br>$ git add source/slider.fa3fc2.js<br>warning: LF will be replaced by CRLF in source/slider.fa3fc2.js.<br>The file will have its original line endings in your working directory.</p>
<p>$ git status<br>On branch master<br>Your branch is up-to-date with ‘yilia/master’.<br>Changes to be committed:<br>  (use “git reset HEAD <file>…” to unstage)</file></p>
<pre><code>modified:   _config.yml
modified:   layout/_partial/after-footer.ejs
modified:   layout/_partial/footer.ejs
modified:   layout/_partial/left-col.ejs
modified:   source-src/css/article-main.scss
modified:   source-src/js/mobile.js
new file:   source/main.0d8e3c.css
new file:   source/main.0d8e3c.js
new file:   source/mobile.0b1d99.js
new file:   source/slider.fa3fc2.js
</code></pre><p>$ git commit -m “first bak”<br>[master 8251377] first bak<br> 10 files changed, 111 insertions(+), 28 deletions(-)<br> create mode 100644 source/main.0d8e3c.css<br> create mode 100644 source/main.0d8e3c.js<br> create mode 100644 source/mobile.0b1d99.js<br> create mode 100644 source/slider.fa3fc2.js</p>
<p>$ git push -u yilia master<br>Counting objects: 18, done.<br>Delta compression using up to 8 threads.<br>Compressing objects: 100% (18/18), done.<br>Writing objects: 100% (18/18), 63.54 KiB | 0 bytes/s, done.<br>Total 18 (delta 10), reused 3 (delta 0)<br>remote: Resolving deltas: 100% (10/10), completed with 10 local objects.<br>Branch master set up to track remote branch master from yilia.<br>To github.com:ipcreator/hexo-theme-yilia.git<br>   8ff6b52..8251377  master -&gt; master</p>
<p>$ git status<br>On branch master<br>Your branch is up-to-date with ‘yilia/master’.<br>Changes not staged for commit:<br>  (use “git add <file>…” to update what will be committed)<br>  (use “git checkout – <file>…” to discard changes in working directory)</file></file></p>
<pre><code>modified:   _config.yml
</code></pre><p>no changes added to commit (use “git add” and/or “git commit -a”)</p>
<p>$ git diff HEAD – _config.yml<br>diff –git a/_config.yml b/_config.yml<br>index 4f8698a..e00540b 100644<br>— a/_config.yml<br>+++ b/_config.yml<br>@@ -79,11 +79,11 @@ duoshuo-key: ipcreator<br> style:</p>
<ul>
<li>#header: ‘#4d4d4d’</li>
<li>header: ‘#47A2E4’</li>
</ul>
<ul>
<li>header: ‘#4d4d4d’</li>
<li>#header: ‘#47A2E4’</li>
</ul>
<ul>
<li>#slider: ‘linear-gradient(200deg,#a0cfe4,#e8c37e)’</li>
<li>slider: ‘linear-gradient(200deg,#47A2E4,#47A2E4)’</li>
</ul>
<ul>
<li>slider: ‘linear-gradient(200deg,#a0cfe4,#e8c37e)’</li>
<li>#slider: ‘linear-gradient(200deg,#47A2E4,#47A2E4)’</li>
</ul>
<p>$ git add _config.yml</p>
<p>$ git commit -m “restore color”<br>[master 1acf4a2] restore color<br> 1 file changed, 4 insertions(+), 4 deletions(-)</p>
<p>$ git push -u yilia master<br>Counting objects: 3, done.<br>Delta compression using up to 8 threads.<br>Compressing objects: 100% (3/3), done.<br>Writing objects: 100% (3/3), 329 bytes | 0 bytes/s, done.<br>Total 3 (delta 2), reused 0 (delta 0)<br>remote: Resolving deltas: 100% (2/2), completed with 2 local objects.<br>Branch master set up to track remote branch master from yilia.<br>To github.com:ipcreator/hexo-theme-yilia.git<br>   2547415..1acf4a2  master -&gt; master</p>
<h2 id="Coding-net实践"><a href="#Coding-net实践" class="headerlink" title="Coding.net实践"></a>Coding.net实践</h2><p>一、先在coding.net新建一个仓库<br>二、使用gitclone方法新建一个本地库<br>三、将要上传的文件拷贝到本地库<br>四、先在本地add和commit<br>五、提交到远程库</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>git clone</div><div class="line"><span class="variable">$ </span>git status</div><div class="line"><span class="variable">$ </span>git add .</div><div class="line"><span class="variable">$ </span>git commit -m <span class="string">"First commit"</span></div><div class="line"><span class="variable">$ </span>git push</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/git-workflow-release-cycle-2feature.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&quot;&gt;廖雪峰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;史上最浅显易懂的Git教程！&lt;/p&gt;
&lt;p&gt;为什么要编写这个教程？因为我在学习Git的过程中，买过书，也在网上Google了一堆Git相关的文章和教程，但令人失望的是，这些教程不是难得令人发指，就是简单得一笔带过，或者，只支离破碎地介绍Git的某几个命令，还有直接从Git手册粘贴帮助文档的，总之，初学者很难找到一个由浅入深，学完后能立刻上手的Git教程。&lt;/p&gt;
&lt;p&gt;既然号称史上最浅显易懂的Git教程，那这个教程有什么让你怦然心动的特点呢？&lt;/p&gt;
&lt;p&gt;首先，本教程绝对面向初学者，没有接触过版本控制概念的读者也可以轻松入门，不必担心起步难度；&lt;/p&gt;
&lt;p&gt;其次，本教程实用性超强，边学边练，一点也不觉得枯燥。而且，你所学的Git命令是“充分且必要”的，掌握了这些东西，你就可以通过Git轻松地完成你的工作。&lt;/p&gt;
&lt;p&gt;文字+图片还看不明白？有视频！！！&lt;/p&gt;
&lt;p&gt;本教程只会让你成为Git用户，不会让你成为Git专家。很多Git命令只有那些专家才明白（事实上我也不明白，因为我不是Git专家），但我保证这些命令可能你一辈子都不会用到。既然Git是一个工具，就没必要把时间浪费在那些“高级”但几乎永远不会用到的命令上。一旦你真的非用不可了，到时候再自行Google或者请教专家也未迟。&lt;/p&gt;
&lt;p&gt;如果你是一个开发人员，想用上这个世界上目前最先进的分布式版本控制系统，那么，赶快开始学习吧！&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Git" scheme="http://ipcreator.me/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Scikit-learn入门指南</title>
    <link href="http://ipcreator.me/2017/02/18/Program/Resources/basic-knowledge-of-scikit-learn/"/>
    <id>http://ipcreator.me/2017/02/18/Program/Resources/basic-knowledge-of-scikit-learn/</id>
    <published>2017-02-18T05:04:06.000Z</published>
    <updated>2017-02-19T06:02:30.217Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201701/ZJMTak4Y8ch3Nwd0.html" target="_blank" rel="external">雷锋网 恒亮</a></p>
<p>对Python语言有所了解的科研人员可能都知道SciPy——一个开源的基于Python的科学计算工具包。基于SciPy，目前开发者们针对不同的应用领域已经发展出了为数众多的分支版本，它们被统一称为Scikits，即SciPy工具包的意思。而在这些分支版本中，最有名，也是专门面向机器学习的一个就是Scikit-learn。</p>
<p>Scikit-learn项目最早由数据科学家 David Cournapeau 在 2007 年发起，需要NumPy和SciPy等其他包的支持，是Python语言中专门针对机器学习应用而发展起来的一款开源框架。</p>
<p>和其他众多的开源项目一样，Scikit-learn目前主要由社区成员自发进行维护。可能是由于维护成本的限制，Scikit-learn相比其他项目要显得更为保守。这主要体现在两个方面：一是Scikit-learn从来不做除机器学习领域之外的其他扩展，二是Scikit-learn从来不采用未经广泛验证的算法。</p>
<p>本文将简单介绍Scikit-learn框架的六大功能，安装和运行Scikit-learn的大概步骤，同时为后续各更深入地学习Scikit-learn提供参考。原文来自infoworld网站的特约撰稿人Martin Heller，他曾在1986-2010年间做过长达20多年的数据库、通用软件和网页开发，具有丰富的开发经验。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/588354590d9b4.png?imageMogr2/format/jpg/quality/90" alt=""></p>
  <a id="more"></a>
<p>  Scikit-learn的六大功能</p>
<p>Scikit-learn的基本功能主要被分为六大部分：分类，回归，聚类，数据降维，模型选择和数据预处理。</p>
<p>分类是指识别给定对象的所属类别，属于监督学习的范畴，最常见的应用场景包括垃圾邮件检测和图像识别等。目前Scikit-learn已经实现的算法包括：支持向量机（SVM），最近邻，逻辑回归，随机森林，决策树以及多层感知器（MLP）神经网络等等。</p>
<p>需要指出的是，由于Scikit-learn本身不支持深度学习，也不支持GPU加速，因此这里对于MLP的实现并不适合于处理大规模问题。有相关需求的读者可以查看同样对Python有良好支持的Keras和Theano等框架。</p>
<p>回归是指预测与给定对象相关联的连续值属性，最常见的应用场景包括预测药物反应和预测股票价格等。目前Scikit-learn已经实现的算法包括：支持向量回归（SVR），脊回归，Lasso回归，弹性网络（Elastic Net），最小角回归（LARS ），贝叶斯回归，以及各种不同的鲁棒回归算法等。可以看到，这里实现的回归算法几乎涵盖了所有开发者的需求范围，而且更重要的是，Scikit-learn还针对每种算法都提供了简单明了的用例参考。</p>
<p>聚类是指自动识别具有相似属性的给定对象，并将其分组为集合，属于无监督学习的范畴，最常见的应用场景包括顾客细分和试验结果分组。目前Scikit-learn已经实现的算法包括：K-均值聚类，谱聚类，均值偏移，分层聚类，DBSCAN聚类等。</p>
<p>数据降维是指使用主成分分析（PCA）、非负矩阵分解（NMF）或特征选择等降维技术来减少要考虑的随机变量的个数，其主要应用场景包括可视化处理和效率提升。</p>
<p>模型选择是指对于给定参数和模型的比较、验证和选择，其主要目的是通过参数调整来提升精度。目前Scikit-learn实现的模块包括：格点搜索，交叉验证和各种针对预测误差评估的度量函数。</p>
<p>数据预处理是指数据的特征提取和归一化，是机器学习过程中的第一个也是最重要的一个环节。这里归一化是指将输入数据转换为具有零均值和单位权方差的新变量，但因为大多数时候都做不到精确等于零，因此会设置一个可接受的范围，一般都要求落在0-1之间。而特征提取是指将文本或图像数据转换为可用于机器学习的数字变量。</p>
<p>需要特别注意的是，这里的特征提取与上文在数据降维中提到的特征选择非常不同。特征选择是指通过去除不变、协变或其他统计上不重要的特征量来改进机器学习的一种方法。</p>
<p>总结来说，Scikit-learn实现了一整套用于数据降维，模型选择，特征提取和归一化的完整算法/模块，虽然缺少按步骤操作的参考教程，但Scikit-learn针对每个算法和模块都提供了丰富的参考样例和详细的说明文档。</p>
<p>安装和运行Scikit-learn</p>
<p>如前所述，Scikit-learn需要NumPy和SciPy等其他包的支持，因此在安装Scikit-learn之前需要提前安装一些支持包，具体列表和教程可以查看Scikit-learn的官方文档： <a href="http://scikit-learn.org/stable/install.html" target="_blank" rel="external">http://scikit-learn.org/stable/install.html</a> ，以下仅列出Python、NumPy和SciPy等三个必备包的安装说明。</p>
<p>Python：<a href="https://www.python.org/about/gettingstarted/" target="_blank" rel="external">https://www.python.org/about/gettingstarted/</a></p>
<p>NumPy：<a href="http://www.numpy.org/" target="_blank" rel="external">http://www.numpy.org/</a></p>
<p>SciPy：<a href="http://www.scipy.org/install.html" target="_blank" rel="external">http://www.scipy.org/install.html</a></p>
<p>假定已经完整安装了所有支持包，那么利用安装Scikit-learn只需要简单的一条简单的pip命令（也可以用conda命令，详见官方文档）：</p>
<p>$ sudo pip install -U scikit-learn</p>
<p>这里加上sudo是为了避免安装过程中出现一些权限问题，如果用户已经确保了管理员权限也可以省略。</p>
<p>当然，开发者也可以选择自己到GitHub开源平台上下载Scikit-learn的源代码，解压后在根目录键入make自行编译和连接可执行文件，效果是一样的。另外，为了确保测试方便，高级用户还可以选择安装针对Python的测试框架nose，安装方法详见其官方说明： <a href="http://nose.readthedocs.io/en/latest/" target="_blank" rel="external">http://nose.readthedocs.io/en/latest/</a>  。</p>
<p>通过Jupyter Notebook工具运行Scikit-learn样例的过程也很简单，用户只需要在官方给出的样例库： <a href="http://scikit-learn.org/stable/auto_examples/index.html#general-examples" target="_blank" rel="external">http://scikit-learn.org/stable/auto_examples/index.html#general-examples</a>  选择一个样例，然后在页面中下载其Python源码和IPython notebook文件，借着通过Jupyter Notebook工具运行就可以了。假如选择了交叉验证预测的样例，那么其运行情况的截图如下所示。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/58835330012c6.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>原作者在这里表示，Scikit-learn是他测试过的最简单易用的机器学习框架。他表示，Scikit-learn样例的运行结果和文档描述一模一样，API接口的设计合理且一致性高，而且几乎不存在“阻抗不匹配”的数据结构，使用这种功能完善且几乎没有Bug的开源框架进行机器学习研究，无疑是一件值得高兴的事。</p>
<p>更深入地学习Scikit-learn</p>
<p>如前所述，Scikit-learn针对每个算法和模块都提供了丰富的参考样例和详细的说明文档，据官方的统计大约有200多个。而且为了清晰明白，绝大多数样例都至少给出了一张由Matplotlib绘制的数据图表。这些都是官方提供的学习Scikit-learn框架最直接有效的学习材料。</p>
<p>针对科学数据处理的应用场景，官方还给出了一个更为详细和全面的参考教程：A tutorial on statistical-learning for scientific data processing，其中包括统计学习、监督学习、模型选择和无监督学习等若干部分，内容覆盖全面，讲解细致，并且使用了真实的数据、代码和图表。</p>
<p>另外，教程中还调用了与文本相关的样例，例如下图所示的四个不同SVM分类器的比较。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5883532f1329c.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>这里需要指出的是，虽然运行Scikit-learn官方给出的样例后通常都能得到一致的结果，但大多数情况下系统都会抛出警告信息。作者认为抛出警告信息的原因来自两个方面：一是苹果vecLib框架本身对Scikit-learn支持不好（作者用的是MacOS），二是样例中使用的Python版本可能是早期的版本，而实际运行中是最新的版本。例如下图中是使用Python 2.7.10版本抛出的警告信息，而Scikit-learn官方页面上并没有出现。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/58835330b6cf2.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>总体上来说，作为专门面向机器学习的Python开源框架，Scikit-learn可以在一定范围内为开发者提供非常好的帮助。它内部实现了各种各样成熟的算法，容易安装和使用，样例丰富，而且教程和文档也非常详细。</p>
<p>另一方面，Scikit-learn也有缺点。例如它不支持深度学习和强化学习，这在今天已经是应用非常广泛的技术，例如准确的图像分类和可靠的实时语音识别和语义理解等。此外，它也不支持图模型和序列预测，不支持Python之外的语言，不支持PyPy，也不支持GPU加速。</p>
<p>看到这里可能会有人担心Scikit-learn的性能表现，这里需要指出的是：如果不考虑多层神经网络的相关应用，Scikit-learn的性能表现是非常不错的。究其原因，一方面是因为其内部算法的实现十分高效，另一方面或许可以归功于Cython编译器：通过Cython在Scikit-learn框架内部生成C语言代码的运行方式，Scikit-learn消除了大部分的性能瓶颈。</p>
<p>应该明确的一点是：虽然概括地说Scikit-learn并不适合深度学习问题，但对于某些特殊场景而言，使用Scikit-learn仍然是明智的选择。例如要创建连接不同对象的预测函数时，或者在未标记的数据集中为了训练模型对不同的对象进行分类时，面对这些场景Scikit-learn只通过普通的旧机器学习模型就能很好地解决，而并不需要建立数十层的复杂神经网络。</p>
<p>就好像喜欢Scala语言的人会选择Spark ML，喜欢绘制图表和偶尔编写少量Python/R语言代码的人会选择微软Cortana和Azure一样，对于那些Python语言的死忠粉而言，Scikit-learn可能是各种机器学习库中的最好选择。雷锋网(公众号：雷锋网)雷锋网</p>
<p>来源：infoworld，雷锋网编译</p>
<p>雷锋网版权文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201701/ZJMTak4Y8ch3Nwd0.html&quot;&gt;雷锋网 恒亮&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;对Python语言有所了解的科研人员可能都知道SciPy——一个开源的基于Python的科学计算工具包。基于SciPy，目前开发者们针对不同的应用领域已经发展出了为数众多的分支版本，它们被统一称为Scikits，即SciPy工具包的意思。而在这些分支版本中，最有名，也是专门面向机器学习的一个就是Scikit-learn。&lt;/p&gt;
&lt;p&gt;Scikit-learn项目最早由数据科学家 David Cournapeau 在 2007 年发起，需要NumPy和SciPy等其他包的支持，是Python语言中专门针对机器学习应用而发展起来的一款开源框架。&lt;/p&gt;
&lt;p&gt;和其他众多的开源项目一样，Scikit-learn目前主要由社区成员自发进行维护。可能是由于维护成本的限制，Scikit-learn相比其他项目要显得更为保守。这主要体现在两个方面：一是Scikit-learn从来不做除机器学习领域之外的其他扩展，二是Scikit-learn从来不采用未经广泛验证的算法。&lt;/p&gt;
&lt;p&gt;本文将简单介绍Scikit-learn框架的六大功能，安装和运行Scikit-learn的大概步骤，同时为后续各更深入地学习Scikit-learn提供参考。原文来自infoworld网站的特约撰稿人Martin Heller，他曾在1986-2010年间做过长达20多年的数据库、通用软件和网页开发，具有丰富的开发经验。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201701/588354590d9b4.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Scikit" scheme="http://ipcreator.me/tags/Scikit/"/>
    
  </entry>
  
  <entry>
    <title>大数据/数据挖掘/推荐系统/机器学习相关资源</title>
    <link href="http://ipcreator.me/2017/02/18/Program/Resources/big-data-resources/"/>
    <id>http://ipcreator.me/2017/02/18/Program/Resources/big-data-resources/</id>
    <published>2017-02-18T04:23:06.000Z</published>
    <updated>2017-02-19T06:02:30.218Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://github.com/Flowerowl/Big_Data_Resources" target="_blank" rel="external">Zhe Yu/Flowerowl</a></p>
<p>大数据/数据挖掘/推荐系统/机器学习相关资源</p>
<p>Share my personal resources </p>

<h1><a id="user-content-书籍" class="anchor" href="#书籍" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>书籍</h1>

<ul><br><li><p>各种书~各种ppt~更新中~ <a href="https://pan.baidu.com/s/1c1Xp6Pa" target="_blank" rel="external">https://pan.baidu.com/s/1c1Xp6Pa</a></p></li><br><li><p>机器学习经典书籍小结 <a href="http://www.cnblogs.com/snake-hand/archive/2013/06/10/3131145.html" target="_blank" rel="external">http://www.cnblogs.com/snake-hand/archive/2013/06/10/3131145.html</a></p></li><br><li><p>机器学习&amp;深度学习经典资料汇总 <a href="http://www.thebigdata.cn/JiShuBoKe/13299.html" target="_blank" rel="external">http://www.thebigdata.cn/JiShuBoKe/13299.html</a></p></li><br></ul>

<a id="more"></a>
<h1><a id="user-content-视频" class="anchor" href="#视频" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>视频</h1>

<ul><br><li><p>浙大数据挖掘系列 <a href="http://v.youku.com/v_show/id_XNTgzNDYzMjg=.html?f=2740765" target="_blank" rel="external">http://v.youku.com/v_show/id_XNTgzNDYzMjg=.html?f=2740765</a></p></li><br><li><p>用Python做科学计算 <a href="http://www.tudou.com/listplay/fLDkg5e1pYM.html" target="_blank" rel="external">http://www.tudou.com/listplay/fLDkg5e1pYM.html</a></p></li><br><li><p>R语言视频 <a href="http://pan.baidu.com/s/1koSpZ" target="_blank" rel="external">http://pan.baidu.com/s/1koSpZ</a></p></li><br><li><p>Hadoop视频 <a href="http://pan.baidu.com/s/1b1xYd" target="_blank" rel="external">http://pan.baidu.com/s/1b1xYd</a></p></li><br><li><p>42区 . 技术 . 创业 . 第二讲 <a href="http://v.youku.com/v_show/id_XMzAyMDYxODUy.html" target="_blank" rel="external">http://v.youku.com/v_show/id_XMzAyMDYxODUy.html</a></p></li><br><li><p>加州理工学院公开课：机器学习与数据挖掘 <a href="http://v.163.com/special/opencourse/learningfromdata.html" target="_blank" rel="external">http://v.163.com/special/opencourse/learningfromdata.html</a></p></li><br><li><p>William Huang教授–BI和数据挖掘技术 <a href="https://www.youtube.com/watch?v=gPm8SOJ1Nao" target="_blank" rel="external">https://www.youtube.com/watch?v=gPm8SOJ1Nao</a></p></li><br><li><p>Jingyuan Wang王静远-北航-机器学习工具在城市数据分析中的应用<a href="https://www.youtube.com/watch?v=H2_BATE8uok" target="_blank" rel="external">https://www.youtube.com/watch?v=H2_BATE8uok</a></p></li><br><li><p>Tensor Flow 介紹 (1/2)<a href="https://www.youtube.com/watch?v=jA4Bh-xj_mE" target="_blank" rel="external">https://www.youtube.com/watch?v=jA4Bh-xj_mE</a></p></li><br><li><p>Tensor Flow 介紹 (2/2)<a href="https://www.youtube.com/watch?v=YUCsOgkFqpk" target="_blank" rel="external">https://www.youtube.com/watch?v=YUCsOgkFqpk</a></p></li><br></ul>

<h1><a id="user-content-课程" class="anchor" href="#课程" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>课程</h1>

<h3><a id="user-content-机器学习" class="anchor" href="#机器学习" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>机器学习</h3>

<ul><br><li><p>Machine Learning Stanford University <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">https://www.coursera.org/learn/machine-learning</a></p></li><br><li><p>機器學習基石 (Machine Learning Foundations) National Taiwan University <a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">https://www.coursera.org/course/ntumlone</a></p></li><br></ul>

<h1><a id="user-content-会议" class="anchor" href="#会议" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>会议</h1>

<h3><a id="user-content-数据挖掘" class="anchor" href="#数据挖掘" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据挖掘</h3>

<ul><br><li><p>ACM SigKDD <a href="http://www.kdd.org" target="_blank" rel="external">http://www.kdd.org</a></p></li><br><li><p>ICDM <a href="http://icdm2015.stonybrook.edu/" target="_blank" rel="external">http://icdm2015.stonybrook.edu/</a></p></li><br><li><p>SIAM <a href="http://www.siam.org/" target="_blank" rel="external">http://www.siam.org/</a></p></li><br></ul>

<h1><a id="user-content-qq群" class="anchor" href="#qq群" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>QQ群</h1>

<ul><br><li><p>机器学习&amp;模式识别 246159753</p></li><br><li><p>数据挖掘机器学习 236347059</p></li><br><li><p>推荐系统 274750470</p></li><br></ul>

<h1><a id="user-content-github" class="anchor" href="#github" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Github</h1>

<h3><a id="user-content-推荐系统" class="anchor" href="#推荐系统" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>推荐系统</h3>

<ul><br><li><p>推荐系统开源软件列表汇总和评点 <a href="http://in.sdo.com/?p=1707" target="_blank" rel="external">http://in.sdo.com/?p=1707</a></p></li><br><li><p>Mrec(Python) <a href="https://github.com/mendeley/mrec" target="_blank" rel="external">https://github.com/mendeley/mrec</a></p></li><br><li><p>Crab(Python) <a href="https://github.com/muricoca/crab" target="_blank" rel="external">https://github.com/muricoca/crab</a></p></li><br><li><p>Python-recsys(Python) <a href="https://github.com/ocelma/python-recsys" target="_blank" rel="external">https://github.com/ocelma/python-recsys</a></p></li><br><li><p>CofiRank(C++) <a href="https://github.com/markusweimer/cofirank" target="_blank" rel="external">https://github.com/markusweimer/cofirank</a></p></li><br><li><p>GraphLab(C++) <a href="https://github.com/graphlab-code/graphlab" target="_blank" rel="external">https://github.com/graphlab-code/graphlab</a></p></li><br><li><p>EasyRec(Java) <a href="https://github.com/hernad/easyrec" target="_blank" rel="external">https://github.com/hernad/easyrec</a></p></li><br><li><p>Lenskit(Java) <a href="https://github.com/grouplens/lenskit" target="_blank" rel="external">https://github.com/grouplens/lenskit</a></p></li><br><li><p>Mahout(Java) <a href="https://github.com/apache/mahout" target="_blank" rel="external">https://github.com/apache/mahout</a></p></li><br><li><p>Recommendable(Ruby) <a href="https://github.com/davidcelis/recommendable" target="_blank" rel="external">https://github.com/davidcelis/recommendable</a></p></li><br></ul>

<h3><a id="user-content-库" class="anchor" href="#库" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>库</h3>

<ul><br><li><p>NLTK  <a href="https://github.com/nltk/nltk" target="_blank" rel="external">https://github.com/nltk/nltk</a></p></li><br><li><p>Pattern <a href="https://github.com/clips/pattern" target="_blank" rel="external">https://github.com/clips/pattern</a></p></li><br><li><p>Pyrallel <a href="https://github.com/pydata/pyrallel" target="_blank" rel="external">https://github.com/pydata/pyrallel</a></p></li><br><li><p>Theano <a href="https://github.com/Theano/Theano" target="_blank" rel="external">https://github.com/Theano/Theano</a></p></li><br><li><p>Pylearn2 <a href="https://github.com/lisa-lab/pylearn2" target="_blank" rel="external">https://github.com/lisa-lab/pylearn2</a></p></li><br><li><p>TextBlob <a href="https://github.com/sloria/TextBlob" target="_blank" rel="external">https://github.com/sloria/TextBlob</a></p></li><br><li><p>MBSP <a href="https://github.com/clips/MBSP" target="_blank" rel="external">https://github.com/clips/MBSP</a></p></li><br><li><p>Gensim <a href="https://github.com/piskvorky/gensim" target="_blank" rel="external">https://github.com/piskvorky/gensim</a></p></li><br><li><p>Langid.py <a href="https://github.com/saffsd/langid.py" target="_blank" rel="external">https://github.com/saffsd/langid.py</a></p></li><br><li><p>Jieba <a href="https://github.com/fxsjy/jieba" target="_blank" rel="external">https://github.com/fxsjy/jieba</a></p></li><br><li><p>xTAS <a href="https://github.com/NLeSC/xtas" target="_blank" rel="external">https://github.com/NLeSC/xtas</a></p></li><br><li><p>NumPy <a href="https://github.com/numpy/numpy" target="_blank" rel="external">https://github.com/numpy/numpy</a></p></li><br><li><p>SciPy <a href="https://github.com/scipy/scipy" target="_blank" rel="external">https://github.com/scipy/scipy</a></p></li><br><li><p>Matplotlib <a href="https://github.com/matplotlib/matplotlib" target="_blank" rel="external">https://github.com/matplotlib/matplotlib</a></p></li><br><li><p>scikit-learn <a href="https://github.com/scikit-learn/scikit-learn" target="_blank" rel="external">https://github.com/scikit-learn/scikit-learn</a></p></li><br><li><p>Pandas <a href="https://github.com/pydata/pandas" target="_blank" rel="external">https://github.com/pydata/pandas</a></p></li><br><li><p>MDP <a href="http://mdp-toolkit.sourceforge.net/" target="_blank" rel="external">http://mdp-toolkit.sourceforge.net/</a></p></li><br><li><p>PyBrain <a href="https://github.com/pybrain/pybrain" target="_blank" rel="external">https://github.com/pybrain/pybrain</a></p></li><br><li><p>PyML <a href="http://pyml.sourceforge.net/" target="_blank" rel="external">http://pyml.sourceforge.net/</a></p></li><br><li><p>Milk <a href="https://github.com/luispedro/milk" target="_blank" rel="external">https://github.com/luispedro/milk</a></p></li><br><li><p>PyMVPA <a href="https://github.com/PyMVPA/PyMVPA" target="_blank" rel="external">https://github.com/PyMVPA/PyMVPA</a></p></li><br><li><p>TensorFlow <a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">https://github.com/tensorflow/tensorflow</a></p></li><br></ul>

<h1><a id="user-content-博客" class="anchor" href="#博客" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>博客</h1>

<ul><br><li><p>周涛 <a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=3075" target="_blank" rel="external">http://blog.sciencenet.cn/home.php?mod=space&amp;uid=3075</a></p></li><br><li><p>Greg Linden <a href="http://glinden.blogspot.com/" target="_blank" rel="external">http://glinden.blogspot.com/</a> </p></li><br><li><p>Marcel Caraciolo   <a href="http://aimotion.blogspot.com/" target="_blank" rel="external">http://aimotion.blogspot.com/</a></p></li><br><li><p>RsysChina       <a href="http://weibo.com/p/1005051686952981" target="_blank" rel="external">http://weibo.com/p/1005051686952981</a></p></li><br><li><p>推荐系统人人小站  <a href="http://zhan.renren.com/recommendersystem" target="_blank" rel="external">http://zhan.renren.com/recommendersystem</a></p></li><br><li><p>阿稳    <a href="http://www.wentrue.net" target="_blank" rel="external">http://www.wentrue.net</a></p></li><br><li><p>梁斌    <a href="http://weibo.com/pennyliang" target="_blank" rel="external">http://weibo.com/pennyliang</a></p></li><br><li><p>刁瑞    <a href="http://diaorui.net" target="_blank" rel="external">http://diaorui.net</a></p></li><br><li><p>guwendong <a href="http://www.guwendong.com" target="_blank" rel="external">http://www.guwendong.com</a></p></li><br><li><p>xlvector <a href="http://xlvector.net" target="_blank" rel="external">http://xlvector.net</a></p></li><br><li><p>懒惰啊我 <a href="http://www.cnblogs.com/flclain/" target="_blank" rel="external">http://www.cnblogs.com/flclain/</a></p></li><br><li><p>free mind <a href="http://blog.pluskid.org/" target="_blank" rel="external">http://blog.pluskid.org/</a></p></li><br><li><p>lovebingkuai  <a href="http://lovebingkuai.diandian.com/" target="_blank" rel="external">http://lovebingkuai.diandian.com/</a></p></li><br><li><p>LeftNotEasy <a href="http://www.cnblogs.com/LeftNotEasy" target="_blank" rel="external">http://www.cnblogs.com/LeftNotEasy</a></p></li><br><li><p>LSRS 2013 <a href="http://graphlab.org/lsrs2013/program/" target="_blank" rel="external">http://graphlab.org/lsrs2013/program/</a> </p></li><br><li><p>Google小组 <a href="https://groups.google.com/forum/#!forum/resys" target="_blank" rel="external">https://groups.google.com/forum/#!forum/resys</a></p></li><br><li><p>Journal of Machine Learning Research <a href="http://jmlr.org/" target="_blank" rel="external">http://jmlr.org/</a></p></li><br><li><p>在线的机器学习社区 <a href="http://www.52ml.net/16336.html" target="_blank" rel="external">http://www.52ml.net/16336.html</a></p></li><br><li><p>清华大学信息检索组 <a href="http://www.thuir.cn" target="_blank" rel="external">http://www.thuir.cn</a></p></li><br><li><p>我爱自然语言处理 <a href="http://www.52nlp.cn/" target="_blank" rel="external">http://www.52nlp.cn/</a></p></li><br><li><p>数据挖掘与数据分析<a href="http://spss-market.r.blog.163.com/" target="_blank" rel="external">http://spss-market.r.blog.163.com/</a></p></li><br></ul>

<h1><a id="user-content-文章" class="anchor" href="#文章" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>文章</h1>

<ul><br><li><p>心中永远的正能量  <a href="http://blog.csdn.net/yunlong34574" target="_blank" rel="external">http://blog.csdn.net/yunlong34574</a></p></li><br><li><p>机器学习最佳入门学习资料汇总 <a href="http://article.yeeyan.org/view/22139/410514" target="_blank" rel="external">http://article.yeeyan.org/view/22139/410514</a></p></li><br><li><p>Books for Machine Learning with R <a href="http://www.52ml.net/16312.html" target="_blank" rel="external">http://www.52ml.net/16312.html</a></p></li><br><li><p>是什么阻碍了你的机器学习目标？ <a href="http://www.52ml.net/16436.htm" target="_blank" rel="external">http://www.52ml.net/16436.htm</a></p></li><br><li><p>推荐系统初探 <a href="http://yongfeng.me/attach/rs-survey-zhang-slices.pdf" target="_blank" rel="external">http://yongfeng.me/attach/rs-survey-zhang-slices.pdf</a></p></li><br><li><p>推荐系统中协同过滤算法若干问题的研究 <a href="http://pan.baidu.com/s/1bnjDBYZ" target="_blank" rel="external">http://pan.baidu.com/s/1bnjDBYZ</a></p></li><br><li><p>Netflix 推荐系统：第一部分 <a href="http://blog.csdn.net/bornhe/article/details/8222450" target="_blank" rel="external">http://blog.csdn.net/bornhe/article/details/8222450</a></p></li><br><li><p>Netflix 推荐系统：第二部分 <a href="http://blog.csdn.net/bornhe/article/details/8222497" target="_blank" rel="external">http://blog.csdn.net/bornhe/article/details/8222497</a></p></li><br><li><p>探索推荐引擎内部的秘密 <a href="http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html</a></p></li><br><li><p>推荐系统resys小组线下活动见闻2009-08-22   <a href="http://www.tuicool.com/articles/vUvQVn" target="_blank" rel="external">http://www.tuicool.com/articles/vUvQVn</a></p></li><br><li><p>Recommendation Engines Seminar Paper, Thomas Hess, 2009: 推荐引擎的总结性文章 <a href="http://www.slideshare.net/antiraum/recommender-engines-seminar-paper" target="_blank" rel="external">http://www.slideshare.net/antiraum/recommender-engines-seminar-paper</a></p></li><br><li><p>Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions, Adomavicius, G.; Tuzhilin, A., 2005  <a href="http://dl.acm.org/citation.cfm?id=1070751" target="_blank" rel="external">http://dl.acm.org/citation.cfm?id=1070751</a></p></li><br><li><p>A Taxonomy of RecommenderAgents on the Internet, Montaner, M.; Lopez, B.; de la Rosa, J. L., 2003 <a href="http://www.springerlink.com/index/KK844421T5466K35.pdf" target="_blank" rel="external">http://www.springerlink.com/index/KK844421T5466K35.pdf</a></p></li><br><li><p>A Course in Machine Learning <a href="http://ciml.info/" target="_blank" rel="external">http://ciml.info/</a></p></li><br><li><p>基于mahout构建社会化推荐引擎  <a href="http://www.doc88.com/p-745821989892.html" target="_blank" rel="external">http://www.doc88.com/p-745821989892.html</a></p></li><br><li><p>个性化推荐技术漫谈 <a href="http://blog.csdn.net/java060515/archive/2007/04/19/1570243.aspx" target="_blank" rel="external">http://blog.csdn.net/java060515/archive/2007/04/19/1570243.aspx</a></p></li><br><li><p>Design of Recommender System <a href="http://www.slideshare.net/rashmi/design-of-recommender-systems" target="_blank" rel="external">http://www.slideshare.net/rashmi/design-of-recommender-systems</a></p></li><br><li><p>How to build a recommender system <a href="http://www.slideshare.net/blueace/how-to-build-a-recommender-system-presentation" target="_blank" rel="external">http://www.slideshare.net/blueace/how-to-build-a-recommender-system-presentation</a></p></li><br><li><p>推荐系统架构小结  <a href="http://blog.csdn.net/idonot/article/details/7996733" target="_blank" rel="external">http://blog.csdn.net/idonot/article/details/7996733</a></p></li><br><li><p>System Architectures for Personalization and Recommendation <a href="http://techblog.netflix.com/2013/03/system-architectures-for.html" target="_blank" rel="external">http://techblog.netflix.com/2013/03/system-architectures-for.html</a></p></li><br><li><p>The Netflix Tech Blog <a href="http://techblog.netflix.com/" target="_blank" rel="external">http://techblog.netflix.com/</a></p></li><br><li><p>百分点推荐引擎——从需求到架构<a href="http://www.infoq.com/cn/articles/baifendian-recommendation-engine" target="_blank" rel="external">http://www.infoq.com/cn/articles/baifendian-recommendation-engine</a></p></li><br><li><p>推荐系统 在InfoQ上的内容  <a href="http://www.infoq.com/cn/recommend" target="_blank" rel="external">http://www.infoq.com/cn/recommend</a></p></li><br><li><p>推荐系统实时化的实践和思考 <a href="http://www.infoq.com/cn/presentations/recommended-system-real-time-practice-thinking" target="_blank" rel="external">http://www.infoq.com/cn/presentations/recommended-system-real-time-practice-thinking</a></p></li><br><li><p>质量保证的推荐实践  <a href="http://www.infoq.com/cn/news/2013/10/testing-practice/" target="_blank" rel="external">http://www.infoq.com/cn/news/2013/10/testing-practice/</a> </p></li><br><li><p>推荐系统的工程挑战  <a href="http://www.infoq.com/cn/presentations/Recommend-system-engineering" target="_blank" rel="external">http://www.infoq.com/cn/presentations/Recommend-system-engineering</a></p></li><br><li><p>社会化推荐在人人网的应用  <a href="http://www.infoq.com/cn/articles/zyy-social-recommendation-in-renren/" target="_blank" rel="external">http://www.infoq.com/cn/articles/zyy-social-recommendation-in-renren/</a></p></li><br><li><p>利用20%时间开发推荐引擎  <a href="http://www.infoq.com/cn/presentations/twenty-percent-time-to-develop-recommendation-engine" target="_blank" rel="external">http://www.infoq.com/cn/presentations/twenty-percent-time-to-develop-recommendation-engine</a></p></li><br><li><p>使用Hadoop和 Mahout实现推荐引擎 <a href="http://www.jdon.com/44747" target="_blank" rel="external">http://www.jdon.com/44747</a></p></li><br><li><p>SVD 简介 <a href="http://www.cnblogs.com/FengYan/archive/2012/05/06/2480664.html" target="_blank" rel="external">http://www.cnblogs.com/FengYan/archive/2012/05/06/2480664.html</a></p></li><br><li><p>Netflix推荐系统：从评分预测到消费者法则 <a href="http://blog.csdn.net/lzt1983/article/details/7696578" target="_blank" rel="external">http://blog.csdn.net/lzt1983/article/details/7696578</a></p></li><br><li><p>关于数据挖掘学习的讨论<a href="https://www.zhihu.com/question/20751219" target="_blank" rel="external">https://www.zhihu.com/question/20751219</a></p></li><br></ul>

<h1><a id="user-content-论文" class="anchor" href="#论文" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>论文</h1>

<p>《推荐系统实战》引用</p>

<ul><br><li><p><a href="http://en.wikipedia.org/wiki/Information_overload" target="_blank" rel="external">P1</a></p></li><br><li><p><a href="http://www.readwriteweb.com/archives/recommender_systems.php" target="_blank" rel="external">A Guide to Recommender System P4</a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Cross-selling" target="_blank" rel="external">Cross Selling P6</a></p></li><br><li><p><a href="http://stanford2009.wikispaces.com/" target="_blank" rel="external">课程：Data Mining and E-Business: The Social Data Revolution P7)</a></p></li><br><li><p><a href="http://thesearchstrategy.com/ebooks/an%20introduction%20to%20search%20engines%20and%20web%20navigation.pdf" target="_blank" rel="external">An Introduction to Search Engines and Web Navigation p7</a><br>　　</p></li><br><li><p><a href="http://www.netflixprize.com/" target="_blank" rel="external">p8</a></p></li><br><li><p><a href="http://cdn-0.nflximg.com/us/pdf/Consumer_Press_Kit.pdf" target="_blank" rel="external">p9</a></p></li><br><li><p><a href="http://stuyresearch.googlecode.com/hg-history/c5aa9d65d48c787fd72dcd0ba3016938312102bd/blake/resources/p293-davidson.pdf" target="_blank" rel="external">(The Youtube video recommendation system) p9</a><br>　　 </p></li><br><li><p><a href="http://www.slideshare.net/plamere/music-recommendation-and-discovery" target="_blank" rel="external">(PPT: Music Recommendation and Discovery) p12</a></p></li><br><li><p><a href="http://www.facebook.com/instantpersonalization/" target="_blank" rel="external">P13</a><br>　　 </p></li><br><li><p><a href="http://about.digg.com/blog/digg-recommendation-engine-updates" target="_blank" rel="external">(Digg Recommendation Engine Updates) P16</a></p></li><br><li><p><a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36955.pdf" target="_blank" rel="external">(The Learning Behind Gmail Priority Inbox)p17</a><br>　　 </p></li><br><li><p><a href="http://www.grouplens.org/papers/pdf/mcnee-chi06-acc.pdf" target="_blank" rel="external">(Accurate is not always good: How Accuracy Metrics have hurt Recommender Systems) P20</a></p></li><br><li><p><a href="http://www-users.cs.umn.edu/%7Emcnee/mcnee-cscw2006.pdf" target="_blank" rel="external">(Don’t Look Stupid: Avoiding Pitfalls when Recommending Research Papers)P23</a><br>　　  </p></li><br><li><p><a href="http://www.sigkdd.org/explorations/issues/9-2-2007-12/7-Netflix-2.pdf" target="_blank" rel="external">(Major componets of the gravity recommender system) P25</a></p></li><br><li><p><a href="http://cacm.acm.org/blogs/blog-cacm/22925-what-is-a-good-recommendation-algorithm/fulltext" target="_blank" rel="external">(What is a Good Recomendation Algorithm?) P26</a></p></li><br><li><p><a href="http://research.microsoft.com/pubs/115396/evaluationmetrics.tr.pdf" target="_blank" rel="external">(Evaluation Recommendation Systems) P27</a><br>　　  </p></li><br><li><a href="http://mtg.upf.edu/static/media/PhD_ocelma.pdf" target="_blank" rel="external">(Music Recommendation and Discovery in the Long Tail) P29</a><br>　　 </li><br><li><p><a href="http://ir.ii.uam.es/divers2011/" target="_blank" rel="external">(Internation Workshop on Novelty and Diversity in Recommender Systems) p29</a></p></li><br><li><p><a href="http://www.cs.ucl.ac.uk/fileadmin/UCL-CS/research/Research_Notes/RN_11_21.pdf" target="_blank" rel="external">(Auralist: Introducing Serendipity into Music Recommendation ) P30</a><br>　　 </p></li><br><li><p><a href="http://www.springerlink.com/content/978-3-540-78196-7/#section=239197&amp;page=1&amp;locus=21" target="_blank" rel="external">(Metrics for evaluating the serendipity of recommendation lists) P30</a></p></li><br><li><p><a href="http://dare.uva.nl/document/131544" target="_blank" rel="external">(The effects of transparency on trust in and acceptance of a content-based art recommender) P31</a><br>　　 </p></li><br><li><p><a href="http://brettb.net/project/papers/2007%20Trust-aware%20recommender%20systems.pdf" target="_blank" rel="external">(Trust-aware recommender systems) P31</a></p></li><br><li><p><a href="http://recsys.acm.org/2011/pdfs/RobustTutorial.pdf" target="_blank" rel="external">(Tutorial on robutness of recommender system) P32</a></p></li><br><li><p><a href="http://youtube-global.blogspot.com/2009/09/five-stars-dominate-ratings.html" target="_blank" rel="external">(Five Stars Dominate Ratings) P37 </a></p></li><br><li><p><a href="http://www.informatik.uni-freiburg.de/%7Ecziegler/BX/" target="_blank" rel="external">(Book-Crossing Dataset) P38 </a></p></li><br><li><p><a href="http://www.dtic.upf.edu/%7Eocelma/MusicRecommendationDataset/lastfm-1K.html" target="_blank" rel="external">(Lastfm Dataset) P39</a><br>　　 </p></li><br><li><p><a href="http://mmdays.com/2008/11/22/power_law_1/" target="_blank" rel="external">浅谈网络世界的Power Law现象 P39</a> </p></li><br><li><p><a href="http://www.grouplens.org/node/73/" target="_blank" rel="external">(MovieLens Dataset) P42</a></p></li><br><li><p><a href="http://research.microsoft.com/pubs/69656/tr-98-12.pdf" target="_blank" rel="external">(Empirical Analysis of Predictive Algorithms for Collaborative Filtering) P49</a></p></li><br><li><p><a href="http://vimeo.com/1242909" target="_blank" rel="external">(Digg Vedio) P50</a></p></li><br><li><p><a href="http://www.cs.umd.edu/%7Esamir/498/Amazon-Recommendations.pdf" target="_blank" rel="external">(Amazon.com Recommendations Item-to-Item Collaborative Filtering) P59</a> </p></li><br><li><p><a href="http://glinden.blogspot.com/2006/03/early-amazon-similarities.html" target="_blank" rel="external">(Greg Linden Blog) P63</a></p></li><br><li><p><a href="http://www.hpl.hp.com/techreports/2008/HPL-2008-48R1.pdf" target="_blank" rel="external">(One-Class Collaborative Filtering) P67</a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent" target="_blank" rel="external">(Stochastic Gradient Descent) P68 </a></p></li><br><li><p><a href="http://www.ideal.ece.utexas.edu/seminar/LatentFactorModels.pdf" target="_blank" rel="external">(Latent Factor Models for Web Recommender Systems) P70 </a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Bipartite_graph" target="_blank" rel="external">(Bipatite Graph) P73</a></p></li><br><li><p><a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=4072747&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4072747" target="_blank" rel="external">(Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation) P74</a></p></li><br><li><p><a href="http://www-cs-students.stanford.edu/%7Etaherh/papers/topic-sensitive-pagerank.pdf" target="_blank" rel="external">(Topic Sensitive Pagerank) P74</a> </p></li><br><li><p><a href="http://www.stanford.edu/dept/ICME/docs/thesis/Li-2009.pdf" target="_blank" rel="external">(FAST ALGORITHMS FOR SPARSE MATRIX INVERSE COMPUTATIONS) P77</a></p></li><br><li><p><a href="https://www.aaai.org/ojs/index.php/aimagazine/article/view/1292" target="_blank" rel="external">(LIFESTYLE FINDER: Intelligent User Profiling Using Large-Scale Demographic Data) P80</a></p></li><br><li><p><a href="http://research.yahoo.com/files/wsdm266m-golbandi.pdf" target="_blank" rel="external">( adaptive bootstrapping of recommender systems using decision trees) P87</a> </p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Vector_space_model" target="_blank" rel="external">(Vector Space Model) P90</a></p></li><br><li><p><a href="http://tunedit.org/challenge/VLNetChallenge" target="_blank" rel="external">(冷启动问题的比赛) P92</a></p></li><br><li><p><a href="http://www.cs.princeton.edu/%7Eblei/papers/BleiNgJordan2003.pdf" target="_blank" rel="external">(Latent Dirichlet Allocation) P92</a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" target="_blank" rel="external">(Kullback–Leibler divergence) P93</a></p></li><br><li><p><a href="http://www.pandora.com/about/mgp" target="_blank" rel="external">(About The Music Genome Project) P94</a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/List_of_Music_Genome_Project_attributes" target="_blank" rel="external">(Pandora Music Genome Project Attributes) P94</a></p></li><br><li><p><a href="http://www.jinni.com/movie-genome.html" target="_blank" rel="external">(Jinni Movie Genome) P94</a> </p></li><br><li><p><a href="http://www.shilad.com/papers/tagsplanations_iui2009.pdf" target="_blank" rel="external">(Tagsplanations: Explaining Recommendations Using Tags) P96</a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Tag_(metadata)" target="_blank" rel="external">(Tag Wikipedia) P96</a></p></li><br><li><p><a href="http://www.shilad.com/shilads_thesis.pdf" target="_blank" rel="external">(Nurturing Tagging Communities) P100</a></p></li><br><li><p><a href="http://www.stanford.edu/%7Emorganya/research/chi2007-tagging.pdf" target="_blank" rel="external">(Why We Tag: Motivations for Annotation in Mobile and Online Media ) P100</a></p></li><br><li><p><a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=delicious%20dataset%20dai-larbor&amp;amp;source=web&amp;cd=1&amp;ved=0CFIQFjAA&amp;url=http%3A%2F%2Fwww.dai-labor.de%2Fen%2Fcompetence_centers%2Firml%2Fdatasets%2F&amp;ei=1R4JUKyFOKu0iQfKvazzCQ&amp;;usg=AFQjCNGuVzzKIKi3K2YFybxrCNxbtKqS4A&amp;amp;cad=rjt" target="_blank" rel="external">(Delicious Dataset) P101</a></p></li><br><li><p><a href="http://research.microsoft.com/pubs/73692/yihgoca-www06.pdf" target="_blank" rel="external">(Finding Advertising Keywords on Web Pages) P118</a></p></li><br><li><p><a href="http://www.kde.cs.uni-kassel.de/ws/rsdc08/" target="_blank" rel="external">(基于标签的推荐系统比赛) P119</a></p></li><br><li><p><a href="http://delab.csd.auth.gr/papers/recsys.pdf" target="_blank" rel="external">(Tag recommendations based on tensor dimensionality reduction）P119</a></p></li><br><li><p><a href="http://www.l3s.de/web/upload/documents/1/recSys09.pdf" target="_blank" rel="external">(latent dirichlet allocation for tag recommendation) P119</a></p></li><br><li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.5271&amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="external">(Folkrank: A ranking algorithm for folksonomies) P119</a> </p></li><br><li><p><a href="http://www.grouplens.org/system/files/tagommenders_numbered.pdf" target="_blank" rel="external">(Tagommenders: Connecting Users to Items through Tags) P119</a> </p></li><br><li><p><a href="http://www.grouplens.org/system/files/group07-sen.pdf" target="_blank" rel="external">(The Quest for Quality Tags) P120</a></p></li><br><li><p><a href="http://2011.camrachallenge.com/" target="_blank" rel="external">(Challenge on Context-aware Movie Recommendation) P123</a></p></li><br><li><p><a href="http://bits.blogs.nytimes.com/2011/09/07/the-lifespan-of-a-link/" target="_blank" rel="external">(The Lifespan of a link) P125</a></p></li><br><li><p><a href="http://www0.cs.ucl.ac.uk/staff/l.capra/publications/lathia_sigir10.pdf" target="_blank" rel="external">(Temporal Diversity in Recommender Systems) P129</a></p></li><br><li><p><a href="http://staff.science.uva.nl/%7Ekamps/ireval/papers/paper_14.pdf" target="_blank" rel="external">(Evaluating Collaborative Filtering Over Time) P129</a></p></li><br><li><p><a href="http://www.google.com/places/" target="_blank" rel="external">(Hotpot) P139 </a></p></li><br><li><p><a href="http://www.readwriteweb.com/archives/google_launches_recommendation_engine_for_places.php" target="_blank" rel="external">(Google Launches Hotpot, A Recommendation Engine for Places) P139</a> </p></li><br><li><p><a href="http://xavier.amatriain.net/pubs/GeolocatedRecommendations.pdf" target="_blank" rel="external">(geolocated recommendations) P140</a></p></li><br><li><p><a href="http://www.nytimes.com/interactive/2010/01/10/nyregion/20100110-netflix-map.html" target="_blank" rel="external">(A Peek Into Netflix Queues) P141</a></p></li><br><li><p><a href="http://www.cs.umd.edu/users/meesh/420/neighbor.pdf" target="_blank" rel="external">(Distance Browsing in Spatial Databases1) P142</a></p></li><br><li><p><a href="http://www.eng.auburn.edu/%7Eweishinn/papers/MDM2010.pdf" target="_blank" rel="external">(Efﬁcient Evaluation of k-Range Nearest Neighbor Queries in Road Networks) P143</a></p></li><br><li><p><a href="http://blog.nielsen.com/nielsenwire/consumer/global-advertising-consumers-trust-real-friends-and-virtual-strangers-the-most/" target="_blank" rel="external">(Global Advertising: Consumers Trust Real Friends and Virtual Strangers the Most) P144 </a></p></li><br><li><p><a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36371.pdf" target="_blank" rel="external">(Suggesting Friends Using the Implicit Social Graph) P145</a></p></li><br><li><p><a href="http://blog.nielsen.com/nielsenwire/online_mobile/friends-frenemies-why-we-add-and-remove-facebook-friends/" target="_blank" rel="external">(Friends &amp; Frenemies: Why We Add and Remove Facebook Friends) P147</a></p></li><br><li><p><a href="http://snap.stanford.edu/data/" target="_blank" rel="external">(Stanford Large Network Dataset Collection) P149 </a></p></li><br><li><p><a href="http://www.dai-labor.de/camra2010/" target="_blank" rel="external">(Workshop on Context-awareness in Retrieval and Recommendation) P151</a></p></li><br><li><p><a href="http://www.comp.hkbu.edu.hk/%7Elichen/download/p245-yuan.pdf" target="_blank" rel="external">(Factorization vs. Regularization: Fusing Heterogeneous Social Relationships in Top-N Recommendation) P153 </a></p></li><br><li><p><a href="http://www.infoq.com/news/2009/06/Twitter-Architecture/" target="_blank" rel="external">(Twitter, an Evolving Architecture) P154</a></p></li><br><li><p><a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;amp;source=web&amp;cd=2&amp;ved=0CGQQFjAB&amp;url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.165.3679%26rep%3Drep1%26type%3Dpdf&amp;ei=dIIJUMzEE8WviQf5tNjcCQ&amp;usg=AFQjCNGw2bHXJ6MdYpksL66bhUE8krS41w&amp;sig2=5EcEDhRe9S5SQNNojWk7_Q" target="_blank" rel="external">(Recommendations in taste related domains) P155</a></p></li><br><li><p><a href="http://www.ercim.eu/publication/ws-proceedings/DelNoe02/RashmiSinha.pdf" target="_blank" rel="external">(Comparing Recommendations Made by Online Systems and Friends) P155</a> </p></li><br><li><p><a href="http://techcrunch.com/2010/04/22/facebook-edgerank/" target="_blank" rel="external">(EdgeRank: The Secret Sauce That Makes Facebook’s News Feed Tick) P157</a></p></li><br><li><p><a href="http://www.grouplens.org/system/files/p217-chen.pdf" target="_blank" rel="external">(Speak Little and Well: Recommending Conversations in Online Social Streams) P158</a></p></li><br><li><p><a href="http://blog.linkedin.com/2008/04/11/learn-more-abou-2/" target="_blank" rel="external">(Learn more about “People You May Know”) P160</a></p></li><br><li><p><a href="http://domino.watson.ibm.com/cambridge/research.nsf/58bac2a2a6b05a1285256b30005b3953/8186a48526821924852576b300537839/$FILE/TR%202009.09%20Make%20New%20Frends.pdf" target="_blank" rel="external">(“Make New Friends, but Keep the Old” – Recommending People on Social Networking Sites) P164 </a> </p></li><br><li><p><a href="http://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=social+recommendation+using+prob&amp;source=web&amp;amp;cd=2&amp;ved=0CFcQFjAB&amp;url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.141.465%26rep%3Drep1%26type%3Dpdf&amp;amp;ei=LY0JUJ7OL9GPiAfe8ZzyCQ&amp;usg=AFQjCNH-xTUWrs9hkxTA8si5fztAdDAEng" target="_blank" rel="external">(SoRec: Social Recommendation Using Probabilistic Matrix) P165 </a></p></li><br><li><p><a href="http://olivier.chapelle.cc/pub/DBN_www2009.pdf" target="_blank" rel="external">(A Dynamic Bayesian Network Click Model for Web Search Ranking) P177</a></p></li><br><li><p><a href="http://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=online+learning+from+click+data+spnsored+search&amp;amp;source=web&amp;cd=1&amp;ved=0CFkQFjAA&amp;amp;url=http%3A%2F%2Fwww.research.yahoo.net%2Ffiles%2Fp227-ciaramita.pdf&amp;ei=HY8JUJW8CrGuiQfpx-XyCQ&amp;usg=AFQjCNE_CYbEs8DVo84V-0VXs5FeqaJ5GQ&amp;cad=rjt" target="_blank" rel="external">(Online Learning from Click Data for Sponsored Search) P177</a></p></li><br><li><p><a href="http://www.cs.cmu.edu/%7Edeepay/mywww/papers/www08-interaction.pdf" target="_blank" rel="external">(Contextual Advertising by Combining Relevance with Click Feedback) P177 </a> </p></li><br><li><p><a href="http://tech.hulu.com/blog/2011/09/19/recommendation-system/" target="_blank" rel="external">(Hulu 推荐系统架构) P178</a></p></li><br><li><p><a href="http://mymediaproject.codeplex.com/" target="_blank" rel="external">(MyMedia Project) P178</a></p></li><br><li><p><a href="http://www.grouplens.org/papers/pdf/www10_sarwar.pdf" target="_blank" rel="external">(item-based collaborative filtering recommendation algorithms) P185</a></p></li><br><li><p><a href="http://www.stanford.edu/%7Ekoutrika/Readings/res/Default/billsus98learning.pdf" target="_blank" rel="external">(Learning Collaborative Information Filters) P186 </a></p></li><br><li><p><a href="http://sifter.org/%7Esimon/journal/20061211.html" target="_blank" rel="external">(Simon Funk Blog:Funk SVD) P187 </a></p></li><br><li><p><a href="http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf" target="_blank" rel="external">(Factor in the Neighbors: Scalable and Accurate Collaborative Filtering) P190 </a></p></li><br><li><p><a href="http://nlpr-web.ia.ac.cn/2009papers/gjhy/gh26.pdf" target="_blank" rel="external">(Time-dependent Models in Collaborative Filtering based Recommender System) P193 </a></p></li><br><li><p><a href="http://sydney.edu.au/engineering/it/%7Ejosiah/lemma/kdd-fp074-koren.pdf" target="_blank" rel="external">(Collaborative filtering with temporal dynamics) P193</a></p></li><br><li><p><a href="http://en.wikipedia.org/wiki/Least_squares" target="_blank" rel="external">(Least Squares Wikipedia) P195</a></p></li><br><li><p><a href="http://www.mimuw.edu.pl/%7Epaterek/ap_kdd.pdf" target="_blank" rel="external">(Improving regularized singular value decomposition for collaborative filtering) P195</a></p></li><br><li><p><a href="http://public.research.att.com/%7Evolinsky/netflix/kdd08koren.pdf" target="_blank" rel="external">(Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model) P195</a><br>　　  </p></li><br></ul>

<p><br><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90ACM%20RecSys%202009%20Workshop%E3%80%91Improving%20recommendation%20accuracy%20by%20clustering%20so.pdf&amp;id=37991" target="_blank" rel="external"><br><br>    </a><br></p>


<p><br><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20Best%20Stu%20Paper%E3%80%91Incorporating%20Occupancy%20into%20Frequent%20Pattern%20Mini.pdf&amp;id=37992" target="_blank" rel="external"><br>        【CIKM 2012 Best Stu Paper】Incorporating Occupancy into Frequent Pattern<br>        Mini.pdf<br>    </a><br></p>

<p><br><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91A%20Latent%20Pairwise%20Preference%20Learning%20Approach%20for%20Recomme.pdf&amp;id=37993" target="_blank" rel="external"><br>        【CIKM 2012 poster】A Latent Pairwise Preference Learning Approach for Recomme.pdf<br>    </a><br></p>

<p><br><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91An%20Effective%20Category%20Classification%20Method%20Based%20on%20a%20Lan.pdf&amp;id=37994" target="_blank" rel="external"><br>        【CIKM 2012 poster】An Effective Category Classification Method Based on<br>        a Lan.pdf<br>    </a><br></p>

<p><br><br>   <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91Learning%20to%20Rank%20for%20Hybrid%20Recommendation.pdf&amp;id=37995" target="_blank" rel="external"><br>        【CIKM 2012 poster】Learning to Rank for Hybrid Recommendation.pdf<br>    </a><br></p>

<p><br><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91Learning%20to%20Recommend%20with%20Social%20Relation%20Ensemble.pdf&amp;id=37996" target="_blank" rel="external"><br>        【CIKM 2012 poster】Learning to Recommend with Social Relation Ensemble.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91Maximizing%20Revenue%20from%20Strategic%20Recommendations%20under%20De.pdf&amp;id=37997" target="_blank" rel="external"><br>        【CIKM 2012 poster】Maximizing Revenue from Strategic Recommendations under<br>        De.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91On%20Using%20Catexperts%20for%20Improving%20the%20Performance%20an.pdf&amp;id=37998" target="_blank" rel="external"><br>        【CIKM 2012 poster】On Using Category Experts for Improving the Performance<br>        an.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91Relation%20Regularized%20Subspace%20Recommending%20for%20Related%20Sci.pdf&amp;id=37999" target="_blank" rel="external"><br>        【CIKM 2012 poster】Relation Regularized Subspace Recommending for Related<br>        Sci.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91Top-N%20Recommendation%20through%20Belief%20Propagation.pdf&amp;id=38000" target="_blank" rel="external"><br>        【CIKM 2012 poster】Top-N Recommendation through Belief Propagation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20poster%E3%80%91Twitter%20Hyperlink%20Recommendation%20with%20User-Tweet-Hyperlink.pdf&amp;id=38001" target="_blank" rel="external"><br>        【CIKM 2012 poster】Twitter Hyperlink Recommendation with User-Tweet-Hyperlink.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91Automatic%20Query%20Expansion%20Based%20on%20Tag%20Recommendation.pdf&amp;id=38002" target="_blank" rel="external"><br>        【CIKM 2012 short】Automatic Query Expansion Based on Tag Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91Graph-Based%20Workflow%20Recommendation-%20On%20Improving%20Business%20.pdf&amp;id=38003" target="_blank" rel="external"><br>        【CIKM 2012 short】Graph-Based Workflow Recommendation- On Improving Business<br>        .pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91Location-Sensitive%20Resources%20Recommendation%20in%20Social%20Taggi.pdf&amp;id=38004" target="_blank" rel="external"><br>        【CIKM 2012 short】Location-Sensitive Resources Recommendation in Social<br>        Taggi.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91More%20Than%20Relevance-%20High%20Utility%20Query%20Recommendation%20By%20M.pdf&amp;id=38005" target="_blank" rel="external"><br>        【CIKM 2012 short】More Than Relevance- High Utility Query Recommendation<br>        By M.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91PathRank-%20A%20Novel%20Node%20Ranking%20Measure%20on%20a%20Heterogeneous%20G.pdf&amp;id=38006" target="_blank" rel="external"><br>        【CIKM 2012 short】PathRank- A Novel Node Ranking Measure on a Heterogeneous<br>        G.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91PRemiSE-%20Personalized%20News%20Recommendation%20via%20Implicit%20Soci.pdf&amp;id=38007" target="_blank" rel="external"><br>        【CIKM 2012 short】PRemiSE- Personalized News Recommendation via Implicit<br>        Soci.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91Query%20Recommendation%20for%20Children.pdf&amp;id=38008" target="_blank" rel="external"><br>        【CIKM 2012 short】Query Recommendation for Children.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91The%20Early-Adopter%20Graph%20and%20its%20Application%20to%20Web-Page%20Rec.pdf&amp;id=38009" target="_blank" rel="external"><br>        【CIKM 2012 short】The Early-Adopter Graph and its Application to Web-Page<br>        Rec.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91Time-aware%20Topic%20Recommendation%20Based%20on%20Micro-blogs.pdf&amp;id=38010" target="_blank" rel="external"><br>        【CIKM 2012 short】Time-aware Topic Recommendation Based on Micro-blogs.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%20short%E3%80%91Using%20Program%20Synthesis%20for%20Social%20Recommendations.pdf&amp;id=38011" target="_blank" rel="external"><br>        【CIKM 2012 short】Using Program Synthesis for Social Recommendations.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91A%20Decentralized%20Recommender%20System%20for%20Effective%20Web%20Credibility%20.pdf&amp;id=38012" target="_blank" rel="external"><br>        【CIKM 2012】A Decentralized Recommender System for Effective Web Credibility<br>        .pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91A%20Generalized%20Framework%20for%20Reciprocal%20Recommender%20Systems.pdf&amp;id=38013" target="_blank" rel="external"><br>        【CIKM 2012】A Generalized Framework for Reciprocal Recommender Systems.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91Dynamic%20Covering%20for%20Recommendation%20Systems.pdf&amp;id=38014" target="_blank" rel="external"><br>        【CIKM 2012】Dynamic Covering for Recommendation Systems.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91Efficient%20Retri.%20of%20Recommendations%20in%20a%20Matrix%20Factorization%20.pdf&amp;id=38015" target="_blank" rel="external"><br>        【CIKM 2012】Efficient Retrieval of Recommendations in a Matrix Factorization<br>        .pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91Exploring%20Personal%20Impact%20for%20Group%20Recommendation.pdf&amp;id=38016" target="_blank" rel="external"><br>        【CIKM 2012】Exploring Personal Impact for Group Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91LogUCB-%20An%20Explore-Exploit%20Algorithm%20For%20Comments%20Recommendation.pdf&amp;id=38017" target="_blank" rel="external"><br>        【CIKM 2012】LogUCB- An Explore-Exploit Algorithm For Comments Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91Metaphor-%20A%20System%20for%20Related%20Search%20Recommendations.pdf&amp;id=38018" target="_blank" rel="external"><br>        【CIKM 2012】Metaphor- A System for Related Search Recommendations.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91Social%20Contextual%20Recommendation.pdf&amp;id=38019" target="_blank" rel="external"><br>        【CIKM 2012】Social Contextual Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90CIKM%202012%E3%80%91Social%20Recommendation%20Across%20Multiple%20Relational%20Domains.pdf&amp;id=38020" target="_blank" rel="external"><br>        【CIKM 2012】Social Recommendation Across Multiple Relational Domains.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90COMMUNICATIONS%20OF%20THE%20ACM%E3%80%91Recommender%20Systems.pdf&amp;id=38021" target="_blank" rel="external"><br>        【COMMUNICATIONS OF THE ACM】Recommender Systems.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90ICDM%202012%20short___%E3%80%91Multiplicative%20Algorithms%20for%20Constrained%20Non-negative%20M.pdf&amp;id=38022" target="_blank" rel="external"><br>        【ICDM 2012 short___】Multiplicative Algorithms for Constrained Non-negative<br>        M.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90ICDM%202012%20short%E3%80%91Collaborative%20Filtering%20with%20Aspect-based%20Opinion%20Mining-%20A.pdf&amp;id=38023" target="_blank" rel="external"><br>        【ICDM 2012 short】Collaborative Filtering with Aspect-based Opinion Mining-<br>        A.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90ICDM%202012%20short%E3%80%91Learning%20Heterogeneous%20Similarity%20Measures%20for%20Hybrid-Recom.pdf&amp;id=38024" target="_blank" rel="external"><br>        【ICDM 2012 short】Learning Heterogeneous Similarity Measures for Hybrid-Recom.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90ICDM%202012%20short%E3%80%91Mining%20Personal%20Context-Aware%20Preferences%20for%20Mobile%20Users.pdf&amp;id=38025" target="_blank" rel="external"><br>        【ICDM 2012 short】Mining Personal Context-Aware Preferences for Mobile<br>        Users.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90ICDM%202012%E3%80%91Link%20Prediction%20and%20Recommendation%20across%20Heterogenous%20Social%20Networks.pdf&amp;id=38026" target="_blank" rel="external"><br>        【ICDM 2012】Link Prediction and Recommendation across Heterogenous Social<br>        Networks.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90IEEE%20Computer%20Society%202009%E3%80%91Matrix%20factorization%20techniques%20for%20recommender%20.pdf&amp;id=38027" target="_blank" rel="external"><br>        【IEEE Computer Society 2009】Matrix factorization techniques for recommender<br>        .pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90IEEE%20Consumer%20Communications%20and%20Networking%20Conference%202006%E3%80%91FilmTrust%20movie.pdf&amp;id=38028" target="_blank" rel="external"><br>        【IEEE Consumer Communications and Networking Conference 2006】FilmTrust<br>        movie.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90IEEE%20Trans%20on%20Audio%2C%20Speech%20and%20Laguage%20Processing%202010%E3%80%91Personalized%20music%20.pdf&amp;id=38029" target="_blank" rel="external"><br>        【IEEE Trans on Audio, Speech and Laguage Processing 2010】Personalized<br>        music .pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90IEEE%20Transactions%20on%20Knowledge%20and%20Data%20Engineering%202005%E3%80%91Toward%20the%20next%20ge.pdf&amp;id=38030" target="_blank" rel="external"><br>        【IEEE Transactions on Knowledge and Data Engineering 2005】Toward the next<br>        ge.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90INFOCOM%202011%E3%80%91Bayesian-inference%20Based%20Recommendation%20in%20Online%20Social%20Network.pdf&amp;id=38031" target="_blank" rel="external"><br>        【INFOCOM 2011】Bayesian-inference Based Recommendation in Online Social<br>        Network.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90KDD%202009%E3%80%91Learning%20optimal%20ranking%20with%20tensor%20factorization%20for%20tag%20recomme.pdf&amp;id=38032" target="_blank" rel="external"><br>        【KDD 2009】Learning optimal ranking with tensor factorization for tag recomme.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202009%E3%80%91Learning%20to%20Recommend%20with%20Social%20Trust%20Ensemble.pdf&amp;id=38033" target="_blank" rel="external"><br>        【SIGIR 2009】Learning to Recommend with Social Trust Ensemble.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Adaptive%20Diversification%20of%20Recommendation%20Results%20via%20Latent%20Fa.pdf&amp;id=38034" target="_blank" rel="external"><br>        【SIGIR 2012】Adaptive Diversification of Recommendation Results via Latent<br>        Fa.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Collaborative%20Personalized%20Tweet%20Recommendation.pdf&amp;id=38035" target="_blank" rel="external"><br>        【SIGIR 2012】Collaborative Personalized Tweet Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Dual%20Role%20Model%20for%20Question%20Recommendation%20in%20Community%20Questio.pdf&amp;id=38036" target="_blank" rel="external"><br>        【SIGIR 2012】Dual Role Model for Question Recommendation in Community Questio.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Exploring%20Social%20Influence%20for%20Recommendation%20-%20A%20Generative%20Mod.pdf&amp;id=38037" target="_blank" rel="external"><br>        【SIGIR 2012】Exploring Social Influence for Recommendation - A Generative<br>        Mod.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Increasing%20Temporal%20Diversity%20with%20Purchase%20Intervals.pdf&amp;id=38038" target="_blank" rel="external"><br>        【SIGIR 2012】Increasing Temporal Diversity with Purchase Intervals.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Learning%20to%20Rank%20Social%20Update%20Streams.pdf&amp;id=38039" target="_blank" rel="external"><br>        【SIGIR 2012】Learning to Rank Social Update Streams.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Personalized%20Click%20Shaping%20through%20Lagrangian%20Duality%20for%20Online.pdf&amp;id=38040" target="_blank" rel="external"><br>        【SIGIR 2012】Personalized Click Shaping through Lagrangian Duality for<br>        Online.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91Predicting%20the%20Ratings%20of%20Multimedia%20Items%20for%20Making%20Personaliz.pdf&amp;id=38041" target="_blank" rel="external"><br>        【SIGIR 2012】Predicting the Ratings of Multimedia Items for Making Personaliz.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91TFMAP-Optimizing%20MAP%20for%20Top-N%20Context-aware%20Recommendation.pdf&amp;id=38042" target="_blank" rel="external"><br>        【SIGIR 2012】TFMAP-Optimizing MAP for Top-N Context-aware Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGIR%202012%E3%80%91What%20Reviews%20are%20Satisfactory-%20Novel%20Features%20for%20Automatic%20Help.pdf&amp;id=38043" target="_blank" rel="external"><br>        【SIGIR 2012】What Reviews are Satisfactory- Novel Features for Automatic<br>        Help.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91%20A%20Semi-Supervised%20Hybrid%20Shilling%20Attack%20Detector%20for%20Trustwor.pdf&amp;id=38044" target="_blank" rel="external"><br>        【SIGKDD 2012】 A Semi-Supervised Hybrid Shilling Attack Detector for Trustwor.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91%20RecMax-%20Exploiting%20Recommender%20Systems%20for%20Fun%20and%20Profit.pdf&amp;id=38045" target="_blank" rel="external"><br>        【SIGKDD 2012】 RecMax- Exploiting Recommender Systems for Fun and Profit.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91Circle-based%20Recommendation%20in%20Online%20Social%20Networks.pdf&amp;id=38046" target="_blank" rel="external"><br>        【SIGKDD 2012】Circle-based Recommendation in Online Social Networks.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91Cross-domain%20Collaboration%20Recommendation.pdf&amp;id=38047" target="_blank" rel="external"><br>        【SIGKDD 2012】Cross-domain Collaboration Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91Finding%20Trending%20Local%20Topics%20in%20Search%20Queries%20for%20Personaliza.pdf&amp;id=38048" target="_blank" rel="external"><br>        【SIGKDD 2012】Finding Trending Local Topics in Search Queries for Personaliza.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91GetJar%20Mobile%20Application%20Recommendations%20with%20Very%20Sparse%20Datasets.pdf&amp;id=38049" target="_blank" rel="external"><br>        【SIGKDD 2012】GetJar Mobile Application Recommendations with Very Sparse<br>        Datasets.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91Incorporating%20Heterogenous%20Information%20for%20Personalized%20Tag%20Rec.pdf&amp;id=38050" target="_blank" rel="external"><br>        【SIGKDD 2012】Incorporating Heterogenous Information for Personalized Tag<br>        Rec.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90SIGKDD%202012%E3%80%91Learning%20Personal%2BSocial%20Latent%20Factor%20Model%20for%20Social%20Recomme.pdf&amp;id=38051" target="_blank" rel="external"><br>        【SIGKDD 2012】Learning Personal+Social Latent Factor Model for Social Recomme.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90VLDB%202012%E3%80%91Challenging%20the%20Long%20Tail%20Recommendation.pdf&amp;id=38052" target="_blank" rel="external"><br>        【VLDB 2012】Challenging the Long Tail Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90VLDB%202012%E3%80%91Supercharging%20Recommender%20Systems%20using%20Taxonomies%20for%20Learning%20U.pdf&amp;id=38053" target="_blank" rel="external"><br>        【VLDB 2012】Supercharging Recommender Systems using Taxonomies for Learning<br>        U.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202012%20Best%20paper%E3%80%91Build%20Your%20Own%20Music%20Recommender%20by%20Modeling%20Internet%20R.pdf&amp;id=38054" target="_blank" rel="external"><br>        【WWW 2012 Best paper】Build Your Own Music Recommender by Modeling Internet<br>        R.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91A%20Personalized%20Recommender%20System%20Based%20on%20User%5C%26%23039%3Bs%20Informatio.pdf&amp;id=38055" target="_blank" rel="external"><br>        【WWW 2013】A Personalized Recommender System Based on User’s Informatio.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Diversified%20Recommendation%20on%20Graphs-Pitfalls%2C%20Measures%2C%20and%20Algorithms.pdf&amp;id=38056" target="_blank" rel="external"><br>        【WWW 2013】Diversified Recommendation on Graphs-Pitfalls, Measures, and<br>        Algorithms.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Do%20Social%20Explanations%20Work-Studying%20and%20Modeling%20the%20Effects%20of%20S.pdf&amp;id=38057" target="_blank" rel="external"><br>        【WWW 2013】Do Social Explanations Work-Studying and Modeling the Effects<br>        of S.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Generation%20of%20Coalition%20Structures%20to%20Provide%20Proper%20Groups%5C%26%23039%3B.pdf&amp;id=38058" target="_blank" rel="external"><br>        【WWW 2013】Generation of Coalition Structures to Provide Proper Groups’.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Learning%20to%20Recommend%20with%20Multi-Faceted%20Trust%20in%20Social%20Networks.pdf&amp;id=38059" target="_blank" rel="external"><br>        【WWW 2013】Learning to Recommend with Multi-Faceted Trust in Social Networks.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Multi-Label%20Learning%20with%20Millions%20of%20Labels-Recommending%20Advertis.pdf&amp;id=38060" target="_blank" rel="external"><br>        【WWW 2013】Multi-Label Learning with Millions of Labels-Recommending Advertis.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Personalized%20Recommendation%20via%20Cross-Domain%20Triadic%20Factorization.pdf&amp;id=38061" target="_blank" rel="external"><br>        【WWW 2013】Personalized Recommendation via Cross-Domain Triadic Factorization.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Profile%20Deversity%20in%20Search%20and%20Recommendation.pdf&amp;id=38062" target="_blank" rel="external"><br>        【WWW 2013】Profile Deversity in Search and Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Real-Time%20Recommendation%20of%20Deverse%20Related%20Articles.pdf&amp;id=38063" target="_blank" rel="external"><br>        【WWW 2013】Real-Time Recommendation of Deverse Related Articles.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Recommendation%20for%20Online%20Social%20Feeds%20by%20Exploiting%20User%20Response.pdf&amp;id=38064" target="_blank" rel="external"><br>        【WWW 2013】Recommendation for Online Social Feeds by Exploiting User Response.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Recommending%20Collaborators%20Using%20Keywords.pdf&amp;id=38065" target="_blank" rel="external"><br>        【WWW 2013】Recommending Collaborators Using Keywords.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Signal-Based%20User%20Recommendation%20on%20Twitter.pdf&amp;id=38066" target="_blank" rel="external"><br>        【WWW 2013】Signal-Based User Recommendation on Twitter.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91SoCo-%20A%20Social%20Network%20Aided%20Context-Aware%20Recommender%20System.pdf&amp;id=38067" target="_blank" rel="external"><br>        【WWW 2013】SoCo- A Social Network Aided Context-Aware Recommender System.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Tailored%20News%20in%20the%20Palm%20of%20Your%20HAND-A%20Multi-Perspective%20Transpa.pdf&amp;id=38068" target="_blank" rel="external"><br>        【WWW 2013】Tailored News in the Palm of Your HAND-A Multi-Perspective Transpa.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91TopRec-Domain-Specific%20Recommendation%20through%20Community%20Topic%20Mini.pdf&amp;id=38069" target="_blank" rel="external"><br>        【WWW 2013】TopRec-Domain-Specific Recommendation through Community Topic<br>        Mini.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91User%5C%26%23039%3Bs%20Satisfaction%20in%20Recommendation%20Systems%20for%20Groups-an%20.pdf&amp;id=38070" target="_blank" rel="external"><br>        【WWW 2013】User’s Satisfaction in Recommendation Systems for Groups-an<br>        .pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Using%20Link%20Semantics%20to%20Recommend%20Collaborations%20in%20Academic%20Socia.pdf&amp;id=38071" target="_blank" rel="external"><br>        【WWW 2013】Using Link Semantics to Recommend Collaborations in Academic<br>        Socia.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=%E3%80%90WWW%202013%E3%80%91Whom%20to%20Mention-Expand%20the%20Diffusion%20of%20Tweets%20by%20%40%20Recommendation.pdf&amp;id=38072" target="_blank" rel="external"><br>        【WWW 2013】Whom to Mention-Expand the Diffusion of Tweets by @ Recommendation.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=Recommender%2BSystems%2BHandbook.pdf&amp;id=38073" target="_blank" rel="external"><br>        Recommender+Systems+Handbook.pdf<br>    </a><br></p>

<p><br>    <a href="http://blog.sciencenet.cn/home.php?mod=attachment&amp;filename=tutorial.pdf&amp;id=38074" target="_blank" rel="external"><br>        tutorial.pdf<br>    </a><br></p>

<h1><a id="user-content-各个领域的推荐系统" class="anchor" href="#各个领域的推荐系统" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>各个领域的推荐系统</h1>

<p><strong>图书</strong></p>

<ul><br><li>Amazon</li><br><li>豆瓣读书</li><br><li>当当网</li><br></ul>

<p><strong>新闻</strong></p>

<ul><br><li>Google News</li><br><li>Genieo</li><br><li>Getprismatic  <a href="http://getprismatic.com/" target="_blank" rel="external">http://getprismatic.com/</a></li><br></ul>

<p><strong>电影</strong></p>

<ul><br><li>Netflix</li><br><li>Jinni</li><br><li>MovieLens</li><br><li>Rotten Tomatoes</li><br><li>Flixster</li><br><li>MTime</li><br></ul>

<p><strong>音乐</strong></p>

<ul><br><li>豆瓣电台</li><br><li>Lastfm</li><br><li>Pandora</li><br><li>Mufin</li><br><li>Lala</li><br><li>EMusic</li><br><li>Ping</li><br><li>虾米电台</li><br><li>Jing.FM</li><br></ul>

<p><strong>视频</strong></p>

<ul><br><li>Youtube</li><br><li>Hulu</li><br><li>Clciker</li><br></ul>

<p><strong>文章</strong></p>

<ul><br><li>CiteULike</li><br><li>Google Reader</li><br><li>StumbleUpon</li><br></ul>

<p><strong>旅游</strong></p>

<ul><br><li>Wanderfly</li><br><li>TripAdvisor</li><br></ul>

<p><strong>社会网络</strong></p>

<ul><br><li>Facebook</li><br><li>Twitter</li><br></ul>

<p><strong>综合</strong></p>

<ul><br><li>Amazon</li><br><li>GetGlue</li><br><li>Strands</li><br><li>Hunch</li><br></ul>

<p></p><h1><a id="user-content-欢迎贡献资源待续" class="anchor" href="#欢迎贡献资源待续" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>欢迎贡献资源~~待续</h1><br><br>  <p></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://github.com/Flowerowl/Big_Data_Resources&quot;&gt;Zhe Yu/Flowerowl&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;大数据/数据挖掘/推荐系统/机器学习相关资源&lt;/p&gt;
&lt;p&gt;Share my personal resources &lt;/p&gt;

&lt;h1&gt;&lt;a id=&quot;user-content-书籍&quot; class=&quot;anchor&quot; href=&quot;#书籍&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;书籍&lt;/h1&gt;

&lt;ul&gt;&lt;br&gt;&lt;li&gt;&lt;p&gt;各种书~各种ppt~更新中~ &lt;a href=&quot;https://pan.baidu.com/s/1c1Xp6Pa&quot;&gt;https://pan.baidu.com/s/1c1Xp6Pa&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;br&gt;&lt;li&gt;&lt;p&gt;机器学习经典书籍小结 &lt;a href=&quot;http://www.cnblogs.com/snake-hand/archive/2013/06/10/3131145.html&quot;&gt;http://www.cnblogs.com/snake-hand/archive/2013/06/10/3131145.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;br&gt;&lt;li&gt;&lt;p&gt;机器学习&amp;amp;深度学习经典资料汇总 &lt;a href=&quot;http://www.thebigdata.cn/JiShuBoKe/13299.html&quot;&gt;http://www.thebigdata.cn/JiShuBoKe/13299.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;br&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Big Data" scheme="http://ipcreator.me/tags/Big-Data/"/>
    
      <category term="Data Mining" scheme="http://ipcreator.me/tags/Data-Mining/"/>
    
  </entry>
  
  <entry>
    <title>Python 资源大全中文版</title>
    <link href="http://ipcreator.me/2017/02/18/Program/Resources/tools-of-python/"/>
    <id>http://ipcreator.me/2017/02/18/Program/Resources/tools-of-python/</id>
    <published>2017-02-18T01:02:06.000Z</published>
    <updated>2017-02-19T06:02:30.218Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://github.com/wangaicc/awesome-python-cn" target="_blank" rel="external">litai wong/wangaicc</a></p>
<p>我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。<a href="https://github.com/vinta/awesome-python" target="_blank" rel="external">awesome-python</a> 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。</p>
<p>Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。</p>
<a id="more"></a>
<hr>
<h3 id="我们要做什么？"><a href="#我们要做什么？" class="headerlink" title="我们要做什么？"></a>我们要做什么？</h3><ul>
<li>基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。</li>
<li>整理后的内容，将收录在<a href="http://hao.jobbole.com/" target="_blank" rel="external">伯乐在线资源频道</a>。可参考已整理的内容：<ul>
<li>《<a href="http://hao.jobbole.com/python-scrapy/" target="_blank" rel="external">Scrapy：Python的爬虫框架</a>》</li>
<li>《<a href="http://hao.jobbole.com/flask/" target="_blank" rel="external">Flask：一个使用Python编写的轻量级Web应用框架</a>》</li>
</ul>
</li>
</ul>
<hr>
<h3 id="如何参与本项目？"><a href="#如何参与本项目？" class="headerlink" title="如何参与本项目？"></a>如何参与本项目？</h3><p>从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。</p>
<p>不过加入前，有几个小要求：</p>
<ul>
<li>英文还不错，能读懂英文并用自己的话复述；</li>
<li>在用 Python；</li>
</ul>
<p>如有兴趣，请加 QQ：50872495。加 Q 时请注明「Python大全」</p>
<hr>
<h3 id="本项目的参与者"><a href="#本项目的参与者" class="headerlink" title="本项目的参与者"></a>本项目的参与者</h3><ul>
<li>维护者：</li>
<li>贡献者：<a href="https://github.com/hanxiaomax" target="_blank" rel="external">艾凌风</a>、Namco、<a href="https://github.com/Daetalus" target="_blank" rel="external">Daetalus</a>、<a href="http://www.jobbole.com/members/huanglimin/" target="_blank" rel="external">黄利民</a>、<a href="http://www.jobbole.com/members/atupal/" target="_blank" rel="external">atupal</a>、<a href="http://www.jobbole.com/members/rainbow/" target="_blank" rel="external">rainbow</a>、<a href="https://github.com/mutoulbj" target="_blank" rel="external">木头lbj</a></li>
</ul>
<p>注：名单不分排名，不定期补充更新</p>
<hr>
<h3 id="奖励计划"><a href="#奖励计划" class="headerlink" title="奖励计划"></a>奖励计划</h3><p>虽然奖励可能并不是你加入的主要原因，但还是有必要提一下：</p>
<ul>
<li>整理超过 20 个资源后，可在伯乐在线上开通打赏；</li>
<li>每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品；</li>
<li><a href="http://hao.jobbole.com/rewards/" target="_blank" rel="external">奖励详情</a></li>
</ul>
<hr>
<h3 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h3><p>管理 Python 版本和环境的工具</p>
<ul>
<li>p：非常简单的交互式 python 版本管理工具。<a href="https://github.com/qw3rtman/p" target="_blank" rel="external">官网</a></li>
<li>pyenv：简单的 Python 版本管理工具。<a href="https://github.com/yyuu/pyenv" target="_blank" rel="external">官网</a></li>
<li>Vex：可以在虚拟环境中执行命令。<a href="https://github.com/sashahart/vex" target="_blank" rel="external">官网</a></li>
<li>virtualenv：创建独立 Python 环境的工具。<a href="https://pypi.python.org/pypi/virtualenv" target="_blank" rel="external">官网</a></li>
<li>virtualenvwrapper：virtualenv 的一组扩展。<a href="https://pypi.python.org/pypi/virtualenvwrapper" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h3><p>管理包和依赖的工具。</p>
<ul>
<li>pip：Python 包和依赖关系管理工具。<a href="https://pip.pypa.io/" target="_blank" rel="external">官网</a></li>
<li>pip-tools：保证 Python 包依赖关系更新的一组工具。<a href="https://github.com/nvie/pip-tools" target="_blank" rel="external">官网</a></li>
<li>conda：跨平台，Python 二进制包管理工具。<a href="https://github.com/conda/conda/" target="_blank" rel="external">官网</a></li>
<li>Curdling：管理 Python 包的命令行工具。<a href="http://clarete.li/curdling/" target="_blank" rel="external">官网</a></li>
<li>wheel：Python 分发的新标准，意在取代 eggs。<a href="http://pythonwheels.com/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="包仓库"><a href="#包仓库" class="headerlink" title="包仓库"></a>包仓库</h3><p>本地 PyPI 仓库服务和代理。</p>
<ul>
<li>warehouse：下一代 PyPI。<a href="https://github.com/pypa/warehouse" target="_blank" rel="external">官网</a><ul>
<li>Warehouse：PyPA 提供的 PyPI 镜像工具。<a href="https://warehouse.python.org/" target="_blank" rel="external">官网</a> <a href="https://bitbucket.org/pypa/bandersnatch" target="_blank" rel="external">bandersnatch</a></li>
</ul>
</li>
<li>devpi：PyPI 服务和打包/测试/分发工具。<a href="http://doc.devpi.net/" target="_blank" rel="external">官网</a></li>
<li>localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。<a href="https://github.com/mvantellingen/localshop" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="分发"><a href="#分发" class="headerlink" title="分发"></a>分发</h3><p>打包为可执行文件以便分发。</p>
<ul>
<li>PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。<a href="https://github.com/pyinstaller/pyinstaller" target="_blank" rel="external">官网</a></li>
<li>dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。<a href="http://dh-virtualenv.readthedocs.org/" target="_blank" rel="external">官网</a></li>
<li>Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。<a href="http://nuitka.net/" target="_blank" rel="external">官网</a></li>
<li>py2app：将 Python 脚本变为独立软件包（Mac OS X）。<a href="http://pythonhosted.org/py2app/" target="_blank" rel="external">官网</a></li>
<li>py2exe：将 Python 脚本变为独立软件包（Windows）。<a href="http://www.py2exe.org/" target="_blank" rel="external">官网</a></li>
<li>pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python本身。<a href="http://pynsist.readthedocs.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="构建工具"><a href="#构建工具" class="headerlink" title="构建工具"></a>构建工具</h3><p>将源码编译成软件。</p>
<ul>
<li>buildout：一个构建系统，从多个组件来创建，组装和部署应用。<a href="http://www.buildout.org/" target="_blank" rel="external">官网</a></li>
<li>BitBake：针对嵌入式 Linux 的类似 make 的构建工具。<a href="http://www.yoctoproject.org/docs/1.6/bitbake-user-manual/bitbake-user-manual.html" target="_blank" rel="external">官网</a></li>
<li>fabricate：对任何语言自动找到依赖关系的构建工具。<a href="https://code.google.com/p/fabricate/" target="_blank" rel="external">官网</a></li>
<li>PlatformIO：多平台命令行构建工具。<a href="https://github.com/ivankravets/platformio" target="_blank" rel="external">官网</a></li>
<li>PyBuilder：纯 Python 实现的持续化构建工具。<a href="https://github.com/pybuilder/pybuilder" target="_blank" rel="external">官网</a></li>
<li>SCons：软件构建工具。<a href="http://www.scons.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="交互式解析器"><a href="#交互式解析器" class="headerlink" title="交互式解析器"></a>交互式解析器</h3><p>交互式 Python 解析器。</p>
<ul>
<li>IPython：功能丰富的工具，非常有效的使用交互式 Python。<a href="https://github.com/ipython/ipython" target="_blank" rel="external">官网</a></li>
<li>bpython：界面丰富的 Python 解析器。<a href="http://bpython-interpreter.org/" target="_blank" rel="external">官网</a></li>
<li>ptpython：高级交互式Python解析器， 构建于<a href="https://github.com/jonathanslenders/python-prompt-toolkit" target="_blank" rel="external">python-prompt-toolkit</a> 之上。<a href="https://github.com/jonathanslenders/ptpython" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p>文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。</p>
<ul>
<li>imghdr：（Python 标准库）检测图片类型。<a href="https://docs.python.org/2/library/imghdr.html" target="_blank" rel="external">官网</a></li>
<li>mimetypes：（Python 标准库）将文件名映射为 MIME 类型。<a href="https://docs.python.org/2/library/mimetypes.html" target="_blank" rel="external">官网</a></li>
<li>path.py：对 os.path 进行封装的模块。<a href="https://github.com/jaraco/path.py" target="_blank" rel="external">官网</a></li>
<li>pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。<a href="https://pathlib.readthedocs.org/en/pep428/" target="_blank" rel="external">官网</a></li>
<li>python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。<a href="https://github.com/ahupp/python-magic" target="_blank" rel="external">官网</a></li>
<li>Unipath：用面向对象的方式操作文件和目录。<a href="https://github.com/mikeorr/Unipath" target="_blank" rel="external">官网</a></li>
<li>watchdog：管理文件系统事件的 API 和 shell 工具<a href="https://github.com/gorakhargosh/watchdog" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h3><p>操作日期和时间的类库。</p>
<ul>
<li>arrow：更好的 Python 日期时间操作类库。<a href="https://github.com/crsmithdev/arrow" target="_blank" rel="external">官网</a></li>
<li>Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。<a href="https://github.com/KoffeinFlummi/Chronyk" target="_blank" rel="external">官网</a></li>
<li>dateutil：Python datetime 模块的扩展。<a href="https://pypi.python.org/pypi/python-dateutil" target="_blank" rel="external">官网</a></li>
<li>delorean：解决 Python 中有关日期处理的棘手问题的库。<a href="https://github.com/myusuf3/delorean/" target="_blank" rel="external">官网</a></li>
<li>moment：一个用来处理时间和日期的Python库。灵感来自于Moment.js。<a href="https://github.com/zachwill/moment" target="_blank" rel="external">官网</a></li>
<li>PyTime：一个简单易用的Python模块，用于通过字符串来操作日期/时间。<a href="https://github.com/shnode/PyTime" target="_blank" rel="external">官网</a></li>
<li>pytz：现代以及历史版本的世界时区定义。将时区数据库引入Python。<a href="https://launchpad.net/pytz" target="_blank" rel="external">官网</a></li>
<li>when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。<a href="https://github.com/dirn/When.py" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="文本处理"><a href="#文本处理" class="headerlink" title="文本处理"></a>文本处理</h3><p>用于解析和操作文本的库。</p>
<ul>
<li>通用<ul>
<li>chardet：字符编码检测器，兼容 Python2 和 Python3。<a href="https://github.com/chardet/chardet" target="_blank" rel="external">官网</a></li>
<li>difflib：(Python 标准库)帮助我们进行差异化比较。<a href="https://docs.python.org/2/library/difflib.html" target="_blank" rel="external">官网</a></li>
<li>ftfy：让Unicode文本更完整更连贯。<a href="https://github.com/LuminosoInsight/python-ftfy" target="_blank" rel="external">官网</a></li>
<li>fuzzywuzzy：模糊字符串匹配。<a href="https://github.com/seatgeek/fuzzywuzzy" target="_blank" rel="external">官网</a></li>
<li>Levenshtein：快速计算编辑距离以及字符串的相似度。<a href="https://github.com/ztane/python-Levenshtein/" target="_blank" rel="external">官网</a></li>
<li>pangu.py：在中日韩语字符和数字字母之间添加空格。<a href="https://github.com/vinta/pangu.py" target="_blank" rel="external">官网</a></li>
<li>yfiglet-figlet：<a href="https://github.com/pwaller/pyfiglet" target="_blank" rel="external">pyfiglet -figlet</a> 的 Python实现。</li>
<li>shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。<a href="https://github.com/stochastic-technologies/shortuuid" target="_blank" rel="external">官网</a></li>
<li>unidecode：Unicode 文本的 ASCII 转换形式 。<a href="https://pypi.python.org/pypi/Unidecode" target="_blank" rel="external">官网</a></li>
<li>uniout：打印可读的字符，而不是转义的字符串。<a href="https://github.com/moskytw/uniout" target="_blank" rel="external">官网</a></li>
<li>xpinyin：一个用于把汉字转换为拼音的库。<a href="https://github.com/lxneng/xpinyin" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Slug化<ul>
<li>awesome-slugify：一个 Python slug 化库，可以保持 Unicode。<a href="https://github.com/dimka665/awesome-slugify" target="_blank" rel="external">官网</a></li>
<li>python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。<a href="https://github.com/un33k/python-slugify" target="_blank" rel="external">官网</a></li>
<li>unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。<a href="https://github.com/mozilla/unicode-slugify" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>解析器<ul>
<li>phonenumbers：解析，格式化，储存，验证电话号码。<a href="https://github.com/daviddrysdale/python-phonenumbers" target="_blank" rel="external">官网</a></li>
<li>PLY：lex 和 yacc 解析工具的 Python 实现。<a href="http://www.dabeaz.com/ply/" target="_blank" rel="external">官网</a></li>
<li>Pygments：通用语法高亮工具。<a href="http://pygments.org/" target="_blank" rel="external">官网</a></li>
<li>pyparsing：生成通用解析器的框架。<a href="http://pyparsing.wikispaces.com/" target="_blank" rel="external">官网</a></li>
<li>python-nameparser：把一个人名分解为几个独立的部分。<a href="https://github.com/derek73/python-nameparser" target="_blank" rel="external">官网</a></li>
<li>python-user-agents：浏览器 user agent 解析器。<a href="https://github.com/selwin/python-user-agents" target="_blank" rel="external">官网</a></li>
<li>sqlparse：一个无验证的 SQL 解析器。<a href="https://sqlparse.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="特殊文本格式处理"><a href="#特殊文本格式处理" class="headerlink" title="特殊文本格式处理"></a>特殊文本格式处理</h3><p>一些用来解析和操作特殊文本格式的库。</p>
<ul>
<li>通用<ul>
<li>tablib：一个用来处理中表格数据的模块。<a href="https://github.com/kennethreitz/tablib" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Office<ul>
<li>Marmir：把输入的Python 数据结构转换为电子表单。<a href="https://github.com/brianray/mm" target="_blank" rel="external">官网</a></li>
<li>openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。<a href="https://openpyxl.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。<a href="https://github.com/python-openxml/python-docx" target="_blank" rel="external">官网</a></li>
<li>unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。<a href="https://github.com/dagwieers/unoconv" target="_blank" rel="external">官网</a></li>
<li>XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。<a href="https://xlsxwriter.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。<a href="http://xlwings.org/" target="_blank" rel="external">官网</a></li>
<li>xlwt：读写 Excel 文件的数据和格式信息。<a href="https://github.com/python-excel/xlwt" target="_blank" rel="external">官网</a> / <a href="https://github.com/python-excel/xlrd" target="_blank" rel="external">xlrd</a></li>
<li>relatorio：模板化OpenDocument 文件。<a href="http://relatorio.tryton.org/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>PDF<ul>
<li>PDFMiner：一个用于从PDF文档中抽取信息的工具。<a href="https://github.com/euske/pdfminer" target="_blank" rel="external">官网</a></li>
<li>PyPDF2：一个可以分割，合并和转换 PDF 页面的库。<a href="https://github.com/mstamy2/PyPDF2" target="_blank" rel="external">官网</a></li>
<li>ReportLab：快速创建富文本 PDF 文档。<a href="http://www.reportlab.com/opensource/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Markdown<ul>
<li>Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。<a href="https://github.com/lepture/mistune" target="_blank" rel="external">官网</a></li>
<li>Python-Markdown：John Gruber’s Markdown 的 Python 版实现。<a href="https://github.com/waylan/Python-Markdown" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>YAML<ul>
<li>PyYAML：Python 版本的 YAML 解析器。<a href="http://pyyaml.org/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>CSV<ul>
<li>csvkit：用于转换和操作 CSV 的工具。<a href="https://github.com/onyxfish/csvkit" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Archive<ul>
<li>unp：一个用来方便解包归档文件的命令行工具。<a href="https://github.com/mitsuhiko/unp" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h3><p>用来处理人类语言的库。</p>
<ul>
<li>NLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。<a href="http://www.nltk.org/" target="_blank" rel="external">官网</a></li>
<li>jieba：中文分词工具。<a href="https://github.com/fxsjy/jieba" target="_blank" rel="external">官网</a></li>
<li>langid.py：独立的语言识别系统。<a href="https://github.com/saffsd/langid.py" target="_blank" rel="external">官网</a></li>
<li>Pattern：Python 网络信息挖掘模块。<a href="http://www.clips.ua.ac.be/pattern" target="_blank" rel="external">官网</a></li>
<li>SnowNLP：一个用来处理中文文本的库。<a href="https://github.com/isnowfy/snownlp" target="_blank" rel="external">官网</a></li>
<li>TextBlob：为进行普通自然语言处理任务提供一致的 API。<a href="http://textblob.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。<a href="https://github.com/2shou/TextGrocery" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h3><p>用以生成项目文档的库。</p>
<ul>
<li>Sphinx：Python 文档生成器。<a href="http://www.sphinx-doc.org/en/latest/" target="_blank" rel="external">官网</a><ul>
<li>awesome-sphinxdoc：<a href="https://github.com/yoloseem/awesome-sphinxdoc" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>MkDocs：对 Markdown 友好的文档生成器。<a href="http://www.mkdocs.org/" target="_blank" rel="external">官网</a></li>
<li>pdoc：一个可以替换Epydoc 的库，可以自动生成 Python 库的 API 文档。<a href="https://github.com/BurntSushi/pdoc" target="_blank" rel="external">官网</a></li>
<li>Pycco：文学编程（literate-programming）风格的文档生成器。<a href="https://github.com/pycco-docs/pycco" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>用来保存和解析配置的库。</p>
<ul>
<li>config：<a href="https://docs.python.org/2/library/logging.html" target="_blank" rel="external">logging</a> 模块作者写的分级配置模块。<a href="https://www.red-dove.com/config-doc/" target="_blank" rel="external">官网</a></li>
<li>ConfigObj：INI 文件解析器，带验证功能。<a href="http://www.voidspace.org.uk/python/configobj.html" target="_blank" rel="external">官网</a></li>
<li>ConfigParser：(Python 标准库) INI 文件解析器。<a href="https://docs.python.org/2/library/configparser.html" target="_blank" rel="external">官网</a></li>
<li>profig：通过多种格式进行配置，具有数值转换功能。<a href="http://profig.readthedocs.org/en/default/" target="_blank" rel="external">官网</a></li>
<li>python-decouple：将设置和代码完全隔离。<a href="https://github.com/henriquebastos/python-decouple" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><p>用于创建命令行程序的库。</p>
<ul>
<li>命令行程序开发<ul>
<li>cement：Python 的命令行程序框架。<a href="http://builtoncement.com/" target="_blank" rel="external">官网</a></li>
<li>click：一个通过组合的方式来创建精美命令行界面的包。<a href="http://click.pocoo.org/dev/" target="_blank" rel="external">官网</a></li>
<li>cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。<a href="http://docs.openstack.org/developer/cliff/" target="_blank" rel="external">官网</a></li>
<li>clint：Python 命令行程序工具。<a href="https://github.com/kennethreitz/clint" target="_blank" rel="external">官网</a></li>
<li>colorama：跨平台彩色终端文本。<a href="https://pypi.python.org/pypi/colorama" target="_blank" rel="external">官网</a></li>
<li>docopt：Python 风格的命令行参数解析器。<a href="http://docopt.org/" target="_blank" rel="external">官网</a></li>
<li>Gooey：一条命令，将命令行程序变成一个 GUI 程序。<a href="https://github.com/chriskiehl/Gooey" target="_blank" rel="external">官网</a></li>
<li>python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。<a href="https://github.com/jonathanslenders/python-prompt-toolkit" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/pythonpy/" target="_blank" rel="external">Pythonpy</a>：在命令行中直接执行任何Python指令。<a href="http://github.com/Russell91/pythonpy/wiki" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>生产力工具<ul>
<li>aws-cli：Amazon Web Services 的通用命令行界面。<a href="https://github.com/aws/aws-cli" target="_blank" rel="external">官网</a></li>
<li>bashplotlib：在终端中进行基本绘图。<a href="https://github.com/glamp/bashplotlib" target="_blank" rel="external">官网</a></li>
<li>caniusepython3：判断是哪个项目妨碍你你移植到 Python 3。<a href="https://github.com/brettcannon/caniusepython3" target="_blank" rel="external">官网</a></li>
<li>cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。<a href="https://github.com/audreyr/cookiecutter" target="_blank" rel="external">官网</a></li>
<li>doitlive：一个用来在终端中进行现场演示的工具。<a href="https://github.com/sloria/doitlive" target="_blank" rel="external">官网</a></li>
<li>howdoi：通过命令行获取即时的编程问题解答。<a href="https://github.com/gleitz/howdoi" target="_blank" rel="external">官网</a></li>
<li>httpie：一个命令行HTTP 客户端，cURL 的替代品，易用性更好。<a href="https://github.com/jkbrzt/httpie" target="_blank" rel="external">官网</a></li>
<li>PathPicker：从bash输出中选出文件。<a href="https://github.com/facebook/PathPicker" target="_blank" rel="external">官网</a></li>
<li>percol：向UNIX shell 传统管道概念中加入交互式选择功能。<a href="https://github.com/mooz/percol" target="_blank" rel="external">官网</a></li>
<li>SAWS：一个加强版的 AWS 命令行。<a href="https://github.com/donnemartin/saws" target="_blank" rel="external">官网</a></li>
<li>thefuck：修正你之前的命令行指令。<a href="https://github.com/nvbn/thefuck" target="_blank" rel="external">官网</a></li>
<li>mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。<a href="https://github.com/dbcli/mycli" target="_blank" rel="external">官网</a></li>
<li>pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。<a href="https://github.com/dbcli/pgcli" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="下载器"><a href="#下载器" class="headerlink" title="下载器"></a>下载器</h3><p>用来进行下载的库.</p>
<ul>
<li>s3cmd：一个用来管理Amazon S3 和 CloudFront 的命令行工具。<a href="https://github.com/s3tools/s3cmd" target="_blank" rel="external">官网</a></li>
<li>s4cmd：超级 S3 命令行工具，性能更加强劲。<a href="https://github.com/bloomreach/s4cmd" target="_blank" rel="external">官网</a></li>
<li>you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。<a href="https://www.soimort.org/you-get/" target="_blank" rel="external">官网</a></li>
<li>youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。<a href="http://rg3.github.io/youtube-dl/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h3><p>用来操作图像的库.</p>
<ul>
<li>pillow：Pillow 是一个更加易用版的 <a href="http://www.pythonware.com/products/pil/" target="_blank" rel="external">PIL</a>。<a href="http://pillow.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>hmap：图像直方图映射。<a href="https://github.com/rossgoodwin/hmap" target="_blank" rel="external">官网</a></li>
<li>imgSeek：一个使用视觉相似性搜索一组图片集合的项目。<a href="http://sourceforge.net/projects/imgseek/" target="_blank" rel="external">官网</a></li>
<li>nude.py：裸体检测。<a href="https://github.com/hhatto/nude.py" target="_blank" rel="external">官网</a></li>
<li>pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。<a href="https://pythonhosted.org/pyBarcode/" target="_blank" rel="external">官网</a></li>
<li>pygram：类似 Instagram 的图像滤镜。<a href="https://github.com/ajkumar25/pygram" target="_blank" rel="external">官网</a></li>
<li>python-qrcode：一个纯 Python 实现的二维码生成器。<a href="https://github.com/lincolnloop/python-qrcode" target="_blank" rel="external">官网</a></li>
<li>Quads：基于四叉树的计算机艺术。<a href="https://github.com/fogleman/Quads" target="_blank" rel="external">官网</a></li>
<li>scikit-image：一个用于（科学）图像处理的 Python 库。<a href="http://scikit-image.org/" target="_blank" rel="external">官网</a></li>
<li>thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。<a href="https://github.com/thumbor/thumbor" target="_blank" rel="external">官网</a></li>
<li>wand：<a href="http://www.imagemagick.org/script/magick-wand.php" target="_blank" rel="external">MagickWand</a>的Python 绑定。MagickWand 是 ImageMagick的 C API 。<a href="https://github.com/dahlia/wand" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="OCR"><a href="#OCR" class="headerlink" title="OCR"></a>OCR</h3><p>光学字符识别库。</p>
<ul>
<li>pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。<a href="https://github.com/jflesch/pyocr" target="_blank" rel="external">官网</a></li>
<li>pytesseract：<a href="https://github.com/tesseract-ocr" target="_blank" rel="external">Google Tesseract OCR</a> 的另一个封装(wrapper)。<a href="https://github.com/madmaze/pytesseract" target="_blank" rel="external">官网</a></li>
<li>python-tesseract - <a href="https://github.com/tesseract-ocr" target="_blank" rel="external">Google Tesseract OCR</a> 的一个包装类。</li>
</ul>
<h3 id="音频"><a href="#音频" class="headerlink" title="音频"></a>音频</h3><p>用来操作音频的库</p>
<ul>
<li>audiolazy：Python 的数字信号处理包。<a href="https://github.com/danilobellini/audiolazy" target="_blank" rel="external">官网</a></li>
<li>audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。<a href="https://github.com/beetbox/audioread" target="_blank" rel="external">官网</a></li>
<li>beets：一个音乐库管理工具及 <a href="https://musicbrainz.org/" target="_blank" rel="external">MusicBrainz</a> 标签添加工具<a href="http://beets.io/" target="_blank" rel="external">官网</a></li>
<li>dejavu：音频指纹提取和识别<a href="https://github.com/worldveil/dejavu" target="_blank" rel="external">官网</a></li>
<li>django-elastic-transcoder：Django + <a href="http://aws.amazon.com/elastictranscoder/" target="_blank" rel="external">Amazon Elastic Transcoder</a>。<a href="https://github.com/StreetVoice/django-elastic-transcoder" target="_blank" rel="external">官网</a></li>
<li>eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。<a href="http://eyed3.nicfit.net/" target="_blank" rel="external">官网</a></li>
<li>id3reader：一个用来读取 MP3 元数据的 Python 模块。<a href="http://nedbatchelder.com/code/modules/id3reader.py" target="_blank" rel="external">官网</a></li>
<li>m3u8：一个用来解析 m3u8 文件的模块。<a href="https://github.com/globocom/m3u8" target="_blank" rel="external">官网</a></li>
<li>mutagen：一个用来处理音频元数据的 Python 模块。<a href="https://bitbucket.org/lazka/mutagen" target="_blank" rel="external">官网</a></li>
<li>pydub：通过简单、简洁的高层接口来操作音频文件。<a href="https://github.com/jiaaro/pydub" target="_blank" rel="external">官网</a></li>
<li>pyechonest：<a href="http://developer.echonest.com/" target="_blank" rel="external">Echo Nest</a> API 的 Python 客户端<a href="https://github.com/echonest/pyechonest" target="_blank" rel="external">官网</a></li>
<li>talkbox：一个用来处理演讲/信号的 Python 库<a href="http://scikits.appspot.com/talkbox" target="_blank" rel="external">官网</a></li>
<li>TimeSide：开源 web 音频处理框架。<a href="https://github.com/Parisson/TimeSide" target="_blank" rel="external">官网</a></li>
<li>tinytag：一个用来读取MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。<a href="https://github.com/devsnd/tinytag" target="_blank" rel="external">官网</a></li>
<li>mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。<a href="http://bspaans.github.io/python-mingus/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h3><p>用来操作视频和GIF的库。</p>
<ul>
<li>moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。<a href="http://zulko.github.io/moviepy/" target="_blank" rel="external">官网</a></li>
<li>scikit-video：SciPy 视频处理常用程序。<a href="https://github.com/aizvorski/scikit-video" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="地理位置"><a href="#地理位置" class="headerlink" title="地理位置"></a>地理位置</h3><p>地理编码地址以及用来处理经纬度的库。</p>
<ul>
<li>GeoDjango：世界级地理图形 web 框架。<a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/" target="_blank" rel="external">官网</a></li>
<li>GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。<a href="https://github.com/maxmind/geoip-api-python" target="_blank" rel="external">官网</a></li>
<li>geojson：GeoJSON 的 Python 绑定及工具。<a href="https://github.com/frewsxcv/python-geojson" target="_blank" rel="external">官网</a></li>
<li>geopy：Python 地址编码工具箱。<a href="https://github.com/geopy/geopy" target="_blank" rel="external">官网</a></li>
<li>pygeoip：纯 Python GeoIP API。<a href="https://github.com/appliedsec/pygeoip" target="_blank" rel="external">官网</a></li>
<li>django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。<a href="https://github.com/SmileyChris/django-countries" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p>使用HTTP的库。</p>
<ul>
<li>requests：人性化的HTTP请求库。<a href="http://docs.python-requests.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>grequests：requests 库 + gevent ，用于异步 HTTP 请求.<a href="https://github.com/kennethreitz/grequests" target="_blank" rel="external">官网</a></li>
<li>httplib2：全面的 HTTP 客户端库。<a href="https://github.com/jcgregorio/httplib2" target="_blank" rel="external">官网</a></li>
<li>treq：类似 requests 的Python API 构建于 Twisted HTTP 客户端之上。<a href="https://github.com/twisted/treq" target="_blank" rel="external">官网</a></li>
<li>urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。<a href="https://github.com/shazow/urllib3" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>Python实现的数据库。</p>
<ul>
<li>pickleDB：一个简单，轻量级键值储存数据库。<a href="https://pythonhosted.org/pickleDB/" target="_blank" rel="external">官网</a></li>
<li>PipelineDB：流式 SQL 数据库。<a href="https://www.pipelinedb.com/" target="_blank" rel="external">官网</a></li>
<li>TinyDB：一个微型的，面向文档型数据库。<a href="https://github.com/msiemens/tinydb" target="_blank" rel="external">官网</a></li>
<li>ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。<a href="http://www.zodb.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="数据库驱动"><a href="#数据库驱动" class="headerlink" title="数据库驱动"></a>数据库驱动</h3><p>用来连接和操作数据库的库。</p>
<ul>
<li>ySQL：<a href="http://shlomi-noach.github.io/awesome-mysql/" target="_blank" rel="external">awesome-mysql</a>系列<ul>
<li>mysql-python：Python 的 MySQL 数据库连接器。<a href="http://sourceforge.net/projects/mysql-python/" target="_blank" rel="external">官网</a></li>
<li>ysqlclient：<a href="https://github.com/PyMySQL/mysqlclient-python" target="_blank" rel="external">mysql-python</a> 分支，支持 Python 3。</li>
<li>oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs.<a href="https://pythonhosted.org/oursql/" target="_blank" rel="external">官网</a></li>
<li>PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。<a href="https://github.com/PyMySQL/PyMySQL" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>PostgreSQL<ul>
<li>psycopg2：Python 中最流行的 PostgreSQL 适配器。<a href="http://initd.org/psycopg/" target="_blank" rel="external">官网</a></li>
<li>queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。<a href="https://github.com/gmr/queries" target="_blank" rel="external">官网</a></li>
<li>txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。<a href="http://txpostgres.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>其他关系型数据库<ul>
<li>apsw：另一个 Python SQLite封装。<a href="http://rogerbinns.github.io/apsw/" target="_blank" rel="external">官网</a></li>
<li>dataset：在数据库中存储Python字典</li>
<li>pymssql：一个简单的Microsoft SQL Server数据库接口。<a href="http://www.pymssql.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>NoSQL 数据库<ul>
<li>cassandra-python-driver：Cassandra 的 Python 驱动。<a href="https://github.com/datastax/python-driver" target="_blank" rel="external">官网</a></li>
<li>HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。<a href="http://happybase.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。<a href="https://plyvel.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>py2neo：Neo4j restful 接口的Python 封装客户端。<a href="http://py2neo.org/2.0/" target="_blank" rel="external">官网</a></li>
<li>pycassa：Cassandra 的 Python Thrift 驱动。<a href="https://github.com/pycassa/pycassa" target="_blank" rel="external">官网</a></li>
<li>PyMongo：MongoDB 的官方 Python 客户端。<a href="https://docs.mongodb.org/ecosystem/drivers/python/" target="_blank" rel="external">官网</a></li>
<li>redis-py：Redis 的 Python 客户端。<a href="https://github.com/andymccurdy/redis-py" target="_blank" rel="external">官网</a></li>
<li>telephus：基于 Twisted 的 Cassandra 客户端。<a href="https://github.com/driftx/Telephus" target="_blank" rel="external">官网</a></li>
<li>txRedis：基于 Twisted 的 Redis 客户端。<a href="https://github.com/deldotdr/txRedis" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="ORM"><a href="#ORM" class="headerlink" title="ORM"></a>ORM</h3><p>实现对象关系映射或数据映射技术的库。</p>
<ul>
<li>关系型数据库<ul>
<li>Django Models：Django 的一部分。<a href="https://docs.djangoproject.com/en/dev/topics/db/models/" target="_blank" rel="external">官网</a></li>
<li>SQLAlchemy：Python SQL 工具以及对象关系映射工具。<a href="http://www.sqlalchemy.org/" target="_blank" rel="external">官网</a><ul>
<li><a href="https://github.com/dahlia/awesome-sqlalchemy" target="_blank" rel="external">awesome-sqlalchemy</a>系列</li>
</ul>
</li>
<li>Peewee：一个小巧，富有表达力的 ORM。<a href="https://github.com/coleifer/peewee" target="_blank" rel="external">官网</a></li>
<li>PonyORM：提供面向生成器的 SQL 接口的 ORM。<a href="https://ponyorm.com/" target="_blank" rel="external">官网</a></li>
<li>python-sql：编写 Python 风格的 SQL 查询。<a href="https://pypi.python.org/pypi/python-sql" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>NoSQL 数据库<ul>
<li>django-mongodb-engine：Django MongoDB 后端。<a href="https://github.com/django-nonrel/mongodb-engine" target="_blank" rel="external">官网</a></li>
<li>PynamoDB：<a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="external">Amazon DynamoDB</a> 的一个 Python 风格接口。<a href="https://github.com/jlafon/PynamoDB" target="_blank" rel="external">官网</a></li>
<li>flywheel：Amazon DynamoDB 的对象映射工具。<a href="https://github.com/mathcamp/flywheel" target="_blank" rel="external">官网</a></li>
<li>MongoEngine：一个Python 对象文档映射工具，用于 MongoDB。<a href="http://mongoengine.org/" target="_blank" rel="external">官网</a></li>
<li>hot-redis：为 Redis 提供 Python 丰富的数据类型。<a href="https://github.com/stephenmcd/hot-redis" target="_blank" rel="external">官网</a></li>
<li>redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。<a href="https://github.com/kiddouk/redisco" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>其他<ul>
<li>butterdb：Google Drive 电子表格的 Python ORM。<a href="https://github.com/Widdershin/butterdb" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="Web-框架"><a href="#Web-框架" class="headerlink" title="Web 框架"></a>Web 框架</h3><p>全栈 Web 框架。</p>
<ul>
<li><a href="http://hao.jobbole.com/django/" target="_blank" rel="external">Django</a>：Python 界最流行的 web 框架。<a href="https://www.djangoproject.com/" target="_blank" rel="external">官网</a><ul>
<li><a href="https://github.com/rosarior/awesome-django" target="_blank" rel="external">awesome-django</a>系列</li>
</ul>
</li>
<li><a href="http://hao.jobbole.com/flask/" target="_blank" rel="external">Flask</a>：一个 Python 微型框架。<a href="http://flask.pocoo.org/" target="_blank" rel="external">官网</a><ul>
<li><a href="https://github.com/rosarior/awesome-django" target="_blank" rel="external">awesome-flask</a>系列</li>
</ul>
</li>
<li>yramid：一个小巧，快速，接地气的开源Python web 框架。<ul>
<li><a href="https://github.com/uralbash/awesome-pyramid" target="_blank" rel="external">awesome-pyramid</a>系列</li>
</ul>
</li>
<li><a href="http://hao.jobbole.com/bottle/" target="_blank" rel="external">Bottle</a>：一个快速小巧，轻量级的 WSGI 微型 web 框架。<a href="http://bottlepy.org/docs/dev/index.html" target="_blank" rel="external">官网</a></li>
<li>CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有WSGI 线程池。<a href="http://www.cherrypy.org/" target="_blank" rel="external">官网</a></li>
<li>TurboGears：一个可以扩展为全栈解决方案的微型框架。<a href="http://www.turbogears.org/" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-webpy/" target="_blank" rel="external">web.py</a>：一个 Python 的 web 框架，既简单，又强大。<a href="http://webpy.org/" target="_blank" rel="external">官网</a></li>
<li>web2py：一个全栈 web 框架和平台，专注于简单易用。<a href="http://www.web2py.com/" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/tornado/" target="_blank" rel="external">Tornado</a>：一个web 框架和异步网络库。<a href="http://www.tornadoweb.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h3><p>允许或拒绝用户访问数据或功能的库。</p>
<ul>
<li>Carteblanche：Module to align code with thoughts of users and designers. Also magically handles navigation and permissions.<a href="https://github.com/neuman/python-carteblanche/" target="_blank" rel="external">官网</a></li>
<li>django-guardian：Django 1.2+ 实现了单个对象权限。<a href="https://github.com/django-guardian/django-guardian" target="_blank" rel="external">官网</a></li>
<li>django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。<a href="https://github.com/dfunckt/django-rules" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h3><p>内容管理系统</p>
<ul>
<li>django-cms：一个开源的，企业级 CMS，基于 Django。<a href="http://www.django-cms.org/en/" target="_blank" rel="external">官网</a></li>
<li>djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。<a href="http://djedi-cms.org/" target="_blank" rel="external">官网</a></li>
<li>FeinCMS：基于 Django 构建的最先进的内容管理系统之一。<a href="http://www.feincms.org/" target="_blank" rel="external">官网</a></li>
<li>Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。<a href="http://kotti.pylonsproject.org/" target="_blank" rel="external">官网</a></li>
<li>Mezzanine：一个强大的，持续的，灵活的内容管理平台。<a href="http://mezzanine.jupo.org/" target="_blank" rel="external">官网</a></li>
<li>Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。<a href="http://opps.github.io/opps/" target="_blank" rel="external">官网</a></li>
<li>Plone：一个构建于开源应用服务器 Zope 之上的 CMS。<a href="https://plone.org/" target="_blank" rel="external">官网</a></li>
<li>Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。<a href="http://quokkaproject.org/" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/wagtail/" target="_blank" rel="external">Wagtail</a>：一个 Django 内容管理系统。<a href="https://wagtail.io/" target="_blank" rel="external">官网</a></li>
<li>Widgy：最新的 CMS 框架，基于 Django。<a href="https://wid.gy/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="电子商务"><a href="#电子商务" class="headerlink" title="电子商务"></a>电子商务</h3><p>用于电子商务以及支付的框架和库。</p>
<ul>
<li>django-oscar：一个用于 Django 的开源的电子商务框架。<a href="http://oscarcommerce.com/" target="_blank" rel="external">官网</a></li>
<li>django-shop：一个基于 Django 的店铺系统。<a href="https://github.com/awesto/django-shop" target="_blank" rel="external">官网</a></li>
<li>Cartridge：一个基于 Mezzanine 构建的购物车应用。<a href="https://github.com/stephenmcd/cartridge" target="_blank" rel="external">官网</a></li>
<li>shoop：一个基于 Django 的开源电子商务平台。<a href="https://www.shoop.io/en/" target="_blank" rel="external">官网</a></li>
<li>alipay：非官方的 Python 支付宝 API。<a href="https://github.com/lxneng/alipay" target="_blank" rel="external">官网</a></li>
<li>merchant：一个可以接收来自多种支付平台支付的 Django 应用。<a href="https://github.com/agiliq/merchant" target="_blank" rel="external">官网</a></li>
<li>money：货币类库with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.<a href="https://github.com/carlospalol/money" target="_blank" rel="external">官网</a></li>
<li>python-currencies：显示货币格式以及它的数值。<a href="https://github.com/Alir3z4/python-currencies" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="RESTful-API"><a href="#RESTful-API" class="headerlink" title="RESTful API"></a>RESTful API</h3><p>用来开发RESTful APIs的库</p>
<ul>
<li>Django<ul>
<li>django-rest-framework：一个强大灵活的工具，用来构建 web API。<a href="http://www.django-rest-framework.org/" target="_blank" rel="external">官网</a></li>
<li>django-tastypie：为Django 应用开发API。<a href="http://tastypieapi.org/" target="_blank" rel="external">官网</a></li>
<li>django-formapi：为 Django 的表单验证，创建 JSON APIs 。<a href="https://github.com/5monkeys/django-formapi" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Flask<ul>
<li>flask-api：为 flask 开发的，可浏览 Web APIs 。<a href="http://www.flaskapi.org/" target="_blank" rel="external">官网</a></li>
<li>flask-restful：为 flask 快速创建REST APIs 。<a href="http://flask-restful.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。<a href="https://flask-restless.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>flask-api-utils：为 Flask 处理 API 表示和验证。<a href="https://github.com/marselester/flask-api-utils" target="_blank" rel="external">官网</a></li>
<li>eve：REST API 框架，由 Flask, MongoDB 等驱动。<a href="https://github.com/nicolaiarocci/eve" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Pyramid<ul>
<li>cornice：一个Pyramid 的 REST 框架 。<a href="https://cornice.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>与框架无关的<ul>
<li>falcon：一个用来建立云 API 和 web app 后端的噶性能框架。<a href="http://falconframework.org/" target="_blank" rel="external">官网</a></li>
<li>sandman：为现存的数据库驱动系统自动创建 REST APIs 。<a href="https://github.com/jeffknupp/sandman" target="_blank" rel="external">官网</a></li>
<li>restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。<a href="http://restless.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。<a href="https://github.com/vertical-knowledge/ripozo" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>实现验证方案的库。</p>
<ul>
<li>OAuth<ul>
<li>Authomatic：简单但是强大的框架，身份验证/授权客户端。<a href="http://peterhudec.github.io/authomatic/" target="_blank" rel="external">官网</a></li>
<li>django-allauth：Django 的验证应用。<a href="https://github.com/pennersr/django-allauth" target="_blank" rel="external">官网</a></li>
<li>django-oauth-toolkit：为 Django 用户准备的 OAuth2。<a href="https://github.com/evonove/django-oauth-toolkit" target="_blank" rel="external">官网</a></li>
<li>django-oauth2-provider：为 Django 应用提供 OAuth2 接入。<a href="https://github.com/caffeinehit/django-oauth2-provider" target="_blank" rel="external">官网</a></li>
<li>Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。<a href="https://github.com/lepture/flask-oauthlib" target="_blank" rel="external">官网</a></li>
<li>OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。<a href="https://github.com/idan/oauthlib" target="_blank" rel="external">官网</a></li>
<li>python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。<a href="https://github.com/joestump/python-oauth2" target="_blank" rel="external">官网</a></li>
<li>python-social-auth：一个设置简单的社会化验证方式。<a href="https://github.com/omab/python-social-auth" target="_blank" rel="external">官网</a></li>
<li>rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。<a href="https://github.com/litl/rauth" target="_blank" rel="external">官网</a></li>
<li>sanction：一个超级简单的OAuth2 客户端实现。<a href="https://github.com/demianbrecht/sanction" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>其他<ul>
<li>jose：JavaScript 对象签名和加密草案的实现。<a href="https://github.com/demonware/jose" target="_blank" rel="external">官网</a></li>
<li>PyJWT：JSON Web 令牌草案 01。<a href="https://github.com/jpadilla/pyjwt" target="_blank" rel="external">官网</a></li>
<li>python-jws：JSON Web 签名草案 02 的实现。<a href="https://github.com/brianloveswords/python-jws" target="_blank" rel="external">官网</a></li>
<li>python-jwt：一个用来生成和验证 JSON Web 令牌的模块。<a href="https://github.com/davedoesdev/python-jwt" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="模板引擎"><a href="#模板引擎" class="headerlink" title="模板引擎"></a>模板引擎</h3><p>模板生成和词法解析的库和工具。</p>
<ul>
<li>Jinja2：一个现代的，对设计师友好的模板引擎。<a href="https://github.com/mitsuhiko/jinja2" target="_blank" rel="external">官网</a></li>
<li>Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。<a href="https://chameleon.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Genshi：Python 模板工具，用以生成 web 感知的结果。<a href="http://genshi.edgewall.org/" target="_blank" rel="external">官网</a></li>
<li>Mako：Python 平台的超高速轻量级模板。<a href="http://www.makotemplates.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>处理事件以及任务队列的库。</p>
<ul>
<li>celery：一个异步任务队列/作业队列，基于分布式消息传递。<a href="http://www.celeryproject.org/" target="_blank" rel="external">官网</a></li>
<li>huey：小型多线程任务队列。<a href="https://github.com/coleifer/huey" target="_blank" rel="external">官网</a></li>
<li>mrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。<a href="https://github.com/pricingassistant/mrq" target="_blank" rel="external">官网</a></li>
<li>rq：简单的 Python 作业队列。<a href="http://python-rq.org/" target="_blank" rel="external">官网</a></li>
<li>simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。<a href="https://github.com/rdegges/simpleq" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>对数据进行索引和执行搜索查询的库和软件。</p>
<ul>
<li>django-haystack：Django 模块化搜索。<a href="https://github.com/django-haystack/django-haystack" target="_blank" rel="external">官网</a></li>
<li>elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。<a href="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html" target="_blank" rel="external">官网</a></li>
<li>elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。<a href="https://github.com/elastic/elasticsearch-dsl-py" target="_blank" rel="external">官网</a></li>
<li>solrpy：<a href="http://lucene.apache.org/solr/" target="_blank" rel="external">solr</a>的 Python 客户端。<a href="https://github.com/edsu/solrpy" target="_blank" rel="external">官网</a></li>
<li>Whoosh：一个快速的纯 Python 搜索引擎库。<a href="http://whoosh.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="动态消息"><a href="#动态消息" class="headerlink" title="动态消息"></a>动态消息</h3><p>用来创建用户活动的库。</p>
<ul>
<li>django-activity-stream：从你的站点行为中生成通用活动信息流。<a href="https://github.com/justquick/django-activity-stream" target="_blank" rel="external">官网</a></li>
<li>Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。<a href="https://github.com/tschellenbach/Stream-Framework" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h3><p>管理、压缩、缩小网站资源的工具。</p>
<ul>
<li>django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。<a href="https://github.com/django-compressor/django-compressor" target="_blank" rel="external">官网</a></li>
<li>django-storages：一个针对 Django 的自定义存储后端的工具集合。<a href="http://django-storages.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。<a href="http://www.fanstatic.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。<a href="http://fileconveyor.org/" target="_blank" rel="external">官网</a></li>
<li>Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。<a href="http://flask-assets.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。<a href="https://github.com/jaysonsantos/jinja-assets-compressor" target="_blank" rel="external">官网</a></li>
<li>webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。<a href="http://webassets.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存数据的库。</p>
<ul>
<li>Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python脚本和应用上。<a href="http://beaker.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>django-cache-machine：Django 模型的自动缓存和失效。<a href="https://github.com/django-cache-machine/django-cache-machine" target="_blank" rel="external">官网</a></li>
<li>django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。<a href="https://github.com/Suor/django-cacheops" target="_blank" rel="external">官网</a></li>
<li>django-viewlet：渲染模板，同时具有额外的缓存控制功能。<a href="https://github.com/5monkeys/django-viewlet" target="_blank" rel="external">官网</a></li>
<li>dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。<a href="http://dogpilecache.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。<a href="https://pypi.python.org/pypi/HermesCache" target="_blank" rel="external">官网</a></li>
<li>johnny-cache：django应用缓存框架。<a href="https://github.com/jmoiron/johnny-cache" target="_blank" rel="external">官网</a></li>
<li>pylibmc：<a href="http://libmemcached.org/libMemcached.html" target="_blank" rel="external">libmemcached</a> 接口的 Python 封装。<a href="https://github.com/lericson/pylibmc" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="电子邮件"><a href="#电子邮件" class="headerlink" title="电子邮件"></a>电子邮件</h3><p>用来发送和解析电子邮件的库。</p>
<ul>
<li>django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。<a href="https://github.com/StreetVoice/django-celery-ses" target="_blank" rel="external">官网</a></li>
<li>envelopes：供人类使用的电子邮件库。<a href="http://tomekwojcik.github.io/envelopes/" target="_blank" rel="external">官网</a></li>
<li>flanker：一个 email 地址和 Mime 解析库。<a href="https://github.com/mailgun/flanker" target="_blank" rel="external">官网</a></li>
<li>imbox：Python IMAP 库<a href="https://github.com/martinrusev/imbox" target="_blank" rel="external">官网</a></li>
<li>inbox.py：Python SMTP 服务器。<a href="https://github.com/kennethreitz/inbox.py" target="_blank" rel="external">官网</a></li>
<li>inbox：一个开源电子邮件工具箱。<a href="https://github.com/nylas/sync-engine" target="_blank" rel="external">官网</a></li>
<li>lamson：Python 风格的 SMTP 应用服务器。<a href="https://github.com/zedshaw/lamson" target="_blank" rel="external">官网</a></li>
<li>mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。<a href="https://github.com/WoLpH/mailjet" target="_blank" rel="external">官网</a></li>
<li>marrow.mailer：高性能可扩展邮件分发框架。<a href="https://github.com/marrow/marrow.mailer" target="_blank" rel="external">官网</a></li>
<li>modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。<a href="https://github.com/tonioo/modoboa" target="_blank" rel="external">官网</a></li>
<li>pyzmail：创建，发送和解析电子邮件。<a href="http://www.magiksys.net/pyzmail/" target="_blank" rel="external">官网</a></li>
<li>Talon：Mailgun 库，用来抽取信息和签名。<a href="https://github.com/mailgun/talon" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="国际化"><a href="#国际化" class="headerlink" title="国际化"></a>国际化</h3><p>用来进行国际化的库。</p>
<ul>
<li>Babel：一个Python 的国际化库。<a href="http://babel.pocoo.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Korean：一个韩语词态库。<a href="https://korean.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="URL处理"><a href="#URL处理" class="headerlink" title="URL处理"></a>URL处理</h3><p>解析URLs的库</p>
<ul>
<li>furl：一个让处理 URL 更简单小型 Python 库。<a href="https://github.com/gruns/furl" target="_blank" rel="external">官网</a></li>
<li>purl：一个简单的，不可变的URL类，具有简洁的 API 来进行询问和处理。<a href="https://github.com/codeinthehole/purl" target="_blank" rel="external">官网</a></li>
<li>pyshorteners：一个纯 Python URL 缩短库。<a href="https://github.com/ellisonleao/pyshorteners" target="_blank" rel="external">官网</a></li>
<li>shorturl：生成短小 URL 和类似 bit.ly 短链的Python 实现。<a href="https://github.com/Alir3z4/python-shorturl" target="_blank" rel="external">官网</a></li>
<li>webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado和 Pyramid。<a href="https://github.com/sloria/webargs" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="HTML处理"><a href="#HTML处理" class="headerlink" title="HTML处理"></a>HTML处理</h3><p>处理 HTML和XML的库。</p>
<ul>
<li>BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。<a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="external">官网</a></li>
<li>bleach：一个基于白名单的 HTML 清理和文本链接库。<a href="http://bleach.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>cssutils：一个 Python 的 CSS 库。<a href="https://pypi.python.org/pypi/cssutils/" target="_blank" rel="external">官网</a></li>
<li>html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。<a href="https://github.com/html5lib/html5lib-python" target="_blank" rel="external">官网</a></li>
<li>lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。<a href="http://lxml.de/" target="_blank" rel="external">官网</a></li>
<li>MarkupSafe：为Python 实现 XML/HTML/XHTML 标记安全字符串。<a href="https://github.com/mitsuhiko/markupsafe" target="_blank" rel="external">官网</a></li>
<li>pyquery：一个解析 HTML 的库，类似 jQuery。<a href="https://github.com/gawel/pyquery" target="_blank" rel="external">官网</a></li>
<li>untangle：将XML文档转换为Python对象，使其可以方便的访问。<a href="https://github.com/stchris/untangle" target="_blank" rel="external">官网</a></li>
<li>xhtml2pdf：HTML/CSS 转 PDF 工具。<a href="https://github.com/xhtml2pdf/xhtml2pdf" target="_blank" rel="external">官网</a></li>
<li>xmltodict：像处理 JSON 一样处理 XML。<a href="https://github.com/martinblech/xmltodict" target="_blank" rel="external">官网</a></li>
</ul>
<p>爬取网络站点的库</p>
<ul>
<li>Scrapy：一个快速高级的屏幕爬取及网页采集框架。<a href="http://scrapy.org/" target="_blank" rel="external">官网</a></li>
<li>cola：一个分布式爬虫框架。<a href="https://github.com/chineking/cola" target="_blank" rel="external">官网</a></li>
<li>Demiurge：基于PyQuery 的爬虫微型框架。<a href="https://github.com/matiasb/demiurge" target="_blank" rel="external">官网</a></li>
<li>feedparser：通用 feed 解析器。<a href="http://pythonhosted.org/feedparser/" target="_blank" rel="external">官网</a></li>
<li>Grab：站点爬取框架。<a href="http://grablib.org/" target="_blank" rel="external">官网</a></li>
<li>MechanicalSoup：用于自动和网络站点交互的 Python 库。<a href="https://github.com/hickford/MechanicalSoup" target="_blank" rel="external">官网</a></li>
<li>portia：Scrapy 可视化爬取。<a href="https://github.com/scrapinghub/portia" target="_blank" rel="external">官网</a></li>
<li>pyspider：一个强大的爬虫系统。<a href="https://github.com/binux/pyspider" target="_blank" rel="external">官网</a></li>
<li>RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。<a href="https://github.com/jmcarp/robobrowser" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="网页内容提取"><a href="#网页内容提取" class="headerlink" title="网页内容提取"></a>网页内容提取</h3><p>用于进行网页内容提取的库。</p>
<ul>
<li>Haul：一个可以扩展的图像爬取工具。<a href="https://github.com/vinta/Haul" target="_blank" rel="external">官网</a></li>
<li>html2text：将 HTML 转换为 Markdown 格式文本<a href="https://github.com/Alir3z4/html2text" target="_blank" rel="external">官网</a></li>
<li>lassie：人性化的网页内容检索库。<a href="https://github.com/michaelhelmick/lassie" target="_blank" rel="external">官网</a></li>
<li>micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。<a href="https://github.com/coleifer/micawber" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-newspaper/" target="_blank" rel="external">newspaper</a>：使用 Python 进行新闻提取，文章提取以及内容策展。<a href="https://github.com/codelucas/newspaper" target="_blank" rel="external">官网</a></li>
<li>opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python模块。<a href="https://github.com/erikriver/opengraph" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-goose/" target="_blank" rel="external">python-goose</a>：HTML内容/文章提取器。<a href="https://github.com/grangier/python-goose" target="_blank" rel="external">官网</a></li>
<li>python-readability：arc90 公司 readability 工具的 Python 高速端口。<a href="https://github.com/buriy/python-readability" target="_blank" rel="external">官网</a></li>
<li>sanitize：为杂乱的数据世界带来调理性。<a href="https://github.com/Alir3z4/python-sanitize" target="_blank" rel="external">官网</a></li>
<li>sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。<a href="https://github.com/miso-belica/sumy" target="_blank" rel="external">官网</a></li>
<li>textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。<a href="https://github.com/deanmalmgren/textract" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="表单"><a href="#表单" class="headerlink" title="表单"></a>表单</h3><p>进行表单操作的库。</p>
<ul>
<li>Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。<a href="http://deform.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>django-bootstrap3：集成了 Bootstrap 3 的 Django。<a href="https://github.com/dyve/django-bootstrap3" target="_blank" rel="external">官网</a></li>
<li>django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don’t repeat yourself） 的方式来创建美观的表单。<a href="http://django-crispy-forms.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>django-remote-forms：一个平台独立的 Django 表单序列化工具。<a href="https://github.com/WiserTogether/django-remote-forms" target="_blank" rel="external">官网</a></li>
<li>WTForms：一个灵活的表单验证和呈现库。<a href="http://wtforms.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。<a href="http://wtforms-json.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="数据验证"><a href="#数据验证" class="headerlink" title="数据验证"></a>数据验证</h3><p>数据验证库。多用于表单验证。</p>
<ul>
<li>Cerberus：A mappings-validator with a variety of rules, normalization-features and simple customization that uses a pythonic schema-definition.<a href="http://docs.python-cerberus.org/en/stable/" target="_blank" rel="external">官网</a></li>
<li>colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。<a href="http://docs.pylonsproject.org/projects/colander/en/latest/" target="_blank" rel="external">官网</a></li>
<li>kmatch：一种用于匹配/验证/筛选 Python 字典的语言。<a href="https://github.com/ambitioninc/kmatch" target="_blank" rel="external">官网</a></li>
<li>schema：一个用于对 Python 数据结构进行验证的库。<a href="https://github.com/keleshev/schema" target="_blank" rel="external">官网</a></li>
<li>Schematics：数据结构验证。<a href="https://github.com/schematics/schematics" target="_blank" rel="external">官网</a></li>
<li>valideer：轻量级可扩展的数据验证和适配库。<a href="https://github.com/podio/valideer" target="_blank" rel="external">官网</a></li>
<li>voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python的 JSON，YAML 等数据。<a href="https://github.com/alecthomas/voluptuous" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="反垃圾技术"><a href="#反垃圾技术" class="headerlink" title="反垃圾技术"></a>反垃圾技术</h3><p>帮助你和电子垃圾进行战斗的库。</p>
<ul>
<li>django-simple-captcha：一个简单、高度可定制的Django 应用，可以为任何Django表单添加验证码。<a href="https://github.com/mbi/django-simple-captcha" target="_blank" rel="external">官网</a></li>
<li>django-simple-spam-blocker：一个用于Django的简单的电子垃圾屏蔽工具。<a href="https://github.com/moqada/django-simple-spam-blocker" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h3><p>用来进行标记的库。</p>
<ul>
<li>django-taggit：简单的 Django 标记工具。<a href="https://github.com/alex/django-taggit" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="管理面板"><a href="#管理面板" class="headerlink" title="管理面板"></a>管理面板</h3><p>管理界面库。</p>
<ul>
<li>Ajenti：一个你的服务器值得拥有的管理面板。<a href="https://github.com/Eugeny/ajenti" target="_blank" rel="external">官网</a></li>
<li>django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。<a href="http://djangosuit.com/" target="_blank" rel="external">官网</a></li>
<li>django-xadmin：Django admin 的一个替代品，具有很多不错的功能。<a href="https://github.com/sshwsfc/django-xadmin" target="_blank" rel="external">官网</a></li>
<li>flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。<a href="https://github.com/flask-admin/flask-admin" target="_blank" rel="external">官网</a></li>
<li>flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。<a href="https://github.com/mher/flower" target="_blank" rel="external">官网</a></li>
<li>Grappelli：Django 管理界面的一个漂亮的皮肤。<a href="http://grappelliproject.com/" target="_blank" rel="external">官网</a></li>
<li>Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。<a href="https://github.com/wooey/wooey" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="静态站点生成器"><a href="#静态站点生成器" class="headerlink" title="静态站点生成器"></a>静态站点生成器</h3><p>静态站点生成器是一个软件，它把文本和模板作为输入，然后输出HTML文件。</p>
<ul>
<li>Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。<a href="http://blog.getpelican.com/" target="_blank" rel="external">官网</a></li>
<li>Cactus：为设计师设计的静态站点生成器。<a href="https://github.com/koenbok/Cactus/" target="_blank" rel="external">官网</a></li>
<li>Hyde：基于 Jinja2 的静态站点生成器。<a href="http://hyde.github.io/" target="_blank" rel="external">官网</a></li>
<li>Nikola：一个静态网站和博客生成器。<a href="https://www.getnikola.com/" target="_blank" rel="external">官网</a></li>
<li>Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由Sphinx驱动。<a href="http://tinkerer.me/" target="_blank" rel="external">官网</a></li>
<li>Lektor：一个简单易用的静态 CMS 和博客引擎。<a href="https://www.getlektor.com/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>操作系统进程启动及通信库。</p>
<ul>
<li>envoy：比 Python <a href="https://docs.python.org/2/library/subprocess.html" target="_blank" rel="external">subprocess</a> 模块更人性化。<a href="https://github.com/kennethreitz/envoy" target="_blank" rel="external">官网</a></li>
<li>sarge：另一 种 subprocess 模块的封装。<a href="http://sarge.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>sh：一个完备的 subprocess 替代库。<a href="https://github.com/amoffat/sh" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="并发和并行"><a href="#并发和并行" class="headerlink" title="并发和并行"></a>并发和并行</h3><p>用以进行并发和并行操作的库。</p>
<ul>
<li>multiprocessing：(Python 标准库) 基于进程的“线程”接口。<a href="https://docs.python.org/2/library/multiprocessing.html" target="_blank" rel="external">官网</a></li>
<li>threading：(Python 标准库)更高层的线程接口。<a href="https://docs.python.org/2/library/threading.html" target="_blank" rel="external">官网</a></li>
<li>eventlet：支持 WSGI 的异步框架。<a href="http://eventlet.net/" target="_blank" rel="external">官网</a></li>
<li>gevent：一个基于协程的 Python 网络库，使用<a href="https://github.com/python-greenlet/greenlet" target="_blank" rel="external">greenlet</a>。<a href="http://www.gevent.org/" target="_blank" rel="external">官网</a></li>
<li>Tomorrow：用于产生异步代码的神奇的装饰器语法实现。<a href="https://github.com/madisonmay/Tomorrow" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>用于网络编程的库。</p>
<ul>
<li>asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。<a href="https://docs.python.org/3/library/asyncio.html" target="_blank" rel="external">官网</a></li>
<li>Twisted：一个事件驱动的网络引擎。<a href="https://twistedmatrix.com/trac/" target="_blank" rel="external">官网</a></li>
<li>pulsar：事件驱动的并发框架。<a href="https://github.com/quantmind/pulsar" target="_blank" rel="external">官网</a></li>
<li>diesel：基于Greenlet 的事件 I/O 框架。<a href="https://github.com/dieseldev/diesel" target="_blank" rel="external">官网</a></li>
<li>pyzmq：一个 ZeroMQ 消息库的 Python 封装。<a href="http://zeromq.github.io/pyzmq/" target="_blank" rel="external">官网</a></li>
<li>txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。<a href="https://github.com/smira/txZMQ" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h3><p>帮助使用WebSocket的库。</p>
<ul>
<li>AutobahnPython：给 Python 、使用的 WebSocket &amp; WAMP 基于 Twisted 和 <a href="https://docs.python.org/3/library/asyncio.html" target="_blank" rel="external">asyncio</a>。<a href="https://github.com/crossbario/autobahn-python" target="_blank" rel="external">官网</a></li>
<li>Crossbar：开源统一应用路由(Websocket &amp; WAMP for Python on Autobahn).<a href="https://github.com/crossbario/crossbar/" target="_blank" rel="external">官网</a></li>
<li>django-socketio：给 Django 用的 WebSockets。<a href="https://github.com/stephenmcd/django-socketio" target="_blank" rel="external">官网</a></li>
<li>WebSocket-for-Python：为Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。<a href="https://github.com/Lawouach/WebSocket-for-Python" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="WSGI-服务器"><a href="#WSGI-服务器" class="headerlink" title="WSGI 服务器"></a>WSGI 服务器</h3><p>兼容 WSGI 的 web 服务器</p>
<ul>
<li>gunicorn：Pre-forked, 部分是由 C 语言编写的。<a href="https://pypi.python.org/pypi/gunicorn" target="_blank" rel="external">官网</a></li>
<li>uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。<a href="https://uwsgi-docs.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>bjoern：异步，非常快速，由 C 语言编写。<a href="https://pypi.python.org/pypi/bjoern" target="_blank" rel="external">官网</a></li>
<li>fapws3：异步 (仅对于网络端)，由 C 语言编写。<a href="http://www.fapws.org/" target="_blank" rel="external">官网</a></li>
<li>meinheld：异步，部分是由 C 语言编写的。<a href="https://pypi.python.org/pypi/meinheld" target="_blank" rel="external">官网</a></li>
<li>netius：异步，非常快速。<a href="https://github.com/hivesolutions/netius" target="_blank" rel="external">官网</a></li>
<li>paste：多线程，稳定，久经考验。<a href="http://pythonpaste.org/" target="_blank" rel="external">官网</a></li>
<li>rocket：多线程。<a href="https://pypi.python.org/pypi/rocket" target="_blank" rel="external">官网</a></li>
<li>waitress：多线程, 是它驱动着 Pyramid 框架。<a href="https://waitress.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。<a href="http://werkzeug.pocoo.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="RPC-服务器"><a href="#RPC-服务器" class="headerlink" title="RPC 服务器"></a>RPC 服务器</h3><p>兼容 RPC 的服务器。</p>
<ul>
<li>SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。<a href="https://github.com/joshmarshall/jsonrpclib/" target="_blank" rel="external">官网</a></li>
<li>SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。<a href="https://docs.python.org/2/library/simplexmlrpcserver.html" target="_blank" rel="external">官网</a></li>
<li>zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。<a href="https://github.com/0rpc/zerorpc-python" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="密码学"><a href="#密码学" class="headerlink" title="密码学"></a>密码学</h3><ul>
<li>cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。<a href="https://cryptography.io/en/latest/" target="_blank" rel="external">官网</a></li>
<li>hashids：在 Python 中实现 <a href="http://hashids.org/" target="_blank" rel="external">hashids</a> 。<a href="https://github.com/davidaurelio/hashids-python" target="_blank" rel="external">官网</a></li>
<li>Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。<a href="http://www.paramiko.org/" target="_blank" rel="external">官网</a></li>
<li>Passlib：安全密码存储／哈希库，<a href="https://pythonhosted.org/passlib/" target="_blank" rel="external">官网</a></li>
<li>PyCrypto：Python 密码学工具箱。<a href="https://www.dlitz.net/software/pycrypto/" target="_blank" rel="external">官网</a></li>
<li>PyNacl：网络和密码学(NaCl) 库的 Python 绑定。<a href="https://github.com/pyca/pynacl" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="图形用户界面"><a href="#图形用户界面" class="headerlink" title="图形用户界面"></a>图形用户界面</h3><p>用来创建图形用户界面程序的库。</p>
<ul>
<li>curses：内建的 <a href="http://www.gnu.org/software/ncurses/" target="_blank" rel="external">ncurses</a> 封装，用来创建终端图形用户界面。<a href="https://docs.python.org/2/library/curses.html#module-curses" target="_blank" rel="external">官网</a></li>
<li>enaml：使用类似 QML 的Declaratic语法来创建美观的用户界面。<a href="https://github.com/nucleic/enaml" target="_blank" rel="external">官网</a></li>
<li>kivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS平台上。<a href="https://kivy.org/" target="_blank" rel="external">官网</a></li>
<li>pyglet：一个Python 的跨平台窗口及多媒体库。<a href="https://bitbucket.org/pyglet/pyglet/wiki/Home" target="_blank" rel="external">官网</a></li>
<li>PyQt：跨平台用户界面框架 <a href="http://www.qt.io/" target="_blank" rel="external">Qt</a> 的 Python 绑定 ，支持Qt v4 和 Qt v5。<a href="https://riverbankcomputing.com/software/pyqt/intro" target="_blank" rel="external">官网</a></li>
<li>PySide：P跨平台用户界面框架 <a href="http://www.qt.io/" target="_blank" rel="external">Qt</a> 的 Python 绑定 ，支持Qt v4。<a href="https://wiki.qt.io/PySide" target="_blank" rel="external">官网</a></li>
<li>Tkinter：Tkinter 是 Python GUI 的一个事实标准库。<a href="https://wiki.python.org/moin/TkInter" target="_blank" rel="external">官网</a></li>
<li>Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。<a href="https://github.com/pybee/toga" target="_blank" rel="external">官网</a></li>
<li>urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。<a href="http://urwid.org/" target="_blank" rel="external">官网</a></li>
<li>wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。<a href="http://wxpython.org/" target="_blank" rel="external">官网</a></li>
<li>PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定<a href="https://wiki.gnome.org/Projects/PyGObject" target="_blank" rel="external">官网</a></li>
<li>Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。<a href="https://github.com/zoofIO/flexx" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="游戏开发"><a href="#游戏开发" class="headerlink" title="游戏开发"></a>游戏开发</h3><p>超赞的游戏开发库。</p>
<ul>
<li>Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。<a href="http://cocos2d.org/" target="_blank" rel="external">官网</a></li>
<li>Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用C++编写, 针对 Python 进行了完全的封装。<a href="https://www.panda3d.org/" target="_blank" rel="external">官网</a></li>
<li>Pygame：Pygame 是一组 Python 模块，用来编写游戏。<a href="http://www.pygame.org/news.html" target="_blank" rel="external">官网</a></li>
<li>PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。<a href="http://www.ogre3d.org/tikiwiki/PyOgre" target="_blank" rel="external">官网</a></li>
<li>PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。<a href="http://pyopengl.sourceforge.net/" target="_blank" rel="external">官网</a></li>
<li>PySDL2：SDL2 库的封装，基于 ctypes。<a href="http://pysdl2.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>RenPy：一个视觉小说（visual novel）引擎。<a href="http://www.renpy.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>用来生成和操作日志的库。</p>
<ul>
<li>logging：(Python 标准库) 为 Python 提供日志功能。<a href="https://docs.python.org/2/library/logging.html" target="_blank" rel="external">官网</a></li>
<li>logbook：Logging 库的替代品。<a href="http://pythonhosted.org/Logbook/" target="_blank" rel="external">官网</a></li>
<li>Eliot：为复杂的和分布式系统创建日志。<a href="https://eliot.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Raven：Sentry的 Python 客户端。<a href="http://raven.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Sentry：实时记录和收集日志的服务器。<a href="https://pypi.python.org/pypi/sentry" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><p>进行代码库测试和生成测试数据的库。</p>
<ul>
<li>测试框架<ul>
<li>unittest：(Python 标准库) 单元测试框架。<a href="https://docs.python.org/2/library/unittest.html" target="_blank" rel="external">官网</a></li>
<li>nose：nose 扩展了 unittest 的功能。<a href="https://nose.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>contexts：一个 Python 3.3+ 的 BDD 框架。受到C#</li>
<li>hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。<a href="https://github.com/DRMacIver/hypothesis" target="_blank" rel="external">官网</a></li>
<li>mamba：Python 的终极测试工具， 拥护BDD。<a href="http://nestorsalceda.github.io/mamba/" target="_blank" rel="external">官网</a></li>
<li>PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。<a href="https://github.com/asweigart/pyautogui" target="_blank" rel="external">官网</a></li>
<li>pyshould：Should 风格的断言，基于 <a href="https://github.com/hamcrest/PyHamcrest" target="_blank" rel="external">PyHamcrest</a>。<a href="https://github.com/drslump/pyshould" target="_blank" rel="external">官网</a></li>
<li>pytest：一个成熟的全功能 Python 测试工具。<a href="http://pytest.org/latest/" target="_blank" rel="external">官网</a></li>
<li>green：干净，多彩的测试工具。<a href="https://github.com/CleanCut/green" target="_blank" rel="external">官网</a></li>
<li>pyvows：BDD 风格的测试工具，受Vows.js的启发。<a href="http://heynemann.github.io/pyvows/" target="_blank" rel="external">官网</a>-</li>
<li>Robot Framework：一个通用的自动化测试框架。<a href="https://github.com/robotframework/robotframework" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Web 测试<ul>
<li>Selenium：<a href="http://www.seleniumhq.org/" target="_blank" rel="external">Selenium</a> WebDriver 的 Python 绑定。<a href="https://pypi.python.org/pypi/selenium" target="_blank" rel="external">官网</a></li>
<li>locust：使用 Python 编写的，可扩展的用户加载测试工具。<a href="https://github.com/locustio/locust" target="_blank" rel="external">官网</a></li>
<li>sixpack：一个和语言无关的 A/B 测试框架。<a href="https://github.com/seatgeek/sixpack" target="_blank" rel="external">官网</a></li>
<li>splinter：开源的 web 应用测试工具。<a href="https://splinter.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Mock测试<ul>
<li>mock：(Python 标准库) 一个用于伪造测试的库。<a href="https://docs.python.org/3/library/unittest.mock.html" target="_blank" rel="external">官网</a></li>
<li>doublex：Python 的一个功能强大的 doubles  测试框架。<a href="https://pypi.python.org/pypi/doublex" target="_blank" rel="external">官网</a></li>
<li>freezegun：通过伪造日期模块来生成不同的时间。<a href="https://github.com/spulec/freezegun" target="_blank" rel="external">官网</a></li>
<li>httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。<a href="https://github.com/patrys/httmock" target="_blank" rel="external">官网</a></li>
<li>httpretty：Python 的 HTTP 请求 mock 工具。<a href="http://falcao.it/HTTPretty/" target="_blank" rel="external">官网</a></li>
<li>responses：伪造 Python 中的 requests 库的一个通用库。<a href="https://github.com/getsentry/responses" target="_blank" rel="external">官网</a></li>
<li>VCR.py：在你的测试中记录和重放 HTTP 交互。<a href="https://github.com/kevin1024/vcrpy" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>对象工厂<ul>
<li>factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。<a href="https://github.com/rbarrois/factoryboy" target="_blank" rel="external">官网</a></li>
<li>mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。<a href="https://github.com/klen/mixer" target="_blank" rel="external">官网</a></li>
<li>modelmommy：为 Django 测试创建随机固件<a href="https://github.com/vandersonmota/modelmommy" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>代码覆盖率<ul>
<li>coverage：代码覆盖率测量。<a href="https://pypi.python.org/pypi/coverage" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>伪数据<ul>
<li>faker：一个 Python 库，用来生成伪数据。<a href="http://www.joke2k.net/faker/" target="_blank" rel="external">官网</a></li>
<li>fake2db：伪数据库生成器。<a href="https://github.com/emirozer/fake2db" target="_blank" rel="external">官网</a></li>
<li>radar：生成随机的日期/时间。<a href="https://pypi.python.org/pypi/radar" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>错误处理<ul>
<li>FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。<a href="https://github.com/ajalt/fuckitpy" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="代码分析和Lint工具"><a href="#代码分析和Lint工具" class="headerlink" title="代码分析和Lint工具"></a>代码分析和Lint工具</h3><p>进行代码分析，解析和操作代码库的库和工具。</p>
<ul>
<li>代码分析<ul>
<li>code2flow：把你的 Python 和 JavaScript 代码转换为流程图。<a href="https://github.com/scottrogowski/code2flow" target="_blank" rel="external">官网</a></li>
<li>pycallgraph：这个库可以把你的Python 应用的流程(调用图)进行可视化。<a href="https://github.com/gak/pycallgraph" target="_blank" rel="external">官网</a></li>
<li>pysonar2：Python 类型推断和检索工具。<a href="https://github.com/yinwang0/pysonar2" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Lint工具<ul>
<li>Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。<a href="https://pypi.python.org/pypi/flake8" target="_blank" rel="external">官网</a></li>
<li>Pylint：一个完全可定制的源码分析器。<a href="http://www.pylint.org/" target="_blank" rel="external">官网</a></li>
<li>pylama：Python 和 JavaScript 的代码审查工具。<a href="https://pylama.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="Debugging-Tools"><a href="#Debugging-Tools" class="headerlink" title="Debugging Tools"></a>Debugging Tools</h3><p>用来进行代码调试的库。</p>
<ul>
<li>调试器<ul>
<li>ipdb：IPython 启用的 <a href="https://docs.python.org/2/library/pdb.html" target="_blank" rel="external">pdb</a>。<a href="https://pypi.python.org/pypi/ipdb" target="_blank" rel="external">官网</a></li>
<li>pudb：全屏，基于控制台的 Python 调试器。<a href="https://pypi.python.org/pypi/pudb" target="_blank" rel="external">官网</a></li>
<li>pyringe：可以在 Python 进程中附加和注入代码的调试器。<a href="https://github.com/google/pyringe" target="_blank" rel="external">官网</a></li>
<li>wdb：一个奇异的 web 调试器，通过 WebSockets 工作。<a href="https://github.com/Kozea/wdb" target="_blank" rel="external">官网</a></li>
<li>winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。<a href="http://winpdb.org/" target="_blank" rel="external">官网</a></li>
<li>django-debug-toolbar：为 Django 显示各种调试信息。<a href="https://github.com/django-debug-toolbar/django-debug-toolbar" target="_blank" rel="external">官网</a></li>
<li>django-devserver：一个 Django 运行服务器的替代品。<a href="https://github.com/dcramer/django-devserver" target="_blank" rel="external">官网</a></li>
<li>flask-debugtoolbar：django-debug-toolbar 的 flask 版。<a href="https://github.com/mgood/flask-debugtoolbar" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>性能分析器<ul>
<li>lineprofiler：逐行性能分析。<a href="https://github.com/rkern/lineprofiler" target="_blank" rel="external">官网</a></li>
<li>memoryprofiler：监控 Python 代码的内存使用。<a href="https://github.com/fabianp/memoryprofiler" target="_blank" rel="external">官网</a></li>
<li>profiling：一个交互式 Python 性能分析工具。<a href="https://github.com/what-studio/profiling" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>其他<ul>
<li>pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。<a href="https://github.com/eliben/pyelftools" target="_blank" rel="external">官网</a></li>
<li>python-statsd：<a href="https://github.com/etsy/statsd/" target="_blank" rel="external">statsd</a> 服务器的 Python 客户端。<a href="https://github.com/WoLpH/python-statsd" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="Science-and-Data-Analysis"><a href="#Science-and-Data-Analysis" class="headerlink" title="Science and Data Analysis"></a>Science and Data Analysis</h3><p>用来进行科学计算和数据分析的库。</p>
<ul>
<li>astropy：一个天文学 Python 库。<a href="http://www.astropy.org/" target="_blank" rel="external">官网</a></li>
<li>bcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。<a href="https://github.com/chapmanb/bcbio-nextgen" target="_blank" rel="external">官网</a></li>
<li>bccb：生物分析相关代码集合<a href="https://github.com/chapmanb/bcbb" target="_blank" rel="external">官网</a></li>
<li>Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。<a href="http://biopython.org/wiki/MainPage" target="_blank" rel="external">官网</a></li>
<li>blaze：NumPy 和 Pandas 的大数据接口。<a href="http://blaze.readthedocs.org/en/latest/index.html" target="_blank" rel="external">官网</a></li>
<li>cclib：一个用来解析和解释计算化学软件包输出结果的库。<a href="http://cclib.github.io/" target="_blank" rel="external">官网</a></li>
<li>NetworkX：一个为复杂网络设计的高性能软件。<a href="https://networkx.github.io/" target="_blank" rel="external">官网</a></li>
<li>Neupy：执行和测试各种不同的人工神经网络算法。<a href="http://neupy.com/pages/home.html" target="_blank" rel="external">官网</a></li>
<li>Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由Cython 和 NumPy 的开发者开发。<a href="http://numba.pydata.org/" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/numpy/" target="_blank" rel="external">NumPy</a>：使用 Python 进行科学计算的基础包。<a href="http://www.numpy.org/" target="_blank" rel="external">官网</a></li>
<li>Open Babel：一个化学工具箱，用来描述多种化学数据。<a href="http://openbabel.org/wiki/MainPage" target="_blank" rel="external">官网</a></li>
<li>Open Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。<a href="https://github.com/avelino/mining" target="_blank" rel="external">官网</a></li>
<li>orange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。<a href="http://orange.biolab.si/" target="_blank" rel="external">官网</a></li>
<li>Pandas：提供高性能，易用的数据结构和数据分析工具。<a href="http://pandas.pydata.org/" target="_blank" rel="external">官网</a></li>
<li>PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。<a href="http://www.pydy.org/" target="_blank" rel="external">官网</a></li>
<li>PyMC：马尔科夫链蒙特卡洛采样工具。<a href="https://github.com/pymc-devs/pymc3" target="_blank" rel="external">官网</a></li>
<li>RDKit：化学信息学和机器学习软件。<a href="http://www.rdkit.org/" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/scipy/" target="_blank" rel="external">SciPy</a>：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。<a href="http://www.scipy.org/" target="_blank" rel="external">官网</a></li>
<li>statsmodels：统计建模和计量经济学。<a href="https://github.com/statsmodels/statsmodels" target="_blank" rel="external">官网</a></li>
<li>SymPy：一个用于符号数学的 Python 库。<a href="https://github.com/sympy/sympy" target="_blank" rel="external">官网</a></li>
<li>zipline：一个 Python 算法交易库。<a href="https://github.com/quantopian/zipline" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><p>进行数据可视化的库。 参见: <a href="https://github.com/sorrycc/awesome-javascript#data-visualization" target="_blank" rel="external">awesome-javascript</a>。</p>
<ul>
<li>matplotlib：一个 Python 2D 绘图库。<a href="http://matplotlib.org/" target="_blank" rel="external">官网</a></li>
<li>bokeh：用 Python 进行交互式 web 绘图。<a href="https://github.com/bokeh/bokeh" target="_blank" rel="external">官网</a></li>
<li>ggplot：ggplot2 给 R 提供的 API 的 Python 版本。<a href="https://github.com/yhat/ggplot" target="_blank" rel="external">官网</a></li>
<li>plotly：协同 Python 和 matplotlib 工作的 web 绘图库。<a href="https://plot.ly/python/" target="_blank" rel="external">官网</a></li>
<li>pygal：一个 Python SVG 图表创建工具。<a href="http://www.pygal.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>pygraphviz：Graphviz 的 Python 接口。<a href="https://pypi.python.org/pypi/pygraphviz" target="_blank" rel="external">官网</a></li>
<li>PyQtGraph：交互式实时2D/3D/图像绘制及科学/工程学组件。<a href="http://www.pyqtgraph.org/" target="_blank" rel="external">官网</a></li>
<li>SnakeViz：一个基于浏览器的 Python’s cProfile 模块输出结果查看工具。<a href="http://jiffyclub.github.io/snakeviz/" target="_blank" rel="external">官网</a></li>
<li>vincent：把 Python 转换为 Vega 语法的转换工具。<a href="https://github.com/wrobstory/vincent" target="_blank" rel="external">官网</a></li>
<li>VisPy：基于 OpenGL 的高性能科学可视化工具。<a href="http://vispy.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h3><p>计算机视觉库。</p>
<ul>
<li>OpenCV：开源计算机视觉库。<a href="http://opencv.org/" target="_blank" rel="external">官网</a></li>
<li>SimpleCV：一个用来创建计算机视觉应用的开源框架。<a href="http://simplecv.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><p>机器学习库。 参见: <a href="https://github.com/josephmisiti/awesome-machine-learning#python" target="_blank" rel="external">awesome-machine-learning</a>.</p>
<ul>
<li>Crab：灵活、快速的推荐引擎。<a href="https://github.com/muricoca/crab" target="_blank" rel="external">官网</a></li>
<li>gensim：人性化的话题建模库。<a href="https://github.com/piskvorky/gensim" target="_blank" rel="external">官网</a></li>
<li>hebel：GPU 加速的深度学习库。<a href="https://github.com/hannes-brt/hebel" target="_blank" rel="external">官网</a></li>
<li>NuPIC：智能计算 Numenta 平台。<a href="https://github.com/numenta/nupic" target="_blank" rel="external">官网</a></li>
<li>pattern：Python 网络挖掘模块。<a href="https://github.com/clips/pattern" target="_blank" rel="external">官网</a></li>
<li>PyBrain：另一个 Python 机器学习库。<a href="https://github.com/pybrain/pybrain" target="_blank" rel="external">官网</a></li>
<li>Pylearn2：一个基于 <a href="https://github.com/Theano/Theano" target="_blank" rel="external">Theano</a> 的机器学习库。<a href="https://github.com/lisa-lab/pylearn2" target="_blank" rel="external">官网</a></li>
<li>python-recsys：一个用来实现推荐系统的 Python 库。<a href="https://github.com/ocelma/python-recsys" target="_blank" rel="external">官网</a></li>
<li>scikit-learn：基于 SciPy 构建的机器学习 Python 模块。<a href="http://scikit-learn.org/" target="_blank" rel="external">官网</a></li>
<li>pydeep：Python 深度学习库。<a href="https://github.com/andersbll/deeppy" target="_blank" rel="external">官网</a></li>
<li>vowpalporpoise：轻量级 <a href="https://github.com/JohnLangford/vowpalwabbit/" target="_blank" rel="external">Vowpal Wabbit</a> 的 Python 封装。<a href="https://github.com/josephreisinger/vowpalporpoise" target="_blank" rel="external">官网</a></li>
<li>skflow：一个 <a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">TensorFlow</a> 的简化接口(模仿 scikit-learn)。<a href="https://github.com/tensorflow/skflow" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>MapReduce 框架和库。</p>
<ul>
<li>dpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。<a href="https://github.com/douban/dpark" target="_blank" rel="external">官网</a></li>
<li>dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。<a href="https://github.com/klbostee/dumbo" target="_blank" rel="external">官网</a></li>
<li>luigi：这个模块帮你构建批处理作业的复杂流水线。<a href="https://github.com/spotify/luigi" target="_blank" rel="external">官网</a></li>
<li>mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。<a href="https://github.com/Yelp/mrjob" target="_blank" rel="external">官网</a></li>
<li>PySpark：Spark 的 Python API 。<a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">官网</a></li>
<li>streamparse：运行针对事实数据流的 Python 代码。集成了<a href="http://storm.apache.org/" target="_blank" rel="external">Apache Storm</a>。<a href="https://github.com/Parsely/streamparse" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h3><p>使用 Python 进行函数式编程。</p>
<ul>
<li>CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。<a href="https://github.com/pytoolz/cytoolz/" target="_blank" rel="external">官网</a></li>
<li>fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。<a href="https://github.com/kachayev/fn.py" target="_blank" rel="external">官网</a></li>
<li>funcy：炫酷又实用的函数式工具。<a href="https://github.com/Suor/funcy" target="_blank" rel="external">官网</a></li>
<li>Toolz：一组用于迭代器，函数和字典的函数式编程工具。<a href="https://github.com/pytoolz/toolz" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="第三方-API"><a href="#第三方-API" class="headerlink" title="第三方 API"></a>第三方 API</h3><p>用来访问第三方 API的库。 参见： <a href="https://github.com/realpython/list-of-python-api-wrappers" target="_blank" rel="external">List of Python API Wrappers and Libraries</a>。</p>
<ul>
<li>apache-libcloud：一个为各种云设计的 Python 库。<a href="https://libcloud.apache.org/" target="_blank" rel="external">官网</a></li>
<li>boto：Amazon Web Services 的 Python 接口。<a href="https://github.com/boto/boto" target="_blank" rel="external">官网</a></li>
<li>django-wordpress：WordPress models and views for Django.<a href="https://github.com/sunlightlabs/django-wordpress/" target="_blank" rel="external">官网</a></li>
<li>facebook-sdk：Facebook 平台的 Python SDK.<a href="https://github.com/pythonforfacebook/facebook-sdk" target="_blank" rel="external">官网</a></li>
<li>facepy：Facepy 让和 Facebook’s Graph API 的交互变得更容易。<a href="https://github.com/jgorset/facepy" target="_blank" rel="external">官网</a></li>
<li>gmail：Gmail 的 Python 接口。<a href="https://github.com/charlierguo/gmail" target="_blank" rel="external">官网</a></li>
<li>google-api-python-client：Python 用的 Google APIs 客户端库。<a href="https://github.com/google/google-api-python-client" target="_blank" rel="external">官网</a></li>
<li>gspread：Google 电子表格的 Python API.<a href="https://github.com/burnash/gspread" target="_blank" rel="external">官网</a></li>
<li>twython：Twitter API 的封装。<a href="https://github.com/ryanmcgrath/twython" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="DevOps-工具"><a href="#DevOps-工具" class="headerlink" title="DevOps 工具"></a>DevOps 工具</h3><p>用于 DevOps 的软件和库。</p>
<ul>
<li>Ansible：一个非常简单的 IT 自动化平台。<a href="https://github.com/ansible/ansible" target="_blank" rel="external">官网</a></li>
<li>SaltStack：基础设施自动化和管理系统。<a href="https://github.com/saltstack/salt" target="_blank" rel="external">官网</a></li>
<li>OpenStack：用于构建私有和公有云的开源软件。<a href="http://www.openstack.org/" target="_blank" rel="external">官网</a></li>
<li>Docker Compose：快速，分离的开发环境，使用 Docker。<a href="https://docs.docker.com/compose/" target="_blank" rel="external">官网</a></li>
<li>Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。<a href="http://www.fabfile.org/" target="_blank" rel="external">官网</a></li>
<li>cuisine：为 Fabric 提供一系列高级函数。<a href="https://github.com/sebastien/cuisine" target="_blank" rel="external">官网</a></li>
<li>Fabtools：一个用来编写超赞的 Fabric 文件的工具。<a href="https://github.com/ronnix/fabtools" target="_blank" rel="external">官网</a></li>
<li>gitapi：Git 的纯 Python API。<a href="https://bitbucket.org/haard/gitapi" target="_blank" rel="external">官网</a></li>
<li>hgapi：Mercurial 的纯 Python API。<a href="https://bitbucket.org/haard/hgapi" target="_blank" rel="external">官网</a></li>
<li>honcho：<a href="https://github.com/ddollar/foreman" target="_blank" rel="external">Foreman</a>的 Python 克隆版，用来管理基于<a href="https://devcenter.heroku.com/articles/procfile" target="_blank" rel="external">Procfile</a>的应用。<a href="https://github.com/nickstenning/honcho" target="_blank" rel="external">官网</a></li>
<li>pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。<a href="https://github.com/pexpect/pexpect" target="_blank" rel="external">官网</a></li>
<li>psutil：一个跨平台进程和系统工具模块。<a href="https://github.com/giampaolo/psutil" target="_blank" rel="external">官网</a></li>
<li>supervisor：UNIX 的进程控制系统。<a href="https://github.com/Supervisor/supervisor" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h3><p>任务调度库。</p>
<ul>
<li>APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。<a href="http://apscheduler.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>django-schedule：一个 Django 排程应用。<a href="https://github.com/thauber/django-schedule" target="_blank" rel="external">官网</a></li>
<li>doit：一个任务执行和构建工具。<a href="http://pydoit.org/" target="_blank" rel="external">官网</a></li>
<li>gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。<a href="https://github.com/gunnery/gunnery" target="_blank" rel="external">官网</a></li>
<li>Joblib：一组为 Python 提供轻量级作业流水线的工具。<a href="http://pythonhosted.org/joblib/index.html" target="_blank" rel="external">官网</a></li>
<li>Plan：如有神助地编写 crontab 文件。<a href="https://github.com/fengsp/plan" target="_blank" rel="external">官网</a></li>
<li>schedule：人性化的 Python 任务调度库。<a href="https://github.com/dbader/schedule" target="_blank" rel="external">官网</a></li>
<li>Spiff：使用纯 Python 实现的强大的工作流引擎。<a href="https://github.com/knipknap/SpiffWorkflow" target="_blank" rel="external">官网</a></li>
<li>TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。<a href="http://docs.openstack.org/developer/taskflow/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="外来函数接口"><a href="#外来函数接口" class="headerlink" title="外来函数接口"></a>外来函数接口</h3><p>使用外来函数接口的库。</p>
<ul>
<li>cffi：用来调用 C 代码的外来函数接口。<a href="https://pypi.python.org/pypi/cffi" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/ctypes/" target="_blank" rel="external">ctypes</a>：(Python 标准库) 用来调用 C 代码的外来函数接口。<a href="https://docs.python.org/2/library/ctypes.html" target="_blank" rel="external">官网</a></li>
<li>PyCUDA：Nvidia CUDA API 的封装。<a href="https://mathema.tician.de/software/pycuda/" target="_blank" rel="external">官网</a></li>
<li>SWIG：简化的封装和接口生成器。<a href="http://www.swig.org/Doc1.3/Python.html" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h3><p>让 Python 更快的库。</p>
<ul>
<li>Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。<a href="http://cython.org/" target="_blank" rel="external">官网</a></li>
<li>PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。<a href="https://github.com/Maratyszcza/PeachPy" target="_blank" rel="external">官网</a></li>
<li>PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。<a href="http://pypy.org/" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/pyston-llvm-jit/" target="_blank" rel="external">Pyston</a>：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。<a href="https://github.com/dropbox/pyston" target="_blank" rel="external">官网</a></li>
<li>Stackless Python：一个强化版的 Python。<a href="https://bitbucket.org/stackless-dev/stackless/overview" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="微软的-Windows平台"><a href="#微软的-Windows平台" class="headerlink" title="微软的 Windows平台"></a>微软的 Windows平台</h3><p>在 Windows 平台上进行 Python 编程。</p>
<ul>
<li>Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。<a href="http://python-xy.github.io/" target="_blank" rel="external">官网</a></li>
<li>pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="external">官网</a></li>
<li>PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。<a href="https://github.com/pythonnet/pythonnet" target="_blank" rel="external">官网</a></li>
<li>PyWin32：针对 Windows 的Python 扩展。<a href="http://sourceforge.net/projects/pywin32/" target="_blank" rel="external">官网</a></li>
<li>WinPython：Windows 7/8 系统下便携式开发环境。<a href="https://winpython.github.io/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="网络可视化和SDN"><a href="#网络可视化和SDN" class="headerlink" title="网络可视化和SDN"></a>网络可视化和SDN</h3><p>用来进行网络可视化和SDN(软件定义网络)的工具和库。</p>
<ul>
<li>Mininet：一款流行的网络模拟器以及用 Python 编写的 API。<a href="http://mininet.org/" target="_blank" rel="external">官网</a></li>
<li>POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。<a href="https://github.com/noxrepo/pox" target="_blank" rel="external">官网</a></li>
<li>Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。<a href="http://frenetic-lang.org/pyretic/" target="_blank" rel="external">官网</a></li>
<li>SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。<a href="https://github.com/sdn-ixp/internet2award" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h3><p>用来对硬件进行编程的库。</p>
<ul>
<li>ino：操作<a href="https://www.arduino.cc/" target="_blank" rel="external">Arduino</a>的命令行工具。<a href="http://inotool.org/" target="_blank" rel="external">官网</a></li>
<li>Pyro：Python 机器人编程库。<a href="http://pyrorobotics.com/" target="_blank" rel="external">官网</a></li>
<li>PyUserInput：跨平台的，控制鼠标和键盘的模块。<a href="https://github.com/SavinaRoja/PyUserInput" target="_blank" rel="external">官网</a></li>
<li>scapy：一个非常棒的操作数据包的库。<a href="https://github.com/secdev/scapy" target="_blank" rel="external">官网</a></li>
<li>wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作WiFi。<a href="https://wifi.readthedocs.org/en/latest/" target="_blank" rel="external">官网</a></li>
<li>Pingo：Pingo 为类似Raspberry Pi，pcDuino， Intel Galileo等设备提供统一的API用以编程。<a href="http://www.pingo.io/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h3><p>帮助从 Python 2 向 Python 3迁移的库。</p>
<ul>
<li>Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。<a href="http://python-future.org/index.html" target="_blank" rel="external">官网</a></li>
<li>Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。<a href="https://github.com/mitsuhiko/python-modernize" target="_blank" rel="external">官网</a></li>
<li>Six：Python 2 和 3 的兼容性工具。<a href="https://pypi.python.org/pypi/six" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><p>不属于上面任何一个类别，但是非常有用的库。</p>
<ul>
<li>blinker：一个快速的 Python 进程内信号/事件分发系统。<a href="https://github.com/jek/blinker" target="_blank" rel="external">官网</a></li>
<li>itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。<a href="https://github.com/mitsuhiko/itsdangerous" target="_blank" rel="external">官网</a></li>
<li>pluginbase：一个简单但是非常灵活的 Python 插件系统。<a href="https://github.com/mitsuhiko/pluginbase" target="_blank" rel="external">官网</a></li>
<li>Pychievements：一个用来创建和追踪成就的 Python 框架。<a href="https://github.com/PacketPerception/pychievements" target="_blank" rel="external">官网</a></li>
<li>Tryton：一个通用商务框架。<a href="http://www.tryton.org/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="算法和设计模式"><a href="#算法和设计模式" class="headerlink" title="算法和设计模式"></a>算法和设计模式</h3><p>Python 实现的算法和设计模式。</p>
<ul>
<li><a href="http://hao.jobbole.com/algorithms/" target="_blank" rel="external">algorithms</a>：一个 Python 算法模块。<a href="https://github.com/nryoung/algorithms" target="_blank" rel="external">官网</a></li>
<li>python-patterns：Python 设计模式的集合。<a href="https://github.com/faif/python-patterns" target="_blank" rel="external">官网</a></li>
<li>sortedcontainers：快速，纯 Python 实现的SortedList，SortedDict 和 SortedSet 类型。<a href="http://www.grantjenks.com/docs/sortedcontainers/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="编辑器插件"><a href="#编辑器插件" class="headerlink" title="编辑器插件"></a>编辑器插件</h3><p>编辑器和 IDE 的插件</p>
<ul>
<li>Emacs<ul>
<li>Elpy：Emacs Python 开发环境。<a href="https://github.com/jorgenschaefer/elpy" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Sublime Text<ul>
<li>SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。<a href="https://github.com/srusskih/SublimeJEDI" target="_blank" rel="external">官网</a></li>
<li>Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。<a href="https://github.com/DamnWidget/anaconda" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Vim<ul>
<li>YouCompleteMe：引入基于 <a href="https://github.com/davidhalter/jedi" target="_blank" rel="external">Jedi</a> 的 Python 自动补全引擎。<a href="https://github.com/Valloric/YouCompleteMe" target="_blank" rel="external">官网</a></li>
<li>Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。<a href="https://github.com/davidhalter/jedi-vim" target="_blank" rel="external">官网</a></li>
<li>Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。<a href="https://github.com/klen/python-mode" target="_blank" rel="external">官网</a></li>
</ul>
</li>
<li>Visual Studio<ul>
<li>PTVS：Visual Studio 的 Python 工具<a href="https://github.com/Microsoft/PTVS" target="_blank" rel="external">官网</a></li>
</ul>
</li>
</ul>
<h3 id="集成开发环境"><a href="#集成开发环境" class="headerlink" title="集成开发环境"></a>集成开发环境</h3><p>流行的 Python 集成开发环境。</p>
<ul>
<li>PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。<a href="https://www.jetbrains.com/pycharm/" target="_blank" rel="external">官网</a></li>
<li>LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。<a href="http://www.liclipse.com/" target="_blank" rel="external">官网</a></li>
<li>Spyder：开源 Python IDE。<a href="https://github.com/spyder-ide/spyder" target="_blank" rel="external">官网</a></li>
</ul>
<h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>在线工具和简化开发的 API 。</p>
<h3 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h3><p>参见: <a href="https://github.com/ciandcd/awesome-ciandcd#online-build-system" target="_blank" rel="external">awesome-CIandCD</a>.</p>
<ul>
<li>Travis CI：一个流行的工具，为你的开源和<a href="https://travis-ci.com/" target="_blank" rel="external">私人</a>项目提供持续集成服务。(仅支持 GitHub)<a href="https://travis-ci.org/" target="_blank" rel="external">官网</a></li>
<li>CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)<a href="https://circleci.com/" target="_blank" rel="external">官网</a></li>
<li>Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。<a href="https://vexor.io/" target="_blank" rel="external">官网</a></li>
<li>Wercker：基于 Docker 平台，用来构建和部署微服务。<a href="http://wercker.com/" target="_blank" rel="external">官网</a></li>
</ul>
<h3 id="代码质量"><a href="#代码质量" class="headerlink" title="代码质量"></a>代码质量</h3><ul>
<li>Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。<a href="https://www.codacy.com/" target="_blank" rel="external">官网</a></li>
<li>QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。<a href="https://www.quantifiedcode.com/" target="_blank" rel="external">官网</a></li>
</ul>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>在这里可以找到新的 Python 库。</p>
<h3 id="网站"><a href="#网站" class="headerlink" title="网站"></a>网站</h3><ul>
<li><a href="https://www.reddit.com/r/python" target="_blank" rel="external">r/Python</a></li>
<li><a href="https://www.coolgithubprojects.com/" target="_blank" rel="external">CoolGithubProjects</a></li>
<li><a href="https://www.djangopackages.com/" target="_blank" rel="external">Django Packages</a></li>
<li><a href="http://www.fullstackpython.com/" target="_blank" rel="external">Full Stack Python</a></li>
<li><a href="http://python3wos.appspot.com/" target="_blank" rel="external">Python 3 Wall of Superpowers</a></li>
<li><a href="http://pythonhackers.com/open-source/" target="_blank" rel="external">Python Hackers</a></li>
<li><a href="https://python.zeef.com/alan.richmond" target="_blank" rel="external">Python ZEEF</a></li>
<li><a href="https://github.com/trending?l=python" target="_blank" rel="external">Trending Python repositories on GitHub today</a></li>
<li><a href="http://pypi-ranking.info/alltime" target="_blank" rel="external">PyPI Ranking</a></li>
</ul>
<h3 id="周刊"><a href="#周刊" class="headerlink" title="周刊"></a>周刊</h3><ul>
<li><a href="http://importpython.com/newsletter/" target="_blank" rel="external">Import Python Newsletter</a></li>
<li><a href="http://pycoders.com/" target="_blank" rel="external">Pycoder’s Weekly</a></li>
<li><a href="http://www.pythonweekly.com/" target="_blank" rel="external">Python Weekly</a></li>
</ul>
<h3 id="Twitter"><a href="#Twitter" class="headerlink" title="Twitter"></a>Twitter</h3><ul>
<li><a href="https://twitter.com/codetengu" target="_blank" rel="external">@codetengu</a></li>
<li><a href="https://twitter.com/getpy" target="_blank" rel="external">@getpy</a></li>
<li><a href="https://twitter.com/planetpython" target="_blank" rel="external">@planetpython</a></li>
<li><a href="https://twitter.com/pycoders" target="_blank" rel="external">@pycoders</a></li>
<li><a href="https://twitter.com/pypi" target="_blank" rel="external">@pypi</a></li>
<li><a href="https://twitter.com/pythontrending" target="_blank" rel="external">@pythontrending</a></li>
<li><a href="https://twitter.com/PythonWeekly" target="_blank" rel="external">@PythonWeekly</a></li>
</ul>
<h3 id="学习指南"><a href="#学习指南" class="headerlink" title="学习指南"></a>学习指南</h3><ul>
<li><a href="http://hao.jobbole.com/scipy-lecture-notes/" target="_blank" rel="external">Scipy-lecture-notes</a>：如何用Python来做学术？<a href="https://github.com/scipy-lectures/scipy-lecture-notes" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/scientific-python-lectures/" target="_blank" rel="external">SScientific-python-lectures</a>：Python科学计算的资料。<a href="https://github.com/jrjohansson/scientific-python-lectures" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/mario-level-1/" target="_blank" rel="external">Mario-Level-1</a>：用Python和Pygame写的超级马里奥第一关。<a href="https://github.com/justinmeister/Mario-Level-1" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-koans/" target="_blank" rel="external">Python Koans</a>：Python的交互式学习工具。<a href="https://github.com/gregmalcolm/python_koans" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/minecraft-python/" target="_blank" rel="external">Minecraft</a>：用python写的Minecraft游戏。<a href="https://github.com/fogleman/Minecraft" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-pycrumbs/" target="_blank" rel="external">pycrumbs</a>：Python资源大全。<a href="https://github.com/kirang89/pycrumbs/blob/master/pycrumbs.md" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-patterns/" target="_blank" rel="external">python-patterns</a>：使用python实现设计模式。<a href="https://github.com/faif/python-patterns" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/python-projects/" target="_blank" rel="external">Projects</a>：Python项目大集合。<a href="https://github.com/karan/Projects" target="_blank" rel="external">官网</a></li>
<li><a href="http://hao.jobbole.com/the-hitchhikers-guide-to-python/" target="_blank" rel="external">The Hitchhiker’s Guide to Python</a>：旅行者的Python学习指南。<a href="http://docs.python-guide.org/en/latest/" target="_blank" rel="external">官网</a></li>
</ul>
<p></p><h3 id="websites">知名网站</h3><br><em>值得关注的 Python 技术站点。</em><p></p>
<h4>中文站点</h4>

<ul>
<li>伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。<a href="http://python.jobbole.com/" target="_blank" rel="external">官网</a></li>
</ul>
<h4>英文站点</h4>

<p>待补充</p>
<p></p><h3 id="weibo-weixin">微博、微信公众号</h3><p></p>
<ul>
<li>Python开发者 微博：<a href="http://weibo.com/u/5305630013" target="_blank" rel="external">@Python开发者</a></li>
<li>Python开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享Python技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。<br><br><img src="http://ww3.sinaimg.cn/small/63918611gw1epb2cbm6cmj2046046wek.jpg" width="150" height="150"></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://github.com/wangaicc/awesome-python-cn&quot;&gt;litai wong/wangaicc&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。&lt;a href=&quot;https://github.com/vinta/awesome-python&quot;&gt;awesome-python&lt;/a&gt; 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。&lt;/p&gt;
&lt;p&gt;Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Python" scheme="http://ipcreator.me/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革</title>
    <link href="http://ipcreator.me/2017/02/18/Program/TensorFlow/changes-by-google-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/18/Program/TensorFlow/changes-by-google-tensorflow/</id>
    <published>2017-02-18T01:02:06.000Z</published>
    <updated>2017-02-19T06:02:30.218Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.csdn.net/article/2015-11-13/2826207" target="_blank" rel="external">谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革</a></p>
<p>摘要：在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。</p>
<a id="more"></a>
<p>谷歌宣布将其最重要的创新项目之一 —— 人工智能引擎 ——作为开源项目发布到网上供大家免费使用，这展示了计算机软件行业正进行着什么样的变革。</p>
<p>最近，互联网巨头们接二连三地将自己线上核心业务所用的软件开源。项目开源加快了技术发展的进程。随着人工智能引擎TensorFlow的开源，谷歌能以各种方式为公司范围之外的机器学习研究提供支持，这些研究成果也将反馈给谷歌。</p>
<p>不过谷歌的人工智能引擎也反映了当今计算机硬件行业的发展趋势。在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。</p>
<p>根据负责谷歌AI项目的工程师Jeff Dean的说法，<strong>谷歌不仅用GPU训练其AI服务，而且还运行这些服务产品 —— 将它们植入用户手中的智能电话。</strong></p>
<p>那是一次重大的转变。目前，Facebook在其庞大的计算机数据中心里用GPU训练人脸识别模型，但在为用户提供服务时 —— 真刀实战地在社交网站上识别人脸 —— 还是使用传统的处理器，或者CPU。Facebook的CTO Mike “Schrep” Schroepfer近日在公司总部举行的一次简短的记者见面会上指出，这种基本配置是目前的行业标准。但谷歌为了追求更高层次的效率，某些时候在数据中心里GPU既用来训练AI模型，又用来执行模型。谷歌也并不是踽踽独行。中国搜索引擎巨头百度也正在搭建一套类似的AI系统。“这是一次巨大的模式变革”，百度首席科学家Andrew Ng说道。</p>
<p>这一变革对于专注于GPU的芯片巨头NVIDIA来说是件好事。而且这也是世界最大的芯片制造商Intel产品的空白区。Intel不生产GPU。一些互联网企业和研究院开始关注可编程逻辑阵列FPGA了，将它作为AI领域的GPU替代品，并且Intel最近收购了一家专门生产可编程芯片的公司。</p>
<p>AI在全球的在线服务业务中扮演了越来越重要的角色 —— 备选芯片架构在AI中的地位也越来越重要。目前，在我们提供线上服务的计算机数据中心里已经如此了，若干年内，同样的现象也将会在移动设备上出现，因为我们使用的服务其实是相同的。</p>
<h2 id="深度学习实践"><a href="#深度学习实践" class="headerlink" title="深度学习实践"></a>深度学习实践</h2><p>在谷歌、Facebook、微软、百度等公司，GPU被证明对“深度学习”非常有效，因为它可以并行处理许多小数据集。深度学习依赖于神经网络 —— 一种模拟人类大脑中神经元的系统 —— 这些网络是用来快速分析大量的数据。举个例子，为了教会神经网络识别一只猫，你就需要输入无数张猫的图像。GPU擅长处理这类任务。另外，它们的能耗也没有CPU这么高。</p>
<p>但是，这些公司在实际应用中使用深度学习技术时 —— 比如识别猫的手机App —— 这个App是由运行在CPU上的数据系统驱动的。根据在百度AI团队负责高性能计算系统的Bryan Catanzaro介绍，这是因为GPU只在持续不断输入数据的时候效率才高，而通常用来驱动手机App的数据服务器软件并不以这种方式往芯片传输数据。通常情况下，当收到手机App发来的请求后，服务器每次处理一个请求。Catanzaro解释道，如果你使用GPU分别处理收到的每个请求，“很难保证GPU有足够多的任务，让它能够有效运行。GPU从未真正发挥出作用。”</p>
<p>就是说，如果在执行环节你能不断地给GPU传入数据，那么它的效率比CPU高得多。百度正在其新的AI平台做这方面尝试。简单说来，就是请求发送到数据中心，然后将多个请求打包传入GPU。“我们打包这些请求，不再让处理器每次处理一个请求，而是每次处理多个请求，”Catanzaro说道。“别让GPU闲下来。”</p>
<p>目前还不清楚谷歌将如何处理这个问题。但是他们表示已经有TensorFlow在执行阶段使用GPU的案例。“基于不同的问题，我们有时候把GPU既用于训练，又用于识别，”谷歌发言人Jason Freidenfelds证实。</p>
<p>这似乎显得微不足道。事实上却是一项大工程。驱动这些AI应用产品的系统包括数十台、数百台、甚至上千台的机器。而且这些系统在我们日常生活中的地位日益重要。现在谷歌的深度学习技术不仅用来识别照片、识别语音、机器翻译，还用来提高搜索质量。其它公司也将同样的技术用于精准广告投放、计算机安全，甚至理解自然语言的应用。换句话说，像谷歌和百度这样的公司还需要大量的GPU。</p>
<h2 id="无处不在的AI"><a href="#无处不在的AI" class="headerlink" title="无处不在的AI"></a>无处不在的AI</h2><p>与此同时，<strong>TensorFlow也将其中一些AI产品从数据中心推向了智能手机端。</strong></p>
<p>一般来说，如果在手机端使用深度学习相关的App，必须往数据中心回传信息。所有的AI都在服务器端。例如，你在安卓手机上执行了一个命令，这条命令必须传到谷歌的数据中心，在那里用巨大的CPU或者GPU网络来处理。</p>
<p>但是，谷歌也一直在提升自己的AI引擎，某些情况下可以在手机端执行完成。“你能使用一个模型描述，并且在手机端上运行”，Dean说，“而且你并不需要真的对模型描述或是代码做改动。”</p>
<p>谷歌的翻译App正是这么搭建的。谷歌在数据中心训练模型来识别单词和完成翻译，一旦训练完成，App就能独立地运行 —— 不需要网络连接。你可以把手机对准一块法语路牌，立即就能显示出英语翻译。</p>
<p>这要做好很困难。毕竟，手机的处理能力有限。随着时间推进，越来越多的这类任务会被迁移到手机端。深度学习软件会改进，移动设备硬件也在发展。“深度学习的未来在小巧灵活的移动设备上”，深度学习创业公司的创始人Chris Nicholson如是说。</p>
<p>举例来说，GPU正在试图寻找置入手机的方式，硬件制造商也在不断改进CPU的速度和效率。同时，IBM也在开发专为AI任务定制的“neuromorphic”芯片，使用过的人觉得它非常适合移动设备。</p>
<p>如今，谷歌的AI引擎不仅运行在服务器的CPU和GPU上，还运行在常规的智能手机芯片上。但据谷歌工程师Rajat Monga称，他们开发的TensorFlow能让工程师们轻而易举地迁移到其它硬件平台上。现在工具已经开源，外部人员也可以使用了。Dean如此描述TensorFlow：“它应该可以移植到各种硬件。”<br>没错，硬件界也在经历变革 —— 和软件界并驾齐驱。</p>
<p>原文链接：<a href="http://www.wired.com/2015/11/googles-open-source-ai-tensorflow-signals-fast-changing-hardware-world/" target="_blank" rel="external">TensorFlow, Google’s Open Source AI, Signals Big Changes in Hardware</a></p>
<p> Too（译者/赵屹华 审校/刘帝伟、朱正贵 责编/周建丁）</p>
<p>译者简介：赵屹华，计算广告工程师@搜狗，前生物医学工程师，关注推荐算法、机器学习领域。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.csdn.net/article/2015-11-13/2826207&quot;&gt;谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Google" scheme="http://ipcreator.me/tags/Google/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>超智能体</title>
    <link href="http://ipcreator.me/2017/02/18/Program/Concepts/super-intelligence-individual/"/>
    <id>http://ipcreator.me/2017/02/18/Program/Concepts/super-intelligence-individual/</id>
    <published>2017-02-17T23:53:06.000Z</published>
    <updated>2017-02-18T02:37:32.651Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.gitbook.com/book/yjango/superorganism/details" target="_blank" rel="external">作者：yjango</a></p>
<p>生命不限于个体。并非所有生命拥有意识，但所有生命都拥有智能。这些智能体通过大量并行和多层迭代的方式形成新的智能体。细胞、器官、个体、国家、地球，不论从哪个层级上观察，都是一个“智能体”。<br>人类作为智能的一环，需跳出自身层级，用超出人类自身感知、情感和意识的方式去理解生命。</p>
<h2 id="关于本书"><a href="#关于本书" class="headerlink" title="关于本书"></a>关于本书</h2><p>该书最终的目的是：通过理解智能，学习如何学习。</p>
<ol>
<li>如何机器学习</li>
<li><p>如何大脑学习</p>
<a id="more"></a>
<h2 id="如何阅读"><a href="#如何阅读" class="headerlink" title="如何阅读"></a>如何阅读</h2></li>
</ol>
<p>智能并非人类所特有，而是自生命诞生时起就产生了。没有智能就没有生命。智能又并非单一状态，它和宇宙一样，都在不断的扩张。不同阶段的智能表现出的能力不同。神经元、蚁群、人类、社会、国家、地球，乃至整个宇宙都可被视为智能体。它们通过组合和迭代来形成更高级的智能功能。智能从未停止发展，而我们人类也只不过是其中一个“细胞”。这本书将从智能的角度展示对世界的不同理解。</p>
<p>核心知识：并非每个章节的内容本身（读者完全可以找到很多对应内容的经典书籍）。<strong>真正有价值的是将这些知识以何种方式排列和表达。</strong></p>
<p>传达方式：语言是交流的工具，而交流的前提是双方的脑中都有相同内容。但是读者和作者的信息是不对等的。语言作为教学手段本身就有限。所以我描述的方式也并非直接告诉读者一个结论，打上这就是真理的标签，而是结合图，结合例子尽可能的消除信息的不等。我不是以教学者的身份来分享知识，而是引出一个问题让读者一起思考。虽然我提供了我的见解，但我相信会有很多读者能提出比我更好的见解。</p>
<p>行文风格</p>
<p>行文分很多部分，彼此的关系是递进或并列。每个部分通常会以一个问题的引入开始，结合若干实例对该问题进行思考，经过描述，最后得出总结性概括。文中带链接的内容请打开观看。</p>
<h2 id="表达格式"><a href="#表达格式" class="headerlink" title="表达格式"></a>表达格式</h2><p>问题：<em>一、斜线文字</em></p>
<p>实例：</p>
<ul>
<li><p>例子（情景、方式等）：普通格式</p>
</li>
<li><p>描述：普通格式</p>
</li>
</ul>
<p>结论：</p>
<blockquote>
<p>引用格式</p>
</blockquote>
<p>例如</p>
<p><em>猫咪觉得自己属于人类吗？</em></p>
<ul>
<li>实例1：实例内容</li>
<li>实例2：实例内容</li>
</ul>
<p>描述内容</p>
<blockquote>
<p>猫咪觉得人类属于自己</p>
</blockquote>
<h2 id="智能的起源"><a href="#智能的起源" class="headerlink" title="智能的起源"></a>智能的起源</h2><p>我们对智能的探索陷入了错误的方式中。</p>
<p>一、如果某天所有人类突然失忆，在不拆开计算机的情况下，我们该如何弄清计算机的工作原理，并给计算机下一个定义？</p>
<p>方式：从计算机软件开始研究，描述各种软件的功能，并找一个可以概括所有功能的定义。人们会发现计算机可以产生图像。但很快又发现很多软件并没有图形界面。有的软件可以玩射击游戏，有的却可以操控机械。各式各样的功能会被人们发现并逐一分类，使得用一个定义概括所有功能成为不可能。更不用说这些软件的功能还在持续增长。</p>
<p>显然我们并不以具体功能，而是以计算机最基本的工作原理去定义计算机。如今人们对智能的探索正是陷入了以功能来研究智能的方式中。人们把智能划分成了认知、理解、思考、学习等各式各样的功能并研究着，使得研究不同功能的专家对智能的定义都不相同。</p>
<p>如果我们能够知道宇宙自大爆炸之后是以何种方式进行扩张的。我们就可以从起点开始，推测出所有星系可能的形状甚至它们在未来可能的形状。</p>
<p>所以要想搞清智能的本质，不妨先试着找出智能的源头，思考一下为什么会产生智能。</p>
<blockquote>
<p>智能的研究需要从智能的源头开始</p>
</blockquote>
<p><img src="https://yjango.gitbooks.io/superorganism/content/universe.jpg" alt=""></p>
<h2 id="智能的本质"><a href="#智能的本质" class="headerlink" title="智能的本质"></a>智能的本质</h2><h3 id="一、生命是如何产生的？"><a href="#一、生命是如何产生的？" class="headerlink" title="一、生命是如何产生的？"></a>一、生命是如何产生的？</h3><p>在漫漫的宇宙演变中，我想很多星球都有产生生命的概率。</p>
<p>情景：想象某刻火星上产生了生命，但却遇到高温又被分解成了无机物。 第二个产生的生命却因为找不到支持机体的能源而再次化成了无机物。 第三个有机体幸运的诞生在大量能源旁，却由于能源的耗尽而前功尽弃。</p>
<p>问题的关键并非生命能否产生，而是产生的生命能否存活。</p>
<h3 id="二、究竟是什么阻碍了生命，生命又该如何存活？"><a href="#二、究竟是什么阻碍了生命，生命又该如何存活？" class="headerlink" title="二、究竟是什么阻碍了生命，生命又该如何存活？"></a>二、究竟是什么阻碍了生命，生命又该如何存活？</h3><p>如果世界是静止的，那么生命自然不朽。然而我们的世界在时时刻刻发生着变化，会从一个状态变化到另一个状态。生物无从知道下一刻等待它的究竟是毁灭还是幸存？这种未来的不确定性（uncertainty）阻碍了生命的延续。</p>
<p>实例：</p>
<ul>
<li>植物会因为干旱而枯萎；野兽会因为捕不到猎物而饿死；每天又有约160中国人死于交通事故。</li>
</ul>
<p>阻碍生命的正是这种不可预测性（随机），它还有另一个名字，叫做熵（entropy）。而热力学第二定律表述孤立系统会自发的朝向最大熵状态演化。</p>
<p>实例：</p>
<ul>
<li>我们房间会越来越乱，掉在地上的杯子的碎片会随处散落，熵会自发性的不断增加。我们从未见过房间自己越来越整洁，将杯子碎片会摔出一个完整的杯子的情况。说明了熵增在孤立系统下并不可逆。</li>
</ul>
<p><img src="https://yjango.gitbooks.io/superorganism/content/%E7%8C%AA%E7%BD%90%E5%AD%90.jpg" alt=""></p>
<p>熵增不可逆的现象也意味着世界持续的发生变化。在过去可能产生过无数个生命，但只有那些可以根据变化而做出相应变化的生命才能躲避危险从而幸存。这种能力就是智能，同时也是生命得以延续的原因。</p>
<blockquote>
<p>智能：可以根据环境变化而做出相应变化的能力</p>
</blockquote>
<p>由于阻止生命延续的实际是不确定性（随机性、不可预测性），那生命所做的就是减少该不确定性来延续。</p>
<p>奥地利物理学家薛定谔在《生命是什么》首次提出负熵的概念，并认为生命以负熵为生，所以智能也可被描述是：</p>
<blockquote>
<p>智能：熵减的能力</p>
</blockquote>
<h2 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h2><p><img src="https://yjango.gitbooks.io/superorganism/content/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0.png" alt=""></p>
<h3 id="一、什么是线性代数？"><a href="#一、什么是线性代数？" class="headerlink" title="一、什么是线性代数？"></a>一、什么是线性代数？</h3><p>不断变化的世界使我们产生时间观念。正确描述事物状态及其不同时间下的变化至关重要。我们知道在三维空间下如何描述物体的位置。然而除了长宽高，世界上还有很多决定事物状态的因素。如决定股票价钱的因素、决定天气的因素。这些因素又该如何合理的描述？线性代数给了我们答案。推荐读物《Linear Algebra and Its Applications》。</p>
<blockquote>
<p>线性代数是有关任意维度空间下事物状态和状态变化的规则。</p>
</blockquote>
<p><strong>矩阵乘法</strong></p>
<p>二、矩阵是什么？矩阵乘法又是什么？</p>
<p>带着这个问题我们开始对矩阵及其乘法进行第一遍理解。</p>
<p><strong>向量点乘</strong></p>
<p>全篇将会以一个实例进行讨论，请观看一遍视频<a href="http://www.bilibili.com/video/av6467776/" target="_blank" rel="external">PPAP洗脑全球</a>。</p>
<p>三、视频的内容涉及到很多种状态及变换。用线性代数应该如何描述？</p>
<p>视频内容可以写成3个向量乘法：</p>
<p>1、I have a pen, I have an apple—-&gt;apple pen</p>
<p>[applepen][applepen][applepen] = [11]⋅[penapple][11]⋅[penapple][][11]⋅[penapple]  （eq.1）</p>
<p><a href="https://yjango.gitbooks.io/superorganism/content/applepen.jpg" target="_blank" rel="external">https://yjango.gitbooks.io/superorganism/content/applepen.jpg</a></p>
<p>2、I have a pen, I have a pineapple—-&gt;pineapple pen<br>[pineapplepen][pineapplepen][pineapplepen] = [11]⋅[penpineapple][11]⋅[penpineapple][][11]⋅[penpineapple]  （eq.2） 1</p>
<p><a href="https://yjango.gitbooks.io/superorganism/content/pineapplepen.jpg" target="_blank" rel="external">https://yjango.gitbooks.io/superorganism/content/pineapplepen.jpg</a></p>
<p>3、apple pen, pineapple pen—-&gt;pen pineapple apple pen<br>[penpineappleapplepen][penpineappleapplepen][penpineappleapplepen] = [11]⋅[applepenpineapplepen][11]⋅[applepenpineapplepen][][11]⋅[applepenpineapplepen]  （eq.3）</p>
<p><a href="https://yjango.gitbooks.io/superorganism/content/allpen.jpg" target="_blank" rel="external">https://yjango.gitbooks.io/superorganism/content/allpen.jpg</a></p>
<p>每个等式右边的第二个向量表示变化前拥有什么，右边的第一个向量表示变化时各拿几个，而等式的左边表示变化后获得了什么。从中可以看出来：</p>
<blockquote>
<p>向量点乘(dot product)是一种组合(combination)</p>
</blockquote>
<p><strong>矩阵乘向量</strong></p>
<p>四、有没有其他描述方式？</p>
<p>可以把（eq.1）（eq.2）合二为一，表示为（eq.4）：<br>（eq.1）I have a pen, I have an apple—-&gt;apple pen，<br>（eq.2）I have a pen, I have a pineapple—-&gt;pineapple pen</p>
<p>[applepenpineapplepen][applepenpineapplepen][][applepenpineapplepen] = [100111]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[100111][]⋅[applepineapplepen][101011]⋅[applepineapplepen]  （eq.4） 1</p>
<p>此时，表示各拿几个的向量变成了两行（两组）向量，也就成了矩阵（向量是只有一行或一列的矩阵）。 每个向量也叫一组权重(weights)。</p>
<p>在 [101][101][101] 中，第一个1对应着apple，第二个0对应着pineapple，第三个1对应着pen。不可以随意调换位置，所以，</p>
<blockquote>
<p>向量是有顺序的一组数字，每个数字是向量的一个因素(element)<br>因素横着排列的向量叫做行向量(row vector)<br>因素竖着排列的向量叫做列向量(column vector)<br>更具体的描述一下第一个结论。向量点乘是一种组合，但<br>向量点乘是一个向量中各个因素的一个组合</p>
</blockquote>
<p>五、如何计算矩阵乘向量？<br>（eq.4）可分两步：<br>计算第一行权重形成的组合：  [101]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[101]⋅[applepineapplepen][101]⋅[applepineapplepen] 得到的组合apple pen后，放到第一行 [applepen][applepen][][applepen] 。<br>计算第二行权重形成的组合：  [011]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[011]⋅[applepineapplepen][011]⋅[applepineapplepen] 得到的组合pineapple pen后，放到第二行 [pineapplepen][pineapplepen][][pineapplepen] 。<br>行成的 [applepenpineapplepen][applepenpineapplepen][][applepenpineapplepen] 依然有顺序，仍然是一个向量。比较向量点乘，可以看出</p>
<blockquote>
<p>矩阵乘向量是向量中各个因素有顺序的多个组合</p>
</blockquote>
<p>向量乘矩阵</p>
<p>六、形成组合的成分一定是元素（数）吗？<br>形成组合的成分并非一定是向量中的各个元素，也可以是不同向量之间形成组合。<br>可以把（eq.1）（eq.2）（eq.3）所完成的行为改写成（eq.5）（eq.6）：<br>[applepenpineapplepen][applepenpineapplepen][applepenpineapplepen] = [11]⋅[penapplepenpineapple][11]⋅[penapplepenpineapple][][11]⋅[penpenapplepineapple]  （eq.5）<br>[penpineappleapplepen][penpineappleapplepen][penpineappleapplepen] = [pineapplepenapplepen]⋅[11][pineapplepenapplepen]⋅[11][][pineapplepenapplepen]⋅[11]  （eq.6）<br>（eq.5）等式右侧的矩阵由两个行向量组成。</p>
<ul>
<li>矩阵中的第一个行向量表示两次组合中分别先拿什么，第二个行向量表示两次组合中分别后拿什么。</li>
<li>权重 [11][11][11] 的第一个因素对应着矩阵中第一个行向量的个数，第二个因素表示右侧第二个行向量的个数。</li>
<li>矩阵中每个行向量内部因素的比例不变，整体完成矩阵内向量与向量之间的组合。</li>
</ul>
<blockquote>
<p>向量乘矩阵可以是矩阵中各个行向量有顺的多个组合</p>
</blockquote>
<p>你会发现（eq.6）不同于（eq.5），要形成组合的向量被拿到了乘法点(dot)的左边，而权重被拿到了右边。</p>
<ul>
<li>效果是拿一个penpineapple和一个applepen形成组合。</li>
<li>因为当行向量的因素作为组合成分时，乘法点右侧的矩阵（向量）是权重的信息。<br>可以看出矩阵乘法并不满足乘法交换律，因为交换了两个矩阵的位置，就交换了权重与要形成组合的向量的位置。<blockquote>
<p>矩阵乘法不满足乘法交换律：commutative law: AB =! BA</p>
</blockquote>
</li>
</ul>
<p><strong>矩阵乘矩阵</strong></p>
<p>七、可以进行批量组合吗？<br>矩阵乘矩阵就可以看作是对一个矩阵中各个向量的批量线性组合。<br>如果视频中跳了两遍舞蹈。第二遍跳舞时，他在两次组合中，首次拿的东西都是两个，那么就可以把（eq.5）等式右侧的行向量变成两个行向量，形成了一个矩阵。<br>[applepenapple+2∗penpineapplepenpineapple+2∗pen][applepenapple+2∗penpineapplepenpineapple+2∗pen][][applepenpineapplepenapple+2∗penpineapple+2∗pen] = [1211]⋅[penapplepenpineapple][1211][]⋅[penapplepenpineapple][][1121]⋅[penpenapplepineapple]</p>
<p>在唱第二遍时，就要唱：<br>I have two pens. I have an apple. Apple-2pens!<br>I have two pens. I have a pineapple. Pineapple-2pens!</p>
<p>之前仅仅是把单词放在一起，并没有说明他们是如何组合的。而上式中终于写出了：pineapple +2*pen。</p>
<p><strong>也就是只有乘法来控制数量，加法来组合不同向量。这样的组合方式才是线性代数讨论的组合，即线性组合。</strong></p>
<p>所以所有已概括的结论中，组合前面都要加上“线性”两个字。同时控制数量的数是属于什么数要事先规定好（经常被规定为是实数 ∈R∈R∈R ，也有虚数域）。<br>不过这还没有结束，严谨性是数学的特点。上文所说的“加法”和“乘法”也只不过是个名字而已。它们到底指的是什么运算，遵循什么样的规则需要明确规定。<br>当你看线性代数教材的时候，你就会发现这8条规则。</p>
<ul>
<li>x+y=y+x</li>
<li>x+(y+z)=(x+y)+z</li>
<li>有一个唯一的“零向量” 对任意 x 都能使 x+0=x</li>
<li>每个 x都有一个唯一的相反数使得 x+(−x)=0</li>
<li>1x=x</li>
<li>(c1c2)x=c1(c2x)</li>
<li>c(x+y)=cx+cy</li>
<li>(c1+c2)x=c1x+c2x(c1+c2)x=c1x+c2x</li>
</ul>
<p>不需要去记它们。只需要知道，它们是用于描述和约束在线性代数中的加法，乘法的运算。</p>
<p>特别要注意的是，这些运算都有一个原点（0），为了允许正负的出现。</p>
<blockquote>
<p>线性组合：向量乘上各自对应的标量后再相加所形成的组合。（满足上述对乘法、加法的规则）</p>
</blockquote>
<p>##矩阵是什么##</p>
<p>八、熟悉了各个乘法后，矩阵到底是什么？</p>
<p><strong>线性代数是用来描述状态和变化的，而矩阵是存储状态和变化的信息的媒介。</strong></p>
<p>矩阵的信息可以分为状态（静态）和变化（动态）信息来看待。</p>
<p><strong>矩阵的静态信息</strong></p>
<p>当把矩阵以静态信息来看待时，其信息的侧重点在于状态二字。<br>向量可用于描述一个事物的状态，该事物的状态由向量内各个因素来描述。<br>而矩阵可以视为多个维度（因素的个数）相同的向量的有序排列。<br>同时矩阵也可以视为一个“向量”，用于描述一个事物的状态，内部的每个向量就是矩阵的“因素”，该事物的状态由矩阵内各个向量来描述。</p>
<p><strong>多个标量有序排列后形成向量，多个向量有序排列后形成矩阵，多个矩阵有序排列后形成三维张量（3D tensor）。 所以标量可以视为因素个数为1的向量，向量可以视为因素个数为1的矩阵，矩阵可以视为因素个数为1的三维张量（3D tensor）。</strong></p>
<p>坐标值与坐标系：</p>
<p><strong>描述一个事物的状态需要在一个选好的坐标系中进行，所以矩阵所包含的信息从来都是成对出现。</strong></p>
<p>向量举例来说，这个向量并没有被赋予任何数值。但已经确定了我们要在apple的数量和pen的数量的两个因素（两个维度）下描述数据。换句话说，坐标系已被规定好。所以当写出任何具有实际数值的向量，如时，坐标系（二维向量空间）和坐标值就同时被确定了。它实际上是和的缩写。二者无法分割。即使是，虽然pen，apple前没有任何具体数字。但依然包含所有因素间的比例相同的隐含信息。调换2和1的顺序同时也表示坐标轴之间的调换。</p>
<p>矩阵的动态信息</p>
<p><strong>当把矩阵以动态信息来看待时，其信息的侧重点在于变化二字。这时的矩阵可以看做是一个方程。</strong><br><strong>变化可以理解为由于矩阵的作用，事物本身的变化，也可以理解为坐标系的变化。</strong><br><strong>向量可用于控制变化时所用成分的数量，即一组权重。</strong><br>矩阵可以视为多个维度（因素的个数）相同的权重的有序排列。可对另一个矩阵的静态信息进行批量变化。</p>
<p>矩阵乘法是什么</p>
<p><strong>矩阵可以被视为载有状态和变化两种信息的媒介。而矩阵乘法就是变化的行为。</strong><br>在一个矩阵内，把矩阵内的向量理解为向量或权重都可以。<br>但是当两个矩阵进行矩阵乘法时，一旦选择以动态信息理解其中一个矩阵，另一个矩阵的信息就会被瞬间静态信息。</p>
<blockquote>
<p>两个矩阵相乘，一个矩阵提供状态信息，另个矩阵提供变化信息。</p>
</blockquote>
<p>两个矩阵相乘 时，</p>
<blockquote>
<p>当把前者矩阵(A)中行向量理解成若干组权重，后者矩阵(B)中的行向量就是要形成组合的成分。</p>
</blockquote>
<p><img src="https://yjango.gitbooks.io/superorganism/content/rowmatirx.jpg" alt=""></p>
<blockquote>
<p>当把后者矩阵(B)中列向量理解成若干组权重，前者矩阵(A)中的列向量就是要形成组合的成分。</p>
</blockquote>
<p><img src="https://yjango.gitbooks.io/superorganism/content/columnmatirx.jpg" alt=""></p>
<p>注意对应行向量与列向量。</p>
<p><strong>转置一个矩阵可以理解为调换一个矩阵的动态与静态信息。</strong></p>
<p>单位矩阵可以被理解为动态与静态信息相同。</p>
<p>回想线性组合的描述（向量乘上各自对应的标量后再相加所形成的组合），因为向量的维度和权重的维度要一一对应。所以，</p>
<blockquote>
<p>矩阵A(m by n)和矩阵B(p by q)能够做乘法的条件是 n = p</p>
</blockquote>
<h2 id="向量空间"><a href="#向量空间" class="headerlink" title="向量空间"></a>向量空间</h2><p>很多线性代数教材所引入的第一个概念就是线性空间（linear space）。可见它的地位。虽然它有些抽象，但是却是自然而然推演出来的一个概念。</p>
<p>九、空间是什么？</p>
<p><strong>空间的本质是集合。而且是一个能够容纳所有要描述状态的集合。若超过空间范围，就该寻找正确的空间。</strong></p>
<p>对“要描述内容”进行进一步说明，需从如何理解线性代数这四个字开始。</p>
<p>我们已经知道了 <strong>什么是线性（那8个条件约束的加法和乘法）</strong>。<br><strong>那什么是代数？意思是指你可以把任何概念都代入其中。</strong></p>
<p>看视频的时候，人们自然而然的会把苹果菠萝换成其他事物，比如PPAP河南话版。也可以换成任何宇宙上有的物体。<br>不仅仅是物体，甚至可以是一个抽象的概念。</p>
<p>我个人最喜欢的描述是：</p>
<blockquote>
<p>向量空间是描述状态(state)的线性空间。再加上之前的约束，于是我们就有了向量空间是能够容纳所有线性组合的状态空间</p>
</blockquote>
<p>十、什么样的状态空间能够容纳所有的线性组合？</p>
<p>情景：假如要描述一个人的两个状态（下图中的行向位置和纵向位置），向量的维度就是二维。那么一个大圆盘够不够容纳所有的线性组合？答案是不够。</p>
<p><img src="https://yjango.gitbooks.io/superorganism/content/plain.jpg" alt=""></p>
<p>因为线性组合是向量乘以各自对应的标量后再相加所形成的组合，而这个标量是实数域的时候，由于实数域无线延伸，那么乘以标量后的状态也会无限延伸。所以 <strong>向量空间一定是各个维度都像实数轴一样可以无线延伸。最终得到的将不会是一维下的线段，二维下的圆盘。而一定是一维下的无限延伸的直线，二维下的无限延伸的平面。</strong></p>
<p>向量空间的基本特点是各个维度都可以无限延伸，且过原点。<br>之所以用状态二字，是因为刚才的两个维度，可以用于描述速度和体温。这时两个维度所展开的依然是一个平面，但却不是描述位置的平面。</p>
<h2 id="子空间"><a href="#子空间" class="headerlink" title="子空间"></a>子空间</h2><p>子空间（subspace）可以被想成是向量空间内的向量空间，同样要满足能够容纳线性组合的条件。</p>
<p>十一、最小的子空间是什么？<br>只有一个状态的空间（集合）。这个状态不是其他状态，就是0。只有这样才可以在乘以标量后依然不会跑出空间外。</p>
<p>十二、其次空集可不可以是向量空间？<br>不可以，空集是没有任何元素的集合，既然什么状态都没有，又怎么能够容纳线性组合。<br>最小的向量空间是只包含零向量的空间</p>
<p>十三、假如上图的圆盘是个无线延伸的平面，那平面的子空间可以是平面上所有直线吗？<br>不可以，8个运算规则中明确规定了，一定要有原点，这样才可以包含正负。所以这个平面的子空间是所有过原点的直线，加上中心的那个原点自己所组成的最小子空间，再加上这个平面自身（最大的子空间）。</p>
<h2 id="线性无关"><a href="#线性无关" class="headerlink" title="线性无关"></a>线性无关</h2><p>十四、该如何选择因素？</p>
<p>在视频的例子中，当要把（eq.1）（eq.2）合为（eq.4）时，是这个样子： = （eq.4），但最右侧的向量并不是4个维度。而是三个。因为pen 和pen是一个东西。</p>
<p>我们想用的是 <strong>若干个毫不相关的因素去描述状态。在线性空间下的毫不相关，叫做线性无关。</strong></p>
<p>十五、要描述的状态是由向量来描述时怎么办？</p>
<p><strong>判断两个向量是否线性无关时，可以看他是否在空间下平行。</strong></p>
<p>但怎么判断几个向量之间（不一定是两个）是否线性无关？我们需要可靠的依据。<br>线性无关（linearly independent）: 当表示权重，表示向量时，<br>只发生在when 全都等于零时。</p>
<blockquote>
<p>换句话说，这些向量不可以通过线性组合形成彼此。形成彼此的情况只能是他们都是零向量。</p>
</blockquote>
<h2 id="张成"><a href="#张成" class="headerlink" title="张成"></a>张成</h2><p>注意词的属性和关联词。<br>张成（spanning）是一个动词，动词的主语是一组向量（a set of vectors）。<br>描述的是一组向量通过线性组合所能形成子空间。描述的内容并不是形成的这个空间，而是形成的这个行为。</p>
<p>，是4个向量，但只可以张成一个三维空间。（因为有两维线性相关，所以并不能张成4维）</p>
<p>基底</p>
<p>一个向量空间的一个基底（A basis for a vector space V）是一串有顺序的向量（a sequence of vectors），满足：<br>A、向量之间彼此线性无关 （不可多余）<br>B、这些向量可以张成向量空间V （不可过少）<br><strong>刚刚好可以张成向量空间V的一串向量是该向量空间V的一个基底.</strong><br>基底是一个类似people的复数名词，是从属于某个空间的，而不是矩阵，也不是向量。</p>
<h2 id="维度"><a href="#维度" class="headerlink" title="维度"></a>维度</h2><p><strong>一个向量空间可以有无数个基底。但每个基底所包含的向量的个数（the number of vectors in every basis）是一个空间的维度。</strong></p>
<p>注意：维度是空间的概念，而不是描述一个具体的向量。人们常说的n维向量实际是指n维向量空间内的向量，由于在讨论时并未给向量指定任何实际的数值，所以可以是任何值，可以张成整个空间。所以其真正描述的依旧是一个空间。并且，维度是站在观察者角度，希望在某个向量空间下尽可能的描述物体状态而选择的，并不一定是被描述者真实处在的空间。</p>
<p>但若是你觉得理解起来有困难。就简单记住：<br><strong>互不相关的因素的个数是一个向量空间的维度</strong></p>
<h2 id="秩"><a href="#秩" class="headerlink" title="秩"></a>秩</h2><p>矩阵可以视为动态和静态信息的媒介。而 <strong>一个具体的矩阵到底涵盖了多少信息可以由秩（rank）来描述。</strong><br>指的是一个矩阵的所有列向量所能张成的空间的维度。<br>矩阵的所有列向量所张成的空间叫做列空间（column space）<br>矩阵的所有行向量所张成的空间叫做行空间（row space）<br><strong>一个矩阵的列空间的维度是这个矩阵的秩，同时也等于该矩阵行空间的维度</strong><br>秩是用于描述矩阵所包含信息量的。</p>
<h2 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h2><p>最终我们想要做的就是描述事物的变化。上文所有的内容都可以说是为此刻所做的铺垫。<br><strong>矩阵乘以矩阵可以视作一个矩阵内部向量的批量线性变换（linear transformation）。</strong> 所以可以仅讨论由矩阵乘以向量所形成的一次线性变换。</p>
<h2 id="十六、什么是变换？"><a href="#十六、什么是变换？" class="headerlink" title="十六、什么是变换？"></a>十六、什么是变换？</h2><p>这里写图片描述</p>
<p><img src="http://img.blog.csdn.net/20161019110942425" alt=""><br>by David C.Lay</p>
<p>一个从n维实数域（）到m维实数域（）的变换（transformation or mapping or function）是将n维实数域（）空间下任意一个向量转换成为在m维实数域（）空间下对应向量<br>其中n维实数域（）空间叫做变换的domain，m维实数域（）空间叫做该变换的codomain。<br>向量叫做向量的image（变换行为下的）<br>所有image组成的集合叫做变换的range</p>
<p>而线性变换是是指线性规则所造成的变换，是由一个矩阵来实现的。此时你就会看到无处不在的式子：</p>
<blockquote>
<p>y=Ax  ：列向量 xx 左乘一个矩阵 AA 后得到列向量 yy</p>
</blockquote>
<p>= （eq.4）举例来说， 是三维空间的向量（即的domain是三维），而经过线性变换后，变成了二维空间的向量（即的codomain是二维）。</p>
<p>矩阵可以被理解成一个函数(function)，将三维空间下的每个向量投到二维空间下。<br><strong>y=Ax  也可以理解为经由一个外力，使其状态发生了改变。</strong><br>同时也是深层神经网络每层变换中的核心：y=a(Ax+b)</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.gitbook.com/book/yjango/superorganism/details&quot;&gt;作者：yjango&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;生命不限于个体。并非所有生命拥有意识，但所有生命都拥有智能。这些智能体通过大量并行和多层迭代的方式形成新的智能体。细胞、器官、个体、国家、地球，不论从哪个层级上观察，都是一个“智能体”。&lt;br&gt;人类作为智能的一环，需跳出自身层级，用超出人类自身感知、情感和意识的方式去理解生命。&lt;/p&gt;
&lt;h2 id=&quot;关于本书&quot;&gt;&lt;a href=&quot;#关于本书&quot; class=&quot;headerlink&quot; title=&quot;关于本书&quot;&gt;&lt;/a&gt;关于本书&lt;/h2&gt;&lt;p&gt;该书最终的目的是：通过理解智能，学习如何学习。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何机器学习&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如何大脑学习&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
      <category term="Algorithm" scheme="http://ipcreator.me/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>A Visual and Interactive Guide to the Basics of Neural Networks</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/visual-interactive-guide-basics-neural-networks/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/visual-interactive-guide-basics-neural-networks/</id>
    <published>2017-02-17T02:36:06.000Z</published>
    <updated>2017-02-17T15:14:57.701Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/" target="_blank" rel="external">J Alammar</a></p>
<p><img src="https://jalammar.github.io/images/NNs_2_variables.png" alt=""></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>I’m not a machine learning expert. I’m a software engineer by training and I’ve had little interaction with AI. I had always wanted to delve deeper into machine learning, but never really found my “in”. That’s why when Google open sourced TensorFlow in November 2015, I got super excited and knew it was time to jump in and start the learning journey. Not to sound dramatic, but to me, it actually felt kind of like Prometheus handing down fire to mankind from the Mount Olympus of machine learning. In the back of my head was the idea that the entire field of Big Data and technologies like Hadoop were vastly accelerated when Google researchers released their Map Reduce paper. This time it’s not a paper – it’s the actual software they use internally after years and years of evolution.</p>
<p>So I started learning what I can about the basics of the topic, and saw the need for gentler resources for people with no experience in the field. This is my attempt at that.</p>
  <a id="more"></a>
<h2 id="start-here">Start here</h2><br><p>Let’s start with a simple example. Say you’re helping a friend who wants to buy a house. She was quoted $400,000 for a 2000 sq ft house (185 meters). Is this a good price or not?</p><br><br><p>It’s not easy to tell without a frame of reference. So you ask your friends who have bought houses in that same neighborhoods, and you end up with three data points:</p><br><br><div class="one_variable"><br><br>  <table><br>    <thead><br>      <tr><br>        <th>Area (sq ft) (x)</th><br>        <th>Price (y)</th><br>      </tr><br>    </thead><br>    <tbody><br>      <tr><br>        <td>2,104</td><br>        <td>399,900</td><br>      </tr><br>      <tr><br>        <td>1,600</td><br>        <td>329,900</td><br>      </tr><br>      <tr><br>        <td>2,400</td><br>        <td>369,000</td><br>      </tr><br>    </tbody><br>  </table><br><br></div><br><br><p>Personally, my first instinct would be to get the average price per sq ft. That comes to $180 per sq ft.</p><br><br><p>Welcome to your first neural network! Now it’s not quite at Siri level yet, but now you know the fundamental building block. And it looks like this:</p><br><br><div class="img-div"><br>    <img src="/images/simple_NN_1.png"><br></div><br><br><p>Diagrams like this show you the structure of the network and how it calculates a prediction. The calculation starts from the input node at the left. The input value flows to the right. It gets multiplied by the weight and the result becomes our output.</p><br><br><p>Multiplying 2,000 sq ft by 180 gives us $360,000. That’s all there is to it at this level. Calculating the prediction is simple multiplication. But before that, we needed to think about the weight we’ll be multiplying by. Here we started with an average, later we’ll look at better algorithms that can scale as we get more inputs and more complicated models. Finding the weight is our “training” stage. So whenever you hear of someone “training” a neural network, it just means finding the weights we use to calculate the prediction.</p><br><br><div class="img-div"><br>    <img src="/images/NNs_formula_no_bias.png"><br></div><br><br><p>This is a form of prediction. This is a simple predictive model that takes an input, does a calculation, and gives an output (since the output can be of continuous values, the technical name for what we have would be a “regression model”)</p><br><br><p>Let us visualize this process (for simplicity, let’s switch our price unit from $1 to $1000. Now our weight is 0.180 rather than 180):</p><br><br><p class="gif-space"></p><br><br><p><img src="/images/data_points_graph_animated.gif" alt=""></p><br><br><p class="gif-space"></p><br><br><p class="gif-space"></p><br><br><h2 id="harder-better-faster-stronger">Harder, Better, Faster, Stronger</h2>

<p>Can we do better than estimate the price based on the average of our data points? Let’s try. Let’s first define what it means to be better in this scenario. If we apply our model to the three data points we have, how good of a job would it do?</p>

<p class="gif-space"></p>

<p><img src="/images/data_points_error_animated.gif" alt=""></p>

<p class="gif-space"></p>

<p>That’s quite a bit of yellow. Yellow is bad. Yellow is error. We want to shrink yellow as much as we can.</p>

<div class="one_variable"><br><br>  <div class="one_variable"><br><br>    <table><br>    <thead><br>      <tr><br>        <th>Area (x)</th><br>        <th>Price ($1000) (<span class="y_">y<em></em></span>)</th><br>        <th>Prediction (<span class="y">y</span>)</th><br>        <th>&lt;span class=”y“&gt;y<em>-<span class="y">y</span></em></th><br>        <th>(&lt;span class=”y“&gt;y_-<span class="y">y</span>)²</th><br>      </tr><br>    </thead><br>    <tbody><br>      <tr><br>        <td>2,104</td><br>        <td>399.9</td><br>        <td>379</td><br>        <td>21</td><br>        <td>449</td><br>      </tr><br>      <tr><br>        <td>1,600</td><br>        <td>329.9</td><br>        <td>288</td><br>        <td>42</td><br>        <td>1756</td><br>      </tr><br>      <tr><br>        <td>2,400</td><br>        <td>369</td><br>        <td>432</td><br>        <td>-63</td><br>        <td>3969</td><br>      </tr><br>      <tr><br>        <td> </td><br>        <td> </td><br>        <td colspan="2" align="right"><span class="total"> Average:</span></td><br>        <td><b>2,058</b></td><br>      </tr><br>    </tbody><br>  </table><br><br>  </div>

<p></p></div><p></p>
<p>Here we can see the <span class="y_">actual price value</span>, the <span class="y">predicted price value</span>, and the <span class="error-value">difference between them</span>. Then we’ll need to average these differences so we have a number that tells us how much error there is in this prediction model. The problem is, the 3rd row has -63 as its value. We have to deal with this negative value if we want to use the difference between the prediction and price as our error measuring stick. That’s one reason why we introduce an additional column that shows the error squared, thus getting rid of the negative value.</p>

<p>This is now our definition of doing better – a better model is one that has less error. Error is measured as the average of the errors for each point in our data set. For each point, the error is measured by the difference between the actual value and the predicted value, raised to the power of 2. This is called <a href="http://mste.illinois.edu/patel/amar430/meansquare.html" target="_blank" rel="external">Mean Square Error</a>. Using it as a guide to train our model makes it our <strong>loss function</strong> (also, <strong>cost function</strong>).</p>

<p>Now that we defined our measuring stick for what makes a better model, let’s experiment with a couple more weight values and compare them with our average pick:</p>

<p class="gif-space"></p>

<p><img src="/images/lines_and_errors_animated.gif" alt=""></p>

<div class="img-div"><br>We can’t improve much on the model by varying the weight any more. But if we add a bias we can find values that improve the model.<br></div><br><p class="gif-space"></p><br><br><p>Our lines can better approximate our values now that we have this b value added to the line formula. In this context, we call it a “bias”. This makes our neural network look like this:</p><br><br><div class="img-div"><br>    <img src="/images/NNs_bias.png"><br></div>

<p>We can generalize it by saying that a neural network with one input and one output (<em>spoiler warning:</em> and no hidden layers) looks like this:</p>

<div class="img-div"><br>    <img src="/images/NNs_bias_2.png"><br></div><br><p>In this graph, W and b are values we find during the training process. X is the input we plug into the formula (area in sq ft in our example). Y is the predicted price.</p><br><br><p>Calculating a prediction now uses this formula:</p><br><br><div class="img-div"><br>    <img src="/images/NNs_formula.png"><br></div>

<p>So our current model calculates predictions by plugging in the area of house as x in this formula:</p>

<div class="img-div"><br>    <img src="/images/NNs_formula_ex.png"><br></div>

<h2 id="train-your-dragon">Train Your Dragon</h2><br><p>How about you take a crack at training our toy neural network? Minimize the loss function by tweaking the weight and bias dials. Can you get an error value below 799?</p><br><br><div id="training-one-chart" class="training-chart"></div><br><table id="training-one" class="training-table"><br>    <tr><br>        <td><br>            Error<br>        </td><br>        <td colspan="2"><br>            <span id="error-value"></span><br>        </td><br>    </tr><br>    <tr><br>        <td class="error-cell" colspan="3"><br>            <span id="error-value-message"></span>&nbsp;<br>        </td><br>    </tr><br>    <tr><br>        <td><br>            Weight<br>        </td><br>        <td><br>            <input id="weightSlider" type="range" class="weight" min="0" max="0.4" step="0.001"><br>        </td><br>        <td class="slider-value"><br>            <span id="weight" class="weight">0</span><br>        </td><br>    </tr><br>    <tr><br>        <td><br>            Bias<br>        </td><br>        <td><br>            <input id="biasSlider" type="range" class="bias" min="0" max="460" step="1"><br>        </td><br>        <td class="slider-value"><br>            <span id="bias" class="bias">0</span><br>        </td><br>    </tr><br></table><br><br><div id="neural-network-graph" class="nn-graph-area"></div><br><br><h2 id="automation">Automation</h2><br><p>Congratulations on manually training your first neural network! Let’s look at how to automate this training process. Below is another example with an additional autopilot-like functionality. These are the GD Step buttons. They use an algorithm called “Gradient Descent” to try to step towards the correct weight and bias values that minimize the loss function.</p><br><br><div class="container"><br>    <div class="row"><br><br>        <div class="col-sm-6 graphs"><br>            <div id="training-one-gd-chart" class="training-chart"></div><br><br><br>                <div class="row training-chart mini-charts"><br>                    <div id="training-one-gd-error-chart" class="error-chart col-xs-6"></div><br>                    <div id="training-one-gd-heatmap" class="error-chart col-xs-6"></div><br>                </div><br><br>        </div><br><br>        <div class="col-sm-6"><br><br>            <table id="training-one-gd" class="training-table"><br>                <tr><br>                    <td colspan="3" class="gd-buttons"><br>                        <input type="button" value="GD Step" id="gradient-descent-button" class="btn btn-primary"><br>                        <input type="button" value="10 GD Steps " id="gradient-descent-10-button" class="btn btn-primary"><br>                        <input type="button" value="100 GD Steps " id="gradient-descent-100-button" class="btn btn-primary"><br>                    </td><br>                </tr><br>                <tr><br>                    <td><br>                        Error<br>                    </td><br>                    <td colspan="2"><br>                        <span id="error-value"></span><br>                    </td><br><br>                </tr><br><br>                <tr><br>                    <td class="error-cell" colspan="3"><br>                        <span id="error-value-message"></span>&nbsp;<br>                    </td><br><br>                </tr><br>                <tr><br>                    <td><br>                        Weight<br>                    </td><br>                    <td><br>                        <input id="weightSlider" type="range" class="weight" min="0" max="0.4" step="0.0001"><br>                    </td><br>                    <td class="slider-value"><br>                        <span id="weight" class="weight">0</span><br>                    </td><br>                </tr><br>                <tr><br>                    <td><br>                        Bias<br>                    </td><br>                    <td><br>                        <input id="biasSlider" type="range" class="bias" min="0" max="460" step="0.1"><br>                    </td><br>                    <td class="slider-value"><br>                        <span id="bias" class="bias">0</span><br>                    </td><br>                </tr><br>            </table><br><br>            <div id="neural-network-gd-graph" class="nn-graph-area"></div><br>        </div><br>    </div><br></div><br><br><p>The two new graphs are to help you track the error values as you fiddle with the parameters (weight and bias) of the model. It’s important to keep track of the error as the training process is all about reducing this error as much possible.</p><br><br><p>How does gradient descent know where its next step should be? Calculus. You see, knowing the function we’re minimizing (our loss function, the average of (y_ - y)² for all our data points), and knowing the current inputs into it (the current weight and bias), the derivatives of the loss function tell us which direction to nudge W and b in order to minimize the error.</p><br><br><p>Learn more about gradient descent and how to use it to calculate the new weights &amp; bias in the first lectures of Coursera’s <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">Machine Learning</a> course.</p><br><br><h2 id="and-then-there-were-two">And Then There Were Two</h2>

<p>Is the size of the house the only variable that goes into how much it costs? Obviously there are many other factors. Let’s add another variable and see how we can adjust our neural network to it.</p>

<p>Say your friend does a bit more research and finds a bunch more data points. She also finds out how many bathrooms each house has:</p>

<div class="two_variables"><br><br>  <table><br>    <thead><br>      <tr><br>        <th>Area (sq ft) (x1)</th><br>        <th>Bathrooms (x2)</th><br>        <th>Price (y)</th><br>      </tr><br>    </thead><br>    <tbody><br>      <tr><br>        <td>2,104</td><br>        <td>3</td><br>        <td>399,900</td><br>      </tr><br>      <tr><br>        <td>1,600</td><br>        <td>3</td><br>        <td>329,900</td><br>      </tr><br>      <tr><br>        <td>2,400</td><br>        <td>3</td><br>        <td>369,000</td><br>      </tr><br>      <tr><br>        <td>1,416</td><br>        <td>2</td><br>        <td>232,000</td><br>      </tr><br>      <tr><br>        <td>3,000</td><br>        <td>4</td><br>        <td>539,900</td><br>      </tr><br>      <tr><br>        <td>1,985</td><br>        <td>4</td><br>        <td>299,900</td><br>      </tr><br>      <tr><br>        <td>1,534</td><br>        <td>3</td><br>        <td>314,900</td><br>      </tr><br>      <tr><br>        <td>1,427</td><br>        <td>3</td><br>        <td>198,999</td><br>      </tr><br>      <tr><br>        <td>1,380</td><br>        <td>3</td><br>        <td>212,000</td><br>      </tr><br>      <tr><br>        <td>1,494</td><br>        <td>3</td><br>        <td>242,500</td><br>      </tr><br>    </tbody><br>  </table><br><br></div>

<p>Our neural network with two variables looks like this:</p>

<div class="img-div"><br>    <img src="/images/NNs_2_variables.png"><br></div>

<p>We now have to find two weights (one for each input) and one bias to create our new model.</p>

<p>Calculating Y looks like this:</p>

<div class="img-div"><br>    <img src="/images/NNs_formula_two_variables.png"><br></div>

<p>But how do we find w1 and w2? This is a little trickier than when we only had to worry about one weight value. How much does having an extra bathroom change how we predict the value of a home?</p>

<p>Take a stab at finding the right weights and bias. You will start here to see the complexity we start getting into as the number of our inputs increase. We start losing the ability to create simple 2d shapes that allow us to visualize the model at a glance. Instead, we’ll have to mainly rely on how the error value is evolving as we tweak our model parameters.</p>

<div class="container"><br>    <div class="row"><br><br>        <div class="col-sm-6 graphs"><br>            <div id="training-two-chart" class="error-chart"></div>

<pre><code>    &lt;/div&gt;

    &lt;div class=&quot;col-sm-6&quot;&gt;

        &lt;table id=&quot;training-two-table&quot; class=&quot;training-table&quot;&gt;
            &lt;tr&gt;
                &lt;td colspan=&quot;3&quot; class=&quot;gd-buttons&quot;&gt;
                    &lt;input type=&quot;button&quot; value=&quot;GD Step&quot; id=&quot;gradient-descent-button&quot; class=&quot;btn btn-primary&quot; /&gt;
                    &lt;input type=&quot;button&quot; value=&quot;10 GD Steps &quot; id=&quot;gradient-descent-10-button&quot; class=&quot;btn btn-primary&quot; /&gt;
                    &lt;input type=&quot;button&quot; value=&quot;100 GD Steps &quot; id=&quot;gradient-descent-100-button&quot; class=&quot;btn btn-primary&quot; /&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    Error
                &lt;/td&gt;
                &lt;td colspan=&quot;2&quot;&gt;
                    &lt;span id=&quot;error-value&quot;&gt;&lt;/span&gt;
                &lt;/td&gt;

            &lt;/tr&gt;

            &lt;tr&gt;
                &lt;td class=&quot;error-cell&quot; colspan=&quot;3&quot;&gt;
                    &lt;span id=&quot;error-value-message&quot;&gt;&lt;/span&gt;&amp;nbsp;
                &lt;/td&gt;

            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    Weight #1
                &lt;/td&gt;
                &lt;td&gt;
                    &lt;input id=&quot;weight0Slider&quot; type=&quot;range&quot; class=&quot;weight&quot; min=&quot;-0.4&quot; max=&quot;0.4&quot; step=&quot;0.0001&quot; /&gt;
                &lt;/td&gt;
                &lt;td class=&quot;slider-value&quot;&gt;
                    &lt;span id=&quot;weight0&quot; class=&quot;weight&quot;&gt;0&lt;/span&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    Weight #2
                &lt;/td&gt;
                &lt;td&gt;
                    &lt;input id=&quot;weight1Slider&quot; type=&quot;range&quot; class=&quot;weight&quot; min=&quot;-100&quot; max=&quot;200&quot; step=&quot;0.0001&quot; /&gt;
                &lt;/td&gt;
                &lt;td class=&quot;slider-value&quot;&gt;
                    &lt;span id=&quot;weight1&quot; class=&quot;weight&quot;&gt;0&lt;/span&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    Bias
                &lt;/td&gt;
                &lt;td&gt;
                    &lt;input id=&quot;biasSlider&quot; type=&quot;range&quot; class=&quot;bias&quot; min=&quot;-100&quot; max=&quot;300&quot; step=&quot;0.1&quot; /&gt;
                &lt;/td&gt;
                &lt;td class=&quot;slider-value&quot;&gt;
                    &lt;span id=&quot;bias&quot; class=&quot;bias&quot;&gt;0&lt;/span&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
        &lt;/table&gt;

        &lt;div id=&quot;neural-network-two-graph&quot; class=&quot;nn-graph-area&quot;&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
</code></pre><p></p></div><p></p>
<p>Our trusty gradient descent is here to help once again. It still is valuable in helping us find the right weights and bias.</p>

<h2 id="features">Features</h2><br><p>Now that you’ve seen neural networks with one and two features, you can sort of figure out how to add additional features and use them to calculate your predictions. The number of weights will continue to grow, and our implementation of gradient descent will have to be tweaked as we add each feature so that it can update the new weights associated with the new feature.</p><br><br><p>It’s important to note here that we don’t blindly feed the network everything we know about our examples. We have to be selective about which features we feed the model. Feature selection/processing is an entire discipline with its own set of best practices and considerations. If you want to see an example of the process of examining a dataset to choose which features to feed a prediction model, check out  <a href="https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic" target="_blank" rel="external">A Journey Through Titanic</a>. It’s a notebook where <a href="https://twitter.com/Omar_ElGabry" target="_blank" rel="external">Omar EL Gabry</a> narrates his process for solving Kaggle’s Titanic challenge. Kaggle makes available the passenger’s manifest of the Titanic including data like name, sex, age, cabin, and whether the person survived or not. The challenge is to build a model that predicts whether a person survived or not given their other information.</p><br><br><h2 id="classification">Classification</h2>

<p>Let’s continue to tweak our example. Assume your friend gives you a list of houses. This time, she has labeled which ones she thinks have a good size and number of bathrooms:</p>

<div class="two_variables"><br><br>  <table><br>    <thead><br>      <tr><br>        <th>Area (sq ft) (x1)</th><br>        <th>Bathrooms (x2)</th><br>        <th>Label (y)</th><br>      </tr><br>    </thead><br>    <tbody><br>      <tr><br>        <td>2,104</td><br>        <td>3</td><br>        <td>Good</td><br>      </tr><br>      <tr><br>        <td>1,600</td><br>        <td>3</td><br>        <td>Good</td><br>      </tr><br>      <tr><br>        <td>2,400</td><br>        <td>3</td><br>        <td>Good</td><br>      </tr><br>      <tr><br>        <td>1,416</td><br>        <td>2</td><br>        <td>Bad</td><br>      </tr><br>      <tr><br>        <td>3,000</td><br>        <td>4</td><br>        <td>Bad</td><br>      </tr><br>      <tr><br>        <td>1,985</td><br>        <td>4</td><br>        <td>Good</td><br>      </tr><br>      <tr><br>        <td>1,534</td><br>        <td>3</td><br>        <td>Bad</td><br>      </tr><br>      <tr><br>        <td>1,427</td><br>        <td>3</td><br>        <td>Good</td><br>      </tr><br>      <tr><br>        <td>1,380</td><br>        <td>3</td><br>        <td>Good</td><br>      </tr><br>      <tr><br>        <td>1,494</td><br>        <td>3</td><br>        <td>Good</td><br>      </tr><br>    </tbody><br>  </table><br><br></div>

<p>She needs you to use this to create a model to predict whether she would like a house or not given its size and number of bathrooms. You will use this list above to build the model, then she will use the model to classify many other houses. One additional change in the process, is that she has another list of 10 houses she has labeled, but she’s keeping it from you. That other list would be used to evaluate your model after you’ve trained it – thus trying to ensure your model grasps the conditions that actually make her like the features of the house.</p>

<p>The neural networks we’ve been toying around with until now are all doing “regression” – they calculate and output a “continuous” value (the output can be 4, or 100.6, or 2143.342343). In practice, however, neural networks are more often used in “classification” type problems. In these problems, the neural network’s output has to be from a set of discrete values (or “classes”) like “Good” or “Bad”. How this works out in practice, is that we’ll have a model that will say that it’s 75% sure that a house is “Good” rather than just spit out “good” or “bad”.</p>

<div class="img-div"><br>    <img src="/images/android_tensorflow_classifier_results.jpg"><br>    The TensorFlow app I discussed in my <a href="https://jalammar.github.io/Supercharging-android-apps-using-tensorflow/" target="_blank" rel="external">previous post</a> is a good example for a classification model in practice.<br><br></div>

<p>One way we can transform the network we’ve seen into a classification network is to have it output two values – one for each class (our classes now being “good” and “bad”). We then pass these values through an operation called “<a href="https://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/" target="_blank" rel="external">softmax</a>”. The output of softmax is the probability of each class. For example, say that layer of the network outputs 2 for “good” and 4 for “bad”, if we feed [2, 4] to softmax, it will return [0.11,  0.88] as the output. Which translates the values to say the network is 88% sure that the inputted value is “bad” and our friend would not like that house.</p>

<p>Softmax takes an array and outputs an array of the same length. Notice that its outputs are all positive and sum up to 1 – which is useful when we’re outputting a probability value. Also notice that even though 4 is double 2, its probability is not only double, but is eight times that of 2. This is a useful property that exaggerates the difference in output thus improving our training process.</p>

<table><br>  <thead><br>    <tr><br>      <th> </th><br>      <th>output</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <td>softmax([ 1 ])</td><br>      <td>[ 1 ]</td><br>    </tr><br>    <tr><br>      <td>softmax([ 1, 1 ])</td><br>      <td>[ 0.5, 0.5 ]</td><br>    </tr><br>    <tr><br>      <td>softmax([ 0, 1 ])</td><br>      <td>[ 0.26,  0.73 ]</td><br>    </tr><br>    <tr><br>      <td>softmax([ 2, 4 ])</td><br>      <td>[ 0.11,  0.88 ]</td><br>    </tr><br>    <tr><br>      <td>softmax([ 5, 10 ])</td><br>      <td>[ 0.007,  0.993 ]</td><br>    </tr><br>    <tr><br>      <td>softmax([ -1, 0, 1 ])</td><br>      <td>[ 0.09,  0.24,  0.66 ]</td><br>    </tr><br>    <tr><br>      <td>softmax([ 1, 2, 4 ])</td><br>      <td>[ 0.04,  0.11,  0.84 ]</td><br>    </tr><br>  </tbody><br></table>

<p>As you can see in the last two rows, softmax extends to any number of inputs. So now if our friend adds a third label (say “Good, but I’ll have to airbnb one room”), softmax scales to accomedate that change.</p>

<p>Take a second to explore the shape of the network as you vary the number of features (x1, x2, x3…etc) (which can be area, number of bathrooms, price, proximity to school/work…etc) and vary the number of classes (y1, y2, y3…etc) (which can be “too expensive”, “good deal”, “good if I airbnb”, “too small”):</p>

<table><br>    <tr><br>        <td><br>            Features (x):<br>        </td><br>        <td><br>           <div class="input-group"><br>                  <span class="input-group-btn"><br>                      <button type="button" class="btn btn-default btn-number" data-type="minus" data-field="quant[1]"><br>                          <span class="glyphicon glyphicon-minus"></span><br>                      </button><br>                  </span><br>                  <input type="text" name="quant[1]" class="form-control input-number" value="2"><br>                  <span class="input-group-btn"><br>                      <button type="button" class="btn btn-default btn-number" data-type="plus" data-field="quant[1]"><br>                          <span class="glyphicon glyphicon-plus"></span><br>                      </button><br>                  </span><br>            </div><br>        </td><br>    </tr><br>    <tr><br>        <td><br>            Classes (y):<br>        </td><br>        <td><br>           <div class="input-group"><br>                  <span class="input-group-btn"><br>                      <button type="button" class="btn btn-default btn-number" data-type="minus" data-field="quant[2]"><br>                          <span class="glyphicon glyphicon-minus"></span><br>                      </button><br>                  </span><br>                  <input type="text" name="quant[2]" class="form-control input-number" value="2"><br>                  <span class="input-group-btn"><br>                      <button type="button" class="btn btn-default btn-number" data-type="plus" data-field="quant[2]"><br>                          <span class="glyphicon glyphicon-plus"></span><br>                      </button><br>                  </span><br>            </div><br>        </td><br>    </tr><br></table>

<div id="shallow-neural-network-graph" class="nn-graph-area"></div>

<p>You can see an example of how to create and train this network using TensorFlow in <a href="https://github.com/jalammar/simpleTensorFlowClassificationExample/blob/master/Basic%20Classification%20Example%20with%20TensorFlow.ipynb" target="_blank" rel="external">this notebook</a> I created to accompany this post.</p>

<p></p><h2 id="true-motivation">True Motivation</h2><p></p>
<p>If you have reached this far, I have to reveal to you another motivation of mine to write this post. This post is meant as an even gentler intro to TensorFlow tutorials. If you start working through <a href="https://www.tensorflow.org/versions/r0.10/tutorials/mnist/beginners/index.html" target="_blank" rel="external">MNIST For ML Beginners</a> now, and come across this graph:</p>

<div class="img-div"><br>    <img src="/images/softmax-regression-scalargraph.png"><br>    I wrote this post to prepare people without machine learning experience for this graph in the TensorFlow introductory tutorial. That’s why I simulated its visual style.<br></div>

<p>I hope you would feel prepared and that you have an understanding of this system and how it works. If you want to start tinkering with code, feel free to pick up from the intro <a href="https://www.tensorflow.org/versions/r0.10/tutorials/mnist/beginners/index.html" target="_blank" rel="external">tutorial</a> and teach a neural network how to detect handwritten digits.</p>

<p>You should also continue your education by learning the theoretical and mathematical underpinnings of the concepts we discussed here. Good questions to ask now include:</p>

<ul><br>  <li>What other kinds of cost functions exist? Which are better for which applications?</li><br>  <li>What’s the algorithm to actually calculate new weights using gradient descent?</li><br>  <li>What are the applications for machine learning in the fields you’re already knowledgeable about? What new magic can you wield by mixing this spell with others in your spell book?</li><br></ul>

<p>Great learning resources include:</p>

<ul><br>  <li>Coursera’s <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">Machine Learning</a> course by <a href="https://twitter.com/AndrewYNg" target="_blank" rel="external">Andrew Ng</a>. This is the one I started with. Starts with regression then moves to classification and neural networks.</li><br>  <li>Coursera’s <a href="https://www.coursera.org/learn/neural-networks" target="_blank" rel="external">Neural Networks for Machine Learning</a> by <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton" target="_blank" rel="external">Geoffrey Hinton</a>. More focused on neural networks and its visual applications.</li><br>  <li>Stanford’s <a href="https://www.youtube.com/watch?v=g-PvXUjD6qg&amp;list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA" target="_blank" rel="external">CS231n: Convolutional Neural Networks for Visual Recognition</a> by <a href="https://twitter.com/karpathy" target="_blank" rel="external">Andrej Karpathy</a>. It’s interesting to see some advanced concepts and the state of the art in visual recognition using deep neural networks.</li><br>  <li>The <a href="http://www.asimovinstitute.org/neural-network-zoo/" target="_blank" rel="external">Neural Network Zoo</a> is a great resource to learn more about the different types of neural networks.</li><br></ul>

<p></p><h2 id="acknowledgements">Acknowledgements</h2><p></p>
<p>Thanks to <a href="https://www.linkedin.com/in/yasmine-alfouzan-b05ba317" target="_blank" rel="external">Yasmine Alfouzan</a>, <a href="https://twitter.com/a3ammar" target="_blank" rel="external">Ammar Alammar</a>, <a href="https://www.linkedin.com/in/khalidalnuaim" target="_blank" rel="external">Khalid Alnuaim</a>, <a href="https://twitter.com/fahd09" target="_blank" rel="external">Fahad Alhazmi</a>, <a href="https://www.linkedin.com/in/mkhdev" target="_blank" rel="external">Mazen Melibari</a>, and <a href="https://www.linkedin.com/in/hadeel-al-negheimish-4a73abb3" target="_blank" rel="external">Hadeel Al-Negheimish</a> for their assistance in reviewing previous versions of this post.</p>

<p>Please contact me on <a href="https://twitter.com/jalammar" target="_blank" rel="external">Twitter</a> with any corrections or feedback.</p>
</div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/&quot;&gt;J Alammar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://jalammar.github.io/images/NNs_2_variables.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;p&gt;I’m not a machine learning expert. I’m a software engineer by training and I’ve had little interaction with AI. I had always wanted to delve deeper into machine learning, but never really found my “in”. That’s why when Google open sourced TensorFlow in November 2015, I got super excited and knew it was time to jump in and start the learning journey. Not to sound dramatic, but to me, it actually felt kind of like Prometheus handing down fire to mankind from the Mount Olympus of machine learning. In the back of my head was the idea that the entire field of Big Data and technologies like Hadoop were vastly accelerated when Google researchers released their Map Reduce paper. This time it’s not a paper – it’s the actual software they use internally after years and years of evolution.&lt;/p&gt;
&lt;p&gt;So I started learning what I can about the basics of the topic, and saw the need for gentler resources for people with no experience in the field. This is my attempt at that.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Neural Networks" scheme="http://ipcreator.me/tags/Neural-Networks/"/>
    
  </entry>
  
  <entry>
    <title>Supercharging Android Apps With TensorFlow</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/supercharging-android-apps-with-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/supercharging-android-apps-with-tensorflow/</id>
    <published>2017-02-17T02:26:06.000Z</published>
    <updated>2017-02-17T15:10:29.777Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://jalammar.github.io/Supercharging-android-apps-using-tensorflow/" target="_blank" rel="external">J Alammar</a></p>
<p>Supercharging Android Apps With TensorFlow (Google’s Open Source Machine Learning Library)<br>In November 2015, Google announced and open sourced TensorFlow, its latest and greatest machine learning library. This is a big deal for three reasons:</p>
<ol>
<li>Machine Learning expertise: Google is a dominant force in machine learning. Its prominence in search owes a lot to the strides it achieved in machine learning.</li>
<li>Scalability: the announcement noted that TensorFlow was initially designed for internal use and that it’s already in production for some live product features.</li>
<li>Ability to run on Mobile.</li>
</ol>
<p>This last reason is the operating reason for this post since we’ll be focusing on Android. If you examine the tensorflow repo on GitHub, you’ll find a little tensorflow/examples/android directory. I’ll try to shed some light on the Android TensorFlow example and some of the things going on under the hood.</p>
  <a id="more"></a>
<h2 id="A-Look-of-Recognition"><a href="#A-Look-of-Recognition" class="headerlink" title="A Look of Recognition"></a>A Look of Recognition</h2><p>The app glances out through your camera and tries to identify the objects it sees. Sometimes it does a good job, other times it can’t quite pin down the object, and at times it leads to thought provoking guesses! Overall, it feels pretty magical.</p>
<p><img src="https://jalammar.github.io/images/android_tensorflow_classifier_results.jpg" alt=""><br>android_tensorflow_classifier_results.jpg</p>
<p>The app accomplishes this feat using a bundled machine learning model running in TensorFlow on the device (no network calls to a backend service). The model is trained against millions of images so that it can look at the photos the camera feeds it and classify the object into its best guess (from the 1000 object classifications it knows). Along with its best guess, it shows a confidence score to indicate how sure it is about its guess.</p>
<p>The Android example page gives you an idea on how to build the app, and ultimately culminates in producing this <a href="https://s3.amazonaws.com/jalammar.github.io/tensorflow_demo.apk" target="_blank" rel="external">APK</a> (I built and uploaded the APK to save you some time since the building process requires installing the Android NDK and Bazel, Google’s build tool).</p>
<p>NOTE: Android 5.0 or later required since the example uses the Camera2 package introduced in Android 5.0.</p>
<p>NOTE: if your device runs Android 6.0 or later, you have to install the app with the following command (It gives the app the appropriate permissions it needs to run):</p>
<pre><code>adb install -r -g /path/to/apk.apk
</code></pre><h2 id="App-Structure-Walkthrough"><a href="#App-Structure-Walkthrough" class="headerlink" title="App Structure Walkthrough"></a>App Structure Walkthrough</h2><p><img src="https://jalammar.github.io/images/android-tensorflow-app-structure_1.png" alt=""><br>android-tensorflow-app-structure_1.png</p>
<p>The core TensorFlow engine is built with C++, but programmers can write their TensorFlow software in either C++ or Python. The Android TensorFlow example uses the C++ interface in the following manner:</p>
<p>On startup, the app launches an Android activity (CameraActivity.java) which then starts a fragment (CameraConnectionFragment.java)<br>The fragment does some setup to basically start the camera and feed the incoming stream of images to an object it instantiates (TensorflowImageListener.java)<br>The listener consults the classifier (TensorflowClassifier.java) about each image it gets, and receives the classification and confidence score for each image.<br>The good thing is that most of this logic is in normal Android Java SDK territory – so this should be familiar to most Android devs. So where is the C++?<br><img src="https://jalammar.github.io/images/android-tensorflow-app-structure_2.png" alt=""><br>android-tensorflow-app-structure_2.png</p>
<p>If you look closely at TensorflowClassifier, you may notice the following methods:</p>
<pre><code>public native int initializeTensorflow( );

private native String classifyImageBmp(Bitmap bitmap);
</code></pre><p>The native keywords in these method signatures indicate that these methods are implemented in native C++ code. Look for them under the “android/jni” directory and true enough, you’ll find tensorflow_jni.cc</p>
<pre><code>JNIEXPORT jint JNICALL
TENSORFLOW_METHOD(initializeTensorflow)(...) {
...
}


JNIEXPORT jstring JNICALL
TENSORFLOW_METHOD(classifyImageBmp)(...) {
...
}
</code></pre><p>JNI (short for Java Native Interface) is a way in which the Java parts of an Android app can communicate with the native C++ parts. So when we call classifyImageBmp(bitmap) in our Java code, it will actually invoke the C++ function exported in tensorflow_jni.cc and return the value it returns.</p>
<p>A Bitmap file cannot directly be sent to TensorFlow as input. It has be transformed into an input tensor that we’d send in step #2 in the flow above. A tensor is an n-dimensional array of values, and is the motif TensorFlow uses to send data between all of its different parts/operations. This model expect a 3-dimensional array that supplies the Red/Green/Blue value of each pixel in the image. The dimensions are:</p>
<ol>
<li>X-index of the pixel</li>
<li>Y-index of the pixel</li>
<li>indication of which value this cell holds (0 for red, 1 for green, 2 for blue)<br>And the value of the cell would be the actual value of R or G or B channel for that pixel.<br><img src="https://jalammar.github.io/images/input_tensor.png" alt=""><br>input_tensor.png</li>
</ol>
<p>(This is somewhat oversimplified. I glanced over two things for simplicity’s sake. First is the conversion from the YUV format that the Android camera exports to the RGB format the model expects. Second is that the model actually takes a 4-dimensional tensor, but these three are the ones we care about)</p>
<h2 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h2><p>As you read the example’s README.md, you’ll notice that it instructs you to download a zip file containing the TensorFlow model and add it to the assets directory. This zip file contains two files that are important for us:</p>
<p>tensorflow_inception_graph.pb- At 54 MBs unzipped, this file constitutes the majority of the APK size (58 MBs). This is our trained machine learning model and where the magic comes from. It’s a pre-built TensorFlow Graph describing the exact operations needed to compute a classification from input image data. This Graph is serialized and encoded into binary with Google’s Protocol Buffers so it can be deserialized across different platforms (think of it as a binary-encoded JSON file).</p>
<p>imagenet_comp_graph_label_strings.txt- this contains the 1000 classifications that the output of the model corresponds to (e.g. “vending machine”, “water bottle”, “coffee mug”). These classifications are defined by the ImageNet Large Scale Visual Recognition Challenge which the model was built to compete in.</p>
<p>The model here is what’s known as a deep convolutional neural network. It is built in the Inception architecture described in Going Deeper with Convolutions. Convolutional neural networks are some of the most popular models in deep learning. They have been very successful in image recognition (so much so, that most highly ranked teams in the competition used them).</p>
<p>The model is read from the file and fed into TensorFlow when the app starts up. This code is actually really interesting to read and see how to communicate with tensorflow (if you run the app with your device connected to your computer, you can see these helpful log messages printed in logcat).</p>
<h2 id="Build-System"><a href="#Build-System" class="headerlink" title="Build System"></a>Build System</h2><p>The Android app example is not built the traditional Gradle way. Because the app has to contain NDK elements as well as TensorFlow itself, a more elaborate build system was utilized. The example is configured to be built with Google’s Bazel build system running from the TensorFlow root directory.</p>
<p>The WORKSPACE file in the root directory specifies the main parameters of the project. The BUILD file in the Android directory instructs the build system to build the Java and C++ files of the app.</p>
<h2 id="The-Possibilities"><a href="#The-Possibilities" class="headerlink" title="The Possibilities"></a>The Possibilities</h2><p><strong>Using a trained model in your app seems to be the lowest hanging fruit for mobile TensorFlow apps at the moment.</strong> While you can probably train a model on Android, mobile devices are not well suited for the intensive processing required by complex models with larger training sets.</p>
<p>Want to learn more about machine learning? Consider checking out the Machine Learning course on Coursera. There’s also a good discussion in /r/MachineLearning here: In your experience, which machine learning course on Coursera (or other MOOC web site) was the best?.</p>
<p>Want to comment? /r/androiddev, Hacker News.</p>
<p>Written on January 6, 2016</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://jalammar.github.io/Supercharging-android-apps-using-tensorflow/&quot;&gt;J Alammar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Supercharging Android Apps With TensorFlow (Google’s Open Source Machine Learning Library)&lt;br&gt;In November 2015, Google announced and open sourced TensorFlow, its latest and greatest machine learning library. This is a big deal for three reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Machine Learning expertise: Google is a dominant force in machine learning. Its prominence in search owes a lot to the strides it achieved in machine learning.&lt;/li&gt;
&lt;li&gt;Scalability: the announcement noted that TensorFlow was initially designed for internal use and that it’s already in production for some live product features.&lt;/li&gt;
&lt;li&gt;Ability to run on Mobile.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This last reason is the operating reason for this post since we’ll be focusing on Android. If you examine the tensorflow repo on GitHub, you’ll find a little tensorflow/examples/android directory. I’ll try to shed some light on the Android TensorFlow example and some of the things going on under the hood.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow Android Camera Demo</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/tensorflow-android-camera-demo/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/tensorflow-android-camera-demo/</id>
    <published>2017-02-17T02:26:06.000Z</published>
    <updated>2017-02-17T14:55:11.735Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android" target="_blank" rel="external">作者：tensorflow</a></p>
<p><img src="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/sample_images/classify1.jpg" alt=""></p>
<p><img src="https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/android/sample_images/stylize1.jpg" alt=""></p>
<p><img src="https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/android/sample_images/detect1.jpg" alt=""></p>
<p>This folder contains an example application utilizing TensorFlow for Android devices.</p>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>The demos in this folder are designed to give straightforward samples of using TensorFlow in mobile applications.</p>
<p>Inference is done using the TensorFlow Android Inference Interface, which may be built separately if you want a standalone library to drop into your existing application.</p>
<p>A device running Android 5.0 (API 21) or higher is required to run the demo.</p>
<a id="more"></a>
<h2 id="Current-samples"><a href="#Current-samples" class="headerlink" title="Current samples:"></a>Current samples:</h2><pre><code>TF Classify: Uses the Google Inception model to classify camera frames in real-time, displaying the top results in an overlay on the camera image.
TF Detect: Demonstrates a model based on Scalable Object Detection using Deep Neural Networks to localize and track people in the camera preview in real-time.
TF Stylize: Uses a model based on A Learned Representation For Artistic Style to restyle the camera preview image to that of a number of different artists.
</code></pre><h2 id="Prebuilt-APK"><a href="#Prebuilt-APK" class="headerlink" title="Prebuilt APK:"></a>Prebuilt APK:</h2><pre><code>If you just want the fastest path to trying the demo, you may download the nightly build here. Expand the &quot;View&quot; and then the &quot;out&quot; folders under &quot;Last Successful Artifacts to find tensorflow_demo.apk. Also available are precompiled native libraries that you may drop into your own applications. See tensorflow/contrib/android/README.md for more details.
</code></pre><h2 id="Running-the-Demo"><a href="#Running-the-Demo" class="headerlink" title="Running the Demo"></a>Running the Demo</h2><pre><code>Once the app is installed it can be started via the &quot;TF Classify&quot;, &quot;TF Detect&quot; and &quot;TF Stylize&quot; icons, which have the orange TensorFlow logo as their icon.

While running the activities, pressing the volume keys on your device will toggle debug visualizations on/off, rendering additional info to the screen that may be useful for development purposes.
</code></pre><h2 id="Building-the-Demo-from-Source"><a href="#Building-the-Demo-from-Source" class="headerlink" title="Building the Demo from Source"></a>Building the Demo from Source</h2><pre><code>Pick your preferred approach below. At the moment, we have full support for Bazel, and partial support for gradle, cmake, make, and Android Studio.

As a first step for all build types, clone the TensorFlow repo with:

git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
Note that --recurse-submodules is necessary to prevent some issues with protobuf compilation.
</code></pre><h2 id="Bazel"><a href="#Bazel" class="headerlink" title="Bazel"></a>Bazel</h2><pre><code>Install Bazel and Android Prerequisites

Bazel is the primary build system for TensorFlow. To build with Bazel, it and the Android NDK and SDK must be installed on your system.

Get the recommended Bazel version listed in os_setup.html
The Android NDK is required to build the native (C/C++) TensorFlow code. The current recommended version is 12b, which may be found here.
The Android SDK and build tools may be obtained here, or alternatively as part of Android Studio. Build tools API &gt;= 23 is required to build the TF Android demo.
Edit WORKSPACE

The Android entries in &lt;workspace_root&gt;/WORKSPACE must be uncommented with the paths filled in appropriately depending on where you installed the NDK and SDK. Otherwise an error such as: &quot;The external label &apos;//external:android/sdk&apos; is not bound to anything&quot; will be reported.

Also edit the API levels for the SDK in WORKSPACE to the highest level you have installed in your SDK. This must be &gt;= 23 (this is completely independent of the API level of the demo, which is defined in AndroidManifest.xml). The NDK API level may remain at 21.

Install Model Files (optional)

The TensorFlow GraphDefs that contain the model definitions and weights are not packaged in the repo because of their size. They are downloaded automatically and packaged with the APK by Bazel via a new_http_archive defined in WORKSPACE during the build process.

Optional: If you wish to place the models in your assets manually (E.g. for non-Bazel builds), remove all of the model_files entries from the assets list in tensorflow_demo found in the [BUILD](BUILD) file. Then download and extract the archives yourself to the assets directory in thesource tree:

BASE_URL=https://storage.googleapis.com/download.tensorflow.org/models
for MODEL_ZIP in inception5h.zip mobile_multibox_v1a.zip stylize_v1.zip
do
  curl -L ${BASE_URL}/${MODEL_ZIP} -o /tmp/${MODEL_ZIP}
  unzip /tmp/${MODEL_ZIP} -d tensorflow/examples/android/assets/
done
This will extract the models and their associated metadata files to the local assets/ directory.

Build

After editing your WORKSPACE file to update the SDK/NDK configuration, you may build the APK. Run this from your workspace root:

bazel build -c opt //tensorflow/examples/android:tensorflow_demo
If you get build errors about protocol buffers, run git submodule update --init and make sure that you&apos;ve modified your WORKSPACE file as instructed, then try building again.

Install

Make sure that adb debugging is enabled on your Android 5.0 (API 21) or later device, then after building use the following command from your workspace root to install the APK:

adb install -r bazel-bin/tensorflow/examples/android/tensorflow_demo.apk
</code></pre><h2 id="Android-Studio"><a href="#Android-Studio" class="headerlink" title="Android Studio"></a>Android Studio</h2><pre><code>Android Studio may be used to build the demo in conjunction with Bazel. First, make sure that you can build with Bazel following the above directions. Then, look at build.gradle and make sure that the path to Bazel matches that of your system.

At this point you can add the tensorflow/examples/android directory as a new Android Studio project. Click through installing all the Gradle extensions it requests, and you should be able to have Android Studio build the demo like any other application (it will call out to Bazel to build the native code with the NDK).
</code></pre><h2 id="CMake"><a href="#CMake" class="headerlink" title="CMake"></a>CMake</h2><pre><code>Full CMake support for the demo is coming soon, but for now it is possible to build the TensorFlow Android Inference library using tensorflow/contrib/android/cmake.
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android&quot;&gt;作者：tensorflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/sample_images/classify1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/android/sample_images/stylize1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/android/sample_images/detect1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;This folder contains an example application utilizing TensorFlow for Android devices.&lt;/p&gt;
&lt;h2 id=&quot;Description&quot;&gt;&lt;a href=&quot;#Description&quot; class=&quot;headerlink&quot; title=&quot;Description&quot;&gt;&lt;/a&gt;Description&lt;/h2&gt;&lt;p&gt;The demos in this folder are designed to give straightforward samples of using TensorFlow in mobile applications.&lt;/p&gt;
&lt;p&gt;Inference is done using the TensorFlow Android Inference Interface, which may be built separately if you want a standalone library to drop into your existing application.&lt;/p&gt;
&lt;p&gt;A device running Android 5.0 (API 21) or higher is required to run the demo.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow Android stand-alone demo</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/tensorflow-android-stand-alone-demo/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/tensorflow-android-stand-alone-demo/</id>
    <published>2017-02-17T02:16:06.000Z</published>
    <updated>2017-02-17T14:48:18.479Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/miyosuda/TensorFlowAndroidDemo" target="_blank" rel="external">作者：miyosuda</a></p>
<p><img src="https://camo.githubusercontent.com/c7524a5212d3212f0c017a50cac6c765e1389964/687474703a2f2f6e6172722e6a702f707269766174652f6d69796f7368692f74656e736f72666c6f772f74656e736f72666c6f775f73637265656e312e706e67" alt=""></p>
<p>Android demo source files extracted from original TensorFlow source. (TensorFlow r0.10)</p>
<p>To build this demo, you don’t need to prepare build environment with Bazel, and it only requires AndroidStudio.</p>
<p>If you would like to build jni codes, only NDK is requied to build it.</p>
  <a id="more"></a>
<pre><code>How to build jni codes
</code></pre><p>First install NDK, and set path for NDK tools, and then type commands below to create .so file.</p>
<pre><code><figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>cd jni-build</div><div class="line"><span class="variable">$ </span>make</div><div class="line"><span class="variable">$ </span>make install</div></pre></td></tr></table></figure>
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/miyosuda/TensorFlowAndroidDemo&quot;&gt;作者：miyosuda&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/c7524a5212d3212f0c017a50cac6c765e1389964/687474703a2f2f6e6172722e6a702f707269766174652f6d69796f7368692f74656e736f72666c6f772f74656e736f72666c6f775f73637265656e312e706e67&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Android demo source files extracted from original TensorFlow source. (TensorFlow r0.10)&lt;/p&gt;
&lt;p&gt;To build this demo, you don’t need to prepare build environment with Bazel, and it only requires AndroidStudio.&lt;/p&gt;
&lt;p&gt;If you would like to build jni codes, only NDK is requied to build it.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Android" scheme="http://ipcreator.me/tags/Android/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow的技术应用</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/applications-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/applications-of-tensorflow/</id>
    <published>2017-02-17T02:06:06.000Z</published>
    <updated>2017-02-17T02:12:35.170Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.leiphone.com/news/201702/pwAazPPM6idKOeSZ.html" target="_blank" rel="external">作者：AI研习社</a></p>
<blockquote>
<p><strong>通过一些TensorFlow实际应用，让大家对TensorFlow有理性和感性的双层认知。</strong></p>
</blockquote>
<p>随着谷歌2015年发布开源人工系统TensorFlow，让本就如火如荼的深度学习再添一把火，截至现在，TensorFlow已经历了多个版本演进，功能不断完善，AI开发者也能灵活自如的运用TensorFlow解决一些实际问题，下面雷锋网(公众号：雷锋网)会对一些比较实用的TensorFlow应用做相关整理，让大家对TensorFlow有理性和感性的双层认知。</p>
  <a id="more"></a>
<pre><code>TensorFlow在图像识别中的应用
</code></pre><p>对人类而言，区分画面、图像就如同与生俱来一样简单，例如我们能够轻松的识别老虎与雄狮的区别，但如果把这个问题交给计算机看上去并不简单。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a425f346c57.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>在过去几年里，机器学习在解决这些难题方面取得了巨大的进步。其中，我们发现一种称为深度卷积神经网络的模型在困难的视觉识别任务中取得了理想的效果 —— 达到人类水平，在某些领域甚至超过。下面这篇文章雷锋网重点整理了TensorFlow在图像识别中的应用，看计算机如何识别图像。</p>
<p>地址：<a href="http://www.csdn.net/article/2015-12-16/2826496" target="_blank" rel="external">http://www.csdn.net/article/2015-12-16/2826496</a></p>
<p>除了认识TensorFlow在图像识别中的应用，关于如何搭建图像识别系统雷锋网也有相关教程：</p>
<p><a href="http://www.leiphone.com/news/201701/Y4uyEktkkwb5YhJM.html" target="_blank" rel="external">手把手教你用TensorFlow搭建图像识别系统（一）</a></p>
<p><a href="http://www.leiphone.com/news/201701/2tH3DgLmsGhnDd8D.html" target="_blank" rel="external">手把手教你用TensorFlow搭建图像识别系统（二）</a></p>
<p><a href="http://www.leiphone.com/news/201701/UHuzaB7hDiKAVZ3X.html" target="_blank" rel="external">手把手教你用TensorFlow搭建图像识别系统（三）</a></p>
<p>农场主与TensorFlow的邂逅，AI告诉你一根优秀的黄瓜应该具备什么素质</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a5828f60698.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>一根优秀的黄瓜应该具备什么素质？相信这是很多人不可描述的问题，而对于黄瓜农场主而言，同一个品种的黄瓜可以根据颜色、刺、体态等因素分成9类，但分检工作对于人来说恰好是一个枯燥繁琐的过程。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201609/57c7eb25b0e4c.gif" alt=""></p>
<p>一位日本农场主 Makoto 为解决这一难题，利用TensorFlow制作了一款黄瓜分类机，通过机器就能够完成黄瓜的分类工作，但识别准确率目前只有70%，Makoto 目前正打算使用谷歌的云机器学习（Cloud Machine Learning）平台，来进一步改善他的黄瓜分类机。</p>
<p>地址：<a href="http://www.leiphone.com/news/201609/dHgxLbz96OQqVN8z.html（来源雷锋网）" target="_blank" rel="external">http://www.leiphone.com/news/201609/dHgxLbz96OQqVN8z.html（来源雷锋网）</a></p>
<p>用TensorFlow搭建图像分类器</p>
<p>本文将详细介绍如何通过TensorFlow搭建图像分类器，从安装、优化、编码、和使用等方面手把手教你用TensorFlow搭建图像分类器。</p>
<p>地址：<a href="http://www.leiphone.com/news/201702/JdaLcpYO59zTTF06.html" target="_blank" rel="external">http://www.leiphone.com/news/201702/JdaLcpYO59zTTF06.html</a></p>
<p>如何使用Tensorflow实现快速风格迁移？</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a425f4818b1.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>风格迁移（Style Transfer）是深度学习众多应用中非常有趣的一种，如图，我们可以使用这种方法把一张图片的风格“迁移”到另一张图片上，但原始的风格迁移的速度是非常慢的。在GPU上，生成一张图片都需要10分钟左右，而如果只使用CPU而不使用GPU运行程序，甚至需要几个小时。这个时间还会随着图片尺寸的增大而迅速增大，那么能否实现使用Tensorflow实现快速风格迁移？</p>
<p>地址：<a href="http://www.leiphone.com/news/201701/tGlVRXWShwe7ffHW.html" target="_blank" rel="external">http://www.leiphone.com/news/201701/tGlVRXWShwe7ffHW.html</a></p>
<p>运用TensorFlow处理简单的NLP问题</p>
<p>当前互联网每天都在产生大量的文本和音频数据，通过挖掘这些数据，我们可以做一些更加便捷的应用，例如机器翻译、语音识别、词性标注以及信息检索等，这些都属于NLP范畴。而在NLP领域中，语言模型是最基本的一个环节，本文主要围绕语言模型展开，首先介绍其基本原理，进而引出词向量(word2vec)、循环神经网络(RNN)、长短时记忆网络(LSTM)等深度学习相关模型，并详细介绍如何利用 TensorFlow 实现上述模型。</p>
<p>地址：<a href="http://blog.csdn.net/frankiegu/article/details/52133763" target="_blank" rel="external">http://blog.csdn.net/frankiegu/article/details/52133763</a></p>
<p>在TensorFlow中用深度度学习修复图像</p>
<p>生活中经常会遇到图片缺失问题，设计师和摄影师用内容自动填补来补充图像中不想要的或缺失的部分，本文将介绍通过一个 DCGAN 用深度学习进行图像修复。</p>
<p>地址：<a href="http://blog.csdn.net/whiteboy1999/article/details/53727376?locationNum=1&amp;fps=1" target="_blank" rel="external">http://blog.csdn.net/whiteboy1999/article/details/53727376?locationNum=1&amp;fps=1</a></p>
<p>基于Tensorflow的CNN/CRF图像分割技术</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a54a6900cd3.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>本篇文章验证了卷积神经网络应用于图像分割领域时存在的一个问题——粗糙的分割结果。根据像素间交叉熵损失的定义，我们在简化的场景下进行了模型的训练，并使用后向传播来更新权重。我们使用条件随机场（CRFs）来解决分割结果粗糙的问题，并取得了很好的效果。</p>
<p>地址：<a href="https://yq.aliyun.com/articles/67189?spm=5176.8067842.tagmain.47.W3YH1h" target="_blank" rel="external">https://yq.aliyun.com/articles/67189?spm=5176.8067842.tagmain.47.W3YH1h</a></p>
<p>利用Docker和阿里云容器服务轻松搭建分布式TensorFlow训练集群</p>
<p>由于在现实世界里，单机训练大型神经网络的速度非常缓慢，这就需要运行分布式TensorFlow集群并行化的训练模型。但是TensorFlow本身只是计算框架，要将其应用在生产环境，还是需要集群管理工具的资源调度，监控以及生命周期管理等能力。</p>
<p>本文将分两个部分介绍如何在阿里云容器服务上玩转TensorFlow训练集群。</p>
<p>第一部分：<a href="https://yq.aliyun.com/articles/68337?spm=5176.100239.blogcont60894.15.tOeTKV" target="_blank" rel="external">https://yq.aliyun.com/articles/68337?spm=5176.100239.blogcont60894.15.tOeTKV</a></p>
<p>第二部分：<a href="https://yq.aliyun.com/articles/60894?spm=5176.8067842.tagmain.29.W3YH1h" target="_blank" rel="external">https://yq.aliyun.com/articles/60894?spm=5176.8067842.tagmain.29.W3YH1h</a></p>
<p>雷锋网原创文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.leiphone.com/news/201702/pwAazPPM6idKOeSZ.html&quot;&gt;作者：AI研习社&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;通过一些TensorFlow实际应用，让大家对TensorFlow有理性和感性的双层认知。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;随着谷歌2015年发布开源人工系统TensorFlow，让本就如火如荼的深度学习再添一把火，截至现在，TensorFlow已经历了多个版本演进，功能不断完善，AI开发者也能灵活自如的运用TensorFlow解决一些实际问题，下面雷锋网(公众号：雷锋网)会对一些比较实用的TensorFlow应用做相关整理，让大家对TensorFlow有理性和感性的双层认知。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow 的入门与安装</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/setup-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/setup-of-tensorflow/</id>
    <published>2017-02-17T01:56:06.000Z</published>
    <updated>2017-02-17T01:59:11.229Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.leiphone.com/news/201702/I9mcLjB6pKjTf1Or.html" target="_blank" rel="external">作者：AI研习社</a></p>
<blockquote>
<p><strong>作为AI 领域最受关注和使用率最高的开源框架之一，TensorFlow 究竟是如何安装的呢？这篇汇总资料你不得不看！</strong></p>
</blockquote>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a2d3a8ba7be.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>自2015年11月发布以来，谷歌旗下的机器学习开源框架TensorFlow已经在图像识别，大数据分析，语音识别和语义理解，机器翻译等各个领域得到了广泛应用，同时也得到了业内人士的普遍认可，成为了目前最受关注和使用率最高的开源框架之一。</p>
<p>本文将重点整理TensorFlow框架的入门和安装教程。更多关于TensorFlow的深入介绍、应用项目以及各机器学习开源框架之间的对比等内容，请见雷锋网(公众号：雷锋网)的系列文章。</p>
  <a id="more"></a>
<p>下面是本文整理的资料内容：</p>
<p>在安装之前，这里先列出一些对TensorFlow给出大略介绍的文章，其中包括一些重要的概念解释，TensorFlow的具体含义和优点，以及TensorFlow的基本工作原理等。</p>
<ol>
<li><p>《TensorFlow极速入门》<br>链接：<a href="http://www.leiphone.com/news/201702/vJpJqREn7EyoAd09.html" target="_blank" rel="external">http://www.leiphone.com/news/201702/vJpJqREn7EyoAd09.html</a><br>本文介绍了 graph 与 session 等基本组件，解释了 rank 和 shape 等基础数据结构概念，讲解了一些 variable 需要注意的地方并介绍了 placeholders 与 feed_dict 。最终以一个手写数字识别的实例将这些点串起来进行了具体说明。</p>
</li>
<li><p>《TensorFlow学习笔记1：入门》<br>链接：<a href="http://www.jeyzhang.com/tensorflow-learning-notes.html" target="_blank" rel="external">http://www.jeyzhang.com/tensorflow-learning-notes.html</a><br>本文与上一篇的行文思路基本一致，首先概括了TensorFlow的特性，然后介绍了graph、session、variable 等基本概念的含义，以具体代码的形式针对每个概念给出了进一步的解释。最后通过手写数字识别的实例将这些点串起来进行了具体说明。<br>需要指出的是，两篇文章覆盖的基础概念不尽相同，并且举例用的代码也不一样。</p>
</li>
<li><p>《TensorFlow入门》<br>链接：<a href="http://www.jianshu.com/p/6766fbcd43b9#" target="_blank" rel="external">http://www.jianshu.com/p/6766fbcd43b9#</a><br>与上面两篇不同，本文简单介绍了 TensorFlow 的含义、优点、安装和基本工作原理之后，直接通过代码示例的方式讲解了 TensorFlow 的简单用法，包括生成三维数据，然后用一个平面拟合它，以及通过 variable 实现一个简单的计数器等。</p>
</li>
</ol>
<p>值得一提的是，以上第二和第三篇分别来自两个系列文章，这两个系列也都是关于 TensorFlow 入门和实践的优秀博客。第二篇的后续文章讲述了卷积神经网络（CNN）模型构建，以及利用 TensorFlow 生成词向量 (Word Embedding) 的具体过程。第三篇则实际上是基于斯坦福大学基于深度学习的自然语言处理课程的学习笔记，该系列其他的文章还讲述了循环神经网络（RNN）和 word2vec 模型等更深入的知识，感兴趣的读者可以从文章的作者页找到更多文章。</p>
<p>上述文章都更倾向于 TensorFlow 的简单介绍了基础用法，但对于TensorFlow具体安装过程的讲述则不够细致。因此这里专门针对TensorFlow的安装过程推荐一篇教程。</p>
<ol>
<li>《真正从零开始，TensorFlow详细安装入门图文教程！》<br>链接：<a href="http://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html" target="_blank" rel="external">http://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html</a><br>上文来自雷锋网小编的亲身实践，真正做到了从零开始，详细介绍了在Linux环境下如何通过pip命令安装TensorFlow框架的完整流程，以及面对一些常见问题的处理办法。值得一提的是，本文在讲解完框架安装之后，还针对Komodo开发环境进行了简单介绍。</li>
</ol>
<p>经过了以上来自民间的实践教程之后，相信各位读者对TensorFlow的大致情况和具体安装方法已经有了自己的理解。下面对于那些想要更全面和深入地了解TensorFlow的读者，我们推荐几个官方的教程。</p>
<ol>
<li><p>谷歌官方入门教程<br>链接：<a href="https://www.tensorflow.org/get_started/" target="_blank" rel="external">https://www.tensorflow.org/get_started/</a></p>
</li>
<li><p>谷歌教程翻译<br><a href="https://github.com/jikexueyuanwiki/tensorflow-zh" target="_blank" rel="external">https://github.com/jikexueyuanwiki/tensorflow-zh</a></p>
</li>
</ol>
<p>这里谷歌给出的入门教程内容十分丰富，除了最基本的安装、名词解释和代码示例之外，还给出了 API 接口的详细解释和说明。但考虑到内容全是英文，因此雷锋网在这里给出了国内志愿者对谷歌内容的中文翻译版，可以为那些英文不好的读者提供参考。</p>
<ol>
<li>TensorFlow中文社区<br><a href="http://www.tensorfly.cn/" target="_blank" rel="external">http://www.tensorfly.cn/</a><br>最后我们在这里推荐一个 TensorFlow 的中文社区，该网站几乎可以认为是 TensorFlow 的中文官网，除了上述谷歌官方教程的中文翻译之外，该网站还包括进阶指南、API中文手册、精华文章和TF社区等诸多板块。</li>
</ol>
<p>雷锋网版权文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.leiphone.com/news/201702/I9mcLjB6pKjTf1Or.html&quot;&gt;作者：AI研习社&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;作为AI 领域最受关注和使用率最高的开源框架之一，TensorFlow 究竟是如何安装的呢？这篇汇总资料你不得不看！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201702/58a2d3a8ba7be.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;自2015年11月发布以来，谷歌旗下的机器学习开源框架TensorFlow已经在图像识别，大数据分析，语音识别和语义理解，机器翻译等各个领域得到了广泛应用，同时也得到了业内人士的普遍认可，成为了目前最受关注和使用率最高的开源框架之一。&lt;/p&gt;
&lt;p&gt;本文将重点整理TensorFlow框架的入门和安装教程。更多关于TensorFlow的深入介绍、应用项目以及各机器学习开源框架之间的对比等内容，请见雷锋网(公众号：雷锋网)的系列文章。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>框架平台的综合对比</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/platforms-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/platforms-of-tensorflow/</id>
    <published>2017-02-17T01:56:06.000Z</published>
    <updated>2017-02-17T02:03:41.956Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.leiphone.com/news/201702/H164EWZE7w9wu6UM.html" target="_blank" rel="external">作者：AI研习社</a></p>
<blockquote>
<p><strong>TensorFlow 与其他平台、框架对比，具有哪些优点及劣势？</strong></p>
</blockquote>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a3fff2bdea1.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>作为机器学习领域、尤其是 Python 生态圈最受欢迎的框架平台，TensorFlow 具有许多吸引开发者的优点。其中最显而易见的是谷歌的技术支持和完善的社区（庞大用户群）。这些都为 TensorFlow 的普及打下了基础。但是，开发者需要了解 Tensorflow 在技术上有哪些值得一提的优势，又有哪些不足，以便在处理特定任务时进行工具选择。而这些，必须要在与其他平台、框架的对比中才能凸显。顺便说一句老生常谈的话，<strong>没有万能的工具，只有在不同应用场景下最合适的选择。</strong> 因此，雷锋网(公众号：雷锋网)整理了介绍 Tensorflow、Caffe、Microsoft Cognitive Toolkit （CNTK）、MXnet、Torch 等平台框架，以及对它们做横向对比的文章，供读者按图索骥。</p>
  <a id="more"></a>
<pre><code>## 综合介绍

这部分的文章，对 TensorFlow 和其它主流深度学习框架、平台做了概括性介绍，归纳它们的主要特点。有经验的开发者可跳过。

**谷歌、微软、OpenAI 等巨头的七大机器学习开源项目 看这篇就够了**

对 Tensorflow、DeepMind Lab、Universe、FastText、CNTK、MXNet、SystemML 这七个开源机器学习平台、框架做了介绍。它们都是谷歌、微软、亚马逊、IBM 等国际互联网巨头开发或维护的平台，在一定程度上反应了巨头们的 ML 布局以及研究倾向。

注意：该文章发布时 Facebook 尚未推出 Pytorch。现在看来，Pytorch 是脸书在 ML 领域的关键项目。

地址：http://www.leiphone.com/news/201612/rFVygnQf4WjogJQR.html

**深度学习——你需要了解的八大开源框架**

对 TensorFlow、Torch、Caffe、Theano、Deeplearning4j 等主流开源框架作了简要介绍，总结了它们的核心优势及特点。

地址：http://www.leiphone.com/news/201608/5kCJ4Vim3wMjpBPU.html （来源雷锋网）

**对比深度学习十大框架：TensorFlow 最流行但并不是最好**

这篇文章翻译自 Medium，同样是对开源框架的综合性介绍。它出自 BEEVA Labs 的数据分析师 Ricardo Guerrero Gomez-Ol 之手，对 TensorFlow、Theano、Keras、Lasagne 等框架和工具做了简要介绍。

地址：http://geek.csdn.net/news/detail/132553

## 横向对比

**这几天 AI 圈都在关注的深度学习库评测**

整理自香港浸会大学褚晓文教授研究团队的论文。褚教授在论文中对 Caffe、CNTK、MXNet、TensorFlow、Torch 几大工具在 CPU、GPU 平台上的性能表现做了深度评测。该论文一经发表便受到广泛关注，堪称是迄今为止，对上述几个主流深度学习框架最深入、客观的计算性能对比。其研究结果，简明扼要得归纳了这几大平台分别最适合处理何种神经网络任务。雷锋网强力推荐。

地址：http://www.leiphone.com/news/201701/OlEiX6kZLKHVUyW2.html （来源雷锋网）

**机器学习和深度学习的最佳框架大比拼**

这篇文章翻译自 Infoworld，对  TensorFlow、Caffe、CNTK、MXNet、Scikit-learning、Spark MLlib 等几大框架的优缺点进行了点评，以及实践总结。本文针对不同背景、习惯的开发者，提供了平台选择上的建议。

地址：https://news.cnblogs.com/n/562250/  

**TensorFlow 等主流深度学习框架比较分析**

这篇文章罗列了 TensorFlow、Theano、MXnet 三者的主要属性和技术规格，做了简明扼要的对比。

地址：http://www.tuicool.com/articles/BVFb6bb

**Caffe、TensorFlow、MXnet 三个开源库对比**

这是国内一名为陈汝丹的开发者的实操心得，对三个框架发表了自己的看法。文章对技术的讨论较为细致，适合做实践参考。

地址：http://chenrudan.github.io/blog/2015/11/18/comparethreeopenlib.html#0-tsina-1-2654-397232819ff9a47a7b7e80a40613cfe1

## 与其它框架的对比

**如何评价百度刚刚开源的 Paddle 平台？**

2016 年下半年开源的 PaddlePaddle 是百度的诚意之作，或许还是国内诞生的最具重量级的机器学习框架。这篇文章对其做了介绍，并邀请行业人士对 PaddlePaddle 相对于 TensorFlow、Caffe 的优缺点做了简要评论。

地址：http://www.leiphone.com/news/201608/TfDtMfbKkUOEieWm.html（来源雷锋网）

**应该选择 TensorFlow 还是 Theano？**

由于 TensorFlow 与 Theano 有替代关系，两者之间的比较是个相对热门的话题。这是知乎上的问答，直接对比了这两个深度学习框架。

地址：https://www.zhihu.com/question/41907061

## 补充

**TensorFlow 与 Apache Spark 结合：雅虎开源“TensorFlowOnSpark”**

最后，说到 TensorFlow 就不得不提最近的一个大新闻——“TensorFlowOnSpark”。该框架使得 TensorFlow 兼容于 Apache Spark，能直接获取后者的数据集，为开发者减少大量麻烦。

地址：http://www.leiphone.com/news/201702/XwhHugKHTk86WQso.html

雷锋网原创文章，未经授权禁止转载。详情见转载须知。
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.leiphone.com/news/201702/H164EWZE7w9wu6UM.html&quot;&gt;作者：AI研习社&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;TensorFlow 与其他平台、框架对比，具有哪些优点及劣势？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201702/58a3fff2bdea1.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作为机器学习领域、尤其是 Python 生态圈最受欢迎的框架平台，TensorFlow 具有许多吸引开发者的优点。其中最显而易见的是谷歌的技术支持和完善的社区（庞大用户群）。这些都为 TensorFlow 的普及打下了基础。但是，开发者需要了解 Tensorflow 在技术上有哪些值得一提的优势，又有哪些不足，以便在处理特定任务时进行工具选择。而这些，必须要在与其他平台、框架的对比中才能凸显。顺便说一句老生常谈的话，&lt;strong&gt;没有万能的工具，只有在不同应用场景下最合适的选择。&lt;/strong&gt; 因此，雷锋网(公众号：雷锋网)整理了介绍 Tensorflow、Caffe、Microsoft Cognitive Toolkit （CNTK）、MXnet、Torch 等平台框架，以及对它们做横向对比的文章，供读者按图索骥。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow的迭代更新</title>
    <link href="http://ipcreator.me/2017/02/17/Program/TensorFlow/history-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/17/Program/TensorFlow/history-of-tensorflow/</id>
    <published>2017-02-17T01:49:06.000Z</published>
    <updated>2017-02-17T01:55:48.288Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.leiphone.com/news/201702/mCdH02cb8MWBaiAs.html" target="_blank" rel="external">作者：AI研习社</a></p>
<blockquote>
<p><strong>谷歌于2015年11月发布了全新人工智能系统TensorFlow，距今已有15个月时间，在这期间发生了哪些变化？</strong></p>
</blockquote>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a3d3459f765.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>谷歌于2015年11月发布了全新人工智能系统TensorFlow。该系统可被用于语音识别或照片识别等多项机器深度学习领域，主要针对2011年开发的深度学习基础架构DistBelief进行了各方面的改进，它可在小到一部智能手机、大到数千台数据中心服务器的各种设备上运行。</p>
  <a id="more"></a>
<pre><code>那么为什么会产生TensorFlow系统，以及谷歌为何将其开源？这个问题可以看雷锋网文章[《Google开源TensorFlow系统，这背后都有什么门道？》](http://www.leiphone.com/news/201511/Voza1pFNQB4bzKdR.html)。
</code></pre><p>2016年4月14日，Google发布了分布式TensorFlow，版本号为0.8，这是TensorFlow发布之后的比较重大的版本更新。Google的博文介绍了TensorFlow在图像分类的任务中，在100个GPUs和不到65小时的训练时间下，达到了78%的正确率。在激烈的商业竞争中，更快的训练速度是人工智能企业的核心竞争力。而分布式TensorFlow意味着它能够真正大规模进入到人工智能产业中，产生实质的影响。</p>
<p>详情可以阅读雷锋网文章<a href="http://www.leiphone.com/news/201604/povAwFh18LvmXEAS.html" target="_blank" rel="external">《开源后5个月，Google的深度学习系统都有哪些改变？》</a>。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a3e17d01b03.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>在2016年6月，TensorFlow发布了新版本的早期版本，版本号为0.9，增加了对iOS的支持。</p>
<p>随着谷歌增加了TensorFlow对iOS的支持，应用程序将能够在更聪明的神经网络功能集成到它们的应用程序，最终使它们更聪明相当能干。具体更新内容可以在<a href="http://www.leiphone.com/news/201606/E3723MUOliivg28r.html" target="_blank" rel="external">《谷歌AI平台发布早期版本，并登陆iOS》</a>中看到。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a3e22b3b803.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>在2017年1月底，TensorFlow 终于将迎来史上最重大更新：TensorFlow 1.0。Tensorflow它已成为 GitHub 最受欢迎的机器学习开源项目。因其高度普及率，尤其是在 Python 生态圈中，TensorFlow 的功能变化会对全世界的机器学习开发者造成重大影响。</p>
<p>上月初，谷歌公布了 TensorFlow 1.0.0-alpha ，即 TensorFlow 1.0 的第一个“草稿”版本。近日，新的候选版本 TensorFlow 1.0.0-rc0 被发布出来，披露了更多技术细节，标志着我们离 “完全体”的 TensorFlow 1.0 更近一步。</p>
<p>1.0 版本不仅为 TensorFlow 机器学习函数库带来多重升级，而且为 Python 和 Java 用户使用 TensorFlow 做开发降低了难度。另外，新版本的漏洞修补也得到了改善。更有意思的是，由于对 TensorFlow 计算做优化的新编译器，<strong>在智能手机上运行基于 TensorFlow 的机器学习 APP 将成为可能。</strong> 具体更新内容可以看雷锋网(公众号：雷锋网)文章<a href="http://www.leiphone.com/news/201701/x8fEWZIMCWty6EvZ.html" target="_blank" rel="external">《TensorFlow 1.0 要来了！它将带来哪些革命性变化？》</a></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a3e25989b7e.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>在2月7日谷歌通过博客正式发布了 TensorFlow Fold，该库针对 TensorFlow 1.0 框架量身打造，可以帮助深度学习开发者根据不同结构的输入数据建立动态的计算图（Dynamic Computation Graphs），简化了模型训练阶段对输入数据的预处理过程，提升了系统的运行效率。这个库的更多信息可以在<a href="http://www.leiphone.com/news/201702/r1W8K2Xp3VE1FLoJ.html" target="_blank" rel="external">《谷歌刚发布的深度学习动态计算图工具TensorFlow Fold是什么？》</a>中看到。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/58a3e28362a90.gif" alt=""></p>
<p>雷锋网原创文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.leiphone.com/news/201702/mCdH02cb8MWBaiAs.html&quot;&gt;作者：AI研习社&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;谷歌于2015年11月发布了全新人工智能系统TensorFlow，距今已有15个月时间，在这期间发生了哪些变化？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201702/58a3d3459f765.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;谷歌于2015年11月发布了全新人工智能系统TensorFlow。该系统可被用于语音识别或照片识别等多项机器深度学习领域，主要针对2011年开发的深度学习基础架构DistBelief进行了各方面的改进，它可在小到一部智能手机、大到数千台数据中心服务器的各种设备上运行。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>人工智能 VS 机器学习</title>
    <link href="http://ipcreator.me/2017/02/15/Program/Concepts/ai-vs-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/15/Program/Concepts/ai-vs-machine-learning/</id>
    <published>2017-02-15T14:49:06.000Z</published>
    <updated>2017-02-27T03:50:54.939Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dy.163.com/v2/article/detail/CBLFGEEV0511CUKV.html" target="_blank" rel="external">作者：网易AI研究院</a></p>
 <div align="center"><br><img src="http://dingyue.nosdn.127.net/FvoCteXeaxOQg4IblKLzFzKWGzhz86zMvylL6jsI6tLsx1485348908493compressflag.jpg" width="839" height="416"><br> </div>

<p>  对于企业而言，该投资人工智能还是机器学习呢？国外媒体发表Avanade高级总监贾马尔·赫瓦贾（Jamal Khawaja）的文章对这一问题进行了深入解析。</p>
  <a id="more"></a>
<p>　在过去的一年里，笔者一直在研究两种在如何利用大数据上相互矛盾的方法：人工智能（AI）和机器学习（ML）。毕竟，大数据没什么令人兴奋的，除非你有个机制去处理它。经过数周的深入研究后，我意识到大家对于一切的定义都是不一致的。另外，二者之间的区别相当无趣乏味。因此，我将尝试用一种既不讨好供应商也不讨好学术界的语言，来解析我对未来十年行业的发展的看法。</p>
<p>　　不过，在展开讨论之前，我们首先说明一些背景信息。先来谈谈AI和ML与大数据相关的定义：</p>
<p>　　<strong>人工智能</strong>：AI的目标是理解神经功能，模拟大脑的神经功能来从给定的情境中学习。在很多情况下，大脑实质上就是鲁布·戈德堡机器（即极为复杂的机器设备）。有了这种进化性的构建模块，我们就能够达到一种复杂的终端状态。</p>
<p>　　早在1980年代，AI在科学家当中是一个热门研究领域：专家们是如何做他们的工作的，如何将他们的那些任务简化成一系列的规则，如何通过编程给计算机引入那些规则，进而取代那些专家。研究人员想要教导计算机诊断疾病，翻译各种语言，甚至推断我们想要但不自知的东西。<strong>从根本上说，AI寻求构造在一个系统内进行逻辑推理的能力。</strong></p>
<p>　　这种努力并没有成功。</p>
<p>　　在被宣告失败之前，传统的AI项目吸引了数亿美元的风投资金。当时，AI的问题在于，我们没有足够有成本效率的计算能力去完成那些目标。但得益于Map Reduce和云技术，我们现在有足够充裕的计算能力去做AI。</p>
<p>　　<strong>机器学习</strong>：ML实际上是数项技术的集合，其中包括计算统计学、算法设计和数学，旨在尝试进行数据挖掘分析，以发现模式，再将模式转化成语言。这种技术会给系统提供初始的指令组，然后系统进行数据归纳，发现或者推断出模式，以期将那些信息应用到新的解决方案。</p>
<p>　　<strong>ML是从AI进化而来的。</strong>当AI的挑战变得非常显著，变得无法克服时，理论家们寻求一种更加定制化的归纳计算决策方法。这种模式有不同的种类。供应商们将它们的系统称为“机器智能”或者“监督式学习”。</p>
<p>　　除了更容易构造以外，机器学习的好处都显而易见。<strong>ML始于一个界定的问题，以及描述对给定数据集的恰当分析的规则组。</strong></p>
<h2 id="AI与ML的相似之处"><a href="#AI与ML的相似之处" class="headerlink" title="AI与ML的相似之处"></a>AI与ML的相似之处</h2><p>　　- 迭代算法：尽管机制上存在差异，但ML和AI有着共同的主要组成部分：迭代学习。<strong>在ML中，迭代学习是从所描述的参数组中定义不确定边界的过程。在AI中，迭代学习通过通常随时间变动的非线性序列发生。</strong></p>
<p>　　- 数据越多，迭代越快：系统本身会从学习中构造和优化算法模型。</p>
<p>　　- 可应用在明确算法不能实行的地方（垃圾邮件过滤、OCM和计算机视觉）。本质上，当物体、动作或者任何其它的东西的定义无法精确描述出来的时候，就需要更加复杂的指令组（通常是概率建模）来分析和理解。</p>
<p>-两种系统都依靠基于归纳推理的“学会学习”能力：二者的运作过程存在着很大的差异，但最终的效果都取决于系统从经验中学习的能力。那种学习可以是外显的，有指导的（典型的例子就是机器学习），也可以是基于一系列的先验知识，由系统本身进行推测（典型例子就是人工智能）。</p>
<h2 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h2><p>　　- AI的目标是推理。系统不仅仅要鉴别需要估算什么，还要鉴别如何进行估算，即便在不确定的情况下也是如此。这是一项困难的任务，很多人都缺乏这种能力。</p>
<p>　　- 所基于的神经网络：AI执行最常见的解决方案机制是人工神经网络。从根本上说，不同抽象层次的互联神经元会权衡受观察或者被计算的行为的价值，会通过使用输入的非线性函数来调整驱动系统的算法。</p>
<p>　　- 在不同的抽象层次学习：AI算法会在信号从输入层传送到输出层的过程中将信号遇到的转变参数化。该转变是有可训练的考量因素的处理单元，如权重和阈值。层数反映神经网络的复杂性，参数的权重反映它背后的逻辑。</p>
<p>　　- 寻找方差的转变，以识别变化：在神经网络中，有机制识别方差的实际转变和变化的程度。这是AI的基石之一；量化方差和推断其影响的能力对于AI而言必不可少。</p>
<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>　　- ML专注于根据已知属性预测未知属性，这反过来是依据概率分布。这反映出ML的两个主要目标：</p>
<p>　　1. 目标是解决问题；利用给定的带有定义输入的数据组和监督式误差反向传播，鉴别和解决问题</p>
<p>　　2. ML并不是寻求思考的能力；相反，它是寻求做会思考的实体能够做的事情的能力</p>
<p>-ML方面有两类函数：能够被学习的东西和不能够被学习的东西。这种机制是通过围绕与前馈控制系统相关的复杂性建模建立起来的，该系统负责将来自来源的控制信号向外部环境进行例示。这表明理解的层次不仅仅是围绕系统扰动，还围绕基于数学建模的系统中的预期变化。相反地，反馈系统会反应性地改变控制信号。这些系统无法使得行为有理化时，则会将函数渲染为无法学习的东西，以及在机器学习环境范畴之外的东西。</p>
<p>　　关于ML，值得注意的是量子机器开始被引入系统的学习过程。理论上，量子计算可给给定环境提供无限量的前馈系统。人们可能会断定，量子学习本质上不是确定性的；量子计算（量子位）的基本计算元素创造了一种模糊的逻辑模型。这可能会带来已知物理定律下最具创造性的问题解决过程。目前，它正被应用于图像识别，但未来的实施会考虑训练基于难解运算的概率模型。</p>
<p>　　然而，不管使用哪一种系统：</p>
<p>　　- 你最终都会得出经过优化的结果。你不一定理解你是如何将其进化的，但结果不言而喻。你只能够理解过程和界面。</p>
<p>　　- 学习的中心从产品转向过程：不改动最终产品，而是改动过程。</p>
<p>　　- 这两种模型都不仅仅涉及工程设计：我们试图创造的东西比我们想象的要多。</p>
<p>　　那么，该投资AI还是ML呢？说到底，这取决于你的业务需求。<strong>ML可提供大量的企业友好型工具</strong>，这使得它成为很多企业项目的首选解决方案：它能够受到已知技术的约束；它能够解决特定的问题，所出现的问题能够通过调整输入信息、数据结构或者输出值来解决。事实上，<strong>AI在1980年代失宠是有原因的：无法将专家的能力转化成可外推到更加复杂的场景的规则组。</strong></p>
<p>　　然而，我认为<strong>AI才是未来。推理能力包含比商业需要重要的智力能力和情感能力。</strong>这是程序员、理论家和科学家们自统计学分析创立以来一直在竭力追求的东西；我们如何才能创造出能够解答我们不知道的问题的机器呢？IBM在这一领域进行了巨额投资，微软，特斯拉，甲骨文，谷歌，地球上的每一家医疗保健公司，大多数的银行，每一位想要找到赚更多钱的窍门且精通技术的企业家亦然。</p>
<p>　　如果你是位普通的企业家，那就投资机器学习。它会给你带来好处。但如果你是有远见的人，那就<strong>投资人工智能，你可能会改变世界。</strong>（皓慧）</p>
<p>　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
<h2 id="AI研究院-科普：人工智能与机器学习到底有什么区别？"><a href="#AI研究院-科普：人工智能与机器学习到底有什么区别？" class="headerlink" title="AI研究院 | 科普：人工智能与机器学习到底有什么区别？"></a>AI研究院 | 科普：人工智能与机器学习到底有什么区别？</h2><p>　　【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】</p>
<p>　　<img src="http://dingyue.nosdn.127.net/s3uiNsduKLIguOKVBKBjnBJgyAHbkNsqFOY5ZphBvVd8y1486696266124compressflag.jpg" alt=""></p>
<p>　　网易智能讯 2月10日消息，人们常常把人工智能与机器学习混为一谈，其实这两者之间有着很大的区别。</p>
<p>　　机器学习和人工智能是当前科技领域的两大趋势。实际上，这两个术语经常可以互换使用。然而，两者之间仍然存在着微妙却重大的差异。</p>
<p>　　从很多方面来说，机器学习是人工智能的一部分。而且，人工智能这个术语也比机器学习出现得更早。</p>
<p>　　它们之间的区别到底是什么呢?</p>
<p>　　<strong>人工智能的核心是试图让机器以人脑的方式进行思考。</strong> 著名的图灵测试表明，如果人类不能将一个系统的行为与人类的行为区别开来，那么这个系统就可以说是智能的。然而，目前的技术远未达到这一目标，所以人工智能目前也只是意味着创造出能够做出人类擅长的行为的系统。但这只是个笼统的说法。</p>
<p>　　机器学习也可以追溯到20世纪中期。<strong>阿瑟塞缪尔将机器学习定义为“在没有进行明确编程的情况下的学习能力”。</strong></p>
<p>　　使用及应用</p>
<p>　　机器学习</p>
<p>　　机器学习的原理几十年来一直没有得到重视(这一点与人工智能很像)，但随着上个世纪末之前数据挖掘工作的兴起，人们 <strong>需要一种算法来寻找每一个数据集的模式。机器学习做到了这一点，但它又更进一步，从过程中学习，而它的性能也会随着不断学习而提高。</strong></p>
<p>　　机器学习的另一种用途是图像识别。这些应用最初是由人类训练的，先观察图像，然后进行描述。在使用了成千上万的图像进行训练之后，机器学习系统就可以根据像素分辨出画面中是一条狗、一座房子、一束鲜花还是一个人。</p>
<p>　　机器学习也可以在推荐引擎中使用。这些算法可以帮助Facebook决定在新闻中显示什么信息，或者帮助亚马逊决定向用户推送什么广告。</p>
<p>　　随着大数据分析越来越普及，<strong>企业正在向依靠机器学习来驱动预测分析转变。与统计数据、数据挖掘和预测分析的联系已经足够让人认为机器学习是人工智能的一个领域。</strong></p>
<p>　　原因就在于，诸如自然语言处理或自动推理的人工智能技术可以在没有机器学习能力的情况下完成。机器学习系统并不需要具有人工智能的其他特征。</p>
<p>　　人工智能</p>
<p>　　人工智能目前有数百个使用案例，而随着企业不断采用人工智能来应对商业挑战，人工智能的案例也开始为人所知。</p>
<p>　　当前最受欢迎的人工智能应用之一是语音助手。微软的Cortana、Siri、谷歌助理和亚马逊Alexa都是智能家居和智能手机的核心部分，用户可以通过聊天机器人预约午餐会议，或者用语音助手来控制家里的照明开关。但是，Alexa现在站在另一个行业的前沿。聊天机器人和davis可以让IT管理员通过询问davis问题来识别和修复IT基础架构的问题。</p>
<p>　　人们有充分的理由担心人工智能将取代人类的工作岗位，如数据输入。牛津大学预计，在未来20年，英国约有35%的就业机会将被自动化取代。</p>
<p>　　将两个术语混淆</p>
<p>　　还有一些与这一主题相关的其他的术语。人工神经网络处理信息的方式与人脑类似。但是人工神经网络也相当擅长机器学习，这就让事情变得更加复杂了。</p>
<p>　　这种神经网络构成了深度学习的基础，而 <strong>深度学习本身就是机器学习的一种形式。</strong> 大量的机器学习算法能够利用成百上千的GPU瞬间处理大量数据。</p>
<p>　　如果你对这些感到困惑，不要担心，科学家们仍在探讨机器学习和人工智能的确切定义，探讨可能会一直持续下去。</p>
<p>　　（英文来源：ITPRO 编译：机器小易 审校：日月沉香）</p>
<p>　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dy.163.com/v2/article/detail/CBLFGEEV0511CUKV.html&quot;&gt;作者：网易AI研究院&lt;/a&gt;&lt;/p&gt;
 &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://dingyue.nosdn.127.net/FvoCteXeaxOQg4IblKLzFzKWGzhz86zMvylL6jsI6tLsx1485348908493compressflag.jpg&quot; width = &quot;839&quot; height = &quot;416&quot; &gt;&lt;br&gt; &lt;/div&gt;

&lt;p&gt;  对于企业而言，该投资人工智能还是机器学习呢？国外媒体发表Avanade高级总监贾马尔·赫瓦贾（Jamal Khawaja）的文章对这一问题进行了深入解析。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Atom编辑器入门到精通</title>
    <link href="http://ipcreator.me/2017/02/15/Program/Resources/techniques-of-atom-editor/"/>
    <id>http://ipcreator.me/2017/02/15/Program/Resources/techniques-of-atom-editor/</id>
    <published>2017-02-15T13:38:06.000Z</published>
    <updated>2017-02-15T14:34:03.978Z</updated>
    
    <content type="html"><![CDATA[<p>原文作者：<a href="http://blog.csdn.net/u010494080/article/details/50372857" target="_blank" rel="external">PeterHo</a></p>
<p>Atom是GitHub推出的一款编辑器, 被称为21世纪的黑客编辑器. 其主要的特点是现代, 易用, 可定制.</p>
<p><img src="https://raw.githubusercontent.com/PeterHo/images/master/blog/editor/atom/atom_1/first-launch.png" alt=""></p>
 <a id="more"></a>
<h2 id="命令面板"><a href="#命令面板" class="headerlink" title="命令面板"></a>命令面板</h2><p>命令面板是Atom中最常用的功能之一, 当你在编辑器中使用快捷键Ctrl+Shift+P时, 就会看到它<br>在控制面板中可以输入Atom中和插件中定义的所有命令, 并且支持模糊搜索<br>比如说当你输入cboo时, 所有包含有这4个字符的命令就都列出来了<br>在列出的命令后还显示了此命令对应的快捷键(如果有的话)<br><img src="https://raw.githubusercontent.com/PeterHo/images/master/blog/editor/atom/atom_1/command-palette.png" alt=""></p>
<p>保存文件 快捷键 Ctrl+S<br>保存所有文件: File-&gt;Save All</p>
<p>打开文件夹是一个很实用的功能, 可以像IDE一样打开一个项目的根目录<br>可以通过在主菜单选择File-&gt;Add Project Folder…来打开或者添加一个目录,也可以使用快捷键Ctrl+Alt+O.<br>在打开一个文件夹以后该文件夹下的所有子目录和文件就会如下图一样以目录树的方式显示在主窗口左边<br>你可以通过在目录树栏中右键菜单或选中文件时使用快捷键a,m,delete来对文件进行新建,重命名,删除等操作<br>如果要切换目录树栏的显示与隐藏可以使用快捷键Ctrl+\或输入命令Tree View:Toggle<br>目录树中右键菜单中还能实现文件的复制粘贴等功能<br><img src="https://raw.githubusercontent.com/PeterHo/images/master/blog/editor/atom/atom_1/project-view.png" alt=""></p>
<p>查找文件</p>
<p>当打开一个或多个目录时,你可以:</p>
<ul>
<li>通过Ctrl+T或Ctrl+P来搜索目录中的文件</li>
<li>通过Ctrl+B来搜索一个当前打开的文件</li>
<li>通过Ctrl+Shift+B来搜索一个新建的或更改过的文件</li>
</ul>
<h2 id="文本编辑基础"><a href="#文本编辑基础" class="headerlink" title="文本编辑基础"></a>文本编辑基础</h2><p>使用Ctrl+F进行文件内查找<br>使用Ctrl+Shift+F进行工程内查找</p>
<h2 id="代码片段-Snippets"><a href="#代码片段-Snippets" class="headerlink" title="代码片段(Snippets)"></a>代码片段(Snippets)</h2><p>代码片段(Snippets)</p>
<blockquote>
<p>片段（Snippet）是一个编程用语，指的是源代码、机器码、文本中可重复使用的小区块。通常它们是有正式定义的执行单位，以纳入更大的编程模块。片段经常用来明晰其他“凌乱”函式的功用，或尽量减少使用与其他函式共用的重复代码。 片段管理是某些文本编辑器、程式源代码编辑器、IDE、与相关软件的其中一项功能。其使得使用者能够在反复的编辑作业中保持和使用这些片段。</p>
</blockquote>
<p><strong>让我们通过一个实验来感受一下Snippets给我们带来的便利体验 </strong></p>
<ol>
<li>打开Atom编辑器</li>
<li>使用Cmd+N新建一个文件</li>
<li>使用Cmd+S保存文件,将文件名改为new.html</li>
<li>在new.html中键入html四个字符,然后按tab键,这时你会发现html这段文本被扩展成了<figure class="highlight apache"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="section">&lt;html&gt;</span></div><div class="line">  <span class="section">&lt;head&gt;</span></div><div class="line">    <span class="section">&lt;title&gt;</span><span class="section">&lt;/title&gt;</span></div><div class="line">  <span class="section">&lt;/head&gt;</span></div><div class="line">  <span class="section">&lt;body&gt;</span></div><div class="line"></div><div class="line">  <span class="section">&lt;/body&gt;</span></div><div class="line"><span class="section">&lt;/html&gt;</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>并且光标被移到了<title>标签之间,方便你直接输入这个html文件的标题</title></p>
<ol>
<li>在<title>标签之间输入完成html页面标题以后,再次键入tab键<br>你会发现光标又被移到了<body>标签下面了</body></title></li>
</ol>
<p>Snippets,它让你可以很方便地通过一个关键词来插入一段代码块,并且还能通过tab键在这段代码块的输入点之间移动光标,达到快速编码的目的<br>不同类型的文件有不同的Snippets,你可以通过控制面板输入Snippets:available来列出当前文件所提供的所有的Snippets</p>
<p><img src="https://raw.githubusercontent.com/PeterHo/images/master/blog/editor/atom/atom_4/snippets.png" alt=""></p>
<h2 id="预览"><a href="#预览" class="headerlink" title="预览"></a>预览</h2><p>在进行Markdown文档的编辑时, 我们经常想要看一看编辑的效果. Atom默认就支持这一功能.<br>我们只需要在编辑md文件时使用Ctrl+Shift+M, 就能显示一个预览窗口, 方便我们随时查看md编辑的效果. 并且这个预览窗口还能随着我们的编辑自动刷新预览的内容和效果.</p>
<p><img src="https://raw.githubusercontent.com/PeterHo/images/master/blog/editor/atom/atom_6/preview.png" alt=""></p>
<p>Snippets(代码片段)</p>
<p>Atom中内置了多个Snippets来方便Markdown文档的编辑.比如img(插入图片), table(插入表格), b(插入粗体), i(插入斜体), code(插入代码)等.<br>关于Snippets的详细使用方法请参考本系列文章的第四章Atom使用进阶.</p>
<h2 id="CSON"><a href="#CSON" class="headerlink" title="CSON"></a>CSON</h2><p>CSON(CoffeeScript Object Notation)是Atom配置文件的文件格式, 它使用键值对的格式来存储数据. 就像下面这个样子</p>
<p>key:<br>    key: value<br>    key: value<br>    key: [value, value]</p>
<p>跟Python类似, CSON使用缩进来标识语句块.</p>
<p>CSON的key的名字不能重复, 如果CSON中包含了多个同名的key, 那么最后的那个key的值会覆盖之前同名的key.<br>因此不能这样配置</p>
<h1 id="只有第二个snippet会被载入"><a href="#只有第二个snippet会被载入" class="headerlink" title="只有第二个snippet会被载入"></a>只有第二个snippet会被载入</h1><p>‘.source.js’:<br>  ‘console.log’:<br>    ‘prefix’: ‘log’<br>    ‘body’: ‘console.log(${1:”crash”});$2’<br>‘.source.js’:<br>  ‘console.error’:<br>    ‘prefix’: ‘error’<br>    ‘body’: ‘console.error(${1:”crash”});$2’</p>
<p>而应该这样配置</p>
<h1 id="两个snippets都会被载入"><a href="#两个snippets都会被载入" class="headerlink" title="两个snippets都会被载入"></a>两个snippets都会被载入</h1><p>‘.source.js’:<br>  ‘console.log’:<br>    ‘prefix’: ‘log’<br>    ‘body’: ‘console.log(${1:”crash”});$2’<br>  ‘console.error’:<br>    ‘prefix’: ‘error’<br>    ‘body’: ‘console.error(${1:”crash”});$2’</p>
<p>value可以是字符串, 数字, 对象, 布尔值, null, 或数组.</p>
<h2 id="配置热键"><a href="#配置热键" class="headerlink" title="配置热键"></a>配置热键</h2><p>在Atom中热键的配置方式与主题类似, 举个例子:</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">'atom-text-editor</span><span class="symbol">':</span></div><div class="line">  <span class="symbol">'enter</span><span class="symbol">':</span> <span class="symbol">'editor:newline</span>'</div><div class="line"></div><div class="line"><span class="symbol">'atom-text-editor</span>[<span class="name">mini</span>] input<span class="symbol">':</span></div><div class="line">  <span class="symbol">'enter</span><span class="symbol">':</span> <span class="symbol">'core:confirm</span>'</div></pre></td></tr></table></figure>
<p>上面的代码定义了Enter键在不同环境中的不同表现. 在正常的编辑窗口中按enter键触发editor:newline命令, 也即是普通的回车. 而当在一个编辑框中键入enter时, 则会触发core:confirm命令.</p>
<p>在默认情况下, 当Atom启动时会加载keymap.cson文件来获取自定义热键, 并且keymap.cson是最后被加载的配置文件, 这样可以保证我们配置的热键可以覆盖Atom自身或其插件定义的热键. 这个文件同样位于~/.atom目录下, 当然也可以通过主菜单Edit-&gt;Keymap…来直接编辑这个文件.</p>
<p>我们也可以<strong>在设置窗口的Keybindings页面查看当前所有的快捷键.</strong></p>
<p>Atom还提供了一个窗口来帮助我们调试热键的设置, 可以使用Ctrl+.或命令Key Binding Resolver: Toggle来呼出该窗口. 此窗口可以实时显示我们按下的热键所对应的处理方法.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文作者：&lt;a href=&quot;http://blog.csdn.net/u010494080/article/details/50372857&quot;&gt;PeterHo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Atom是GitHub推出的一款编辑器, 被称为21世纪的黑客编辑器. 其主要的特点是现代, 易用, 可定制.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/PeterHo/images/master/blog/editor/atom/atom_1/first-launch.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Atom" scheme="http://ipcreator.me/tags/Atom/"/>
    
  </entry>
  
  <entry>
    <title>吴恩达 NIPS 2016：利用深度学习开发人工智能应用的基本要点</title>
    <link href="http://ipcreator.me/2017/02/14/Program/Concepts/ppt-of-andrew-ng/"/>
    <id>http://ipcreator.me/2017/02/14/Program/Concepts/ppt-of-andrew-ng/</id>
    <published>2017-02-14T06:39:06.000Z</published>
    <updated>2017-02-14T06:48:40.515Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201612/PTmKczqq5XWr2n8c.html" target="_blank" rel="external">雷锋网 亚峰</a></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0d1235f.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>雷锋网(公众号：雷锋网)按：为了方便读者学习和收藏，雷锋网特地把吴恩达教授在NIPS 2016大会中的PPT做为中文版，由三川和亚峰联合编译并制作。</p>
<p>今日，在第 30 届神经信息处理系统大会（NIPS 2016）中，百度首席科学家吴恩达教授发表演讲：《利用深度学习开发人工智能应用的基本要点（Nuts and Bolts of Building Applications using Deep Learning）》。</p>
<p>此外，吴恩达教授曾在今年 9 月 24/25 日也发表过同为《Nuts and Bolts of Applying Deep Learning》的演讲(1小时20分钟)，以下是 YouTube 链接：</p>
<p><a href="https://www.youtube.com/watch?v=F1ka6a13S9I" target="_blank" rel="external">https://www.youtube.com/watch?v=F1ka6a13S9I</a></p>
  <a id="more"></a>
<p>  一、深度学习为何崛起</p>
<p>吴恩达在开场提到：深度学习为何这么火？</p>
<p>答案很简单：</p>
<p>第一是因为规模正在推动深度学习的进步。</p>
<p>从传统算法到小型神经网络、中型神经网络最后演化为现在的大型神经网络。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584779f49171a.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>第二：端到端学习的崛起</p>
<p>从下图中的上半部分可以看出，传统端到端学习是把实体数据表达成数字数据，输出数字值作为结果。如退昂识别最后以整数标签输出为结果。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584779feabee6.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>而现在的端对端学习更为直接纯粹，如机器翻译：输入英语文本，输出法语文本；语音识别：输入音频，输出文本。但端对端学习需要大量的训练集。</p>
<p>吴恩达先讲述了常见的深度学习模型，然后再着分析端到端学习的具体应用。</p>
<p>二、主要的深度学习模型</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0b0ae08.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>普通神经网络</p>
<p>顺序模型   (1D  顺序)  RNN,  GRU,  LSTM,  CTC,  注意力模型</p>
<p>图像模型  2D 和  3D 卷积神经网络</p>
<p>先进/未来 技术：无监督学习（稀疏编码 ICA,  SFA,）增强学习</p>
<p>三、端到端学习应用案例</p>
<p>语音识别</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0c0e9a6.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>传统模型：语音→运算特征—（人工设计的 MFCC 特征）→音素识别器—（音素识别）→最终识别器→输出。</p>
<p>端到端学习：音频→学习算法→转录结果；在给定了足够的有标注数据（音频、转录结果）时，这种方法的效果会很好。</p>
<p>自动驾驶</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584779fc94f79.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>传统模型：摄像头图像→检测汽车+检测行人→路径规划→方向控制。</p>
<p>端到端学习：摄像头图像→学习算法→方向控制。</p>
<p>自动驾驶对安全有极高要求，因此需要极高的精确度。采取纯粹的端到端学习十分有挑战性。只在有足够（x，y）的数据，来学习足够复杂的函数的情况下，端到端学习才有效果。</p>
<p>四、机器学习策略</p>
<p>你经常有很多改进 AI 系统的主意，应该怎么做？<strong>好的战略能避免浪费数月精力做无用的事。</strong></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477fa2221e1.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>以语音识别为例，可以把原语音数据分割成：</p>
<p>60% 训练集（训练模型）</p>
<p>20% 开发集（开发过程中用于调参、验证等步骤的数据集）</p>
<p>20% 测试集（测试时所使用的数据集）</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477fdc2707d.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>这里面普及几个概念：</p>
<p>人类水平的误差与训练集的误差之间的差距是可避免的偏差，这部分误差可以通过进一步的学习/模型调整优化来避免。</p>
<p>训练集和开发集之间的差距称为方差，其因为跑了不同的数据从而导致误差率变化。</p>
<p>上述两种偏差合在一起，就是偏差-方差权衡（bias-variance trade-off）。</p>
<p>机器学习的基本方案</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477ff3216e7.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>自动数据合成示例</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0000ceb.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>不同训练、测试集的分布</p>
<p>假设你想要为一个汽车后视镜产品，开发语音识别系统。你有 5000 小时的普通语音数据，还有 10 小时的车内数据。你怎么对数据分组呢？这是一个不恰当的方式：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a09dce13.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>不同训练和测试集分配</p>
<p>更好的方式：让开发和测试集来自同样的分配机制。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a01dc926.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>五、机器学习新方案</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a067f05f.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>普通人类、偏差、方差分析</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a07a8ad7.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>人类的表现水平</p>
<p>当机器学习在处理某项任务上比人类表现还差时，你经常会看到最快的进步。</p>
<p>机器学习超越人后，很快就会靠近贝叶斯最优误差线。</p>
<p>可以依靠人类的直觉：（i）人类提供加标签的数据。（ii）进行错误分析，来理解人是怎么对样本正确处理的（iii）预估偏差/方差。比如，一项图像识别任务的训练误差 8%， 开发误差 10%，你应该怎么处理？</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a08d579e.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0419c23.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>六、人工智能产品管理</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0514bd9.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>新的监督DL算法的存在，意味着对使用 DL开发应用的团队合作，我们在重新思考工作流程。产品经理能帮助 AI 团队，优先进行最出成果的机器学习任务。比如，对于汽车噪音、咖啡馆的谈话声、低带宽音频、带口音的语音，你是应该提高语音效果呢，还是改善延迟，缩小二进制，还是做别的什么？</p>
<p>今天的人工智能能做什么呢？这里给产品经理一些启发：</p>
<p>如果一个普通人完成一项智力任务只需不到一秒的思考时间，我们很可能现在，或者不远的将来，用 AI 把该任务自动化。</p>
<p>对于我们观察到的具体的、重复性的事件（比如用户点击广告；快递花费的时间），我们可以合理地预测下一个事件的结果（用户是否点击下一个此类广告）。</p>
<p>产品经理和研究员、工程师该如何分工</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/58478049baadd.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>七、吴恩达新书推荐</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5847805854dda.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>雷锋网原创文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201612/PTmKczqq5XWr2n8c.html&quot;&gt;雷锋网 亚峰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201612/58477a0d1235f.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;雷锋网(公众号：雷锋网)按：为了方便读者学习和收藏，雷锋网特地把吴恩达教授在NIPS 2016大会中的PPT做为中文版，由三川和亚峰联合编译并制作。&lt;/p&gt;
&lt;p&gt;今日，在第 30 届神经信息处理系统大会（NIPS 2016）中，百度首席科学家吴恩达教授发表演讲：《利用深度学习开发人工智能应用的基本要点（Nuts and Bolts of Building Applications using Deep Learning）》。&lt;/p&gt;
&lt;p&gt;此外，吴恩达教授曾在今年 9 月 24/25 日也发表过同为《Nuts and Bolts of Applying Deep Learning》的演讲(1小时20分钟)，以下是 YouTube 链接：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=F1ka6a13S9I&quot;&gt;https://www.youtube.com/watch?v=F1ka6a13S9I&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Facebook 发布开源框架 PyTorch</title>
    <link href="http://ipcreator.me/2017/02/14/Program/Resources/pytorch-of-facebook/"/>
    <id>http://ipcreator.me/2017/02/14/Program/Resources/pytorch-of-facebook/</id>
    <published>2017-02-14T05:11:06.000Z</published>
    <updated>2017-02-16T01:00:02.364Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201701/Tb4KueUFvTWNUPRb.html" target="_blank" rel="external">雷锋网 三川</a></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5881deecab918.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>本周，Facebook 的 AI 研究团队发布了一个 Python 工具包，专门针对 GPU 加速的深度神经网络（DNN）编程。它有望辅助、或在一定程度上替代，现有的 Python 数学、统计库（比如 NumPy）。它实现了机器学习框架 Torch 在 Python 语言环境的执行。开发团队表示，除 Facebook之外，它还已经被推特、卡内基梅隆大学和 Salesforce 等机构采用。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5881df38d336d.png?imageMogr2/format/jpg/quality/90" alt=""></p>
  <a id="more"></a>
<p>  Torch 是一个十分老牌、对多维矩阵数据进行操作的张量（tensor ）库，在机器学习和其他数学密集型应用有广泛应用。但由于其语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。如今，作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。雷锋网此前对 Torch 做过介绍。详情请看盘点四大民间机器学习开源框架：Theano、Caffe、Torch 和 SciKit-learn 。</p>
<p>PyTorch 的特点和优势</p>
<p>PyTorch 提供了：</p>
<p>运行在 GPU 或 CPU 之上、基础的张量操作库，</p>
<p>内置的神经网络库</p>
<p>模型训练功能</p>
<p>支持共享内存的多进程并发（multiprocessing ）库。PyTorch 开发团队表示：这对数据载入和 hogwild 训练十分有帮助。</p>
<p>PyTorch 的首要优势是，它处于机器学习第一大语言 Python 的生态圈之中，使得开发者能接入广大的 Python 库和软件。因此，Python 开发者能够用他们熟悉的风格写代码，而不需要针对外部 C 语言或 C++ 库的 wrapper，使用它的专门语言。雷锋网获知，现有的工具包可以与 PyTorch 一起运行，比如 NumPy、SciPy 和 Cython（为了速度把 Python 编译成 C 语言）。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5881dfdf8fc44.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>PyTorch 还为改进现有的神经网络，提供了更快速的方法——不需要从头重新构建整个网络。这是由于 PyTorch 采用了动态计算图（dynamic computational graph）结构，而不是大多数开源框架，比如 TensorFlow、Caffe、CNTK、Theano 等采用的静态计算图。雷锋网(公众号：雷锋网)获知，该技术从另一个 Python 的神经网络框架——Chainer 那里借用。开发者团队还强调 PyTorch 优越的内存效率，因为它采用了定制的 GPU 内存分配器。这使得开发者的深度学习模型能够有“最大限度的内存效能”，训练比从前更大的深度神经网络。</p>
<p>虽然 PyTorch 为机器学习应用而优化，这并不是它的唯一使用场景。比如说，相比 NumPy ，PyTorch 的张量计算可作为它对应功能的替代。PyTorch 为这些功能提供了 GPU 加速的版本。在没有强力 GPU 加持的情况下，开发者能使用 CPU 运行。</p>
<p>这是 PyTorch 中包含的工具包列表：</p>
<p>torch ：类似  NumPy 的张量库，强 GPU 支持</p>
<p>torch.autograd  ：基于 tape 的自动区别库，支持 torch 之中的所有可区分张量运行。</p>
<p>torch.nn ：为最大化灵活性未涉及、与 autograd 深度整合的神经网络库</p>
<p>torch.optim：与 torch.nn 一起使用的优化包，包含 SGD, RMSProp, LBFGS, Adam 等标准优化方式</p>
<p>torch.multiprocessing： python 多进程并发，进程之间 torch Tensors 的内存共享。</p>
<p>torch.utils：数据载入器。具有训练器和其他便利功能。 Trainer and other utility functions for convenience    </p>
<p>torch.legacy(.nn/.optim) ：处于向后兼容性考虑，从 Torch 移植来的 legacy 代码。</p>
<p>via <a href="http://www.infoworld.com/article/3159120/artificial-intelligence/facebook-brings-gpu-powered-machine-learning-to-python.html" target="_blank" rel="external">infoworld</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201701/Tb4KueUFvTWNUPRb.html&quot;&gt;雷锋网 三川&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201701/5881deecab918.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本周，Facebook 的 AI 研究团队发布了一个 Python 工具包，专门针对 GPU 加速的深度神经网络（DNN）编程。它有望辅助、或在一定程度上替代，现有的 Python 数学、统计库（比如 NumPy）。它实现了机器学习框架 Torch 在 Python 语言环境的执行。开发团队表示，除 Facebook之外，它还已经被推特、卡内基梅隆大学和 Salesforce 等机构采用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201701/5881df38d336d.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
  </entry>
  
  <entry>
    <title>如何训练深度神经网络？老司机的 15 点建议</title>
    <link href="http://ipcreator.me/2017/02/14/Program/TensorFlow/how-to-train-deep-neural-network/"/>
    <id>http://ipcreator.me/2017/02/14/Program/TensorFlow/how-to-train-deep-neural-network/</id>
    <published>2017-02-13T23:54:06.000Z</published>
    <updated>2017-02-13T23:57:08.535Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201701/gOwAU7YFQkJcFkVB.html" target="_blank" rel="external">雷锋网</a></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/587f11cbe835b.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>本文为印度深度学习专家、创业者 Rishabh Shukla 在 GitHub 上发表的长博文，总结了他过去的开发经验，旨在给新入门的开发者提供指导。雷锋网做了不改变原意的编译。</p>
<p>在深度学习领域，为了高效训练深度神经网络，有些实践方法被过来人强烈推荐。</p>
<p>在这篇博文中，我会覆盖几种最常使用的实践方法，从高品质训练数据的重要性、超参数（hyperparameters）到更快创建 DNN（深度神经网络） 原型模型的一般性建议。这些推荐方法中的大多数，已被学术界的研究所证实，并在论文中展示了相关实验、数学证据，比如 Efficient BackProp(Yann LeCun et al.) 和 Practical Recommendations for Deep Architectures(Yoshua Bengio)。</p>
  <a id="more"></a>
<ol>
<li>训练数据</li>
</ol>
<p>许多 ML 开发者习惯把原始训练数据直接扔给 DNN——为什么不这么做呢？既然任何 DNN （大多数人的假设）仍然能够给出不错的结果，不是吗？但是，有句老话叫“给定恰当的数据类型，一个简单的模型能比复杂 DNN 提供更好、更快的结果”。虽然这有一些例外，但在今天，这句话仍然没有过时。因此，不管你是在计算机视觉（ CV），自然语言处理（NLP）还是统计建模（Statistical Modelling）等领域，想要对原始数据预处理，有几个方法可以得到更好的训练数据：</p>
<p>获取越大的数据库越好。DNN 对数据很饥渴，越多越好。</p>
<p>去除所有包含损坏数据的训练样本，比如短文字，高度扭曲的图像，假输出标签，包含许多虚值（null values）的属性。</p>
<p>Data Augmentation（数据扩张）——生成新样例。以图像为例，重新调节，增加噪声等等。</p>
<ol>
<li>选择恰当的激励函数（activation function）</li>
</ol>
<p>激励函数是所有神经网络的核心部分之一。</p>
<p>激励函数把渴望已久的非线性（non-linearity）加入了模型。多年来，Sigmoid 函数 一直是多数人倾向的选择。但是，Sigmoid 函数不可避免地存在两个缺陷：1. 尾部  sigmoids 的饱和，进一步导致梯度消失。2. 不以 0 为中心（输出在 0 到 1 之间）。</p>
<p>一个更好的替代选择是 Tanh 函数。数学上来说，Tanh 只是调整、平移过的 Sigmoid 函数：tanh(x) = 2*sigmoid(x) - 1。虽然 Tanh 仍旧存在梯度消失的缺陷，但好消息是：Tanh 以 0 为中心。因此，把 Tanh 作为激励函数能更快地收敛（converge）。我发现使用 Tanh 通常比 Sigmoid 效果更好。</p>
<p>你还可以探索其他选择，比如 ReLU, SoftSign 等等。对于一些特定任务， 它们能够改善上述问题。</p>
<ol>
<li>隐藏单元和隐层（Hidden Units and Layers）的数量</li>
</ol>
<p>如何训练深度神经网络？老司机的 15 点建议</p>
<p>保留超出最优数量的隐藏单元，一般是比较保险的做法。这是因为任何正则化方法（ regularization method）都会处理好超出的单元，至少在某种程度上是这样。在另一方面，保留比最优数量更少的隐藏单元，会导致更高的模型欠拟合（underfitting）几率。</p>
<p>另外，当采用无监督预训练的表示时（unsupervised pre-trained representations，下文会做进一步解释），隐藏单元的最优数目一般会变得更大。因此，预训练的表示可能会包含许多不相关信息（对于特定任务）。通过增加隐藏单元的数目，模型会得到所需的灵活性，以在预训练表示中过滤出最合适的信息。</p>
<p>选择隐层的最优数目比较直接。正如 Yoshua Bengio 在  Quora 中提到的：</p>
<p>“你只需不停增加层，直到测试误差不再减少。”</p>
<ol>
<li>权重初始化 （Weight Initialization）</li>
</ol>
<p>永远用小的随机数字初始化权重，以打破不同单元间的对称性（symmetry）。但权重应该是多小呢？推荐的上限是多少？用什么概率分布产生随机数字？</p>
<p>当使用 Sigmoid 激励函数时，如果权重初始化为很大的数字，那么 sigmoid 会饱和（尾部区域），导致死神经元（dead neurons）。如果权重特别小，梯度也会很小。因此，最好是在中间区域选择权重，比如说那些围绕平均值均衡分布的数值。</p>
<p>幸运的是，已经有许多关于初始权重合适取值的研究。这对于高效的收敛非常重要。为初始化均衡分布的权重，均匀分布（uniform distribution ）或许是最好的选择之一。另外，就像论文中所展示的（Glorot and Bengio, 2010），有更多输入连接（fan_in）的单位，应该有相对更小的权重。</p>
<p>多亏这些十分透彻的试验，现在我们已经有了经过检验的公式，可以直接用来权重的初始化。</p>
<p>比如说在  ~ Uniform(-r, r) 提取的权重，对于 tanh 激励  r=sqrt(6/(fan_in+fan_out))；对于 sigmoid 激励 r=4*(sqrt(6/fan_in+fan_out)) 。fan_in 是上一层的大小， 而 fan_out 是下一层的。</p>
<ol>
<li>学习率</li>
</ol>
<p>这或许是最重要的超参数之一，调节着学习过程。如果学习率设置得太小，你的模型很可能需要 n 年来收敛。设置得太大，再加上不多的初始训练样本，你的损失可能会极高。一般来说，0.01 的学习率比较保险。但雷锋网(公众号：雷锋网)提醒各位读者，这不是一个严格的标准。最优学习率与特定任务的属性息息相关。</p>
<p>相比固定学习率，在每个周期、或每几千个样例后逐渐降低学习率是另一个选择。虽然这能更快地训练，但需要人工决定新的学习率。一般来说，学习率可以在每个周期后减半。几年前，这种策略十分普遍。</p>
<p>幸运的是，我们现在有了更好的、基于动能（momentum based）的方法，来调整学习率。这取决于误差函数的曲率。另外，既然有些参数有更快、或更慢的学习速率；它或许能帮助我们针对模型中的单独参数，设定不同的学习率。</p>
<p>最近有大量关于优化方法的研究，导致了自适应学习率（adaptive learning rates）。目前我们有许多选择，从老式动能方法（ Momentum Method ），到  Adagrad、Adam （个人最爱）、 RMSProp 等等。；类似于 Adagrad 或 Adam 的方法，能替我们省去人工选择初始学习率的麻烦；给定合适的时间，模型会开始平滑地收敛。当然，选择一个特别合适的初始学习率仍然能起到帮助作用。</p>
<ol>
<li>超参数调参：扔掉网格搜索，拥抱随机搜索</li>
</ol>
<p>网格搜索（Grid Search ）在经典机器学习中十分普遍。但它在寻找 DNN 的最优超参数方面一点也不高效。这主要是由于 DNN 尝试不同超参数组合所耗费的时间。随着超参数不断增长，网格搜索需要的计算性能会指数级增长。</p>
<p>有两种解决办法：</p>
<p>取决于你之前的经验，你可以人工对部分常见超参数调参，比如学习率、隐层数目。</p>
<p>采用随机搜索（random search），或者随机采样代替网格搜索，来选择最优超参数。</p>
<p>超参数组合通常在期望范围之内、从均匀分布中被选择出来。加入之前获得的知识来进一步缩小搜寻空间，也是有可能的（比如，学习率不应该太大也不应该太小）。大家发现，随机搜索比网格搜索高效地多。</p>
<ol>
<li>学习方法</li>
</ol>
<p>随机梯度下降（ Stochastic Gradient Descent ）的老方法也许对于 DNN 不是那么有效率（有例外）。最近，有许多研究聚焦于开发更灵活的优化算法，比如 Adagrad、Adam,、AdaDelta,、RMSProp 等等。在提供自适应学习率之外，这些复杂的方法还对于模型的不同参数使用不同的学习率，通常能有更平滑的收敛。把这些当做超参数是件好事，你应该每次都在训练数据的子集上试试它们。</p>
<ol>
<li>权重的维度保持为 2 的幂</li>
</ol>
<p>即便是运行最先进的深度学习模型，使用最新、最强大的计算硬件，内存管理仍然在字节（byte）级别上进行。所以，把参数保持在 64, 128, 512, 1024 等 2 的次方永远是件好事。这也许能帮助分割矩阵和权重，导致学习效率的提升。当用 GPU 运算，这变得更明显。</p>
<ol>
<li>无监督预训练（Unsupervised Pretraining ）</li>
</ol>
<p>不管你进行的是 NLP（自然语言处理）、计算机视觉还是语音识别等任务，无监督预训练永远能帮助你训练监督、或其他无监督模型：NLP 中词向量就（Word Vectors）无所不在；你可以用 ImageNet 的数据库，使用无监督方式对你的模型预训练，或是对于两个类别的监督分类；或是更大频域的音频样本，来在扬声器消崎模型（speaker disambiguation model）中使用该信息。</p>
<ol>
<li>Mini-Batch（小批量） 对比随机学习（Stochastic Learning）</li>
</ol>
<p>训练一个模型的主要目的是学习合适的参数，即产生输入到输出的最优映射。这些参数利用每个训练样本进行调参，不管你决定使用 batch, mini-batch 还是随机学习。当采用随机学习方法时，学习每个训练样本后权重的梯度都会进行调参，向梯度加入噪音（随机学习中“随机”的由来）。这样做的结果十分理想，比如说，训练中加入的噪音使得模型更不容易过拟合。</p>
<p>但是，随机学习方法也许效率不高。如今的计算设备有非常可观的运算能力，随机学习很可能会浪费其中的一大部分。如果我们能计算矩阵相乘，那么为什么要限制自己，重复单个矢量组之间的乘法呢？因此，为了更高的吞吐率和更快的学习，我推荐使用 mini-batch 而不是随机学习。</p>
<p>但是，选择适当的 batch 规模同样重要。所以我们能保留一些噪音（相比大规模 batch），与此同时更高效地利用计算性能。一般来说，包含  16 个到 128 个样例的 batch（2 的幂）是不错的选择。通常，一旦你发现了更重要的超参数（通过随机搜索或是人工搜索），batch 规模就会确性下来。但是，有些场景中模型得到训练数据流（比如网络学习），那么采用随机学习就是不错的选择。</p>
<ol>
<li>打乱训练样本</li>
</ol>
<p>这来自于信息理论（Information Theory）——“学习到一件不太可能发生的事却发生了，比学习一件很可能发生的事已经发生，包含更多的信息。”同样的，把训练样例的顺序随机化（在不同周期，或者 mini-batch），会导致更快的收敛。如果模型看到的很多样例不在同一种顺序下，运算速度会有小幅提升。</p>
<ol>
<li>使用 Dropout 正则化</li>
</ol>
<p>如果有数百万的参数需要学习，正则化就是避免 DNN 过拟合的必须手段。你也可以继续使用 L1/L2 正则化，但 Dropout 是检查 DNN 过拟合的更好方式（雷锋网按：Dropout 是指随机让网络某些隐层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重会保留下来）。执行 Dropout 很容易，并且通常能带来更快地学习。0.5 的默认值是一个不错的选择，当然，这取决于具体任务。如果模型不太复杂，0.2 的 Dropout 值或许就够了。</p>
<p>在测试阶段，Dropout 应该被关闭，权重要调整到相应大小。只要对一个模型进行 Dropout 正则化，多一点训练时间，误差一定会降低。</p>
<ol>
<li>周期 / 训练迭代次数</li>
</ol>
<p>“对深度学习模型进行多个周期的训练，会得到更好的模型”——我们经常听到这句话。但多少周期才是“多”呢？其实，这里有一个简单的策略：继续按照一个固定的样例数或者周期训练模型，比如两万个样例或者一个周期。在每批样例之后，比较测试误差（test error）和训练误差（train error），如果它们的差距在缩小，那么继续训练。另外，记得在每批训练之后，保存模型的参数，所以训练好之后你可以从多个模型中做选择。</p>
<ol>
<li>可视化</li>
</ol>
<p>训练深度学习模型有上千种出差错的方式。我猜大家都遇到过这样的场景：模型已经训练了几个小时或者好几天，然而在训练完成之后，才意识到某个地方出问题了。为了不让你自己神经错乱，一定要对训练过程作可视化处理。比较显而易见的措施是保存或打印损失值、训练误差、测试误差等项目的日志。</p>
<p>在此之外，一个很好的措施是采用可视化库（visualization library ），在几个训练样例之后、或者周期之间，生成权重柱状图。这或许能帮助我们追踪深度学习模型中的一些常见问题，比如梯度消失与梯度爆发（Exploding Gradient）。</p>
<ol>
<li>使用支持 GPU 和自动微分法 (Automatic Differentiation）的库</li>
</ol>
<p>谢天谢地，对于快速创建原型模型，我们已经有了相当不错的库，比如 Theano, Tensorflow, Keras 等等。几乎所有这些深度学习库支持 GPU 计算和自动微分法。所以，你不需要深入研究核心 GPU 编程技术（除非你想——这绝对很有意思）。你也不需要写自己的微分代码——在非常复杂的模型上这相当费劲（但若需要，你应该有能力去做）。 Tensorflow还提供了分布式计算的支持——如果你是土豪的话。</p>
<p>最后雷锋网提醒，这并不是训练 DNN 的完整注意事项表。为了容纳最常见的实践方法，作者去除了一些概念，比如 Normalization of inputs, Batch/Layer Normalization, Gradient Check 等。</p>
<p>via <a href="http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/" target="_blank" rel="external">github</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201701/gOwAU7YFQkJcFkVB.html&quot;&gt;雷锋网&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201701/587f11cbe835b.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文为印度深度学习专家、创业者 Rishabh Shukla 在 GitHub 上发表的长博文，总结了他过去的开发经验，旨在给新入门的开发者提供指导。雷锋网做了不改变原意的编译。&lt;/p&gt;
&lt;p&gt;在深度学习领域，为了高效训练深度神经网络，有些实践方法被过来人强烈推荐。&lt;/p&gt;
&lt;p&gt;在这篇博文中，我会覆盖几种最常使用的实践方法，从高品质训练数据的重要性、超参数（hyperparameters）到更快创建 DNN（深度神经网络） 原型模型的一般性建议。这些推荐方法中的大多数，已被学术界的研究所证实，并在论文中展示了相关实验、数学证据，比如 Efficient BackProp(Yann LeCun et al.) 和 Practical Recommendations for Deep Architectures(Yoshua Bengio)。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Neural Network" scheme="http://ipcreator.me/tags/Neural-Network/"/>
    
  </entry>
  
  <entry>
    <title>脑芯编：窥脑究竟，织网造芯</title>
    <link href="http://ipcreator.me/2017/02/14/Program/Concepts/brain-and-chips/"/>
    <id>http://ipcreator.me/2017/02/14/Program/Concepts/brain-and-chips/</id>
    <published>2017-02-13T23:14:06.000Z</published>
    <updated>2017-02-16T02:27:24.266Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.leiphone.com/news/201612/E4eY2HYElJIC0be5.html" target="_blank" rel="external">雷锋网：本文作者痴笑，矽说（微信号：silicon_talks）主笔。</a></p>
<p>你信不信有一天，硅工造的芯片会写诗？</p>
<p>如果信，<br>那说好的“诗三百，一言以蔽之，思无邪”，<br>还真的是“无邪”么？<br>如果不信，请读下面这一首：<br><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fd23f4a433.png?imageMogr2/format/jpg/quality/90" alt=""><br>脑芯编：窥脑究竟，织网造芯（一）</p>
<p>如果要给这诗一个赏析，大概可以是一个忧伤的故事。</p>
<p>天边云的变换复杂，而我却是半梦半醒，我在想一个人，想第一次和他相见，想他的风流倜傥，想他的英雄飒爽。<br>如果你是个文科生，或许你会嘲笑这首连平仄都不满足的劣质诗歌，韵脚也押的有些蹩脚，故事更是为赋新词强说愁。</p>
<p>如果你是理科男，或许对这种思春的小情怀不以为然。</p>
<p>不过，那是因为你们并没有看懂这首诗。</p>
<p>因为这诗暗藏了一个密码，藏着人工智能遇到摩尔定律后蹭出的火花。</p>
<p>另外，这诗不是人工智能的产物，只是矽说在这个人工智能横行的年代里特有的小情怀。</p>
<p>但可能在不远的将来，人工智能将会开车，会翻译，会调情，也会写下更美的篇章。想解开这个人工智能与集成电路的秘密？关注雷锋网(公众号：雷锋网)后期更新，我们一句一句地读下去。</p>
  <a id="more"></a>
<h2 id="〈一〉昨夜神风送层云"><a href="#〈一〉昨夜神风送层云" class="headerlink" title="〈一〉昨夜神风送层云"></a>〈一〉昨夜神风送层云</h2><p>在我读书的时候，人工智能（Artifical Intelligence, AI）从来就是CS (Computer Science)的天下，哪有电路撺掇的份。那时候的码农们或许会挂着机器学习，数据挖掘，支持向量机，压缩感知……但从来没有一次，电路的突破是由人工智能推动的。可是在今天，如果你打开半导体行业的利好消息，有多少不是和人工智能，深度学习相关的？</p>
<p>过去几个月，光在半导体巨头们发生的人工智能的故事就足以吊足大家的胃口。何况，这还是只是很多硅工心目中的人工智能元年。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fd320e7eec.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>是什么导致了半导体行业”AI一出惊天下“的巨大改变？矽说推出“脑芯编”系列，为你揭秘类脑芯片的过去，现在与未来。</p>
<p>从人工智能到神经网络神经网络</p>
<p>在人工智能改变半导体行业之前，在AI领域发生过一场“华山论剑”，耗时数载，最终以“深度学习神经网络（Deep Learning Neural Network）”一统江湖落下帷幕。该过程腥风血雨，而主角“神经网络”的遭遇更堪比张无忌、杨过，历经少年时的悲惨遭遇，被无数号称时代“大侠”嗤之以鼻，但终究是主角光环加持，加之得外家指点，十年一剑终成大器，号令天下，谁敢不从。</p>
<p>本篇对这里其中的故事，按下不表，有好事者，可以去各处搜搜，剧情精彩不容错过。但是这里还是要感谢，在神经网络经历最寒冬的时候，一众大牛如 Yann LeCun (读作杨雷昆，不是严立春！！)，Geoffrey Hinton等的默默坚守，才有神经网络的今天。不过他们也早已是Facebook / Google的首席科学家，如今功成名就，也是吾等小辈无法企及的高度。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fd367a6d30.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>Yann LeCun,   Geoffrey Hinton</p>
<p>神经网络在人工智能领域，属于机器学习一路的分支。所谓机器学习，就是让电脑经过学习后代替人脑做出判断，理解，甚至决定（还记得赢了李世石的AlphaGo么？）。而所谓深度学习和浅学习的区别在于设计者是否告诉电脑的学习策略。最常见的例子是大家电子邮件系统里的垃圾邮件分类，一般一份邮件是否是垃圾邮件，在于它是否满足一些标准，比如是不是群发的，有没有叫你买东西的广告，是不是图片占有比例很高，然后发信人有没有被举报过等等……这些标准都是一个个特征，如果一种机器学习方法规定了学习的特征与策略，那就是浅学习，如果没有规定，需要算法本身去挖掘策略，那就是深度学习。</p>
<p>所以，深度学习的一大隐忧就是——人类并不知道算法本身究竟在想什么？所以如果哪天他在他负责的算法下隐藏了一个暗算/统治人类的bug，那我们就被彻底奴役了。</p>
<p>不过，所谓“庄生晓梦迷蝴蝶”，人类自己究竟是不是被另外一个物种开发出来的一种新智慧呢？然后，那个物种是不是已经被我们灭绝了呢？我们并没有答案。</p>
<p>码农老师教的生物课</p>
<p>为了弄清这横扫千军的神经网络，首先让我们来上一堂不污的生物课。既然叫神经网络，那起源就是生物脑科学。很久以前，人们发现一个单神经细胞（也叫神经元）包括输入（树突dendrites），激活判断（细胞核nucleus），输出（轴突axon）和与下一个神经元的连接关系（突触synapse）。如果用数学抽象出来过程，就是把一堆输入经过线性组合以后经过一个阈值判断，然后输出给下一级。这样一个简单的神经元就形成。把足够多个神经元连起来就能实现神经网络了。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fd3a83cb17.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>上面两个图就是真实的神经元和它的数学模型。不过我还是要吐槽下：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fd3e86d523.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>从上述神经元的提出，到许多仿生的算法结构的研究，如多层感知器(Multilayer Perceptron) ，脉冲神经元(Spiking Neural)之类的，经过了一个甲子的时间，特别但都没没什么巨大的成功，原因有两个：</p>
<p>（1）当时的集成电路计算规模与资源远没有达到面向实际应用的需求，仔细去研究神经元的数学模型，会发现每个神经元有若干个权重和成累加计算 。他对应汇编可以大致是如下流程：</p>
<p>累加器清零                            (mov)<br>– 循环开始                             (branch)<br>    从存储器中加载权重          (load)<br>    从存储器/外设中加载输入    (load)<br>    权重 乘以 输入                    (multiply)<br>    累加                                    (add)<br>– 判断是否重新循环              (goto)<br>    激活函数                             (??)<br>输出 存储                           (store)<br>对于一个N输入的神经元要走N个循环，这对于上个世纪的单核单线程的CPU，实在是操作难度太复杂。这也就是为什么当流水线与并行处理 不断壮大的近十年，神经网络的发展得到了迅猛发展。</p>
<p>（2）连得不对。这短短四个字，虽说的轻巧，但要找到连连看的窍门，着实花费了多少人的青春？关于怎么连，各位看官先别着急，且听脑芯编下回分解。</p>
<p>作为脑芯编的开篇，今天就到这里，所谓“神风送层云”指的就是集成电路的下一个增长点或许就在在人工智能领域取得巨大成功的神经网络硬件实现上。</p>
<h2 id="〈二〉几重卷积几重生"><a href="#〈二〉几重卷积几重生" class="headerlink" title="〈二〉几重卷积几重生"></a>〈二〉几重卷积几重生</h2><p>蜘蛛结网，是为了捕食昆虫；<br>蜘蛛侠结网，是为了拯救世界；<br>码农Data Scientist (~ds~) 结网，是为了——<br>换一个角度看世界，<br>英语叫做： Representation。<br>如果你只想知道一个关于神经网络的常识，我认为上面这个单词是最不应该错过的。就像每个学模拟电子学的人，其实归根结底就是学了两个字——放大。</p>
<p>话接上回，我们说到，通过一系列乘累加和非线性激活函数，我们就可以实现一个神经元。而关键的问题就是如何把神经元们连起来。解决这个问题之前，我们先要明白神经网络的作用——通过一系列线性和非线性的变化重新将输入信息映射成为表达事物的本质的简化特征。</p>
<p>如果你觉得上面一句的每个字都认识，却不知道他在说什么，那么我们来看一个经典的例子——人类的视觉皮层（Visual Cortex）。</p>
<p>视觉皮层, 一场生物与AI的伟大握手</p>
<p>码农老师的生物课又来了……</p>
<p>你有没有想过当你看到生命中一个重要的人的时候，比如说基友（码农怎么会有妹纸？），你是看到是他/她的鼻子，眼睛，脸上的痘痘，昨晚熬夜的黑眼圈……但是这些东西最后都只留下了一个映像——我面基了。可是你有没有想过从你看到图像，到你得到的结论，无数的信息都已经没有过滤，你的脑子完成了一次将4K3D图像压缩成两个字的过程，到底发生了什么事？</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5851e4d856ce4.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>这个过程就是从信息经过视觉皮层（神经网络？？）的过程。从前到后，他经过了几站：</p>
<p>（1）始发站——视网膜 ，比较像是一个电子系统的传感器，用来接收信号；</p>
<p>（2）快速交流道——LGN，他是将左右眼看到的信号重新编码后传递给视觉皮层，像是一个电子系统中的主控处理器与总线（请原谅我不说LGN的中文，因为说了你也记 不住） ；</p>
<p>（3）第一站——主视觉区V1，第一层神经网络，司“边界检测（Edge Detection）”一职，这可能是神经元数量最丰富的一个区域；</p>
<p>（4）第二站——次视觉区V2，第二层神经网络，司“基础特征提取”一职，归纳视觉信号的形状、大小、颜色、频率……</p>
<p>（5）第三站—— V3，司“位置“，也是个过渡区，一条线上你有些站你不知道为什么会停~</p>
<p>（6）第四站——V4/V5（MT）分支，深度神经网络，各司“色彩/运动”；</p>
<p>（6）V4分支终点站1——换乘inferotemporal Cortex，近深度智能TE区，司 ”目标识别“ <del>~终于终于我认出基友来了，撒花</del></p>
<p>（7）V5分支终点站2——换乘Parietal Cortex, 进深度智能MST区，司“空间运动分析”。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5851e5045817e.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>视觉皮层可能是目前为止人类认识的最透彻的大脑部分，不过，好像建立在无数的活体实验上。。。即使如此，还是有很多未知的空间亟待生物学家探索。</p>
<p>不知道读到这里，对人工智能略有了解的你有没有觉得这堂生物课在哪里见过？ 先做边界检测，在再做特征提取，在进行分类识别，这不就是大名鼎鼎的</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5851e53c8e71c.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>卷积，让加速成为一种可能</p>
<p>其实在神经网络领域里，目前为止唯一能算的上前所未有成功的就是CNN （Convolution Neural Network，卷积神经网络）。最早的CNN可以追溯到98年Yann LeCun的一篇如何识别手写数字的paper，这里出现了第一个CNN的雏形LeNet：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5851e5579eda1.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>从结构上来，CNN继承了视觉皮层中对信号处理“层”的概念，虽然不是那么的100%的吻合，但是CNN的初级层往往用来做“边界检测”这样的简单的特征提取，而在深度层重新组合初级层的信息成为抽象的再表达（Representation）,最后交给事件的发生的相关概率归纳出事物的本质。</p>
<p>另外，一个比较不太准确的趋势是神经元的数量随层的深度逐渐减少，但是单个神经元的粗壮程度（输入数量）随层的深度逐渐增加。视觉皮层也具有相似的规律，V1的数量多，但是结构比较简单，但到了V4/V5，链接变得很复杂，但占的区域却比V1小的多。</p>
<p>然而，这些都不是做电路的人重点。</p>
<p>对于硅工们而言，CNN获得巨大成功的原因在于：它极大地节省了神经网络的硬件开销，使神经元为单位作加速器成为了可能。</p>
<p>（1） CNN定义了一种更高能效的元操作——卷积核</p>
<p>关于卷积是什么，大家可以去参考一篇《一文读懂卷积神经网络》（广泛地转载于各大公众号间），下图是我目前看到的最形象的卷积描述。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5851e607733af.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>该图片源自网络，感谢原gif作者</p>
<p>其本质就是对于一个区块，判断和自己系数组成的“基”区块的相似程度，得到的分数越高就越相似。这样，当一种“基区块”被赋予一种特征是，即使用于整张图片的特征提取，他的系数也是固定的，因此大量的系数加载操作可以被省略。同时，一个固定大小的“卷积核”成为了比“乘累加”更高阶、更高效的原子操作，在现代计算机体系结构中，实现越复杂，但操作越固定的加速器，其效率和速度的提升也就越大。</p>
<p>（2） Pooling —— 是垃圾就要扔掉</p>
<p>CNN网络的另一个巨大贡献就是在卷积层和层之间，设置了一个”垃圾箱“，把上一层产生的无效信息都扔掉，避免了超大规模的数据传输和存储。大家把这叫做Pooling，我又要来吐槽那个中国人给他取了个”池化“的名字，虽然我也找不到更好的名字，但根本无法帮助理解。Pooling的策略很多，最常见的是max pooling就是留个最大的，然后又其他都扔掉。</p>
<p>（3） “乱撸”？ (ReLU)</p>
<p>LeNet后期发展到AlexNet后，激活函数也从sigmoid变成了ReLu，他们的图形曲线大概如下所示。用脚趾头也知道，Relu操作的实现就是把符号位为负置0就好了。至于sigmoid么，传承自经典机器学习回归理论，是e指数的除法操作，编译后简直就是一场噩梦，我们先把他当作一个古老的神话就好了。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5851e64598d02.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>以上种种硬件实现的简化，加上CNN的巨大胜利，都当让硅工们看到了直接从电路角度优化的角度切入人工智能芯片的可能。但是，也发现了一个问题，传统的硬件加速的算法往往是做死的，比如椭圆加密，浮点乘除等等。但是CNN的元操作——卷积核——虽然模式固定，但是其每一层的卷积核数量和层数却是纷繁复杂，固定的硬件并不能实现网络的可塑性（structual plasticity）？</p>
<p>那该怎么办？下一次，如何利用具有高度可编程性的CPU来配置不同结构的神经网络——计算机的”形与令“。就到这里，且听下回分解。</p>
<h2 id="〈三〉梦里不问形与令"><a href="#〈三〉梦里不问形与令" class="headerlink" title="〈三〉梦里不问形与令"></a>〈三〉梦里不问形与令</h2><p>世界上有两种管家：</p>
<p>一种是Batman的Alfred<br>能服务能做饭能伪装能打架<br>狠起来超人也不是干不过<br>另一种是天朝的大内总管<br>掌印秉笔，啥事不会<br>老大又吩咐了就去传个话<br>你脑子里的CPU是哪一种？</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fc646c2275.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>有了神经元，知道了怎么把神经元连成网络，这个系列终于进入了主题——怎么实现神经网络。如果在这个问题上加一个条件，那就是“怎样用芯片实现神经网络的计算”？</p>
<p>在回答这个问题以前，让我们先去拜访两位长者——Alan Turing和John Von Neumann，目前大家公认的计算机之父。话说前者才是真的“苟利国家生死以，岂因祸福避趋之”，详见卷福主演的奥斯卡获奖电影《模仿游戏》。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fc6a0193ea.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>Turing-Von-Neumann架构</p>
<p>为了表达对大师的尊敬，我起了个很干脆的标题。大师之所以是大师，是因为他们定义了在80年前定义了通用计算机的数学模型和体系结构。在这过去的80年里，任何试图推翻这些结构的“投机”分子几乎都没什么好下场。但是，总有人希望推翻这个架构。先简单的描述下两位长者干了什么。</p>
<p>Alan Turing在1936年提出了一种具有普适性的逻辑计算模型，证明通过有限状态机完成输入数据的操作，可以实现任意复杂的逻辑运算。图灵机本身描述的场景在现在看来已经没什么意义，但是他第一次完整的定义普适计算机体系机构——一卷很长很长的带子（infinite lengthtape）通过一个有磁头(head)的有限状态表(finite state table)进行读取/处理/改写的机器。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fc6c9758fe.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>9年后，Von Neumann把带子改叫做“Memory”，状态表叫做“CPU”，磁头改叫做“Connection (Bus) ”，换了一副图，就有了史称“冯诺依曼架构”的现代计算机体系结构。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fc6e6f2767.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>教科书上会说这个结构有啥特点，这是让你背的。其实很简单，图灵-冯诺依曼架构最大的特点是把计算任务分为了2个部分——数据存储(memory)和数据处理(processor)。处理器几乎不能存数据，存储器几乎不能算数据。两部分用一种连接方式(bus)按一定规则通信。泾渭分明的特点让冯诺依曼架构处理事情起来特别有条理，就像“男主外女主内”的家庭角色分配一样，在硬件资源极度受限的情况下，成为了自动化发展的中坚力量。</p>
<p>冯诺依曼架构有一个升级版，叫做哈佛(Harvard)架构，把存储空间分为了指令(instruction)存储和数据存储，对应不一样的操作。目前的主流嵌入式微处理器基本采用这个架构，但Anyway这并不重要。</p>
<p>冯诺依曼架构在过去的60年称霸人间，如果这项专利申请成功的话，这一定是史上最赚钱的专利。可是，冯诺依曼架构在经历了各种法院撕逼后，被判定为一项没有收益人的专利……（Youyou Tu和青蒿素在这面前简直不值一提）</p>
<p>成也萧何 - x86的不可一世</p>
<p>虽然冯老爷子在自己的架构下发明了人类第一台计算机，ENIAC和EDVAC，但诺依曼的真正崛起还是要归功于x86。如果你不知道80x86是什么，那只能说明我们已经有代沟了，嗯，很深深的代沟。</p>
<p>Intel自1978年推出8086后，x86体系架构就一直是电脑（上到服务器，下到平板电脑）核心处理芯片的不二选择。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fc723e9c30.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>Intel x86 i7 版图</p>
<p>顺便做个普及，在冯诺依曼架构下，每个处理器会干的事情是有限制的，通常这个限制叫做指令集。它规定CPU的基本操作，没有指令集(instruction set)定义的复杂操作可以通过基本操作的组合来完成，比如指令集里没有乘法，那我们可以通过一定数量的加法来完成。</p>
<p>在冯老爷子的机构里，谁的指令集越大，可以访问的存储空间越大，谁就越牛逼。x86的指令集从8086到i7不断扩张与膨胀，最终成为了一个会算双精单精、矢量图像，多核多线程多Cache的巨无霸。简单的说，到2013年的时候，史上最强core已经无所不能了。可是历史不断在重演一幕就是，当绝顶高手号称要独孤求败的时候，不知道哪里窜出来的毛小伙子可能一个起手式就把你撂倒了。圣经里大卫王这么干掉了Goliath，《倚天屠龙记》里，张无忌这么称霸了光明顶。</p>
<p>那谁是x86的张无忌呢？</p>
<p>移动设备，RISC的春天</p>
<p>独孤求败的x86其实有个致命的缺陷——能效，通俗地说就是“做一次”要花费的能量。可是每块肌肉都很发达的muscleman总是要比一般人多吃几碗饭吧。我们现在能买到的i7即使在省电模式也要消费超过47W的功耗。本身47W不算什么，但是苹果乔大叔的出现，让47W一下子很麻烦。</p>
<p>Iphone/Ipad和一系列手持的充电设备对瓦级以上的功耗是非常敏感的！x86的功耗导致它“充电2小时使用5分钟”的悲惨结局。肌肉男瘦身变成筋肉男的必然的命运。</p>
<p>这时，x86，或者说是intel的张无忌出现了—ARM Cortex RISC. 所谓RSIC就是精简指令集（Reduced Instruction Set），他能干的事情很有限，但是他的功耗低。X86在其巅峰时期无数次地战胜过RISC，以至于ARM出现时并有没足够重视他，那时候Intel还在和AMD抢64位x86的主导权呢。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/584fc75dae36b.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>为什么无数次败下阵来的RISC可以最终成功呢？因为这次，他寻找到了一个partner——加速器。在移动端的应用设备里，其实也有很对需要强大计算消耗的进程，这是RISC本身无法胜任的。但是，实际应用上，往往这些进程是有固定的模式和使用场景的。比如手机在通话时的语音编解码，拍照时的图像处理（俗称“美颜”）和无线通信是的编解码。对于这样一个经常重复，且模式固定的高通量计算，可以在总线上加入一个专用模块（ASIC）加速，在处理专用任务是ASIC的能效又比通用处理器高很多。下图就是ARM有名的产品之一A9，除了CPU外，它的浮点与超标量计算（NEON）都被移到了CPU外（一般来说，这不能算作加速器）</p>
<p>这就是开头的那个故事，你每天充的电不够“超人”吃的，与只能换个块头小，但是能够指挥其他人的总管</p>
<p>败也萧何 – 冯诺依曼瓶颈</p>
<p>“泾渭分明，靠总线连”的冯诺依曼架构带来了单核/少核时代计算机的春天，但冯诺依曼架构的致命缺陷——冯诺依曼瓶颈——也悄悄地增长。随着摩尔定律的发展，远距离的搬移大规模数据早已取代了计算本身，成为制约高效计算的重要瓶颈，对于x86结构，有太多指令可以直接穿过总线访问存储空间。</p>
<p>在RISC+加速器的体系结构里，总线作为“总管”和“内务府”、“上书房”、“御膳房”间的桥梁，更是好不吃紧。当瓶颈出现在通信上时，冯诺依曼架构就体现出了它垂垂老矣的一面。</p>
<p>这个问题，在实时处理的人工智能场景下显得格外突出，信号从入到出，都是按照是数据流(Data flow)的传输模式一帧一帧地来。这一特征在类脑的神经网络实现中就更加明显。如果每一个卷积的系数都要去云深不知处的存储海洋里去寻找，那神经元的处理效率会非常低。简单地说：</p>
<p>谁脑子TM的是一半纯记忆一半纯分析的呢？</p>
<p>脑子么，都是左右开工的。边走边忘，雁过留痕，却也是旧相识，恢复不出来一个一毛一样的。</p>
<p>所以，摆在类脑芯面前的路有三条：</p>
<p>（1）  采用冯诺依曼经典架构，把神经元计算写在指令集里，反正是超人，技多不压身；</p>
<p>（2）  采用RISC+神经元/神经网络加速器，给“总管”再开个府呗；</p>
<p>（3）  放弃冯诺依曼架构，完全分布式硬件，像“数据流“一样的风骚走位。</p>
<p>这三个选项都有不错的代表，我们慢慢来。</p>
<p>梦里不问形与令，你知道计算机形（体系结构）和令（指令集）了么？</p>
<h2 id="如何对神经网络人工智能硬件进行优化设计？"><a href="#如何对神经网络人工智能硬件进行优化设计？" class="headerlink" title="如何对神经网络人工智能硬件进行优化设计？"></a>如何对神经网络人工智能硬件进行优化设计？</h2><p>有三种方式，可以在传统体系结构的基础上面向神经网络人工智能硬件进行优化设计。</p>
<p>本文为《脑芯编：窥脑究竟，织网造芯》系列第四篇。</p>
<p>写这篇的时候想到哥哥的《我》，因为这次的主角就是，那个特里独行的我：</p>
<p>我就是我，是长度不一样的开拓<br>天空海阔，要讨最并行的生活<br>我喜欢我，让矢量算出一种结果<br>简单的指令集，一样加速的很妥妥<br>他的名字，叫做<br>SIMD<br>Single Instruction Multiple Data<br>话接上回《窥脑究竟，结网造芯（三）》我们说到，有三种方式，可以在传统体系结构的基础上面向神经网络人工智能硬件进行优化设计。这次，我们先来提第一种——在简单指令集（RISC）中增加指令的方式来达到性能的优化。我们将着重介绍如何加速卷积核的计算（忘了（一）和（二）？点这里！）</p>
<p>这次的故事，要从并行计算机体系结构讲起。说到并行计算机体系结构，就要掉一个书袋——</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a0cb9a28b.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>我从上的第一门计算机体系结构课，到并行提算计体系机构，到高级计算机体系结构都在用这一本书。不得不感谢作者让我少买了好多教科书钱。当然，牛x书的作者也很牛x，这里就不八卦了。有人愿意把这本书叫做计算机体系结构的bible，我不评论，但是下面我们所讲的，好多都出自这本书。</p>
<p>言归正传，这个特立独行的故事从这里开先，我们要认识一个老爷爷（还活着好像），他叫Michael Flynn。老人家生于大萧条时代的扭腰城，一不小心提出了一个分类法，叫做Flynn Taxonomy（1966）。然后计算机体系机构就被Flynn taxonomy的五指山给压几十年。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a1ad71993.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>Flynn Taxonomy的五指山把计算机结构分为两个部分：指令与数据。在时间轴上指令与数据可以单步执行或多次运行进行分类，即单指令单数据（SISD），单指令多数据（SIMD），多指令单数据（MISD）和多指令多数据（MIMD）。</p>
<p>并行，从Pipeline到SIMD</p>
<p>Flynn taxonomy给并行计算机体系结构指了两条明路——指令级并行和数据级并行。</p>
<p>首先来看下指令与数据的关系。指令是处理器单步可以实现的操作的集合。指令集里的每一条指令，都包含两个部分：（1）什么操作；（2）对什么数据进行操作。专业地，我们把前者叫做opcode，后者叫做operand（也就是数据）。当然，并不是所有的命令都有数据操作。传统定义的指令集里面，对应的operand不超过2。比如，加减乘除都是典型的二元操作。数据读写就是一元的，还有些就是没有任何数据的操作，比如一个条件判断（if）发生了，根据判断结果程序何去何从，只是一个jump操作，他并不需要任何数据输入。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a1fcea2a3.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>指令级并行的第一种、也是最经典的办法叫做时间上并行，这是所有的体系结构教科书最喜欢教的流水线架构（pipeline）。简而言之，在发明流水线以前，处理器里面只有一个老司机，什么事情都得他来干，但是下一条指令得等老司机干完上一个~但是，流水线就是把一个老死机变成了三个臭皮匠，每个人干三分之一就给下一个，这样下一条指令只需在上一条被干完1/3后就可以进来了。虽然老司机体力好，但赶不上年轻的臭皮匠干的快啊。这样，流水线可以实现时间上的指令集并行，成倍提高实际指令的处理效率。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a22c2f924.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>经典MIPS-5 级流水线</p>
<p>有一就有二，有时间当然就有空间。所以，第二种办法是空间上的并行。空间并行基于一个观察——对数据的操作有很多种——加减乘除移位、整数操作、浮点操作……每一个模块的处理（ALU/EXU）是独立的，所以，就空间上，一个浮点加法在处理的时候，完全可以同时进行一个整数移位操作，像老顽童教小龙女的左右互搏分心二用。所以，在计算机体系的历史上，练成“左右互博”术的处理器包括超标量（Superscalar）/超长指令(Very Long Instruction Word, VLIW)处理器。具体我们先不展开。</p>
<p>相比于流水线／超标量复杂的修炼过程（黄蓉都练不会“左右互博”），数据级并行就是简单纯粹的叠加硬件，打造并行处理的“千手观音”：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a25c458be.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>“千手观音”的学名叫做SIMD，Single Instruction Multiple Data，单指令多数据（流）处理器。其实，说白了就是原来有处理单元（ALU/EXU）现在一个加法器，现在变成了N个了。对应神经网络的计算，原来要M次展开的乘累加，现在只要M/N次，对应的时钟和时间都显著地降低。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a28b3f7c4.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>简单粗暴的并行，不仅提高了让每个指令的数据吞吐率，还让本身单一的标量处理进化成阵列式的“矢量型”处理，于是就有SIMD又有了“矢量处理”指令的称呼。其实，SIMD并不是到了神经网络再兴起的新玩样儿，早在MP3的年代，SIMD处理器就广泛地使用在各类信号处理芯片中。所以关于SIMD指令也早有了需要行业标准。以下，我们就来看一个SIMD指令集实例——</p>
<p>ARM NEON，厉害了word令</p>
<p>在上一编中，我们简单提到了史上第一个攻城掠地的RISC-ARM。为手机、平板等便携式的最重要处理器，ARM的SIMD指令也是王者风范，从它的名字开始——NEON。</p>
<p>NEON的指令的操作的输入（operand）是一组128位位宽的寄存器，但这个寄存器存着的几个数，就由码农自己去预定义了，可以是4个32位的浮点，或者定点，或者8个16位定点，或者16个8位定点……整个指令集宽泛地定义了输入、输出的位宽，供变成者自由支配，考虑到在神经网络中，前馈网络往往只要16位、8位整数位宽，所以最高效的NEON命令可以一次实现16个乘累加计算（16个Synapse）。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a2b1e3ab0.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>仅仅是SIMD怎能彰显NEON的侠者风范？ NEON还充分应用了指令级并行，采用10级流水线（4级decode+6级运算单元）,可以简单地理解为把卷积计算的吞吐率由提高了10倍。加起来，相比与传统的单指令5级流水，提高至少32倍的效率。再辅以ARM Cortex A7以上的超标量核心处理单元,筑起了第一条通用并行计算的快车道。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a2c45e2f6.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>当神经网络遇上SIMD，滑起吧！</p>
<p>流水线和SIMD都是在神经网络还没羽翼丰满的时候就已经称霸江湖的大侠。在神经网络不可一世的今天，这两者还是固步自封么？答案显然是否定的。</p>
<p>当通用SIMD处理器遇上神经网络，他们既碰撞出了火花，也开始相互埋怨。我们先说埋怨——存储空间管理。我们知道，在NN中通常每个卷积核都需要先load系数与输入数据，再算出部分的乘累加结果，再store回存储空间。而指令执行与存储空间的通信就是我们上一编讲到的——冯诺伊曼瓶颈。对于神经网络来说，如此多次的存储读写是制约性能的关键。减少数据的载入与中间结果是面向神经网络的SIMD指令的主要问题。</p>
<p>那火花是什么？</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857a32026751.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>这就给SIMD带来了一个面向神经网络的新机遇——部分更新与数据滑行（sliding）。我们来看下面这张动图「原作为MIT Eyeriss项目研究组」。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5857b487c9ddd.gif" alt=""></p>
<p>对于一个采用SIMD的卷积核，有一组输入是固定——系数矢量，而另一组输入像一个FIFO，在起始填满后，每次注入一个单元（也排出一个单元）进行乘雷佳，另外上一次累加的结果在保存在执行单元的寄存器内，只有最终的卷积核结果会写回到存储器中。</p>
<p>这样，在神经网络中，无论是数据导入、还是结果输出，起对存储空间的访问都会大大降低。当然，上述示意图仅仅是一维的。当卷积核的维度达到二三维时，情况会复杂很多。这里推荐大家可以去读读MIT的Eyeriss，Kaist的MIMD，或者IMEC的2D-SIMD（ENVISION）。这里就不太多展开了。</p>
<p>好了，这次就到这里。所谓“烛台簇华照单影”就是那一粒粒自由定义的小数据，在同一声SIMD的指令下，排成队，集成行，成为了一个孤独的矢量运算。</p>
<h2 id="脑芯编：分手？摆脱冯诺依曼的深度学习硬件"><a href="#脑芯编：分手？摆脱冯诺依曼的深度学习硬件" class="headerlink" title="脑芯编：分手？摆脱冯诺依曼的深度学习硬件"></a>脑芯编：分手？摆脱冯诺依曼的深度学习硬件</h2><p>本文作者：矽说    2017-01-21 12:26</p>
<p>导语：“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。很多人把TrueNorth看作深度学习硬件发展史上打得最响的水花。</p>
<p>雷锋网(公众号：雷锋网)按：本文作者痴笑，矽说（微信号：silicon_talks）主笔。本文为《脑芯编：窥脑究竟，织网造芯》系列第五篇。</p>
<p>不知不觉，《脑芯编》已经走过了上半阙。默默挥手告别那些弃剧的看官，也由衷感谢仍然愿意用手指点进来的您。你们是撑住脑芯编不烂尾的重要力量，与其肉麻，不如再念一遍诗的上半阙：</p>
<p>昨夜神风送层云，（神经元与网络）</p>
<p>几重卷积几重生。（卷积神经网络）</p>
<p>梦里不知形与令，（计算体系结构）</p>
<p>烛台簇华照单影。（单指令多数据）</p>
<p>上次我们讲到，现行的计算机体系结构——“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。其计算和存储分离的特点，使得神经元计算的效率低下。合理改变指令集，加入乘累加指令和SIMD（单指令多数据）指令可以缓解该问题，但仍然指标不治本。</p>
<p>此时，革“冯诺依曼”的命变成了很多懵逼骚年（讲的是心态，年纪可是很大哦）的选项。非冯架构的深度学习硬件一时间成为了洛阳纸贵的一时之选。这个过程自然有资本主义的糖衣炮弹加持，美国国防部先进项目研究局（传说中的DARPA，可以理解为神盾局？）便在非冯架构上与世界顶级研究机构——IBM合作，搞了个叫SyNAPSE （System of Neuromophic Adaptive Plastic Scalable Electronics，其实synapse在字面上也“突触”的拼法）的项目。从第一阶段到最终，DARPA赞助了IBM 4千2百万刀，打响了深度学习抗冯的第一枪——TrueNorth（真北）。</p>
<p>当然，很多人也把TrueNorth看作深度学习硬件发展史上打得最响的水花。</p>
<p>Neuromophic，替天行道？</p>
<p>任何革命都要师出有名，就算水泊梁山也有个“替天行道”的名头。那真北的“名”在哪里呢？很简单，我们要造一个真“大脑”，而不是计算机这样给冯老爷子当傀儡的“伪电脑”。英语叫做Neuromophic，神经形态的硬件。于是就有了这张图：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882df0757279.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>真北的设计理念，以人脑为起蓝本，依葫芦画瓢，不带点儿差的。</p>
<p>IBM的工程狮从微观到宏观，将人的大脑分成三个层次——神经核团、脑功能区和脑皮层。每个核团由很多个神经元组成，每个功能区由很多核团组成，一个能完整地进行一项任务的皮层由很多个功能区组成。（是不是好久没有上过码农老师的生物课了，有没有点怀念呢？下面还有。）</p>
<p>对应的，真北架构下，也分为这三个层次。先做了一个核团对应的硬件——neurosynaptic core，每个core由256个输出与输入、以及对应的系数存储，并集成了神经信号的路由器（router）使得信号可以在长距离上游走；在此基础上，一块芯片有64乘64个这样的核团，共4096个，组成了一个“功能区”。而很多完整的应用和复杂的任务，还需要芯片与芯片间的互联，实现一个完整的皮层功能。看，这才是真正的神经形态的“电脑”。</p>
<p>TrueNorth还追求了一个大脑的特点，没有全局时钟控制的信号传递。真北只有帧时钟（1KHz，和intel的3.6GHz比慢了几百万倍哦~），并没有控制信号流的时钟，数据和数据之间采用异步的方式进行通讯，寻求高能效和低功耗。</p>
<p>这里留给读者一个问题：为什么是非冯呢？（提示：memory在哪里？）如果各位看官到这里眼皮还没有搭起来，可以考虑去读读TrueNorth的Science原著，保证一夜睡到天明。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882df534880c.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>SpikeNN，致命缺陷？</p>
<p>如果有一件事情，可以把昏昏欲睡的人们从周公的世界里拉回来，那一定是——撕逼。</p>
<p>当所有人都觉得TrueNorth要改变人类的时候，惊天一声雷从华山之巅劈下来。出手的，是在神经网络中有“东邪西毒南帝北丐”之称呼的Yann LeCun。（我们在脑芯编（一）中提到过他。）</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882e0a993ecf.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>深度学习的“东邪西毒南帝北丐”F4</p>
<p>Yann大人在Facebook上发了一篇长长的博客来表达自己对True North的不屑。这里节录部分。（冬天了，小编最近比较懒，所以靠复制黏贴凑字数）</p>
<p>Now, what wrong with TrueNorth? My main criticism is that TrueNorth implements networks of integrate-and-fire spiking neurons. This type of neural net that has never been shown to yield accuracy anywhere close to state of the art on any task of interest (like, say recognizing objects from the ImageNet dataset).<br>简单的说，问题出在Spiking Neural Networks。Spiking的中文可以叫做脉冲，用现代的生物医学技术发现，spike是人脑中信息传递的真实电学过程。下图就是人脑中一个神经元附近测到spike信号：</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882e0d5ba7f7.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>医学上，也叫这个信号为细胞膜动作电位（Action Potential）。事事以脑科学为准绳的TrueNorth，自然在这基础理论上一定是向生物学看齐的。可是，问题便在于，在神经网络被提出来的前几十年，就是这spike NN的英魂不散，才导致了其早期“食之无味，弃之可惜”的尴尬地位。</p>
<p>就像那个最有名的比喻：因为鸟的翅膀，让人类渴望飞翔；但放弃对翅膀的模仿，才让飞机真正飞上蓝天。很多事物只能赐予灵感，却无法100%照搬，否则下场就是那些个鸟人。（这话也不是我这种小辈敢说的，同样来自Yann大人）</p>
<p>Memristor，吴下阿蒙?</p>
<p>一方面，如果spike完成神经信号的传递与运算真的有问题，那人类为什么聪明？ 另一方面，如果SpikeNN真的100%模仿了我们的脑子，为什么连个ImageNet分类都分不清楚？一定是哪里出了问题。答案是后者。</p>
<p>首先，在我们通常使用的神经网络里面有个假设——系数（Weight）在训练完成后是固定，不改变的。这个假设在CNN/RNN等一系列架构中显得天下太平，因为系数位宽大么。但是到了SpikeNN就是个大麻烦，所有的信号是二进制的，所谓的系数只改变链接关系、延时，不改变幅度，自由度大大衰减。那我们的脑子真的是这样的么？</p>
<p>唉，生物课又来了。</p>
<p>虽然我们的大脑的神经元看上去是二元的，但是神经元通路还有一个可塑性维度，叫STDP （Spike Timing Dependent Plasticity），就是突触的连接强度（Plasticity，可塑性）收到输入输出脉冲（Spikie）间的时间先后（Time Dependent）关系，其本质核心如下图。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882e0fb15171.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>如果输入将将早于输出，代表输入输出间是完美的因果关系，神经元联系会被增强；如果输入的脉冲稍晚于输出，那么他们之间是果因关系，神经元的联系应该要减弱。STDP被认为是我们大脑的主要学习机制，而且在不同动物上都经过了实验验证。</p>
<p>问题来了，这种学习机制和CS里面主流的学习机制——Stochastic Gradient Descent (SGD，中文叫做随机梯度最速下降？) 的后馈算法有着天壤之别。小编觉得这也是目前神经网络算法与神经科学的最大分歧。</p>
<p>没有STDP的真北就这样陷入了SpikeNN的坑。但话说回来，STDP这么高级的操作模型，用传统模数混合集成电路实现是非常浪费面积，且不划算的。好巧不巧，人类突然造出了一个除了电阻电容电感之外的第四类电学器件——Memristor，忆阻器。仿佛是上帝要有光，就有一缕阳光照进SpikeNN的黑暗的胡同里。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882e111dc984.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>对于一个电阻，两端的电压和电流成正比，对于一个电容，两段的电荷和电压正比，对于一个电感，两端的磁通量和电流正比，对于一个忆阻器，就应该是两端的磁通量和电荷成正比。虽然很抽象，但是忆阻器的实际效果就是其电阻（导通强度）受流过的电流调制。这个效果已经非常接近STDP了。</p>
<p>试想，连在忆阻器两端的突触，当设定为上一层的神经元先发生spike，而下一层后发生spike，那一个正向的电路流过忆阻器，减小忆阻器阻值，加强链接。反之，负向电流流过忆阻器，增大阻值，减缓链接。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882e12495542.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>于是，大家逐渐开始相信，在真北架构上如果能用可随摩尔定律减小的微纳尺寸忆阻器，或许才是Brain Inspired Computer真正焕发春天时候。</p>
<p>于是，兼容先进集成电路的高性能忆阻器就成了问题的关键。但是，作为memristor的发明者和最努力的推广者——HP，最近好像有点无奈。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201701/5882e13881167.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>但是也不要太灰心，最近intel和micron联合推得风声水起的3D Xpoint Memory被认为是某种程度的RRAM/memristor。究竟忆阻器是吴下阿蒙，还是未来的江左梅郎，还在未定之天呢。</p>
<p>这一期可能是脑心编目前为止最为干货满满的一期，牵涉好多paper，如果看官您的目光移驾到这里，小编我也是要这厢有礼的，不容易啊。</p>
<p>”真北路上初相见“，告诉你采用非冯架构的IBM TrueNorth（真北）的出生、虐缘和不明亮也不灰暗的未来。下一次，我们要来讲讲以GPU为代表的协处理器深度学习架构——“一见泰坦误终身”。</p>
<p>特别鸣谢复旦大学脑芯片研究中心提供技术咨询，欢迎有志青年报考。</p>
<p>雷锋网版权文章，未经授权禁止转载。详情见转载须知。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.leiphone.com/news/201612/E4eY2HYElJIC0be5.html&quot;&gt;雷锋网：本文作者痴笑，矽说（微信号：silicon_talks）主笔。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;你信不信有一天，硅工造的芯片会写诗？&lt;/p&gt;
&lt;p&gt;如果信，&lt;br&gt;那说好的“诗三百，一言以蔽之，思无邪”，&lt;br&gt;还真的是“无邪”么？&lt;br&gt;如果不信，请读下面这一首：&lt;br&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201612/584fd23f4a433.png?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;br&gt;脑芯编：窥脑究竟，织网造芯（一）&lt;/p&gt;
&lt;p&gt;如果要给这诗一个赏析，大概可以是一个忧伤的故事。&lt;/p&gt;
&lt;p&gt;天边云的变换复杂，而我却是半梦半醒，我在想一个人，想第一次和他相见，想他的风流倜傥，想他的英雄飒爽。&lt;br&gt;如果你是个文科生，或许你会嘲笑这首连平仄都不满足的劣质诗歌，韵脚也押的有些蹩脚，故事更是为赋新词强说愁。&lt;/p&gt;
&lt;p&gt;如果你是理科男，或许对这种思春的小情怀不以为然。&lt;/p&gt;
&lt;p&gt;不过，那是因为你们并没有看懂这首诗。&lt;/p&gt;
&lt;p&gt;因为这诗暗藏了一个密码，藏着人工智能遇到摩尔定律后蹭出的火花。&lt;/p&gt;
&lt;p&gt;另外，这诗不是人工智能的产物，只是矽说在这个人工智能横行的年代里特有的小情怀。&lt;/p&gt;
&lt;p&gt;但可能在不远的将来，人工智能将会开车，会翻译，会调情，也会写下更美的篇章。想解开这个人工智能与集成电路的秘密？关注雷锋网(公众号：雷锋网)后期更新，我们一句一句地读下去。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Google RAISR技术落地应用 可节约75%流量</title>
    <link href="http://ipcreator.me/2017/02/13/BusinessAI/google-raisr/"/>
    <id>http://ipcreator.me/2017/02/13/BusinessAI/google-raisr/</id>
    <published>2017-02-13T06:30:06.000Z</published>
    <updated>2017-02-16T00:59:05.703Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dy.163.com/v2/article/detail/CB0RI9DI0511CUKV.html" target="_blank" rel="external">作者：网易AI研究院</a></p>
<p><img src="http://dingyue.nosdn.127.net/UaNmJZxUHa7whiaTEF=QBFNOYzjbosm=TAWB5N0XSsBgL1484657007496compressflag.jpg" alt=""></p>
<p>谷歌在11月推出了一项新技术 <strong>RAISR，全称为“Rapid and Accurate Image Super-Resolution”，意即“快速、精确的超解析度技术”。RAISR利用机器学习将低分辨率图像转化为高分辨率图像。</strong></p>
<p>RAISR首先制作较小版本的图像，使用传统方法将至拉伸，然后将拉伸后的模糊图像同原本的高分辨率图像进行对比。算法习得两者之间的差异，这允许它在保留图像的底层结构之上构建信息。</p>
  <a id="more"></a>
<p>　　<br><img src="http://dingyue.nosdn.127.net/2eh4=xQBPAVvF1uXWULTEkEqtX4u95Qj0b3vlYGD=21sW1484656062276compressflag.jpg" alt=""><br>　　（谷歌RAISR流程图）</p>
<p>　　谷歌已经在自家社交平台Google+上应用RAISR技术。RAISR也能够在手机上工作，帮助用户在传输信息时节省数据流量。</p>
<p>　　<img src="http://dingyue.nosdn.127.net/Nk0eYXSjonmnNBhQa=2idbk0b1B2xjsHJKMGLeqhsYy=Y1484656728761compressflag.jpg" alt=""></p>
<p>　　使用RAISR之后，Google +能够节省高达75%的网络带宽。<strong>通过网络传送低分辨率的图像，图像在接受之后又能恢复高清。</strong> 相当于只有1/4的文件体积需要网络传输。</p>
<p>　　<img src="http://dingyue.nosdn.127.net/g9IB3ACM8QRbvYT5OtFP3d2F92odJlLY4fdduRwNkQHoC1484656062276compressflag.png" alt=""></p>
<p>　　图像的传输对网络带宽具有很高的要求，在网络连接昂贵或连接状态不稳定的情况下尤其如此。在这种情况下通过网络加载图像是让人头痛的事，很多人甚至选择关闭图像，纯文本浏览网页。如今RAISR技术可以大幅度减少图像传输对网络带宽的需求。</p>
<p>　　<img src="http://dingyue.nosdn.127.net/Md9DvmpaSJztuPyhkNEwkBkUzI8YlLJo19kuYBCc3ZuYF1484656062276compressflag.jpg" alt=""></p>
<p>　　该功能正被逐步推广到安卓用户中去。从用户的角度来看，RAISR的整个运行过程几乎难以察觉，无形地帮用户节约流量。现在每周有十亿张图像经过RAISR处理，为用户减少了1/3的网络消耗。谷歌计划在未来更广泛地推广这项技术，并表示将进一步努力减少图像传输所需的时间和带宽要求。</p>
<p>　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dy.163.com/v2/article/detail/CB0RI9DI0511CUKV.html&quot;&gt;作者：网易AI研究院&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://dingyue.nosdn.127.net/UaNmJZxUHa7whiaTEF=QBFNOYzjbosm=TAWB5N0XSsBgL1484657007496compressflag.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;谷歌在11月推出了一项新技术 &lt;strong&gt;RAISR，全称为“Rapid and Accurate Image Super-Resolution”，意即“快速、精确的超解析度技术”。RAISR利用机器学习将低分辨率图像转化为高分辨率图像。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RAISR首先制作较小版本的图像，使用传统方法将至拉伸，然后将拉伸后的模糊图像同原本的高分辨率图像进行对比。算法习得两者之间的差异，这允许它在保留图像的底层结构之上构建信息。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Google" scheme="http://ipcreator.me/tags/Google/"/>
    
  </entry>
  
  <entry>
    <title>大数据深度学习下车辆厂牌型号识别</title>
    <link href="http://ipcreator.me/2017/02/13/BusinessAI/recognize-license-number-of-car/"/>
    <id>http://ipcreator.me/2017/02/13/BusinessAI/recognize-license-number-of-car/</id>
    <published>2017-02-13T06:30:01.000Z</published>
    <updated>2017-02-16T11:48:51.139Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.36dsj.com/archives/24575" target="_blank" rel="external">36大数据 数控小V</a></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/170.jpg" alt=""></p>
<p>2015年3月，北京文安公司发布了基于大数据下深度学习的机动车厂牌型号识别技术。</p>
<p>车辆身份识别系统是智能交通的重要分支，它需要人工智能、图像处理、计算机视觉、模式识别等相关技术的综合应用。目前国内的车牌识别技术已经日益成熟，随着智能交通技术应用的不断加深，业界迫切希望提取更多元的车辆信息，除车牌号码外，还需要车辆的厂牌、型号以及颜色等信息特征。这些特征在停车场无人管理、交通事故处理、交通肇事逃逸、违章车辆自动记录等领域具有广泛而迫切的应用需求。</p>
  <a id="more"></a>
<pre><code>## 技术实现途径

机动车厂牌型号识别技术分为多个环节，一般是通过对摄像机采集的数字图像进行去噪、增强、车标定位、特征提取、识别等分析完成。为了得到较高的识别率，要求每一个处理步骤要有很高的准确率，而实际背景复杂，四季、昼夜、晴雨等不同情况的光照以及车辆运动速度的快慢等直接影响车辆图像的成像环节，造成车辆图像颜色失真、车身及车标区域灰度不均匀、边缘模糊、粘连等问题，增加了处理难度；反光、逆光、夜晚光照不足、树荫、车身颜色显著区域分布位置不同等情况又增加车身颜色识别难度；再加上车辆类别繁多以及车身本身的污损、遮挡、模糊，也为进一步提高识别率带来诸多困难。

北京文安自05年起，在行业里深耕多年，掌握了大量的实际数据与丰富的算法经验，针对诸多问题，公司综合采用了国际先进的人工智能、计算机视觉、图像处理、模式识别、大数据训练、深度学习等等技术来，通过从视频流中检测车辆、车头区域的定位、变形和倾斜校正、去除运动和成像造成的模糊、车辆特征的定位和识别、海量特征的选取和决策等多个环节来实现。


## 1. 百万级大数据训练，特征提取更丰富

在系统的设计和实现过程中，公司开发应用了当今国际上最先进的计算机视觉技术，并通过超百万的大数据学习样本进行训练，大量实地数据的系统调整和测试，还采集了描述车头、车灯、散热格栅等各个部分的外形轮廓、相对位置、颜色、纹理等多种特征，组成了海量的辅助分类信息，与厂牌型号识别的结果一起最终通过可在线学习的特征决策模块，得到综合可信度评价，从而得到最终的识别结果。
</code></pre><p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/240.jpg" alt=""></p>
<pre><code>## 2. 深度学习算法，提高数据精准性

浩瀚如海的大数据，结构复杂，种类繁多，单纯依靠人力定义的过程无法处理这海量数据。于是我们采用基于模仿人类神经网络的人工智能算法，让机器从海量数据当中自我学。深度学习的实质，就是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。我们通过利用大数据来深度学习各类信息、特征，更能够刻画数据的丰富内在信息。从而得出更多元更精准的厂牌型号及其他信息。

## 3. 并行计算，使算法不断优化

系统还通过利用北京文安强大的并行计算能力，极大的加快了计算速度和数据处理速度，使算法不断优化，目前厂牌识别种类已达632种。常规情况下，识别率在92%以上，识别车身颜色包括黑白灰红等十余种。在样本大数据不断增加的同时，通过模型训练及深度学习，指标将不断提升。

![](http://www.36dsj.com/wp-content/uploads/2015/03/337.jpg)

机动车厂牌型号的识别为违法车辆以及套牌车辆的有效监测提供了有力的手段，为保障人民人身安全和打击违法犯罪行为提供了有效的工具。机动车厂牌型作为车辆识别的重要属性，在大数据深度学习背景下，未来将不断完善，并将推动为智能交通向更加精准、高效发展，使我们的生活更加智能、高效、便捷。
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.36dsj.com/archives/24575&quot;&gt;36大数据 数控小V&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.36dsj.com/wp-content/uploads/2015/03/170.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2015年3月，北京文安公司发布了基于大数据下深度学习的机动车厂牌型号识别技术。&lt;/p&gt;
&lt;p&gt;车辆身份识别系统是智能交通的重要分支，它需要人工智能、图像处理、计算机视觉、模式识别等相关技术的综合应用。目前国内的车牌识别技术已经日益成熟，随着智能交通技术应用的不断加深，业界迫切希望提取更多元的车辆信息，除车牌号码外，还需要车辆的厂牌、型号以及颜色等信息特征。这些特征在停车场无人管理、交通事故处理、交通肇事逃逸、违章车辆自动记录等领域具有广泛而迫切的应用需求。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Deep Learning" scheme="http://ipcreator.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>基于char-rnn和tensorflow生成周杰伦歌词</title>
    <link href="http://ipcreator.me/2017/02/13/BusinessAI/generate-lyric-from-lyric-of-jay/"/>
    <id>http://ipcreator.me/2017/02/13/BusinessAI/generate-lyric-from-lyric-of-jay/</id>
    <published>2017-02-13T06:30:00.000Z</published>
    <updated>2017-02-16T10:23:54.458Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.36dsj.com/archives/70163" target="_blank" rel="external">leido</a></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2016/11/455-2.jpg" alt=""></p>
<p>最近深度学习在机器视觉CV、自然语言处理NLP领域表现出强大的潜力，各种深度学习/机器学习框架也层出不穷。TensorFlow是google于去年(2015.11)开源的深度学习框架，截止目前(2016-11-28)Github上已经有38000+的star数，称之为最近最受欢迎的深度学习框架一点也不过分。</p>
<p>本着学习TensorFlow和RNN的目的，前些天发现了char-rnn这个有趣的项目，具体就是基于字符预测下一个字符，比日说已知hello的前四个字母hell，那我们就可以据此预测下一个字符很可能是o,因为是字符char级别的，并没有单词或句子层次上的特征提取，相对而言比较简单易学。</p>
  <a id="more"></a>
<p>因为原作者的代码是基于torch写的，为了熟悉tensorflow，我就仔细地研究了一下具体代码，然后改写成基于tf的代码，github上也有基于TensorFlow的char-rnn-tensorflow，恕我直言，有以下三点比较膈应：</p>
<p>代码写的不够直观简洁<br>另外因为最新tensorflow的部分api有所变化<br>中英文之间有一些差异，看能否成功移植到处理中文上<br>于是打算基于以上两个项目，自己重写!</p>
<p>基本原理</p>
<p>拿中文举例来说，每个字与每个字并不是统计上独立的，比如说如果不爱就不要再伤害长度为10的序列，如果我们知道如，下一个字有可能是果，如果知道前两个字如果，第三个字就是不的可能性大些，依次类推，如果知道前9个字如果不爱就不要再伤，那么最后一个就有可能是害字。用图直观的表示如下。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2016/11/444-2.png" alt=""></p>
<p>总的来说，这是一个seq2seq的模型，训练数据用的是周杰伦01年到11年所有歌的歌词，训练数据和代码我都放到Github上，可以从<a href="https://github.com/leido/char-rnn-cn" target="_blank" rel="external">这里</a>下载</p>
<p>全部代码如下：</p>
<p><img class="aligncenter size-full wp-image-70167" src="http://www.36dsj.com/wp-content/uploads/2016/11/445-2.png" alt="36大数据" width="602" height="875" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/445-2.png 602w, http://www.36dsj.com/wp-content/uploads/2016/11/445-2-295x429.png 295w, http://www.36dsj.com/wp-content/uploads/2016/11/445-2-433x629.png 433w" sizes="(max-width: 602px) 100vw, 602px"> <img class="aligncenter size-full wp-image-70168" src="http://www.36dsj.com/wp-content/uploads/2016/11/446-2.png" alt="36大数据" width="605" height="914" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/446-2.png 605w, http://www.36dsj.com/wp-content/uploads/2016/11/446-2-284x429.png 284w, http://www.36dsj.com/wp-content/uploads/2016/11/446-2-416x629.png 416w" sizes="(max-width: 605px) 100vw, 605px"> <img class="aligncenter size-full wp-image-70169" src="http://www.36dsj.com/wp-content/uploads/2016/11/447-2.png" alt="36大数据" width="604" height="912" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/447-2.png 604w, http://www.36dsj.com/wp-content/uploads/2016/11/447-2-284x429.png 284w, http://www.36dsj.com/wp-content/uploads/2016/11/447-2-417x629.png 417w" sizes="(max-width: 604px) 100vw, 604px"> <img class="aligncenter size-full wp-image-70170" src="http://www.36dsj.com/wp-content/uploads/2016/11/448-1.png" alt="36大数据" width="602" height="915" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/448-1.png 602w, http://www.36dsj.com/wp-content/uploads/2016/11/448-1-282x429.png 282w, http://www.36dsj.com/wp-content/uploads/2016/11/448-1-414x629.png 414w" sizes="(max-width: 602px) 100vw, 602px"> <img class="aligncenter size-full wp-image-70171" src="http://www.36dsj.com/wp-content/uploads/2016/11/449-1.png" alt="36大数据" width="603" height="915" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/449-1.png 603w, http://www.36dsj.com/wp-content/uploads/2016/11/449-1-283x429.png 283w, http://www.36dsj.com/wp-content/uploads/2016/11/449-1-415x629.png 415w" sizes="(max-width: 603px) 100vw, 603px"> <img class="aligncenter size-full wp-image-70172" src="http://www.36dsj.com/wp-content/uploads/2016/11/450.png" alt="36大数据" width="605" height="918" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/450.png 605w, http://www.36dsj.com/wp-content/uploads/2016/11/450-283x429.png 283w, http://www.36dsj.com/wp-content/uploads/2016/11/450-415x629.png 415w" sizes="(max-width: 605px) 100vw, 605px"> <img class="aligncenter size-full wp-image-70173" src="http://www.36dsj.com/wp-content/uploads/2016/11/451.png" alt="36大数据" width="603" height="913" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/451.png 603w, http://www.36dsj.com/wp-content/uploads/2016/11/451-283x429.png 283w, http://www.36dsj.com/wp-content/uploads/2016/11/451-415x629.png 415w" sizes="(max-width: 603px) 100vw, 603px"> <img class="aligncenter size-full wp-image-70174" src="http://www.36dsj.com/wp-content/uploads/2016/11/452.png" alt="36大数据" width="606" height="911" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/452.png 606w, http://www.36dsj.com/wp-content/uploads/2016/11/452-285x429.png 285w, http://www.36dsj.com/wp-content/uploads/2016/11/452-418x629.png 418w" sizes="(max-width: 606px) 100vw, 606px"> <img class="aligncenter size-full wp-image-70175" src="http://www.36dsj.com/wp-content/uploads/2016/11/453.png" alt="36大数据" width="607" height="142" srcset="http://www.36dsj.com/wp-content/uploads/2016/11/453.png 607w, http://www.36dsj.com/wp-content/uploads/2016/11/453-600x140.png 600w" sizes="(max-width: 607px) 100vw, 607px"></p>



<p>python3 gen_lyrics 0训练差不多10几分钟，然后运行python3 gen_lyrics.py 1生成的歌词如下：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2016/11/454-1.png" alt=""></p>
<p>End.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.36dsj.com/archives/70163&quot;&gt;leido&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.36dsj.com/wp-content/uploads/2016/11/455-2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;最近深度学习在机器视觉CV、自然语言处理NLP领域表现出强大的潜力，各种深度学习/机器学习框架也层出不穷。TensorFlow是google于去年(2015.11)开源的深度学习框架，截止目前(2016-11-28)Github上已经有38000+的star数，称之为最近最受欢迎的深度学习框架一点也不过分。&lt;/p&gt;
&lt;p&gt;本着学习TensorFlow和RNN的目的，前些天发现了char-rnn这个有趣的项目，具体就是基于字符预测下一个字符，比日说已知hello的前四个字母hell，那我们就可以据此预测下一个字符很可能是o,因为是字符char级别的，并没有单词或句子层次上的特征提取，相对而言比较简单易学。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>新型耳机将要拉开AI增强人耳听觉序幕？</title>
    <link href="http://ipcreator.me/2017/02/13/BusinessAI/ai-on-ear-phone/"/>
    <id>http://ipcreator.me/2017/02/13/BusinessAI/ai-on-ear-phone/</id>
    <published>2017-02-13T06:21:06.000Z</published>
    <updated>2017-02-27T03:44:48.080Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dy.163.com/v2/article/detail/CBPNF1U20511CUKV.html" target="_blank" rel="external">作者：网易AI研究院</a></p>
<p><img src="http://dingyue.nosdn.127.net/GHHKKK5WXVGhYX4o4=tUSFdOMN2l5N3FBnjRaJ5or7iqT1485488780276compressflag.jpg" alt=""></p>
<p>  据国外媒体报道，有家新公司在打造一种经过人工智能（AI）技术增强的耳机产品，其背后的理念是 <strong>AI人耳比普通的人耳要好使。</strong></p>
<p>　　我们往往要在喧闹环境中专注于特定的声音——如孩子的哭喊声，在嘈杂的俱乐部中听朋友说话等等——这并不容易做到。要是人工智能能够让我们的耳朵变得更加智能呢？有家公司打算明年初推出这种智能平台：售价299美元的蓝牙耳机。他们的真正目的是什么呢？揭开AI增强的人耳听觉的序幕。（这可能也预示着手机的末日。）</p>
<p>　　该款耳机名为Here One。</p>
  <a id="more"></a>
<p><img src="http://dingyue.nosdn.127.net/9g1g3wF9eYoMxPuF0fvkxWXC9Yx3j6nHudHwCAXvzU0es1485488780276.jpg" alt=""></p>
<p>其背后的新公司Doppler Labs对即将推出的产品的演示令人印象深刻。它的功能清单令人大开眼界，既能够让人一窥人耳听觉被强化的未来，也能够呈现各种有待征服的技术挑战。<strong>该产品是那种基于技术的个性化人类增强型设备的一个例子，未来可能将会出现更多这样的设备。</strong></p>
<p>　　以下是Doppler希望Here One和相配的手机应用在推出之时能够提供的功能。而它明显将会配备的功能则包括：无线流式音频，无线电话，控制Siri、Google Voice等虚拟助手。</p>
<h2 id="用户能够同时听到混合串流音乐和周围的声音"><a href="#用户能够同时听到混合串流音乐和周围的声音" class="headerlink" title="用户能够同时听到混合串流音乐和周围的声音"></a>用户能够同时听到混合串流音乐和周围的声音</h2><p>　　之前尝试捕捉环境声音的一些产品听上去很怪异，声音有点滞后。而Doppler的产品则显然终于解决了这一问题。刚刚戴上Here One耳机时，《连线》杂志撰稿人大卫·皮尔斯（David Pierce）发现，Here One版的真实世界相当通透，相当即时，以至于他一开始都意识不到自己已经戴上耳机开始听。该功能背后的理念在于，在给人们提供收听美妙音乐的方式的同时，确保没有将他们与周围的世界隔绝。</p>
<h2 id="放大或减弱用户需要倾听的说话者的声音"><a href="#放大或减弱用户需要倾听的说话者的声音" class="headerlink" title="放大或减弱用户需要倾听的说话者的声音"></a>放大或减弱用户需要倾听的说话者的声音</h2><p>　　在戴上Here One耳机后，《连线》撰稿人与Doppler高管的对话持续正常进行，直至后者突然将自己在Here One耳机中的声音停掉。专注于你想要倾听的人和屏蔽不想要听的那些人的声音，这我们可以尝试去做到，但我们的器官是做不到这一点的。</p>
<p>　　<img src="http://dingyue.nosdn.127.net/PnFHFGCNOAvM=2BBlr6vNYPcRza9f8RwEY4EzacYobQG31485488780276.jpg" alt=""></p>
<h2 id="减弱噪音音量，或者完全将其消除"><a href="#减弱噪音音量，或者完全将其消除" class="headerlink" title="减弱噪音音量，或者完全将其消除"></a>减弱噪音音量，或者完全将其消除</h2><p>　　<strong>Here One的智能过滤功能依赖于机器学习技术。</strong> 它需要在用户可能遇到的声音上有广泛的数据，日常生活中有着各种各样的声音。Doppler的弗里茨·拉恩曼（Fritz Lanman）向Quartz表示，“婴儿的哭喊声极其多变，它们属于宽频带噪声，变化莫测，非常特别。”</p>
<p>　　为了实现那一目标，Doppler一直在收集音频样本——截至目前已经超过100万份，它们收集自五大洲——收集过后它会将那些样本转化成供Here One使用的声音检测算法。该公司目前在做的一件很有意思的事情是，<strong>在全球各地从卖出的Here One耳机收集音频数据，并持续以新算法形式将那些数据反馈回用户。</strong>（Doppler表示那些数据都有进行匿名化处理。）也就是说，该公司实质上是在众包其系统的声音检测算法，他们卖出的耳机越多，覆盖的受众就越多。</p>
<h2 id="倾听不同方向的声音"><a href="#倾听不同方向的声音" class="headerlink" title="倾听不同方向的声音"></a>倾听不同方向的声音</h2><p>　　通过设置，Here One耳机可以变得只倾听你身前或者身后的东西，完全隔绝其它方向的声音。Doppler在决定如何称呼向后倾听功能，考虑将其称作“窃听”或者“间谍”模式。从根本上说，它就像是转耳“猫”模式。我们再也不用羡慕会180度转耳的猫了。</p>
<h2 id="定制用户周围的声音"><a href="#定制用户周围的声音" class="headerlink" title="定制用户周围的声音"></a>定制用户周围的声音</h2><p>　　一系列的控制功能让用户改变听到的世界，让用户都能够享有自己的音景。这是一种新型的泡沫现实——这可能是好事，也有可能是坏事。不管怎么样，用户都将能够调整那些声音的音量——智能过滤器让你可以锁定它们——用均衡器（EQ）改变它们的音调特点，又或者给它们增加音频效果。</p>
<h2 id="创建个人收听档案"><a href="#创建个人收听档案" class="headerlink" title="创建个人收听档案"></a>创建个人收听档案</h2><p>　　Here One能够注意用户的收听习惯，当用户进入不同的声音环境时，它会根据用户的习惯提供调整建议。这是让用户走出刺耳的环境，进入属于自己的定制化音频环境的又一种方式。</p>
<p>　　Doppler还让媒体看了一下其它的一些还没有完善的功能特性。</p>
<h2 id="实时翻译"><a href="#实时翻译" class="headerlink" title="实时翻译"></a>实时翻译</h2><p>　　在演示中，Doppler用西班牙语给《连线》的皮尔斯讲了一个笑话，而后者听到的是用英语说出的笑话。这应该是得益于人工智能技术。该功能目前尚不完善——比如，笑话延时了大概五秒钟——但这种功能的价值显而易见。可以说，这是旅行者们期盼已久的功能，它有望促进世界各地文化背景不同的人之间的沟通交流。</p>
<h2 id="自动识别和提高你在乎的人的声音"><a href="#自动识别和提高你在乎的人的声音" class="headerlink" title="自动识别和提高你在乎的人的声音"></a>自动识别和提高你在乎的人的声音</h2><p>　　这种功能在很多时候都很有帮助，比如在嘈杂的环境中听到你疼爱的婴儿在哭。当然，若能够自动识别和屏蔽用户讨厌的人的声音，也是很不错的：用户可以让Here One自动屏蔽一个烦人的朋友的声音。但从AI角度来看，在现实世界中鉴别声音的身份是件非常困难的事情。Siri、Echo、Google Voice和Cortana能够轻松做到这一点：他们只需在安静的环境中听几次你的声音，就能够根据声音辨认出来。而从混乱而不断变化的音景中鉴别出某人的声音则要困难得多，Doppler还没有走到这一步。</p>
<h2 id="关于用户的手机的未来"><a href="#关于用户的手机的未来" class="headerlink" title="关于用户的手机的未来"></a>关于用户的手机的未来</h2><p>　　要是用户可以直接通过蓝牙耳机打电话，用户还有什么理由需要手机上的应用呢？未来我们还需要手机屏幕和应用吗？我们可能还是需要的：对于复杂的信息，视觉体验可让用户更容易理解。《连线》指出，技术专家克里斯·诺赛尔（Chris Noessel）曾这么说到《她》（Her）科幻电影中AI操作系统Samantha与人类的沟通方式，<strong>“Samantha经常通过耳机跟西奥多说话。而当她需要向他展示某样东西时，她会让他注意手机或者桌面屏幕。”</strong> 不过，Doppler还是想要将手机完全剔除出去。“我们知道，用户从口袋中掏出手机这一步，就是体验的阻力部分。”Doppler用户体验与用户界面主管西恩·弗尔（Sean Furr）指出。</p>
<p>　　这涉及很多重要的问题，如我们是什么，我们该如何互动，我们该如何体验和穿梭于这个世界。我们所有人都生活在自己的声音世界是好事情吗？这会让人们更难对现实产生共鸣吗？在这种技术真正整合到我们的生活中之前，这些问题都不会有答案。（皓慧）</p>
<h2 id="车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE-预警系统"><a href="#车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE-预警系统" class="headerlink" title="车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统"></a><a href="http://www.leiphone.com/news/201702/Y13uPQtxYETjaFgx.html" target="_blank" rel="external">车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统</a></h2><p>本文作者：李子湃    2017-02-10 23:22</p>
<p>导语：在汽车传感器检测到将要发生不可避免的碰撞时，粉红噪声（Pink Noise）刺激耳内镫骨肌收缩，保护内耳和鼓膜。</p>
<p>车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589dda24798b8.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>从制动辅助系统(BAS)到电子感应制动系统（SBC），主动安全技术已经从避免车辆碰撞发展到避免更加微小的人身伤害。</p>
<p>奔驰在近日公布了应对车祸造成听力损伤的解决方案：通过检测不可避免的车祸并发出安全的粉色噪声（最大80分贝），让声音刺激耳内肌肉收缩，预防车辆碰撞甚至是气囊弹开所发出的巨大噪声造成的听力受损。</p>
<p>粉色噪声是自然界最常见的噪音，简单说来，粉红噪音的频率分量功率主要分布在中低频段。根据IEEE的数据，奔驰采用的粉色噪声强度大约是 80 分贝，相当于一台洗碗机工作的声音，对于人耳来说比较安全。而在车祸发生时产生的高达 145 分贝的声音，有极大几率对听力造成损害，安全气囊弹开的时候，声音更高达 165 分贝。雷锋网(公众号：雷锋网)查阅到的数据显示，曾遭受车祸并得到安全气囊保护的被调查者中，有 17% 的人受到永久性的听力损伤。</p>
<p>这种听觉保护技术加入奔驰称之为 <strong>PRE-SAFE的主动安全系统之后，这套系统几乎已经覆盖了目前车祸发生时大部分人员受伤的情况，包括正副驾驶之间的碰撞，甚至是汽车最忌讳的侧面撞击。</strong> 此前奔驰公布的一项PRE-SAFE技术显示，车辆在预警到侧面撞击之后，会主动将撞击一侧的乘客“推”向中间位置，整个过程的响应速度在毫秒级别。</p>
<p>雷锋网原创文章，未经授权禁止转载。详情见转载须知。</p>
<h2 id="我如何用深度学习改造母亲的助听器？"><a href="#我如何用深度学习改造母亲的助听器？" class="headerlink" title="]我如何用深度学习改造母亲的助听器？"></a><a href="http://www.leiphone.com/news/201612/VEc4syIuEt5eOoZ5.html" target="_blank" rel="external">]我如何用深度学习改造母亲的助听器？</a></h2><p>本文作者：小东    2016-12-20 10:12</p>
<p>导语：<strong>深度学习重新定义助听设备，过滤杂音效果良好。</strong></p>
<p>雷锋网(公众号：雷锋网)按：目前的人造听力系统存在一个关键问题：无法过滤背景噪音。尽管用户对倾听的需求十分强烈，然而硬件只是单纯地将声音放大——自然也包括噪音。英国认知科学家Colin Cherry于1953年首次将这一问题称为”cocktail party problem”（鸡尾酒会难题）。</p>
<p>作者 DeLiang Wang 是一名俄亥俄州立大学的教授，他主要关注计算机科学及工程领域，此外，他也在学校的认知及大脑科学研究中心工作。本文是他基于自己亲人的切身体会，利用深度学习改造助听器的自述，雷锋网编译，未经许可不得转载。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/585897d507888.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>我如何用深度学习改造母亲的助听器？</p>
<p>我上大学的时候，母亲的听力逐渐下降。不过一直以来，我很愿意回家将我所学的东西与她分享，她也很乐意倾听。但渐渐地我发现，如果多个人同时说话，那么母亲很难分清到底是哪个人在和她讲话。尽管她使用了助听器，但对她来说区分这些声音仍旧很难。在我们家庭聚餐的时候，我母亲不希望我们同时和他说话，希望每次只有一个人和她说话。</p>
<p>我母亲的痛苦遭遇反应了目前助听设备面临的一个主要问题，即助听器滤音效果不好。尽管信号处理专家、人工智能专家、听力专家已经努力了几十年，但现在的人造听力系统仍不能很好滤掉背景噪音。</p>
<p>据估计，六十年后将会有约25%的人需要佩戴助听设备，如果这些设备去除杂音的效果不好，那么我们可以想象这样一个场景：</p>
<p>当一个人和佩戴助听设备的人谈话时，此时一辆汽车呼啸而过，但这些助听设备只是简单的将杂音与话音放大，却无法很好去除汽车杂音，此时对于用户的听力将会造成多么大的伤害，他们将听不清对方的讲话。<br>是时候该解决这个问题了，我在俄亥俄州立大学的实验室目前尝试使用深度学习模型实现杂音与声音分离，此外我们还尝试了多种用于去除杂音的数字滤波器。</p>
<p>我们相信基于深度学习模型的听力修复可以使听力受损人的听力理解能力达到甚至超过正常人。实际上，我们的早期模型效果一直在提升。由原来听清 10% 提高到 90%。在现实生活中，即使人们没有听清一句话中的每一词，他们也可以理解这句话的意思。所以这实际上已经意味着，人们已经从“一句都听不懂”变成了“能听懂一句话”的状态。</p>
<p>对于有听觉问题的人，没有好的助听设备，人的听力只会越来越糟。世界卫生组织估计约 15%（776百万人）患有听觉问题，随着老年人口的增多，这一数字将会逐渐变大，并且高级听力设备的潜在市场不仅局限于听觉受损用户。开发商可以将这一技术用于智能手机，以提升智能手机的通话质量。一些人的工作环境背景噪音复杂，这个设备可以解决这问题。处于战争环境中的士兵也可以佩戴这个设备使得他们之间的通话更加顺畅。</p>
<p>语音清洗与过滤</p>
<p>助听设备的市场广阔，据印度MarketsandMarkets研究发现，目前助听行业规模大约为60亿美金，市场规模在2020年以前预计以每年6%的速度递增。为了满足新用户需求，我们需要解决‘鸡尾酒会难题’，那么如何解决呢？深度学习给我们提供了一个很好的解决思路。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5852b94c8ba46.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>语音清洗流程如下：</p>
<ol>
<li>信号转换：机器学习程序首先将语音信号转换为时域信号。  </li>
<li>特征表示：在时域范围内用85个特征表示语音信号，</li>
<li>语音分类：将这些用特征表示的语音信号传入深度学习模型中，找出语音信号与杂音信号，</li>
<li>杂音过滤：使用滤波器去除杂音信号，保留语音信号。</li>
</ol>
<p>数十年来，电子与计算机专家尝试从信号处理的角度实现语音与杂音的分离，但均以失败告终。目前最有效的方法就是语音活动检测器，用于识别不同人之间的说话。在这种方法下，系统检测出不同的语音信号，然后滤去这些声音信号，留下理想的、无杂音信号。不幸的是，这种方法效果很不好，它通常会滤去很多语音或只滤去少量杂音。即便经过了几十年的发展，这项技术的实际效果仍然不太理想。</p>
<p>我觉得我们得使用新的方法解决这个问题，我们首先研究了 Albert Bregman（ McGill University）的关于人类听力系统的理论，他认为人类的听觉系统将不同的声音分成不同的声音流，一个声音流对应一个音源，每一个声音流据有不同的音高、音量、方向。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5852b974c7af6.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>上图展示了声音场景是如何形成的</p>
<p>总之，许多音流（像曲棍球比赛中朋友们的呐喊）组成 Bregman 所谓的听觉场景。如果不同音波的音频一样，那么音量最大那个将会盖过其它声音，这一现象被称作听觉掩蔽效应。例如，下雨的的时候没人会听到钟表的滴答声。这原理也用在了MP3的文件中，它通过压缩被掩蔽的声音，使得文件大小变为了原来的十分之一，文件虽然缩小了，但用户却没有任何感觉。</p>
<p>回顾了Bregman的工作，我们设想我们是否可以构建一个滤波器，在特定时刻对于特定音频，这个滤波器可以找到主声波。听觉感知专家Psychoacousticians将人类的听觉频率（20Hz到20000Hz）分成24份，那么问题就变成了我们需要一个滤波器，在某一时刻这个滤波器可以告诉我们是否存在一个包含比其它语音或杂音都大的声音，然后江这个大的声音进行分离出来。</p>
<p>我的实验室在2001年就开始了这项工作，并给音流打标签，以表明他们的主音流是语音流还是杂音流。有了这些标记数据，然后我们基于机器学习的方法，训练一个能区分主音流是声音还是杂音的分类器，这些特征包括音量、音调等。</p>
<p>原始过滤器是一个二元过滤器，用于对特定时刻特定频率的声音进行标识，这个过滤器在时域范围对声音信号进行0、1标识，如果主音为声音，标1；主音为杂音，标0。最后生成一个主音为声音与主音为杂音的样本集合，滤波器除去标识为0的声音，保留标识为1的声音。为了保证句子能够被理解，必须保证标识为1的语音占有一定的比例。</p>
<p>2006年，在美国空军实验室我们对声音滤波器进行测试，与此同时，另外一家机构也队我们的产品进行独立的第三方评估，在这些试验中，我们的产品性能优异。不仅有助于提高听觉受损者的听力水平，还有助于提高正常人的听力水平。</p>
<p>我们创造了一款在实验室中表现优良的听力设备，在设计过程中，我们训练的时候是将语音信号与杂音信号分开的。测试的时候将这两者混合在一起，然后测试。由于这些信息均为为标记信息，所以过滤器知道什么情况下语音信号要大于杂音信号，所以我们称之为理想滤波器。但实际情况是滤波器应该能靠自己进行判断，而不是靠我们提前告诉它。</p>
<p>不过，理想滤波器确实能提高听觉受损者与正常者的听力理解水平。这表明我们可以将分类方法用于区分语音与噪音。分类方法实际上是一种机器学习的方法，通过训练、反馈、惩罚等一些列类似于人的学习过程，来实现对声音信号的正确分类。</p>
<p>在接下来的几年中，我们实验室开始尝试使用分类方法来模仿我们滤波器，同时，我们基于机器学习设计新的分类器，提高自动语音识别的质量。后来一组来自University of Texas的研究人员使用一种不同的方法首次实现语音可懂性的实质意义上的进步，这种方法仅使用了单声道特征。</p>
<p>但是对于助听设备来说，这些分类方法的效果与精度还不够，这些方法还不能处理现实世界中复杂环境下的声音信息。因此，我们需要更好的方法。</p>
<p>如何进一步改善系统？</p>
<p>我们决定进一步改善系统效果，使我们的系统可以应用在现实环境中且不需训练。为了解决这个问题，我们构建了一个以前从未构建过的机器学习系统，经过复杂的训练，这个神经网络系统，可以用于声音与杂音的分离。在24个测试样本中，这套系统提高听力受损人员的听力理解力约50%。效果良好。</p>
<p>神经网络是由一些简单的神经元组成，这些简单那神经元组合在一起就可以处理复杂的问题。当一个新的神经网络模型构建好以后，这个模型需要利用数据不断的调整神经元与神经元之间的权重（类似于人脑学习），以达到实现语音信号分类的目的。</p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201612/5852b9aa81c9a.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>如上图所示：左侧为为输入层，右侧为输出层，通过调节层与层之间的神经元之间的链接权重提高系统性能。</p>
<p>神经网络有不同的形状、大小、深度。隐层多余两层的就可以称为深度神经网络，上一层的输出是下一层的输入，就好比给下一个隐层增加一些先验知识。</p>
<p>例如，我们通过数据训练一个签名识别网络，如果此时有一个新的签名，这个签名与数据集中的签名是一个人写的，却与数据集中的签名不完全一样，但我们的网络仍可以识别出来，因为我们的网络层是可以识别出同一人签名的不同特征的，只要特征相同，就可以认为是同一个人写的，这些特征包括文字的倾斜角度，字母i的点是否点上等。</p>
<p>为了构建我们自己的深度学习网络，我们开始编写基于音频、振幅的特征抽取器，我们定义了数十个特征用以区别声音与杂音。最终我们确定了85个特征。其中最重要的特征是音频与音强。抽完特征以后，我们用这85个特征对神经网络进行训练。我们的训练包含两个阶段：</p>
<p>一、通过无监督方法训练系统参数。<br>二、用杂音数据对模型进行训练，这一步是有监督训练。我们用标记好的正例与负例对我们的系统进行测试与改善。<br>具体流程如下：输入一个新数据，系统首先对数据进行特征提取，特征表示，对数据进行分类（是声音还是杂音），与正确结果进行比较。如果结果有误，对神经网络进行调参，使得我们的输出在下一次的训练中尽可能与正确结果相接近。</p>
<p>为了实现神经元与神经元之间的权重调整（调参），我们首先计算神经网络的输出误差，我们有一个误差函数，这个函数用来计算神经网络的输出结果误差。根据这个结果误差，我们对神经元之间的连接权重进行调整，以降低误差，这个训练过程需要重复上千次。最终实现一个较好的训练模型。</p>
<p>为了使得结果更好，我们在前面深度学习的基础上在构建一个深度学习模型，将第一个的输出做为第二模型的输入，对结果进行细粒度的调优，第一层的关注的是声音单元本身的特征，第二层检验的是声音单元‘邻居’的特征。那么为什么对周围声音进行检测也有用呢？道理很简单，第一层好比是一个正在销售的房屋，我们对它的各个房间进行查看，第二层就好比这个屋子的‘邻居’，我们对它的‘邻居’进行检验。换句话说，第二层为第一层提供了声音信号的上下文信息，有助于提高分类的准确率。例如，一个音节可能包含几个时域，背景噪音可能只在突然出现音节的起始阶段，后面就没有了。在这个例子中，上下文信息就可以使我们更好的从杂音中提取出声音。</p>
<p>在完成训练后，我们的深度学习分类器要比我们原先的分类器好很多，事实上，这是我们首次在算法上取得突破，使得我们的助听设备可以提高听觉受损人员的听力水平。为了测试我们的设备性能，我们对12名听障人员、12名听力正常人员进行测试，测试用例是成对出现的，第一次声音与杂音混在一起，第二次是经过我们神经网络处理过的声音。例如包含“It’s getting cold in here”和“They ate the lemon pie,”的句子有两种杂音，一种是嗡嗡声，另一种背景杂音是很多人在一起说话。这个嗡嗡声很像冰箱压缩机工作的声音，而另一种杂音是是我们生成的，是四男四女的说话声，以此来模仿鸡尾酒会的这一类背景噪音。</p>
<p>在对背景噪音进行处理后，无论是听觉受损人员还是听觉正常人员其听力理解能力均有大幅提升，在未经处理的声音中，听觉受损人员只可以听清29%的单词，但在处理过的声音中，他们可以理解84%的内容。在一些例子中，一开始只能听清10%，经过处理后就可以理解90%的内容了。在有嗡嗡杂音环境下，听觉受损人员的理解力从未经处理时的36%提升到82%。</p>
<p>对于听力正常的人，我们的系统同样有效，它可以使正常人在有杂音的环境下听到的更多，这就意味着将来的某一天，我们的系统可以帮助更多的人。在嗡嗡杂音下，未经处理，正常人只能听懂37%，处理后可以听懂80%，在鸡尾酒会的这一类背景噪音下，其听力理解力由42%提升到78%。</p>
<p>我们实验中最有意思的结果是，如果一个听力受损的人使用我们的助听设备，那么他的听力能否超过正常人？答案是肯定的。在嗡嗡环境下，听力受损的人（使用我们的助听设备）可以比正常人多听懂15%内容，在聚会噪音背景下可以多听懂20%。以这个结果来看，可以说我们的系统是最接近解决‘鸡尾酒会问题’的系统。</p>
<p>局限自然有，展望依然在</p>
<p>尽管如此，我们的算法仍有局限，在测试样例中，我们的背景噪声与我们训练用的背景噪声很相似。但实际情况却不是这样的，所以在实际应用中，系统需要快速学习周围环境中的各种背景噪声，并将其滤掉。例如通风系统的声音、房间内回音等。</p>
<p>我们购买了一个包含10000种杂音的数据集（这个数据集起初是为电影制造商准备的），用其来训练我们模型。今年，我们发现经过训练的程序可以处理以前从未遇到过的杂音了，并且去杂音效果得到了及具现实意义的提高（无论对听觉受损者还是听觉正常者），现在，由于得到了全国失聪及其他沟通障碍研究所（ National Institute on Deafness and Other Communication Disorders ）的支持，我们决定在更多环境下，使用更多的听障人员来测试我们的系统。</p>
<p>最后，我相信我们系统可以在性能更加强大的计算机上进行训练，并且移植到人听障人士身上，或者与智能手机进行配对使用。商家会周期性的对新数据进行训练，并发布新的版本以便让用户升级他们的助听设备，从而使其能够滤去新的杂音。我们已经申请了数个专利并且与多个合作伙伴进行了商业化应用。</p>
<p>使用这个方法，鸡尾酒会难题看起来不在是那么难以解决。我们坚信，只要有更多杂音数据、更加广泛的训练，我们终究可以解决这个难题。事实上，我认为我们现在处理声音的流程与小孩早期区分杂音与声音的过成是很类似的。都是在不断的重复中提升性能的。总之，经验越多，方法就变得越好。</p>
<p>雷锋网小编也设想到，如果一个有着听力障碍的热心读者参加了明年雷锋网举办的GAIR大会，在人头攒动的会场，他可能一直会被会展播放的背景音乐所打扰，无法专心与新结识的大牛们聊天。如果有了硬件相关的技术提升，那么想必会让活动的效果更好，而这也是科技尤其是人工智能所带给我们的福祉：让智能与未来伴随我们的生活，并使之变得更加美好。</p>
<p>via <a href="http://spectrum.ieee.org/consumer-electronics/audiovideo/deep-learning-reinvents-the-hearing-aid" target="_blank" rel="external">Deep Learning Reinvents the Hearing Aid</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dy.163.com/v2/article/detail/CBPNF1U20511CUKV.html&quot;&gt;作者：网易AI研究院&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://dingyue.nosdn.127.net/GHHKKK5WXVGhYX4o4=tUSFdOMN2l5N3FBnjRaJ5or7iqT1485488780276compressflag.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;  据国外媒体报道，有家新公司在打造一种经过人工智能（AI）技术增强的耳机产品，其背后的理念是 &lt;strong&gt;AI人耳比普通的人耳要好使。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　我们往往要在喧闹环境中专注于特定的声音——如孩子的哭喊声，在嘈杂的俱乐部中听朋友说话等等——这并不容易做到。要是人工智能能够让我们的耳朵变得更加智能呢？有家公司打算明年初推出这种智能平台：售价299美元的蓝牙耳机。他们的真正目的是什么呢？揭开AI增强的人耳听觉的序幕。（这可能也预示着手机的末日。）&lt;/p&gt;
&lt;p&gt;　　该款耳机名为Here One。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow极速入门</title>
    <link href="http://ipcreator.me/2017/02/13/Program/TensorFlow/quick-learning-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/13/Program/TensorFlow/quick-learning-of-tensorflow/</id>
    <published>2017-02-13T01:20:06.000Z</published>
    <updated>2017-02-17T15:30:30.501Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.leiphone.com/news/201702/vJpJqREn7EyoAd09.html" target="_blank" rel="external">AI研习社</a></p>
<p><img src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee26746f0a.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>目前，深度学习已经广泛应用于各个领域，很多童鞋想要一探究竟，这里抛砖引玉的介绍下最火的深度学习开源框架tensorflow。</p>
<p>雷锋网按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于深度学习技术的探索，对新事物有着强烈的好奇心。</p>
  <a id="more"></a>
<p></p><p><span style="color: rgb(0, 0, 0);"><strong>雷锋网<span style="color:#FD5D3C;">(公众号：雷锋网)</span>按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于<a target="_blank" href="http://www.leiphone.com/news/201701/LqwiP7VUJO9DgBPi.html" title="深度学习">深度学习</a>技术的探索，对新事物有着强烈的好奇心。</strong></span></p><p><span style="color: rgb(247, 150, 70);"><strong><span style="font-size: 20px;">一、前言</span></strong></span></p><p>目前，深度学习已经广泛应用于各个领域，比如图像识别，图形定位与检测，<a target="_blank" href="http://www.leiphone.com/news/201412/SPIrQG1uFa6jWMVZ.html" title="语音识别">语音识别</a>，机器翻译等等，对于这个神奇的领域，很多童鞋想要一探究竟，这里抛砖引玉的简单介绍下最火的深度学习开源框架 <a target="_blank" href="http://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html" title="TensorFlow">tensorflow</a>。本教程不是 cookbook，所以不会将所有的东西都事无巨细的讲到，所有的示例都将使用 python。</p><p>那么本篇教程会讲到什么？首先是一些基础概念，包括计算图，graph 与 session，基础数据结构，Variable，placeholder 与 feed_dict 以及使用它们时需要注意的点。最后给出了在 tensorflow 中建立一个<a target="_blank" href="http://www.leiphone.com/news/201609/SJGulTsdGcisR8Wz.html" title="机器学习">机器学习</a>模型步骤，并用一个手写数字识别的例子进行演示。</p><p><span style="font-size: 18px;"><strong>1、tensorflow是什么？</strong></span></p><p>tensorflow 是 google 开源的机器学习工具，在2015年11月其实现正式开源，开源协议Apache 2.0。</p><p>下图是 query 词频时序图，从中可以看出 tensorflow 的火爆程度。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee1c900b6e.jpg?imageMogr2/format/jpg/quality/90"></p><p><span style="font-size: 18px;"><strong>2、 why tensorflow?</strong></span></p><p>Tensorflow 拥有易用的 python 接口，而且可以部署在一台或多台 cpu , gpu 上，兼容多个平台，包括但不限于 安卓/windows/linux 等等平台上，而且拥有 tensorboard这种可视化工具，可以使用 checkpoint 进行实验管理，得益于图计算，它可以进行自动微分计算，拥有庞大的社区，而且很多优秀的项目已经使用 tensorflow 进行开发了。</p><p><span style="font-size: 18px;"><strong>3、 易用的tensorflow工具</strong></span></p><p>如果不想去研究 tensorflow 繁杂的API,仅想快速的实现些什么，可以使用其他高层工具。比如 tf.contrib.learn，tf.contrib.slim，Keras 等，它们都提供了高层封装。这里是 tflearn 的样例集（github链接 &nbsp;<a href="https://github.com/tflearn/tflearn/tree/master/examples）。" target="_blank" rel="external">https://github.com/tflearn/tflearn/tree/master/examples）。</a></p><p><strong><span style="font-size: 18px;">4、 tensorflow安装</span></strong></p><p>目前 tensorflow 的安装已经十分方便，有兴趣可以参考官方文档 （<a href="https://www.tensorflow.org/get_started/os_setup）。" target="_blank" rel="external">https://www.tensorflow.org/get_started/os_setup）。</a><br></p><p><span style="font-size: 20px;"><strong><span style="color: rgb(247, 150, 70);">二、 tensorflow基础</span></strong></span></p><p>实际上编写tensorflow可以总结为两步.</p><blockquote><p>（1）组装一个graph;</p><p>（2）使用session去执行graph中的operation。</p></blockquote><p>因此我们从 graph 与 session 说起。<br></p><p><span style="font-size: 18px;"><strong>1、 graph与session</strong></span></p><p><strong>（1）计算图</strong></p><p>Tensorflow 是基于计算图的框架，因此理解 graph 与 session 显得尤为重要。不过在讲解 graph 与 session 之前首先介绍下什么是计算图。假设我们有这样一个需要计算的表达式。该表达式包括了两个加法与一个乘法，为了更好讲述引入中间变量c与d。由此该表达式可以表示为：</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee26746f0a.jpg?imageMogr2/format/jpg/quality/90"></p><p>当需要计算e时就需要计算c与d，而计算c就需要计算a与b，计算d需要计算b。这样就形成了依赖关系。这种有向无环图就叫做计算图，因为对于图中的每一个节点其微分都很容易得出，因此应用链式法则求得一个复杂的表达式的导数就成为可能，所以它会应用在类似tensorflow这种需要应用反向传播算法的框架中。<br></p><p><strong>（2）概念说明</strong></p><p>下面是 graph , session , operation , tensor 四个概念的简介。</p><p>Tensor：类型化的多维数组，图的边；</p><p>Operation:执行计算的单元，图的节点；</p><p>Graph：一张有边与点的图，其表示了需要进行计算的任务；</p><p>Session:称之为会话的上下文，用于执行图。</p><p>Graph仅仅定义了所有 operation 与 tensor 流向，没有进行任何计算。而session根据 graph 的定义分配资源，计算 operation，得出结果。既然是图就会有点与边，在图计算中 operation 就是点而 tensor 就是边。Operation 可以是加减乘除等数学运算，也可以是各种各样的优化算法。每个 operation 都会有零个或多个输入，零个或多个输出。 tensor 就是其输入与输出，其可以表示一维二维多维向量或者常量。而且除了Variables指向的 tensor 外所有的 tensor 在流入下一个节点后都不再保存。</p><p><strong>（3）举例</strong></p><p>下面首先定义一个图（其实没有<a target="_blank" href="http://www.leiphone.com/news/201511/tgBJPsUzzzgvFHLp.html" title="必要">必要</a>，tensorflow会默认定义一个），并做一些计算。</p><blockquote><p>import &nbsp;tensorflow as tf</p><p>graph &nbsp;= tf.Graph()</p><p>with &nbsp;graph.as_default():</p><p>&nbsp;&nbsp;&nbsp; foo = tf.Variable(3,name=&#39;foo&#39;)</p><p>&nbsp;&nbsp;&nbsp; bar = tf.Variable(2,name=&#39;bar&#39;)</p><p>&nbsp;&nbsp;&nbsp; result = foo + bar</p><p>&nbsp;&nbsp;&nbsp; initialize = &nbsp;tf.global_variables_initializer()</p></blockquote><p>这段代码，首先会载入tensorflow，定义一个graph类，并在这张图上定义了foo与bar的两个变量，最后对这个值求和，并初始化所有变量。其中，Variable是定义变量并赋予初值。让我们看下result（下方代码）。后面是输出，可以看到并没有输出实际的结果，由此可见在定义图的时候其实没有进行任何实际的计算。</p><blockquote><p>print(result) &nbsp;#Tensor(&quot;add:0&quot;, shape=(), dtype=int32)</p></blockquote><p>下面定义一个session，并进行真正的计算。</p><blockquote><p>with &nbsp;tf.Session(graph=graph) as sess:</p><p>&nbsp;&nbsp;&nbsp; sess.run(initialize)</p><p>&nbsp;&nbsp;&nbsp; res = sess.run(result)</p><p>&nbsp;&nbsp;&nbsp;print(res)&nbsp; # 5</p></blockquote><p>这段代码中，定义了session，并在session中执行了真正的初始化，并且求得result的值并打印出来。可以看到，在session中产生了真正的计算，得出值为5。</p><p>下图是该graph在tensorboard中的显示。这张图整体是一个graph,其中foo,bar,add这些节点都是operation，而foo和bar与add连接边的就是tensor。当session运行result时，实际就是求得add这个operation流出的tensor值，那么add的所有上游节点都会进行计算，如果图中有非add上游节点（本例中没有）那么该节点将不会进行计算，这也是图计算的优势之一。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee2ee3a59c.png?imageMogr2/format/jpg/quality/90"></p><p><strong><span style="font-size: 18px;">2、数据结构</span></strong></p><p>Tensorflow的数据结构有着rank,shape,data types的概念，下面来分别讲解。</p><p><strong>（1）rank</strong></p><p>Rank一般是指数据的维度，其与线性代数中的rank不是一个概念。其常用rank举例如下。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee32a881f4.png?imageMogr2/format/jpg/quality/90"></p><p><strong>（2）shape</strong></p><p>Shape指tensor每个维度数据的个数，可以用python的list/tuple表示。下图表示了rank,shape的关系。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee33fb9d1b.png?imageMogr2/format/jpg/quality/90"></p><p><strong>（3）data type</strong></p><p>Data type，是指单个数据的类型。常用DT_FLOAT，也就是32位的浮点数。下图表示了所有的types。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee35bc6cf0.jpg?imageMogr2/format/jpg/quality/90"></p><p><strong><span style="font-size: 18px;">3、 Variables</span></strong></p><p><strong>（1）介绍</strong></p><p>当训练模型时，需要使用Variables保存与更新参数。Variables会保存在内存当中，所有tensor一旦拥有Variables的指向就不会在session中丢失。其必须明确的初始化而且可以通过Saver保存到磁盘上。Variables可以通过Variables初始化。</p><blockquote><p>weights &nbsp;= tf.Variable(tf.random_normal([784, 200], stddev=0.35),name=&quot;weights&quot;)</p><p>biases &nbsp;= tf.Variable(tf.zeros([200]), name=&quot;biases&quot;)</p></blockquote><p>其中，tf.random_normal是随机生成一个正态分布的tensor，其shape是第一个参数，stddev是其标准差。tf.zeros是生成一个全零的tensor。之后将这个tensor的值赋值给Variable。</p><p><strong>（2）初始化</strong></p><p>实际在其初始化过程中做了很多的操作，比如初始化空间，赋初值（等价于tf.assign），并把Variable添加到graph中等操作。注意在计算前需要初始化所有的Variable。一般会在定义graph时定义global_variables_initializer，其会在session运算时初始化所有变量。</p><p>直接调用global_variables_initializer会初始化所有的Variable，如果仅想初始化部分Variable可以调用tf.variables_initializer。</p><blockquote><p>Init_ab &nbsp;= tf.variables_initializer([a,b],name=”init_ab”)</p></blockquote><p>Variables可以通过eval显示其值，也可以通过assign进行赋值。Variables支持很多数学运算，具体可以参照官方文档 （<a href="https://www.tensorflow.org/api_docs/python/math_ops/）。" target="_blank" rel="external">https://www.tensorflow.org/api_docs/python/math_ops/）。</a></p><p><strong>（3）Variables与constant的区别</strong></p><p>值得注意的是Variables与constant的区别。Constant一般是常量，可以被赋值给Variables，constant保存在graph中，如果graph重复载入那么constant也会重复载入，其非常浪费资源，如非必要尽量不使用其保存大量数据。而Variables在每个session中都是单独保存的，甚至可以单独存在一个参数服务器上。可以通过代码观察到constant实际是保存在graph中，具体如下。</p><blockquote><p>const &nbsp;= tf.constant(1.0,name=&quot;constant&quot;)</p><p>print(tf.get_default_graph().as_graph_def())</p></blockquote><p>这里第二行是打印出图的定义，其输出如下。</p><blockquote><p>node {</p><p>&nbsp; name: &quot;constant&quot;</p><p>&nbsp; op: &quot;Const&quot;</p><p>&nbsp; attr {</p><p>&nbsp;&nbsp;&nbsp; key: &quot;dtype&quot;</p><p>&nbsp;&nbsp;&nbsp; value {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; type: DT_FLOAT</p><p>&nbsp;&nbsp;&nbsp; }</p><p>&nbsp; }</p><p>&nbsp; attr {</p><p>&nbsp;&nbsp;&nbsp; key: &quot;value&quot;</p><p>&nbsp;&nbsp;&nbsp; value {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tensor {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dtype: DT_FLOAT</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tensor_shape {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float_val: 1.0</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</p><p>&nbsp;&nbsp;&nbsp; }</p><p>&nbsp; }</p><p>}</p><p>versions {</p><p>&nbsp; producer: 17</p><p>}</p></blockquote><p><strong>（4）命名</strong></p><p>另外一个值得注意的地方是尽量每一个变量都明确的命名，这样易于管理命令空间，而且在导入模型的时候不会造成不同模型之间的命名冲突，这样就可以在一张graph中容纳很多个模型。<br></p><p><span style="font-size: 18px;"><strong>4、 placeholders与feed_dict</strong></span></p><p>当我们定义一张graph时，有时候并不知道需要计算的值，比如模型的输入数据，其只有在训练与预测时才会有值。这时就需要placeholder与feed_dict的帮助。</p><p>定义一个placeholder，可以使用tf.placeholder(dtype,shape=None,name=None)函数。</p><blockquote><p>foo = &nbsp;tf.placeholder(tf.int32,shape=[1],name=&#39;foo&#39;)</p><p>bar = tf.constant(2,name=&#39;bar&#39;)</p><p>result = foo + bar</p><p>with tf.Session() as sess:</p><p>&nbsp;&nbsp;&nbsp; print(sess.run(result))</p></blockquote><p>在上面的代码中，会抛出错误（InvalidArgumentError），因为计算result需要foo的具体值，而在代码中并没有给出。这时候需要将实际值赋给foo。最后一行修改如下:</p><blockquote><p>print(sess.run(result,{foo:[3]}))</p></blockquote><p>其中最后的dict就是一个feed_dict，一般会使用python读入一些值后传入，当使用minbatch的情况下，每次输入的值都不同。<br></p><p><strong><span style="color: rgb(247, 150, 70); font-size: 20px;">三、mnist识别实例</span></strong></p><p>介绍了一些tensorflow基础后，我们用一个完整的例子将这些串起来。</p><p>首先，需要下载数据集，mnist数据可以在Yann LeCun&#39;s website（&nbsp;<a href="http://yann.lecun.com/exdb/mnist/&nbsp;）下载到，也可以通过如下两行代码得到。" target="_blank" rel="external">http://yann.lecun.com/exdb/mnist/&nbsp;）下载到，也可以通过如下两行代码得到。</a></p><blockquote><p>from &nbsp;tensorflow.examples.tutorials.mnist import input_data</p><p>mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, &nbsp;one_hot=True)</p></blockquote><p>该数据集中一共有55000个样本，其中50000用于训练，5000用于验证。每个样本分为X与y两部分，其中X如下图所示，是28<em>28的图像，在使用时需要拉伸成784维的向量。</em></p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee4273f11f.png?imageMogr2/format/jpg/quality/90"></p><p>整体的X可以表示为。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee43d17487.png?imageMogr2/format/jpg/quality/90"></p><p><br></p><p>y为X真实的类别，其数据可以看做如下图的形式。因此，问题可以看成一个10分类的问题。</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee485af025.png?imageMogr2/format/jpg/quality/90"></p><p>而本次演示所使用的模型为逻辑回归，其可以表示为</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee4a8e546f.png?imageMogr2/format/jpg/quality/90"></p><p>用图形可以表示为下图，具体原理这里不再阐述，更多细节参考&nbsp;该链接&nbsp;（<a href="http://tech.meituan.com/intro_to_logistic_regression.html）。" target="_blank" rel="external">http://tech.meituan.com/intro_to_logistic_regression.html）。</a></p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee4d0e0287.png?imageMogr2/format/jpg/quality/90"></p><p>那么 let&#39;s coding。</p><p>当使用tensorflow进行graph构建时，大体可以分为五部分：</p><blockquote><p>&nbsp; &nbsp;1、 为 输入X与 输出y 定义placeholder；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;2、定义权重W；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;3、定义模型结构；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;4、定义损失函数；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;5、定义优化算法。</p></blockquote><p>首先导入需要的包，定义X与y的placeholder以及 W,b 的 Variables。其中None表示任意维度，一般是min-batch的 batch size。而 W 定义是 shape 为784,10，rank为2的Variable，b是shape为10，rank为1的Variable。</p><blockquote><p>import tensorflow as tf</p><p>x = tf.placeholder(tf.float32, &nbsp;[None, 784])</p><p>y_ = tf.placeholder(tf.float32, &nbsp;[None, 10])</p><p>W = tf.Variable(tf.zeros([784, &nbsp;10]))</p><p>b = tf.Variable(tf.zeros([10]))</p></blockquote><p>之后是定义模型。x与W矩阵乘法后与b求和，经过softmax得到y。</p><blockquote><p>y = tf.nn.softmax(tf.matmul(x, &nbsp;W) + b)</p></blockquote><p>求逻辑回归的损失函数，这里使用了cross entropy，其公式可以表示为：</p><p style="text-align: center;"><img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/article/740_740/201702/589ee5141c7e3.png?imageMogr2/format/jpg/quality/90"></p><p>这里的 cross entropy 取了均值。定义了学习步长为0.5，使用了梯度下降算法（GradientDescentOptimizer）最小化损失函数。不要忘记初始化 Variables。</p><blockquote><p>cross_entropy=tf.reduce_mean(-tf.reduce<em>sum(y</em>tf.log(y),reduction_indices=[1]))</p><p>train_step = &nbsp;tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</p><p>init = &nbsp;tf.global_variables_initializer()</p></blockquote><p>最后，我们的 graph 至此定义完毕，下面就可以进行真正的计算，包括初始化变量，输入数据，并计算损失函数与利用优化算法更新参数。</p><blockquote><p>with tf.Session() as sess:</p><p>&nbsp;&nbsp;&nbsp; sess.run(init)</p><p>&nbsp;&nbsp;&nbsp; for i in range(1000):</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; batch_xs, batch_ys = &nbsp;mnist.train.next_batch(100)</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(train_step, feed_dict={x: &nbsp;batch<em>xs, y</em>: batch_ys})</p></blockquote><p>其中，迭代了1000次，每次输入了100个样本。mnist.train.next_batch 就是生成下一个 batch 的数据，这里知道它在干什么就可以。那么训练结果如何呢，需要进行评估。这里使用单纯的正确率，正确率是用取最大值索引是否相等的方式，因为正确的 label 最大值为1，而预测的 label 最大值为最大概率。</p><blockquote><p>correct<em>prediction = &nbsp;tf.equal(tf.argmax(y,1), tf.argmax(y</em>,1))</p><p>accuracy = tf.reduce_mean(tf.cast(correct_prediction, &nbsp;tf.float32))</p><p>print(sess.run(accuracy, &nbsp;feed<em>dict={x: mnist.test.images, y</em>: mnist.test.labels}))</p></blockquote><p>至此，我们开发了一个简单的手写数字识别模型。</p><p><strong><span style="color: rgb(247, 150, 70); font-size: 20px;">总结</span></strong><br></p><p>总结全文，我们首先介绍了 graph 与 session，并解释了基础数据结构，讲解了一些Variable需要注意的地方并介绍了 placeholders 与 feed_dict 。最终以一个手写数字识别的实例将这些点串起来，希望可以给想要入门的你一丢丢的帮助。<span style="color: rgb(255, 255, 255);">雷锋网</span></p><p>雷锋网版权文章，未经授权禁止转载。详情见<a href="http://dwz.cn/4ErMxZ" rel="nofollow" target="_blank">转载须知</a>。</p>                                              <img alt="TensorFlow极速入门" src="http://static.leiphone.com/uploads/new/category/pic/201611/5825e462dfd3f.jpg?imageMogr2/thumbnail/!740x140r/gravity/Center/crop/740x140/quality/90"><p></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.leiphone.com/news/201702/vJpJqREn7EyoAd09.html&quot;&gt;AI研习社&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://static.leiphone.com/uploads/new/article/740_740/201702/589ee26746f0a.jpg?imageMogr2/format/jpg/quality/90&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;目前，深度学习已经广泛应用于各个领域，很多童鞋想要一探究竟，这里抛砖引玉的介绍下最火的深度学习开源框架tensorflow。&lt;/p&gt;
&lt;p&gt;雷锋网按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于深度学习技术的探索，对新事物有着强烈的好奇心。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow基本用法</title>
    <link href="http://ipcreator.me/2017/02/13/Program/TensorFlow/simple-understanding-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/13/Program/TensorFlow/simple-understanding-of-tensorflow/</id>
    <published>2017-02-13T01:10:06.000Z</published>
    <updated>2017-02-17T15:31:31.983Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://yjango.gitbooks.io/superorganism/content/tensorflowji_ben_yong_fa.html" target="_blank" rel="external">yjango</a></p>
<p><img src="https://yjango.gitbooks.io/superorganism/content/T1m6Z_B5KT1RXrhCrK.jpg" alt=""></p>
<p>目前主流的TensorFlow。用tensorflow这样工具的原因是：它允许我们用计算图（Computational Graphs）的方式建立网络。同时又可以非常方便的对网络进行操作。下面就是对计算图的直观讲解。</p>
<p>注：看完这部分内容的人，可以紧接着实现一个神经网络：<a href="https://yjango.gitbooks.io/superorganism/content/dai_ma_yan_shi.html" target="_blank" rel="external">代码演示LV1</a>。</p>
  <a id="more"></a>
<h2 id="比喻说明："><a href="#比喻说明：" class="headerlink" title="比喻说明："></a>比喻说明：</h2><p><strong>结构</strong>：而计算图所建立的只是一个网络框架。在编程时，并不会有任何实际值出现在框架中。所有权重和偏移都是框架中的一部分，初始时至少给定初始值才能形成框架。因此需要initialization初始化。</p>
<p><strong>比喻</strong>：计算图就是一个管道。编写网络就是搭建一个管道结构。在投入实际使用前，不会有任何液体进入管道。而神经网络中的权重和偏移就是管道中的阀门，可以控制液体的流动强弱和方向。在神经网络的训练中，阀门会根据数据进行自我调节、更新。但是使用之前至少要给所有阀门一个初始的状态才能形成结构。用计算图又允许我们可以从任意一个节点处取出液体。</p>
<h2 id="用法说明："><a href="#用法说明：" class="headerlink" title="用法说明："></a>用法说明：</h2><p>请类比管道构建来理解计算图的用法</p>
<h3 id="构造阶段（construction-phase）：组装计算图（管道）"><a href="#构造阶段（construction-phase）：组装计算图（管道）" class="headerlink" title="构造阶段（construction phase）：组装计算图（管道）"></a>构造阶段（construction phase）：组装计算图（管道）</h3><p><strong>计算图（graph）</strong>：要组装的结构。由许多操作组成。<br><strong>操作（ops）</strong>：接受（流入）零个或多个输入（液体），返回（流出）零个或多个输出。<br><strong>数据类型</strong>：主要分为张量（tensor）、变量（variable）和常量（constant）<br><strong>张量</strong>：多维array或list（管道中的液体）<br><strong>创建语句</strong>： tensor_name=tf.placeholder(type, shape, name)<br><strong>变量</strong>：在同一时刻对图中所有其他操作都保持静态的数据（管道中的阀门）<br><strong>创建语句</strong>： name_variable = tf.Variable(value, name)<br><strong>初始化语句</strong>：</p>
<p>#个别变量<br>init_op=variable.initializer()</p>
<p>#所有变量<br>init_op=tf.initialize_all_variables()</p>
<p>#注意：init_op的类型是操作（ops），加载之前并不执行<br><strong>更新语句</strong>： update_op=tf.assign(variable to be updated, new_value)<br><strong>常量</strong>：无需初始化的变量<br>创建语句：name_constant=tf.constant(value)</p>
<h3 id="执行阶段（execution-phase）：使用计算图（获取液体）"><a href="#执行阶段（execution-phase）：使用计算图（获取液体）" class="headerlink" title="执行阶段（execution phase）：使用计算图（获取液体）"></a>执行阶段（execution phase）：使用计算图（获取液体）</h3><p><strong>会话</strong>：执行（launch）构建的计算图。可选择执行设备：单个电脑的CPU、GPU，或电脑分布式甚至手机。<br><strong>创建语句</strong>：</p>
<p>#常规<br>sess = tf.Session()</p>
<p>#交互<br>sess = tf.InteractiveSession()</p>
<p>#交互方式可用tensor.eval()获取值，ops.run()执行操作</p>
<p>#关闭<br>sess.close()<br><strong>执行操作</strong>：使用创建的会话执行操作<br><strong>执行语句</strong>：sess.run(op)<br><strong>送值（feed）</strong>：输入操作的输入值（输入液体）<br><strong>语句：sess.run([output], feed_dict={input1:value1, input2:value1})
</strong>取值（fetch）<strong>：获取操作的输出值（得到液体）
</strong>语句**：</p>
<p>#单值获取<br>sess.run(one op)</p>
<p>#多值获取<br>sess.run([a list of ops])</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://yjango.gitbooks.io/superorganism/content/tensorflowji_ben_yong_fa.html&quot;&gt;yjango&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://yjango.gitbooks.io/superorganism/content/T1m6Z_B5KT1RXrhCrK.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;目前主流的TensorFlow。用tensorflow这样工具的原因是：它允许我们用计算图（Computational Graphs）的方式建立网络。同时又可以非常方便的对网络进行操作。下面就是对计算图的直观讲解。&lt;/p&gt;
&lt;p&gt;注：看完这部分内容的人，可以紧接着实现一个神经网络：&lt;a href=&quot;https://yjango.gitbooks.io/superorganism/content/dai_ma_yan_shi.html&quot;&gt;代码演示LV1&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>这一年来，数据科学家都用了哪些算法玩转人工智能？</title>
    <link href="http://ipcreator.me/2017/02/13/Program/Concepts/ai-and-algorithms/"/>
    <id>http://ipcreator.me/2017/02/13/Program/Concepts/ai-and-algorithms/</id>
    <published>2017-02-13T00:58:06.000Z</published>
    <updated>2017-02-27T03:50:54.931Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dy.163.com/v2/article/detail/CCBLQGO50511CUKV.html" target="_blank" rel="external">作者：刘志勇</a></p>
<p> 在“数据为王”的今天，越来越多的人对数据科学产生了兴趣。数据科学家离不开算法的使用，那么，数据科学家最常用的算法，都是哪些呢？</p>
<p> 　　最近，著名的资料探勘信息网站KDnuggets策划了十大算法调查，这次调查对数据科学家常用的算法进行排名，并发现最“产业”和最“学术”的算法，还对这些算法在过去5年间（2011~2016）的变化，做了一番详细的介绍。</p>
<p> 　　这次调查结果，是基于844名受访者投票整理出来。</p>
<p> 　　KDnuggets总结出十大算法及其投票份额如下：</p>
 <div align="center"><br><img src="http://dingyue.nosdn.127.net/XxbMqsswitgYGAfXTPRKrIW4J7xo9xrldOfRmWTK4cRxm1486093692046.jpg" width="483" height="379"><br> </div>

<p> 　　图1：数据科学家使用的十大算法和方法。</p>
<p> 　　请参阅文末的所有算法和方法的完整列表。</p>
  <a id="more"></a>
<p>  从调查中得知，受访者平均使用8.1个算法，与2011年的一项类似调查相比大幅提高。</p>
<p>　　与用于数据分析/数据挖掘的2011年投票算法相比，我们注意到流行的算法仍然是 <strong>回归算法、聚类算法、决策树和可视化</strong>。相对来说最大的增长是以(pct2016/pct2011-1)测定的以下算法：</p>
<p>　　Boosting，从2011年的23.5％至2016年的32.8％，同比增长40％</p>
<p>　　文本挖掘，从2011年的从27.7％至2016年的35.9％，同比增长30％</p>
<p>　　可视化，从2011年的从38.3％至2016年的48.7％，同比增长27％</p>
<p>　　时间序列分析，从2011年的从29.6％至2016年的37.0％，同比增长25％</p>
<p>　　异常/偏差检测，从2011年的从16.4％至2016年的19.5％，同比增长19％</p>
<p>　　集合方法，从2011年的从28.3％至2016年的33.6％，同比增长19％</p>
<p>　　支持向量机，从2011年的从28.6%至2016年的33.6%，同比增长18%</p>
<p>　　回归算法，从2011年的从57.9%至2016年的67.1%，同比增长16%</p>
<p>　　在2016年最受欢迎的新算法是：</p>
<p>　　K-近邻算法（K-nearest neighbors，KNN），46%份额</p>
<p>　　主成分分析（Principal Commponent Analysis，PCA），43%</p>
<p>　　随机森林算法（Random Forests，RF），38%</p>
<p>　　最优化算法（Optimization），24%</p>
<p>　　神经网络-深度学习（Neural networks-Deep Learning），19%</p>
<p>　　奇异值矩阵分解（Singular Value Decomposition，SVD）， 16%</p>
<p>　　跌幅最大的算法分别为：</p>
<p>　　关联规则（Association rules），从2011年的28.6%至2016年的15.3%，同比下降47%</p>
<p>　　增量建模（Uplift modeling），从2011年的4.8%至2016年的3.1%，同比下降36%</p>
<p>　　因子分析（Factor Analysis），从2011年的18.6%至2016年的14.2%，同比下降24%</p>
<p>　　生存分析（Survival Analysis），从2011年的9.3%至2016年的7.9%，同比下降15%</p>
<p>　　下表显示了不同算法类型的用途：监督学习、无监督学习、元分析和其他算法类型。我们排除了NA（4.5%）和其他（3%）的算法。</p>
<p>　　表1：按行业类型的算法使用</p>
<p><img src="http://dingyue.nosdn.127.net/ntwXZpw4Bb3WyNEhTyj=uuYBbfm33CuG7xN39p8gl0jBi1486093692046.png" alt=""></p>
<p>　　我们注意到，<strong>几乎所有人都在使用监督学习算法。</strong></p>
<p>　　政府和产业的数据科学家们比学生或学术界使用了更多的不同类型的算法，产业数据科学家更倾向使用元算法。</p>
<p>　　接下来，我们分析深度学习的十大算法按行业类型的使用。</p>
<p>　　表2：深度学习的十大算法按就业类型的使用</p>
<p>　　Table 2: Top 10 Algorithms + Deep Learning usage by Employment Type</p>
<p><img src="http://dingyue.nosdn.127.net/jKPaTvdZef=C9pjg2oJMqtjCL4r=yPtcbAuwC1wu2enku1486093692047.png" alt=""></p>
<p>　　为了使差异更为醒目，我们计算特定行业类型相关的平均算法使用量设计算法为Bias(Alg,Type)=Usage(Alg,Type)/Usage(Alg,All)-1。</p>
<p><img src="http://dingyue.nosdn.127.net/kIMsTkLRjPKcCrbJUvn3l9xYXId6FU6AH7vq0uDkrbpkE1486093692047.jpg" alt=""></p>
<p>　　图2：按行业的算法使用偏差</p>
<p>　　我们注意到产业界数据科学家更倾向使用回归算法、可视化、统计算法、随机森林算法和时间序列。政府/非盈利组织更倾向使用可视化、主成分分析和时间序列。学术研究人员更倾向使用主成分分析和深度学习。学生通常使用算法较少，但他们用的更多的是文本挖掘和深度学习。</p>
<p>　　接下来，我们看看代表整体KDnuggets访客的地区参与情况。</p>
<p>　　参与投票者的地区分布如下：</p>
<p>　　北美，40%</p>
<p>　　欧洲，32%</p>
<p>　　亚洲8%</p>
<p>　　拉美，5.0%</p>
<p>　　非洲/中东，3.4%</p>
<p>　　澳洲/新西兰，2.2%</p>
<p>　　与2011年的调查一样，我们将产业/政府合并为同一个组，将学术研究人员/学生合并为第二组，并计算算法对产业/ 政府的“亲切度”：</p>
<p><img src="http://dingyue.nosdn.127.net/FfcG4w9Bk4rRwETEVJTT6mwiYrbfLB9sVSKlkqD7rYRIh1486093692047.jpg" alt=""></p>
<p>　　N(Alg,Ind_Gov) / N(Alg,Aca_Stu)<br>　　——————————- - 1<br>　　N(Ind_Gov) / N(Aca_Stu)<br>　　<br>　　亲切度为0的算法在产业/政府和学术研究人员/学生的使用情况相同。IG亲切度约稿表示该算法越“产业”，越低则表示越“学术”。</p>
<p>　　其中最“产业”的算法”是：</p>
<p>　　增量建模（Uplift modeling），2.01</p>
<p>　　异常检测（Anomaly Detection），1.61</p>
<p>　　生存分析（Survival Analysis），1.39</p>
<p>　　因子分析（Factor Analysis），0.83</p>
<p>　　时间序列（Time series/Sequences），0.69</p>
<p>　　关联规则（Association Rules），0.5</p>
<p>　　虽然增量建模又一次成为最“产业”的算法，但出乎意料的是它的使用率如此低：区区3.1%，在这次调查中，是使用率最低的算法。</p>
<p>　　最“学术”的算法是：</p>
<p>　　神经网络（Neural networks - regular），-0.35</p>
<p>　　朴素贝叶斯（Naive Bayes），-0.35</p>
<p>　　支持向量机（SVM），-0.24</p>
<p>　　深度学习（Deep Learning），-0.19</p>
<p>　　最大期望算法（EM），-0.17</p>
<p>　　下图显示了所有算法以及它们在产业界/学术界的亲切度：</p>
<p><img src="http://dingyue.nosdn.127.net/zq9JX56Yi4FQSr5aAOuc2RYQhfvcTwzd5E=deUDVsOGAF1486093692048compressflag.png" alt=""></p>
<p>　　图3：Kdnugets调查：数据科学家使用的流行算法：产业界vs学术界</p>
<p>　　下表包含了算法的详细信息，在2016年和2011年使用它们的受访者百分比调查，变化（％2016 /％2011 - 1）和行业亲切度如上所述。</p>
<p>　　表3：KDnuggets2016调查：数据科学家使用的算法</p>
<p>　　下表包含各个算法的详细信息：</p>
<p>　　N: 根据使用度排名</p>
<p>　　Algorithm: 算法名称</p>
<p>　　Type：类型。S - 监督，U - 无监督，M - 元，Z - 其他，</p>
<p>　　2016 % used：2016年调查中使用该算法的受访者比例</p>
<p>　　2011 % used：2011年调查中使用该算法的受访者比例</p>
<p>　　%Change：变动 (%2016 / %2011 - 1)</p>
<p>　　Industry Affinity：产业亲切度（上文已提到）</p>
<p>　　感谢杜小芳对本文的审校。</p>
<h2 id="AI研究院-AI学习方式越来越像人-却越来越不靠谱？"><a href="#AI研究院-AI学习方式越来越像人-却越来越不靠谱？" class="headerlink" title="AI研究院 | AI学习方式越来越像人 却越来越不靠谱？"></a>AI研究院 | AI学习方式越来越像人 却越来越不靠谱？</h2><p>　　<img src="http://dingyue.nosdn.127.net/58iCfNN6VzwiCVQO5Vxz3WD4ioIs4ph5rvIWQr=0UbFE71486189069842.jpg" alt=""></p>
<p>　　【AI研究院 | 网易智能工作室倾力打造的人工智能行业专业栏目，聚焦行业，深度分析，只为专业】</p>
<p>　　网易智能讯 2月4日报道，据《连线》杂志报道，神经网络正风靡整个硅谷，无数的互联网服务中嵌入各种各样的人工智能（AI）。令人感到激动的是，最好的AI已经可以识别网络照片中的猫咪。但AI研究人员知道，神经网络依然存在许多缺陷。实际上，它们的缺陷非常多，以至于有些人怀疑这些模式识别系统是否是实现AI的可行、可靠方式。</p>
<p>　　神经网络可以通过分析大量数据来学习和了解任务，比如帮助Facebook进行面部识别、帮助微软进行翻译、帮助谷歌进行互联网搜索等。它们甚至已经开始帮助聊天机器人学习对话艺术。它们正成为无人驾驶汽车和其他自动化机器的重要组成部分。但是在没有大量经过仔细标注的数据的帮助下，它们就无法理解世界的意义，它们不适合执行任何任务。AI研究人员很想知道，为何神经网络在做出具体决定时受到如此多的限制？在很多情况下，它们实际上就是“黑盒子”。这种不透明会引发严重问题：如果无人驾驶汽车向着某人撞去，结果会如何？</p>
<p>　　卡内基梅隆大学计算机学教授、帮助开发顶级扑克人工智能系统Libratus的托马斯·桑德霍尔姆（Tuomas Sandholm）说：“深度学习已经受到许多关注，它当之无愧。但是深度学习并不能给你提供任何保证。”这是真的，但也正是因为神经网络存在这些明显弱点，许多世界上最大的科技公司正在扩展它们的AI思维，从最近的招聘、收购、研究动向中作出判断，许多初创企业也正涌往相同的方向。</p>
<p>　　你可能认为这是贝叶斯算法(bayesian)的崛起，这类研究人员通常以科学方法研究AI，他们最初从假设开始，然后基于数据更新这个假设，而非像人经网络那样依赖数据去驱动结论。<strong>贝叶斯算法的研究人员寻找处理不确定性的方法，将新的证据输入到现有模型中，可以执行神经网络不擅长的工作。</strong></p>
<p>　　与神经网络相似的是，贝叶斯算法也可以通过数据进行学习，但是这种机器学习可通过不同的方式进行。AI初创企业Gamalon创始人本·魏格达（Ben Vigoda）说：“令我们感兴趣的是自动化科学方法。”他的公司正通过所谓的“概率规划”计划推动这种趋势。</p>
<p>　　这再次提醒我们，神经网络的快速崛起也将生命注入到许多其他技术中，这些技术可帮助机器变得更加聪明，从强化学习到进化计算等。有许多方法，可以帮助机器进行学习。</p>
<p>　　神秘技术</p>
<p>　　2016年12月份，当加里·马库斯（Gary Marcus）将15人的初创企业卖给Uber时，他带着全新的AI到来。至少他是那样说的。他的公司叫做几何智能（Geometric Intelligence），一个小小的操作就能做出巨大改变。这位现年47岁的纽约大学心理学教授说，他与同事们正在开发能够从很少数据中学习任务的系统，这与人类十分相似，同时超越了深度神经网络的力量。</p>
<p>　　马库斯认为，小数据系统是建造机器必不可少的部分。这些机器可自主进行交谈，汽车也可以自己在公路上行驶。当Uber宣布收购Geometric Intelligence时，马库斯说：“在语言领域和无人驾驶汽车领域，你永远不会有足够数据像深度学习那样产生野蛮之力，这会产生许多问题。毕竟，你不能在繁忙的公路上撞车以便数据，用以预防将来发生车祸。你也不能购买它，它根本不存在。”</p>
<p>　　马库斯和他的联合创始人、剑桥大学信息工程学教授左斌·加拉玛尼(Zoubin Ghahramani)依然没有探讨他们正在开发的技术的具体细节。就像技术界常见的情况，特别是AI领域，这种保密性通常会催生“神秘感”。但是加拉玛尼是贝叶斯算法的支持者之一。他专门从事名为“高斯过程（Gaussian process）”的特殊统计模型，而这种模型在马库斯开发的技术中发挥了重要作用。</p>
<p>　　高斯过程</p>
<p>　　<strong>在某种层次上，高斯过程是寻找特定问题最优解决方案的方式。同时，它也是另一种名为贝叶斯优化的数学技术的基础。</strong> 到目前为止，高斯过程已经帮助网站确定应该显示哪些广告，以及它们的网页应该如何排版。Uber已经招募擅长高斯过程的专家，改善其拼车服务。在谷歌，高斯过程帮助控制该公司的高空联网气球。</p>
<p>　　<strong>从根本上说，高斯过程是确定不确定性的最佳方式。</strong> 爱丁堡大学AI研究员克里斯·威廉姆斯（Chris Williams）说：“知道你不知道的事情是件好事，而犯下自信的错误是你能做到的最糟糕的事情。”</p>
<p>　　在2015年被Twitter收购的初创企业Whetlab，该技术提供了设计神经网络的更好方式。设计神经网络是个充满错误的实验过程，你没有编写软件那么多的编码，以便于从海量数据中学习。这是个困难、耗时的过程，但高斯过程和贝叶斯优化可帮助自动化这些任务。正如WhetLab创始人、哈佛大学计算机科学家赖安·亚当斯（Ryan Adams）所说，他的公司使用机器学习技术改善机器学习技术。神经网络可能会遇到“信心错误”问题，在识别不确定性方面，这种优化可帮助处理问题。亚当斯已经离开Twitter，加盟了谷歌AI团队Google Brain。</p>
<p>　　有些研究人员还认为，<strong>小数据驱动的高斯过程在推动AI自动化方面可能会发挥关键作用</strong>。AI初创企业Prowler首席执行官维沙尔·查特拉斯（Vishal Chatrath）说：“为了开发真正的自动化代理人，它必须能够非常迅速地适应环境。这意味着，它需要以高效的方式学习。高斯过程可轻松胜任。与神经网络不同，它们没有‘黑盒子’问题的负担。如果发生意外，你可以追踪到源头。”</p>
<p>　　不要恐慌</p>
<p>　　在Prowler，查特拉斯已经招募了3名技术专家。之所以将总部选在剑桥，因为这里有许多人是高斯过程及其相关技术的专家。这家公司正开发新的AI系统，它可以学习浏览大型多人游戏和其他数字数节。这是个复杂的过程，但他们希望将来AI系统能出现在真实世界中</p>
<p>　　与此同时，亚马逊也招募了擅长贝叶斯算法技术的AI研究人员，即舍费尔德大学计算机科学家尼尔·劳伦斯（Neil Lawrence）。劳伦斯最近在帖文中指出：“无需感到惊慌，<strong>通过使用我们的数学工具可以探索新一轮的深度学习方法</strong>。我们可以保证，它们大多数都是无害的。”（小小）</p>
<p>　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
<h2 id="识别假新闻与NLP有何不同-为何连FB都搞不定？"><a href="#识别假新闻与NLP有何不同-为何连FB都搞不定？" class="headerlink" title="识别假新闻与NLP有何不同 为何连FB都搞不定？"></a>识别假新闻与NLP有何不同 为何连FB都搞不定？</h2><p>　　【网易智能讯 1月16日消息】假新闻成为新闻头条已达几个月，现在一组研究人员试图运用AI技术来解决假新闻难题。</p>
<p>　　<img src="http://dingyue.nosdn.127.net/lQunouULVzWQQKzQsrHNVIMn2Xhde75VsXiFp=cMOdMPf1484574444143.jpg" alt=""></p>
<p>　　卡内基梅隆大学副教授迪恩·波美勒（Dean Pomerleau）发起一项挑战，声称如果有人开发出能准确发现假新闻的AI算法，他将奖赏研究者2000美元。</p>
<p>　　与此同时一些硅谷大公司——比如谷歌和Facebook——也在解决努力解决这个问题。开发AI算法来解决假新闻。</p>
<p>　　但识别假新闻与其他AI算法的成功（比如图像识别和自然语言处理）不同，<strong>假新闻千变万化，本质上的多变性决定其难以抓取模式特征。</strong> 制服假新闻要求AI系统多一层判断，而这是今日之AI还不具备的能力。</p>
<p>　　除了这个问题，竞争或许更能见证AI的进化。未来研究人员能够开发出比今日更优秀的工具。</p>
<p>　　此外他还更详细地介绍了研究人员在解决假新闻过程中将要面临的挑战和机遇，以及他们的成败如何反映当今AI的发展状态。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dy.163.com/v2/article/detail/CCBLQGO50511CUKV.html&quot;&gt;作者：刘志勇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; 在“数据为王”的今天，越来越多的人对数据科学产生了兴趣。数据科学家离不开算法的使用，那么，数据科学家最常用的算法，都是哪些呢？&lt;/p&gt;
&lt;p&gt; 　　最近，著名的资料探勘信息网站KDnuggets策划了十大算法调查，这次调查对数据科学家常用的算法进行排名，并发现最“产业”和最“学术”的算法，还对这些算法在过去5年间（2011~2016）的变化，做了一番详细的介绍。&lt;/p&gt;
&lt;p&gt; 　　这次调查结果，是基于844名受访者投票整理出来。&lt;/p&gt;
&lt;p&gt; 　　KDnuggets总结出十大算法及其投票份额如下：&lt;/p&gt;
 &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://dingyue.nosdn.127.net/XxbMqsswitgYGAfXTPRKrIW4J7xo9xrldOfRmWTK4cRxm1486093692046.jpg&quot; width = &quot;483&quot; height = &quot;379&quot; &gt;&lt;br&gt; &lt;/div&gt;

&lt;p&gt; 　　图1：数据科学家使用的十大算法和方法。&lt;/p&gt;
&lt;p&gt; 　　请参阅文末的所有算法和方法的完整列表。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
      <category term="Algorithm" scheme="http://ipcreator.me/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>避免炒作，如何寻找有价值的人工智能初创企业？</title>
    <link href="http://ipcreator.me/2017/02/13/BusinessAI/how-to-find-ai-start-up-firm/"/>
    <id>http://ipcreator.me/2017/02/13/BusinessAI/how-to-find-ai-start-up-firm/</id>
    <published>2017-02-13T00:58:06.000Z</published>
    <updated>2017-02-27T03:43:35.604Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dy.163.com/v2/article/detail/CCBUQLJG0511CUKV.html" target="_blank" rel="external">作者：网易AI研究院</a></p>
<p><img src="http://dingyue.nosdn.127.net/IU0mHBufDYJuCfqTLNrBB2w5XVt7aFWiewNOPCU=XBFoJ1486103192435compressflag.png" alt=""></p>
<p>　　据国外媒体报道，毫无疑问现在人工智能概念已经牢牢抓住了公众想象力和媒体的眼球，也带来了大量的业内投资和收购。在新一轮的炒作周期中，投资者该如何辨别相关的人工智能到底是炒作还是真正的现实，这将是一个挑战。</p>
<p>　　日前，科技网站venturebeat采访了CRV, IA Ventures, Two Sigma等知名投资公司中经验丰富的风险投资人，从而深入探究这些成功的投资者是如何评估一家人工智能初创公司的。如果你也是一名人工智能相关创业公司的创始人，在投资者面前需要回答好以下的关键问题：</p>
  <a id="more"></a>
<h2 id="人工智能是公司的核心价值所在吗？"><a href="#人工智能是公司的核心价值所在吗？" class="headerlink" title="人工智能是公司的核心价值所在吗？"></a>人工智能是公司的核心价值所在吗？</h2><p>  　　投资公司Qualcomm Ventures的风险投资人Varun Jain坦言，“很多陷入资金困境的公司都会将自己包装成人工智能企业。”Varun Jain列举了从人工智能路由器到人工智能榨汁机等产品和设备。</p>
<p>  　　Varun Jain解释称，在很多情况下，公司所宣传的人工智能仅仅是一个附加功能，而不是公司的核心价值。他指出，“传统的WiFi路由器可以使用人工智能技术来检测网络中的异常数据，但路由器的功能并不会有实质性的改变。”</p>
<p>  　　相比之下，Qualcomm Ventures投资了Clarifai和Cruise Automation等真正的人工智能初创企业，而Cruise Automation已经被通用收购。Cruise Automation通过人工智能技术为自动驾驶汽车供电，而Clarifai则是利用先进的深度学习和计算机视觉技术来识别图像和视频中的特定物体。</p>
<h2 id="技术团队有多可靠？"><a href="#技术团队有多可靠？" class="headerlink" title="　　技术团队有多可靠？"></a>　　技术团队有多可靠？</h2><p>  　　CRV公司的风险投资人Max Gazor指出，“具备先进人工智能技术的公司往往拥有顶尖的技术人才，他们或者来自业内先进研究实验室，或是来自诸如Google Brain或Facebook人工智能团队等知名行业组织。”</p>
<p>  　　CRV对技术的追求直接体现在他们的投资行为中，他们投资的公司创始人普遍具有非凡的技术经验。初创企业Rethink Robotics创始人Rod Brooks是麻省理工学院人工智能实验室的创始主管，也是著名机器人公司iRobot的创始人。而Jibo的Cynthia Breazeal也曾在麻省理工大学媒体实验室成立过机器人小组，是一名世界知名的社交机器人专家。Pullstring公司的创始人Oren Jacob也是如此，他曾是皮克斯的首席技术官，自公司成立初期就与史蒂夫乔布斯共事。</p>
<p>  　　而投资公司DCM Capital的创始人David Cheng则指出，“在整个行业生命周期的这一特定阶段，<strong>一个公司拥有一定数量的人工智能专家就能够获得开发技术的必要经验，从而开发真正的创新解决方案。</strong> 如果一个团队声称他们的产品使用了领先的人工智能技术却没有相应的团队，那么我们对此将持怀疑态度。”</p>
<h2 id="能够有效解决客户的实际问题吗？"><a href="#能够有效解决客户的实际问题吗？" class="headerlink" title="　　能够有效解决客户的实际问题吗？"></a>　　能够有效解决客户的实际问题吗？</h2><p>  　　投资公司GE Ventures投资人Michael Dolbec指出，“就我个人而言，一个公司若是仅仅对人工智能夸夸其谈，而毫不涉及客户问题，那我就没有什么兴趣。我们投资的是宝贵的技术成果，而不是科学实验项目。”</p>
<p>  　　每一位投资者对此都表示认同。</p>
<p>  　　IA Ventures的Brad Gillespie补充称，“如果让我在二者中选择其一时，那么一个公司的业务专业知识将胜过其机器学习专业技能。”IA Ventures曾投资了Vectra Networks，这是一家由经验丰富业内专家领导的网络安全公司，专注于为客户解决重要问题，为安全分析师最大限度提高可用性。而Vectra Networks的竞争对手不断强调他们机器学习技术的复杂性，但客户的反应是“这些家伙很聪明，但他们并不理解我的业务是什么。他们的产品很花哨，但我并不明白它到底是什么。”</p>
<p>  　　有效解决客户的业务痛点需要创始团队能够超越狭隘的技术方法，拥有解决特定业务的能力。投资公司Two Sigma Ventures的Colin Beirne指出，“当然，<strong>解决当今大多数困难问题需要不同技术的整合，而在特定业务领域使用人工智能能够在一定程度上降低学习理解的复杂性。</strong>”</p>
<h2 id="是否有相关的，自有或可扩展的数据源？"><a href="#是否有相关的，自有或可扩展的数据源？" class="headerlink" title="　　是否有相关的，自有或可扩展的数据源？"></a>　　是否有相关的，自有或可扩展的数据源？</h2><p>  　　投资公司Qualcomm Ventures的Jain总习惯于这样问创始人，“你是如何获取数据的？你是依托大公司提供的数据，还是独立获取数据？”当然这两种方法都是可行的，但投资人更倾向于创业公司能够独立获取数据。</p>
<p>  　　传统上。自动驾驶汽车会在郊区等封闭环境中进行测试。而Qualcomm所投资的Cruise Automation则通过在开放城市环境中操作测试车辆，整合人工干预的因素，从而获取更多驾驶数据。同样，Qualcomm所投资的Clarifai通过应用程序能够获取更多的数据，通过此也能够处理更多的业务数据。</p>
<p>  　　投资者除了对数据源的独特性和合理性有要求，此外人工智能数据还必须要与其面对的问题密切相关。投资公司Battery Ventures的Dharmesh Thakker指出，“<strong>新一代人工智能技术往往取决于获取数据的复杂程度。诸如图像、音视频等非结构化数据处理要比普通文本困难的多。</strong>”在投资决策中，Dharmesh Thakker还会考虑目标公司处理静态数据和快速移动物体数据的能力。诸如自动驾驶汽车获取的实时图像等快速移动物体数据处理算法通常会复杂很多。</p>
<p>  　　最后，创始团队还需要 <strong>证实其有根据自有数据不断改进产品性能的能力</strong>。Qualcomm的Jain会定期考察团队是否有“快速处理数据并不断优化的能力，从而使系统更加健壮。”</p>
<h2 id="开发独有技术还是依靠开源产品"><a href="#开发独有技术还是依靠开源产品" class="headerlink" title="　　开发独有技术还是依靠开源产品"></a>　　开发独有技术还是依靠开源产品</h2><p>  　　投资公司Verizon Ventures的投资人Suresh Madhavan指出，相比于开发专有技术，依托开源框架往往就像是一种赠品，“<strong>开源的确能够让你分析解决一些表面问题，但无助于从根本上解决有难度的业务问题。</strong>”</p>
<p>  　　DCM Ventures的Cheng也同意这一点。DCM的投资团队背后拥有一个由行业顾问和技术专家组成的强大网络。“（这些专家）帮我们审查团队技术、数据架构方式，并能够确定创业团队进行数据收集、存储、解析的根本方法。他们也帮助我们擦亮眼睛，找出滥竽充数者。”</p>
<h2 id="产品是否有粘性？"><a href="#产品是否有粘性？" class="headerlink" title="　　产品是否有粘性？"></a>　　产品是否有粘性？</h2><p>  　　Sumant Mandal是投资公司March Capital的合伙人，也是The Hive的共同创始人，后者是一家专注于人工智能初创企业的孵化器。Mandal坦言，“<strong>对于人工智能初创企业来说， 如果效率不能提高5到10倍，那么就很难打入市场，从而为投资者带来价值。</strong>”Mandal建议初创企业需要考虑客户的收益。比如要将人工智能用于改进招聘流程，Mandal就建议初创团队要问自己，“如果我能够将相应效率提高5倍，那么能否让客户从雇员身上获得百倍收益？”</p>
<p>  　　此外，Mandal还指出，<strong>价值提升必须要以客户可见的方式提供给客户，譬如以仪表盘或是真正有价值的情报等形式展现出来。</strong> Mandal警告称，虽然人工智能在网络安全领域的应用已经很多，但数据和相关人才的缺乏，导致“安全分析师并不需要过多的警报”。</p>
<p>  　　而即便有一个较为理想的产品，仅仅为客户提供单一的解决方案也不是一个可行的商业模式。Woodside Capital的Kartik Gada建议创业公司要寻求收益以及客户的多元化。“你的收入是否稳健？是否常态化？你的客户是否需要相同或更多的解决方案？”</p>
<h2 id="创业团队是否全面？"><a href="#创业团队是否全面？" class="headerlink" title="　　创业团队是否全面？"></a>　　创业团队是否全面？</h2><p>  　　最后一点，投资者倾向于寻求那些能够解决人工智能业务的多样化团队。投资公司Monsanto Growth Ventures的Kiersten Stead解释称，“多样化意味着团队包括业内专家、商业领袖以及销售精英，而不仅仅是工程技术人员。”</p>
<p>  　　但是，Stead观察到，很多创业团队，特别是那些仅仅由人工智能研究人员组成的技术团队，并没有特定行业的相关经验，更容易失败。在农业技术开发和遗传育种方面尤为如此。</p>
<p>  　　她强调，“人工智能技术团队在销售上有短板，反之亦然。我们会寻找行业经验丰富的人工智能企业创始人，他们往往有完整成熟的职业生涯，可与各类人组成一个多样化的团队。”人工智能企业往往会忽视销售和营销，但这对于成功非常重要。</p>
<p>  　　投资公司Woodside Capital的Gada也警告称，“<strong>很多人工智能初创企业犯下的最大错误就是完全无视营销的重要性。很多客户根本不知道他们需要这些产品。</strong>”（晗冰）</p>
<h2 id="AI研究院-企业做人工智能转型有四大关键要素"><a href="#AI研究院-企业做人工智能转型有四大关键要素" class="headerlink" title="AI研究院 | 企业做人工智能转型有四大关键要素"></a>AI研究院 | 企业做人工智能转型有四大关键要素</h2><p>  　　【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】</p>
<p>  　　<img src="http://dingyue.nosdn.127.net/qvgJyuC8=PfZZvxXgv1ME7yu5vNchInjJQ74zChPxAvSr1486702463725compressflag.jpg" alt=""></p>
<p>  　　网易智能讯 2月10日消息，在很多行业我们都已接近人工智能技术发展的临界点，包括自动驾驶汽车、蜂巢无人机、自动售货等。如今一个公司无论规模大小如何，都必须了解人工智能将怎样影响、甚至消灭某个行业，以及学会利用人工智能和机器学习（ML）。</p>
<p>  　　对于企业来说这是一个至关重要的选择——是投身到人工智能领域还是保持现状等着被淘汰，前者可以更有效地帮助企业实现商业目标。人工智能—机器学习将令我们的日常生活更加美好高效，把现有工作提升到更加精确、有效的水平。</p>
<p>  　　像优步、谷歌和Facebook这样的科技创新公司，通过收购和内部组织的转型，在人工智能领域进行了大胆尝试，使它成为一项战略重点。在2017年达沃斯论坛上，世界各国领导人探讨了人工智能对就业的影响，以及哪些行业适合应用这项技术。</p>
<p>  　　事实上，根据互联网数据中心（IDC）的数据显示，到2020年，企业在人工智能方面的投入将从2016年的80亿美元飙升至470亿美元。另外，到2019年，将会有超过1.1亿个安装了嵌入式智能助手的设备走进美国家庭。</p>
<p>  　　Intuit公司的人工智能转型始于4年前，当时业内都在探讨两个问题：金融软件的未来是什么；我们在帮助客户方面扮演怎样的角色。人工智能的趋势在当时是很明显的，包括工作的个性化、自动化、增强和速度等，这些都需要软件来进行辅助。近年来，随着人工智能技术的进步，我们对它的看法也作出了改变。</p>
<p>  　　现在我们将人工智能看作一种为用户提供方便的技术。我们预计人工智能将创造新技术，例如以一种曾经无法想象的高科技方法为消费者处理税务、为小型企业完成账目记录等。但要实现这一目标并非易事。Intuit公司拥有30多种人工智能和机器学习模型，可以在实时体验中接触客户，而且我们还在不断作出新的尝试。我们在实验和成果中不断学习、发展和改进技术。</p>
<p>  　　如果你的公司致力于通过人工智能打造能够满足消费者需求的产品和服务，那么这里有几个关键的问题需要考虑。</p>
<p>  　　<strong>1.重视数据</strong></p>
<p>  　　每一家公司的人工智能探索之旅都从数据开始。数据令机器学习和人工智能更强大。如果你一直在考虑如何利用数据，那么现在就可以开始制定和实施计划了。</p>
<p>  　　在Intuit，我们几年前就已经转向了对数据的关注。我们在与业务部门同事进行沟通后制定了技术路线，充分了解了客户需求、行业趋势以及数据能够带来的客户利益。我们的Intuit Analytics Cloud云分析系统打破了一些障碍，让我们能够以更全面地认识产品产生的海量数据。在拥有人工智能或机器学习模型之前，我们就开始专注于数据分析和个性化的基础性工作。<strong>可靠、快速、准确的数据是人工智能—机器学习发展的催化剂。</strong></p>
<p>  　　<strong>2.展望未来</strong></p>
<p>  　　设想公司的未来是很重要的，同时也要观察人工智能将如何令你更加强大，或者改变你对研发工作的想法。我们在Intuit进行了一场活动，会见了各种各样的组织和个人，包括大学的学者专家、创业公司、风投公司等，探讨了人工智能和机器学习的未来蓝图，以及Intuit公司将如何适应这一转变。规模较小的公司同样可以在相应的资源范围内做出创新。</p>
<p>  　　<strong>3.转变心态</strong></p>
<p>  　　在开始阶段向业务部门和产品负责人解释投资人工智能的益处，可能是一件很有挑战性的事情。重要的是每个季度的客户利益需要体现在商业价值上，而不是单纯研究数据。例如，Intuit的税务分析系统就分析了3000万客户的纳税申报表，对分项扣除还是统一扣除作出相应建议，这可以节省40%的税收工作准备时间。这样一个甚至非数据专家都能理解的切实的商业成果。可以说，<strong>人工智能—机器学习是一段探索之旅。通过实际产生的影响来预估潜在的成果</strong>，这是很重要的。</p>
<p>  　　4.成立团队，选择项目</p>
<p>  　　要在企业中开始发展人工智能，先选择一个容易解决的业务问题，组件一支跨职能员工团队，包括数据科学家、工程师和质量监管人员，同时要注意及时更新团队。在团队中建立起能够理解实验价值的文化。珍惜从人工智能应用中得来的知识。另外，你的团队还应同时拥有专业知识和实战经验。千万不要认为只需要聘请专家。同时，在亟待解决的问题上还需要保持与其他行业科学家的互动，比如其他领域的博士等，他们天生具有好奇心，能够理解科学原理，并且有一套不同的解决方案。<strong>真正的人工智能—机器学习可以在应用数据科学方面带来重大成果。</strong> 不要低估了它的重要性，同时也要改变心态。</p>
<p>  　　我们才刚刚到达人工智能和机器学习的起步阶段。<strong>在公司初创之时紧跟最先进的技术，将有助于你在未来发展中处于优势地位。</strong></p>
<p>  　　（来源/VentureBeat 翻译/机器小易 审校/小ka）</p>
<p>  　　注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。</p>
<h2 id="人工智能的迅速崛起需要警惕这四大风险"><a href="#人工智能的迅速崛起需要警惕这四大风险" class="headerlink" title="人工智能的迅速崛起需要警惕这四大风险"></a>人工智能的迅速崛起需要警惕这四大风险</h2><p><img src="http://dingyue.nosdn.127.net/ydgEN7xEoWpsGyUkJBKbgdXlwrf5u91jceEc1KE5IZXI=1484981995496compressflag.jpg" alt=""></p>
<p>　　【网易智能讯 1月21日消息】大家可以想象一下，一名营销主管深夜翻看公司的幻灯片，该公司承诺利用人工智能（AI）自动化他的评分过程、优化他的广告开支方案、帮助增加他的营销开支回报率，他想要知道，哪里可能出现问题？</p>
<p>的确有可能出现问题。尽管公司使用AI会让营销人员的工作变得更简单，但我们必须承认，AI的承诺往往言过其实。AI带来的好处是显而易见的，但也存在巨大风险。即使你找到最好的AI，并将其应用到你的营销技术堆栈中，依然存在影响你成功部署AI的风险。我并不担心这些风险，也不想将它们藏起来，我认为最好是直接面对它们，直至最终解决它们。</p>
<p>AI主要存在四大类危险：</p>
<p><strong>AI危险一：害怕失去工作</strong><br>这是最容易理解的AI危险，同时也是最容易解决的。人们经常害怕AI，因为他们担心AI会让人类变得多余，最终被拥有机器大脑的AI取代我们独特的技能。对于某些工作来说，这可能是真的。但我认为，AI带来的实际危险可能比人类预想的更低。AI还不够先进，也无法全面取代营销专家。如果营销人员学会有效地使用AI，它们反而会增强人类能力。也就是说，为了促使人们购买AI支持的技术，我们首先需要平抚人们对AI的恐惧。</p>
<p><strong>AI危险二：错位的激励</strong><br>技术传道者有时候会深入企业内部，并利用让人惊叹的创意，阐述他们的产品如何改变每个人。但是有了AI和许多企业技术，这些热情常常会撞墙，因为这些墙将各个部门隔离开。事实证明，公司中拥有大量数据的人，往往不会与其他利益相关者分享数据。无论是出于隐私担忧、部门政策、个人冲突亦或是简单的流程偏差，比如障碍往往可能导致雄心勃勃的AI项目被搁置。</p>
<p>为此，到目前为止，两类公司在部署AI时取得最大成功，一类是初创企业（公司规模较小，刚刚创建还没有僵化思维），一类是像谷歌和Facebook这样的大科技公司（其全部生命线都基于对数据的利用）。介于这两类极端公司之间的其他企业，几乎包括世界上所有公司，部署AI都会遇到更大阻碍。想要利用AI提高效率的营销人员需要意识到部门和监管问题，这些问题可能影响到他们。此外，数据价值链上的所有玩家都需要保持一致。</p>
<p><strong>AI危险三：不可预测性</strong><br>这可能是AI固有的最大危险。所有AI项目都是不可预测的，因为它们正被用于解决未知问题。与传统软件开发不同，目前还没有标准的工程方法，可以通过分步获得可预知的AI结果。在这种情况下，将AI应用到营销数据中就像纯粹的科幻。我们不知道特定的数据集是否能解决特定的问题。就像无法预测科学实验的所有结果那样，AI也很难预测结果。这是有关软件开发的全新思维方式，但对任何营销领域或没有AI经验的人来说，这将是个巨大挑战。</p>
<p><strong>AI危险四：人才匮乏</strong><br>这是AI带来的最后危险，阻碍你的团队引入足够的人才。不幸的是，当前AI领域存在巨大的技术鸿沟。AI领域的绝大多数人才都没有真正处理大规模行业数据的经验。而真正的专家还很少，最新统计显示，数据科学家的职位空缺高达1.6万个。这意味着，找到你需要的专业人士，并让他们帮助部署和执行AI驱动的营销计划非常困难。</p>
<p>由于存在这些风险，你可以看到截止到目前许多AI实验都以失败告终。举例来说，麦肯锡最近做了一项研究，对石油和天然气钻探作业决策中的数据进行实时分析。麦肯锡研究的1家公司在离岸钻井仪器方面投入巨资，并通过RFID标签和内嵌传感器收集到大量数据。不幸的是，他们收集的数据中只有40%能传回到陆地数据中心，只有1%能真正进入数据库中，不到1%能被用于终端用户的产品中。最终，这些数据没有为人们的决策提供任何帮助。</p>
<p>不幸的是，你可能发现同样大的阻力。在使用AI过程中，你会遇到强烈的文化阻碍。许多人不相信机器做出的决定，直到机器算法有机会证明自己的决定。营销高管们部署AI面对的挑战是，需要确保所有相关利益者支持他们。确保人们受到相关训练，确保他们对可能结果产生现实期待，并获得正确的激励奖励。</p>
<p>只有做到这些，你才能开始意识到AI革命为营销领域带来的惊人好处。（小小）</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dy.163.com/v2/article/detail/CCBUQLJG0511CUKV.html&quot;&gt;作者：网易AI研究院&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://dingyue.nosdn.127.net/IU0mHBufDYJuCfqTLNrBB2w5XVt7aFWiewNOPCU=XBFoJ1486103192435compressflag.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;　　据国外媒体报道，毫无疑问现在人工智能概念已经牢牢抓住了公众想象力和媒体的眼球，也带来了大量的业内投资和收购。在新一轮的炒作周期中，投资者该如何辨别相关的人工智能到底是炒作还是真正的现实，这将是一个挑战。&lt;/p&gt;
&lt;p&gt;　　日前，科技网站venturebeat采访了CRV, IA Ventures, Two Sigma等知名投资公司中经验丰富的风险投资人，从而深入探究这些成功的投资者是如何评估一家人工智能初创公司的。如果你也是一名人工智能相关创业公司的创始人，在投资者面前需要回答好以下的关键问题：&lt;/p&gt;
    
    </summary>
    
      <category term="理财" scheme="http://ipcreator.me/categories/%E7%90%86%E8%B4%A2/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Business" scheme="http://ipcreator.me/tags/Business/"/>
    
  </entry>
  
  <entry>
    <title>Gentlest Tensorflow</title>
    <link href="http://ipcreator.me/2017/02/13/Program/TensorFlow/gentle-understanding-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/13/Program/TensorFlow/gentle-understanding-of-tensorflow/</id>
    <published>2017-02-13T00:52:06.000Z</published>
    <updated>2017-02-17T15:32:21.943Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/nethsix/gentle_tensorflow/" target="_blank" rel="external">作者：Neth Six</a></p>
<p><img src="https://avatars1.githubusercontent.com/u/1383827?v=3&amp;s=460" alt=""></p>
<h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>Tensorflow (TF) is Google’s attempt to put the power of Deep Learning into the hands of developers around the world. It comes with a beginner &amp; an advanced tutorial, as well as a course on Udacity. However, the materials attempt to introduce both ML and TF concurrently to solve a multi-feature problem — character recognition, which albeit interesting, unnecessarily convolutes understanding. Gentlest Tensorflow attempts to overcome that by showing how to do linear regression for a single feature problem, and expand from there.</p>
  <a id="more"></a>
<h2 id="Cheatsheet"><a href="#Cheatsheet" class="headerlink" title="Cheatsheet"></a>Cheatsheet</h2><p>cheatsheets/tensorflow_cheatsheet_1.png<br>Linear regression: single feature, single scalar outcome<br>Linear regression: multi-feature, single scalar outcome<br>Logistic regression: multi-feature, multi-class outcome<br>Code</p>
<h2 id="All-the-code-are-in-code-directory"><a href="#All-the-code-are-in-code-directory" class="headerlink" title="All the code are in /code directory:"></a>All the code are in /code directory:</h2><p><strong>linear_regression_one_feature.py</strong></p>
<p>ML with linear regression for a single feature</p>
<p>Example: predict house price from house size (single feature)</p>
<p><strong>linear_regression_one_feature_with_tensorboard.py</strong></p>
<p>Add visualization for ‘ML for single feature’ with Tensorboard</p>
<p>Use tf.scalar_summary, tf.histogram_summary to collect data for variables that we want to visualize</p>
<p>Use scope to collapse TF network graph in to expandable/collapsible black boxes to faciliate visualization</p>
<p><strong>linear_regression_one_feature_using_mini_batch_with_tensorboard.py</strong></p>
<p>Perform ‘stochastic/mini-batch/batch’ Gradient Descent with TF</p>
<p>The CUSTOMIZABLE section contains all the configurations that we can tweak, e.g., batch size, etc.</p>
<p><strong>linear_regression_multi_feature_using_mini_batch_without_matrix_with_tensorboard.py</strong></p>
<p>ML with linear regrssion for 2 features without using ‘matrix’</p>
<p>Create additional tf.Variable, tf.placeholder for each feature</p>
<p>IMPORTANT: This is a messy way to do ML with multiple features. This is provided as an explanation of multi-feature concept.</p>
<p><strong>linear_regression_multi_feature_using_mini_batch_with_tensorboard.py</strong></p>
<p>ML with linear regrssion for 2 features</p>
<p>Expanding existing W (tf.Variable) in matrix ‘height’, and existing x (tf.placeholder) in matrix ‘width’ to accomodate each feature</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/nethsix/gentle_tensorflow/&quot;&gt;作者：Neth Six&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/1383827?v=3&amp;amp;s=460&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Goal&quot;&gt;&lt;a href=&quot;#Goal&quot; class=&quot;headerlink&quot; title=&quot;Goal&quot;&gt;&lt;/a&gt;Goal&lt;/h2&gt;&lt;p&gt;Tensorflow (TF) is Google’s attempt to put the power of Deep Learning into the hands of developers around the world. It comes with a beginner &amp;amp; an advanced tutorial, as well as a course on Udacity. However, the materials attempt to introduce both ML and TF concurrently to solve a multi-feature problem — character recognition, which albeit interesting, unnecessarily convolutes understanding. Gentlest Tensorflow attempts to overcome that by showing how to do linear regression for a single feature problem, and expand from there.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>深度 | 机器学习敲门砖:任何人都能看懂的TensorFlow介绍</title>
    <link href="http://ipcreator.me/2017/02/13/Program/TensorFlow/good-understanding-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/13/Program/TensorFlow/good-understanding-of-tensorflow/</id>
    <published>2017-02-13T00:51:06.000Z</published>
    <updated>2017-02-17T15:34:43.389Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/lenbow/article/details/52152766" target="_blank" rel="external">作者：Soon Hin Khor</a></p>
<p>原文：<a href="http://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-1.html" target="_blank" rel="external">The Gentlest Introduction to Tensorflow – Part 1</a><br><a href="http://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-2.html/2" target="_blank" rel="external">The Gentlest Introduction to Tensorflow – Part 2</a></p>
<p>机器之心编译  参与：Rick、吴攀、李亚洲</p>
<p>　　本文是日本东京 TensorFlow 聚会联合组织者 Hin Khor 所写的 TensorFlow 系列介绍文章的前两部分，自称给出了关于 TensorFlow 的 gentlest 的介绍。这两部分谈到单一特征问题的线性回归问题以及训练（training）的含义，机器之心将继续关注本系列文章的后续更新。</p>
  <a id="more"></a>
<h2 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h2><p>　　引言</p>
<p>　　我们要解决的是一个过于简单且不现实的问题，但其好的一面是便于我们了解机器学习和 TensorFlow 的概念。我们要预测一个基于单一特征（房间面积/平方米）的单标量输出（房价/美元）。这样做消除了处理多维数据的需要，使我们能够在 TensorFlow 中只专注于确定、实现以及训练模型。</p>
<p>　　<strong>机器学习简介</strong></p>
<p>　　我们从一组收集到的数据点开始（见下图），每个数据点代表两个值之间的关系——输出（房价）与影响因素（房子面积）。</p>
<p><img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185277647855356.PNG" alt=""><br>　　<br>　　然而我们无法预测没有数据点的特征的值（见上图）。</p>
<p>　　我们可以使用机器学习来挖掘它们之间的关系（见下图的「最佳拟合预测曲线」），即给定一个不属于数据点的特征值，我们可以准确地预测出输出（特征值和预测线的交点）。</p>
<p><img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185279041726078.PNG" alt="">
　　</p>
<h3 id="步骤一：选择一个模型"><a href="#步骤一：选择一个模型" class="headerlink" title="步骤一：选择一个模型"></a>步骤一：选择一个模型</h3><p>　　1.模型种类</p>
<p>　　为了使用机器学习来做预测，我们需要选择一个能够拟合收集到的数据的最佳模型。</p>
<p>　　我们可以选择一个线性（直线）模型，并通过改变其陡度/梯度和位置对其进行调整，从而匹配数据点。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185279256541303.PNG" alt=""></p>
<p>　　我们也可以选择一个指数（曲线）模型，并通过改变其曲率（curvature）和位置对其进行调整，从而匹配同一数据点集。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185279285052628.PNG" alt=""></p>
<p>　　2.成本函数</p>
<p>　　为了比较哪个模型拟合得更严密，<strong>数学上我们将最佳拟合定义为一个需要被最小化的成本函数。</strong> 成本函数的一个简单样例是每个数据点所代表的实际输出与预测输出之间偏差的绝对值总和（实际结果到最佳拟合曲线的垂直投影）。用图表表示，成本函数被描述为下表中蓝色线段的长度和。<br>　　注意：更准确地说，成本函数往往是实际输出和预测输出之间的方差，因为差值有时是负数；这也称为最小二乘法。</p>
<p>　　3.线性模型简介</p>
<p>　　秉持简洁精神，我们将使用线性模型来对数据点进行建模。线性模型的数学表示是：<br>　　y = W.x + b<br>　　Where:<br>　　x: house size, in sqm<br>　　y: predicted house price, in $<br>　　为了调整模型来更好地拟合数据点，我们可以这样做：</p>
<p>　　调整 W 来改变线性模型的梯度<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185280380207018.PNG" alt=""><br>　　调整 b 来改变线性模型的位置<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185280411397531.PNG" alt=""><br>　　通过使用许多个 W、b 的值，最终我们可以找到一个最佳拟合线性模型，能够将成本函数降到最小。<br>　　除了随机尝试不同的值，有没有一个更好的方法来快速找到 W、b 的值？</p>
<p>　　4.梯度下降<br>　　如果你试图从山上下降到最低点，你的视角就是这个样子。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185280649945725.JPEG" alt=""><br>　　下降趋势并不明显！其最佳方式是执行梯度下降：<br>　　在当前位置以最陡的下降梯度确定方向<br>　　在该方向上采取步长 X<br>　　重复 &amp; 刷新；这就是训练过程<br>　　<strong>最小化成本函数是类似的，因为成本函数就像是起伏的山，我们想要找到其中的最低点，我们可以通过梯度下降类似地实现。</strong><br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185280668810785.PNG" alt=""><br>　　现在我们有了线性模型、成本函数和梯度下降的概念，可以开始使用 TensorFlow 了。</p>
<h3 id="步骤二：在TensorFlow-中建立模型"><a href="#步骤二：在TensorFlow-中建立模型" class="headerlink" title="步骤二：在TensorFlow 中建立模型"></a>步骤二：在TensorFlow 中建立模型</h3><p>　　1.TensorFlow 中的线性模型<br>　　TensorFlow 的2个基本组件是：<br>　　占位符（Placeholder）：表示执行梯度下降时将实际数据值输入到模型中的一个入口点。例如房子面积 (x) 和房价 (y_)。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185280848415395.PNG" alt=""><br>　　变量：表示我们试图寻找的能够使成本函数降到最小的「good」值的变量，例如 W 和 b。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185280912702237.PNG" alt=""><br>　　然后 TensorFlow 中的线性模型 (y = W.x + b) 就是：<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281063120052.PNG" alt=""></p>
<p>　　2.TensorFlow 中的成本函数<br>　　与将数据点的实际房价 (y_) 输入模型类似，我们创建一个占位符。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281081618132.PNG" alt=""><br>　　成本函数的最小方差就是：<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281243718944.PNG" alt=""></p>
<p>　　3.数据<br>　　由于没有房价(y_) 和房子面积 (x) 的实际数据点，我们就生成它们。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281258485201.PNG" alt=""><br>　　简单起见，我们将房价 (ys) 设置成永远是房子面积 (xs) 的 2 倍。</p>
<p>　　4.梯度下降<br>　　有了线性模型、成本函数和数据，我们就可以开始执行梯度下降从而最小化代价函数，以获得 W、b 的「good」值。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281275279024.PNG" alt=""><br>　　0.00001 是我们每次进行训练时在最陡的梯度方向上所采取的「步」长；它也被称作学习率（learning rate）。</p>
<h3 id="步骤三：训练模型"><a href="#步骤三：训练模型" class="headerlink" title="步骤三：训练模型"></a>步骤三：训练模型</h3><p>　　训练包含以预先确定好的次数执行梯度下降，或者是直到成本函数低于某个预先确定的临界值为止。</p>
<p>　　1.TensorFlow 的怪异<br>　　所有变量都需要在训练开始时进行初始化，否则它们可能会带有之前执行过程中的残余值。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281684475306.PNG" alt=""></p>
<p>　　2.TensorFlow 会话<br>　　虽然 TensorFlow 是一个 Python 库，Python 是一种解释性的语言，但是默认情况下不把 TensorFlow 运算用作解释性能的原因，因此不执行上面的 init 。相反 TensorFlow 是在一个会话中进行；创建一个会话 (sess) 然后使用 sess.run() 去执行。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281695953428.PNG" alt=""><br>　　类似地我们在一个循环中调用 withinsess.run() 来执行上面的 train<em>step。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281721325983.JPEG" alt=""><br>　　你需要将由 x, y</em> 所组成的实际数据输入再提供给输入，因为 TensorFlow 将 train<em>step 分解为它的从属项：<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185281759945694.JPEG" alt=""><br>　　从属项的底部是占位符 x，y</em>；而且正如我们之前提到的，tf.placeholders 是用来表示所要提供的实际数据点值房价 (y_) 和房子面积 (x) 的位置。<br>　　结果<br>　　循环中的 print 语句将显示 TensorFlow 如何在每次迭代中学习 W 和 b 的「good」值。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185282154874143.PNG" alt=""></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>　　我们已经以最简单的形式学习了机器学习；<strong>从一个单一特征预测结果。</strong>（为简单起见）我们选择了一个线性模型来拟合我们的数据点，定义一个成本函数来表示最佳拟合，并通过反复调整其梯度变量 W 与位置变量 b 来训练我们的模型，使成本函数降到最小。</p>
<h2 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h2><p>　　简单回顾</p>
<p>　　在上一部分，我们使用 TensorFlow 构建并学习了一个带有单一特征的线性回归模型——给定一个特征值（房屋面积/平方米），我们可以预测输出（房价/美元）。</p>
<p>　　下面是一些总结：<br>　　我们有一些房屋面积和房价的数据（灰色点）<br>　　我们使用线性回归对这些数据进行了建模（红色虚线）<br>　　我们通过训练该线性回归模型的 W（权重）和 b（偏置）找到了最小化「成本」（竖直蓝色实线的长度总和，这些蓝线代表了预测和实际输出之间的差异）的「最好」模型<br>　　给定任意房屋面积，我们可以使用该线性模型预测房价（带箭头的蓝色虚线）<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185282788501777.PNG" alt=""><br>　　一张图解释线性回归</p>
<pre><code>在机器学习文献中，我们常常看到「训练（training）」这个词。在这一部分，我们将在 TensorFlow 中理解「训练」的含义。
</code></pre><p>　　线性回归建模<br>　　Linear Model (in TF notation): y = tf.matmul(x,W) + b<br>　　线性回归的目标是寻找 W 和 b，这样对于给定的任意特征值 x，我们可以通过将 W、b 和 x 的值代入到模型中得到预测 y。<br>　　但是为了找到能准确做出预测的 W 和 b 的值，我们需要使用可用的数据（许多实际特征 x 和实际输出 y_ 的配对，注意下划线）来「训练」该模型。</p>
<p>　　解释「训练」<br>　　为了找到最佳的 W 和 b 值，我们可以从任意的 W 和 b 值开始。我们也需要定义一个成本函数，该函数可以衡量对于一个给定特征值 x 预测输出 y 和实际输出 y_ 之间差异。为了简单起见，我们使用最简单的最小均方误差（MSE：minimum squared error）作为我们的成本函数。<br>　　Cost function (in TF notation): tf.reduce<em>mean(tf.square(y</em> - y))<br>　　通过最小化成本函数，我们可以得到很好的 W 和 b 值。<br>　　我们的训练代码实际上非常简单，并且用 [A, B, C, D] 进行了注释，后面我们还会谈到这些代码。完整代码请访问：<a href="https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py" target="_blank" rel="external">https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py</a></p>
<p>　　# … (省略) 变量/常量声明 …</p>
<p>　　# [A] TensorFlow图<br>　　y = tf.matmul(x,W) + b<br>　　cost = tf.reduce<em>mean(tf.square(y</em>-y))</p>
<p>　　# [B] 用固定「学习率（learn_rate）」训练<br>　　learn_rate = 0.1<br>　　train_step =<br>　　tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)<br>　　for i in range(steps):</p>
<p>　　# [C] 准备数据点<br>　　# … (省略) 准备作为x和y的数据点的代码 …</p>
<p>　　# [D] 在每个步骤/epoch将数据送入’train<em>step’<br>　　feed = { x: xs, y</em>: ys }<br>　　sess.run(train_step, feed_dict=feed)</p>
<p>　　我们的线性模型和成本函数[A]可以表示成下面的 TensorFlow 图：<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283024917706.PNG" alt=""><br>　　创造一个带有模型和成本函数的 TensorFlow 图，并使用一些值初始化 W 和 b<br>　　接下来，我们选择一个数据点 (x, y_) [C]，然后将其送入[D] TensorFlow 图，从而得到预测 y 和相应的成本。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283050555281.PNG" alt=""><br>　　使用单个数据点计算预测 y 和成本</p>
<p>　　为了得到更好的 W 和 b，我们使用TensorFlow 的 tf.train.GradientDescentOptimizer [B]执行梯度下降以降低成本。用非技术的术语来说：给定当前成本，并基于成本岁其它变量（即 W 和 b）的变化方式，优化器（optimizer）将对 W 和 b 执行一些小调整（递增或递减）以使我们的预测更好地契合那个单个数据点。</p>
<p>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283119696947.JPEG" alt=""><br>　　基于当前的成本，决定如何调整 W 和 b 以提升预测 y 和降低成本</p>
<p>　　训练周期中的最后步骤是在调整 W 和 b 对它们进行更新。注意这里的「周期」用机器学习的术语来说是「epoch」。<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283140122068.JPEG" alt=""><br>　　在下一训练 epoch 的迭代前，通过调整 W 和 b 对它们进行更新</p>
<p>　　在下一训练 epoch 中，重复这些步骤，但使用一个不同的数据点！<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283229448084.JPEG" alt=""><br>　　使用不同的数据点进行训练</p>
<p>　　使用各种数据点泛化（generalize）我们的模型，即学习可被用于预测任何特征值的 W 和 b 值。注意：<br>　　在大部分情况下，数据点越多，模型的学习和泛化就越好</p>
<p>　　如果你训练的 epoch 比数据点还多，你可以重复使用数据点，这不成问题。梯度下降优化总是会同时使用数据点及其成本（根据该 epoch 的 W 和 b 值从数据点中计算得到）来对 W 和 b 值进行调整；该优化器也许之前已经见过了这个数据点，但成本并不一样，因此它还是可以学到新的东西，并以不同的方式调整 W 和 b 值。</p>
<p>　　你可以用固定数量的 epoch 训练一个模型，直到其达到令人满意的成本阈值。</p>
<p>　　训练变量</p>
<p>　　1.随机、mini-batch、batch</p>
<p>　　在上面的训练中，我们在每个 epoch 送入单个数据点。这被称为随机梯度下降（stochastic gradient descent）。我们也可以在每个 epoch 送入一堆数据点，这被称为 mini-batch 梯度下降，或者甚至在一个 epoch 一次性送入所有的数据点，这被称为 batch 梯度下降。请看下图的比较，注意这 3 张图的 2 处不同：<br>　　每个 epoch 送入 TensorFlow 图（TF.Graph）的数据点的数量（图右上方）<br>　　梯度下降优化在调整 W 和 b 值时所考虑的数据点的数量（图右下方）<br>　　随机梯度下降<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283435404926.JPEG" alt=""><br>　　mini-batch 梯度下降<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283453741114.JPEG" alt=""><br>　　batch 梯度下降</p>
<p>　　每张图中的数据点的数量有 2 个含义。当数据点更多时：<br>　　计算成本和执行梯度下降所需的计算资源（减法、平方、加法）会增加<br>　　模型的学习和泛化的速度增加<br>　　选择随机、mini-batch、batch 梯度下降的优缺点总结在下图中：<br>　　<img src="http://n1.itc.cn/img8/wb/recom/2016/08/22/147185283466611340.PNG" alt=""><br>　　选择随机、mini-batch、batch 梯度下降的优缺点<br>　　要在随机/mini-batch/batch 梯度下降之间切换，我们只需要在将数据点送入训练步骤[D]之前将这些数据点分成不同的 batch 大小，即为 [C] 使用如下的代码片段：<br>　　# <em> all_xs: 所有的特征值<br>　　# </em> all_ys: 所有的输出值<br>　　# datapoint_size: all_xs/all_ys 中点/项的数量<br>　　# batch_size: 配置如下:<br>　　# 1: 随机模型<br>　　# integer &lt; datapoint_size: mini-batch模式<br>　　# datapoint_size: batch模式<br>　　# i: 当前epoch数量<br>　　if datapoint_size == batch_size:<br>　　# Batch 模式，所以选择所有数据点从 index 0 开始<br>　　batch_start_idx = 0<br>　　elif datapoint_size &lt; batch_size:<br>　　# 不可能<br>　　raise ValueError(“datapoint_size: %d, must be greater than<br>　　batch_size: %d” % (datapoint_size, batch_size))<br>　　else:<br>　　# 随机/mini-batch模式: 从所有可能的数据点中分批选择数据点<br>　　batch_start_idx = (i * batch_size) % (datapoint_size — batch_size)<br>　　batch_end_idx = batch_start_idx + batch_size<br>　　batch_xs = all_xs[batch_start_idx:batch_end_idx]<br>　　batch_ys = all_ys[batch_start_idx:batch_end_idx]<br>　　# 将分批的数据点定义为xs, ys, 它们会被送入 ‘train_step’训练步骤<br>　　xs = np.array(batch_xs)<br>　　ys = np.array(batch_ys)</p>
<p>　　2.学习率变化<br>　　学习率（learn rate）是指梯度下降调整 W 和 b 递增或递减的速度。学习率较小时，处理过程会更慢，但肯定能得到更小成本；而当学习率更大时，我们可以更快地得到最小成本，但有「冲过头」的风险，导致我们没法找到最小成本。<br>　　为了克服这一问题，许多机器学习实践者选择开始时使用较大的学习率（假设开始时的成本离最小成本还很远），然后随每个 epoch 而逐渐降低学习率。<br>　　TensorFlow 提供了 2 种方法可以做到这一点，详细解释可参考：<img src="http://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer；但这里进行了总结。
　　使用梯度下降优化的变体
　　TensorFlow 带有多种支持学习率变化的梯度下降优化器，例如 tf.train.AdagradientOptimizer 和 tf.train.AdamOptimizer.
　　使用 tf.placeholder 调整学习率
　　如同前面所看到的，如果我们在这个例子中声明了 tf.placeholder 来设置学习率，然后在 tf.train.GradientDescentOptimizer 中使用它，我们可以在每个训练 epoch 向其送入一个不同的值，这很像我们给 x 和 y_ 送入不同的数据点，这也是每个 epoch 的 tf.placeholders.
　　我们需要 2 个小修改：
　　# 修改 [B] ，将 &#39;learn_rate&#39; 设置为&#39;tf.placeholder&#39;
　　# 并将其提供给&#39;learning_rate&#39;参数名tf.train.GradientDescentOptimizer
　　learn_rate = tf.placeholder(tf.float32, shape=[]" alt=""><br>　　train_step = tf.train.GradientDescentOptimizer(<br>　　learning_rate=learn_rate).minimize(cost)<br>　　# 修改[D]，包含送入一个’learn_rate’值,<br>　　# 即 ‘initial_learn<em>rate’（初始学习率）除以’i’ (当前epoch数)<br>　　# 注: 这是过于简化的，仅用作示例<br>　　feed = { x: xs, y</em>: ys, learn_rate: initial_learn_rate/i }<br>　　sess.run(train_step, feed_dict=feed)</p>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>　　我们解释了机器学习中「训练（training）」的含义，以及在 TensorFlow 中通过模型和成本定义、然后循环通过训练步骤（将数据点送入梯度下降优化器）来进行训练的方式。我们还讨论了训练中的常见变量，即改变模型学习时每个 epoch 所用的数据点的大小和改变梯度下降优化器的学习率。</p>
<p>　　后续内容<br>　　创建 Tensor Board 来可视化 Tensorflow 的执行，从而检测我们的模型、成本函数或梯度下降中的问题<br>　　使用多个特征表达线性回归<br>　　©本文由机器之心编译，转载请联系本公众号获得授权。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/lenbow/article/details/52152766&quot;&gt;作者：Soon Hin Khor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文：&lt;a href=&quot;http://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-1.html&quot;&gt;The Gentlest Introduction to Tensorflow – Part 1&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-2.html/2&quot;&gt;The Gentlest Introduction to Tensorflow – Part 2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;机器之心编译  参与：Rick、吴攀、李亚洲&lt;/p&gt;
&lt;p&gt;　　本文是日本东京 TensorFlow 聚会联合组织者 Hin Khor 所写的 TensorFlow 系列介绍文章的前两部分，自称给出了关于 TensorFlow 的 gentlest 的介绍。这两部分谈到单一特征问题的线性回归问题以及训练（training）的含义，机器之心将继续关注本系列文章的后续更新。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow一些常用基本概念与函数</title>
    <link href="http://ipcreator.me/2017/02/13/Program/TensorFlow/basic-concept-and-operation-of-tensorflow/"/>
    <id>http://ipcreator.me/2017/02/13/Program/TensorFlow/basic-concept-and-operation-of-tensorflow/</id>
    <published>2017-02-13T00:50:06.000Z</published>
    <updated>2017-02-27T03:52:18.382Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/lenbow/article/details/52152766" target="_blank" rel="external">作者：林海山波</a></p>
<p><img src="http://avatar.csdn.net/D/1/1/1_lenbow.jpg" alt=""></p>
<p> 本文主要对tf的一些常用概念与方法进行描述。</p>
  <a id="more"></a>
  <h3 id="1tensorflow的基本运作">1、tensorflow的基本运作</h3>

  <p>为了快速的熟悉TensorFlow编程，下面从一段简单的代码开始：</p>



  <pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
   <span class="hljs-comment">#定义‘符号’变量，也称为占位符</span>
   a = tf.placeholder(<span class="hljs-string">"float"</span>)
   b = tf.placeholder(<span class="hljs-string">"float"</span>)

   y = tf.mul(a, b) <span class="hljs-comment">#构造一个op节点</span>

   sess = tf.Session()<span class="hljs-comment">#建立会话</span>
   <span class="hljs-comment">#运行会话，输入数据，并计算节点，同时打印结果</span>
   <span class="hljs-keyword">print</span> sess.run(y, feed_dict={a: <span class="hljs-number">3</span>, b: <span class="hljs-number">3</span>})
   <span class="hljs-comment"># 任务完成, 关闭会话.</span>
   sess.close()</code></pre>

  <p>其中tf.mul(a, b)函数便是tf的一个基本的算数运算，接下来介绍跟多的相关函数。</p>



  <h3 id="2tf函数">2、tf函数</h3>

  <pre><code>TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU。一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测。如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作.
  并行计算能让代价大的算法计算加速执行，TensorFlow也在实现上对复杂操作进行了有效的改进。大部分核相关的操作都是设备相关的实现，比如GPU。下面是一些重要的操作/核：
  </code></pre>

  <table><br>  <thead><br>  <tr><br>    <th>操作组</th><br>    <th align="left">操作</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>Maths</td><br>    <td align="left">Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal</td><br>  </tr><br>  <tr><br>    <td>Array</td><br>    <td align="left">Concat, Slice, Split, Constant, Rank, Shape, Shuffle</td><br>  </tr><br>  <tr><br>    <td>Matrix</td><br>    <td align="left">MatMul, MatrixInverse, MatrixDeterminant</td><br>  </tr><br>  <tr><br>    <td>Neuronal Network</td><br>    <td align="left">SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool</td><br>  </tr><br>  <tr><br>    <td>Checkpointing</td><br>    <td align="left">Save, Restore</td><br>  </tr><br>  <tr><br>    <td>Queues and syncronizations</td><br>    <td align="left">Enqueue, Dequeue, MutexAcquire, MutexRelease</td><br>  </tr><br>  <tr><br>    <td>Flow control</td><br>    <td align="left">Merge, Switch, Enter, Leave, NextIteration</td><br>  </tr><br>  </tbody></table>




  <h4 id="tensorflow的算术操作如下">TensorFlow的算术操作如下：</h4>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.add(x, y, name=None)</td><br>    <td align="left">求和</td><br>  </tr><br>  <tr><br>    <td>tf.sub(x, y, name=None)</td><br>    <td align="left">减法</td><br>  </tr><br>  <tr><br>    <td>tf.mul(x, y, name=None)</td><br>    <td align="left">乘法</td><br>  </tr><br>  <tr><br>    <td>tf.div(x, y, name=None)</td><br>    <td align="left">除法</td><br>  </tr><br>  <tr><br>    <td>tf.mod(x, y, name=None)</td><br>    <td align="left">取模</td><br>  </tr><br>  <tr><br>    <td>tf.abs(x, name=None)</td><br>    <td align="left">求绝对值</td><br>  </tr><br>  <tr><br>    <td>tf.neg(x, name=None)</td><br>    <td align="left">取负  (y = -x).</td><br>  </tr><br>  <tr><br>    <td>tf.sign(x, name=None)</td><br>    <td align="left">返回符号 y = sign(x) = -1 if x &lt; 0; 0 if x == 0; 1 if x &gt; 0.</td><br>  </tr><br>  <tr><br>    <td>tf.inv(x, name=None)</td><br>    <td align="left">取反</td><br>  </tr><br>  <tr><br>    <td>tf.square(x, name=None)</td><br>    <td align="left">计算平方 (y = x * x = x^2).</td><br>  </tr><br>  <tr><br>    <td>tf.round(x, name=None)</td><br>    <td align="left">舍入最接近的整数<br># ‘a’ is [0.9, 2.5, 2.3, -4.4]<br>tf.round(a) ==&gt; [ 1.0, 3.0, 2.0, -4.0 ]</td><br>  </tr><br>  <tr><br>    <td>tf.sqrt(x, name=None)</td><br>    <td align="left">开根号 (y = \sqrt{x} = x^{1/2}).</td><br>  </tr><br>  <tr><br>    <td>tf.pow(x, y, name=None)</td><br>    <td align="left">幂次方 <br># tensor ‘x’ is [[2, 2], [3, 3]]<br># tensor ‘y’ is [[8, 16], [2, 3]]<br>tf.pow(x, y) ==&gt; [[256, 65536], [9, 27]]</td><br>  </tr><br>  <tr><br>    <td>tf.exp(x, name=None)</td><br>    <td align="left">计算e的次方</td><br>  </tr><br>  <tr><br>    <td>tf.log(x, name=None)</td><br>    <td align="left">计算log，一个输入计算e的ln，两输入以第二输入为底</td><br>  </tr><br>  <tr><br>    <td>tf.maximum(x, y, name=None)</td><br>    <td align="left">返回最大值 (x &gt; y ? x : y)</td><br>  </tr><br>  <tr><br>    <td>tf.minimum(x, y, name=None)</td><br>    <td align="left">返回最小值 (x &lt; y ? x : y)</td><br>  </tr><br>  <tr><br>    <td>tf.cos(x, name=None)</td><br>    <td align="left">三角函数cosine</td><br>  </tr><br>  <tr><br>    <td>tf.sin(x, name=None)</td><br>    <td align="left">三角函数sine</td><br>  </tr><br>  <tr><br>    <td>tf.tan(x, name=None)</td><br>    <td align="left">三角函数tan</td><br>  </tr><br>  <tr><br>    <td>tf.atan(x, name=None)</td><br>    <td align="left">三角函数ctan</td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="张量操作tensor-transformations">张量操作Tensor Transformations</h4>

  <ul><br>  <li>数据类型转换Casting</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.string_to_number<br>(string_tensor, out_type=None, name=None)</td><br>    <td align="left">字符串转为数字</td><br>  </tr><br>  <tr><br>    <td>tf.to_double(x, name=’ToDouble’)</td><br>    <td align="left">转为64位浮点类型–float64</td><br>  </tr><br>  <tr><br>    <td>tf.to_float(x, name=’ToFloat’)</td><br>    <td align="left">转为32位浮点类型–float32</td><br>  </tr><br>  <tr><br>    <td>tf.to_int32(x, name=’ToInt32’)</td><br>    <td align="left">转为32位整型–int32</td><br>  </tr><br>  <tr><br>    <td>tf.to_int64(x, name=’ToInt64’)</td><br>    <td align="left">转为64位整型–int64</td><br>  </tr><br>  <tr><br>    <td>tf.cast(x, dtype, name=None)</td><br>    <td align="left">将x或者x.values转换为dtype<br># tensor <code>a</code> is [1.8, 2.2], dtype=tf.float<br>tf.cast(a, tf.int32) ==&gt; [1, 2]  # dtype=tf.int32</td><br>  </tr><br>  <tr><br>    <td></td><br>    <td align="left"></td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>形状操作Shapes and Shaping</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.shape(input, name=None)</td><br>    <td align="left">返回数据的shape<br># ‘t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]<br>shape(t) ==&gt; [2, 2, 3]</td><br>  </tr><br>  <tr><br>    <td>tf.size(input, name=None)</td><br>    <td align="left">返回数据的元素数量<br># ‘t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]<br>size(t) ==&gt; 12</td><br>  </tr><br>  <tr><br>    <td>tf.rank(input, name=None)</td><br>    <td align="left">返回tensor的rank<br>注意：此rank不同于矩阵的rank，<br>tensor的rank表示一个tensor需要的索引数目来唯一表示任何一个元素<br>也就是通常所说的 “order”, “degree”或”ndims”<br>#’t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]<br># shape of tensor ‘t’ is [2, 2, 3]<br>rank(t) ==&gt; 3</td><br>  </tr><br>  <tr><br>    <td>tf.reshape(tensor, shape, name=None)</td><br>    <td align="left">改变tensor的形状<br># tensor ‘t’ is [1, 2, 3, 4, 5, 6, 7, 8, 9]<br># tensor ‘t’ has shape [9]<br>reshape(t, [3, 3]) ==&gt; <br>[[1, 2, 3],<br>[4, 5, 6],<br>[7, 8, 9]]<br>#如果shape有元素[-1],表示在该维度打平至一维<br># -1 将自动推导得为 9:<br>reshape(t, [2, -1]) ==&gt; <br>[[1, 1, 1, 2, 2, 2, 3, 3, 3],<br>[4, 4, 4, 5, 5, 5, 6, 6, 6]]</td><br>  </tr><br>  <tr><br>    <td>tf.expand_dims(input, dim, name=None)</td><br>    <td align="left">插入维度1进入一个tensor中<br>#该操作要求-1-input.dims()<br># ‘t’ is a tensor of shape [2]<br>shape(expand_dims(t, 0)) ==&gt; [1, 2]<br>shape(expand_dims(t, 1)) ==&gt; [2, 1]<br>shape(expand_dims(t, -1)) ==&gt; [2, 1] &lt;= dim &lt;= input.dims()</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>切片与合并（Slicing and Joining）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.slice(input_, begin, size, name=None)</td><br>    <td align="left">对tensor进行切片操作<br>其中size[i] = input.dim_size(i) - begin[i]<br>该操作要求 0 &lt;= begin[i] &lt;= begin[i] + size[i] &lt;= Di for i in [0, n]<br>#’input’ is <br>#[[[1, 1, 1], [2, 2, 2]],[[3, 3, 3], [4, 4, 4]],[[5, 5, 5], [6, 6, 6]]]<br>tf.slice(input, [1, 0, 0], [1, 1, 3]) ==&gt; [[[3, 3, 3]]]<br>tf.slice(input, [1, 0, 0], [1, 2, 3]) ==&gt; <br>[[[3, 3, 3],<br>[4, 4, 4]]]<br>tf.slice(input, [1, 0, 0], [2, 1, 3]) ==&gt; <br>[[[3, 3, 3]],<br>[[5, 5, 5]]]</td><br>  </tr><br>  <tr><br>    <td>tf.split(split_dim, num_split, value, name=’split’)</td><br>    <td align="left">沿着某一维度将tensor分离为num_split tensors<br># ‘value’ is a tensor with shape [5, 30]<br># Split ‘value’ into 3 tensors along dimension 1<br>split0, split1, split2 = tf.split(1, 3, value)<br>tf.shape(split0) ==&gt; [5, 10]</td><br>  </tr><br>  <tr><br>    <td>tf.concat(concat_dim, values, name=’concat’)</td><br>    <td align="left">沿着某一维度连结tensor<br>t1 = [[1, 2, 3], [4, 5, 6]]<br>t2 = [[7, 8, 9], [10, 11, 12]]<br>tf.concat(0, [t1, t2]) ==&gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]<br>tf.concat(1, [t1, t2]) ==&gt; [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]<br>如果想沿着tensor一新轴连结打包,那么可以：<br>tf.concat(axis, [tf.expand_dims(t, axis) for t in tensors])<br>等同于tf.pack(tensors, axis=axis)</td><br>  </tr><br>  <tr><br>    <td>tf.pack(values, axis=0, name=’pack’)</td><br>    <td align="left">将一系列rank-R的tensor打包为一个rank-(R+1)的tensor<br># ‘x’ is [1, 4],  ‘y’ is [2, 5],  ‘z’ is [3, 6]<br>pack([x, y, z]) =&gt; [[1, 4], [2, 5], [3, 6]]  <br># 沿着第一维pack<br>pack([x, y, z], axis=1) =&gt; [[1, 2, 3], [4, 5, 6]]<br>等价于tf.pack([x, y, z]) = np.asarray([x, y, z])</td><br>  </tr><br>  <tr><br>    <td>tf.reverse(tensor, dims, name=None)</td><br>    <td align="left">沿着某维度进行序列反转<br>其中dim为列表，元素为bool型，size等于rank(tensor)<br># tensor ‘t’ is <br>[[[[ 0,  1,  2,  3],<br>#[ 4,  5,  6,  7],<br><br>#[ 8,  9, 10, 11]],<br>#[[12, 13, 14, 15],<br>#[16, 17, 18, 19],<br>#[20, 21, 22, 23]]]]<br># tensor ‘t’ shape is [1, 2, 3, 4]<br># ‘dims’ is [False, False, False, True]<br>reverse(t, dims) ==&gt;<br> [[[[ 3,  2,  1,  0],<br> [ 7,  6,  5,  4],<br>[ 11, 10, 9, 8]],<br> [[15, 14, 13, 12],<br> [19, 18, 17, 16],<br> [23, 22, 21, 20]]]]</td><br>  </tr><br>  <tr><br>    <td>tf.transpose(a, perm=None, name=’transpose’)</td><br>    <td align="left">调换tensor的维度顺序<br>按照列表perm的维度排列调换tensor顺序，<br>如为定义，则perm为(n-1…0)<br># ‘x’ is [[1 2 3],[4 5 6]]<br>tf.transpose(x) ==&gt; [[1 4], [2 5],[3 6]]<br># Equivalently<br>tf.transpose(x, perm=[1, 0]) ==&gt; [[1 4],[2 5], [3 6]]</td><br>  </tr><br>  <tr><br>    <td>tf.gather(params, indices, validate_indices=None, name=None)</td><br>    <td align="left">合并索引indices所指示params中的切片<br><img src="http://img.blog.csdn.net/20160808174705034" alt="tf.gather" title=""></td><br>  </tr><br>  <tr><br>    <td>tf.one_hot<br>(indices, depth, on_value=None, off_value=None, <br>axis=None, dtype=None, name=None)</td><br>    <td align="left">indices = [0, 2, -1, 1]<br>depth = 3<br>on_value = 5.0  <br>off_value = 0.0  <br>axis = -1  <br>#Then output is [4 x 3]: <br> output = <br> [5.0 0.0 0.0]  // one_hot(0)  <br>[0.0 0.0 5.0]  // one_hot(2) <br> [0.0 0.0 0.0]  // one_hot(-1) <br> [0.0 5.0 0.0]  // one_hot(1)</td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="矩阵相关运算">矩阵相关运算</h4>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.diag(diagonal, name=None)</td><br>    <td align="left">返回一个给定对角值的对角tensor<br># ‘diagonal’ is [1, 2, 3, 4]<br>tf.diag(diagonal) ==&gt; <br>[[1, 0, 0, 0]<br>[0, 2, 0, 0]<br>[0, 0, 3, 0]<br>[0, 0, 0, 4]]</td><br>  </tr><br>  <tr><br>    <td>tf.diag_part(input, name=None)</td><br>    <td align="left">功能与上面相反</td><br>  </tr><br>  <tr><br>    <td>tf.trace(x, name=None)</td><br>    <td align="left">求一个2维tensor足迹，即对角值diagonal之和</td><br>  </tr><br>  <tr><br>    <td>tf.transpose(a, perm=None, name=’transpose’)</td><br>    <td align="left">调换tensor的维度顺序<br>按照列表perm的维度排列调换tensor顺序，<br>如为定义，则perm为(n-1…0)<br># ‘x’ is [[1 2 3],[4 5 6]]<br>tf.transpose(x) ==&gt; [[1 4], [2 5],[3 6]]<br># Equivalently<br>tf.transpose(x, perm=[1, 0]) ==&gt; [[1 4],[2 5], [3 6]]</td><br>  </tr><br>  <tr><br>    <td>tf.matmul(a, b, transpose_a=False, <br>transpose_b=False, a_is_sparse=False, <br>b_is_sparse=False, name=None)</td><br>    <td align="left">矩阵相乘</td><br>  </tr><br>  <tr><br>    <td>tf.matrix_determinant(input, name=None)</td><br>    <td align="left">返回方阵的行列式</td><br>  </tr><br>  <tr><br>    <td>tf.matrix_inverse(input, adjoint=None, name=None)</td><br>    <td align="left">求方阵的逆矩阵，adjoint为True时，计算输入共轭矩阵的逆矩阵</td><br>  </tr><br>  <tr><br>    <td>tf.cholesky(input, name=None)</td><br>    <td align="left">对输入方阵cholesky分解，<br>即把一个对称正定的矩阵表示成一个下三角矩阵L和其转置的乘积的分解A=LL^T</td><br>  </tr><br>  <tr><br>    <td>tf.matrix_solve(matrix, rhs, adjoint=None, name=None)</td><br>    <td align="left">求解tf.matrix_solve(matrix, rhs, adjoint=None, name=None)<br>matrix为方阵shape为[M,M],rhs的shape为[M,K]，output为[M,K]</td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="复数操作">复数操作</h4>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.complex(real, imag, name=None)</td><br>    <td align="left">将两实数转换为复数形式<br># tensor ‘real’ is [2.25, 3.25]<br># tensor <code>imag</code> is [4.75, 5.75]<br>tf.complex(real, imag) ==&gt; [[2.25 + 4.75j], [3.25 + 5.75j]]</td><br>  </tr><br>  <tr><br>    <td>tf.complex_abs(x, name=None)</td><br>    <td align="left">计算复数的绝对值，即长度。<br># tensor ‘x’ is [[-2.25 + 4.75j], [-3.25 + 5.75j]]<br>tf.complex_abs(x) ==&gt; [5.25594902, 6.60492229]</td><br>  </tr><br>  <tr><br>    <td>tf.conj(input, name=None)</td><br>    <td align="left">计算共轭复数</td><br>  </tr><br>  <tr><br>    <td>tf.imag(input, name=None)<br>tf.real(input, name=None)</td><br>    <td align="left">提取复数的虚部和实部</td><br>  </tr><br>  <tr><br>    <td>tf.fft(input, name=None)</td><br>    <td align="left">计算一维的离散傅里叶变换，输入数据类型为complex64</td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="归约计算reduction">归约计算(Reduction)</h4>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.reduce_sum(input_tensor, reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">计算输入tensor元素的和，或者安照reduction_indices指定的轴进行求和<br># ‘x’ is [[1, 1, 1]<br>#         [1, 1, 1]]<br>tf.reduce_sum(x) ==&gt; 6<br>tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]<br>tf.reduce_sum(x, 1) ==&gt; [3, 3]<br>tf.reduce_sum(x, 1, keep_dims=True) ==&gt; [[3], [3]]<br>tf.reduce_sum(x, [0, 1]) ==&gt; 6</td><br>  </tr><br>  <tr><br>    <td>tf.reduce_prod(input_tensor, <br>reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">计算输入tensor元素的乘积，或者安照reduction_indices指定的轴进行求乘积</td><br>  </tr><br>  <tr><br>    <td>tf.reduce_min(input_tensor, <br>reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">求tensor中最小值</td><br>  </tr><br>  <tr><br>    <td>tf.reduce_max(input_tensor, <br>reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">求tensor中最大值</td><br>  </tr><br>  <tr><br>    <td>tf.reduce_mean(input_tensor, <br>reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">求tensor中平均值</td><br>  </tr><br>  <tr><br>    <td>tf.reduce_all(input_tensor, <br>reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">对tensor中各个元素求逻辑’与’<br># ‘x’ is <br># [[True,  True]<br>#         [False, False]]<br>tf.reduce_all(x) ==&gt; False<br>tf.reduce_all(x, 0) ==&gt; [False, False]<br>tf.reduce_all(x, 1) ==&gt; [True, False]</td><br>  </tr><br>  <tr><br>    <td>tf.reduce_any(input_tensor, <br>reduction_indices=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">对tensor中各个元素求逻辑’或’</td><br>  </tr><br>  <tr><br>    <td>tf.accumulate_n(inputs, shape=None, <br>tensor_dtype=None, name=None)</td><br>    <td align="left">计算一系列tensor的和<br># tensor ‘a’ is [[1, 2], [3, 4]]<br># tensor <code>b</code> is [[5, 0], [0, 6]]<br>tf.accumulate_n([a, b, a]) ==&gt; [[7, 4], [6, 14]]</td><br>  </tr><br>  <tr><br>    <td>tf.cumsum(x, axis=0, exclusive=False, <br>reverse=False, name=None)</td><br>    <td align="left">求累积和<br>tf.cumsum([a, b, c]) ==&gt; [a, a + b, a + b + c]<br>tf.cumsum([a, b, c], exclusive=True) ==&gt; [0, a, a + b]<br>tf.cumsum([a, b, c], reverse=True) ==&gt; [a + b + c, b + c, c]<br>tf.cumsum([a, b, c], exclusive=True, reverse=True) ==&gt; [b + c, c, 0]</td><br>  </tr><br>  <tr><br>    <td></td><br>    <td align="left"></td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="分割segmentation">分割(Segmentation)</h4>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.segment_sum(data, segment_ids, name=None)</td><br>    <td align="left">根据segment_ids的分段计算各个片段的和<br>其中segment_ids为一个size与data第一维相同的tensor<br>其中id为int型数据，最大id不大于size<br>c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])<br>tf.segment_sum(c, tf.constant([0, 0, 1]))<br>==&gt;[[0 0 0 0] <br>[5 6 7 8]]<br>上面例子分为[0,1]两id,对相同id的data相应数据进行求和,<br>并放入结果的相应id中，<br>且segment_ids只升不降</td><br>  </tr><br>  <tr><br>    <td>tf.segment_prod(data, segment_ids, name=None)</td><br>    <td align="left">根据segment_ids的分段计算各个片段的积</td><br>  </tr><br>  <tr><br>    <td>tf.segment_min(data, segment_ids, name=None)</td><br>    <td align="left">根据segment_ids的分段计算各个片段的最小值</td><br>  </tr><br>  <tr><br>    <td>tf.segment_max(data, segment_ids, name=None)</td><br>    <td align="left">根据segment_ids的分段计算各个片段的最大值</td><br>  </tr><br>  <tr><br>    <td>tf.segment_mean(data, segment_ids, name=None)</td><br>    <td align="left">根据segment_ids的分段计算各个片段的平均值</td><br>  </tr><br>  <tr><br>    <td>tf.unsorted_segment_sum(data, segment_ids,<br> num_segments, name=None)</td><br>    <td align="left">与tf.segment_sum函数类似，<br>不同在于segment_ids中id顺序可以是无序的</td><br>  </tr><br>  <tr><br>    <td>tf.sparse_segment_sum(data, indices, <br>segment_ids, name=None)</td><br>    <td align="left">输入进行稀疏分割求和<br>c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])<br># Select two rows, one segment.<br>tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0])) <br> ==&gt; [[0 0 0 0]]<br>对原data的indices为[0,1]位置的进行分割，<br>并按照segment_ids的分组进行求和</td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="序列比较与索引提取sequence-comparison-and-indexing">序列比较与索引提取(Sequence Comparison and Indexing)</h4>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.argmin(input, dimension, name=None)</td><br>    <td align="left">返回input最小值的索引index</td><br>  </tr><br>  <tr><br>    <td>tf.argmax(input, dimension, name=None)</td><br>    <td align="left">返回input最大值的索引index</td><br>  </tr><br>  <tr><br>    <td>tf.listdiff(x, y, name=None)</td><br>    <td align="left">返回x，y中不同值的索引</td><br>  </tr><br>  <tr><br>    <td>tf.where(input, name=None)</td><br>    <td align="left">返回bool型tensor中为True的位置<br># ‘input’ tensor is <br>#[[True, False]<br>#[True, False]]<br># ‘input’ 有两个’True’,那么输出两个坐标值.<br># ‘input’的rank为2, 所以每个坐标为具有两个维度.<br>where(input) ==&gt;<br> [[0, 0],<br>[1, 0]]</td><br>  </tr><br>  <tr><br>    <td>tf.unique(x, name=None)</td><br>    <td align="left">返回一个元组tuple(y,idx)，y为x的列表的唯一化数据列表，<br>idx为x数据对应y元素的index<br># tensor ‘x’ is [1, 1, 2, 4, 4, 4, 7, 8, 8]<br>y, idx = unique(x)<br>y ==&gt; [1, 2, 4, 7, 8]<br>idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]</td><br>  </tr><br>  <tr><br>    <td>tf.invert_permutation(x, name=None)</td><br>    <td align="left">置换x数据与索引的关系<br># tensor <code>x</code> is [3, 4, 0, 2, 1]<br>invert_permutation(x) ==&gt; [2, 4, 3, 0, 1]</td><br>  </tr><br>  </tbody></table>


  <hr>



  <h4 id="神经网络neural-network">神经网络(Neural Network)</h4>

  <ul><br>  <li>激活函数（Activation Functions）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.relu(features, name=None)</td><br>    <td align="left">整流函数：max(features, 0)</td><br>  </tr><br>  <tr><br>    <td>tf.nn.relu6(features, name=None)</td><br>    <td align="left">以6为阈值的整流函数：min(max(features, 0), 6)</td><br>  </tr><br>  <tr><br>    <td>tf.nn.elu(features, name=None)</td><br>    <td align="left">elu函数，exp(features) - 1 if &lt; 0,否则features<br><a href="http://arxiv.org/abs/1511.07289" target="_blank" rel="external">Exponential Linear Units (ELUs) </a></td><br>  </tr><br>  <tr><br>    <td>tf.nn.softplus(features, name=None)</td><br>    <td align="left">计算softplus：log(exp(features) + 1)</td><br>  </tr><br>  <tr><br>    <td>tf.nn.dropout(x, keep_prob, <br>noise_shape=None, seed=None, name=None)</td><br>    <td align="left">计算dropout，keep_prob为keep概率<br>noise_shape为噪声的shape</td><br>  </tr><br>  <tr><br>    <td>tf.nn.bias_add(value, bias, data_format=None, name=None)</td><br>    <td align="left">对value加一偏置量<br>此函数为tf.add的特殊情况，bias仅为一维，<br>函数通过广播机制进行与value求和,<br>数据格式可以与value不同，返回为与value相同格式</td><br>  </tr><br>  <tr><br>    <td>tf.sigmoid(x, name=None)</td><br>    <td align="left">y = 1 / (1 + exp(-x))</td><br>  </tr><br>  <tr><br>    <td>tf.tanh(x, name=None)</td><br>    <td align="left">双曲线切线激活函数</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>卷积函数（Convolution）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.conv2d(input, filter, strides, padding, <br>use_cudnn_on_gpu=None, data_format=None, name=None)</td><br>    <td align="left">在给定的4D input与 filter下计算2D卷积<br>输入shape为 [batch, height, width, in_channels]</td><br>  </tr><br>  <tr><br>    <td>tf.nn.conv3d(input, filter, strides, padding, name=None)</td><br>    <td align="left">在给定的5D input与 filter下计算3D卷积<br>输入shape为[batch, in_depth, in_height, in_width, in_channels]</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>池化函数（Pooling）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.avg_pool(value, ksize, strides, padding, <br>data_format=’NHWC’, name=None)</td><br>    <td align="left">平均方式池化</td><br>  </tr><br>  <tr><br>    <td>tf.nn.max_pool(value, ksize, strides, padding, <br>data_format=’NHWC’, name=None)</td><br>    <td align="left">最大值方法池化</td><br>  </tr><br>  <tr><br>    <td>tf.nn.max_pool_with_argmax(input, ksize, strides,<br> padding, Targmax=None, name=None)</td><br>    <td align="left">返回一个二维元组(output,argmax),最大值pooling，返回最大值及其相应的索引</td><br>  </tr><br>  <tr><br>    <td>tf.nn.avg_pool3d(input, ksize, strides, <br>padding, name=None)</td><br>    <td align="left">3D平均值pooling</td><br>  </tr><br>  <tr><br>    <td>tf.nn.max_pool3d(input, ksize, strides, <br>padding, name=None)</td><br>    <td align="left">3D最大值pooling</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>数据标准化（Normalization）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.l2_normalize(x, dim, epsilon=1e-12, name=None)</td><br>    <td align="left">对维度dim进行L2范式标准化<br>output = x / sqrt(max(sum(x<em>*2), epsilon))</em></td><br>  </tr><br>  <tr><br>    <td>tf.nn.sufficient_statistics(x, axes, shift=None, <br>keep_dims=False, name=None)</td><br>    <td align="left">计算与均值和方差有关的完全统计量<br>返回4维元组,元素个数，<em>元素总和，</em>元素的平方和，*shift结果<br><a href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data&amp;usg=AFQjCNG5RoY7Xvpv4xg-Wy-UJvAPh2zDQw" target="_blank" rel="external">参见算法介绍</a></td><br>  </tr><br>  <tr><br>    <td>tf.nn.normalize_moments(counts, mean_ss, variance_ss, shift, name=None)</td><br>    <td align="left">基于完全统计量计算均值和方差</td><br>  </tr><br>  <tr><br>    <td>tf.nn.moments(x, axes, shift=None, <br>name=None, keep_dims=False)</td><br>    <td align="left">直接计算均值与方差</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>损失函数（Losses）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.l2_loss(t, name=None)</td><br>    <td align="left">output = sum(t ** 2) / 2</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>分类函数（Classification）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.sigmoid_cross_entropy_with_logits<br>(logits, targets, name=None)*</td><br>    <td align="left">计算输入logits, targets的交叉熵</td><br>  </tr><br>  <tr><br>    <td>tf.nn.softmax(logits, name=None)</td><br>    <td align="left">计算softmax<br>softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))</td><br>  </tr><br>  <tr><br>    <td>tf.nn.log_softmax(logits, name=None)</td><br>    <td align="left">logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))</td><br>  </tr><br>  <tr><br>    <td>tf.nn.softmax_cross_entropy_with_logits<br>(logits, labels, name=None)</td><br>    <td align="left">计算logits和labels的softmax交叉熵<br>logits, labels必须为相同的shape与数据类型</td><br>  </tr><br>  <tr><br>    <td>tf.nn.sparse_softmax_cross_entropy_with_logits<br>(logits, labels, name=None)</td><br>    <td align="left">计算logits和labels的softmax交叉熵</td><br>  </tr><br>  <tr><br>    <td>tf.nn.weighted_cross_entropy_with_logits<br>(logits, targets, pos_weight, name=None)</td><br>    <td align="left">与sigmoid_cross_entropy_with_logits()相似，<br>但给正向样本损失加了权重pos_weight</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>符号嵌入（Embeddings）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.embedding_lookup<br>(params, ids, partition_strategy=’mod’, <br>name=None, validate_indices=True)</td><br>    <td align="left">根据索引ids查询embedding列表params中的tensor值<br>如果len(params) &gt; 1，id将会安照partition_strategy策略进行分割<br>1、如果partition_strategy为”mod”，<br>id所分配到的位置为p = id % len(params)<br>比如有13个ids，分为5个位置，那么分配方案为：<br>[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]<br>2、如果partition_strategy为”div”,那么分配方案为：<br>[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]</td><br>  </tr><br>  <tr><br>    <td>tf.nn.embedding_lookup_sparse(params, <br>sp_ids, sp_weights, partition_strategy=’mod’, <br>name=None, combiner=’mean’)</td><br>    <td align="left">对给定的ids和权重查询embedding<br>1、sp_ids为一个N x M的稀疏tensor，<br>N为batch大小，M为任意，数据类型int64<br>2、sp_weights的shape与sp_ids的稀疏tensor权重，<br>浮点类型，若为None，则权重为全’1’</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li>循环神经网络（Recurrent Neural Networks）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.rnn(cell, inputs, initial_state=None, dtype=None, <br>sequence_length=None, scope=None)</td><br>    <td align="left">基于RNNCell类的实例cell建立循环神经网络<br></td><br>  </tr><br>  <tr><br>    <td>tf.nn.dynamic_rnn(cell, inputs, sequence_length=None, <br>initial_state=None, dtype=None, parallel_iterations=None, <br>swap_memory=False, time_major=False, scope=None)</td><br>    <td align="left">基于RNNCell类的实例cell建立动态循环神经网络<br>与一般rnn不同的是，该函数会根据输入动态展开<br>返回(outputs,state)</td><br>  </tr><br>  <tr><br>    <td>tf.nn.state_saving_rnn(cell, inputs, state_saver, state_name, <br>sequence_length=None, scope=None)</td><br>    <td align="left">可储存调试状态的RNN网络</td><br>  </tr><br>  <tr><br>    <td>tf.nn.bidirectional_rnn(cell_fw, cell_bw, inputs, <br>initial_state_fw=None, initial_state_bw=None, dtype=None,<br> sequence_length=None, scope=None)</td><br>    <td align="left">双向RNN, 返回一个3元组tuple<br>(outputs, output_state_fw, output_state_bw)</td><br>  </tr><br>  </tbody></table>


  <blockquote><br>    <p>— <strong><em>tf.nn.rnn简要介绍</em></strong>— <br><br>      cell: 一个RNNCell实例 <br><br>      inputs: 一个shape为[batch_size, input_size]的tensor <br><br>      initial_state: 为RNN的state设定初值，可选 <br><br>      sequence_length：制定输入的每一个序列的长度，size为[batch_size],值范围为[0, T)的int型数据 <br><br>      其中T为输入数据序列的长度 <br><br>      @ <br><br>      @针对输入batch中序列长度不同，所设置的动态计算机制 <br><br>      @对于在时间t，和batch的b行，有 <br><br>      (output, state)(b, t) = ? (zeros(cell.output_size), states(b, sequence_length(b) - 1)) : cell(input(b, t), state(b, t - 1))</p><br><br>    <hr><br>  </blockquote>

  <ul><br>  <li>求值网络（Evaluation）</li><br>  </ul>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>tf.nn.top_k(input, k=1, sorted=True, name=None)</td><br>    <td align="left">返回前k大的值及其对应的索引</td><br>  </tr><br>  <tr><br>    <td>tf.nn.in_top_k(predictions, targets, k, name=None)</td><br>    <td align="left">返回判断是否targets索引的predictions相应的值<br>是否在在predictions前k个位置中，<br>返回数据类型为bool类型，len与predictions同</td><br>  </tr><br>  </tbody></table>


  <ul><br>  <li><a href="https://www.tensorflow.org/versions/r0.10/extras/candidate_sampling.pdf" target="_blank" rel="external">监督候选采样网络（Candidate Sampling）</a></li><br>  </ul>

  <p>对于有巨大量的多分类与多标签模型，如果使用全连接softmax将会占用大量的时间与空间资源，所以采用候选采样方法仅使用一小部分类别与标签作为监督以加速训练。</p>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td><strong><em>Sampled Loss Functions</em></strong></td><br>    <td align="left"></td><br>  </tr><br>  <tr><br>    <td>tf.nn.nce_loss(weights, biases, inputs, labels, num_sampled,<br> num_classes, num_true=1, sampled_values=None,<br> remove_accidental_hits=False, partition_strategy=’mod’,<br> name=’nce_loss’)</td><br>    <td align="left">返回noise-contrastive的训练损失结果</td><br>  </tr><br>  <tr><br>    <td>tf.nn.sampled_softmax_loss(weights, biases, inputs, labels, <br>num_sampled, num_classes, num_true=1, sampled_values=None,<br> remove_accidental_hits=True, partition_strategy=’mod’, <br>name=’sampled_softmax_loss’)</td><br>    <td align="left">返回sampled softmax的训练损失<br><a href="http://arxiv.org/pdf/1412.2007.pdf" target="_blank" rel="external">参考- Jean et al., 2014第3部分</a></td><br>  </tr><br>  <tr><br>    <td><strong><em>Candidate Samplers</em></strong></td><br>    <td align="left"></td><br>  </tr><br>  <tr><br>    <td>tf.nn.uniform_candidate_sampler(true_classes, num_true, <br>num_sampled, unique, range_max, seed=None, name=None)</td><br>    <td align="left">通过均匀分布的采样集合<br>返回三元tuple<br>1、sampled_candidates 候选集合。<br>2、期望的true_classes个数，为浮点值<br>3、期望的sampled_candidates个数，为浮点值</td><br>  </tr><br>  <tr><br>    <td>tf.nn.log_uniform_candidate_sampler(true_classes, num_true,<br> num_sampled, unique, range_max, seed=None, name=None)</td><br>    <td align="left">通过log均匀分布的采样集合，返回三元tuple</td><br>  </tr><br>  <tr><br>    <td>tf.nn.learned_unigram_candidate_sampler<br>(true_classes, num_true, num_sampled, unique, <br>range_max, seed=None, name=None)</td><br>    <td align="left">根据在训练过程中学习到的分布状况进行采样<br>返回三元tuple</td><br>  </tr><br>  <tr><br>    <td>tf.nn.fixed_unigram_candidate_sampler(true_classes, num_true,<br> num_sampled, unique, range_max, vocab_file=”, <br>distortion=1.0, num_reserved_ids=0, num_shards=1, <br>shard=0, unigrams=(), seed=None, name=None)</td><br>    <td align="left">基于所提供的基本分布进行采样</td><br>  </tr><br>  </tbody></table>




  <h1 id="保存与恢复变量">保存与恢复变量</h1>

  <table><br>  <thead><br>  <tr><br>    <th>操作</th><br>    <th align="left">描述</th><br>  </tr><br>  </thead><br>  <tbody><tr><br>    <td>类tf.train.Saver(Saving and Restoring Variables)</td><br>    <td align="left"></td><br>  </tr><br>  <tr><br>    <td>tf.train.Saver.<strong>init</strong>(var_list=None, reshape=False, <br>sharded=False, max_to_keep=5, <br>keep_checkpoint_every_n_hours=10000.0, <br>name=None, restore_sequentially=False,<br> saver_def=None, builder=None)</td><br>    <td align="left">创建一个存储器Saver<br>var_list定义需要存储和恢复的变量</td><br>  </tr><br>  <tr><br>    <td>tf.train.Saver.save(sess, save_path, global_step=None, <br>latest_filename=None, meta_graph_suffix=’meta’,<br> write_meta_graph=True)</td><br>    <td align="left">保存变量</td><br>  </tr><br>  <tr><br>    <td>tf.train.Saver.restore(sess, save_path)</td><br>    <td align="left">恢复变量</td><br>  </tr><br>  <tr><br>    <td>tf.train.Saver.last_checkpoints</td><br>    <td align="left">列出最近未删除的checkpoint 文件名</td><br>  </tr><br>  <tr><br>    <td>tf.train.Saver.set_last_checkpoints(last_checkpoints)</td><br>    <td align="left">设置checkpoint文件名列表</td><br>  </tr><br>  <tr><br>    <td>tf.train.Saver.set_last_checkpoints_with_time(last_checkpoints_with_time)</td><br>    <td align="left">设置checkpoint文件名列表和时间戳</td><br>  </tr><br>  </tbody></table>



  <p><strong>相关链接：</strong></p>

  <p>[1] 安装Tensorflow（Linux ubuntu） <a href="http://blog.csdn.net/lenbow/article/details/51203526" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51203526</a> <br><br>[2] ubuntu下CUDA编译的GCC降级安装 <a href="http://blog.csdn.net/lenbow/article/details/51596706" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51596706</a> <br><br>[3] ubuntu手动安装最新Nvidia显卡驱动 <a href="http://blog.csdn.net/lenbow/article/details/51683783" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51683783</a> <br><br>[4] Tensorflow的CUDA升级，以及相关配置 <a href="http://blog.csdn.net/lenbow/article/details/52118116" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52118116</a> <br><br>[5] 基于gensim的Doc2Vec简析 <a href="http://blog.csdn.net/lenbow/article/details/52120230" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52120230</a> <br><br>[6] TensorFlow的分布式学习框架简介  <a href="http://blog.csdn.net/lenbow/article/details/52130565" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52130565</a></p>


<div id="article_content" class="article_content"><br>        <div class="markdown_views"><p>摘要：本文主要对tf的一些常用概念与方法进行描述。为‘Tensorflow一些常用基本概念与函数’系列之二。</p><br><br><hr><br><br><br><br><h2 id="1tensorflow的基本运作">1、tensorflow的基本运作</h2><br><br><p>为了快速的熟悉TensorFlow编程，下面从一段简单的代码开始：</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br> <span class="hljs-comment">#定义‘符号’变量，也称为占位符</span><br> a = tf.placeholder(<span class="hljs-string">“float”</span>)<br> b = tf.placeholder(<span class="hljs-string">“float”</span>)<br><br> y = tf.mul(a, b) <span class="hljs-comment">#构造一个op节点</span><br><br> sess = tf.Session()<span class="hljs-comment">#建立会话</span><br> <span class="hljs-comment">#运行会话，输入数据，并计算节点，同时打印结果</span><br> <span class="hljs-keyword">print</span> sess.run(y, feed_dict={a: <span class="hljs-number">3</span>, b: <span class="hljs-number">3</span>})<br> <span class="hljs-comment"># 任务完成, 关闭会话.</span><br> sess.close()</code></pre><br><br><p>其中tf.mul(a, b)函数便是tf的一个基本的算数运算，接下来介绍跟多的相关函数。</p><br><br><br><br><h2 id="2tf函数">2、tf函数</h2><br><br><pre><code>TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU。一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测。如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作.<br>并行计算能让代价大的算法计算加速执行，TensorFlow也在实现上对复杂操作进行了有效的改进。大部分核相关的操作都是设备相关的实现，比如GPU。本文主要涉及的相关概念或操作有以下内容：<br></code></pre><br><br><table><br><thead><br><tr><br>  <th>操作组</th><br>  <th align="left">操作</th><br></tr><br></thead><br><tbody><tr><br>  <td>Building Graphs</td><br>  <td align="left">Core graph data structures，Tensor types，Utility functions</td><br></tr><br><tr><br>  <td>Inputs and Readers</td><br>  <td align="left">Placeholders，Readers，Converting，Queues，Input pipeline</td><br></tr><br></tbody></table><br><br><br><br><br><h3 id="21-建立图building-graphs"><strong>2.1 建立图(Building Graphs)</strong></h3><br><br><p>本节主要介绍建立tensorflow图的相关类或函数</p><br><br><h4 id="核心图的数据结构core-graph-data-structures"><em> <strong>核心图的数据结构（Core graph data structures）</strong></em></h4><br><br><p><strong><em>tf.Graph</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.Graph</td><br>  <td align="left">tensorflow中的计算以图数据流的方式表示<br>一个图包含一系列表示计算单元的操作对象<br>以及在图中流动的数据单元以tensor对象表现</td><br></tr><br><tr><br>  <td>tf.Graph.<strong>init</strong>()</td><br>  <td align="left">建立一个空图</td><br></tr><br><tr><br>  <td>tf.Graph.as_default()</td><br>  <td align="left">一个将某图设置为默认图，并返回一个上下文管理器<br>如果不显式添加一个默认图，系统会自动设置一个全局的默认图。<br>所设置的默认图，在模块范围内所定义的节点都将默认加入默认图中</td><br></tr><br><tr><br>  <td>tf.Graph.as_graph_def<br>(from_version=None, add_shapes=False)</td><br>  <td align="left">返回一个图的序列化的GraphDef表示<br>序列化的<a href="https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/core/framework/graph.proto" target="_blank" rel="external">GraphDef</a>可以导入至另一个图中(使用 import_graph_def())<br>或者使用C++ Session API</td><br></tr><br><tr><br>  <td>tf.Graph.finalize()</td><br>  <td align="left">完成图的构建，即将其设置为只读模式</td><br></tr><br><tr><br>  <td>tf.Graph.finalized</td><br>  <td align="left">返回True，如果图被完成</td><br></tr><br><tr><br>  <td>tf.Graph.control_dependencies(control_inputs)</td><br>  <td align="left">定义一个控制依赖，并返回一个上下文管理器<br>with g.control_dependencies([a, b, c]):<br># <code>d</code> 和 <code>e</code> 将在 <code>a</code>, <code>b</code>, 和<code>c</code>执行完之后运行.<br>d = …<br> e = …</td><br></tr><br><tr><br>  <td>tf.Graph.device(device_name_or_function)</td><br>  <td align="left">定义运行图所使用的设备，并返回一个上下文管理器<br><code>with g.device(‘/gpu:0’): …</code><br><code>with g.device(‘/cpu:0’): …</code></td><br></tr><br><tr><br>  <td>tf.Graph.name_scope(name)</td><br>  <td align="left">为节点创建层次化的名称，并返回一个上下文管理器</td><br></tr><br><tr><br>  <td>tf.Graph.add_to_collection(name, value)</td><br>  <td align="left">将value以name的名称存储在收集器(collection)中</td><br></tr><br><tr><br>  <td>tf.Graph.get_collection(name, scope=None)</td><br>  <td align="left">根据name返回一个收集器中所收集的值的列表</td><br></tr><br><tr><br>  <td>tf.Graph.as_graph_element<br>(obj, allow_tensor=True, allow_operation=True)</td><br>  <td align="left">返回一个图中与obj相关联的对象，为一个操作节点或者tensor数据</td><br></tr><br><tr><br>  <td>tf.Graph.get_operation_by_name(name)</td><br>  <td align="left">根据名称返回操作节点</td><br></tr><br><tr><br>  <td>tf.Graph.get_tensor_by_name(name)</td><br>  <td align="left">根据名称返回tensor数据</td><br></tr><br><tr><br>  <td>tf.Graph.get_operations()</td><br>  <td align="left">返回图中的操作节点列表</td><br></tr><br><tr><br>  <td>tf.Graph.gradient_override_map(op_type_map)</td><br>  <td align="left">用于覆盖梯度函数的上下文管理器</td><br></tr><br></tbody></table><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#class tf.Graph</span><br><span class="hljs-comment">#tensorflow运行时需要设置默认的图</span><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default():<br>  <span class="hljs-comment"># Define operations and tensors in <code>g</code>.</span><br>  c = tf.constant(<span class="hljs-number">30.0</span>)<br>  <span class="hljs-keyword">assert</span> c.graph <span class="hljs-keyword">is</span> g<br><br><span class="hljs-comment">##也可以使用tf.get_default_graph()获得默认图，也可在基础上加入节点或子图</span><br>c = tf.constant(<span class="hljs-number">4.0</span>)<br><span class="hljs-keyword">assert</span> c.graph <span class="hljs-keyword">is</span> tf.get_default_graph()</code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.Graph.as_default</span><br><span class="hljs-comment">#以下两段代码功能相同</span><br><span class="hljs-comment">#1、使用Graph.as_default():</span><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default():<br>  c = tf.constant(<span class="hljs-number">5.0</span>)<br>  <span class="hljs-keyword">assert</span> c.graph <span class="hljs-keyword">is</span> g<br><br><span class="hljs-comment">#2、构造和设置为默认</span><br><span class="hljs-keyword">with</span> tf.Graph().as_default() <span class="hljs-keyword">as</span> g:<br>  c = tf.constant(<span class="hljs-number">5.0</span>)<br>  <span class="hljs-keyword">assert</span> c.graph <span class="hljs-keyword">is</span> g</code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.Graph.control_dependencies(control_inputs)</span><br><span class="hljs-comment"># 错误代码</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_func</span><span class="hljs-params">(pred, tensor)</span>:</span><br>  t = tf.matmul(tensor, tensor)<br>  <span class="hljs-keyword">with</span> tf.control_dependencies([pred]):<br>    <span class="hljs-comment"># 乘法操作(op)没有创建在该上下文，所以没有被加入依赖控制</span><br>    <span class="hljs-keyword">return</span> t<br><br><span class="hljs-comment"># 正确代码</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_func</span><span class="hljs-params">(pred, tensor)</span>:</span><br>  <span class="hljs-keyword">with</span> tf.control_dependencies([pred]):<br>    <span class="hljs-comment"># 乘法操作(op)创建在该上下文，所以被加入依赖控制中</span><br>    <span class="hljs-comment">#执行完pred之后再执行matmul</span><br>    <span class="hljs-keyword">return</span> tf.matmul(tensor, tensor)<br></code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># tf.Graph.name_scope(name)</span><br><span class="hljs-comment"># 一个图中包含有一个名称范围的堆栈，在使用name_scope(…)之后，将压(push)新名称进栈中，</span><br><span class="hljs-comment">#并在下文中使用该名称</span><br><span class="hljs-keyword">with</span> tf.Graph().as_default() <span class="hljs-keyword">as</span> g:<br>  c = tf.constant(<span class="hljs-number">5.0</span>, name=<span class="hljs-string">“c”</span>)<br>  <span class="hljs-keyword">assert</span> c.op.name == <span class="hljs-string">“c”</span><br>  c_1 = tf.constant(<span class="hljs-number">6.0</span>, name=<span class="hljs-string">“c”</span>)<br>  <span class="hljs-keyword">assert</span> c_1.op.name == <span class="hljs-string">“c_1”</span><br><br>  <span class="hljs-comment"># Creates a scope called “nested”</span><br>  <span class="hljs-keyword">with</span> g.name_scope(<span class="hljs-string">“nested”</span>) <span class="hljs-keyword">as</span> scope:<br>    nested_c = tf.constant(<span class="hljs-number">10.0</span>, name=<span class="hljs-string">“c”</span>)<br>    <span class="hljs-keyword">assert</span> nested_c.op.name == <span class="hljs-string">“nested/c”</span><br><br>    <span class="hljs-comment"># Creates a nested scope called “inner”.</span><br>    <span class="hljs-keyword">with</span> g.name_scope(<span class="hljs-string">“inner”</span>):<br>      nested_inner_c = tf.constant(<span class="hljs-number">20.0</span>, name=<span class="hljs-string">“c”</span>)<br>      <span class="hljs-keyword">assert</span> nested_inner_c.op.name == <span class="hljs-string">“nested/inner/c”</span><br><br>    <span class="hljs-comment"># Create a nested scope called “inner_1”.</span><br>    <span class="hljs-keyword">with</span> g.name_scope(<span class="hljs-string">“inner”</span>):<br>      nested_inner_1_c = tf.constant(<span class="hljs-number">30.0</span>, name=<span class="hljs-string">“c”</span>)<br>      <span class="hljs-keyword">assert</span> nested_inner_1_c.op.name == <span class="hljs-string">“nested/inner_1/c”</span><br><br>      <span class="hljs-comment"># Treats <code>scope</code> as an absolute name scope, and</span><br>      <span class="hljs-comment"># switches to the “nested/“ scope.</span><br>      <span class="hljs-keyword">with</span> g.name_scope(scope):<br>        nested_d = tf.constant(<span class="hljs-number">40.0</span>, name=<span class="hljs-string">“d”</span>)<br>        <span class="hljs-keyword">assert</span> nested_d.op.name == <span class="hljs-string">“nested/d”</span><br><br>        <span class="hljs-keyword">with</span> g.name_scope(<span class="hljs-string">“”</span>):<br>          e = tf.constant(<span class="hljs-number">50.0</span>, name=<span class="hljs-string">“e”</span>)<br>          <span class="hljs-keyword">assert</span> e.op.name == <span class="hljs-string">“e”</span><br></code></pre><br><br><hr><br><br><p><strong><em>tf.Operation</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.Operation</td><br>  <td align="left">代表图中的一个节点，用于计算tensors数据<br>该类型将由python节点构造器产生(比如tf.matmul())<br>或者Graph.create_op()<br>例如c = tf.matmul(a, b)创建一个Operation类<br>为类型为”MatMul”,输入为’a’,’b’，输出为’c’的操作类</td><br></tr><br><tr><br>  <td>tf.Operation.name</td><br>  <td align="left">操作节点(op)的名称</td><br></tr><br><tr><br>  <td>tf.Operation.type</td><br>  <td align="left">操作节点(op)的类型，比如”MatMul”</td><br></tr><br><tr><br>  <td>tf.Operation.inputs<br>tf.Operation.outputs</td><br>  <td align="left">操作节点的输入与输出</td><br></tr><br><tr><br>  <td>tf.Operation.control_inputs</td><br>  <td align="left">操作节点的依赖</td><br></tr><br><tr><br>  <td>tf.Operation.run(feed_dict=None, session=None)</td><br>  <td align="left">在会话(Session)中运行该操作</td><br></tr><br><tr><br>  <td>tf.Operation.get_attr(name)</td><br>  <td align="left">获取op的属性值</td><br></tr><br></tbody></table><br><br><br><hr><br><br><p><strong><em>tf.Tensor</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.Tensor</td><br>  <td align="left">表示一个由操作节点op产生的值，<br>TensorFlow程序使用tensor数据结构来代表所有的数据, <br>计算图中, 操作间传递的数据都是 tensor，一个tensor是一个符号handle,<br>里面并没有表示实际数据，而相当于数据流的载体</td><br></tr><br><tr><br>  <td>tf.Tensor.dtype</td><br>  <td align="left">tensor中数据类型</td><br></tr><br><tr><br>  <td>tf.Tensor.name</td><br>  <td align="left">该tensor名称</td><br></tr><br><tr><br>  <td>tf.Tensor.value_index</td><br>  <td align="left">该tensor输出外op的index</td><br></tr><br><tr><br>  <td>tf.Tensor.graph</td><br>  <td align="left">该tensor所处在的图</td><br></tr><br><tr><br>  <td>tf.Tensor.op</td><br>  <td align="left">产生该tensor的op</td><br></tr><br><tr><br>  <td>tf.Tensor.consumers()</td><br>  <td align="left">返回使用该tensor的op列表</td><br></tr><br><tr><br>  <td>tf.Tensor.eval(feed_dict=None, session=None)</td><br>  <td align="left">在会话中求tensor的值<br>需要使用<code>with sess.as_default()</code>或者 <code>eval(session=sess)</code></td><br></tr><br><tr><br>  <td>tf.Tensor.get_shape()</td><br>  <td align="left">返回用于表示tensor的shape的类TensorShape</td><br></tr><br><tr><br>  <td>tf.Tensor.set_shape(shape)</td><br>  <td align="left">更新tensor的shape</td><br></tr><br><tr><br>  <td>tf.Tensor.device</td><br>  <td align="left">设置计算该tensor的设备</td><br></tr><br></tbody></table><br><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.Tensor.get_shape()</span><br>c = tf.constant([[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>]])<br>print(c.get_shape())<br>==&gt; TensorShape([Dimension(<span class="hljs-number">2</span>), Dimension(<span class="hljs-number">3</span>)])</code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#现在有个用于图像处理的tensor-&gt;image</span><br>print(image.get_shape())<br>==&gt; TensorShape([Dimension(<span class="hljs-keyword">None</span>), Dimension(<span class="hljs-keyword">None</span>), Dimension(<span class="hljs-number">3</span>)])<br><span class="hljs-comment"># 假如我们知道数据集中图像尺寸为28 x 28，那么可以设置</span><br>image.set_shape([<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">3</span>])<br>print(image.get_shape())<br>==&gt; TensorShape([Dimension(<span class="hljs-number">28</span>), Dimension(<span class="hljs-number">28</span>), Dimension(<span class="hljs-number">3</span>)])</code></pre><br><br><hr><br><br><br><br><h4 id="tensor类型tensor-types"> <strong>tensor类型(Tensor types)</strong></h4><br><br><p><strong><em>tf.DType</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.DType</td><br>  <td align="left">数据类型主要包含<br>tf.float16，tf.float16,tf.float32,tf.float64,<br>tf.bfloat16,tf.complex64,tf.complex128,<br>tf.int8,tf.uint8,tf.uint16,tf.int16,tf.int32,<br>tf.int64,tf.bool,tf.string</td><br></tr><br><tr><br>  <td>tf.DType.is_compatible_with(other)</td><br>  <td align="left">判断other的数据类型是否将转变为该DType</td><br></tr><br><tr><br>  <td>tf.DType.name</td><br>  <td align="left">数据类型名称</td><br></tr><br><tr><br>  <td>tf.DType.base_dtype</td><br>  <td align="left">返回该DType的基础DType，而非参考的数据类型(non-reference)</td><br></tr><br><tr><br>  <td>tf.DType.as_ref</td><br>  <td align="left">返回一个基于DType的参考数据类型</td><br></tr><br><tr><br>  <td>tf.DType.is_floating</td><br>  <td align="left">判断是否为浮点类型</td><br></tr><br><tr><br>  <td>tf.DType.is_complex</td><br>  <td align="left">判断是否为复数</td><br></tr><br><tr><br>  <td>tf.DType.is_integer</td><br>  <td align="left">判断是否为整数</td><br></tr><br><tr><br>  <td>tf.DType.is_unsigned</td><br>  <td align="left">判断是否为无符号型数据</td><br></tr><br><tr><br>  <td>tf.DType.as_numpy_dtype</td><br>  <td align="left">返回一个基于DType的numpy.dtype类型</td><br></tr><br><tr><br>  <td>tf.DType.max<br>tf.DType.min</td><br>  <td align="left">返回这种数据类型能表示的最大值及其最小值</td><br></tr><br><tr><br>  <td>tf.as_dtype(type_value)</td><br>  <td align="left">返回由type_value转变得的相应tf数据类型</td><br></tr><br></tbody></table><br><br><br><hr><br><br><hr><br><br><h4 id="通用函数utility-functions"><em> <strong>通用函数（Utility functions）</strong></em></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.device(device_name_or_function)</td><br>  <td align="left">基于默认的图，其功能便为Graph.device()</td><br></tr><br><tr><br>  <td>tf.container(container_name)</td><br>  <td align="left">基于默认的图，其功能便为Graph.container()</td><br></tr><br><tr><br>  <td>tf.name_scope(name)</td><br>  <td align="left">基于默认的图，其功能便为 Graph.name_scope()</td><br></tr><br><tr><br>  <td>tf.control_dependencies(control_inputs)</td><br>  <td align="left">基于默认的图，其功能便为Graph.control_dependencies()</td><br></tr><br><tr><br>  <td><strong>tf.convert_to_tensor<br>(value, dtype=None, name=None, as_ref=False)</strong></td><br>  <td align="left">将value转变为tensor数据类型</td><br></tr><br><tr><br>  <td>tf.get_default_graph()</td><br>  <td align="left">返回返回当前线程的默认图</td><br></tr><br><tr><br>  <td>tf.reset_default_graph()</td><br>  <td align="left">清除默认图的堆栈，并设置全局图为默认图</td><br></tr><br><tr><br>  <td>tf.import_graph_def(graph_def, input_map=None,<br> return_elements=None, name=None, op_dict=None,<br> producer_op_list=None)</td><br>  <td align="left">将graph_def的图导入到python中</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="图收集graph-collections"> <strong>图收集（Graph collections）</strong></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.add_to_collection(name, value)</td><br>  <td align="left">基于默认的图，其功能便为Graph.add_to_collection()</td><br></tr><br><tr><br>  <td>tf.get_collection(key, scope=None)</td><br>  <td align="left">基于默认的图，其功能便为Graph.get_collection()</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="定义新操作节点defining-new-operations"><em> <strong>定义新操作节点（Defining new operations）</strong></em></h4><br><br><p><strong><em>tf.RegisterGradient</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.RegisterGradient</td><br>  <td align="left">返回一个用于寄存op类型的梯度函数的装饰器</td><br></tr><br><tr><br>  <td>tf.NoGradient(op_type)</td><br>  <td align="left">设置操作节点类型op_type的节点没有指定的梯度</td><br></tr><br><tr><br>  <td>class tf.RegisterShape</td><br>  <td align="left">返回一个用于寄存op类型的shape函数的装饰器</td><br></tr><br><tr><br>  <td>class tf.TensorShape</td><br>  <td align="left">表示tensor的shape</td><br></tr><br><tr><br>  <td>tf.TensorShape.merge_with(other)</td><br>  <td align="left">与other合并shape信息，返回一个TensorShape类</td><br></tr><br><tr><br>  <td>tf.TensorShape.concatenate(other)</td><br>  <td align="left">与other的维度相连结</td><br></tr><br><tr><br>  <td>tf.TensorShape.ndims</td><br>  <td align="left">返回tensor的rank</td><br></tr><br><tr><br>  <td>tf.TensorShape.dims</td><br>  <td align="left">返回tensor的维度</td><br></tr><br><tr><br>  <td>tf.TensorShape.as_list()</td><br>  <td align="left">以list的形式返回tensor的shape</td><br></tr><br><tr><br>  <td>tf.TensorShape.is_compatible_with(other)</td><br>  <td align="left">判断shape是否为兼容<br>TensorShape(None)与其他任何shape值兼容</td><br></tr><br><tr><br>  <td>class tf.Dimension</td><br>  <td align="left"></td><br></tr><br><tr><br>  <td>tf.Dimension.is_compatible_with(other)</td><br>  <td align="left">判断dims是否为兼容</td><br></tr><br><tr><br>  <td>tf.Dimension.merge_with(other)</td><br>  <td align="left">与other合并dims信息</td><br></tr><br><tr><br>  <td><strong>tf.op_scope(values, name, default_name=None)</strong></td><br>  <td align="left">在python定义op时，返回一个上下文管理器</td><br></tr><br></tbody></table><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.RegisterGradient</span><br><span class="hljs-comment">#该装饰器只使用于定义一个新的op类型时候，如果一个op有m个输入，n个输出。那么该梯度函数应该设置原始的</span><br><span class="hljs-comment">#操作类型，以及n个Tensor对象（表示每一个op输出的梯度），以及m个对象(表示每一个op输入的偏梯度)</span><br><span class="hljs-comment">#以操作节点类型为’Sub’为例，两输入为x,y。为一个输出x-y</span><br><span class="hljs-decorator">@tf.RegisterGradient(“Sub”)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_sub_grad</span><span class="hljs-params">(unused_op, grad)</span>:</span><br>  <span class="hljs-keyword">return</span> grad, tf.neg(grad)</code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.op_scope</span><br><span class="hljs-comment">#定义一个名称为my_op的python操作节点op</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_op</span><span class="hljs-params">(a, b, c, name=None)</span>:</span><br>  <span class="hljs-keyword">with</span> tf.op_scope([a, b, c], name, <span class="hljs-string">“MyOp”</span>) <span class="hljs-keyword">as</span> scope:<br>    a = tf.convert_to_tensor(a, name=<span class="hljs-string">“a”</span>)<br>    b = tf.convert_to_tensor(b, name=<span class="hljs-string">“b”</span>)<br>    c = tf.convert_to_tensor(c, name=<span class="hljs-string">“c”</span>)<br>    <span class="hljs-comment"># Define some computation that uses <code>a</code>, <code>b</code>, and <code>c</code>.</span><br>    <span class="hljs-keyword">return</span> foo_op(…, name=scope)</code></pre><br><br><hr><br><br><hr><br><br><br><br><h3 id="22-输入和读取器inputs-and-readers">2.2 <strong>输入和读取器(Inputs and Readers)</strong></h3><br><br><p>本节主要介绍tensorflow中数据的读入相关类或函数</p><br><br><hr><br><br><h4 id="占位符placeholders"> <strong>占位符（Placeholders）</strong></h4><br><br><p>tf提供一种占位符操作，在执行时需要为其提供数据data。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.placeholder(dtype, shape=None, name=None)</td><br>  <td align="left">为一个tensor插入一个占位符<br>eg:x = tf.placeholder(tf.float32, shape=(1024, 1024))</td><br></tr><br><tr><br>  <td>tf.placeholder_with_default(input, shape, name=None)</td><br>  <td align="left">当输出没有fed时，input通过一个占位符op</td><br></tr><br><tr><br>  <td>tf.sparse_placeholder(dtype, shape=None, name=None)</td><br>  <td align="left">为一个稀疏tensor插入一个占位符</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="读取器readers"><em> <strong>读取器（Readers）</strong></em></h4><br><br><p>tf提供一系列读取各种数据格式的类。对于多文件输入，可以使用函数<a href="https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#string_input_producer" target="_blank" rel="external">tf.train.string_input_producer</a>，该函数将创建一个保持文件的FIFO队列，以供reader使用。或者如果输入的这些文件名有相雷同的字符串，也可以使用函数<a href="https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#match_filenames_once" target="_blank" rel="external">tf.train.match_filenames_once</a>。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.ReaderBase</td><br>  <td align="left">不同的读取器类型的基本类</td><br></tr><br><tr><br>  <td>tf.ReaderBase.read(queue, name=None)</td><br>  <td align="left">返回下一个记录对(key, value),queue为tf文件队列FIFOQueue</td><br></tr><br><tr><br>  <td>tf.ReaderBase.read_up_to(queue, num_records, name=None)</td><br>  <td align="left">返回reader产生的num_records对(key, value)</td><br></tr><br><tr><br>  <td>tf.ReaderBase.reader_ref</td><br>  <td align="left">返回应用在该reader上的Op</td><br></tr><br><tr><br>  <td>tf.ReaderBase.reset(name=None)</td><br>  <td align="left">恢复reader为初始状态</td><br></tr><br><tr><br>  <td>tf.ReaderBase.restore_state(state, name=None)</td><br>  <td align="left">恢复reader为之前的保存状态state</td><br></tr><br><tr><br>  <td>tf.ReaderBase.serialize_state(name=None)</td><br>  <td align="left">返回一个reader解码后产生的字符串tansor</td><br></tr><br><tr><br>  <td>class tf.TextLineReader</td><br>  <td align="left"></td><br></tr><br><tr><br>  <td>tf.TextLineReader.num_records_produced(name=None)</td><br>  <td align="left">返回reader已经产生的记录(records )数目</td><br></tr><br><tr><br>  <td>tf.TextLineReader.num_work_units_completed(name=None)</td><br>  <td align="left">返回该reader已经完成的处理的work数目</td><br></tr><br><tr><br>  <td>tf.TextLineReader.read(queue, name=None)</td><br>  <td align="left">返回reader所产生的下一个记录对 (key, value)，该reader可以限定新产生输出的行数</td><br></tr><br><tr><br>  <td>tf.TextLineReader.reader_ref</td><br>  <td align="left">返回应用在该reader上的Op</td><br></tr><br><tr><br>  <td>tf.TextLineReader.reset(name=None)</td><br>  <td align="left">恢复reader为初始状态</td><br></tr><br><tr><br>  <td>tf.TextLineReader.restore_state(state, name=None)</td><br>  <td align="left">恢复reader为之前的保存状态state</td><br></tr><br><tr><br>  <td>tf.TextLineReader.serialize_state(name=None)</td><br>  <td align="left">返回一个reader解码后产生的字符串tansor</td><br></tr><br><tr><br>  <td>class tf.WholeFileReader</td><br>  <td align="left">一个阅读器，读取整个文件，返回文件名称key,以及文件中所有的内容value,该类的方法同上，不赘述</td><br></tr><br><tr><br>  <td>class tf.IdentityReader</td><br>  <td align="left">一个reader，以key和value的形式，输出一个work队列。该类其他方法基本同上</td><br></tr><br><tr><br>  <td>class tf.TFRecordReader</td><br>  <td align="left">读取TFRecord格式文件的reader。该类其他方法基本同上</td><br></tr><br><tr><br>  <td>class tf.FixedLengthRecordReader</td><br>  <td align="left">输出</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="数据转换converting"> <strong>数据转换（Converting）</strong></h4><br><br><p>tf提供一系列方法将各种格式数据转换为tensor表示。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.decode_csv(records, record_defaults, <br>field_delim=None, name=None)</td><br>  <td align="left">将csv转换为tensor，与tf.TextLineReader搭配使用</td><br></tr><br><tr><br>  <td>tf.decode_raw(bytes, out_type, <br>little_endian=None, name=None)</td><br>  <td align="left">将bytes转换为一个数字向量表示，bytes为一个字符串类型的tensor<br>与函数 tf.FixedLengthRecordReader搭配使用，详见<a href="https://www.tensorflow.org/code/tensorflow/models/image/cifar10/cifar10_input.py" target="_blank" rel="external">tf的CIFAR-10例子</a></td><br></tr><br></tbody></table><br><br><br><p>选取与要输入的文件格式相匹配的reader，并将文件队列提供给reader的读方法( read method)。读方法将返回文件唯一标识的key，以及一个记录(record)（有助于对出现一些另类的records时debug），以及一个标量的字符串值。再使用一个（或多个）解码器(decoder) 或转换操作(conversion ops)将字符串转换为tensor类型。</p><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#读取文件队列，使用reader中read的方法，返回key与value</span><br>filename_queue = tf.train.string_input_producer([<span class="hljs-string">“file0.csv”</span>, <span class="hljs-string">“file1.csv”</span>])<br>reader = tf.TextLineReader()<br>key, value = reader.read(filename_queue)<br><br>record_defaults = [[<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>]]<br>col1, col2, col3, col4, col5 = tf.decode_csv(<br>    value, record_defaults=record_defaults)<br>features = tf.pack([col1, col2, col3, col4])<br><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>  <span class="hljs-comment"># Start populating the filename queue.</span><br>  coord = tf.train.Coordinator()<br>  threads = tf.train.start_queue_runners(coord=coord)<br><br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1200</span>):<br>    <span class="hljs-comment"># Retrieve a single instance:</span><br>    example, label = sess.run([features, col5])<br><br>  coord.request_stop()<br>  coord.join(threads)</code></pre><br><br><hr><br><br><br><br><h4 id="example-protocol-buffer"><em> <strong>Example protocol buffer</strong></em></h4><br><br><p>提供了一些<a href="https://www.tensorflow.org/code/tensorflow/core/example/example.proto" target="_blank" rel="external">Example protocol buffers</a>，tf所<a href="https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/index.html#standard-tensorflow-format" target="_blank" rel="external">推荐的用于训练样本的数据格式</a>，它们包含特征信息，<a href="https://www.tensorflow.org/code/tensorflow/core/example/feature.proto" target="_blank" rel="external">详情可见</a>。 <br><br>这是一种与前述将手上现有的各种数据类型转换为支持的格式的方法，这种方法更容易将网络结构与数据集融合或匹配。这种tensorflow所推荐的数据格式是一个包含tf.train.Example protocol buffers (包含特征<a href="https://www.tensorflow.org/code/tensorflow/core/example/feature.proto" target="_blank" rel="external">Features</a>域)的TFRecords文件。 <br><br>1、获取这种格式的文件方式为，首先将一般的数据格式填入Example protocol buffer中，再将 protocol buffer序列化为一个字符串，然后使用tf.python_io.TFRecordWriter类的相关方法将字符串写入一个TFRecords文件中，<a href="https://www.tensorflow.org/code/tensorflow/examples/how_tos/reading_data/convert_to_records.py" target="_blank" rel="external">参见MNIST例子</a>，将MNIST 数据转换为该类型数据。 <br><br>2、读取TFRecords格式文件的方法为，使用tf.TFRecordReader读取器和tf.parse_single_example解码器。parse_single_example操作将 example protocol buffers解码为tensor形式。<a href="https://www.tensorflow.org/code/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py" target="_blank" rel="external">参见MNIST例子</a></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.VarLenFeature</td><br>  <td align="left">解析变长的输入特征feature相关配置</td><br></tr><br><tr><br>  <td>class tf.FixedLenFeature</td><br>  <td align="left">解析定长的输入特征feature相关配置</td><br></tr><br><tr><br>  <td>class tf.FixedLenSequenceFeature</td><br>  <td align="left">序列项目中的稠密(dense )输入特征的相关配置</td><br></tr><br><tr><br>  <td><strong>tf.parse_example(serialized, features, <br>name=None, example_names=None)</strong></td><br>  <td align="left">将一组Example protos解析为tensor的字典形式<br>解析serialized所给予的序列化的一些Example protos<br>返回一个由特征keys映射Tensor和SparseTensor值的字典</td><br></tr><br><tr><br>  <td><strong>tf.parse_single_example(serialized, features, <br>name=None, example_names=None)</strong></td><br>  <td align="left">解析一个单独的Example proto，与tf.parse_example方法雷同</td><br></tr><br><tr><br>  <td>tf.decode_json_example(json_examples, name=None)</td><br>  <td align="left">将JSON编码的样本记录转换为二进制protocol buffer字符串</td><br></tr><br></tbody></table><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.parse_example的使用举例</span><br><span class="hljs-comment">#输入序列化数据如下： </span><br>serialized = [<br>  features<br>    { feature { key: <span class="hljs-string">“ft”</span> value { float_list { value: [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>] } } } },<br>  features<br>    { feature []},<br>  features<br>    { feature { key: <span class="hljs-string">“ft”</span> value { float_list { value: [<span class="hljs-number">3.0</span>] } } }<br>]<br><span class="hljs-comment">#那么输出为一个字典(dict),如下：</span><br>{<span class="hljs-string">“ft”</span>: SparseTensor(indices=[[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>]],<br>                    values=[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>],<br>                    shape=(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>)) }<br><span class="hljs-comment">#########</span><br><span class="hljs-comment">#再来看一个例子，给定两个序列化的原始输入样本：</span><br>[<br>  features {<br>    feature { key: <span class="hljs-string">“kw”</span> value { bytes_list { value: [ <span class="hljs-string">“knit”</span>, <span class="hljs-string">“big”</span> ] } } }<br>    feature { key: <span class="hljs-string">“gps”</span> value { float_list { value: [] } } }<br>  },<br>  features {<br>    feature { key: <span class="hljs-string">“kw”</span> value { bytes_list { value: [ <span class="hljs-string">“emmy”</span> ] } } }<br>    feature { key: <span class="hljs-string">“dank”</span> value { int64_list { value: [ <span class="hljs-number">42</span> ] } } }<br>    feature { key: <span class="hljs-string">“gps”</span> value { } }<br>  }<br>]<br><span class="hljs-comment">#相关参数如下：</span><br>example_names: [<span class="hljs-string">“input0”</span>, <span class="hljs-string">“input1”</span>],<br>features: {<br>    <span class="hljs-string">“kw”</span>: VarLenFeature(tf.string),<br>    <span class="hljs-string">“dank”</span>: VarLenFeature(tf.int64),<br>    <span class="hljs-string">“gps”</span>: VarLenFeature(tf.float32),<br>}<br><span class="hljs-comment">#那么有如下输出：</span><br>{<br>  <span class="hljs-string">“kw”</span>: SparseTensor(<br>      indices=[[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]],<br>      values=[<span class="hljs-string">“knit”</span>, <span class="hljs-string">“big”</span>, <span class="hljs-string">“emmy”</span>]<br>      shape=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]),<br>  <span class="hljs-string">“dank”</span>: SparseTensor(<br>      indices=[[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]],<br>      values=[<span class="hljs-number">42</span>],<br>      shape=[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>]),<br>  <span class="hljs-string">“gps”</span>: SparseTensor(<br>      indices=[],<br>      values=[],<br>      shape=[<span class="hljs-number">2</span>, <span class="hljs-number">0</span>]),<br>}<br><span class="hljs-comment">#########</span><br><span class="hljs-comment">#对于两个样本的输出稠密结果情况</span><br>[<br>  features {<br>    feature { key: <span class="hljs-string">“age”</span> value { int64_list { value: [ <span class="hljs-number">0</span> ] } } }<br>    feature { key: <span class="hljs-string">“gender”</span> value { bytes_list { value: [ <span class="hljs-string">“f”</span> ] } } }<br>   },<br>   features {<br>    feature { key: <span class="hljs-string">“age”</span> value { int64_list { value: [] } } }<br>    feature { key: <span class="hljs-string">“gender”</span> value { bytes_list { value: [ <span class="hljs-string">“f”</span> ] } } }<br>  }<br>]<br><span class="hljs-comment">#我们可以使用以下参数</span><br>example_names: [<span class="hljs-string">“input0”</span>, <span class="hljs-string">“input1”</span>],<br>features: {<br>    <span class="hljs-string">“age”</span>: FixedLenFeature([], dtype=tf.int64, default_value=-<span class="hljs-number">1</span>),<br>    <span class="hljs-string">“gender”</span>: FixedLenFeature([], dtype=tf.string),<br>}<br><span class="hljs-comment">#期望的结果如下</span><br>{<br>  <span class="hljs-string">“age”</span>: [[<span class="hljs-number">0</span>], [-<span class="hljs-number">1</span>]],<br>  <span class="hljs-string">“gender”</span>: [[<span class="hljs-string">“f”</span>], [<span class="hljs-string">“f”</span>]],<br>}</code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">##Example protocol buffer相关使用的例子</span><br><span class="hljs-comment">#将mnist的数据转换为TFRecords文件格式</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow.contrib.learn.python.learn.datasets <span class="hljs-keyword">import</span> mnist<br>SOURCE_URL = <span class="hljs-string">‘<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">http://yann.lecun.com/exdb/mnist/</a>‘</span><br><br>TRAIN_IMAGES = <span class="hljs-string">‘train-images-idx3-ubyte.gz’</span>  <span class="hljs-comment"># MNIST filenames</span><br>TRAIN_LABELS = <span class="hljs-string">‘train-labels-idx1-ubyte.gz’</span><br>TEST_IMAGES = <span class="hljs-string">‘t10k-images-idx3-ubyte.gz’</span><br>TEST_LABELS = <span class="hljs-string">‘t10k-labels-idx1-ubyte.gz’</span><br><br>tf.app.flags.DEFINE_string(<span class="hljs-string">‘directory’</span>, <span class="hljs-string">‘/tmp/data’</span>,<br>                           <span class="hljs-string">‘Directory to download data files and write the ‘</span><br>                           <span class="hljs-string">‘converted result’</span>)<br>tf.app.flags.DEFINE_integer(<span class="hljs-string">‘validation_size’</span>, <span class="hljs-number">5000</span>,<br>                            <span class="hljs-string">‘Number of examples to separate from the training ‘</span><br>                            <span class="hljs-string">‘data for the validation set.’</span>)<br>FLAGS = tf.app.flags.FLAGS<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_int64_feature</span><span class="hljs-params">(value)</span>:</span><br>  <span class="hljs-keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_bytes_feature</span><span class="hljs-params">(value)</span>:</span><br>  <span class="hljs-keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">convert_to</span><span class="hljs-params">(data_set, name)</span>:</span><br>  images = data_set.images<br>  labels = data_set.labels<br>  num_examples = data_set.num_examples<br><br>  <span class="hljs-keyword">if</span> images.shape[<span class="hljs-number">0</span>] != num_examples:<br>    <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">‘Images size %d does not match label size %d.’</span> %<br>                     (images.shape[<span class="hljs-number">0</span>], num_examples))<br>  rows = images.shape[<span class="hljs-number">1</span>]<br>  cols = images.shape[<span class="hljs-number">2</span>]<br>  depth = images.shape[<span class="hljs-number">3</span>]<br><br>  filename = os.path.join(FLAGS.directory, name + <span class="hljs-string">‘.tfrecords’</span>)<br>  print(<span class="hljs-string">‘Writing’</span>, filename)<br>  writer = tf.python_io.TFRecordWriter(filename)<br>  <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> range(num_examples):<br>    image_raw = images[index].tostring()<br>    example = tf.train.Example(features=tf.train.Features(feature={<br>        <span class="hljs-string">‘height’</span>: _int64_feature(rows),<br>        <span class="hljs-string">‘width’</span>: _int64_feature(cols),<br>        <span class="hljs-string">‘depth’</span>: _int64_feature(depth),<br>        <span class="hljs-string">‘label’</span>: _int64_feature(int(labels[index])),<br>        <span class="hljs-string">‘image_raw’</span>: _bytes_feature(image_raw)}))<br>    writer.write(example.SerializeToString())<br>  writer.close()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">(argv)</span>:</span><br>  <span class="hljs-comment"># Get the data.</span><br>  data_sets = mnist.read_data_sets(FLAGS.directory,<br>                                   dtype=tf.uint8,<br>                                   reshape=<span class="hljs-keyword">False</span>)<br><br>  <span class="hljs-comment"># Convert to Examples and write the result to TFRecords.</span><br>  convert_to(data_sets.train, <span class="hljs-string">‘train’</span>)<br>  convert_to(data_sets.validation, <span class="hljs-string">‘validation’</span>)<br>  convert_to(data_sets.test, <span class="hljs-string">‘test’</span>)<br><br><span class="hljs-keyword">if</span> <strong>name</strong> == <span class="hljs-string">‘<strong>main</strong>‘</span>:<br>  tf.app.run()<br></code></pre><br><br><hr><br><br><br><br><h4 id="队列queues"> <strong>队列(Queues)</strong></h4><br><br><p>tensorflow提供了几个队列应用，用来将tf计算图与tensors的阶段流水组织到一起。队列是使用tensorflow计算的一个强大的机制，正如其他Tensorflow的元素一样，一个队列也是tf图中的一个节点(node),它是一个有状态的node，就像一个变量：其他节点可以改变其内容。 <br><br>我们来看一个简单的例子，如下gif图，我们将创建一个先入先出队列(FIFOQueue)并且将值全设为0，然后我们构建一个图以获取队列出来的元素，对该元素加1操作，并将结果再放入队列末尾。渐渐地，队列中的数字便增加。 <br><br><img src="http://img.blog.csdn.net/20160815145525960" alt="这里写图片描述" title=""></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.QueueBase</td><br>  <td align="left">基本的队列应用类.队列(queue)是一种数据结构，<br>该结构通过多个步骤存储tensors,<br>并且对tensors进行入列(enqueue)与出列(dequeue)操作</td><br></tr><br><tr><br>  <td>tf.QueueBase.enqueue(vals, name=None)</td><br>  <td align="left">将一个元素编入该队列中。如果在执行该操作时队列已满，<br>那么将会阻塞直到元素编入队列之中</td><br></tr><br><tr><br>  <td>tf.QueueBase.enqueue_many(vals, name=None)</td><br>  <td align="left">将零个或多个元素编入该队列中</td><br></tr><br><tr><br>  <td>tf.QueueBase.dequeue(name=None)</td><br>  <td align="left">将元素从队列中移出。如果在执行该操作时队列已空，<br>那么将会阻塞直到元素出列，返回出列的tensors的tuple</td><br></tr><br><tr><br>  <td>tf.QueueBase.dequeue_many(n, name=None)</td><br>  <td align="left">将一个或多个元素从队列中移出</td><br></tr><br><tr><br>  <td>tf.QueueBase.size(name=None)</td><br>  <td align="left">计算队列中的元素个数</td><br></tr><br><tr><br>  <td>tf.QueueBase.close<br>(cancel_pending_enqueues=False, name=None)</td><br>  <td align="left">关闭该队列</td><br></tr><br><tr><br>  <td>f.QueueBase.dequeue_up_to(n, name=None)</td><br>  <td align="left">从该队列中移出n个元素并将之连接</td><br></tr><br><tr><br>  <td>tf.QueueBase.dtypes</td><br>  <td align="left">列出组成元素的数据类型</td><br></tr><br><tr><br>  <td>tf.QueueBase.from_list(index, queues)</td><br>  <td align="left">根据queues[index]的参考队列创建一个队列</td><br></tr><br><tr><br>  <td>tf.QueueBase.name</td><br>  <td align="left">返回最队列下面元素的名称</td><br></tr><br><tr><br>  <td>tf.QueueBase.names</td><br>  <td align="left">返回队列每一个组成部分的名称</td><br></tr><br><tr><br>  <td><strong>class tf.FIFOQueue</strong></td><br>  <td align="left">在出列时依照先入先出顺序，其他方法与tf.QueueBase雷同</td><br></tr><br><tr><br>  <td>class tf.PaddingFIFOQueue</td><br>  <td align="left">一个FIFOQueue ，同时根据padding支持batching变长的tensor</td><br></tr><br><tr><br>  <td><strong>class tf.RandomShuffleQueue</strong></td><br>  <td align="left">该队列将随机元素出列，其他方法与tf.QueueBase雷同</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="文件系统的处理dealing-with-the-filesystem"><em> <strong>文件系统的处理(Dealing with the filesystem)</strong></em></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.matching_files(pattern, name=None)</td><br>  <td align="left">返回与pattern匹配模式的文件名称</td><br></tr><br><tr><br>  <td><strong>tf.read_file(filename, name=None)</strong></td><br>  <td align="left">读取并输出输入文件的整个内容</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="输入管道input-pipeline"> <strong>输入管道(Input pipeline)</strong></h4><br><br><p>用于设置输入预取数的管道TF函数，函数 “producer”添加一个队列至图中，同时一个相应用于运行队列中子图(subgraph)的QueueRunner </p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.train.match_filenames_once(pattern, name=None)</td><br>  <td align="left">保存与pattern的文件列表</td><br></tr><br><tr><br>  <td>tf.train.limit_epochs(tensor, num_epochs=None, name=None)</td><br>  <td align="left">返回一个num_epochs次数，然后报告OutOfRange错误</td><br></tr><br><tr><br>  <td>tf.train.input_producer(input_tensor, element_shape=None, <br>num_epochs=None, shuffle=True, seed=None, capacity=32, <br>shared_name=None, summary_name=None, name=None)</td><br>  <td align="left">为一个输入管道输出input_tensor中的多行至一个队列中</td><br></tr><br><tr><br>  <td>tf.train.range_input_producer(limit, num_epochs=None, <br>shuffle=True, seed=None, capacity=32, <br>shared_name=None, name=None)</td><br>  <td align="left">产生一个从1至limit-1的整数至队列中</td><br></tr><br><tr><br>  <td>tf.train.slice_input_producer(tensor_list, num_epochs=None, <br>shuffle=True, seed=None, capacity=32, <br>shared_name=None, name=None)</td><br>  <td align="left">对tensor_list中的每一个tensor切片</td><br></tr><br><tr><br>  <td><strong>tf.train.string_input_producer(string_tensor, num_epochs=None,<br> shuffle=True, seed=None, capacity=32, <br>shared_name=None, name=None)</strong></td><br>  <td align="left">为一个输入管道输出一组字符串(比如文件名)至队列中</td><br></tr><br></tbody></table><br><br><br><hr><br><br><h4 id="在输入管道末端批量打包batching-at-the-end-of-an-input-pipeline"><em> <strong>在输入管道末端批量打包(Batching at the end of an input pipeline)</strong></em></h4><br><br><p>该相关函数增添一个队列至图中以将数据一样本打包为batch。它们也会添加 一个QueueRunner，以便执行的已经被填满队列的子图</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.train.batch(tensors, batch_size, num_threads=1,<br> capacity=32, enqueue_many=False, shapes=None, <br>dynamic_pad=False, allow_smaller_final_batch=False, <br>shared_name=None, name=None)</td><br>  <td align="left">在输入的tensors中创建一些tensor数据格式的batch，<br>若输入为shape[, x, y, z]，那么输出则为[batch_size, x, y, z]<br>返回一个列表或者一个具有与输入tensors相同类型tensors的字典</td><br></tr><br><tr><br>  <td>tf.train.batch_join(tensors_list, batch_size, <br>capacity=32, enqueue_many=False, shapes=None, <br>dynamic_pad=False, allow_smaller_final_batch=False, <br>shared_name=None, name=None)</td><br>  <td align="left">将一个tensors的列表添加至一个队列中以创建样本的batches<br>len(tensors_list)个线程将启动，<br>线程i将tensors_list[i]的tensors入列<br>tensors_list[i1][j]与tensors_list[i2][j]有相同的类型和shape</td><br></tr><br><tr><br>  <td><strong>tf.train.shuffle_batch(tensors, batch_size, capacity, <br>min_after_dequeue, num_threads=1, seed=None, <br>enqueue_many=False, shapes=None, <br>allow_smaller_final_batch=False,<br> shared_name=None, name=None)</strong></td><br>  <td align="left">使用随机乱序的方法创建batches<br>tensors:用于入列的一个list或者dict<br>capacity:一个整数，表示队列中元素最大数目</td><br></tr><br><tr><br>  <td>tf.train.shuffle_batch_join(tensors_list, batch_size, <br>capacity, min_after_dequeue, seed=None, <br>enqueue_many=False, shapes=None, <br>allow_smaller_final_batch=False, <br>shared_name=None, name=None)</td><br>  <td align="left">随机乱序的tensors创建batches，<br>其中tensors_list参数为tensors元组或tensors字典的列表<br>len(tensors_list)个线程将启动，<br>线程i将tensors_list[i]的tensors入列<br>tensors_list[i1][j]与tensors_list[i2][j]有相同的类型和shape</td><br></tr><br></tbody></table><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># 一个简单例子，使用tf.train.shuffle_batch创建一个具有32张图像和32个标签的batches.</span><br>image_batch, label_batch = tf.train.shuffle_batch(<br>      [single_image, single_label],<br>      batch_size=<span class="hljs-number">32</span>,<br>      num_threads=<span class="hljs-number">4</span>,<br>      capacity=<span class="hljs-number">50000</span>,<br>      min_after_dequeue=<span class="hljs-number">10000</span>)<br></code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#Batching函数相关例子，以函数tf.train.shuffle_batch为例</span><br><span class="hljs-comment">#为training, evaluation等操作将样本batching，以下代码使用随机顺序打包样本</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read_my_file_format</span><span class="hljs-params">(filename_queue)</span>:</span><br>  reader = tf.SomeReader()<br>  key, record_string = reader.read(filename_queue)<br>  example, label = tf.some_decoder(record_string)<br>  processed_example = some_processing(example)<br>  <span class="hljs-keyword">return</span> processed_example, label<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">input_pipeline</span><span class="hljs-params">(filenames, batch_size, num_epochs=None)</span>:</span><br>  filename_queue = tf.train.string_input_producer(<br>      filenames, num_epochs=num_epochs, shuffle=<span class="hljs-keyword">True</span>)<br>  example, label = read_my_file_format(filename_queue)<br>  <span class="hljs-comment"># min_after_dequeue defines how big a buffer we will randomly sample</span><br>  <span class="hljs-comment">#   from – bigger means better shuffling but slower start up and more</span><br>  <span class="hljs-comment">#   memory used.</span><br>  <span class="hljs-comment"># capacity must be larger than min_after_dequeue and the amount larger</span><br>  <span class="hljs-comment">#   determines the maximum we will prefetch.  Recommendation:</span><br>  <span class="hljs-comment">#   min_after_dequeue + (num_threads + a small safety margin) <em> batch_size</em></span><br>  min_after_dequeue = <span class="hljs-number">10000</span><br>  capacity = min_after_dequeue + <span class="hljs-number">3</span>  batch_size<br>  example_batch, label_batch = tf.train.shuffle_batch(<br>      [example, label], batch_size=batch_size, capacity=capacity,<br>      min_after_dequeue=min_after_dequeue)<br>  <span class="hljs-keyword">return</span> example_batch, label_batch</code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#如果需要跟多的并行或文件之间的样本乱序操作，可以使用函数tf.train.shuffle_batch_join多实例化reader</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read_my_file_format</span><span class="hljs-params">(filename_queue)</span>:</span><br>  <span class="hljs-comment"># 与上例子相同</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">input_pipeline</span><span class="hljs-params">(filenames, batch_size, read_threads, num_epochs=None)</span>:</span><br>  filename_queue = tf.train.string_input_producer(<br>      filenames, num_epochs=num_epochs, shuffle=<span class="hljs-keyword">True</span>)<br>  example_list = [read_my_file_format(filename<em>queue)<br>                  <span class="hljs-keyword">for</span> </em> <span class="hljs-keyword">in</span> range(read_threads)]<br>  min_after_dequeue = <span class="hljs-number">10000</span><br>  capacity = min_after_dequeue + <span class="hljs-number">3</span> * batch_size<br>  example_batch, label_batch = tf.train.shuffle_batch_join(<br>      example_list, batch_size=batch_size, capacity=capacity,<br>      min_after_dequeue=min_after_dequeue)<br>  <span class="hljs-keyword">return</span> example_batch, label_batch<br></code></pre><br><br><hr><br><br><hr><br><br><p><strong>相关链接：</strong></p><br><br><p>[1] 安装Tensorflow（Linux ubuntu） <a href="http://blog.csdn.net/lenbow/article/details/51203526" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51203526</a> <br><br>[2] ubuntu下CUDA编译的GCC降级安装 <a href="http://blog.csdn.net/lenbow/article/details/51596706" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51596706</a> <br><br>[3] ubuntu手动安装最新Nvidia显卡驱动 <a href="http://blog.csdn.net/lenbow/article/details/51683783" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51683783</a> <br><br>[4] Tensorflow的CUDA升级，以及相关配置 <a href="http://blog.csdn.net/lenbow/article/details/52118116" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52118116</a> <br><br>[5] 基于gensim的Doc2Vec简析 <a href="http://blog.csdn.net/lenbow/article/details/52120230" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52120230</a> <br><br>[6] TensorFlow的分布式学习框架简介 <a href="http://blog.csdn.net/lenbow/article/details/52130565" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52130565</a> <br><br>[7] Tensorflow一些常用基本概念与函数（1）  <a href="http://blog.csdn.net/lenbow/article/details/52152766" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52152766</a></p></div>

<div id="article_content" class="article_content"><br>        <div class="markdown_views"><p>摘要：本系列主要对tf的一些常用概念与方法进行描述。本文主要针对tensorflow的数据IO、图的运行等相关函数进行讲解。为‘Tensorflow一些常用基本概念与函数’系列之三。</p><br><br><br><br><h2 id="1序言">1、序言</h2><br><br><p>本文所讲的内容主要为以下相关函数：</p><br><br><table><br><thead><br><tr><br>  <th>操作组</th><br>  <th align="left">操作</th><br></tr><br></thead><br><tbody><tr><br>  <td>Data IO (Python functions)</td><br>  <td align="left">TFRecordWrite，rtf_record_iterator</td><br></tr><br><tr><br>  <td>Running Graphs</td><br>  <td align="left">Session management，Error classes</td><br></tr><br></tbody></table><br><br><br><h2 id="2tf函数">2、tf函数</h2><br><br><br><br><h3 id="21-数据io-data-io-python-functions">2.1 数据IO {Data IO (Python functions)}</h3><br><br><p>一个TFRecords 文件为一个字符串序列。这种格式并非随机获取，它比较适合大规模的数据流，而不太适合需要快速分区或其他非序列获取方式。</p><br><br><br><br><h4 id="数据io-data-io-python-functions">数据IO {Data IO (Python functions)}</h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.python_io.TFRecordWriter</td><br>  <td align="left">一个用于将记录(records)写入TFRecords文件的类</td><br></tr><br><tr><br>  <td>tf.python_io.TFRecordWriter.<strong>init</strong>(path, options=None)</td><br>  <td align="left">打开文件路径，并创建一个TFRecordWriter以供写入</td><br></tr><br><tr><br>  <td>tf.python_io.TFRecordWriter.write(record)</td><br>  <td align="left">将一个字符串records写入文件中</td><br></tr><br><tr><br>  <td>tf.python_io.TFRecordWriter.close()</td><br>  <td align="left">关闭文件</td><br></tr><br><tr><br>  <td>tf.python_io.tf_record_iterator(path, options=None)</td><br>  <td align="left">从TFRecords文件中读取记录的迭代器</td><br></tr><br></tbody></table><br><br><br><hr><br><br><br><br><h3 id="22-运行图running-graphs">2.2 运行图(Running Graphs)</h3><br><br><br><br><h4 id="会话管理-session-management"><strong>会话管理 (Session management)</strong></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.Session</td><br>  <td align="left">运行TF操作的类,<br>一个Session对象将操作节点op封装在一定的环境内运行，<br>同时tensor对象将被计算求值</td><br></tr><br><tr><br>  <td>tf.Session.<strong>init</strong>(target=”, graph=None, config=None)</td><br>  <td align="left">创建一个新的会话</td><br></tr><br><tr><br>  <td>tf.Session.run(fetches, feed_dict=None, <br>options=None, run_metadata=None)</td><br>  <td align="left">运行fetches中的操作节点并求其值</td><br></tr><br><tr><br>  <td>tf.Session.close()</td><br>  <td align="left">关闭会话</td><br></tr><br><tr><br>  <td>tf.Session.graph</td><br>  <td align="left">返回加载值该会话的图(graph)</td><br></tr><br><tr><br>  <td><strong>tf.Session.as_default()</strong></td><br>  <td align="left">设置该对象为默认会话，并返回一个上下文管理器</td><br></tr><br><tr><br>  <td>tf.Session.reset(target, containers=None, config=None)</td><br>  <td align="left">重设target的资源容器，并关闭所有连接的会话<br>在0.10版本该功能仅应用在分布会话中<br>target:为执行引擎所连接的目标，其包含有资源容器，<br>该资源容器分布在同一个集群的所有works上</td><br></tr><br><tr><br>  <td>class tf.InteractiveSession</td><br>  <td align="left">使用在交互式上下文环境的tf会话，比如shell，ipython</td><br></tr><br><tr><br>  <td>tf.InteractiveSession.close()</td><br>  <td align="left">关闭一个InteractiveSession</td><br></tr><br><tr><br>  <td>tf.get_default_session()</td><br>  <td align="left">返回当前线程的默认会话</td><br></tr><br></tbody></table><br><br><br><p><strong><em>tf.Session</em></strong></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#一个简单的tf.Session例子</span><br><span class="hljs-comment"># 建立一个graph.</span><br>a = tf.constant(<span class="hljs-number">5.0</span>)<br>b = tf.constant(<span class="hljs-number">6.0</span>)<br>c = a <em> b<br><br><span class="hljs-comment"># 将graph载入到一个会话session中</span><br>sess = tf.Session()<br><br><span class="hljs-comment"># 计算tensor <code>c</code>.</span><br>print(sess.run(c))<br></em></code></pre><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#一个会话可能会占用一些资源，比如变量、队列和读取器(reader)。释放这些不再使用的资源非常重要。</span><br><span class="hljs-comment">#使用close()方法关闭会话，或者使用上下文管理器，释放资源。</span><br><span class="hljs-comment"># 使用<code>close()</code>方法.</span><br>sess = tf.Session()<br>sess.run(…)<br>sess.close()<br><br><span class="hljs-comment"># 使用上下文管理器</span><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>  sess.run(…)<br></code></pre><br><br><p>tf.Session()的变量设置， ConfigProto protocol buffer为会话提供了不同的配置选项。比如，创建一个会话，对设备布局使用软约束条件，以及对分布</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># Launch the graph in a session that allows soft device placement and</span><br><span class="hljs-comment"># logs the placement decisions.</span><br>sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=<span class="hljs-keyword">True</span>,<br>                                        log_device_placement=<span class="hljs-keyword">True</span>))<br></code></pre><br><br><p><strong><em>tf.Session.run</em></strong></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><br> a = tf.constant([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>])<br>   b = tf.constant([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>])<br>   <span class="hljs-comment"># ‘fetches’ 可以为单个数</span><br>   v = session.run(a)<br>   <span class="hljs-comment"># v is the numpy array [10, 20]</span><br>   <span class="hljs-comment"># ‘fetches’ 可以为一个list.</span><br>   v = session.run([a, b])<br>   <span class="hljs-comment"># v a Python list with 2 numpy arrays: the numpy array [10, 20] and the</span><br>   <span class="hljs-comment"># 1-D array [1.0, 2.0]</span><br>   <span class="hljs-comment"># ‘fetches’ 可以是 lists, tuples, namedtuple, dicts中的任意:</span><br>   MyData = collections.namedtuple(<span class="hljs-string">‘MyData’</span>, [<span class="hljs-string">‘a’</span>, <span class="hljs-string">‘b’</span>])<br>   v = session.run({<span class="hljs-string">‘k1’</span>: MyData(a, b), <span class="hljs-string">‘k2’</span>: [b, a]})<br>   <span class="hljs-comment"># v 为一个dict，并有</span><br>   <span class="hljs-comment"># v[‘k1’] is a MyData namedtuple with ‘a’ the numpy array [10, 20] and</span><br>   <span class="hljs-comment"># ‘b’ the numpy array [1.0, 2.0]</span><br>   <span class="hljs-comment"># v[‘k2’] is a list with the numpy array [1.0, 2.0] and the numpy array</span><br>   <span class="hljs-comment"># [10, 20].</span><br></code></pre><br><br><p><strong><em>tf.Session.as_default()</em></strong> <br><br>使用关键字with指定会话， 可以在会话中执行<a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">Operation.run()</a>或<a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">Tensor.eval()</a>，以得到运行的tensor结果</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">c = tf.constant(..)<br>sess = tf.Session()<br><br><span class="hljs-keyword">with</span> sess.as_default():<br>  <span class="hljs-keyword">assert</span> tf.get_default_session() <span class="hljs-keyword">is</span> sess<br>  print(c.eval())<br></code></pre><br><br><p>使用函数tf.get_default_session()来得到当前默认的会话 <br><br>需要注意的是，退出该as_default上下文管理器时，并没有关闭该会话(session )，必须明确的关闭会话</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">c = tf.constant(…)<br>sess = tf.Session()<br><span class="hljs-keyword">with</span> sess.as_default():<br>  print(c.eval())<br><span class="hljs-comment"># …</span><br><span class="hljs-keyword">with</span> sess.as_default():<br>  print(c.eval())<br><span class="hljs-comment">#关闭会话</span><br>sess.close()<br><span class="hljs-comment">#使用 with tf.Session()方式可以创建并自动关闭会话</span></code></pre><br><br><p><strong><em>tf.InteractiveSession</em></strong></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">sess = tf.InteractiveSession()<br>a = tf.constant(<span class="hljs-number">5.0</span>)<br>b = tf.constant(<span class="hljs-number">6.0</span>)<br>c = a  b<br><span class="hljs-comment"># 我们直接使用’c.eval()’ 而没有通过’sess’</span><br>print(c.eval())<br>sess.close()</code></pre><br><br><p>以上的例子，在非交互会话的版本中为，</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">a = tf.constant(<span class="hljs-number">5.0</span>)<br>b = tf.constant(<span class="hljs-number">6.0</span>)<br>c = a * b<br><span class="hljs-keyword">with</span> tf.Session():<br>  <span class="hljs-comment"># We can also use ‘c.eval()’ here.</span><br>  print(c.eval())</code></pre><br><br><br><br><h1 id="abc">ABC</h1><br><br><br><br><h4 id="错误类-error-classes"><strong>错误类 (Error classes)</strong></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.OpError</td><br>  <td align="left">一个基本的错误类型，在当TF执行失败时候报错</td><br></tr><br><tr><br>  <td>tf.OpError.op</td><br>  <td align="left">返回执行失败的操作节点，<br>有的操作如Send或Recv可能不会返回，那就要用用到node_def方法</td><br></tr><br><tr><br>  <td><strong>tf.OpError.node_def</strong></td><br>  <td align="left">以NodeDef proto形式表示失败的op</td><br></tr><br><tr><br>  <td>tf.OpError.error_code</td><br>  <td align="left">描述该错误的整数错误代码</td><br></tr><br><tr><br>  <td>tf.OpError.message</td><br>  <td align="left">返回错误信息</td><br></tr><br><tr><br>  <td>class tf.errors.CancelledError</td><br>  <td align="left">当操作或者阶段呗取消时候报错</td><br></tr><br><tr><br>  <td>class tf.errors.UnknownError</td><br>  <td align="left">未知错误类型</td><br></tr><br><tr><br>  <td>class tf.errors.InvalidArgumentError</td><br>  <td align="left">在接收到非法参数时候报错</td><br></tr><br><tr><br>  <td>class tf.errors.NotFoundError</td><br>  <td align="left">当发现不存在所请求的一个实体时候，比如文件或目录</td><br></tr><br><tr><br>  <td>class tf.errors.AlreadyExistsError</td><br>  <td align="left">当创建的实体已经存在的时候报错</td><br></tr><br><tr><br>  <td>class tf.errors.PermissionDeniedError</td><br>  <td align="left">没有执行权限做某操作的时候报错</td><br></tr><br><tr><br>  <td>class tf.errors.ResourceExhaustedError</td><br>  <td align="left">资源耗尽时报错</td><br></tr><br><tr><br>  <td>class tf.errors.FailedPreconditionError</td><br>  <td align="left">系统没有条件执行某个行为时候报错</td><br></tr><br><tr><br>  <td>class tf.errors.AbortedError</td><br>  <td align="left">操作中止时报错，常常发生在并发情形</td><br></tr><br><tr><br>  <td>class tf.errors.OutOfRangeError</td><br>  <td align="left">超出范围报错</td><br></tr><br><tr><br>  <td>class tf.errors.UnimplementedError</td><br>  <td align="left">某个操作没有执行时报错</td><br></tr><br><tr><br>  <td>class tf.errors.InternalError</td><br>  <td align="left">当系统经历了一个内部错误时报出</td><br></tr><br><tr><br>  <td>class tf.errors.DataLossError</td><br>  <td align="left">当出现不可恢复的错误<br>例如在运行 <a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">tf.WholeFileReader.read()</a>读取整个文件的同时文件被删减</td><br></tr><br><tr><br>  <td>tf.errors.XXXXX.<strong>init</strong>(node_def, op, message)</td><br>  <td align="left">使用该形式方法创建以上各种错误类</td><br></tr><br></tbody></table><br><br><br><hr><br><br><hr><br><br><p>相关链接：</p><br><br><p>[1] 安装Tensorflow（Linux ubuntu） <a href="http://blog.csdn.net/lenbow/article/details/51203526" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51203526</a> <br><br>[2] ubuntu下CUDA编译的GCC降级安装 <a href="http://blog.csdn.net/lenbow/article/details/51596706" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51596706</a> <br><br>[3] ubuntu手动安装最新Nvidia显卡驱动 <a href="http://blog.csdn.net/lenbow/article/details/51683783" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51683783</a> <br><br>[4] Tensorflow的CUDA升级，以及相关配置 <a href="http://blog.csdn.net/lenbow/article/details/52118116" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52118116</a> <br><br>[5] 基于gensim的Doc2Vec简析 <a href="http://blog.csdn.net/lenbow/article/details/52120230" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52120230</a> <br><br>[6] TensorFlow的分布式学习框架简介 <a href="http://blog.csdn.net/lenbow/article/details/52130565" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52130565</a> <br><br>[7] Tensorflow一些常用基本概念与函数（1） <a href="http://blog.csdn.net/lenbow/article/details/52152766" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52152766</a> <br><br>[8] Tensorflow一些常用基本概念与函数（2） <a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52181159</a></p></div>

<div id="article_content" class="article_content"><br>        <div class="markdown_views"><p>摘要：本系列主要对tf的一些常用概念与方法进行描述。本文主要针对tensorflow的模型训练Training与测试Testing等相关函数进行讲解。为‘Tensorflow一些常用基本概念与函数’系列之四。</p><br><br><h2 id="1序言">1、序言</h2><br><br><p>本文所讲的内容主要为以下列表中相关函数。函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作，在训练过程中，先实例化一个优化函数，比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：</p><br><br><pre><code>optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br></code></pre><br><br><p>然后，可以设置 一个用于记录全局训练步骤的单值。以及使用minimize()操作，该操作不仅可以优化更新训练的模型参数，也可以为全局步骤(global step)计数。与其他tensorflow操作类似，这些训练操作都需要在<a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">tf.session</a>会话中进行</p><br><br><pre><code>global_step = tf.Variable(0, name=’global_step’, trainable=False)<br>train_op = optimizer.minimize(loss, global_step=global_step)<br></code></pre><br><br><table><br><thead><br><tr><br>  <th>操作组</th><br>  <th align="left">操作</th><br></tr><br></thead><br><tbody><tr><br>  <td>Training</td><br>  <td align="left">Optimizers，Gradient Computation，Gradient Clipping，Distributed execution</td><br></tr><br><tr><br>  <td>Testing</td><br>  <td align="left">Unit tests，Utilities，Gradient checking</td><br></tr><br></tbody></table><br><br><br><br><br><h2 id="2tensorflow函数">2、Tensorflow函数</h2><br><br><br><br><h3 id="21-训练-training">2.1 训练 (Training)</h3><br><br><p>一个TFRecords 文件为一个字符串序列。这种格式并非随机获取，它比较适合大规模的数据流，而不太适合需要快速分区或其他非序列获取方式。</p><br><br><br><br><h4 id="优化-optimizers">█ <strong>优化 (Optimizers)</strong></h4><br><br><p>tf中各种优化类提供了为损失函数计算梯度的方法，其中包含比较经典的优化算法，比如GradientDescent 和Adagrad。</p><br><br><p>▶▶<strong><em>class tf.train.Optimizer</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.train.Optimizer</td><br>  <td align="left">基本的优化类，该类不常常被直接调用，而较多使用其子类，<br>比如GradientDescentOptimizer, AdagradOptimizer<br>或者MomentumOptimizer</td><br></tr><br><tr><br>  <td>tf.train.Optimizer.<strong>init</strong>(use_locking, name)</td><br>  <td align="left">创建一个新的优化器，<br>该优化器必须被其子类(subclasses)的构造函数调用</td><br></tr><br><tr><br>  <td><strong>tf.train.Optimizer.minimize(loss, global_step=None, <br>var_list=None, gate_gradients=1, <br>aggregation_method=None, colocate_gradients_with_ops=False, <br>name=None, grad_loss=None)</strong></td><br>  <td align="left">添加操作节点，用于最小化loss，并更新var_list<br>该函数是简单的合并了compute_gradients()与apply_gradients()函数<br>返回为一个优化更新后的var_list，如果global_step非None，该操作还会为global_step做自增操作</td><br></tr><br><tr><br>  <td>tf.train.Optimizer.compute_gradients(loss,var_list=None, gate_gradients=1,<br> aggregation_method=None, <br>colocate_gradients_with_ops=False, grad_loss=None)</td><br>  <td align="left">对var_list中的变量计算loss的梯度<br>该函数为函数minimize()的第一部分，返回一个以元组(gradient, variable)组成的列表</td><br></tr><br><tr><br>  <td>tf.train.Optimizer.apply_gradients(grads_and_vars, global_step=None, name=None)</td><br>  <td align="left">将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global_step做自增操作</td><br></tr><br><tr><br>  <td>tf.train.Optimizer.get_name()</td><br>  <td align="left">获取名称</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>class tf.train.Optimizer</em> <br><br>用法</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># Create an optimizer with the desired parameters.</span><br>opt = GradientDescentOptimizer(learning_rate=<span class="hljs-number">0.1</span>)<br><span class="hljs-comment"># Add Ops to the graph to minimize a cost by updating a list of variables.</span><br><span class="hljs-comment"># “cost” is a Tensor, and the list of variables contains tf.Variable objects.</span><br>opt_op = opt.minimize(cost, var_list=&lt;list of variables&gt;)<br><span class="hljs-comment"># Execute opt_op to do one step of training:</span><br>opt_op.run()</code></pre><br><br><p>▶▶<strong><em>在使用它们之前处理梯度</em></strong> <br><br>使用minimize()操作，该操作不仅可以计算出梯度，而且还可以将梯度作用在变量上。如果想在使用它们之前处理梯度，可以按照以下三步骤使用optimizer ：</p><br><br><pre><code>1、使用函数compute_gradients()计算梯度<br>2、按照自己的愿望处理梯度<br>3、使用函数apply_gradients()应用处理过后的梯度<br></code></pre><br><br><p>例如：</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># 创建一个optimizer.</span><br>opt = GradientDescentOptimizer(learning_rate=<span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment"># 计算&lt;list of variables&gt;相关的梯度</span><br>grads_and_vars = opt.compute_gradients(loss, &lt;list of variables&gt;)<br><br><span class="hljs-comment"># grads_and_vars为tuples (gradient, variable)组成的列表。</span><br><span class="hljs-comment">#对梯度进行想要的处理，比如cap处理</span><br>capped_grads_and_vars = [(MyCapper(gv[<span class="hljs-number">0</span>]), gv[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> gv <span class="hljs-keyword">in</span> grads_and_vars]<br><br><span class="hljs-comment"># 令optimizer运用capped的梯度(gradients)</span><br>opt.apply_gradients(capped_grads_and_vars)</code></pre><br><br><p>▶▶<strong><em>选通梯度(Gating Gradients)</em></strong> <br><br>函数minimize() 与compute_gradients()都含有一个参数gate_gradient，用于控制在应用这些梯度时并行化的程度。</p><br><br><p>其值可以取：GATE_NONE, GATE_OP 或 GATE_GRAPH <br><br>GATE_NONE : 并行地计算和应用梯度。提供最大化的并行执行，但是会导致有的数据结果没有再现性。比如两个matmul操作的梯度依赖输入值，使用GATE_NONE可能会出现有一个梯度在其他梯度之前便应用到某个输入中，导致出现不可再现的(non-reproducible)结果 <br><br>GATE_OP: 对于每个操作Op，确保每一个梯度在使用之前都已经计算完成。这种做法防止了那些具有多个输入，并且梯度计算依赖输入情形中，多输入Ops之间的竞争情况出现。 <br><br> GATE_GRAPH: 确保所有的变量对应的所有梯度在他们任何一个被使用前计算完成。该方式具有最低级别的并行化程度，但是对于想要在应用它们任何一个之前处理完所有的梯度计算时很有帮助的。</p><br><br><p><br></p><br><br><br><br><h4 id="slots">█ <strong>Slots</strong></h4><br><br><p>一些optimizer的之类，比如 MomentumOptimizer 和 AdagradOptimizer 分配和管理着额外的用于训练的变量。这些变量称之为’Slots’，Slots有相应的名称，可以向optimizer访问的slots名称。有助于在log debug一个训练算法以及报告slots状态</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.train.Optimizer.get_slot_names()</td><br>  <td align="left">返回一个由Optimizer所创建的slots的名称列表</td><br></tr><br><tr><br>  <td>tf.train.Optimizer.get_slot(var, name)</td><br>  <td align="left">返回一个name所对应的slot，name是由Optimizer为var所创建<br>var为用于传入 minimize() 或 apply_gradients()的变量</td><br></tr><br><tr><br>  <td><strong>class tf.train.GradientDescentOptimizer</strong></td><br>  <td align="left">使用梯度下降算法的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.GradientDescentOptimizer.<strong>init</strong>(learning_rate, <br>use_locking=False, name=’GradientDescent’)</td><br>  <td align="left">构建一个新的梯度下降优化器(Optimizer)</td><br></tr><br><tr><br>  <td><strong>class tf.train.AdadeltaOptimizer</strong></td><br>  <td align="left">使用<a href="http://arxiv.org/abs/1212.5701" target="_blank" rel="external">Adadelta算法</a>的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.AdadeltaOptimizer.<strong>init</strong>(learning_rate=0.001, <br>rho=0.95, epsilon=1e-08, <br>use_locking=False, name=’Adadelta’)</td><br>  <td align="left">创建Adadelta优化器</td><br></tr><br><tr><br>  <td><strong>class tf.train.AdagradOptimizer</strong></td><br>  <td align="left">使用<a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" target="_blank" rel="external">Adagrad算法</a>的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.AdagradOptimizer.<strong>init</strong>(learning_rate, <br>initial_accumulator_value=0.1, <br>use_locking=False, name=’Adagrad’)</td><br>  <td align="left">创建Adagrad优化器</td><br></tr><br><tr><br>  <td>class tf.train.MomentumOptimizer</td><br>  <td align="left">使用<a href="http://www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="external">Momentum</a>算法的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.MomentumOptimizer.<strong>init</strong>(learning_rate, <br>momentum, use_locking=False, <br>name=’Momentum’, use_nesterov=False)</td><br>  <td align="left">创建momentum优化器<br>momentum：动量，一个tensor或者浮点值</td><br></tr><br><tr><br>  <td><strong>class tf.train.AdamOptimizer</strong></td><br>  <td align="left">使用<a href="http://arxiv.org/abs/1412.6980" target="_blank" rel="external">Adam 算法</a>的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.AdamOptimizer.<strong>init</strong>(learning_rate=0.001,<br> beta1=0.9, beta2=0.999, epsilon=1e-08,<br> use_locking=False, name=’Adam’)</td><br>  <td align="left">创建Adam优化器</td><br></tr><br><tr><br>  <td>class tf.train.FtrlOptimizer</td><br>  <td align="left">使用<a href="https://www.eecs.tufts.edu/%7Edsculley/papers/ad-click-prediction.pdf" target="_blank" rel="external">FTRL 算法</a>的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.FtrlOptimizer.<strong>init</strong>(learning_rate, <br>learning_rate_power=-0.5, <br>initial_accumulator_value=0.1, <br>l1_regularization_strength=0.0, <br>l2_regularization_strength=0.0,<br> use_locking=False, name=’Ftrl’)</td><br>  <td align="left">创建FTRL算法优化器</td><br></tr><br><tr><br>  <td>class tf.train.RMSPropOptimizer</td><br>  <td align="left">使用<a href="http://www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="external">RMSProp算法</a>的Optimizer</td><br></tr><br><tr><br>  <td>tf.train.RMSPropOptimizer.<strong>init</strong>(learning_rate, <br>decay=0.9, momentum=0.0, epsilon=1e-10, <br>use_locking=False, name=’RMSProp’)</td><br>  <td align="left">创建RMSProp算法优化器</td><br></tr><br></tbody></table><br><br><br><p>▷ <em><a href="http://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="external">tf.train.AdamOptimizer</a></em> <br><br>Adam 的基本运行方式，首先初始化：</p><br><br><pre><code>m_0 &lt;- 0 (Initialize initial 1st moment vector)<br>v_0 &lt;- 0 (Initialize initial 2nd moment vector)<br>t &lt;- 0 (Initialize timestep)<br></code></pre><br><br><p>在<a href="http://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="external">论文</a>中的 section2 的末尾所描述了更新规则，该规则使用梯度g来更新变量：</p><br><br><pre><code>t &lt;- t + 1<br>lr_t &lt;- learning_rate <em> sqrt(1 - beta2^t) / (1 - beta1^t)<br><br>m_t &lt;- beta1 </em> m_{t-1} + (1 - beta1) <em> g<br>v_t &lt;- beta2 </em> v_{t-1} + (1 - beta2) <em> g </em> g<br>variable &lt;- variable - lr_t <em> m_t / (sqrt(v_t) + epsilon)<br></em></code></pre><br><br><p>其中epsilon 的默认值1e-8可能对于大多数情况都不是一个合适的值。例如，当在ImageNet上训练一个 Inception network时比较好的选择为1.0或者0.1。 <br><br>需要注意的是，在稠密数据中即便g为0时， m_t, v_t 以及variable都将会更新。而在稀疏数据中，m_t, v_t 以及variable不被更新且值为零。</p><br><br><br><br><h4 id="梯度计算与截断gradient-computation-and-clipping">█ <strong>梯度计算与截断(Gradient Computation and Clipping)</strong></h4><br><br><p>TensorFlow 提供了计算给定tf计算图的求导函数，并在图的基础上增加节点。优化器(optimizer )类可以自动的计算网络图的导数，但是优化器中的创建器(creators )或者专业的人员可以通过本节所述的函数调用更底层的方法。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.gradients(ys, xs, grad_ys=None, name=’gradients’, <br>colocate_gradients_with_ops=False, gate_gradients=False, <br>aggregation_method=None)</td><br>  <td align="left">构建一个符号函数，计算ys关于xs中x的偏导的和，<br>返回xs中每个x对应的sum(dy/dx)</td><br></tr><br><tr><br>  <td>tf.stop_gradient(input, name=None)</td><br>  <td align="left">停止计算梯度，<br>在EM算法、Boltzmann机等可能会使用到</td><br></tr><br><tr><br>  <td>tf.clip_by_value(t, clip_value_min, clip_value_max, name=None)</td><br>  <td align="left">基于定义的min与max对tesor数据进行截断操作，<br>目的是为了应对梯度爆发或者梯度消失的情况</td><br></tr><br><tr><br>  <td>tf.clip_by_norm(t, clip_norm, axes=None, name=None)</td><br>  <td align="left">使用L2范式标准化tensor最大值为clip_norm<br>返回 t  clip_norm / l2norm(t)</td><br></tr><br><tr><br>  <td>tf.clip_by_average_norm(t, clip_norm, name=None)</td><br>  <td align="left">使用平均L2范式规范tensor数据t，<br>并以clip_norm为最大值<br>返回 t <em> clip_norm / l2norm_avg(t)</em></td><br></tr><br><tr><br>  <td>tf.clip_by_global_norm(t_list, <br>clip_norm, use_norm=None, name=None)</td><br>  <td align="left">返回t_list[i]  clip_norm / max(global_norm, clip_norm)<br>其中global_norm = sqrt(sum([l2norm(t)<strong>2 for t in t_list]))</strong></td><br></tr><br><tr><br>  <td>tf.global_norm(t_list, name=None)</td><br>  <td align="left">返回global_norm = sqrt(sum([l2norm(t)2 for t in t_list]))</td><br></tr><br></tbody></table><br><br><br><p><br></p><br><br><br><br><h4 id="退化学习率decaying-the-learning-rate">█ <strong>退化学习率(Decaying the learning rate)</strong></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.train.exponential_decay(learning_rate, global_step, <br>decay_steps, decay_rate, staircase=False, name=None)</td><br>  <td align="left">对学习率进行指数衰退</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>tf.train.exponential_decay</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#该函数返回以下结果</span><br>decayed_learning_rate = learning_rate <em><br>         decay_rate ^ (global_step / decay_steps)<br><span class="hljs-comment">##例： 以0.96为基数，每100000 步进行一次学习率的衰退</span><br>global_step = tf.Variable(<span class="hljs-number">0</span>, trainable=<span class="hljs-keyword">False</span>)<br>starter_learning_rate = <span class="hljs-number">0.1</span><br>learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,<br>                                           <span class="hljs-number">100000</span>, <span class="hljs-number">0.96</span>, staircase=<span class="hljs-keyword">True</span>)<br><span class="hljs-comment"># Passing global_step to minimize() will increment it at each step.</span><br>learning_step = (<br>    tf.train.GradientDescentOptimizer(learning_rate)<br>    .minimize(…my loss…, global_step=global_step)<br>)<br></em></code></pre><br><br><p><br></p><br><br><br><br><h4 id="移动平均moving-averages">█ <strong>移动平均(Moving Averages)</strong></h4><br><br><p>一些训练优化算法，比如GradientDescent 和Momentum 在优化过程中便可以使用到移动平均方法。使用移动平均常常可以较明显地改善结果。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.train.ExponentialMovingAverage</td><br>  <td align="left">将指数衰退加入到移动平均中</td><br></tr><br><tr><br>  <td>tf.train.ExponentialMovingAverage.apply(var_list=None)</td><br>  <td align="left">对var_list变量保持移动平均</td><br></tr><br><tr><br>  <td>tf.train.ExponentialMovingAverage.average_name(var)</td><br>  <td align="left">返回var均值的变量名称</td><br></tr><br><tr><br>  <td>tf.train.ExponentialMovingAverage.average(var)</td><br>  <td align="left">返回var均值变量</td><br></tr><br><tr><br>  <td>tf.train.ExponentialMovingAverage.variables_to_restore(moving_avg_variables=None)</td><br>  <td align="left">返回用于保存的变量名称的映射</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>tf.train.ExponentialMovingAverage</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># Example usage when creating a training model:</span><br><span class="hljs-comment"># Create variables.</span><br>var0 = tf.Variable(…)<br>var1 = tf.Variable(…)<br><span class="hljs-comment"># … use the variables to build a training model…</span><br>…<br><span class="hljs-comment"># Create an op that applies the optimizer.  This is what we usually</span><br><span class="hljs-comment"># would use as a training op.</span><br>opt_op = opt.minimize(my_loss, [var0, var1])<br><br><span class="hljs-comment"># Create an ExponentialMovingAverage object</span><br>ema = tf.train.ExponentialMovingAverage(decay=<span class="hljs-number">0.9999</span>)<br><br><span class="hljs-comment"># Create the shadow variables, and add ops to maintain moving averages</span><br><span class="hljs-comment"># of var0 and var1.</span><br>maintain_averages_op = ema.apply([var0, var1])<br><br><span class="hljs-comment"># Create an op that will update the moving averages after each training</span><br><span class="hljs-comment"># step.  This is what we will use in place of the usual training op.</span><br><span class="hljs-keyword">with</span> tf.control_dependencies([opt_op]):<br>    training_op = tf.group(maintain_averages_op)<br><br>…train the model by running training_op…<br><br><span class="hljs-comment">#Example of restoring the shadow variable values:</span><br><span class="hljs-comment"># Create a Saver that loads variables from their saved shadow values.</span><br>shadow_var0_name = ema.average_name(var0)<br>shadow_var1_name = ema.average_name(var1)<br>saver = tf.train.Saver({shadow_var0_name: var0, shadow_var1_name: var1})<br>saver.restore(…checkpoint filename…)<br><span class="hljs-comment"># var0 and var1 now hold the moving average values</span><br></code></pre><br><br><p>▷ <em>tf.train.ExponentialMovingAverage.variables_to_restore</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><br>  variables_to_restore = ema.variables_to_restore()<br>  saver = tf.train.Saver(variables_to_restore)<br></code></pre><br><br><p><br></p><br><br><br><br><h4 id="协调器和队列运行器coordinator-and-queuerunner">█ <strong>协调器和队列运行器(Coordinator and QueueRunner)</strong></h4><br><br><p>查看<a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">queue</a>中，queue相关的内容，了解tensorflow中队列的运行方式。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.train.Coordinator</td><br>  <td align="left">线程的协调器</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.clear_stop()</td><br>  <td align="left">清除停止标记</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.join(threads=None, stop_grace_period_secs=120)</td><br>  <td align="left">等待线程终止<br>threads:一个threading.Threads的列表，启动的线程，将额外加入到registered的线程中</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.register_thread(thread)</td><br>  <td align="left">Register一个用于join的线程</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.request_stop(ex=None)</td><br>  <td align="left">请求线程结束</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.should_stop()</td><br>  <td align="left">检查是否被请求停止</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.stop_on_exception()</td><br>  <td align="left">上下文管理器，当一个例外出现时请求停止</td><br></tr><br><tr><br>  <td>tf.train.Coordinator.wait_for_stop(timeout=None)</td><br>  <td align="left">等待Coordinator提示停止进程</td><br></tr><br><tr><br>  <td><strong>class tf.train.QueueRunner</strong></td><br>  <td align="left">持有一个队列的入列操作列表，用于线程中运行<br>queue:一个队列<br>enqueue_ops: 用于线程中运行的入列操作列表</td><br></tr><br><tr><br>  <td>tf.train.QueueRunner.create_threads(sess, <br>coord=None, daemon=False, start=False)</td><br>  <td align="left">创建运行入列操作的线程，返回一个线程列表</td><br></tr><br><tr><br>  <td>tf.train.QueueRunner.from_proto(queue_runner_def)</td><br>  <td align="left">返回由queue_runner_def创建的QueueRunner对象</td><br></tr><br><tr><br>  <td>tf.train.add_queue_runner(qr, collection=’queue_runners’)</td><br>  <td align="left">增加一个QueueRunner到graph的收集器(collection )中</td><br></tr><br><tr><br>  <td>tf.train.start_queue_runners(sess=None, coord=None, daemon=True, start=True, collection=’queue_runners’)</td><br>  <td align="left">启动所有graph收集到的队列运行器(queue runners)</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>class tf.train.Coordinator</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#Coordinator的使用，用于多线程的协调</span><br><span class="hljs-keyword">try</span>:<br>  …<br>  coord = Coordinator()<br>  <span class="hljs-comment"># Start a number of threads, passing the coordinator to each of them.</span><br>  …start thread <span class="hljs-number">1.</span>..(coord, …)<br>  …start thread N…(coord, …)<br>  <span class="hljs-comment"># Wait for all the threads to terminate, give them 10s grace period</span><br>  coord.join(threads, stop_grace_period_secs=<span class="hljs-number">10</span>)<br><span class="hljs-keyword">except</span> RuntimeException:<br>  …one of the threads took more than <span class="hljs-number">10</span>s to stop after request_stop()<br>  …was called.<br><span class="hljs-keyword">except</span> Exception:<br>  …exception that was passed to coord.request_stop()<br></code></pre><br><br><p>▷ <em>tf.train.Coordinator.stop_on_exception()</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">with</span> coord.stop_on_exception():<br>  <span class="hljs-comment"># Any exception raised in the body of the with</span><br>  <span class="hljs-comment"># clause is reported to the coordinator before terminating</span><br>  <span class="hljs-comment"># the execution of the body.</span><br>  …body…<br><span class="hljs-comment">#等价于</span><br><span class="hljs-keyword">try</span>:<br>  …body…<br>exception Exception <span class="hljs-keyword">as</span> ex:<br>  coord.request_stop(ex)</code></pre><br><br><p><br></p><br><br><br><br><h4 id="布执行distributed-execution">█ <strong>布执行(Distributed execution)</strong></h4><br><br><p>可以阅读<a href="http://blog.csdn.net/lenbow/article/details/52130565" target="_blank" rel="external">TensorFlow的分布式学习框架简介 </a>查看更多tensorflow分布式细节。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td><strong>class tf.train.Server</strong></td><br>  <td align="left">一个进程内的tensorflow服务，用于分布式训练</td><br></tr><br><tr><br>  <td>tf.train.Server.<strong>init</strong>(server_or_cluster_def, <br>job_name=None, task_index=None, protocol=None,<br> config=None, start=True)</td><br>  <td align="left">创建一个新的服务，其中job_name, task_index, <br>和protocol为可选参数，<br>优先级高于server_or_cluster_def中相关信息<br>server_or_cluster_def :  为一个tf.train.ServerDef <br>或 tf.train.ClusterDef 协议(protocol)的buffer，<br>或者一个tf.train.ClusterSpec对象</td><br></tr><br><tr><br>  <td><strong>tf.train.Server.create_local_server(config=None, start=True)</strong></td><br>  <td align="left">创建一个新的运行在本地主机的单进程集群</td><br></tr><br><tr><br>  <td><strong>tf.train.Server.target</strong></td><br>  <td align="left">返回tf.Session所连接的目标服务器</td><br></tr><br><tr><br>  <td>tf.train.Server.server_def</td><br>  <td align="left">返回该服务的tf.train.ServerDef</td><br></tr><br><tr><br>  <td><strong>tf.train.Server.start()</strong></td><br>  <td align="left">开启服务</td><br></tr><br><tr><br>  <td>tf.train.Server.join()</td><br>  <td align="left">阻塞直到服务已经关闭</td><br></tr><br></tbody></table><br><br><br><table><br><thead><br><tr><br>  <th>#</th><br>  <th align="left"></th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.train.Supervisor</td><br>  <td align="left">一个训练辅助器，用于checkpoints模型以及计算的summaries。该监视器只是一个小的外壳(wrapper),用于Coordinator, a Saver, 和a SessionManager周围</td><br></tr><br><tr><br>  <td><strong>tf.train.Supervisor.<strong>init</strong>(graph=None, ready_op=0, is_chief=True, init_op=0, init_feed_dict=None, local_init_op=0, logdir=None, <br>summary_op=0, saver=0, global_step=0, <br>save_summaries_secs=120, save_model_secs=600, <br>recovery_wait_secs=30, stop_grace_secs=120,<br> checkpoint_basename=’model.ckpt’, session_manager=None, summary_writer=0, init_fn=None)</strong></td><br>  <td align="left">创建一个监视器Supervisor</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.managed_session(master=”, config=None, start_standard_services=True, close_summary_writer=True)</td><br>  <td align="left">返回一个管路session的上下文管理器</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.prepare_or_wait_for_session(master=”, config=None, wait_for_checkpoint=False, max_wait_secs=7200, start_standard_services=True)</td><br>  <td align="left">确保model已经准备好</td><br></tr><br><tr><br>  <td><strong>tf.train.Supervisor.start_standard_services(sess)</strong></td><br>  <td align="left">为sess启动一个标准的服务</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.start_queue_runners(sess, queue_runners=None)</td><br>  <td align="left">为QueueRunners启动一个线程，queue_runners为一个QueueRunners列表</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.summary_computed(sess, summary, global_step=None)</td><br>  <td align="left">指示计算的summary</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.stop(threads=None, close_summary_writer=True)</td><br>  <td align="left">停止服务以及协调器(coordinator),并没有关闭session</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.request_stop(ex=None)</td><br>  <td align="left">参考Coordinator.request_stop()</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.should_stop()</td><br>  <td align="left">参考Coordinator.should_stop()</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.stop_on_exception()</td><br>  <td align="left">参考 Coordinator.stop_on_exception()</td><br></tr><br><tr><br>  <td>tf.train.Supervisor.Loop(timer_interval_secs, target, args=None, kwargs=None)</td><br>  <td align="left">开启一个循环器线程用于调用一个函数<br>每经过timer_interval_secs秒执行，target(args, <em>*kwargs)</em></td><br></tr><br><tr><br>  <td>tf.train.Supervisor.coord</td><br>  <td align="left">返回监督器(Supervisor)使用的协调器(Coordinator )</td><br></tr><br></tbody></table><br><br><br><table><br><thead><br><tr><br>  <th>#</th><br>  <th align="left"></th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.train.SessionManager</td><br>  <td align="left">训练的辅助器，用于从checkpoint恢复数据以及创建一个session</td><br></tr><br><tr><br>  <td>tf.train.SessionManager.<strong>init</strong>(local_init_op=None, ready_op=None, graph=None, recovery_wait_secs=30)</td><br>  <td align="left">创建一个SessionManager</td><br></tr><br><tr><br>  <td>tf.train.SessionManager.prepare_session(master, init_op=None, saver=None, checkpoint_dir=None, wait_for_checkpoint=False, max_wait_secs=7200, config=None, init_feed_dict=None, init_fn=None)</td><br>  <td align="left">创建一个session，并确保model可以被使用</td><br></tr><br><tr><br>  <td>tf.train.SessionManager.recover_session(master, saver=None, checkpoint_dir=None, wait_for_checkpoint=False, max_wait_secs=7200, config=None)</td><br>  <td align="left">创建一个session，如果可以的话，使用恢复方法创建</td><br></tr><br><tr><br>  <td>tf.train.SessionManager.wait_for_session(master, config=None, max_wait_secs=inf)</td><br>  <td align="left">创建一个session，并等待model准备完成</td><br></tr><br></tbody></table><br><br><br><table><br><thead><br><tr><br>  <th>#</th><br>  <th align="left"></th><br></tr><br></thead><br><tbody><tr><br>  <td><strong>class tf.train.ClusterSpec</strong></td><br>  <td align="left">将一个集群表示为一系列“tasks”，并整合至“jobs”中</td><br></tr><br><tr><br>  <td>tf.train.ClusterSpec.as_cluster_def()</td><br>  <td align="left">返回该cluster中一个tf.train.ClusterDef协议的buffer</td><br></tr><br><tr><br>  <td>tf.train.ClusterSpec.as_dict()</td><br>  <td align="left">返回一个字典，由job名称对应于网络地址</td><br></tr><br><tr><br>  <td>tf.train.ClusterSpec.job_tasks(job_name)</td><br>  <td align="left">返回一个给定的job对应的task列表</td><br></tr><br><tr><br>  <td>tf.train.ClusterSpec.jobs</td><br>  <td align="left">返回该cluster的job名称列表</td><br></tr><br><tr><br>  <td><strong>tf.train.replica_device_setter(ps_tasks=0, ps_device=’/job:ps’, worker_device=’/job:worker’, merge_devices=True, cluster=None, ps_ops=None)</strong></td><br>  <td align="left">返回一个设备函数(device function)，以在建立一个副本graph的时候使用，设备函数(device function)用在with tf.device(device_function)中</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>tf.train.Server</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">server = tf.train.Server(…)<br><span class="hljs-keyword">with</span> tf.Session(server.target):<br>  <span class="hljs-comment"># …</span><br></code></pre><br><br><p>▷ <em>tf.train.Supervisor</em> <br><br>相关参数： <br><br>ready_op : 一维 字符串 tensor。该tensor是用过监视器在prepare_or_wait_for_session()计算，检查model是否准备好可以使用。如果准备好，将返回一个空阵列，如果为None，该model没有被检查。 <br><br>is_chief : 如果为True，创建一个主监视器用于负责初始化与模型的恢复，若为False，则依赖主监视器。 <br><br>init_op : 一个操作，用于模型不能恢复时的初始化操作。默认初始化所有操作 <br><br>local_init_op : 可被所有监视器运行的初始化操作。 <br><br>logdir : 设置log目录 <br><br>summary_op : 一个操作(Operation )，返回Summary 和事件logs，需要设置 logdir <br><br>saver : 一个Saver对象 <br><br>save_summaries_secs : 保存summaries的间隔秒数 <br><br>save_model_secs : 保存model的间隔秒数 <br><br>checkpoint_basename :  checkpoint保存的基本名称</p><br><br><ul><br><li>使用在单进程中</li><br></ul><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">with</span> tf.Graph().as_default():<br>  …add operations to the graph…<br>  <span class="hljs-comment"># Create a Supervisor that will checkpoint the model in ‘/tmp/mydir’.</span><br>  sv = Supervisor(logdir=<span class="hljs-string">‘/tmp/mydir’</span>)<br>  <span class="hljs-comment"># Get a TensorFlow session managed by the supervisor.</span><br>  <span class="hljs-keyword">with</span> sv.managed_session(FLAGS.master) <span class="hljs-keyword">as</span> sess:<br>    <span class="hljs-comment"># Use the session to train the graph.</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> sv.should_stop():<br>      sess.run(&lt;my_train_op&gt;)<br><span class="hljs-comment"># 在上下文管理器with sv.managed_session()内，所有在graph的变量都被初始化。</span><br><span class="hljs-comment"># 或者说，一些服务器checkpoint相应模型并增加summaries至事件log中。</span><br><span class="hljs-comment"># 如果有例外发生，should_stop()将返回True</span></code></pre><br><br><ul><br><li>使用在多副本运行情况中 <br><br>要使用副本训练已经部署在集群上的相同程序，必须指定其中一个task为主要，该task处理 initialization, checkpoints, summaries, 和recovery相关事物。其他task依赖该task。</li><br></ul><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># Choose a task as the chief. This could be based on server_def.task_index,</span><br><span class="hljs-comment"># or job_def.name, or job_def.tasks. It’s entirely up to the end user.</span><br><span class="hljs-comment"># But there can be only one chief*.</span><br>is_chief = (server_def.task_index == <span class="hljs-number">0</span>)<br>server = tf.train.Server(server_def)<br><br><span class="hljs-keyword">with</span> tf.Graph().as_default():<br>  …add operations to the graph…<br>  <span class="hljs-comment"># Create a Supervisor that uses log directory on a shared file system.</span><br>  <span class="hljs-comment"># Indicate if you are the ‘chief’</span><br>  sv = Supervisor(logdir=<span class="hljs-string">‘/shared_directory/…’</span>, is_chief=is_chief)<br>  <span class="hljs-comment"># Get a Session in a TensorFlow server on the cluster.</span><br>  <span class="hljs-keyword">with</span> sv.managed_session(server.target) <span class="hljs-keyword">as</span> sess:<br>    <span class="hljs-comment"># Use the session to train the graph.</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> sv.should_stop():<br>      sess.run(&lt;my_train_op&gt;)<br></code></pre><br><br><p>如果有task崩溃或重启，managed_session() 将检查是否Model被初始化。如果已经初始化，它只需要创建一个session并将其返回至正在训练的正常代码中。如果model需要被初始化，主task将对它进行重新初始化，而其他task将等待模型初始化完成。 <br><br>注意：该程序方法一样适用于单进程的work，该单进程标注自己为主要的便行</p><br><br><p>▷ <em>supervisor中master的字符串形式</em> <br><br>无论运行在本机或者集群上，都可以使用以下值设定master flag：</p><br><br><ul><br><li>定义为 ” ，要求一个进程内且没有使用RPC的session</li><br><li>定义为 ‘local’，要求一个使用基于RPC的主服务接口(“Master interface” )的session来运行tensorflow程序。更多细节可以查看 tf.train.Server.create_local_server()相关内容。</li><br><li>定义为 ‘grpc://hostname:port’，要求一个指定的RPC接口的session，同时运行内部进程的master接入远程的tensorflow workers。可用server.target返回该形式</li><br></ul><br><br><p>▷ <em>supervisor高级用法</em></p><br><br><ul><br><li>启动额外的服务 <br><br>managed_session()启动了 Checkpoint 和Summary服务。如果需要运行更多的服务，可以在managed_session()控制的模块中启动他们。</li><br></ul><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#例如： 开启一个线程用于打印loss. 设置每60秒该线程运行一次，我们使用sv.loop()</span><br> …<br>  sv = Supervisor(logdir=<span class="hljs-string">‘/tmp/mydir’</span>)<br>  <span class="hljs-keyword">with</span> sv.managed_session(FLAGS.master) <span class="hljs-keyword">as</span> sess:<br>    sv.loop(<span class="hljs-number">60</span>, print_loss, (sess))<br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> sv.should_stop():<br>      sess.run(my_train_op)<br></code></pre><br><br><ul><br><li>启动更少的的服务 <br><br>managed_session() 启动了 “summary” 和 “checkpoint” 线程，这些线程通过构建器或者监督器默认自动创建了summary_op 和saver操作。如果想运行自己的 summary 和checkpointing方法，关闭这些服务，通过传递None值给summary_op 和saver参数。</li><br></ul><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">在chief中每<span class="hljs-number">100</span>个step，创建summaries<br>  <span class="hljs-comment"># Create a Supervisor with no automatic summaries.</span><br>  sv = Supervisor(logdir=<span class="hljs-string">‘/tmp/mydir’</span>, is_chief=is_chief, summary_op=<span class="hljs-keyword">None</span>)<br>  <span class="hljs-comment"># As summary_op was None, managed_session() does not start the</span><br>  <span class="hljs-comment"># summary thread.</span><br>  <span class="hljs-keyword">with</span> sv.managed_session(FLAGS.master) <span class="hljs-keyword">as</span> sess:<br>    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> xrange(<span class="hljs-number">1000000</span>):<br>      <span class="hljs-keyword">if</span> sv.should_stop():<br>        <span class="hljs-keyword">break</span><br>      <span class="hljs-keyword">if</span> is_chief <span class="hljs-keyword">and</span> step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-comment"># Create the summary every 100 chief steps.</span><br>        sv.summary_computed(sess, sess.run(my_summary_op))<br>      <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># Train normally</span><br>        sess.run(my_train_op)<br><br></code></pre><br><br><p>▷ <em>tf.train.Supervisor.managed_session</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">()</span>:</span><br>  sv = tf.train.Supervisor(…)<br>  <span class="hljs-keyword">with</span> sv.managed_session(&lt;master&gt;) <span class="hljs-keyword">as</span> sess:<br>    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> xrange(..):<br>      <span class="hljs-keyword">if</span> sv.should_stop():<br>        <span class="hljs-keyword">break</span><br>      sess.run(&lt;my training op&gt;)<br>      …do other things needed at each training step…</code></pre><br><br><p>▷ <em>tf.train.SessionManager</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">with</span> tf.Graph().as_default():<br>   …add operations to the graph…<br>  <span class="hljs-comment"># Create a SessionManager that will checkpoint the model in ‘/tmp/mydir’.</span><br>  sm = SessionManager()<br>  sess = sm.prepare_session(master, init_op, saver, checkpoint_dir)<br>  <span class="hljs-comment"># Use the session to train the graph.</span><br>  <span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:<br>    sess.run(&lt;my_train_op&gt;)<br><span class="hljs-comment">#其中prepare_session()初始化和恢复一个模型参数。 </span><br><br><span class="hljs-comment">#另一个进程将等待model准备完成，代码如下</span><br><span class="hljs-keyword">with</span> tf.Graph().as_default():<br>  …add operations to the graph…<br>  <span class="hljs-comment"># Create a SessionManager that will wait for the model to become ready.</span><br>  sm = SessionManager()<br>  sess = sm.wait_for_session(master)<br>  <span class="hljs-comment"># Use the session to train the graph.</span><br>  <span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:<br>    sess.run(&lt;my_train_op&gt;)<br><span class="hljs-comment">#wait_for_session()等待一个model被其他进程初始化</span><br></code></pre><br><br><p>▷ <em>tf.train.ClusterSpec</em> <br><br>一个tf.train.ClusterSpec表示一系列的进程，这些进程都参与分布式tensorflow的计算。每一个 tf.train.Server都在一个独有的集群中构建。 <br><br>创建一个具有两个jobs及其5个tasks的集群们需要定义从job名称列表到网络地址列表之间的映射。</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">cluster = tf.train.ClusterSpec({<span class="hljs-string">“worker”</span>: [<span class="hljs-string">“worker0.example.com:2222”</span>,<br>                                           <span class="hljs-string">“worker1.example.com:2222”</span>,<br>                                           <span class="hljs-string">“worker2.example.com:2222”</span>],<br>                                <span class="hljs-string">“ps”</span>: [<span class="hljs-string">“ps0.example.com:2222”</span>,<br>                                       <span class="hljs-string">“ps1.example.com:2222”</span>]})</code></pre><br><br><p>▷ <em>tf.train.replica_device_setter</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># To build a cluster with two ps jobs on hosts ps0 and ps1, and 3 worker</span><br><span class="hljs-comment"># jobs on hosts worker0, worker1 and worker2.</span><br>cluster_spec = {<br>    <span class="hljs-string">“ps”</span>: [<span class="hljs-string">“ps0:2222”</span>, <span class="hljs-string">“ps1:2222”</span>],<br>    <span class="hljs-string">“worker”</span>: [<span class="hljs-string">“worker0:2222”</span>, <span class="hljs-string">“worker1:2222”</span>, <span class="hljs-string">“worker2:2222”</span>]}<br><span class="hljs-keyword">with</span> tf.device(tf.replica_device_setter(cluster=cluster_spec)):<br>  <span class="hljs-comment"># Build your graph</span><br>  v1 = tf.Variable(…)  <span class="hljs-comment"># assigned to /job:ps/task:0</span><br>  v2 = tf.Variable(…)  <span class="hljs-comment"># assigned to /job:ps/task:1</span><br>  v3 = tf.Variable(…)  <span class="hljs-comment"># assigned to /job:ps/task:0</span><br><span class="hljs-comment"># Run compute</span><br></code></pre><br><br><p><br></p><br><br><br><br><h4 id="汇总操作summary-operations">█ <strong>汇总操作(Summary Operations)</strong></h4><br><br><p>我们可以在一个session中获取summary操作的输出，并将其传输到SummaryWriter以添加至一个事件记录文件中。</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.scalar_summary(tags, values, collections=None, name=None)</td><br>  <td align="left">输出一个标量值的summary协议buffer<br>tag的shape需要与values的相同，用来做summaries的tags，为字符串</td><br></tr><br><tr><br>  <td>tf.image_summary(tag, tensor, max_images=3, collections=None, name=None)</td><br>  <td align="left">输出一个图像tensor的summary协议buffer</td><br></tr><br><tr><br>  <td>tf.audio_summary(tag, tensor, sample_rate, max_outputs=3, collections=None, name=None)</td><br>  <td align="left">输出一个音频tensor的summary协议buffer</td><br></tr><br><tr><br>  <td>tf.histogram_summary(tag, values, collections=None, name=None)</td><br>  <td align="left">输出一个直方图的summary协议buffer</td><br></tr><br><tr><br>  <td>tf.nn.zero_fraction(value, name=None)</td><br>  <td align="left">返回0在value中的小数比例</td><br></tr><br><tr><br>  <td>tf.merge_summary(inputs, collections=None, name=None)</td><br>  <td align="left">合并summary</td><br></tr><br><tr><br>  <td>tf.merge_all_summaries(key=’summaries’)</td><br>  <td align="left">合并在默认graph中手机的summaries</td><br></tr><br></tbody></table><br><br><br><p>▶▶<strong><em>将记录汇总写入文件中(Adding Summaries to Event Files)</em></strong></p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>class tf.train.SummaryWriter</td><br>  <td align="left">将summary协议buffer写入事件文件中</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.<strong>init</strong>(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None)</td><br>  <td align="left">创建一个SummaryWriter实例以及新建一个事件文件</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.add_summary(summary, global_step=None)</td><br>  <td align="left">将一个summary添加到事件文件中</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.add_session_log(session_log, global_step=None)</td><br>  <td align="left">添加SessionLog到一个事件文件中</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.add_event(event)</td><br>  <td align="left">添加一个事件到事件文件中</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.add_graph(graph, global_step=None, graph_def=None)</td><br>  <td align="left">添加一个Graph到时间文件中</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.add_run_metadata(run_metadata, tag, global_step=None)</td><br>  <td align="left">为一个单一的session.run()调用添加一个元数据信息</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.flush()</td><br>  <td align="left">刷新时间文件到硬盘中</td><br></tr><br><tr><br>  <td>tf.train.SummaryWriter.close()</td><br>  <td align="left">将事件问价写入硬盘中并关闭该文件</td><br></tr><br><tr><br>  <td>tf.train.summary_iterator(path)</td><br>  <td align="left">一个用于从时间文件中读取时间协议buffer的迭代器</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>tf.train.SummaryWriter</em> <br><br>创建一个SummaryWriter 和事件文件。如果我们传递一个Graph进入该构建器中，它将被添加到事件文件当中，这一点与使用add_graph()具有相同功能。 <br><br>TensorBoard 将从事件文件中提取该graph，并将其显示。所以我们能直观地看到我们建立的graph。我们通常从我们启动的session中传递graph：</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><br>…create a graph…<br><span class="hljs-comment"># Launch the graph in a session.</span><br>sess = tf.Session()<br><span class="hljs-comment"># Create a summary writer, add the ‘graph’ to the event file.</span><br>writer = tf.train.SummaryWriter(&lt;some-directory&gt;, sess.graph)<br></code></pre><br><br><p>▷ <em>tf.train.summary_iterator</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#打印时间文件中的内容</span><br><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> tf.train.summary_iterator(path to events file):<br>    print(e)<br><br><span class="hljs-comment">#打印指定的summary值</span><br><span class="hljs-comment"># This example supposes that the events file contains summaries with a</span><br><span class="hljs-comment"># summary value tag ‘loss’.  These could have been added by calling</span><br><span class="hljs-comment"># <code>add_summary()</code>, passing the output of a scalar summary op created with</span><br><span class="hljs-comment"># with: <code>tf.scalar_summary([&#39;loss&#39;], loss_tensor)</code>.</span><br><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> tf.train.summary_iterator(path to events file):<br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> e.summary.value:<br>        <span class="hljs-keyword">if</span> v.tag == <span class="hljs-string">‘loss’</span>:<br>            print(v.simple_value)</code></pre><br><br><p><br></p><br><br><br><br><h4 id="训练的通用函数及其他training-utilities">█ <strong>训练的通用函数及其他(Training utilities)</strong></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.train.global_step(sess, global_step_tensor)</td><br>  <td align="left">一个用于获取全局step的小辅助器</td><br></tr><br><tr><br>  <td>tf.train.write_graph(graph_def, logdir, name, as_text=True)</td><br>  <td align="left">将一个graph proto写入一个文件中</td><br></tr><br><tr><br>  <td>#</td><br>  <td align="left"></td><br></tr><br><tr><br>  <td></td><br>  <td align="left">:—</td><br></tr><br><tr><br>  <td>class tf.train.LooperThread</td><br>  <td align="left">可重复地执行代码的线程</td><br></tr><br><tr><br>  <td>tf.train.LooperThread.<strong>init</strong>(coord, timer_interval_secs, target=None, args=None, kwargs=None)</td><br>  <td align="left">创建一个LooperThread</td><br></tr><br><tr><br>  <td>tf.train.LooperThread.is_alive()</td><br>  <td align="left">返回是否该线程是活跃的</td><br></tr><br><tr><br>  <td>tf.train.LooperThread.join(timeout=None)</td><br>  <td align="left">等待线程结束</td><br></tr><br><tr><br>  <td>tf.train.LooperThread.loop(coord, timer_interval_secs, target, args=None, kwargs=None)</td><br>  <td align="left">启动一个LooperThread，用于周期地调用某个函数<br>调用函数target(args)</td><br></tr><br><tr><br>  <td>tf.py_func(func, inp, Tout, stateful=True, name=None)</td><br>  <td align="left">将python函数包装成tf中操作节点</td><br></tr><br></tbody></table><br><br><br><p>▷ <em>tf.train.global_step</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># Creates a variable to hold the global_step.</span><br>global_step_tensor = tf.Variable(<span class="hljs-number">10</span>, trainable=<span class="hljs-keyword">False</span>, name=<span class="hljs-string">‘global_step’</span>)<br><span class="hljs-comment"># Creates a session.</span><br>sess = tf.Session()<br><span class="hljs-comment"># Initializes the variable.</span><br>sess.run(global_step_tensor.initializer)<br>print(<span class="hljs-string">‘global_step: %s’</span> % tf.train.global_step(sess, global_step_tensor))<br><br>global_step: <span class="hljs-number">10</span><br></code></pre><br><br><p>▷ <em>tf.train.write_graph</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs ">v = tf.Variable(<span class="hljs-number">0</span>, name=<span class="hljs-string">‘my_variable’</span>)<br>sess = tf.Session()<br>tf.train.write_graph(sess.graph_def, <span class="hljs-string">‘/tmp/my-model’</span>, <span class="hljs-string">‘train.pbtxt’</span>)</code></pre><br><br><p>▷ <em>tf.py_func</em></p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#tf.py_func(func, inp, Tout, stateful=True, name=None)</span><br><span class="hljs-comment">#func：为一个python函数</span><br><span class="hljs-comment">#inp：为输入函数的参数，Tensor列表</span><br><span class="hljs-comment">#Tout： 指定func返回的输出的数据类型，是一个列表</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_func</span><span class="hljs-params">(x)</span>:</span><br>  <span class="hljs-comment"># x will be a numpy array with the contents of the placeholder below</span><br>  <span class="hljs-keyword">return</span> np.sinh(x)<br>inp = tf.placeholder(tf.float32, […])<br>y = py_func(my_func, [inp], [tf.float32])<br></code></pre><br><br><br><br><h3 id="22-测试-testing">2.2 测试 (Testing)</h3><br><br><p>TensorFlow 提供了一个方便的继承unittest.TestCase类的方法，该类增加有关TensorFlow 测试的方法。如下例子：</p><br><br><br><br><pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SquareTest</span><span class="hljs-params">(tf.test.TestCase)</span>:</span><br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">testSquare</span><span class="hljs-params">(self)</span>:</span><br>    <span class="hljs-keyword">with</span> self.test_session():<br>      x = tf.square([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>      self.assertAllEqual(x.eval(), [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>])<br><br><br><span class="hljs-keyword">if</span> <strong>name</strong> == <span class="hljs-string">‘<strong>main</strong>‘</span>:<br>  tf.test.main()</code></pre><br><br><p><br></p><br><br><br><br><h4 id="共用utilities">█ <strong>共用(Utilities)</strong></h4><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.test.main()</td><br>  <td align="left">运行所有的单元测试</td><br></tr><br><tr><br>  <td>tf.test.assert_equal_graph_def(actual, expected)</td><br>  <td align="left">断言 两个GraphDefs 是否几乎一样</td><br></tr><br><tr><br>  <td>tf.test.get_temp_dir()</td><br>  <td align="left">返回测试期间使用的临时目录</td><br></tr><br><tr><br>  <td>tf.test.is_built_with_cuda()</td><br>  <td align="left">返回是否Tensorflow支持CUDA(GPU)的build</td><br></tr><br></tbody></table><br><br><br><p><br></p><br><br><h4 id="梯度检查gradient-checking">█ <strong>梯度检查(Gradient checking)</strong></h4><br><br><p>可对比compute_gradient 和compute_gradient_error函数的用法</p><br><br><table><br><thead><br><tr><br>  <th>操作</th><br>  <th align="left">描述</th><br></tr><br></thead><br><tbody><tr><br>  <td>tf.test.compute_gradient(x, x_shape, y, y_shape, x_init_value=None, delta=0.001, init_targets=None)</td><br>  <td align="left">计算并返回理论的和数值的Jacobian矩阵</td><br></tr><br><tr><br>  <td>tf.test.compute_gradient_error(x, x_shape, y, y_shape, x_init_value=None, delta=0.001, init_targets=None)</td><br>  <td align="left">计算梯度的error。在计算所得的与数值估计的Jacobian中 为dy/dx计算最大的error</td><br></tr><br></tbody></table><br><br><br><hr><br><br><hr><br><br><p><strong>相关链接：</strong></p><br><br><p>[1] 安装Tensorflow（Linux ubuntu） <a href="http://blog.csdn.net/lenbow/article/details/51203526" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51203526</a> <br><br>[2] ubuntu下CUDA编译的GCC降级安装 <a href="http://blog.csdn.net/lenbow/article/details/51596706" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51596706</a> <br><br>[3] ubuntu手动安装最新Nvidia显卡驱动 <a href="http://blog.csdn.net/lenbow/article/details/51683783" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/51683783</a> <br><br>[4] Tensorflow的CUDA升级，以及相关配置 <a href="http://blog.csdn.net/lenbow/article/details/52118116" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52118116</a> <br><br>[5] 基于gensim的Doc2Vec简析 <a href="http://blog.csdn.net/lenbow/article/details/52120230" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52120230</a> <br><br>[6] TensorFlow的分布式学习框架简介 <a href="http://blog.csdn.net/lenbow/article/details/52130565" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52130565</a> <br><br>[7] Tensorflow一些常用基本概念与函数（1） <a href="http://blog.csdn.net/lenbow/article/details/52152766" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52152766</a> <br><br>[8] Tensorflow一些常用基本概念与函数（2） <a href="http://blog.csdn.net/lenbow/article/details/52181159" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52181159</a> <br><br>[9] Tensorflow一些常用基本概念与函数（3） <a href="http://blog.csdn.net/lenbow/article/details/52213105" target="_blank" rel="external">http://blog.csdn.net/lenbow/article/details/52213105</a></p></div>
</div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/lenbow/article/details/52152766&quot;&gt;作者：林海山波&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://avatar.csdn.net/D/1/1/1_lenbow.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt; 本文主要对tf的一些常用概念与方法进行描述。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>这一年来，数据科学家都用了哪些算法玩转人工智能？</title>
    <link href="http://ipcreator.me/2017/02/13/Program/Resources/benchmark-of-machine-learning/"/>
    <id>http://ipcreator.me/2017/02/13/Program/Resources/benchmark-of-machine-learning/</id>
    <published>2017-02-13T00:40:06.000Z</published>
    <updated>2017-02-27T03:51:39.021Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://it.sohu.com/20170128/n479665884.shtml" target="_blank" rel="external">新智元mp</a><br>论文作者：Shaohuai Shi, Qiang Wang, Pengfei Xu, Xiaowen Chu<br>译者：吴博, Elaine, Melody</p>
<p>【新智元导读】新年伊始，新智元向你推荐香港浸会大学计算机学院褚晓文团队最新论文《基准评测当前最先进的深度学习软件工具》，评测了 Caffe、CNTK、MXNet、TensorFlow、Torch 这五个最受欢迎的DL框架在 FCN、CNN、RNN 上的表现。这是伯克利RISE实验室大牛、RISC之父 David Patterson 也在关注的深度学习库评测。论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。【进入新智元公众号，在对话框输入“0128”下载论文】</p>
  <a id="more"></a>
<p>  在2016年推出深度学习工具评测的褚晓文团队，赶在猴年最后一天，在arXiv.org上发布了最新的评测版本。这份评测的初版，通过国内AI自媒体的传播，在国内业界影响很大。在学术界，其反响更是非同一般。褚晓文教授在1月5日的朋友圈说David Patterson发邮件咨询他文章细节，感慨老人家论文看得仔细。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/acbd53fe265b45538bce0dfbfe48d16b.jpeg" alt=""></p>
<p>  　　David Patterson在体系结构领域的名声如雷贯耳，RISC之父。不熟悉的吃瓜群众可能留意到1月25日蚂蚁金服宣布跟伯克利大学前身为AmpLab，更名为RISE实验室合作的新闻。David Patterson就是RISE实验室的顶梁大佬之一。</p>
<p>  　　褚晓文教授最新版本的论文对Caffe、CNTK、MXNet、TensorFlow、Torch进行比较评测。在两个CPU平台、三个GPU平台下，比较这五个深度学习库在三类流行深度神经网络(FCN、CNN、RNN)上的性能表现。并对它们在单机多GPU卡环境下分布式版本进行了比较。相比以前的评测，最新的评测添加了对多GPU卡的测试，把MXNet纳入评比范围，还测试了MNIST和Cifar10这两个真实数据集。</p>
<p>  《基准评测当前最先进的深度学习软件工具》<br>  <img src="http://img.mp.itc.cn/upload/20170128/7b6dcf7d1873495981b335fdf2369fef.jpeg" alt="">
  　　</p>
<p>  ##　　1. 简介</p>
<p>  　　在过去十年中，深度学习已成功应用到不同领域，包括计算机视觉、语音识别和自然语言处理等。深度学习的成功，归因于许多层人工神经元对输入数据的高表征能力。而GPU通过显著缩短训练时间，在深度学习的成功中扮演着重要的角色。为了提高开发深度学习方法的效率，有很多开源的深度学习工具包，包括伯克利大学的Caffe，微软的CNTK，谷歌的TensorFlow，还有Torch，MXNet，Theano，百度的 PaddlePaddle等。这些工具都支持多核CPU和超多核GPU。</p>
<p>  　　深度学习的主要任务之一，是学习网络的每一层的权重，这可以通过向量或矩阵运算来实现。TensorFlow使用 Eigen作为矩阵加速库，而 Caffe、CNTK、MXNet和Torch采用OpenBLAS、Intel MKL 或 cuBLAS 来加快相关矩阵运算。所有这些工具包都引入了cuDNN，这是一个为神经网络计算进行GPU加速的深度学习库。但是，由于优化方法的差异，加上不同类型的网络或使用不同类型的硬件，上述工具包的性能差异很大。</p>
<p>  　　鉴于深度学习软件工具及其底层硬件平台的多样化，终端用户难以选择合适的平台来执行深度学习任务。在此论文中，作者用三种最主要的深度神经网络（全连接神经网络FCN，卷积神经网络CNN，以及循环神经网络RNN）来基准评测当下最先进的基于GPU加速的深度学习工具（包括Caffe，CNTK， MXNet， TensorFlow 和Torch），比较它们在CPU和GPU上的运行时间性能。</p>
<p>  　　几个工具的性能评估既针对合成数据，也针对真实数据。评测的硬件平台包括两种CPU（台式机级别的英特尔i7-3820 CPU，服务器级别的英特尔Xeon E5-2630 CPU）和三种Nvidia GPU (GTX 980、GTX 1080、Telsa K80，分别是Maxwell、Pascal和Kepler 架构)。作者也用两个Telsa K80卡（总共4个GK210 GPU）来评估多GPU卡并行的性能。每种神经网络类型均选择了一个小型网络和大型网络。</p>
<p>  　　该评测的主要发现可概括如下：</p>
<p>  总体上，多核CPU的性能并无很好的可扩展性。在很多实验结果中，使用16核CPU的性能仅比使用4核或8核稍好。TensorFlow在CPU环境有相对较好的可扩展性。</p>
<p>  仅用一块GPU卡的话，FCN上Caffe、CNTK和Torch比MXNet和TensorFlow表现更好；CNN上MXNet表现出色，尤其是在大型网络时；而Caffe和CNTK在小型CNN上同样表现不俗；对于带LSTM的RNN，CNTK速度最快，比其他工具好上5到10倍。</p>
<p>  通过将训练数据并行化，这些支持多GPU卡的深度学习工具，都有可观的吞吐量提升，同时收敛速度也提高了。多GPU卡环境下，CNTK平台在FCN和AlexNet上的可扩展性更好，而MXNet和Torch在CNN上相当出色。</p>
<p>  比起多核CPU，GPU平台效率更高。所有的工具都能通过使用GPU达到显著的加速。</p>
<p>  在三个GPU平台中，GTX1080由于其计算能力最高，在大多数实验结果中性能最出色。</p>
<p>  某种程度上而言，性能也受配置文件的影响。例如，CNTK允许用户调整系统配置文件，在运算效率和GPU内存间取舍，而MXNet则能让用户对cuDNN库的自动设置进行调整。</p>
<p>  ##　　2. 背景及相关知识</p>
<p>  随着深度学习技术的快速发展，人们针对不同的应用场合开发出各类深度神经网络，包括全连接神经网络(FCN)、卷积神经网络(CNN)、循环神经网络(RNN)、局限型波兹曼机(RBM)。此论文着重分析三种神经网络（FCN、CNN和RNN）的运行性能（或时间速度）及收敛速度。</p>
<p>  　　FCN的历史可追溯到上世纪80年代，反向传播算法（backpropagation）发明之时。而CNN和RNN，一直以来分别在图像识别和自然语言处理应用上展现出优异的效果。</p>
<p>  　　FCN是一个前向神经网络，由Yann LeCun等人在1989年成功应用于邮编识别。为了减少每一层的参数数量，CNN通过使用一组核(kernel)，建立了一个卷积层，每个核的参数在整个域（例如：一个彩色图像的通道）共享。CNN能减轻全连接层容易导致需要学习大量参数的问题。从LeNet架构开始，CNN已经实现很多成果，包括ImageNet分类、人脸识别和目标检测。</p>
<p>  　　RNN允许网络单元的循环连接。RNN可以将整个历史输入序列跟每个输出相连，找到输入的上下文特性和输出之间的关系。有了这个特性，RNN可以保留之前输入的信息，类似于样本训练时的记忆功能。此外，长短时记忆（LSTM）通过适当地记录和丢弃信息，能解决RNN训练时梯度消失和爆炸的难题。含LSTM单元的RNN被证实是处理语音辨识和自然语言处理任务最有效的方法之一。</p>
<p>  　　随着深度学习日益成功，诞生了许多受欢迎的开源GPU加速工具包。其中，Caffe、CNTK、MXNet、TensorFlow和Torch是最活跃、最受欢迎的例子。</p>
<p>  　　Caffe由伯克利视觉和学习中心（BVLC）开发，自2014成为开源项目。作者声称Caffe可以借助NVIDIA K40或Titan GP卡，每天用GPU加速版本处理4000万图像。结合cuDNN之后，还可以加速约1.3倍。</p>
<p>  　　CNTK是一个由微软研究院开发的工具包，支持大部分流行的神经网络。在2015年2月，官方报道了一个基准性能测试结果，针对一个4层全连接神经网络，CNTK与Caffe、TensorFlow、Theano和Torch对比，速度要快上1.5倍。</p>
<p>  　　MXNet是一个支持多种语言的深度学习框架，旨在提供更灵活有效的编程接口，以提升生产效率。</p>
<p>  　　TensorFlow由谷歌开发，它使用数据流图集成了深度学习框架中最常见的单元。它支持许多最新的网络如CNN，以及带不同设置的RNN。<strong>TensorFlow是为超凡的灵活性、轻便性和高效率而设计的。</strong></p>
<p>  　　Torch是一个科学计算框架，它为机器学习里最为有用的元件——如多维张量——提供数据结构。<br>  　　<img src="http://img.mp.itc.cn/upload/20170128/bf5f53c5db5447f596e12bb97fb9d3ba.jpeg" alt=""><br>  　　(a) 全连接神经网络 (b) 卷积神经网络(AlexNet) (c) 循环神经网络<br>  　　图1：深度学习模型的例子</p>
<p>  　　为了加快深度神经网络的训练速度，有的使用CPU SSE技术和浮点SIMD模型来实现深度学习算法，相比浮点优化的版本能实现3倍加速。Andre Viebke等人利用多线程及SIMD并行化在英特尔Xeon Phi处理器上加速CNN。针对多GPU卡的并行化，Jeffrey Dean等人提出了一种大规模分布式深度网络，开发了两种算法（Downpour SGD和Sandblaster L-BFGS），可以在混有GPU机器的集群上运行。</p>
<p>  　　加快训练方法的另一种方式是减少要学习的参数数量，Song Han等人使用修剪冗余连接的方法，在不失去网络表征能力下减少参数，这可以减少670万到6100万的AlexNet参数。Bahrampour等人也做了类似的性能评测工作，但他们仅用了一个GPU架构（NVIDIA Maxwell Titan X）和旧版的软件（cuDNN v2, v3）。</p>
<p>  　　本文作者早前工作也探讨了单个GPU上跑旧版软件的基准测试结果。此文针对三版主要的GPU架构和一些最新的网络（如：ResNet-50）和软件（如：cuDNN v5）进行基准评测，并深入到工具包代码分析性能。此外，本文也比较了单台机器里多个GPU卡的性能。</p>
<p>  　　因为单个GPU卡内存相对较少，限制了神经网络规模，训练的可伸缩性对于深度学习框架至关重要。在如今的深度学习工具中，支持多GPU卡成为了一个标准功能。为了利用多个GPU卡，分布式同步随机梯度下降法（SDG）使用很广泛，实现了很好的扩展性能。</p>
<p>  　　在可扩展性方面，本文作者着重评估处理时间，以及数据同步方法的收敛速度。在数据并行模型里，针对N个worker，把有M个样本的一个mini-batch分成N份，每份M/N个样本，每个worker用相同的模型独立向前向后处理所分配的样本。当所有worker完成后，把梯度聚合，更新模型。</p>
<p>  　　实际上，不同工具实现同步SGD算法的方式各有不同。</p>
<p>  Caffe：采用删减树策略减少GPU间的数据通信。例如，假设有4个标记为0,1,2,3的GPU。首先，GPU 0和GPU 1交换梯度，GPU 2和GPU 3交换梯度，然后GPU 0和GPU 2交换梯度。之后，GPU 0会计算更新的模型，再将更新的模型传输到GPU 2中；接着GPU 0把模型传输到GPU 1，同时GPU 2把模型传输到GPU 3。</p>
<p>  CNTK：使用MPI作为GPU之间的数据通信方法。CNTK支持4种类型的并行SGD算法（即：DataParallelSGD，BlockMomentumSGD，ModelAveragingSGD，DataParallelASGD）。对于本文关心的 data parallel SGD，CNTK把每个minibatch分摊到N个worker上。每次mini-batch后将梯度进行交换和聚合。</p>
<p>  MXNet：同样将mini-batch样本分配到所有GPU中，每个GPU向前后执行一批规模为M/N的任务，然后在更新模型之前，将梯度汇总。</p>
<p>  TensorFlow：在每个GPU上放置一份复制模型。也将mini-batch分到所有GPU。</p>
<p>  Torch：其数据并行机制类似于MXNet，把梯度聚合的操作放在GPU端，减少了PCI-e卡槽的数据传输。</p>
<p>  ##　　3. 评测方法</p>
<p>  <strong>处理时间(Processing time)及收敛速度(Convergence rate)</strong> 是用户训练深度学习模型时最看重的两个因素。因此该实验主要通过测量这两个指标以评估这几种深度学习工具。</p>
<p>  　　一方面，评估处理时长有一种高效且主流的方法，就是测出对一个mini-batch所输入数据一次迭代的时长。在实际操作中，经历多轮迭代或收敛以后，深度学习的训练过程会终止。因此，对于每种神经网络，该实验使用不同大小的mini-batch来评测各个深度学习软件工具。作者针对每种大小的mini-batch都多次迭代，最后评估其平均运行速度。另一方面，由于数据并行化可能影响收敛速度，该评测还在多GPU卡的情况下比较了收敛速度。</p>
<p>  　　评测使用合成数据集和真实数据集。合成数据集主要用于评估运行时间，真实数据集用于测量收敛速度。每种工具的时间测量方法如下：</p>
<p>  Caffe：使用“caffe train”命令训练所指定网络，随之计算两次连续迭代过程间的平均时间差。<br>  CNTK：与Caffe类似，但排除包含磁盘I / O时间的首个epoch。<br>  MXNet：使用内部定时功能，输出每个epoch和迭代的具体时间。<br>  TensorFlow：在源脚本里使用计时功能，计算平均迭代时间。<br>  Torch：和TensorFlow一样。</p>
<p>  　　这几种工具均提供非常灵活的编程API或用于性能优化的配置选项。例如CNTK中可以在配置文件中指定“maxTempMemSizeIn-SamplesForCNN”选项，以控制CNN使用的临时内存的大小，虽然可能导致效率略微降低，但是内存需求更小了。</p>
<p>  　　MXNet、TensorFlow和Torch也有丰富的API，在用于计算任务时供用户选择。换句话说，可能存在不同API以执行相同的操作。因此本评测结果仅仅是基于作者对这些工具用法的理解，不保证是最佳配置下的结果。</p>
<p>  　　评测中的深度学习软件版本和相关库如表1所示。<br>  　　<img src="http://img.mp.itc.cn/upload/20170128/09e3bf5190ea4d7c84c00fe00541240c.jpeg" alt=""><br>  　　表1：用于评测的深度学习软件</p>
<p>  　　神经网络和数据集：对于合成数据的测试，实验采用具有约5500万个参数的大型神经网络（FCN-S）来评估FCN的性能。同时选择ImageNet所选的AlexNet和ResNet-50作为CNN的代表。</p>
<p>  　　对于真实数据的测试，为MNIST数据集构建的FCN（FCN-R）较小；针对Cifar10数据集则使用名为AlexNet-R和ResNet-56的AlexNet架构。对于RNN，考虑到主要计算复杂度与输入序列长度有关，作者选择2个LSTM层进行测试，输入长度为32。每个网络的详细配置信息如表2和表3所示。<br>  　　<img src="http://img.mp.itc.cn/upload/20170128/623743f8211f4be3b93a54f51775e577.png" alt=""><br>  　　表2：合成数据的神经网络设置。注意：FCN-S有4层隐藏层，每层2048个节点；并且AlexNet-S中排除了batch normalization操作和dropout操作；为了测试CNN，输入数据是来自ImageNet数据库的彩色图像（维度224×224×3），输出维度是ImageNet数据的类别数量。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/eec0ea28137548688e2c7656438f69fb.jpeg" alt=""><br>  　　表3：真实数据的神经网络设置。注：FCN-R有3个隐藏层，节点数分别为2048、4096和1024。AlexNet-R的架构与原始出处里Cifar10所用的AlexNet相同，但不包括本地响应规范化（LRN）操作（CNTK不支持）。对于ResNet-56，作者沿用了最原始文件里的架构。<br>  　　硬件平台：评测使用两种类型的多核CPU，其中包括一个4核台式机级CPU（Intel i7-3820 CPU @ 3.60GHz）和两个8核服务器级CPU（Intel XeonCPU E5-2630 v3 @ 2.40GHz），测试不同线程数下各个工具的性能。另外还用三代不同的GPU卡，分别是采用Maxwell架构的NVIDIA GTX 980 @ 1127MHz，采用Pascal架构的GTX 1080 @1607MHz，以及采用Kepler架构的Telsa K80 @ 562MHz。<br>  　　评测只使用K80 GPU两个GK210芯片中的一个进行单GPU比较，同时，为了使得结果可重复，已禁用GPU自动超频功能。为了避免神经网络大小对主机内存的依赖，两台测试机分别配备64GB内存和128GB内存。硬件配置的详细信息如表4所示。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/c30c5803a0534de989bb41bc741499d7.jpeg" alt=""><br>  　　表4：本评测的硬件设置。注：K80卡上有2个GK210 GPU，但为了比较测试单GPU性能仅使用一个GPU。<br>  　　数据并行化评测则在两个Tesla K80卡上进行，这样共有4个GK210 GPU。对于多GPU卡实验，系统配置如表5所示。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/238ac9e3deb84fccb16b603426986c7f.png" alt=""><br>  　　表5：数据并行性的评测硬件设置。注：K80卡上有两个GK210 GPU，因此进行双GPU并行评测时使用一个K80卡，进行四GPU并行评测时使用两个K80卡。</p>
<p>  　　各神经网络，软件工具和硬件的组合结果如表6所示。<br>  　　<img src="http://img.mp.itc.cn/upload/20170128/a8dcb8f99eb24515a691d294a2681d26_th.jpeg" alt=""><br>  　　表6：各神经网络、软件工具和硬件的组合结果</p>
<h2 id="4-评测结果"><a href="#4-评测结果" class="headerlink" title="　　4. 评测结果"></a>　　4. 评测结果</h2><p>  　　评测结果分别在三个子部分呈现：CPU结果，单GPU结果和多GPU结果。对于CPU结果和单GPU结果，主要关注运行时长；对于多GPU还提出了关于收敛速度的比较。不同平台上的主要评测结果参见表7及表8。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/ed2fc7412342433680f7b61436f0b341_th.jpeg" alt=""><br>  　　表7：评测对比结果（每个mini-batch的运算时间，单位：秒）。注：FCN-S，AlexNet-S，ResNet-50，FCN-R，AlexNet-R，ResNet-56和LSTM的mini-batch大小分别为64，16，16，1024，1024，128，128。</p>
<p>  <img src="http://img.mp.itc.cn/upload/20170128/4a38406eab024503be5769e8ac41905d.png" alt=""><br>  　　表8：单GPU与多GPU间的比对结果（每个mini-batch的运算时间，单位：秒）。注：FCN-R，AlexNet-R和ResNet-56的mini-batch大小分别为4096，1024和128。</p>
<p>  　　4.1. CPU评测结果<br>  　　具体参见表7及原文。</p>
<p>  　　4.2. 单GPU卡评测结果<br>  　　在单GPU的比较上，该评测还展示了不同mini-batch大小的结果，以展示mini-batch大小对性能的影响。（译者注：原论文结论中详细描述了不同mini-batch大小下各学习工具的性能，具体见图表）<br>  　　4.2.1. 合成数据（Synthetic Data）<br>  　　<img src="http://img.mp.itc.cn/upload/20170128/11a1c56f825641eda437a7d0723294d0.jpeg" alt=""><br>  　　FCN-S：Caffe最佳，其次是CNTK和Torch，最后是TensorFlow及MXNet。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/000e636aecab44b99aa57f7679e7c83d.jpeg" alt=""><br>  　　AlexNet-S：MXNet性能最佳，其次是Torch。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/e8f188b64f6c433ca530f06e4227c539.jpeg" alt=""><br>  　　ResNet-50：MXNet性能远远高于其他工具，尤其是mini-batch大小比较大的时候。其次是CNTK和TensorFlow，Caffe相对较差。</p>
<p>  　　4.2.2. 真实数据（Real Data）</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/57bace7104814370b124ec4631f54ff6.jpeg" alt=""><br>  　　FCN-R：Torch最佳，Caffe、CNTK及MXNet三个工具次之，TensorFlow最差。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/e99ac42cc893469db321177e3158e097_th.jpeg" alt=""><br>  　　AlexNet-R：K80 平台上CNTK表现最佳，Caffe和Torch次之，然后是MXNet。TensorFlow处理时间最长。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/fd20ed8fa7b24591ae9515666378c32c_th.jpeg" alt=""><br>  　　ResNet-56：MXNet最优，其次是Caffe、CNTK 和Torch，这三个接近。最后是TensorFlow。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/6e3f243e096b482e900604b7a2eb523d_th.jpeg" alt=""><br>  　　LSTM：CNTK全面超越其他工具。</p>
<p>  　　4.3.多GPU卡评测结果</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/5d425d96f6634b5287743f81de3ee833_th.jpeg" alt=""></p>
<p>  　　FCN-R：单GPU的情况下，Caffe、CNTK及MXNet接近，TensorFlow和Torch稍差。GPU数量翻番时，CNTK和MXNet的可扩展性最佳，均实现了约35%的提速，caffe实现了大约28%的提速，而Torch和TensorFlow只有约10%。GPU数量变为4个时，TensorFlow和Torch没有实现进一步的提速。</p>
<p>  　　而收敛速度往往随着GPU数量的增加而增快。单个GPU时，Torch的训练融合速度最快，其次是Caffe、CNTK和MXNet，TensorFlow最慢。当GPU的数量增加到4时，CNTK和MXNet的收敛速度率接近Torch，而Caffe和TensorFlow收敛相对较慢。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/1bf01dbba09a4580bc98de50b687f32e_th.jpeg" alt=""><br>  　　AlexNet-R：单个GPU时，CNTK，MXNet和Torch性能接近，且比Caffe和TensorFlow快得多。随着GPU数量的增长，全部工具均实现高达40%的提速，而TensorFlow只有30%。<br>  　　至于收敛速度，MXNet和Torch最快，CNTK稍慢，但也比Caffe和TensorFlow快得多。</p>
<p>  　　<img src="http://img.mp.itc.cn/upload/20170128/a5cfe2aa4ce14f67b6ef2f93a827d5e2_th.jpeg" alt=""><br>  　　ResNet-56：单GPU时，Torch用时最少。多个GPU时，MXNet往往更高效。<br>  　　至于收敛速度，整体来说MXNet和Torch比其他三个工具更好，而Caffe最慢。</p>
<p>  ##　　5. 讨论</p>
<p>  对于CPU并行，建议线程数不大于物理CPU内核数。因为在计算过程中需要额外的CPU资源来进行线程调度，如果CPU资源全部用于计算则难以实现高性能。然而，借助于Eigen的BLAS库（BLAS library），因其为了SIMD指令优化过，因此随着CPU内核数的增长，TensorFlow的性能能更好。</p>
<p>  　　在FCN神经网络上，如果只用一个GPU卡，那么Caffe、CNTK和Torch的性能要比MXNet和TensorFlow略好。</p>
<p>  　　通常来说，训练一个网络包含两阶计算（即前馈和后向传播）。在前馈阶段，矩阵乘法是最耗时的操作，评测的四个工具全部采用cuBLAS API：cublasSgemm。如果想要把矩阵A乘以矩阵B的转置，可以将cublasSgemm API的第二个参数设置为CUBLAS_OP_T，即应用in-place矩阵转置。但这就导致与没有转置的矩阵乘法相比，性能减慢3倍（例如，C = A×B^T，其中 A∈R^1024×26752 ，B∈R^2048×26752）。这是因为in-place矩阵转置非常耗时。CNTK和TensorFlow构造自己的数据结构，从而用的是cublasSgemm的CUBLAS_OP_N，而Caffe和Torch使用CUBLAS_OP_T。</p>
<p>  　　在后向传播的阶段，则需要使用矩阵乘法来计算梯度，并使用element-wise矩阵运算来计算参数。如果通过调用cuBLAS来将A乘以B的转置，效率低时，可先转置B（如果GPU具有足够的内存，则采用out-place）再应用矩阵乘法可能会效果更好。</p>
<p>  　　此外，cublasSgemm API完全支持后向传播，因为它在矩阵乘法后添加了一个缩放的矩阵。因此，如果将梯度计算和更新操作合并到单个GPU核中，则可以提高计算效率。为了优化FCN的效率，还可以在不转置的情况下使用cublasSgemm API，并同时使用cublasSgemm来计算梯度及执行更新操作。</p>
<p>  　　在CNN上，所有工具包均使用cuDNN库进行卷积运算。尽管API调用相同，但是参数可能导致GPU内核不同。相关研究发现，在许多情况下，与直接执行卷积运算相比，FFT是更合适的解决方案。在矩阵的FFT之后，卷积计算可以被转换为更快速的内积运算（inner product operation）。</p>
<p>  　　对于使用多个GPU卡的数据并行性，运算的扩展性受到梯度聚合处理的极大影响，因为其需要通过PCI-e传输数据。在本评测的测试平台中，Telsa K80的PCIe 3.0的最高吞吐量约为8GB/秒，这意味着在FCN-R情况下需要0.0256秒的时间将GPU的梯度转移到CPU。但是一个mini-batch的计算时间只有大约100毫秒。因此，减少GPU和CPU之间传输数据的成本将变得极为关键。</p>
<p>  　　不同软件工具的性能表现各异，且与并行设计的策略相关。在Caffe中，梯度更新在GPU端执行，但它使用了树减少策略（tree reduction strategy）。如果说有4个GPU用于训练，则两对GPU将首先各自交换梯度（即GPU 0与GPU 1交换，GPU 2与GPU 3交换），然后GPU 0与GPU 2交换。之后，GPU 0负责计算更新的模型，再将模型传送到GPU 1，然后0将模型传送到1，2传送模型到3，这是一个并行过程。</p>
<p>  　　因此，Caffe的可扩展性（scalability）的性能在很大程度上取决于系统的PCI-e拓扑。CNTK的作者在框架中添加了1比特的随机梯度下降（1-bit stochastic gradient descent），这意味着PCI-e交换梯度的时间可大大缩短。因此，即使使用大型网络，CNTK的可伸缩性也依旧表现良好。</p>
<p>  　　在这类网络上，MXNet也表现出良好的可扩展性，因为它是在GPU上进行梯度聚合，这不仅减少了经常传输梯度数据的PCI-e时间，并能利用GPU资源来进行并行计算。</p>
<p>  　　然而，TensorFlow在CPU端进行梯度聚合和模型更新，这不仅需要很多时间通过PCI-e传输梯度，而且还使用单个CPU更新串行算法中的模型。因此TensorFlow的伸缩性不如其他工具。</p>
<p>  　　对于多个GPU，Torch在扩展性上与TensorFlow类似。其梯度聚合和更新都在CPU端执行，但Torch使用了并行算法来利用所有空闲的CPU资源。因此，其伸缩性要略好于TensorFlow，但仍然比不上Caffe、CNTK和MXNet。</p>
<p>  　　总的来说，因为有了GPU计算资源，上述所有深度学习工具的速度与CPU的版本相比，都有了极大提高。这并不出奇，因为在GPU上的矩阵乘法以及FFT的性能要明显优于CPU。</p>
<p>  　　未来作者还将评测更多的深度学习工具（比如百度的Paddle），也会把 AMD的GPU等也加入评测。并在高性能GPU集群上进行评测。</p>
<p>  　　论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://it.sohu.com/20170128/n479665884.shtml&quot;&gt;新智元mp&lt;/a&gt;&lt;br&gt;论文作者：Shaohuai Shi, Qiang Wang, Pengfei Xu, Xiaowen Chu&lt;br&gt;译者：吴博, Elaine, Melody&lt;/p&gt;
&lt;p&gt;【新智元导读】新年伊始，新智元向你推荐香港浸会大学计算机学院褚晓文团队最新论文《基准评测当前最先进的深度学习软件工具》，评测了 Caffe、CNTK、MXNet、TensorFlow、Torch 这五个最受欢迎的DL框架在 FCN、CNN、RNN 上的表现。这是伯克利RISE实验室大牛、RISC之父 David Patterson 也在关注的深度学习库评测。论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。【进入新智元公众号，在对话框输入“0128”下载论文】&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Tensorflow" scheme="http://ipcreator.me/tags/Tensorflow/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>人工智能和机器学习的进步 需要一个更加开源的世界</title>
    <link href="http://ipcreator.me/2017/02/13/Program/Resources/ai-and-machine-learning-need-more-open-sources/"/>
    <id>http://ipcreator.me/2017/02/13/Program/Resources/ai-and-machine-learning-need-more-open-sources/</id>
    <published>2017-02-13T00:33:06.000Z</published>
    <updated>2017-02-27T03:51:39.014Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dy.163.com/v2/article/detail/CC2EFV8N0511CUKV.html" target="_blank" rel="external">作者：网易AI研究院</a></p>
 <div align="center"><br><img src="http://dingyue.nosdn.127.net/y7fA8RIWdwS8CmRvAC1KG=5KOcTs5TM5WxRn12XHcaGZo1485784023010compressflag.jpg" width="738" height="520"><br> </div>

<p>  国外媒体TechCrunch撰文指出，当前的人工智能（AI）开源模式封闭，存在不足，且不合时宜。</p>
  <a id="more"></a>
<p>  人工智能正变得越来越重要。拥有机器学习（ML）技术经验的企业在寻求取得基于人工智能的技术。</p>
<p>  　　还没有打造出机器学习技术的企业正竭力理解和设计机器学习和AI战略。正当AI受到大肆追捧，人们对该技术既感到困惑，又对它的风险感到恐慌，来自谷歌、Facebook、百度、微软等公司的一连串开源贡献公告（通过 <strong>Tensorflow、BigSur、Torch、SciKit、Caffe、CNTK、DMTK、Deeplearning4j、H2O、Mahout、MLLib、NuPIC、OpenNN等项目）</strong> 带来了一种明显的上手AI以及ML的方式，科技行业以外的企业尤其受益。</p>
<p>  　　发现项目，下载，安装……应该是件轻而易举的事情。但事实上它并没有表面上那么的简单。</p>
<p>  　　对于在AI使能或者AI影响的系统主导的时代软件的共享来说，当前的开源模式并不足够，且已经不合时宜；用户一天里使用过的AI引擎可能多达数千个。</p>
<p>  　　对于AI和ML先驱们来说，共享他们的代码并不足够。整个行业和世界需要新的开源模式： <strong> 经过AI和ML训练的引擎本身开源的同时，数据、功能特性和现实世界表现细节也要开源。</strong></p>
<h2 id="当前的开源模式不足够且过时"><a href="#当前的开源模式不足够且过时" class="headerlink" title="当前的开源模式不足够且过时"></a>当前的开源模式不足够且过时</h2><p>  　　AI和ML使能和影响的系统不同于其它用开源部件打造的软件。用开源部件打造的软件本质上还是具有确定性的，也就是说所设计和编写的软件每一次执行时的表现都是一样的。而 <strong>AI和ML系统，尤其是人工智能系统，并不能保证能够表现出确定性的行为。</strong> 随着对新情境、新环境和新用户的学习和适应，这些系统将会改变它们的行为。本质上，一旦这些AI系统被部署到现实世界，它们的创造者就会失去对AI的控制。当然，创造者们可以在学习框架中加入制衡机制。然而，即便是在AI系统被制约的范围内，仍需要进行大量的解读工作。与此同时，被AI包围的世界面临的更大挑战在于，制定制约条件的人造成的冲突。</p>
<p>  　　想想看，最近有报道援引梅赛德斯董事长克里斯托弗·冯·雨果(Christoph Von Hugo)的话说，梅赛德斯无人驾驶汽车会选择优先保护乘客的生命，而非路人的生命。尽管该公司后来澄清说雨果的话被错误引述，但这揭示了资本主义将如何影响AI系统所嵌入的约束条件的根本性问题。</p>
<h2 id="资本主义与AI伦理道德"><a href="#资本主义与AI伦理道德" class="headerlink" title="资本主义与AI伦理道德"></a>资本主义与AI伦理道德</h2><p>  <div align="center"><br> <img src="http://dingyue.nosdn.127.net/oeDjsmBglpcccKb5VYrqS0VR5ItRLyetZGApnW4jl1oa11485784023010compressflag.jpg" width="680" height="481"><br>  </div><br>  　　<br>  　　如果企业的经营目的是创造利润，那将基于AI的体验描述为带附加价值的差异化体验，要求消费者溢价购买该技术的产品服务会在多久后进入市场呢？</p>
<p>  　　在这种情况下，愿意且有能力购买那种差异化体验的用户相比其他用户将会获得不正当的好处。因为企业将尝试从其对AI的投入中获得回报，这种技术将会局限于那些买得起的人。这将会导致AI内置的限制和行为对那些掏腰包购买的人有利，给他们提供保护，或者偏爱他们。</p>
<p>  　　另一个担忧是，谁来为AI和M使能的产品的故障或者行为表现不佳负责的法律和政策问题。这个责任由谁来担负？用户，服务提供商，数据科学家，还是AI引擎？该如何问责，如何界定责任？回答这些问题的前提是，清晰地描述和遵守引发AI和ML的创造和使用的一系列事件。</p>
<h2 id="AI与AI的互动"><a href="#AI与AI的互动" class="headerlink" title="AI与AI的互动"></a>AI与AI的互动</h2><p>  <div align="center"><br> <img src="http://dingyue.nosdn.127.net/yYjRrrIze9efDETLaqqpzvb4Mp24dFu3gB6Ipv7saL9Fj1485784023010compressflag.jpg" width="640" height="391"><br>  </div>
  　　</p>
<p>  　　机器人玩木制魔术方块的3D渲染图</p>
<p>  　　AI之间的冲突</p>
<p>  　　考虑到AI使能产品在行为表现上可能存在不确定性，在原来没观察到的交互中可能会有意想不到的表现，在AI使能的产品代表两个或者更多的不同用户相互互动的场景中，这一问题会进一步放大。例如。当两辆由两个独立的AI引擎（由不同的公司用不同的训练数据和功能，以及独立配置的偏好和情境信息打造而成）驱动和运作的汽车遇到停车标志，或者将要发生碰撞时，会发生什么事情呢？这些系统在响应类似的情境时，即便有很细小的差异和变化，都可能会产生意想不到的不良影响。</p>
<p>  　　偏好问题蔓延</p>
<p>  　　互相影响的AI的另一个潜在副作用会放大训练的偏好风险。例如，如果无人驾驶汽车观察到另一辆无人驾驶汽车在以路人受伤为代价来保护乘客，观察到这一选择确保另一辆车能够避免发生事故，这种“学习”会使得它在遇到类似的情况时作出类似的行为。这会造成偏好问题蔓延：被独立训练的AI引擎受到另一个AI引擎的行为的影响（不管是正面的影响，还是负面的影响）。</p>
<p>  　　学习的灵活性</p>
<p>  　　即便类似的AI引擎获得的学习数据是一样的，训练环境和用来执行训练的基础设施方面的差异，也会导致训练和学习速度变得不一样，因而它们会得出不一样的结论。随着时间的推移，这些细微的变化会导致AI引擎的行为出现巨大的变化，带来不可预知的影响。</p>
<p>  　　新的AI开源模式</p>
<p>  　　我们需要新的AI开源模式来提供框架解决上述的部分问题。考虑到AI的本质，<strong>开源用于打造AI和ML引擎，将它们嵌入产品当中，并不足够。此外，类似于科学研究，行业将需要贡献回能够形成新改良的系统、引擎和产品基础的AI和ML引擎。</strong></p>
<p>  　　基线、基准与标准</p>
<p>  　　对于无人驾驶汽车、图像识别、语音文本转换等所有重要的场景，尤其是有多家服务提供商涉足的场景， <strong>行业需要能够定义统一的基线和标准，让所有其它的新AI引擎或者现存AI引擎有评估和堆栈排序的标准（例如，美国国家公路安全局针对无人驾驶汽车制定五星安全评级）。</strong> 为重要场景定义为行业所接受和批准的基准，可确保服务提供商和消费者能够在挑选AI与ML使能的产品服务时做出精明的决策。此外，现有的AI引擎可不断地根据基准与标准进行评估，进而确保这些系统的质量不断改进。</p>
<p>  　　<strong>开发AI和ML模型的公司应当考虑对完整的AI和ML模型进行开源贡献（不仅仅是贡献打造这种模型的技术和框架）。</strong> 例如，即便是谷歌已有5年历史的图像识别模型，或者来自微软的Speech to Text语音文本转化模型，都能够在其它的领域或者行业激发AI和ML的快速创新和同化作用，进而形成自维持的创新回路。科技以外的行业也能够利用这些模式来启动自有的项目，以及将它们的学习成果贡献回开源社区。</p>
<p>  　　偏好判定</p>
<p>  　　行业需要偏好判定能力来使得嵌入AI和ML引擎的偏好能够被尽快发现和移除。没有这种能力的话，行业会难以形成在各种各样的场景中有着一致和确定性表现的统一AI引擎。偏好判定和偏好移除在AI开源模型中将需要以下的支持。</p>
<h3 id="数据假定和偏好"><a href="#数据假定和偏好" class="headerlink" title="数据假定和偏好"></a>数据假定和偏好</h3><p>  　　AI使能的产品设计师需要确保它们理解其所做的和嵌入AI与ML引擎的数据假定和偏好。与其它AI使能产品进行交互的产品需要确保它们理解且准备好处理AI引擎行为带来的影响。为了确保消费者或者这类AI和ML模型的整合商做好准备，各个AI和ML模型应当揭示和共享以下的标准。</p>
<p>  　　<strong>数据收集标准</strong></p>
<p>  　　数据是如何被收集的呢？数据生成器有哪些呢？数据收集的频率、地方、时间、方式和原因呢？数据是如何被收集、分层和传输的呢？</p>
<p>  　　<strong>数据选择标准</strong></p>
<p>  　　数据是如何被选来训练的呢？数据不被选择的标准是什么呢？什么数据子集被选择，什么不被选择呢？定义高质量数据的标准是什么呢？可接受但非高质量的数据标准是什么呢？</p>
<p>  　　<strong>数据处理标准</strong></p>
<p>  　　数据经过怎样的处理后才被拿来训练？数据经过怎样的转变、浓缩和概述呢？数据处理的频率如何？有什么会导致预订的数据处理推迟或者停止呢？</p>
<h3 id="功能假定与偏好"><a href="#功能假定与偏好" class="headerlink" title="功能假定与偏好"></a>功能假定与偏好</h3><p>  　　AI和ML模型通过对被模式化的系统的功能或者特点的观察来训练。这些功能提取自数据，被应用于AI和ML引擎，可预测该系统的行为，或者将新信号归类成想要的类别来触发系统特定的动作或者行为。消费者和AI模型的整合商需要清楚有哪些功能被选来开发AI模型，以及有哪些功能被考虑，哪些没被选择及没被选择的原因。此外，用来判定训练功能的洞见将需要记录下来和共享。</p>
<p>  　　<strong>盲点移除</strong></p>
<p>  　　由于模型内置的偏好和假定，AI和ML引擎会形成令其在特定的情境、环境和语境中的有用性和效能受到限制的盲点。</p>
<p>  　　<strong>盲点回报和反馈回路</strong></p>
<p>  　　AI和ML开源模型的另一重要功能，应当是既能够判定特定模型是否有盲点，还能够给AI模型贡献回可用于移除这些盲点的数据（现实生活的例子）。大体上，这种机制类似于垃圾邮件的汇报机制：垃圾邮件检测引擎可利用用户新提供的垃圾邮件案例来更新其对垃圾邮件的定义和检测垃圾邮件所需的过滤工具。</p>
<p>  　　<strong>协作性盲点移除</strong></p>
<p>  　　理想的开源协议的另一个特性会是，不同服务提供商之间相互共享数据，共同协作移除模型中的盲点。想想谷歌的无人驾驶汽车和特斯拉的Autopilot自动驾驶模式。谷歌的汽车在自动驾驶模式下行驶了大约200万英里，而特斯拉汽车在Autopilot下行驶了大约5000万英里的高速公路。抛开这两家公司是竞争对手的事实，它们的数据集包含大量避免碰撞和确保司机、乘客或者路人的安全相关的数据。它们 <strong>可相互利用各自的数据集来改进各自的安全协议和程序。</strong> 也许，这种数据应当成为开源模型的一部分，毕竟它们可最大化行业和用户的利益。</p>
<p>  　　总结</p>
<p>  　　要真正变革和颠覆我们的生活，带来更好、更简单、更安全且更令人愉快的体验，<strong>AI和ML需要被纳入尽可能多的场景当中，需要被纳入各个行业领域的用户案例当中。</strong> 要真正启动和加速这种普及，<strong>开源用以打造AI和ML引擎的框架其实并不足够。我们需要新的开源模式来使得企业能够贡献和利用的不只是AI和ML开发技术，而是整个受训模型。而且，这些受训模型能够得到改进或者调整，或者在特定的场景中适应新环境以及AI和ML基准与标准，进而让新的AI和ML有参照标准。此外，揭示AI和ML模型的假定和偏好（数据或者功能层面）的信息，以及让AI和ML模型消费者能够给特定场景中的所有AI和ML产品贡献回重要数据和反馈的反馈回路，也非常重要。</strong> 没有这种开源模式，科技行业以外的世界将会继续难以实现AI和ML技术的普及。（皓慧）</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dy.163.com/v2/article/detail/CC2EFV8N0511CUKV.html&quot;&gt;作者：网易AI研究院&lt;/a&gt;&lt;/p&gt;
 &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://dingyue.nosdn.127.net/y7fA8RIWdwS8CmRvAC1KG=5KOcTs5TM5WxRn12XHcaGZo1485784023010compressflag.jpg&quot; width = &quot;738&quot; height = &quot;520&quot; &gt;&lt;br&gt; &lt;/div&gt;

&lt;p&gt;  国外媒体TechCrunch撰文指出，当前的人工智能（AI）开源模式封闭，存在不足，且不合时宜。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AI" scheme="http://ipcreator.me/tags/AI/"/>
    
      <category term="Machine Learning" scheme="http://ipcreator.me/tags/Machine-Learning/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
  </entry>
  
  <entry>
    <title>Google 开源项目风格指南 (中文版)</title>
    <link href="http://ipcreator.me/2017/02/12/Program/Resources/google-styleguide/"/>
    <id>http://ipcreator.me/2017/02/12/Program/Resources/google-styleguide/</id>
    <published>2017-02-12T04:10:06.000Z</published>
    <updated>2017-02-15T12:20:26.050Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://github.com/zh-google-styleguide/zh-google-styleguide" target="_blank" rel="external">Jinhai ZHOU/JinhaiZ</a></p>
<p>每个较大的开源项目都有自己的风格指南: 关于如何为该项目编写代码的一系列约定 (有时候会比较武断). 当所有代码均保持一致的风格, 在理解大型代码库时更为轻松.</p>
<p>“风格” 的含义涵盖范围广, 从 “变量使用驼峰格式 (camelCase)” 到 “决不使用全局变量” 再到 “决不使用异常”. 英文版项目维护的是在 Google 使用的编程风格指南. 如果你正在修改的项目源自 Google, 你可能会被引导至 英文版项目页面, 以了解项目所使用的风格.</p>
 <a id="more"></a>
<p>我们已经发布了五份 中文版 的风格指南:</p>
<p><a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-cpp-styleguide/" target="_blank" rel="external">Google C++ 风格指南</a><br><a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-objc-styleguide/" target="_blank" rel="external">Google Objective-C 风格指南</a><br><a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/" target="_blank" rel="external">Google Python 风格指南</a><br><a href="https://github.com/darcyliu/google-styleguide/blob/master/JSONStyleGuide.md" target="_blank" rel="external">Google JSON 风格指南</a><br><a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-shell-styleguide/" target="_blank" rel="external">Google Shell 风格指南</a><br>中文版项目采用 reStructuredText 纯文本标记语法, 并使用 Sphinx 生成 HTML / CHM / PDF 等文档格式.</p>
<p>英文版项目还包含 cpplint - 一个用来帮助适应风格准则的工具, 以及 google-c-style.el, Google 风格的 Emacs 配置文件.<br>另外, 招募志愿者翻译 JavaScript Style Guide 以及 XML Document Format Style Guide, 有意者请联系 Yang.Y.</p>
<h2 id="Software-Release-Practice-HOWTO"><a href="#Software-Release-Practice-HOWTO" class="headerlink" title="Software Release Practice HOWTO"></a><a href="http://en.tldp.org/HOWTO/Software-Release-Practice-HOWTO/index.html" target="_blank" rel="external">Software Release Practice HOWTO</a></h2><p>Eric Steven Raymond</p>
<p>This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it.</p>
<p>This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards.</p>
<p>Table of Contents</p>
<ol>
<li><p>Introduction<br>1.1. Why this document?<br>1.2. New versions of this document</p>
</li>
<li><p>Good patching practice<br>2.1. Do send patches, don’t send whole archives or files<br>2.2. Send patches against the current version of the code.<br>2.3. Don’t include patches for generated files.<br>2.4. Don’t send patch bands that just tweak version-control $-symbols.<br>2.5. Do use -c or -u format, don’t use the default (-e) format<br>2.6. Do include documentation with your patch<br>2.7. Do include an explanation with your patch<br>2.8. Do include useful comments in your code<br>2.9. Just one bugfix or new feature per patch.</p>
</li>
<li><p>Good project- and archive- naming practice<br>3.1. Use GNU-style names with a stem and major.minor.patch numbering.<br>3.2. But respect local conventions where appropriate<br>3.3. Try hard to choose a name prefix that is unique and easy to type</p>
</li>
<li><p>Good licensing and copyright practice: the theory<br>4.1. Open source and copyrights<br>4.2. What qualifies as open source</p>
</li>
<li><p>Good licensing and copyright practice: the practice<br>5.1. Make yourself or the FSF the copyright holder<br>5.2. Use a license conformant to the Open Source Definition<br>5.3. Don’t write your own license if you can possibly avoid it.<br>5.4. Make your license visible in a standard place.</p>
</li>
<li><p>Good development practice<br>6.1. Choose the most portable language you can<br>6.2. Don’t rely on proprietary code<br>6.3. Build systems<br>6.4. Test your code before release<br>6.5. Sanity-check your code before release<br>6.6. Sanity-check your documentation and READMEs before release<br>6.7. Recommended C/C++ portability practices</p>
</li>
<li><p>Good distribution-making practice<br>7.1. Make sure tarballs always unpack into a single new directory<br>7.2. Have a README<br>7.3. Respect and follow standard file naming practices<br>7.4. Design for Upgradability<br>7.5. Provide checksums</p>
</li>
<li><p>Good documentation practice<br>8.1. Documentation formats<br>8.2. Good practice recommendations</p>
</li>
<li><p>Good communication practice<br>9.1. Announce to Freecode<br>9.2. Have a website<br>9.3. Host project mailing lists<br>9.4. Release to major archives</p>
</li>
<li><p>Good project-management practice</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://github.com/zh-google-styleguide/zh-google-styleguide&quot;&gt;Jinhai ZHOU/JinhaiZ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;每个较大的开源项目都有自己的风格指南: 关于如何为该项目编写代码的一系列约定 (有时候会比较武断). 当所有代码均保持一致的风格, 在理解大型代码库时更为轻松.&lt;/p&gt;
&lt;p&gt;“风格” 的含义涵盖范围广, 从 “变量使用驼峰格式 (camelCase)” 到 “决不使用全局变量” 再到 “决不使用异常”. 英文版项目维护的是在 Google 使用的编程风格指南. 如果你正在修改的项目源自 Google, 你可能会被引导至 英文版项目页面, 以了解项目所使用的风格.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Google" scheme="http://ipcreator.me/tags/Google/"/>
    
      <category term="Open Source" scheme="http://ipcreator.me/tags/Open-Source/"/>
    
  </entry>
  
  <entry>
    <title>The Unix and Internet Fundamentals HOWTO</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/the-unix-and-internet-fundamentals-howto/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/the-unix-and-internet-fundamentals-howto/</id>
    <published>2017-01-20T12:31:06.000Z</published>
    <updated>2017-02-15T13:06:21.209Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.faqs.org/docs/Linux-HOWTO/Unix-and-Internet-Fundamentals-HOWTO.html" target="_blank" rel="external">Eric Raymond</a></p>
<p><img src="/img/eric-raymond.jpg" alt="Eric Raymond"></p>
<p>This document describes the working basics of PC-class computers, Unix-like operating systems, and the Internet in non-technical language.</p>
<a id="more"></a>
<p>Table of Contents</p>
<ol>
<li>Introduction<br>1.1. Purpose of this document<br>1.2. New versions of this document<br>1.3. Feedback and corrections<br>1.4. Related resources</li>
<li>Basic anatomy of your computer</li>
<li>What happens when you switch on a computer?</li>
<li>What happens when you log in?</li>
<li>What happens when you run programs from the shell?</li>
<li>How do input devices and interrupts work?</li>
<li>How does my computer do several things at once?</li>
<li>How does my computer keep processes from stepping on each other?<br>8.1. Virtual memory: the simple version<br>8.2. Virtual memory: the detailed version<br>8.3. The Memory Management Unit</li>
<li>How does my computer store things in memory?<br>9.1. Numbers<br>9.2. Characters</li>
<li>How does my computer store things on disk?<br>10.1. Low-level disk and file system structure<br>10.2. File names and directories<br>10.3. Mount points<br>10.4. How a file gets looked up<br>10.5. File ownership, permissions and security<br>10.6. How things can go wrong</li>
<li>How do computer languages work?<br>11.1. Compiled languages<br>11.2. Interpreted languages<br>11.3. P-code languages</li>
<li>How does the Internet work?<br>12.1. Names and locations<br>12.2. The Domain Name System<br>12.3. Packets and routers<br>12.4. TCP and IP<br>12.5. HTTP, an application protocol</li>
<li>To Learn More</li>
</ol>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>1.1. Purpose of this document</p>
<p>This document is intended to help Linux and Internet users who are learning by doing. While this is a great way to acquire specific skills, sometimes it leaves peculiar gaps in one’s knowledge of the basics – gaps which can make it hard to think creatively or troubleshoot effectively, from lack of a good mental model of what is really going on.</p>
<p>I’ll try to <strong>describe in clear, simple language how it all works.</strong> The presentation will be tuned for people using Unix or Linux on PC-class hardware. Nevertheless, I’ll usually refer simply to `Unix’ here, as most of what I will describe is constant across platforms and across Unix variants.</p>
<p>I’m going to assume you’re using an Intel PC. The details differ slightly if you’re running an Alpha or PowerPC or some other Unix box, but  <strong>the basic concepts are the same.</strong></p>
<p>I won’t repeat things, so you’ll have to pay attention, but that also means you’ll learn from every word you read. It’s a good idea to just skim when you first read this; you should come back and reread it a few times after you’ve digested what you have learned.</p>
<p>This is an evolving document. I intend to keep adding sections in response to user feedback, so you should come back and review it periodically.</p>
<p>1.2. New versions of this document</p>
<p>New versions of the Unix and Internet Fundamentals HOWTO will be periodically posted to comp.os.linux.help and comp.os.linux.announce and news.answers. They will also be uploaded to various Linux WWW and FTP sites, including the LDP home page.</p>
<p>You can view the latest version of this on the World Wide Web via the URL <a href="http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html" target="_blank" rel="external">http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html</a>.</p>
<p>This document has been translated into Polish.</p>
<p>1.3. Feedback and corrections</p>
<p>If you have questions or comments about this document, please feel free to mail Eric S. Raymond, at esr@thyrsus.com. I welcome any suggestions or criticisms. I especially welcome hyperlinks to more detailed explanations of individual concepts. If you find a mistake with this document, please let me know so I can correct it in the next version. Thanks.</p>
<p>1.4. Related resources</p>
<p>If you’re reading this in order to learn how to hack, you should also read the How To Become A Hacker FAQ. It has links to some other useful resources.</p>
<h2 id="2-Basic-anatomy-of-your-computer"><a href="#2-Basic-anatomy-of-your-computer" class="headerlink" title="2. Basic anatomy of your computer"></a>2. <strong>Basic anatomy of your computer</strong></h2><p>Your computer has a processor chip inside it that does the actual computing. It has internal memory (what DOS/Windows people call <code>RAM&#39;&#39; and Unix people often call</code>core’’; the Unix term is a folk memory from when RAM consisted of ferrite-core donuts). The processor and memory live on the motherboard, which is the heart of your computer.</p>
<p>Your computer has a screen and keyboard. It has hard drives and floppy disks. Some of these devices are run by controller cards that plug into the motherboard and help the computer drive them; others are run by specialized chipsets directly on the motherboard that fulfill the same function as a controller card. Your keyboard is too simple to need a separate card; the controller is built into the keyboard chassis itself.</p>
<p>We’ll go into some of the details of how these devices work later. For now, here are a few basic things to keep in mind about how they work together:</p>
<p>All the parts of your computer inside the case are connected by a bus. Physically, the bus is what you plug your controller cards into (the video card, the disk controller, a sound card if you have one). <strong>The bus is the data highway between your processor, your screen, your disk, and everything else.</strong></p>
<p>(If you’ve seen references to <code>ISA&#39;,</code>PCI’, and `PCMCIA’ in connection with PCs and have not understood them, these are bus types. ISA is, except in minor details, the same bus that was used on IBM’s original PCs in 1980; it is passing out of use now. PCI, for Peripheral Component Interconnection, is the bus used on most modern PCs, and on modern Macintoshes as well. PCMCIA is a variant of ISA with smaller physical connectors used on laptop computers.)</p>
<p>The processor, which makes everything else go, can’t actually see any of the other pieces directly; it has to talk to them over the bus. The only other subsystem that it has really fast, immediate access to is memory (the core). In order for programs to run, then, they have to be in core (in memory).</p>
<p>When your computer reads a program or data off the disk, what actually happens is that the processor uses the bus to send a disk read request to your disk controller. Some time later the disk controller uses the bus to signal the processor that it has read the data and put it in a certain location in memory. The processor can then use the bus to look at that data.</p>
<p>Your keyboard and screen also communicate with the processor via the bus, but in simpler ways. We’ll discuss those later on. For now, you know enough to understand what happens when you turn on your computer.</p>
<h2 id="3-What-happens-when-you-switch-on-a-computer"><a href="#3-What-happens-when-you-switch-on-a-computer" class="headerlink" title="3. What happens when you switch on a computer?"></a>3. What happens when you switch on a computer?</h2><p> <strong>A computer without a program running is just an inert hunk of electronics. </strong>  The first thing a computer has to do when it is turned on is start up a special program called an operating system. The operating system’s job is to help other computer programs to work by handling the messy details of controlling the computer’s hardware.</p>
<p>The process of bringing up the operating system is called booting (originally this was bootstrapping and alluded to the process of pulling yourself up ``by your bootstraps’’). Your computer knows how to boot because instructions for booting are built into one of its chips,    <strong>the BIOS (or Basic Input/Output System) chip.</strong></p>
<p>The BIOS chip tells it to look in a fixed place, usually on the lowest-numbered hard disk (the boot disk) for a special program called a boot loader (under Linux the boot loader is called LILO). The boot loader is pulled into memory and started. <strong>The boot loader’s job is to start the real operating system.</strong></p>
<p>The loader does this by looking for a kernel, loading it into memory, and starting it. When you boot Linux and see “LILO” on the screen followed by a bunch of dots, it is loading the kernel. (<strong>Each dot means it has loaded another disk block of kernel code.</strong>)</p>
<p>( <strong>You may wonder why the BIOS doesn’t load the kernel directly – why the two-step process with the boot loader? </strong> Well, the BIOS isn’t very smart. In fact it’s very stupid, and Linux doesn’t use it at all after boot time. It was originally written for primitive 8-bit PCs with tiny disks, and literally can’t access enough of the disk to load the kernel directly. The boot loader step also lets you start one of several operating systems off different places on your disk, in the unlikely event that Unix isn’t good enough for you.)</p>
<p>Once the kernel starts, it has to look around, find the rest of the hardware, and get ready to run programs. It does this by poking not at ordinary memory locations but rather at I/O ports – special bus addresses that are likely to have device controller cards listening at them for commands. The kernel doesn’t poke at random; it has a lot of built-in knowledge about what it’s likely to find where, and how controllers will respond if they’re present. This process is called autoprobing.</p>
<p>Most of the messages you see at boot time are the kernel autoprobing your hardware through the I/O ports, figuring out what it has available to it and adapting itself to your machine. The Linux kernel is extremely good at this, better than most other Unixes and much better than DOS or Windows. In fact, many Linux old-timers think the cleverness of Linux’s boot-time probes (which made it relatively easy to install) was a major reason it broke out of the pack of free-Unix experiments to attract a critical mass of users.</p>
<p>But getting the kernel fully loaded and running isn’t the end of the boot process; it’s just the first stage (sometimes called run level 1). After this first stage, the kernel hands control to a special process called `init’ which spawns several housekeeping processes.</p>
<p>The init process’s first job is usually to check to make sure your disks are OK. Disk file systems are fragile things; if they’ve been damaged by a hardware failure or a sudden power outage, there are good reasons to take recovery steps before your Unix is all the way up. We’ll go into some of this later on when we talk about how file systems can go wrong.</p>
<p>Init’s next step is to start several daemons. <strong>A daemon is a program like a print spooler, a mail listener or a WWW server that lurks in the background</strong>, waiting for things to do. These special programs often have to coordinate several requests that could conflict. They are daemons because it’s often easier to write one program that runs constantly and knows about all requests than it would be to try to make sure that a flock of copies (each processing one request and all running at the same time) don’t step on each other. The particular collection of daemons your system starts may vary, but will almost always include a print spooler (a gatekeeper daemon for your printer).</p>
<p>The next step is to prepare for users. Init starts a copy of a program called getty to watch your console (and maybe more copies to watch dial-in serial ports). This program is what issues the login prompt to your console. Once all daemons and getty processes for each terminal are started, we’re at run level 2. At this level, you can log in and run programs.</p>
<p>But we’re not done yet. The next step is to start up various daemons that support networking and other services. Once that’s done, we’re at run level 3 and the system is fully ready for use.</p>
<h2 id="4-What-happens-when-you-log-in"><a href="#4-What-happens-when-you-log-in" class="headerlink" title="4. What happens when you log in?"></a>4. What happens when you log in?</h2><p>When you log in (give a name to getty) you identify yourself to the computer. It then runs a program called (naturally enough) login, which takes your password and checks to see if you are authorized to be using the machine. If you aren’t, your login attempt will be rejected. If you are, login does a few housekeeping things and then starts up a command interpreter, the shell. (Yes, getty and login could be one program. They’re separate for historical reasons not worth going into here.)</p>
<p>Here’s a bit more about what the system does before giving you a shell (you’ll need to know this later when we talk about file permissions). You identify yourself with a login name and password. That login name is looked up in a file called /etc/passwd, which is a sequence of lines each describing a user account.</p>
<p>One of these fields is an encrypted version of the account password (sometimes the encrypted fields are actually kept in a second /etc/shadow file with tighter permissions; this makes password cracking harder). What you enter as an account password is encrypted in exactly the same way, and the login program checks to see if they match. The security of this method depends on the fact that, while it’s easy to go from your clear password to the encrypted version, the reverse is very hard. Thus, even if someone can see the encrypted version of your password, they can’t use your account. (It also means that if you forget your password, there’s no way to recover it, only to change it to something else you choose.)</p>
<p>Once you have successfully logged in, you get all the privileges associated with the individual account you are using. You may also be recognized as part of a group. A group is a named collection of users set up by the system administrator. Groups can have privileges independently of their members’ privileges. A user can be a member of multiple groups. (For details about how Unix privileges work, see the section below on permissions.)</p>
<p>(Note that although you will normally refer to users and groups by name, they are actually stored internally as numeric IDs. The password file maps your account name to a user ID; the /etc/group file maps group names to numeric group IDs. Commands that deal with accounts and groups do the translation automatically.)</p>
<p>Your account entry also contains your home directory, the place in the Unix file system where your personal files will live. Finally, your account entry also sets your shell, the command interpreter that login will start up to accept your commmands.</p>
<h2 id="5-What-happens-when-you-run-programs-from-the-shell"><a href="#5-What-happens-when-you-run-programs-from-the-shell" class="headerlink" title="5. What happens when you run programs from the shell?"></a>5. What happens when you run programs from the shell?</h2><p>The shell is Unix’s interpreter for the commands you type in;  ## it’s called a shell because it wraps around and hides the operating system kernel.##  It’s an important feature of Unix that <strong>the shell and kernel are separate programs communicating through a small set of system calls. </strong> This makes it possible for there to be multiple shells, suiting different tastes in interfaces.</p>
<p>The normal shell gives you the ‘$’ prompt that you see after logging in (unless you’ve customized it to be something else). We won’t talk about shell syntax and the easy things you can see on the screen here; instead we’ll take a look behind the scenes at what’s happening from the computer’s point of view.</p>
<p>After boot time and before you run a program, you can think of your computer as containing a zoo of processes that are all waiting for something to do. They’re all waiting on events. An event can be you pressing a key or moving a mouse. Or, if your machine is hooked to a network, an event can be a data packet coming in over that network.</p>
<p>The kernel is one of these processes. It’s a special one, because it controls when the other user processes can run, and it is normally the only process with direct access to the machine’s hardware. In fact, user processes have to make requests to the kernel when they want to get keyboard input, write to your screen, read from or write to disk, or do just about anything other than crunching bits in memory. These requests are known as system calls.</p>
<p>Normally all I/O goes through the kernel so it can schedule the operations and prevent processes from stepping on each other. A few special user processes are allowed to slide around the kernel, usually by being given direct access to I/O ports. X servers (the programs that handle other programs’ requests to do screen graphics on most Unix boxes) are the most common example of this. But we haven’t gotten to an X server yet; you’re looking at a shell prompt on a character console.</p>
<p>The shell is just a user process, and not a particularly special one. It waits on your keystrokes, listening (through the kernel) to the keyboard I/O port. As the kernel sees them, it echoes them to your screen. When the kernel sees an `Enter’ it passes your line of text to the shell. The shell tries to interpret those keystrokes as commands.</p>
<p>**Let’s say you type <code>ls&#39; and Enter to invoke the Unix directory lister. The shell applies its built-in rules to figure out that you want to run the executable command in the file</code>/bin/ls’. It makes a system call asking the kernel to start /bin/ls as a new child process and give it access to the screen and keyboard through the kernel. Then the shell goes to sleep, waiting for ls to finish.</p>
<p>When /bin/ls is done, it tells the kernel it’s finished by issuing an exit system call. The kernel then wakes up the shell and tells it it can continue running. The shell issues another prompt and waits for another line of input.**</p>
<p>Other things may be going on while your `ls’ is executing, however (we’ll have to suppose that you’re listing a very long directory). You might switch to another virtual console, log in there, and start a game of Quake, for example. Or, suppose you’re hooked up to the Internet. Your machine might be sending or receiving mail while /bin/ls runs.</p>
<h2 id="6-How-do-input-devices-and-interrupts-work"><a href="#6-How-do-input-devices-and-interrupts-work" class="headerlink" title="6. How do input devices and interrupts work?"></a>6. How do input devices and interrupts work?</h2><p>Your keyboard is a very simple input device; simple because it generates small amounts of data very slowly (by a computer’s standards). When you press or release a key, that event is signalled up the keyboard cable to raise a hardware interrupt.</p>
<p>It’s the operating system’s job to watch for such interrupts. For each possible kind of interrupt, there will be an interrupt handler, a part of the operating system that stashes away any data associated with them (like your keypress/keyrelease value) until it can be processed.</p>
<p>What the interrupt handler for your keyboard actually does is post the key value into a system area near the bottom of memory. There, it will be available for inspection when the operating system passes control to whichever program is currently supposed to be reading from the keyboard.</p>
<p>More complex input devices like disk or network cards work in a similar way. Earlier, I referred to a disk controller using the bus to signal that a disk request has been fulfilled. What actually happens is that the disk raises an interrupt. The disk interrupt handler then copies the retrieved data into memory, for later use by the program that made the request.</p>
<p>Every kind of interrupt has an associated priority level. Lower-priority interrupts (like keyboard events) have to wait on higher-priority interrupts (like clock ticks or disk events). Unix is designed to give high priority to the kinds of events that need to be processed rapidly in order to keep the machine’s response smooth.</p>
<p>In your operating system’s boot-time messages, you may see references to IRQ numbers. You may be aware that one of the common ways to misconfigure hardware is to have two different devices try to use the same IRQ, without understanding exactly why.</p>
<p>Here’s the answer.  <strong>IRQ is short for “Interrupt Request”. The operating system needs to know at startup time which numbered interrupts each hardware device will use, so it can associate the proper handlers with each one. </strong> If two different devices try use the same IRQ, interrupts will sometimes get dispatched to the wrong handler. This will usually at least lock up the device, and can sometimes confuse the OS badly enough that it will flake out or crash.</p>
<h2 id="7-How-does-my-computer-do-several-things-at-once"><a href="#7-How-does-my-computer-do-several-things-at-once" class="headerlink" title="7. How does my computer do several things at once?"></a>7. How does my computer do several things at once?</h2><p>It doesn’t, actually. Computers can only do one task (or process) at a time. But a computer can change tasks very rapidly, and fool slow human beings into thinking it’s doing several things at once. This is called timesharing.</p>
<p>One of the kernel’s jobs is to manage timesharing. It has a part called the scheduler which keeps information inside itself about all the other (non-kernel) processes in your zoo. Every 1/60th of a second, a timer goes off in the kernel, generating a clock interrupt. The scheduler stops whatever process is currently running, suspends it in place, and hands control to another process.</p>
<p>1/60th of a second may not sound like a lot of time. But on today’s microprocessors it’s enough to run tens of thousands of machine instructions, which can do a great deal of work. So even if you have many processes, each one can accomplish quite a bit in each of its timeslices.</p>
<p>In practice, a program may not get its entire timeslice. If an interrupt comes in from an I/O device, the kernel effectively stops the current task, runs the interrupt handler, and then returns to the current task. A storm of high-priority interrupts can squeeze out normal processing; this misbehavior is called thrashing and is fortunately very hard to induce under modern Unixes.</p>
<p>In fact, the speed of programs is only very seldom limited by the amount of machine time they can get (there are a few exceptions to this rule, such as sound or 3-D graphics generation). Much more often, delays are caused when the program has to wait on data from a disk drive or network connection.</p>
<p>An operating system that can routinely support many simultaneous processes is called “multitasking”. The Unix family of operating systems was designed from the ground up for multitasking and is very good at it – much more effective than Windows or the Mac OS, which have had multitasking bolted into it as an afterthought and do it rather poorly. Efficient, reliable multitasking is a large part of what makes Linux superior for networking, communications, and Web service.</p>
<h2 id="8-How-does-my-computer-keep-processes-from-stepping-on-each-other"><a href="#8-How-does-my-computer-keep-processes-from-stepping-on-each-other" class="headerlink" title="8. How does my computer keep processes from stepping on each other?"></a>8. How does my computer keep processes from stepping on each other?</h2><p>The kernel’s scheduler takes care of dividing processes in time. Your operating system also has to divide them in space, so that processes can’t step on each others’ working memory. Even if you assume that all programs are trying to be cooperative, you don’t want a bug in one of them to be able to corrupt others. The things your operating system does to solve this problem are called memory management.</p>
<p>Each process in your zoo needs its own area of memory, as a place to run its code from and keep variables and results in. You can think of this set as consisting of a read-only code segment (containing the process’s instructions) and a writeable data segment (containing all the process’s variable storage). The data segment is truly unique to each process, but if two processes are running the same code Unix automatically arranges for them to share a single code segment as an efficiency measure.</p>
<p>8.1. Virtual memory: the simple version</p>
<p>Efficiency is important, because memory is expensive. Sometimes you don’t have enough to hold the entirety of all the programs the machine is running, especially if you are using a large program like an X server. To get around this, Unix uses a technique called virtual memory. It doesn’t try to hold all the code and data for a process in memory. Instead, it keeps around only a relatively small working set; the rest of the process’s state is left in a special swap space area on your hard disk.</p>
<p>Note that in the past, that “Sometimes” last paragraph ago was “Almost always” – the size of memory was typically small relative to the size of running programs, so swapping was frequent. Memory is far less expensive nowadays and even low-end machines have quite a lot of it. On modern single-user machines with 64MB of memory and up, it’s possible to run X and a typical mix of jobs without ever swapping after they’re initially loded into core.</p>
<p>8.2. Virtual memory: the detailed version</p>
<p>Actually, the last section oversimplified things a bit. Yes, programs see most of your memory as one big flat bank of addresses bigger than physical memory, and disk swapping is used to maintain that illusion. But your hardware actually has no fewer than five different kinds of memory in it, and the differences between them can matter a good deal when programs have to be tuned for maximum speed. To really understand what goes on in your machine, you should learn how all of them work.</p>
<p>The five kinds of memory are these: processor registers, internal (or on-chip) cache, external (or off-chip) cache, main memory, and disk. And the reason there are so many kinds is simple:  <strong>speed costs money</strong>. I have listed these kinds of memory in decreasing order of access time and increasing order of cost. Register memory is the fastest and most expensive and can be random-accessed about a billion times a second, while disk is the slowest and cheapest and can do about 100 random accesses a second.</p>
<p>Here’s a full list reflecting early-2000 speeds for a typical desktop machine. While speed and capacity will go up and prices will drop, you can expect these ratios to remain fairly constant – and it’s those ratios that shape the memory hierarchy.</p>
<p>Disk<br>Size: 13000MB    Accesses: 100KB/sec</p>
<p>Main memory<br>Size: 256MB    Accesses: 100M/sec</p>
<p>External cache<br>Size: 512KB    Accesses: 250M/sec</p>
<p>Internal Cache<br>Size: 32KB    Accesses: 500M/sec</p>
<p>Processor<br>Size: 28 bytes    Accesses: 1000M/sec</p>
<p>We can’t build everything out of the fastest kinds of memory. It would be way too expensive – and even if it weren’t, fast memory is volatile. That is, it loses its marbles when the power goes off. Thus, computers have to have hard disks or other kinds of non-volatile storage that retains data when the power goes off. And there’s a huge mismatch between the speed of processors and the speed of disks. The middle three levels of the memory hierarchy (internal cache, external cache, and main memory) basically exist to bridge that gap.</p>
<p>Linux and other Unixes have a feature called virtual memory. What this means is that the operating system behaves as though it has much more main memory than it actually does. Your actual physical main memory behaves like a set of windows or caches on a much larger “virtual” memory space, most of which at any given time is actually stored on disk in a special zone called the swap area. Out of sight of user programs, the OS is moving blocks of data (called “pages”) between memory and disk to maintain this illusion. The end result is that your virtual memory is much larger but not too much slower than real memory.</p>
<p>How much slower virtual memory is than physical depends on how well the operating system’s swapping algorithms match the way your programs use virtual memory. Fortunately, memory reads and writes that are close together in time also tend to cluster in memory space. This tendency is called locality, or more formally locality of reference – and it’s a good thing. If memory references jumped around virtual space at random, you’d typically have to do a disk read and write for each new reference and virtual memory would be as slow as a disk. But because programs do actually exhibit strong locality, your operating system can do relatively few swaps per reference.</p>
<p>It’s been found by experience that the most effective method for a broad class of memory-usage patterns is very simple; it’s called LRU or the “least recently used” algorithm. The virtual-memory system grabs disk blocks into its working set as it needs them. When it runs out of physical memory for the working set, it dumps the least-recently-used block. All Unixes, and most other virtual-memory operating systems, use minor variations on LRU.</p>
<p>Virtual memory is the first link in the bridge between disk and processor speeds. It’s explicitly managed by the OS. But there is still a major gap between the speed of physical main memory and the speed at which a processor can access its register memory. The external and internal caches address this, using a technique similar to virtual memory as I’ve described it.</p>
<p>Just as the physical main memory behaves like a set of windows or caches on the disk’s swap area, the external cache acts as windows on main memory. External cache is faster (250M accesses per sec, rather than 100M) and smaller. The hardware (specifically, your computer’s memory controller) does the LRU thing in the external cache on blocks of data fetched from the main memory. For historical reasons, the unit of cache swapping is called a “line” rather than a page.</p>
<p>But we’re not done. The internal cache gives us the final step-up in effective speed by caching portions of the external cache. It is faster and smaller yet – in fact, it lives right on the processor chip.</p>
<p>If you want to make your programs really fast, it’s useful to know these details. Your programs get faster when they have stronger locality, because that makes the caching work better. The easiest way to make programs fast is therefore to make them small. If a program isn’t slowed down by lots of disk I/O or waits on network events, it will usually run at the speed of the smallest cache that it will fit inside.</p>
<p>If you can’t make your whole program small, some effort to tune the speed-critical portions so they have stronger locality can pay off. Details on techniques for doing such tuning are beyond the scope of this tutorial; by the time you need them, you’ll be intimate enough with some compiler to figure out many of them yourself.</p>
<p>8.3. The Memory Management Unit</p>
<p>Even when you have enough physical core to avoid swapping, the part of the operating system called the memory manager still has important work to do. It has to make sure that programs can only alter their own data segments – that is, prevent erroneous or malicious code in one program from garbaging the data in another. To do this, it keeps a table of data and code segments. The table is updated whenever a process either requests more memory or releases memory (the latter usually when it exits).</p>
<p>This table is used to pass commands to a specialized part of the underlying hardware called an MMU or memory management unit. Modern processor chips have MMUs built right onto them. The MMU has the special ability to put fences around areas of memory, so an out-of-bound reference will be refused and cause a special interrupt to be raised.</p>
<p>If you ever see a Unix message that says “Segmentation fault”, “core dumped” or something similar, this is exactly what has happened; an attempt by the running program to access memory (core) outside its segment has raised a fatal interrupt. This indicates a bug in the program code; the core dump it leaves behind is diagnostic information intended to help a programmer track it down.</p>
<p>There is another aspect to protecting processes from each other besides segregating the memory they access. You also want to be able to control their file accesses so a buggy or malicious program can’t corrupt critical pieces of the system. This is why Unix has file permissions which we’ll discuss later.</p>
<h2 id="9-How-does-my-computer-store-things-in-memory"><a href="#9-How-does-my-computer-store-things-in-memory" class="headerlink" title="9. How does my computer store things in memory?"></a>9. How does my computer store things in memory?</h2><p>You probably know that everything on a computer is stored as strings of bits (binary digits; you can think of them as lots of little on-off switches). Here we’ll explain how those bits are used to represent the letters and numbers that your computer is crunching.</p>
<p>Before we can go into this, you need to understand about the word size of your computer. The word size is the computer’s preferred size for moving units of information around; technically it’s the width of your processor’s registers, which are the holding areas your processor uses to do arithmetic and logical calculations. When people write about computers having bit sizes (calling them, say, <code>32-bit&#39;&#39; or</code>64-bit’’ computers), this is what they mean.</p>
<p>Most computers (including 386, 486, and Pentium PCs) have a word size of 32 bits. The old 286 machines had a word size of 16. Old-style mainframes often had 36-bit words. A few processors (like the Alpha from what used to be DEC and is now Compaq) have 64-bit words. The 64-bit word will become more common over the next five years; Intel is planning to replace the Pentium series with a 64-bit chip called the `Itanium’.</p>
<p>The computer views your memory as a sequence of words numbered from zero up to some large value dependent on your memory size. That value is limited by your word size, which is why programs on older machines like 286s had to go through painful contortions to address large amounts of memory. I won’t describe them here; they still give older programmers nightmares.</p>
<p>9.1. Numbers</p>
<p>Integer numbers are represented as either words or pairs of words, depending on your processor’s word size. One 32-bit machine word is the most common integer representation.</p>
<p>Integer arithmetic is close to but not actually mathematical base-two. The low-order bit is 1, next 2, then 4 and so forth as in pure binary. But signed numbers are represented in twos-complement notation. The highest-order bit is a sign bit which makes the quantity negative, and every negative number can be obtained from the corresponding positive value by inverting all the bits and adding one. This is why integers on a 32-bit machine have the range -2^31 to 2^31 - 1 1 (where ^ is the `power’ operation, 2^3 = 8). That 32nd bit is being used for sign.</p>
<p>Some computer languages give you access to unsigned arithmetic which is straight base 2 with zero and positive numbers only.</p>
<p>Most processors and some languages can do operations in floating-point numbers (this capability is built into all recent processor chips). Floating-point numbers give you a much wider range of values than integers and let you express fractions. The ways in which this is done vary and are rather too complicated to discuss in detail here, but the general idea is much like so-called `scientific notation’, where one might write (say) 1.234 * 10^23; the encoding of the number is split into a mantissa (1.234) and the exponent part (23) for the power-of-ten multiplier (which means the number multiplied out would have 20 zeros on it, 23 minus the three decimal places).</p>
<p>9.2. Characters</p>
<p>Characters are normally represented as strings of seven bits each in an encoding called ASCII (American Standard Code for Information Interchange). On modern machines, each of the 128 ASCII characters is the low seven bits of an octet or 8-bit byte; octets are packed into memory words so that (for example) a six-character string only takes up two memory words. For an ASCII code chart, type `man 7 ascii’ at your Unix prompt.</p>
<p>The preceding paragraph was misleading in two ways. The minor one is that the term <code>octet&#39; is formally correct but seldom actually used; most people refer to an octet as byte and expect bytes to be eight bits long. Strictly speaking, the term</code>byte’ is more general; there used to be, for example, 36-bit machines with 9-bit bytes (though there probably never will be again).</p>
<p>The major one is that not all the world uses ASCII. In fact, much of the world can’t – ASCII, while fine for American English, lacks many accented and other special characters needed by users of other languages. Even British English has trouble with the lack of a pound-currency sign.</p>
<p>There have been several attempts to fix this problem. All use the extra high bit that ASCII doesn’t, making it the low half of a 256-character set. The most widely-used of these is the so-called `Latin-1’ character set (more formally called ISO 8859-1). This is the default character set for Linux, HTML, and X. Microsoft Windows uses a mutant version of Latin-1 that adds a bunch of characters such as right and left double quotes in places proper Latin-1 leaves unassigned for historical reasons (for a scathing account of the trouble this causes, see the demoroniser page).</p>
<p>Latin-1 handles western European languages, including English, French, German, Spanish, Italian, Dutch, Norwegian, Swedish, Danish. However, this isn’t good enough either, and as a result there is a whole series of Latin-2 through -9 character sets to handle things like Greek, Arabic, Hebrew, Esperanto, and Serbo-Croatian. For details, see the ISO alphabet soup page.</p>
<p>The ultimate solution is a huge standard called Unicode (and its identical twin ISO/IEC 10646-1:1993). Unicode is identical to Latin-1 in its lowest 256 slots. Above these in 16-bit space it includes Greek, Cyrillic, Armenian, Hebrew, Arabic, Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada, Malayalam, Thai, Lao, Georgian, Tibetan, Japanese Kana, the complete set of modern Korean Hangul, and a unified set of Chinese/Japanese/Korean (CJK) ideographs. For details, see the Unicode Home Page.</p>
<h2 id="10-How-does-my-computer-store-things-on-disk"><a href="#10-How-does-my-computer-store-things-on-disk" class="headerlink" title="10. How does my computer store things on disk?"></a>10. How does my computer store things on disk?</h2><p>When you look at a hard disk under Unix, you see a tree of named directories and files. Normally you won’t need to look any deeper than that, but it does become useful to know what’s going on underneath if you have a disk crash and need to try to salvage files. Unfortunately, there’s no good way to describe disk organization from the file level downwards, so I’ll have to describe it from the hardware up.</p>
<p>10.1. Low-level disk and file system structure</p>
<p>The surface area of your disk, where it stores data, is divided up something like a dartboard – into circular tracks which are then pie-sliced into sectors. Because tracks near the outer edge have more area than those close to the spindle at the center of the disk, the outer tracks have more sector slices in them than the inner ones. Each sector (or disk block) has the same size, which under modern Unixes is generally 1 binary K (1024 8-bit words). <strong>Each disk block has a unique address or disk block number.</strong></p>
<p>Unix divides the disk into disk partitions. Each partition is a continuous span of blocks that’s used separately from any other partition, either as a file system or as swap space. The original reasons for partitions had to do with crash recovery in a world of much slower and more error-prone disks; the boundaries between them reduce the fraction of your disk likely to become inaccessible or corrupted by a random bad spot on the disk. Nowadays, it’s more important that partitions can be declared read-only (preventing an intruder from modifying critical system files) or shared over a network through various means we won’t discuss here. <strong>The lowest-numbered partition on a disk is often treated specially, as a boot partition where you can put a kernel to be booted.</strong></p>
<p>Each partition is either swap space (used to implement virtual memory) or a file system used to hold files. <strong>Swap-space partitions are just treated as a linear sequence of blocks. File systems, on the other hand, need a way to map file names to sequences of disk blocks.</strong> Because files grow, shrink, and change over time, a file’s data blocks will not be a linear sequence but may be scattered all over its partition (from wherever the operating system can find a free block when it needs one). This scattering effect is called fragmentation.</p>
<p>10.2. File names and directories</p>
<p>Within each file system, the mapping from names to blocks is handled through a structure called an i-node. There’s a pool of these things near the ``bottom’’ (lowest-numbered blocks) of each file system (the very lowest ones are used for housekeeping and labeling purposes we won’t describe here). <strong>Each i-node describes one file. File data blocks (including directories) live above the i-nodes (in higher-numbered blocks).</strong></p>
<p>Every i-node contains a list of the disk block numbers in the file it describes. (Actually this is a half-truth, only correct for small files, but the rest of the details aren’t important here.) Note that the i-node does not contain the name of the file.</p>
<p>Names of files live in directory structures. <strong> A directory structure just maps names to i-node numbers. This is why, in Unix, a file can have multiple true names (or hard links); they’re just multiple directory entries that happen to point to the same i-node.</strong></p>
<p>10.3. Mount points</p>
<p>In the simplest case, your entire Unix file system lives in just one disk partition. While you’ll see this arrangement on some small personal Unix systems, it’s unusual. More typical is for it to be spread across several disk partitions, possibly on different physical disks. So, for example, your system may have one small partition where the kernel lives, a slightly larger one where OS utilities live, and a much bigger one where user home directories live.</p>
<p>The only partition you’ll have access to immediately after system boot is your root partition, which is (almost always) the one you booted from. It holds the root directory of the file system, the top node from which everything else hangs.</p>
<p>The other partitions in the system have to be attached to this root in order for your entire, multiple-partition file system to be accessible. About midway through the boot process, your Unix will make these non-root partitions accessible. It will mount each one onto a directory on the root partition.</p>
<p>For example, if you have a Unix directory called `/usr’, it is probably a mount point to a partition that contains many programs installed with your Unix but not required during initial boot.</p>
<p>10.4. How a file gets looked up</p>
<h2 id="Now-we-can-look-at-the-file-system-from-the-top-down-When-you-open-a-file-such-as-say-home-esr-WWW-ldp-fundamentals-sgml-here-is-what-happens"><a href="#Now-we-can-look-at-the-file-system-from-the-top-down-When-you-open-a-file-such-as-say-home-esr-WWW-ldp-fundamentals-sgml-here-is-what-happens" class="headerlink" title="Now we can look at the file system from the top down. When you open a file (such as, say, /home/esr/WWW/ldp/fundamentals.sgml) here is what happens:"></a>Now we can look at the file system from the top down. When you open a file (such as, say, /home/esr/WWW/ldp/fundamentals.sgml) here is what happens:</h2><p>Your kernel starts at the root of your Unix file system (in the root partition). It looks for a directory there called <code>home&#39;. Usually</code>home’ is a mount point to a large user partition elsewhere, so it will go there. In the top-level directory structure of that user partition, it will look for a entry called <code>esr&#39; and extract an i-node number. It will go to that i-node, notice that its associated file data blocks are a directory structure, and look up</code>WWW’. Extracting that i-node, it will go to the corresponding subdirectory and look up <code>ldp&#39;. That will take it to yet another directory i-node. Opening that one, it will find an i-node number for</code>fundamentals.sgml’. That i-node is not a directory, but instead holds the list of disk blocks associated with the file.##</p>
<p>10.5. File ownership, permissions and security</p>
<p>To keep programs from accidentally or maliciously stepping on data they shouldn’t, Unix has permission features. These were originally designed to support timesharing by protecting multiple users on the same machine from each other, back in the days when Unix ran mainly on expensive shared minicomputers.</p>
<p>In order to understand file permissions, you need to recall the description of users and groups in the section What happens when you log in?. <strong>Each file has an owning user and an owning group. </strong>These are initially those of the file’s creator; they can be changed with the programs chown(1) and chgrp(1).</p>
<p>The basic permissions that can be associated with a file are <code>read&#39; (permission to read data from it),</code>write’ (permission to modify it) and <code>execute&#39; (permission to run it as a program). Each file has three sets of permissions; one for its owning user, one for any user in its owning group, and one for everyone else. The</code>privileges’ you get when you log in are just the ability to do read, write, and execute on those files for which the permission bits match your user ID or one of the groups you are in, or files that have been made accessible to the world.</p>
<p>To see how these may interact and how Unix displays them, let’s look at some file listings on a hypothetical Unix system. Here’s one:</p>
<p>snark:~$ ls -l notes<br>-rw-r–r–   1 esr      users         2993 Jun 17 11:00 notes<br>This is an ordinary data file. The listing tells us that it’s owned by the user <code>esr&#39; and was created with the owning group</code>users’. Probably the machine we’re on puts every ordinary user in this group by default; other groups you commonly see on timesharing machines are <code>staff&#39;,</code>admin’, or `wheel’ (for obvious reasons, groups are not very important on single-user workstations or PCs). Your Unix may use a different default group, perhaps one named after your user ID.</p>
<p>The string <code>-rw-r--r--&#39; represents the permission bits for the file. The very first dash is the position for the directory bit; it would show</code>d’ if the file were a directory. After that, the first three places are user permissions, the second three group permissions, and the third are permissions for others (often called <code>world&#39; permissions). On this file, the owning user</code>esr’ may read or write the file, other people in the `users’ group may read it, and everybody else in the world may read it. This is a pretty typical set of permissions for an ordinary data file.</p>
<p>Now let’s look at a file with very different permissions. This file is GCC, the GNU C compiler.</p>
<p>snark:~$ ls -l /usr/bin/gcc<br>-rwxr-xr-x   3 root     bin         64796 Mar 21 16:41 /usr/bin/gcc<br>This file belongs to a user called <code>root&#39; and a group called</code>bin’; it can be written (modified) only by root, but read or executed by anyone. This is a typical ownership and set of permissions for a pre-installed system command. <strong>The <code>bin&#39; group exists on some Unixes to group together system commands (the name is a historical relic, short for</code>binary’). </strong> Your Unix might use a <code>root&#39; group instead (not quite the same as the</code>root’ user!).</p>
<p><strong>The `root’ user is the conventional name for numeric user ID 0, a special, privileged account that can override all privileges.</strong> Root access is useful but dangerous; a typing mistake while you’re logged in as root can clobber critical system files that the same command executed from an ordinary user account could not touch.</p>
<p>Because the root account is so powerful, access to it should be guarded very carefully. Your root password is the single most critical piece of security information on your system, and it is what any crackers and intruders who ever come after you will be trying to get.</p>
<p>About passwords: Don’t write them down – and don’t pick a passwords that can easily be guessed, like the first name of your girlfriend/boyfriend/spouse. This is an astonishingly common bad practice that helps crackers no end. In general, don’t pick any word in the dictionary; there are programs called dictionary crackers that look for likely passwords by running through word lists of common choices. A good technique is to pick a combination consisting of a word, a digit, and another word, such as <code>shark6cider&#39; or</code>jump3joy’; that will make the search space too large for a dictionary cracker. Don’t use these examples, though – crackers might expect that after reading this document and put them in their dictionaries.</p>
<p>Now let’s look at a third case:</p>
<p>snark:~$ ls -ld ~<br>drwxr-xr-x  89 esr      users          9216 Jun 27 11:29 /home2/esr<br>snark:~$<br>This file is a directory (note the `d’ in the first permissions slot). We see that it can be written only by esr, but read and executed by anybody else.</p>
<p>Read permission gives you the ability to list the directory – that is, to see the names of files and directories it contains. Write permission gives you the ability to create and delete files in the directory. If you remember that the directory includes a list of the names of the files and subdirectories it contains, these rules will make sense.</p>
<p>Execute permission on a directory means you can get through the directory to open the files and directories below it. In effect, it gives you permission to access the i-nodes in the directory. A directory with execute completely turned off would be useless.</p>
<p>Occasionally you’ll see a directory that is world-executable but not world-readable; this means a random user can get to files and directories beneath it, but only by knowing their exact names (the directory cannot be listed).</p>
<p><strong>It’s important to remember that read, write, or execute permission on a directory is independent of the permissions on the files and directories beneath. In particular, write access on a directory means you can create new files or delete existing files there, but does not automatically give you write access to existing files.</strong></p>
<p>Finally, let’s look at the permissions of the login program itself.</p>
<p>snark:~$ ls -l /bin/login<br>-rwsr-xr-x   1 root     bin         20164 Apr 17 12:57 /bin/login<br>This has the permissions we’d expect for a system command – except for that ‘s’ where the owner-execute bit ought to be. This is the visible manifestation of a special permission called the `set-user-id’ or setuid bit.</p>
<p>The setuid bit is normally attached to programs that need to give ordinary users the privileges of root, but in a controlled way. When it is set on an executable program, you get the privileges of the owner of that program file while the program is running on your behalf, whether or not they match your own.</p>
<p>Like the root account itself, setuid programs are useful but dangerous. Anyone who can subvert or modify a setuid program owned by root can use it to spawn a shell with root privileges. For this reason, opening a file to write it automatically turns off its setuid bit on most Unixes. Many attacks on Unix security try to exploit bugs in setuid programs in order to subvert them. Security-conscious system administrators are therefore extra-careful about these programs and reluctant to install new ones.</p>
<p>There are a couple of important details we glossed over when discussing permissions above; namely, how the owning group and permissions are assigned when a file or directory is first created. The group is an issue because users can be members of multiple groups, but one of them (specified in the user’s /etc/passwd entry) is the user’s default group and will normally own files created by the user.</p>
<p>The story with initial permission bits is a little more complicated. A program that creates a file will normally specify the permissions it is to start with. But these will be modified by a variable in the user’s environment called the umask. The umask specifies which permission bits to turn off when creating a file; the most common value, and the default on most systems, is ——-w- or 002, which turns off the world-write bit. See the documentation of the umask command on your shell’s manual page for details.</p>
<p>Initial directory group is also a bit complicated. On some Unixes a new directory gets the default group of the creating user (this in the System V convention); on others, it gets the owning group of the parent directory in which it’s created (this is the BSD convention). On some modern Unixes, including Linux, the latter behavior can be selected by setting the set-group-ID on the directory (chmod g+s).</p>
<p>10.6. How things can go wrong</p>
<p>Earlier it was hinted that file systems can be fragile things. Now we know that to get to a file you have to hopscotch through what may be an arbitrarily long chain of directory and i-node references. Now suppose your hard disk develops a bad spot?</p>
<p>If you’re lucky, it will only trash some file data. If you’re unlucky, it could corrupt a directory structure or i-node number and leave an entire subtree of your system hanging in limbo – or, worse, result in a corrupted structure that points multiple ways at the same disk block or i-node. Such corruption can be spread by normal file operations, trashing data that was not in the original bad spot.</p>
<p>Fortunately, this kind of contingency has become quite uncommon as disk hardware has become more reliable. Still, it means that your Unix will want to integrity-check the file system periodically to make sure nothing is amiss. Modern Unixes do a fast integrity check on each partition at boot time, just before mounting it. Every few reboots they’ll do a much more thorough check that takes a few minutes longer.</p>
<p>If all of this sounds like Unix is terribly complex and failure-prone, it may be reassuring to know that these boot-time checks typically catch and correct normal problems before they become really disastrous. Other operating systems don’t have these facilities, which speeds up booting a bit but can leave you much more seriously screwed when attempting to recover by hand (and that’s assuming you have a copy of Norton Utilities or whatever in the first place…).</p>
<p>One of the trends in current Unix designs is journalling file systems. These arrange traffic to the disk so that it’s guaranteed to be in a consistent state that can be recovered when the system comes back up. This will speed up the boot-time integrity check a lot.</p>
<h2 id="11-How-do-computer-languages-work"><a href="#11-How-do-computer-languages-work" class="headerlink" title="11. How do computer languages work?"></a>11. How do computer languages work?</h2><p>We’ve already discussed how programs are run. Every program ultimately has to execute as a stream of bytes that are instructions in your computer’s machine language. But human beings don’t deal with machine language very well; doing so has become a rare, black art even among hackers.</p>
<p>Almost all Unix code except a small amount of direct hardware-interface support in the kernel itself is nowadays written in a high-level language. (<strong>The <code>high-level&#39; in this term is a historical relic meant to distinguish these from</code>low-level’ assembler languages, which are basically thin wrappers around machine code.</strong>)</p>
<p>There are several different kinds of high-level languages. In order to talk about these, you’ll find it useful to bear in mind that the source code of a program (the human-created, editable version) has to go through some kind of translation into machine code that the machine can actually run.</p>
<p>11.1. Compiled languages</p>
<p>The most conventional kind of language is a compiled language. Compiled languages get translated into runnable files of binary machine code by a special program called (logically enough) a compiler. Once the binary has been generated, you can run it directly without looking at the source code again. (Most software is delivered as compiled binaries made from code you don’t see.)</p>
<p>Compiled languages tend to give excellent performance and have the most complete access to the OS, but also to be difficult to program in.</p>
<p>C, the language in which Unix itself is written, is by far the most important of these (with its variant C++). FORTRAN is another compiled language still used among engineers and scientists but years older and much more primitive. In the Unix world no other compiled languages are in mainstream use. Outside it, COBOL is very widely used for financial and business software.</p>
<p>There used to be many other compiler languages, but most of them have either gone extinct or are strictly research tools. If you are a new Unix developer using a compiled language, it is overwhelmingly likely to be C or C++.</p>
<p>11.2. Interpreted languages</p>
<p>An interpreted language depends on an interpreter program that reads the source code and translates it on the fly into computations and system calls. The source has to be re-interpreted (and the interpreter present) each time the code is executed.</p>
<p>Interpreted languages tend to be slower than compiled languages, and often have limited access to the underlying operating system and hardware. On the other hand, they tend to be easier to program and more forgiving of coding errors than compiled languages.</p>
<p>Many Unix utilities, including the shell and bc(1) and sed(1) and awk(1), are effectively small interpreted languages. BASICs are usually interpreted. So is Tcl. Historically, the most important interpretive language has been LISP (a major improvement over most of its successors). Today, Unix shells and the Lisp that lives inside the Emacs editor are probably the most important pure interpreted languages.</p>
<p>11.3. P-code languages</p>
<p>Since 1990 a kind of hybrid language that uses both compilation and interpretation has become increasingly important. P-code languages are like compiled languages in that the source is translated to a compact binary form which is what you actually execute, but that form is not machine code. Instead it’s pseudocode (or p-code), which is usually a lot simpler but more powerful than a real machine language. When you run the program, you interpret the p-code.</p>
<p>P-code can run nearly as fast as a compiled binary (p-code interpreters can be made quite simple, small and speedy). But p-code languages can keep the flexibility and power of a good interpreter.</p>
<p>Important p-code languages include Python, Perl, and Java.</p>
<h2 id="12-How-does-the-Internet-work"><a href="#12-How-does-the-Internet-work" class="headerlink" title="12. How does the Internet work?"></a>12. How does the Internet work?</h2><p>To help you understand how the Internet works, we’ll look at the things that happen when you do a typical Internet operation – pointing a browser at the front page of this document at its home on the Web at the Linux Documentation Project. This document is</p>
<p><a href="http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html" target="_blank" rel="external">http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html</a><br>which means it lives in the file LDP/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html under the World Wide Web export directory of the host www.linuxdoc.org.</p>
<p>12.1. Names and locations</p>
<p>The first thing your browser has to do is to establish a network connection to the machine where the document lives. To do that, it first has to find the network location of the host www.linuxdoc.org (<code>host&#39; is short for</code>host machine’ or <code>network host&#39;; www.linuxdoc.org is a typical hostname). The corresponding location is actually a number called an IP address (we&#39;ll explain the</code>IP’ part of this term later).</p>
<p>To do this, your browser queries a program called a name server. The name server may live on your machine, but it’s more likely to run on a service machine that yours talks to. When you sign up with an ISP, part of your setup procedure will almost certainly involve telling your Internet software the IP address of a nameserver on the ISP’s network.</p>
<p>The name servers on different machines talk to each other, exchanging and keeping up to date all the information needed to resolve hostnames (map them to IP addresses). Your nameserver may query three or four different sites across the network in the process of resolving www.linuxdoc.org, but this usually happens very quickly (as in less than a second). We’ll look at how nameservers detail in the next section.</p>
<p>The nameserver will tell your browser that www.linuxdoc.org’s IP address is 152.19.254.81; knowing this, your machine will be able to exchange bits with www.linuxdoc.org directly.</p>
<p>12.2. The Domain Name System</p>
<p>The whole network of programs and databases that cooperates to translate hostnames to IP addresses is called <code>DNS&#39; (Domain Name System). When you see references to a</code>DNS server’, that means what we just called a nameserver. Now I’ll explain how the overall system works.</p>
<p>Internet hostnames are composed of parts separated by dots. A domain is a collection of machines that share a common name suffix. Domains can live inside other domains. For example, the machine www.linuxdoc.org lives in the .linuxdoc.org subdomain of the .org domain.</p>
<p>Each domain is defined by an authoritative name server that knows the IP addresses of the other machines in the domain. The authoritative (or <code>primary&#39;) name server may have backups in case it goes down; if you see references to a secondary name server or (</code>secondary DNS’) it’s talking about one of those. These secondaries typically refresh their information from their primaries every few hours, so a change made to the hostname-to-IP mapping on the primary will automatically be propagated.</p>
<p>Now here’s the important part. The nameservers for a domain do not have to know the locations of all the machines in other domains (including their own subdomains); they only have to know the location of the nameservers. In our example, the authoritative name server for the .org domain knows the IP address of the nameserver for .linuxdoc.org, but not the address of all the other machines in linuxdoc.org.</p>
<p>The domains in the DNS system are arranged like a big inverted tree. At the top are the root servers. Everybody knows the IP addresses of the root servers; they’re wired into your DNS software. The root servers know the IP addresses of the nameservers for the top-level domains like .com and .org, but not the addresses of machines inside those domains. <strong>Each top-level domain server knows where the nameservers for the domains directly beneath it are, and so forth.</strong></p>
<p>DNS is carefully designed so that each machine can get away with the minimum amount of knowledge it needs to have about the shape of the tree, and local changes to subtrees can be made simply by changing one authoritative server’s database of name-to-IP-address mappings.</p>
<p>When you query for the IP address of www.linuxdoc.org, what actually happens is this: First, your nameserver asks a root server to tell it where it can find a nameserver for .org. Once it knows that, it then asks the .org server to tell it the IP address of a .linuxdoc.org nameserver. Once it has that, it asks the .linuxdoc.org nameserver to tell it the address of the host www.linuxdoc.org.</p>
<p>Most of the time, your nameserver doesn’t actually have to work that hard. Nameservers do a lot of cacheing; when yours resolves a hostname, it keeps the association with the resulting IP address around in memory for a while. This is why, when you surf to a new website, you’ll usually only see a message from your browser about “Looking up” the host for the first page you fetch. Eventually the name-to-address mapping expires and your DNS has to re-query — this is important so you don’t have invalid information hanging around forever when a hostname changes addresses. Your cached IP address for a site is also thrown out if the host is unreachable.</p>
<p>12.3. Packets and routers</p>
<p>What the browser wants to do is send a command to the Web server on www.linuxdoc.org that looks like this:</p>
<p>GET /LDP/HOWTO/Fundamentals.html HTTP/1.0<br>Here’s how that happens. The command is made into a packet, a block of bits like a telegram that is wrapped with three important things; the source address (the IP address of your machine), the destination address (152.19.254.81), and a service number or port number (80, in this case) that indicates that it’s a World Wide Web request.</p>
<p>Your machine then ships the packet down the wire (your connection to your ISP, or local network) until it gets to a specialized machine called a router. The router has a map of the Internet in its memory – not always a complete one, but one that completely describes your network neighborhood and knows how to get to the routers for other neighborhoods on the Internet.</p>
<p>Your packet may pass through several routers on the way to its destination. Routers are smart. They watch how long it takes for other routers to acknowledge having received a packet. They also use that information to direct traffic over fast links. They use it to notice when another routers (or a cable) have dropped off the network, and compensate if possible by finding another route.</p>
<p>There’s an urban legend that the Internet was designed to survive nuclear war. This is not true, but the Internet’s design is extremely good at getting reliable performance out of flaky hardware in an uncertain world. This is directly due to the fact that its intelligence is distributed through thousands of routers rather than concentrated in a few massive and vulnerable switches (like the phone network). This means that failures tend to be well localized and the network can route around them.</p>
<p>Once your packet gets to its destination machine, that machine uses the service number to feed the packet to the web server. The web server can tell where to reply to by looking at the command packet’s source IP address. When the web server returns this document, it will be broken up into a number of packets. The size of the packets will vary according to the transmission media in the network and the type of service.</p>
<p>12.4. TCP and IP</p>
<p>To understand how multiple-packet transmissions are handled, you need to know that the Internet actually uses two protocols, stacked one on top of the other.</p>
<p>The lower level, IP (Internet Protocol), is responsible for labeling individual packets with the source address and destination address of two computers exchanging information over a network. For example, when you access <a href="http://www.linuxdoc.org" target="_blank" rel="external">http://www.linuxdoc.org</a>, the packets you send will have your computer’s IP address, such as 192.168.1.101, and the IP address of the www.linuxdoc.org computer, 152.2.210.81. These addresses work in much the same way that your home address works when someone sends you a letter. The post office can read the address and determine where you are and how best to route the letter to you, much like a router does for Internet traffic.</p>
<p>The upper level, TCP (Transmission Control Protocol), gives you reliability. When two machines negotiate a TCP connection (which they do using IP), the receiver knows to send acknowledgements of the packets it sees back to the sender. If the sender doesn’t see an acknowledgement for a packet within some timeout period, it resends that packet. Furthermore, the sender gives each TCP packet a sequence number, which the receiver can use you reassemble packets in case they show up out of order. (This can easily happen if network links go up or down during a connection.)</p>
<p>TCP/IP packets also contain a checksum to enable detection of data corrupted by bad links. (The checksum is computed from the rest of the packet in such a way that if the either the rest of the packet or the checksum is corrupted, redoing the computation and comparing is very likely to indicate an error.) So, from the point of view of anyone using TCP/IP and nameservers, it looks like a reliable way to pass streams of bytes between hostname/service-number pairs. People who write network protocols almost never have to think about all the packetizing, packet reassembly, error checking, checksumming, and retransmission that goes on below that level.</p>
<p>12.5. HTTP, an application protocol</p>
<p>Now let’s get back to our example. Web browsers and servers speak an application protocol that runs on top of TCP/IP, using it simply as a way to pass strings of bytes back and forth. This protocol is called HTTP (Hyper-Text Transfer Protocol) and we’ve already seen one command in it – the GET shown above.</p>
<p>When the GET command goes to www.linuxdoc.org’s webserver with service number 80, it will be dispatched to a server daemon listening on port 80. Most Internet services are implemented by server daemons that do nothing but wait on ports, watching for and executing incoming commands.</p>
<p>If the design of the Internet has one overall rule, it’s that all the parts should be as simple and human-accessible as possible. HTTP, and its relatives (like the Simple Mail Transfer Protocol, SMTP, that is used to move electronic mail between hosts) tend to use simple printable-text commands that end with a carriage-return/line feed.</p>
<p>This is marginally inefficient; in some circumstances you could get more speed by using a tightly-coded binary protocol. But experience has shown that the benefits of having commands be easy for human beings to describe and understand outweigh any marginal gain in efficiency that you might get at the cost of making things tricky and opaque.</p>
<p>Therefore, what the server daemon ships back to you via TCP/IP is also text. The beginning of the response will look something like this (a few headers have been suppressed):</p>
<p>HTTP/1.1 200 OK<br>Date: Sat, 10 Oct 1998 18:43:35 GMT<br>Server: Apache/1.2.6 Red Hat<br>Last-Modified: Thu, 27 Aug 1998 17:55:15 GMT<br>Content-Length: 2982<br>Content-Type: text/html<br>These headers will be followed by a blank line and the text of the web page (after which the connection is dropped). Your browser just displays that page. The headers tell it how (in particular, the Content-Type header tells it the returned data is really HTML).</p>
<ol>
<li>To Learn More</li>
</ol>
<p>There is a Reading List HOWTO that lists books you can read to learn more about the topics we have touched on here. You might also want to read the How To Become A Hacker document.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.faqs.org/docs/Linux-HOWTO/Unix-and-Internet-Fundamentals-HOWTO.html&quot;&gt;Eric Raymond&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/eric-raymond.jpg&quot; alt=&quot;Eric Raymond&quot;&gt;&lt;/p&gt;
&lt;p&gt;This document describes the working basics of PC-class computers, Unix-like operating systems, and the Internet in non-technical language.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Unix" scheme="http://ipcreator.me/tags/Unix/"/>
    
      <category term="Internet" scheme="http://ipcreator.me/tags/Internet/"/>
    
  </entry>
  
  <entry>
    <title>如何成为一名黑客</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/how-to-become-a-hacker/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/how-to-become-a-hacker/</id>
    <published>2017-01-20T12:31:06.000Z</published>
    <updated>2017-02-15T13:04:57.169Z</updated>
    
    <content type="html"><![CDATA[<p>如何成为一名黑客<br>——Eric S. Raymond <a href="&#109;&#x61;&#x69;&#x6c;&#116;&#x6f;&#58;&#x65;&#x73;&#x72;&#x40;&#x74;&#x68;&#121;&#114;&#x73;&#x75;&#x73;&#46;&#x63;&#x6f;&#109;">&#x65;&#x73;&#x72;&#x40;&#x74;&#x68;&#121;&#114;&#x73;&#x75;&#x73;&#46;&#x63;&#x6f;&#109;</a><br><a href="http://translations.readthedocs.io/en/latest/hacker_howto.html" target="_blank" rel="external">Wang Dingwei <a href="&#x6d;&#x61;&#105;&#108;&#116;&#x6f;&#58;&#x77;&#x61;&#x6e;&#x67;&#100;&#105;&#x6e;&#x67;&#x77;&#x65;&#x69;&#x38;&#50;&#64;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;">&#x77;&#x61;&#x6e;&#x67;&#100;&#105;&#x6e;&#x67;&#x77;&#x65;&#x69;&#x38;&#50;&#64;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;</a></a> 基于 Barret 的翻译更正而成。转载请注明出处。</p>
<p>目录</p>
<ol>
<li>为什么会有这份文档？</li>
<li>什么是黑客？</li>
<li>黑客的态度</li>
<li>黑客的基本技能</li>
<li>提高自己在黑客圈中的地位</li>
<li>黑客和书呆子(Nerd)的联系</li>
<li>向黑客的格调靠拢</li>
<li>关于黑客、开源、以及自由软件的历史</li>
<li>其它资源</li>
<li>FAQ（常见问题解答）</li>
</ol>
<a id="more"></a>
<h1 id="为什么会有这份文档？"><a href="#为什么会有这份文档？" class="headerlink" title="为什么会有这份文档？"></a>为什么会有这份文档？</h1><p>作为 Jargon File（译注：黑客行话大全）的编辑和几份其他类似性质知名文章的作者，我经常收到充满热情的网络新手的电子邮件询问：“我如何才能成为一名出色的 Hacker？”早在 1996 年，我注意到网上似乎没有任何的 FAQ 或者 Web 形式的文档提到及这个至关重要的问题，因此我写了这份文档。现在，很多 Hacker 都认为这是一篇权威性文档，那我也姑且这么认为吧。不过，我不认为我是这个话题的绝对权威；如果你不喜欢这篇文档，你也可以自己写一份。</p>
<p>如果你读到的是这份文档的离线拷贝，你可以在 <a href="http://catb.org/~esr/faqs/hacker-howto.html" target="_blank" rel="external">http://catb.org/~esr/faqs/hacker-howto.html</a> 读到最新版本。</p>
<p>注意：文档的结尾有一份 FAQ（常见问题解答）。如果你想通过邮件询问我关于这份文档的问题，请先读这份 FAQ 看看能否找到答案——一遍不行就读两遍。</p>
<p>目前这份文档有很多翻译版本：阿拉伯语、白俄罗斯语、丹麦语、 荷兰语 、爱沙尼亚语、德语 、希腊语、意大利语 、希伯来语、 挪威语 、葡萄牙语（巴西）、 罗马尼亚语 、西班牙语 、土耳其语、瑞典语 。注意由于这份文档时有修正，所以以上翻译版本可能有不同程度的过时。</p>
<p>装饰本文的“五点九宫格”图像被称作“glider”，在一种叫做 Life 的数学模型中，这个简单的样本有一些异乎寻常的属性，多年以来 Hacker 们都为此着迷。我认为这个图像是一个很好的黑客徽标：它显得抽象而且神秘，而且像是一扇大门，通向一个截然不同的有其内在逻辑的世界。你可以阅读更多关于 Glider 徽标 的内容。</p>
<p><img src="http://catb.org/~esr/faqs/glider.png" alt=""></p>
<h1 id="什么是黑客？"><a href="#什么是黑客？" class="headerlink" title="什么是黑客？"></a>什么是黑客？</h1><p>Jargon File 讲了一堆关于“hacker”这个词的定义，大部分是关于“技术高超”、“热衷解决问题”、以及“超越极限”的内容。但如果你只想知道如何成为一名黑客的话，真正重要的只有两条。</p>
<p>这可以追溯到几十年前，那时候第一代分时微型计算机才刚刚诞生, 而 ARPAnet 的实验也才刚展开。那时的编程专家和组网高手建立了一个具有共享性质的文化社群， “hacker” 这个名词就是其中的成员创造的。<strong>黑客们建立了互联网，黑客们让 Unix 操作系统演化到现在的模样，黑客们经营着 Usenet，黑客们让万维网运转起来。如果你是这个文化的一部分，如果你对这种文化有所贡献，而且这个社群的其它成员也认识你并称你为 hacker，那么你就是一名黑客。</strong></p>
<p>黑客的思维方式并不仅仅局限在软件黑客的文化圈内。也有人用黑客态度对待其它事情，如电子和音乐方面——其实你可以在任何最高级别的科学和艺术活动中发现它的身影。软件黑客对这些领域的践行者尊重有加，并把他们也称作黑客——有人宣称黑客天性是绝对独立于他们工作的特定领域的。但在这份文档中，我们将集中书写在软件黑客的技术和态度，以及发明了“黑客”一词的、以共享为特征的文化传统。</p>
<p>有另外一群人大声嚷嚷着自己是黑客，但他们根本不是。他们主要由青少年男性构成，是一些蓄意破坏计算机和电话系统的人。真正的黑客把这些人叫做 <strong>“骇客”(cracker)</strong>，并不屑与之为伍。黑客们通常认为他们是一群懒散、没有责任心、而且不是很聪明的人。会通过热接线发动汽车并不意味着你是一个汽车工程师。一样的道理，会破坏安全也不意味着你是一名黑客，不幸的是，很多记者和作家往往错把“骇客”当成黑客；这种做法一直使真正的黑客感到恼火。</p>
<p>根本的区别是：<strong>黑客搞建设，骇客搞破坏。</strong></p>
<p>如果你想成为一名黑客，请接着读下去。如果你想做一个骇客，就去读 alt.2600 新闻组吧，顺便准备好去蹲个五到十年的监狱，而且最终你会意识到你并不像自己想象的那么聪明。</p>
<p>关于骇客，我能说的只有这些。</p>
<h1 id="黑客的态度"><a href="#黑客的态度" class="headerlink" title="黑客的态度"></a>黑客的态度</h1><ol>
<li>这个世界充满了令人着迷的问题等着我们解决。</li>
<li>一个问题不应该被解决两次。</li>
<li>无聊和乏味的工作是罪恶。</li>
<li>崇尚自由。</li>
<li>态度不能替代能力。</li>
</ol>
<p><strong>黑客们解决问题，建设事物，同时他们信仰自由和无私的双向帮助。</strong> 要想作为一名黑客被社群认同，你需要体现出自己已经具备了这种态度。而要体现出这种态度，你就得真正相信和赞同这种态度。</p>
<p>但是，如果你认为培养黑客态度只是进入黑客文化圈的敲门砖，那就大错特错了。这种态度将有助于有助于你的学习，并且能为你提供源源不断的动力，所以它对你而言是至关重要的。<strong>和所有创造性的艺术一样，成为大师的最有效方法，就是模仿大师的精神——智力上的模仿还不够，还要从感情上进行模仿。</strong></p>
<p>或者正如下面这首现代的禅诗讲的：</p>
<p>修行之道：</p>
<ul>
<li>关注大师的言行，</li>
<li>跟随大师的举动，</li>
<li>和大师一并修行，</li>
<li>领会大师的意境，</li>
<li>成为真正的大师。</li>
</ul>
<p>所以，如果你想成为一名黑客，反复读下面的事情直至你相信它们为止：</p>
<h2 id="1-这个世界充满了令人着迷的问题等着我们解决。"><a href="#1-这个世界充满了令人着迷的问题等着我们解决。" class="headerlink" title="1. 这个世界充满了令人着迷的问题等着我们解决。"></a>1. 这个世界充满了令人着迷的问题等着我们解决。</h2><p>做一名黑客会有很多乐趣，但是这些乐趣需要付出很多努力才能获得。这些努力需要动力。成功的运动员在表演和超越自我极限的时候获得身体上的愉悦，并把这种愉悦作为自己的动力。同样，为了成为一名黑客，你要从 <strong>解决问题、磨练技术，以及锻炼智力中得到基本的享受。</strong></p>
<p>如果你不是天性如此，而你又想成为一名黑客，你就要设法成为这样的人。否则你会发现，你的黑客热情会被其他分心的事物吞噬掉——如金钱、性、以及社交圈的认同。</p>
<p>（你必须建立对于 <strong>自己学习能力的信念</strong>——就算你掌握的知识不足以解决当前的问题，如果你从问题的一小部分下手并从中学习，你将学到足够的知识用来解决下一部分——以此类推，直到整个问题都被你解决为止。）</p>
<h2 id="2-一个问题不应该被解决两次。"><a href="#2-一个问题不应该被解决两次。" class="headerlink" title="2. 一个问题不应该被解决两次。"></a>2. 一个问题不应该被解决两次。</h2><p>有创新能力的大脑是一种宝贵的有限资源。当世界还充满非常多有待解决的有趣的新问题时，它们不应该被浪费在重新发明轮子的事情上。</p>
<p>作为一名黑客，你必须相信其他黑客的思考时间是宝贵的——因此共享信息、解决问题、并发布结果给其他黑客几乎是一种道义，这样其他人就可以去解决新问题，而不用在旧问题上面浪费精力了。</p>
<p>（这并不是在说你有义务把自己所有的作品都免费发布出来，但这样做的黑客能获得大家最大的尊敬。使用黑客技能养家糊口甚至发财致富都没关系，只要你别忘记自己作为一个黑客的责任，不背离黑客群体即可。）</p>
<h2 id="3-无聊和乏味的工作是罪恶。"><a href="#3-无聊和乏味的工作是罪恶。" class="headerlink" title="3. 无聊和乏味的工作是罪恶。"></a>3. 无聊和乏味的工作是罪恶。</h2><p>黑客（以及所有创造力的人们）都不应该被愚蠢的重复性劳动所困扰。重复性劳动浪费了他们解决新问题的时间，而 <strong>解决新问题正是黑客最大的价值所在。</strong> 这种浪费会伤害到每一个人。无聊和乏味的工作不仅仅是令人不舒服而已，而且本身就是一种罪恶。</p>
<p>作为一个黑客，你必须坚信这点并 <strong>尽可能多地将乏味的工作自动化</strong>，这不仅是为了你自己，也是为了其他人（尤其是其他黑客们）。</p>
<p>(对此有一个明显的例外。黑客有时为了休息大脑、学习技能、或者别的特别的原因，也会做一些在他人看来是重复性或枯燥的事情。但这是自愿的——只要是有思维能力的人，就不应该被迫做无聊的活儿。）</p>
<h2 id="4-崇尚自由。"><a href="#4-崇尚自由。" class="headerlink" title="4. 崇尚自由。"></a>4. 崇尚自由。</h2><p>黑客们是天生的反权威主义者。任何能向你发号施令的人都可以让你停止解决令你着迷的问题，同时，按照权威主义者的一般思路，他通常会给出一些极端愚昧的理由。因此，不论何处，任何权威主义的做法，只要它影响到了你和其他的黑客，你就要和它斗到底。</p>
<p>（这并非向所有权威挑战。儿童需要监护，罪犯要被看管起来。如果服从命令得到某种东西比起用其他方式得到它更节约时间，黑客可以同意接受某种形式的权威。但这是一个有限度的，斟酌过的的交易；那种权威主义者想要的个人服从是不在考虑范围内的。）</p>
<p>权威主义者喜欢审查和保密。他们不信任自愿的合作和信息的共享——他们只喜欢由他们控制的所谓“合作”。因此，作为一个黑客，你应该对审查、保密，以及使用武力或欺骗去压迫有行为能力的人们的做法有一种本能的敌意。同时你要有为此信念付出的意愿。</p>
<h2 id="5-态度不能替代能力。"><a href="#5-态度不能替代能力。" class="headerlink" title="5. 态度不能替代能力。"></a>5. 态度不能替代能力。</h2><p>作为一名黑客，你必须培养起这些态度。但只具备这些态度并不能使你成为一名黑客，也不能使你成为一个运动健将和摇滚明星。<strong>成为一名黑客需要智力、实践、奉献精神、以及辛苦的工作。</strong></p>
<p>因此，你 <strong>必须学着忽略态度问题，并尊重各种各样的能力。</strong> 黑客们不会为那些装模做样的人浪费时间，但他们却非常尊重能力——尤其是从事黑客工作的能力（虽然有能力总归是好事）。如果能具备少有人能掌握的技能就更好了，当然如果你具备一些急需的技能，而这些技能又需要敏锐的思维、高超的技巧、和专注的精神，那就是再好不过了。</p>
<p>如果你尊重能力，你就会享受到提高自己能力的乐趣——辛苦的工作和奉献将不会是一件苦差事，而是一种紧张的娱乐，这是成为黑客至关重要重要的一点。</p>
<h1 id="黑客的基本技能"><a href="#黑客的基本技能" class="headerlink" title="黑客的基本技能"></a>黑客的基本技能</h1><ol>
<li>学习如何编程。</li>
<li>学习使用开源 Unix 系统。</li>
<li>学会使用万维网以及编写 HTML。</li>
<li>学习英语，如果你的水平不够用的话。</li>
</ol>
<p>黑客态度重要，但技术更加重要。态度无法替代技术，在你被别的黑客称为黑客之前，你必须掌握一些基本的技术作为你随身携带的工具。</p>
<p>随着新技术的出现和老技术的过时，这个工具包的内容也在不断改变。比如以前机器语言编程也被列在里边，而 HTML 是直到最近才包括进去的。不过现在可以清楚地告诉你包含以下内容：</p>
<h2 id="1-学习如何编程。"><a href="#1-学习如何编程。" class="headerlink" title="1. 学习如何编程。"></a>1. 学习如何编程。</h2><p>这一条无须多说，当然是最基本的黑客技能。如果你还不会任何编程语言，我建议你 <strong>从 Python 开始学起。它设计清晰，文档齐全，而且对初学者比较友好</strong>。虽然它很适合作为一种入门语言，但它不仅仅只是个玩具；它非常强大、灵活，也适合做大型项目。我在一篇更详细的 Evaluation of Python（译注：Python 试用体验）中有更详细的论述。 Python 网站有很好的入门教程。</p>
<p>我曾经推荐过将 Java 作为初学的语言，但这则批评改变了我的想法（在里边搜索”The Pitfalls of Java as a First Programming Language” 就知道我的意思了）。<strong>作为一名黑客，你不能像人们挖苦的一样，“像水管工人一样装电脑”，你必须知道各个部件的工作原理。现在我觉得可能还是学过 C 和 Lisp 后再学 Java 比较好。</strong></p>
<p>有一个大体的规律，就是如果你过于偏重使用一种语言，这种语言一方面会成为你得心应手的工具，另一方面也会阻碍你的学习。有这个问题的不只是编程语言，类似 RubyOnRails、CakePHP、以及 Django 的 web 应用框架也有这个问题，它们只会让你肤浅地懂得一些东西，当你碰到难以解决的问题或者需要调试时，你就可能不知所措了。</p>
<p><strong>如果你想进入正式的编程领域，你将不得不学习 C 语言，它是 Unix 的核心语言。C++ 与 C 非常其他类似；如果你了解其中一种，学习另一种应该不难。但这两种都不适合编程入门者学习。而且事实上，你越避免用C编程，你的工作效率会越高。</strong></p>
<p>C 语言效率极高，而且占用很少的系统资源。不幸的是，C 的高效是通过你手动做很多底层的管理（如内存管理）来达到的。底层代码都很复杂，而且极易出现 bug，你要花很多的时间调试。而现今的计算机速度如此之快，花时间调试程序通常是得不偿失——比较明智的做法是使用一种运行较慢、效率较低，但能大幅节省你的开发时间的语言。因此，还是选择 Python 吧。</p>
<p>其他对黑客而言比较重要的语言包括 Perl 和 LISP。<strong>从实用的角度来说，Perl 是值得一学的；它被广泛用于动态网页和系统管理中，因此，即便你从不用Perl 写程序，至少也应该学会读懂 Perl。</strong> 许多人使用 Perl 的理由和 我建议你使用 Python 的理由一样，都是为了避免用 C 完成那些不需要 C 高效率的工作。你会需要理解那些工作的代码的。</p>
<p><strong>LISP 值得学习的理由不同——最终掌握了它时你会得到丰富的启迪和经验。</strong> 虽然你实际上很少会用到 LISP，但这些经验会使你在以后的日子里成为一个更好的程序员。</p>
<p>当然，实际上你 <strong>最好五种都会（Python，Java，C/C++，Perl 和 LISP）。除了是最重要的黑客语言外，它们还代表了截然不同的编程思路和方法，每种都会让你受益非浅。</strong>（你可以通过修改 Emacs 编辑器的模式）</p>
<p>单单学习编程语言并不会让你达到黑客的程度，甚至连程序员的程度都难企及——你需要脱离某种编程语言的素服，学习通过编程解决问题的思路。要成为一个真正的黑客，你需要达到几天就能学会一门编程语言的水平，你可以将文档里的信息和你已经掌握的知识结合起来，很快就学会一门编程语言。这意味着你需要先学会机种思路截然不同的语言才行。</p>
<p>编程是一个复杂的技能，我无法给你完整的指南来教会你如何编程，不过我可以告诉你，书本和课程也无法教会你如何编程——很多黑客，或者也许几乎所有的黑客，都是靠自学的。你从书本上学到语言的特点——只是一些皮毛，但要使书面知识成为自身技能，你只能通过实践和虚心向他人学习。因此你 <strong>要做的就是 (a) 读代码，(b) 写代码。</strong></p>
<p>Peter Novig 是 Google 公司的顶尖黑客之一，而且是最受欢迎的 AI 课本的一名作者。他写了一篇好文章名叫 <strong>Teach Yourself Programming in Ten Years（译注：十年教会自己编程）</strong> ，其中的“recipe for programming success”（译注：编程的成功之道）尤其值得一读。</p>
<p><strong>学习编程就象学习自然语言写作一样。最好的做法是读一些大师的名著，试着自己写点东西，再读些，再写点，再读些，再写点……如此往复，直到你的文章具备范文的力量和感觉为止。</strong></p>
<p>以前要找适合阅读的好代码并不容易，因为几乎没有大型程序的源代码能让新手练手。这种状况已经戏剧性地发生变化；开源软件、编程工具、和操作系统（全都由黑客写成）现在已经随处可见。让我们在下一个话题中继续讨论……</p>
<h2 id="2-学习使用开源的-Unix-系统。"><a href="#2-学习使用开源的-Unix-系统。" class="headerlink" title="2. 学习使用开源的 Unix 系统。"></a>2. 学习使用开源的 Unix 系统。</h2><p>我将假设你已经有一台个人计算机供自己使用了（你可以体会一下这意味着多少东西。早些时候，计算机是如此的昂贵，没有人能买得起。而黑客文化就是在那样的环境下演化来的）。新手们能够朝学习黑客技能迈出的最基本的一步，就是找一版 Linux 或 BSD-Unix，安装在个人电脑上，并且把它跑起来。</p>
<p>没错，这世界上除了Unix还有其他操作系统。但它们都是以二进制形式发布的——你无法读到它的源代码，也不可能修改它。<strong>尝试在运行 DOS、Windows、或 MacOS 的机器上学习黑客技术，就象是穿着骑士铠甲学跳舞。</strong></p>
<p>除此之外，Unix 还是 Internet 的操作系统。你可以学会上网却不知道 Unix，但你不了解 Unix 就无法成为一名 Internet 黑客。因此，今天的黑客文化在很大程度上是以 Unix 为核心的。（这点并不总是真的，一些很早的黑客对此一直很不满，但 Unix 和 Internet 之间的联系已是如此之强，就连 Microsoft 这样强力的公司也对此也无可奈何。）</p>
<p>所以, 安装一套 Unix 吧——我个人偏爱 Linux，但还有其他种类共你选择（是的，你可以在同一电脑上同时安装 Linux 和 DOS/Windows)。学习它，运行它，鼓捣它。用它上 Internet。阅读它的源代码。修改它的源代码。你会用到很多优秀的编程工具（包括 C， LISP，Python 及 Perl），这些工具在 Windows 下是做梦都没法得到的。你会觉得乐趣无穷。当你有一天成为大师再回顾初学的日子，你会觉得那时学到的东西可真多。</p>
<p>如果你想了解更多关于学习 Unix 的信息，读一下 <a href="http://catb.org/~esr/faqs/loginataka.html" target="_blank" rel="external">The Loginataka</a>（译注：ESR 的另一著作，可以称为黑客大藏经）吧。也许你还想看看 <a href="http://catb.org/~esr/writings/taoup/" target="_blank" rel="external">The Art of Unix Programming</a> （译注：Unix 编程艺术，经典著作）。</p>
<p>你可以访问 <a href="http://www.linux.org/" target="_blank" rel="external">Linux Online!</a> 网站，这个网站可以帮你起步。你可以从那里下载到Linux，或者更好的办法是找一个本地的 Linux 用户组，让他们帮你安装 Linux。</p>
<p>在这份 HOWTO 文档发布后的前十年里，关于 Linux 我写的是，从新人的观点来看，所有的Linux 发行版都差不多，但在 2006-2007 之间，我们终于有了一个最佳选择： Ubuntu。我们可以说各种Linux 发行版各有千秋，但 Ubuntu 是新人最容易上手的一个发行版。</p>
<p>你可以在 www.bsd.org 找到 BSD Unix 的求助及其他资源。</p>
<p>Linux 有一种被称为 Live CD 的发行方式，这种发行版会从CD 运行起来，而且不会动到你硬盘里的东西，Live CD 是尝试 Linux 的一个不错的方法。由于光驱读写本来就比较慢，Live CD 的速度一般也会比较慢，不过 Live CD 总归是一个能尝试各种可能性而又不过激的方法。</p>
<p>我有写一篇<a href="http://en.tldp.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html" target="_blank" rel="external">]关于 Unix 和 Internet 基础的入门文章</a>。</p>
<p>对于新手，我以前不鼓励你自己独立安装Linux 或者 BSD，现在这些系统的安装工具已经足够好了，就算对新手来说，独立安装操作系统也不是不可能的事。无论如何，我还是推荐你联系本地的 Linux 用户组，向他们寻求帮助，这会进程更加顺利。</p>
<h2 id="3-学会使用万维网以及编写-HTML。"><a href="#3-学会使用万维网以及编写-HTML。" class="headerlink" title="3. 学会使用万维网以及编写 HTML。"></a>3. 学会使用万维网以及编写 HTML。</h2><p>黑客文化建造的大多东西都在你看不见的地方发挥着作用。这些东西可以帮助工厂、办公室、以及大学正常运转起来，但从表面上很难看到它们对非黑客的普通人的生活的影响。而 Web 是一个大大的例外。就连政客也同意，这个庞大耀眼的黑客玩具正在改变整个世界。就算只是因为这个（还有许多其它的原因），Web 也值得你一学。</p>
<p>这并不是仅仅意味着如何使用浏览器（谁都会），而是要学会如何写 HTML，也就是 Web 的标记语言。如果你不会编程，写HTML会教你一些有助于学习的思考习惯。因此，先完成一个主页。</p>
<p>但仅仅拥有一个主页不能使你成为一名黑客。 Web里充满了各种网页。大多数是毫无意义的、毫无信息量的垃圾——界面时髦的垃圾，不过还是垃圾（更多相关信息访问 <a href="http://catb.org/~esr/html-hell.html" target="_blank" rel="external">The HTML Hell Page</a>）。</p>
<p>要想有价值，你的网页必须有内容——它必须有趣或对其它黑客有帮助。这是下一个话题所涉及的……</p>
<h2 id="4-学习英语，如果你的水平不够用的话。"><a href="#4-学习英语，如果你的水平不够用的话。" class="headerlink" title="4. 学习英语，如果你的水平不够用的话。"></a>4. 学习英语，如果你的水平不够用的话。</h2><p>作为一个以英语为母语的美国人，我以前很不情愿提到这点，免得被当做一种文化上的帝国主义。但相当多以其他语言为母语的人一直劝我指出这一点，那就是：英语是黑客文化和 Internet 的工作语言，只有懂英语，你才能在黑客社区顺利做事。</p>
<p>大概1991年的时候，我就了解到许多黑客在技术讨论中使用英语，甚至有时他们来自同一种母语也在用英文讨论。在现阶段，英语有着比其他语言丰富得多的技术词汇，因此是一个对于工作来说相当好的工具。基于类似的原因，英文技术书籍的翻译通常都不怎么令人满意。（如果有翻译的话）。</p>
<p>Linus Torvalds 是芬兰人，但他的代码注解是用英语写的（很明显他从没想过其他的可能性）。他流利的英语。是他能够管理全球范围的 Linux 开发人员社区的重要因素。 这是一个值得学习的例子。</p>
<p>就算你的母语是英语，这也无法保证你的语言技能足够达到黑客的标准。如果你的写作文字不通、语法混乱、错字连篇，包括我在内的大部分的黑客都会忽略你的存在。虽然写作马虎不一定意味着思考也马虎，但我们发现两者的关联性还是挺强的——马虎的头脑对我们来说毫无价值，如果你写作能力不够，就好好学习写作吧。</p>
<h1 id="提高自己在黑客圈中的地位"><a href="#提高自己在黑客圈中的地位" class="headerlink" title="提高自己在黑客圈中的地位"></a>提高自己在黑客圈中的地位</h1><ol>
<li>撰写开源软件</li>
<li>帮助测试并调试开源软件</li>
<li>发布有用的信息</li>
<li>帮助维护基础设施的运转</li>
<li>为黑客文化本身服务</li>
</ol>
<p>和大部分不涉及金钱的文化一样，黑客王国靠声誉运转。你设法解决有趣的问题，但它们到底多有趣，你的解法有多好，是要由那些和你具有同样技术水平，或比你更厉害的人去评判的。</p>
<p>相应地你需要认识到，当你在玩黑客游戏时，你的分数主要是靠其他黑客对你的技术的评价得到的（这就是为什么只有在其它黑客称你为黑客时，你才算得上是一名黑客）。常人的印象里，黑客是一项独来独往的工作，所以上述评价方式并不为众人所知。另一个黑客文化误区是拒绝承认自我或外部评价是一个人的动力，这种想法在 1990 年代末以后就逐渐衰退了，但现在还有人这么认为。这也是让上述评价方式鲜为人知的原因之一。</p>
<p>明确地讲，<strong>黑客行为就是人类学家所称的“奉献文化”</strong>。在这里你不是凭借你对别人的统治来建立地位和名望，也不是靠美貌，或拥有其他人想要的东西，而是靠你的贡献。尤其是贡献你的时间、你的创造、以及你的技术成果。</p>
<p>要获得其他黑客的尊敬，你可以从下面五种事情着手：</p>
<h2 id="1-撰写开源软件"><a href="#1-撰写开源软件" class="headerlink" title="1. 撰写开源软件"></a>1. 撰写开源软件</h2><p>第一个方法（也是最重要，最传统的方法）是写些被其他黑客认为有趣或有用的程序，并把程序源代码提供给整个黑客文化圈使用。</p>
<p>（过去我们称之为“free software （自由软件）”， 但这却使很多不知 free 的精确含义的人感到困惑。现在我们很多人，根据搜索引擎网页内容分析，至少三分之二的人在使用”<a href="http://www.opensource.org/" target="_blank" rel="external">open-source software</a>，即“开源软件”这个词）。</p>
<p>黑客领域里最受尊敬的偶像，是那些写了大型的、好用的、用途广泛的软件，并把它们发布出来，使得每人都在使用他软件的人。</p>
<p>但是从历史方面来讲有一点值得一提。虽然黑客们一直认为开源软件的开发者是真正的黑客，但在 1990 年代中期以前，大部分黑客会把自己的主要时间用来撰写闭源软件，直到我 1996 年开始写这篇 HOWTO 时也是如此。但从 1997 年后开源软件进入了主流，而且改变了这一切。以现在的观点来看，“黑客社群”和“开源开发者”是对这一个社群的两种称呼，但值得记住的是，以前这两者的概念并不完全一样。(要了解更多信息，你可以看看 <a href="http://catb.org/~esr/faqs/hacker-howto.html#history" target="_blank" rel="external">关于黑客、开源、以及自由软件的历史</a>这一节的内容。)</p>
<h2 id="2-帮助测试并调试开源软件"><a href="#2-帮助测试并调试开源软件" class="headerlink" title="2. 帮助测试并调试开源软件"></a>2. 帮助测试并调试开源软件</h2><p>黑客也尊敬那些使用和测试开源软件的人。这个世界并不完美，我们不可避免地要把大多数的开发时间放在调试阶段。这就是为什么任何有头脑的开源代码的作者都会告诉你好的 beta 测试员象红宝石一样珍贵。好的测试者知道如何清楚描述出错症状，很好地定位错误，能忍受快速发布中的 bug，并且乐意配合做一些例行的诊断性工作。一个优秀的测试者可以让一场旷日持久辛苦不堪的调试大战变成一场有益身心的小打小闹。</p>
<p>如果你是个新手，试着找一个你感兴趣的正在开发中的程序，做一个好的 beta 测试员。你会自然地从帮着测试，进步到帮着抓 bug，到最后帮着改程序。你会从中学到很多，而且善因种善果，以后别人也会很乐意帮助你。</p>
<h2 id="3-发布有用的信息"><a href="#3-发布有用的信息" class="headerlink" title="3. 发布有用的信息"></a>3. 发布有用的信息</h2><p>另一件好事是收集整理有用有趣的信息，做成网页或类似 FAQ 的文档，并且让大家都能看到。</p>
<p>技术性 FAQ 的维护者会受到和开源代码的作者一样多的尊敬。</p>
<h2 id="4-帮助维护基础设施的运转"><a href="#4-帮助维护基础设施的运转" class="headerlink" title="4. 帮助维护基础设施的运转"></a>4. 帮助维护基础设施的运转</h2><p>黑客文化（还有互联网工程方面的发展）是靠志愿者推动的。要使Internet能正常工作，就要有大量枯燥的工作不得不去完成——管理邮件列表和新闻组，维护大型软件库，开发 RFC 和其它技术标准等等。</p>
<p>做这类事情的人会得到很多尊敬，因为每人都知道这些事情费时颇多，而又不象编程那样有趣。做这些事情需要奉献精神。</p>
<h2 id="5-为黑客文化本身服务"><a href="#5-为黑客文化本身服务" class="headerlink" title="5. 为黑客文化本身服务"></a>5. 为黑客文化本身服务</h2><p>最后，你可以为这个文化本身做宣传（例如像我这样，写一个“如何成为黑客”的教程 :-) ）这并不要求在你已经在这个圈子呆了很久，因以上四点中的某点而出名，有一定声誉后才能去做。</p>
<p>黑客文化没有领袖，这点是确认无疑的。但黑客圈里确实有些文化英雄、部落长者、史学家、还有发言人。如果你在这圈里呆足够长时间，你也许也能成为其中之一。 记住：<strong>黑客们不相信他们的部落长者的自夸，因此过分追求这种名誉是危险的。与其奋力追求，不如先摆正自己的位置，等它自己落到你的手中——那时则要做到谦虚和优雅。</strong></p>
<p>##黑客和书呆子(Nerd)的联系</p>
<p>和大家普遍认为的相反，并不是只有书呆子才能成为一名黑客。但它确实有帮助，而且许多黑客事实上是书呆子。做一个深居简出的人有助于你集中精力进行十分重要的事情，如思考和编程。</p>
<p>因此，很多黑客都接受了“geek（奇客）”这个标签，并把它作为骄傲的奖章——这是宣布他们独立于主流社会期望的一种方式（这个标签也是他们喜欢科幻小说和策略型游戏的标记，而这些也是很多黑客喜欢的东西）。1990 年代更多用的称呼是“nerd（书呆子）”，那时“nerd”只带点轻微的贬义，而“geek”则是地地道道的蔑称，而在 2000 年以后，这两者逐渐调转过来了，至少再美国的大众文化中是这样。而到了现在，甚至在非技术人群里，也有不少以 geek 精神为傲的文化团体。</p>
<p>如果你能集中足够的精力做好黑客工作同时还能有正常的生活，这是件好事。现在要做到这一点比我在 1970 年代还是新手的时候要容易的多；如今主流文化对技术怪人要友善得多。甚至有越来越多的人意识到黑客通常是很好的恋人和配偶的材料。</p>
<p>如果你因为生活上不如意而迷上做黑客，那也没什么——至少你不会分神了。也许你以后还能找到自己的生活。</p>
<h2 id="向黑客的格调靠拢"><a href="#向黑客的格调靠拢" class="headerlink" title="向黑客的格调靠拢"></a>向黑客的格调靠拢</h2><p>重申一下，要做一名黑客，你必须深入体验黑客精神。就算你不在计算机边上，你仍然有很多对黑客工作有帮助的事情可做。它们并不能替代真正的编程（没有什么能替代编程），但很多黑客都那么做，并感到它们与黑客的本质存在某些基本的连系。</p>
<ul>
<li>学会用母语流畅地写作。尽管很多人认为程序员写不出好文章，但是有相当数量的黑客（包括所有我知道的最棒的黑客）都是很有能力的写手。</li>
<li>阅读科幻小说。参加科幻小说讨论会。（这是一个认识黑客和准黑客的好方法）</li>
<li>学习一种武术。武术中需要的精神自律能力和黑客在这方面的需求非常相似。黑中最受欢迎的武术是来自亚洲的空手格斗类武术，例如跆拳道、空手道、武术、合气道、柔术等。西式击剑和亚洲剑术也有不少的跟随者。1990 年后期以来，在可以合法使用枪支的地方，射击受欢迎的程度也越来越高了。<strong>大部分黑客喜欢的武术类型都是那些强调精神的自律，放松的意识，以及意念的控制，而不仅仅是单纯的力量、运动精神、以及身体的强健。</strong></li>
<li>实实在在学习一种冥想修炼。多年以来黑客中最受欢迎的形式是参禅。（很重要的一点是，参禅和宗教可以说是独立的，你不需要接受一种新宗教，或者放弃现有的宗教信仰，就能做参禅的修炼。其他的形式也许也管用，但注意一定要挑那些靠谱的，不需要你相信不着边际的事物的冥想方式来演练。</li>
<li>提高自己对双关语和文字游戏的鉴赏能力。<br>如果这些事情有很多你已经在做了，那你可能是天生做黑客的材料。至于为什么偏偏是这些事情，原因并不完全清楚，但它们都涉及用到左－右脑能力的综合，这似乎是关键所在（黑客们既需要清晰的逻辑思维，有时又需要偏离逻辑跳出问题的表象）。</li>
</ul>
<p>最后，还有一些不要去做的事情。</p>
<ul>
<li>不要使用愚蠢的，哗众取宠的ID或昵称。</li>
<li>不要卷入 Usenet（或任何其他地方）的骂战。</li>
<li>不要自称为“cyberpunk（网络朋克）”，也不要浪费时间和那些人打交道。</li>
<li>不要让你的 email 或者帖子中充满错误的拼写和语法。<br>以上的事情只会为你招来嘲笑。黑客们个个记忆超群——你将需要数年的时间让他们忘记你犯下的错误。</li>
</ul>
<p>网名的问题值得深思。将身份隐藏在虚假的名字后是骇客、软件破解者、及其他低等生物幼稚愚蠢的行为。黑客不会做这些事；他们对他们所作的感到骄傲，而且乐于人们将作品与他们的真名相联系。因此, 如果你现在还在使用假名，那就放弃它吧。<strong>在黑客文化里假名是失败者的标记。</strong></p>
<h2 id="关于黑客、开源、以及自由软件的历史"><a href="#关于黑客、开源、以及自由软件的历史" class="headerlink" title="关于黑客、开源、以及自由软件的历史"></a>关于黑客、开源、以及自由软件的历史</h2><p>1996 年我开始写这篇 HOWTO，那时候的大环境和现在很不一样。这里会给你简单介绍一下相关的历史变迁，这样大致可以澄清一下开源软件、自由软件、以及 Linux 和黑客圈的关系。如果你对这些不感兴趣，你可以直接跳过这一节，继续读下面的 FAQ。</p>
<p>我在这里所描述黑客精神和社会远远早于1990 Linux 出现的时候，我第一次涉足黑客圈是 1976 年，而究其根源则可追溯到20世纪60年代初。但在 Linux 出现之前，大多数黑客使用的操作系统要么是私有的商业版本，要么是自己开发的未得到广泛使用的系统（例如麻省理工学院的 ITS 系统）。虽然那时也有人想要改变这种状况，但他们的努力影响范围相当有限，充其量仅在某个黑客社区有少数忠实用户而已。</p>
<p>现在所谓“开源”历史和黑客社区的历史几乎一样长，但直到 1985 年前，它只是一种没有固定称谓的习惯做法，而不是一套有理论做后盾，有宣言做前锋的自觉运动。这种状态在 1985年结束了，长老级黑客 Richard Stallman（也被称为“RMS”）将其命名为“自由软件 (Free Software)”。这种命名也是一种宣言的方式，不过大多数黑客社区都不接收这种包含明显思想烙印的标签。因此而大多数现有的黑客社区从来没有接受。结果，“自由软件”这一标签被黑客社群中声音较大的少数人（尤其是 BSD Unix 的相关人士）拒绝掉了，而剩下的大部分人（包括我）虽然也有保留意见，可也还是沿用了这一称谓。</p>
<p>尽管很多人存在保留意见，RMS 的“自由软件”的大旗也一直举到了 1990 年代中期。直到 Liunx 崛起时它才受到了重大挑战。Linux 给了的开源开发者一个新的自然归宿，很多项目都已我们现称的开源的方式由 Unix 移植到了 Linux 系统中。Linux 的社区也得到了爆炸性增长，成为了一个比以前黑客文化更为庞大，并且异质化的新的群体。RMS 曾今尝试将这一社群也归并到他的“自由软件运动”大旗下，但终究没有成功，原因可以归于 Linux 社区的样性，以及 Linus Torvalds 本人的质疑。Torvalds 公开拒绝了 RMS 的自由软件思想，但还是沿用了“自由软件”这一术语，这也引来了很多年轻黑客的效仿。</p>
<p>1996年，当我第一次发表这篇 HOWTO 的时候，黑客社团正在围绕着 Linux 和其它几个开源操作系统（尤其是 BSD Unix 的衍生系统）进行着快速的重组。几十年来围绕着闭源系统进行闭源开发的方式还没有开始淡出集体记忆，但在大家看来，这似乎已经是死去的历史了。越来越多的黑客都已经开始注重自己在开源项目（例如 Linux、Apache 等）上的贡献，并将这些贡献当做自己的成就。</p>
<p>然而在那个时候“开源”这一名词还没有出现。这个名词是 1998 年初才开始出现的，而在出现的半年内，大部分的黑客社区就接受了这一名词，只有少数不接受这一概念的人还在坚持使用“自由软件”这一名词。1998 年以后，或者更准确地说是 2003 年以后，所谓的“hacking” 和 “开源（自由）软件开发”的含义已经非常接近了。从今天的眼光来看，这种区分已经没有意义了，看趋势，这个现状将来也不大可能有多大的改变。</p>
<p>不管怎样，这段变更的历史还是值得记住的。</p>
<h2 id="其它资源"><a href="#其它资源" class="headerlink" title="其它资源"></a>其它资源</h2><p>Paul Graham 写了一篇 <a href="http://www.paulgraham.com/gh.html" target="_blank" rel="external">Great Hackers</a>，还有 <a href="http://www.paulgraham.com/college.html" target="_blank" rel="external">Undergraduation</a> 一篇，里边有充满智慧的言论。</p>
<p>Younger hackers might find <a href="http://catb.org/~esr/faqs/things-every-hacker-once-knew" target="_blank" rel="external">Things Every Hacker Once Knew</a> interesting and useful.</p>
<p>我还写过一篇 <a href="http://catb.org/~esr/writings/hacker-history/hacker-history.html" target="_blank" rel="external">A Brief History Of Hackerdom</a> （译注：黑客文化简史）。</p>
<p>我写了一本 <a href="http://catb.org/~esr/writings/cathedral-bazaar/index.html" target="_blank" rel="external">The Cathedral and the Bazaar</a>（译注：大教堂与市集），对于 Linux 及开放源代码文化现象有详细的解释。这种现象在我的另一篇 <a href="http://catb.org/~esr/writings/homesteading/" target="_blank" rel="external">Homesteading the Noosphere</a> （译注：开拓智域）中还有更直接的阐述。</p>
<p>Rick Moen 写了一份很好的关于 <a href="http://linuxmafia.com/faq/Linux_PR/newlug.html" target="_blank" rel="external">how to run a Linux user group</a>（译注：如何运营Linux 用户组）的文档。</p>
<p>我和Rick Moen合作完成了另一份关于 <a href="http://catb.org/~esr/faqs/smart-questions.html" target="_blank" rel="external">How To Ask Smart Questions</a>（译注：提问的智慧）的文章，可以让在寻求帮助时得到事半功倍的效果。</p>
<p>如果你想知道 PC、UNIX 及 Internet 基本概念和工作原理，参考 <a href="http://en.tldp.org/HOWTO//Unix-and-Internet-Fundamentals-HOWTO/" target="_blank" rel="external">The Unix and Internet Fundamentals HOWTO</a>。</p>
<p>当你发布软件或者补丁的时候，请遵照 <a href="http://en.tldp.org/HOWTO/Software-Release-Practice-HOWTO/index.html" target="_blank" rel="external">Software Release Practice HOWTO</a> 去做。</p>
<p>如果你对禅诗感兴趣，也许你还喜欢看这篇 <a href="http://catb.org/~esr//writings/unix-koans" target="_blank" rel="external">Rootless Root: The Unix Koans of Master Foo</a></p>
<h1 id="FAQ（常见问题解答）"><a href="#FAQ（常见问题解答）" class="headerlink" title="FAQ（常见问题解答）"></a>FAQ（常见问题解答）</h1><p>怎样才能知道自己已经是一名够格的黑客？<br>你能教我做黑客吗？<br>那么，我要如何开始？<br>我得什么时候开始学？现在会不会太迟了？<br>要学多久才能学会黑客技能？<br>Visual Basic 是好的入门语言吗？<br>你能帮我“黑”掉一个站点吗？或者教我怎么黑它？<br>我怎么样才能得到别人帐号的密码？<br>我如何入侵/查看/监视别人的 Email？<br>我如何才能在IRC聊天室里偷到频道 op 的特权？<br>我被黑了。你能帮我避免以后再被攻击吗？<br>我的 Windows 软件出现问题了。你能帮我吗？<br>我在哪里能找到可以与之交流的真正的黑客？<br>你能推荐一些有关黑客的好书吗？<br>成为一名黑客我需要擅长数学吗？<br>我该从那种语言学起？<br>我需要什么样的机器配置？<br>我想贡献社区。你可以帮我选一个问题让我下手吗？<br>我得因此憎恨和反对 Microsoft 吗？<br>开放源代码软件不会使程序员丢饭碗吗？<br>我要如何开始？哪里有免费的Unix？</p>
<h2 id="怎样才能知道自己已经是一名够格的黑客？"><a href="#怎样才能知道自己已经是一名够格的黑客？" class="headerlink" title="怎样才能知道自己已经是一名够格的黑客？"></a>怎样才能知道自己已经是一名够格的黑客？</h2><p>你可以问自己下面三个问题：</p>
<ul>
<li>你能流利地读写代码吗？</li>
<li>你认同黑客社群的目的和价值吗？</li>
<li>黑客社群里有没有资深成员称呼你为黑客呢？</li>
</ul>
<p>如果你对这三个问题的答案都是“是”的话，你已经是一名黑客了。如果你只满足其中两项，那就说明你还不够格。</p>
<p>第一个问题是关于技能的。如果你已经符合本文前面提到的最低需求的话，你也算过关，不过如果你发布过为数不少的开源代码并被社群接受，那你就算满分过关了。</p>
<p>第二个问题是关于态度的。如果黑客精神的五项基本原则对你来说能有共鸣，而且已经是你处事的方式，你就算过关一半了。这算靠里的一半，靠外的一半和你在黑客社区长期项目上的投入和关联程度有关。</p>
<p>这里列出了一些项目的不完全列表供你参考：Linux 的改进和用户群扩大对你来说是否重要？你对于自由软件精神是否充满激情？你对于垄断是否有敌意？你是否相信计算机这种工具会让增加世界财富，让这个世界更富有人道主义？</p>
<p>不过值得注意的一点是，黑客社群有一些特有的政治倾向，其中两条，一条是保卫言论自由权，一种是抵御所谓“知识产权”对于开源社区的侵害。实践这两条的是一些民间组织，例如电子前沿基金会（Electronic Frontier Foundation）就是其中之一。不过虽然如此，黑客们对于有任何明确政治目的的团体都是心怀戒备的，因为我们已经从各种经验教训中学到一点：这些活动只会分裂黑客社团，并让黑客们分心。如果有人以黑客精神为名组织一场首都大游行，那他就完全没有弄明白这点。真正的应对方式也许应该是“闭上嘴巴，给他们看代码”。</p>
<p>第三个问题有点循环递归的味道。在“什么是黑客”一节我已经讲过，作为一名黑客的意义在于参与某个黑客社群，也就是社交网络的一个亚文化团体，作为内部的贡献成员以及外部的宣传者积极活动。和很久以前相比，黑客群体现在的团结意识和自我意识已经增强了很多。过去三十年来，随着互联网的发展，社交网络逐渐开始发挥举足轻重的作用，而黑客的亚文化团体也更加容易发展和维护了。这种变革的明显一个有代表性的现象是：有的黑客社群现在都有自己专门的文化衫了。</p>
<p>研究社交网络的社会学家把黑客文化归为“看不见的大学”，而且注意到这些网络社交圈还有所谓的“看门人”——其中的一些核心成员，他们有一定的权威，可以准新成员的进入。所谓的“看不见的大学”本来就是一个松散的非正式组织，所以这些“看门人”也只是这门称呼而已。但不是每个黑客都是“看门人”，这是每个黑客都深刻明白的一点。“看门人”需要有一定的资历和成就，究竟要到什么程度很难讲，但一旦有这样的人出现，每一个黑客都能辨识出来。</p>
<h2 id="你能教我做黑客吗？"><a href="#你能教我做黑客吗？" class="headerlink" title="你能教我做黑客吗？"></a>你能教我做黑客吗？</h2><p>自从第一次发布这份文档，我每周都会收到一些请求，（频繁的话一天几封）要我“教会他们做黑客”。遗憾的是，我 没有时间和精力来做这个；我自己的黑客项目，及我作为一个开放源代码倡导者 的四处奔波已经占用了我110%的时间。</p>
<p>即便我想教你，黑客也依然基本上是一项自行修炼的的态度和技术。 当真正的黑客想帮助你的时候，如果你乞求他们一汤匙一汤匙“喂”你的话，你会发现他们不会尊重你。</p>
<p><strong>先去学一些东西。显示你在尝试，你能靠自己去学习。然后再去向你遇到的黑客请教特殊的问题。</strong></p>
<p>如果你发E-mail给一位黑客寻求他的帮助，这是两件首要记住的事情。 第一，写出来的文字显得懒且粗心的人通常非常懒于思考且非常马大哈，不能成为好黑客——因此注意拼写正确，使用正确的语法及发音，否则你可能会无人理睬。 第二，不要试图要求回复到一个ISP帐号，而那个帐号与你 的发信地址不同。这样做的人一般是使用盗用帐号，我们对于回报或者帮助窃贼不感兴趣。</p>
<h2 id="那么，我要如何开始？"><a href="#那么，我要如何开始？" class="headerlink" title="那么，我要如何开始？"></a>那么，我要如何开始？</h2><p>对你而言最佳的入门方式也许是去参加 <a href="http://www.tldp.org/links/index.html" target="_blank" rel="external">LUG</a>（Linux用户组）的聚会。 你可以找到在 LDP 的综合 Linux 信息页面上找到类似的组织；也许有一个在你家附近的，而且非常有可能与一所大学或学校挂钩。如果你提出要求，LUG 成员兴许会给你一套 Linux，当然此后会帮你安装并带你入门。</p>
<h2 id="我得什么时候开始学？现在会不会太迟了？"><a href="#我得什么时候开始学？现在会不会太迟了？" class="headerlink" title="我得什么时候开始学？现在会不会太迟了？"></a>我得什么时候开始学？现在会不会太迟了？</h2><p>你有动力学习的时候就是好时候。大多数人看来都是在15－20岁之间开始感兴趣的，但据我所知，在此年龄段之外的例外也是有的。</p>
<h2 id="要学多久才能学会黑客技能？"><a href="#要学多久才能学会黑客技能？" class="headerlink" title="要学多久才能学会黑客技能？"></a>要学多久才能学会黑客技能？</h2><p>这取决于你的聪明程度和努力程度。<strong>对于大多数人，只要足够专注，就能在 18 个月到 2 年之间学会一套令人尊敬的技能。</strong> 但是，不要以为这样就够了；如果你是一个真正的黑客，你要用你的余生来学习和完善你的技术。</p>
<h2 id="Visual-Basic-是好的入门语言吗？"><a href="#Visual-Basic-是好的入门语言吗？" class="headerlink" title="Visual Basic 是好的入门语言吗？"></a>Visual Basic 是好的入门语言吗？</h2><p>既然你问了这个问题，那你肯定是想在 Microsoft Windows 操作系统下学习黑客技能。这本身就不是一个好主意。我前面讲过在 Windows 下 hack 就跟穿着骑士铠甲跳舞一样，我不是在开玩笑。别走这条路，Windows 是一个很低劣的 hack 环境，而且一直如此。</p>
<p>Visual Basic 有一个特征性问题，就是它不可以被移植到其他平台。虽然也有些 Visual Basic 开源实现的雏形，但实现的只是 ECMA 标准的一个很小的子集。<strong>在 Windows 下大部分类库的知识产权都是 Microsoft 独家所有，如果你不是及其小心的话，你的代码将只能在 Microsoft 支持的平台上使用。</strong> 如果你不打算从 Unix 起步，那你也有更好的语言可选，而且类库质量还更高，例如 Python 就是其中之一</p>
<p>和其他的 Basic 类语言一样，Visual Basic 这门编程语言的设计也很糟糕，它会教你一些坏的变成习惯。你就别问我细节了，这可是罄竹难书。还是去学一门设计优良的语言吧。<strong>其中一个坏习惯是让你依赖于单一厂商的函数库、控件及开发工具。</strong> 一般而言，任何不能够支持至少 Linux 或者某一种 BSD，或其不能支持至少三种以上操作系统的语言，都是一种不适合应付黑客工作的语言。</p>
<h2 id="你能帮我“黑”掉一个站点吗？或者教我怎么黑它？"><a href="#你能帮我“黑”掉一个站点吗？或者教我怎么黑它？" class="headerlink" title="你能帮我“黑”掉一个站点吗？或者教我怎么黑它？"></a>你能帮我“黑”掉一个站点吗？或者教我怎么黑它？</h2><p>No。任何读完这份 FAQ 后还问这个问题的人，都是无可救药的蠢材，即使有时间指教我也不会理睬。任何发给我的此类电子邮件都会被忽略或被痛骂一顿。</p>
<h2 id="我怎么样才能得到别人帐号的密码？"><a href="#我怎么样才能得到别人帐号的密码？" class="headerlink" title="我怎么样才能得到别人帐号的密码？"></a>我怎么样才能得到别人帐号的密码？</h2><p>这是骇客行为。滚得远远的，白痴。</p>
<h2 id="我如何入侵-查看-监视别人的-Email？"><a href="#我如何入侵-查看-监视别人的-Email？" class="headerlink" title="我如何入侵/查看/监视别人的 Email？"></a>我如何入侵/查看/监视别人的 Email？</h2><p>这是骇客行为。在我面前消失，智障。</p>
<h2 id="我如何才能在IRC聊天室里偷到频道-op-的特权？"><a href="#我如何才能在IRC聊天室里偷到频道-op-的特权？" class="headerlink" title="我如何才能在IRC聊天室里偷到频道 op 的特权？"></a>我如何才能在IRC聊天室里偷到频道 op 的特权？</h2><p>这是骇客行为。滚开，笨蛋。</p>
<h2 id="我被黑了。你能帮我避免以后再被攻击吗？"><a href="#我被黑了。你能帮我避免以后再被攻击吗？" class="headerlink" title="我被黑了。你能帮我避免以后再被攻击吗？"></a>我被黑了。你能帮我避免以后再被攻击吗？</h2><p>不行。目前为止，每次问我这个问题的，都是一些运行 Microsoft Windows 的菜鸟。不可能有效的保护 Windows 系统免受骇客攻击；太多代码和架构的缺陷使保护 Windows 的努力有如隔靴搔痒。<strong>唯一可靠的预防来自转移到 Linux 或其他设计得至少足够安全的系统。</strong></p>
<h2 id="我的-Windows-软件出现问题了。你能帮我吗？"><a href="#我的-Windows-软件出现问题了。你能帮我吗？" class="headerlink" title="我的 Windows 软件出现问题了。你能帮我吗？"></a>我的 Windows 软件出现问题了。你能帮我吗？</h2><p>当然。打开 DOS 命令行输入“format c:”。你遇到的任何问题将会在几分钟之内消失。</p>
<h2 id="我在哪里能找到可以与之交流的真正的黑客？"><a href="#我在哪里能找到可以与之交流的真正的黑客？" class="headerlink" title="我在哪里能找到可以与之交流的真正的黑客？"></a>我在哪里能找到可以与之交流的真正的黑客？</h2><p>最佳办法是在你附近找一个Unix或Linux的用户组，参加他们的聚会。（你可以在 ibiblio 的 LDP 站点找到一些用户组的链接。）</p>
<p>（我过去曾说过不能在IRC上找到真正的黑客，但我发觉现在情况有所改变。显然一些真正的黑客的社区像 GIMP 及 Perl，也有IRC频道了。）</p>
<h2 id="你能推荐一些有关黑客的好书吗？"><a href="#你能推荐一些有关黑客的好书吗？" class="headerlink" title="你能推荐一些有关黑客的好书吗？"></a>你能推荐一些有关黑客的好书吗？</h2><p>我维护着一份 <a href="http://en.tldp.org/HOWTO/Reading-List-HOWTO/index.html" target="_blank" rel="external">Linux Reading List HOWTO</a>，也许你会觉得有用。<a href="http://catb.org/~esr/faqs/loginataka.html" target="_blank" rel="external">The Loginataka</a> 也大致值得一读。</p>
<p>关于Python的介绍，请访问在<a href="http://docs.python.org/tutorial/index.html" target="_blank" rel="external">Python站点上的入门教程</a>。</p>
<h2 id="成为一名黑客我需要擅长数学吗？"><a href="#成为一名黑客我需要擅长数学吗？" class="headerlink" title="成为一名黑客我需要擅长数学吗？"></a>成为一名黑客我需要擅长数学吗？</h2><p>不用。黑客道很少使用常规的数学或算术，不过你绝对 <strong>需要能逻辑性地思考和进行精密的推理。</strong> 尤其是你不会用到微积分或电路分析（我们把这些留给电子工程师们 :-)）。有限数学中的一些grounding （包括布尔代数，集合论，组合数学，图论）的背景知识会对你有所帮助。</p>
<p>更重要的一点：你要有逻辑思维能力，能够以数学家的方式追溯因果。虽然大部分的数学知识对你可能没什么用处，但数学思维的能力对你来说是极其重要的。如果你缺乏这方面的智慧，要做一名黑客恐怕是无望了。如果你缺乏这方面的训练，还是尽早开始吧。</p>
<h2 id="我该从那种语言学起？"><a href="#我该从那种语言学起？" class="headerlink" title="我该从那种语言学起？"></a>我该从那种语言学起？</h2><p>如果你还没学过XHTML（HTML最新的表现形式）的话，就从它开始吧。市面上有一大堆的封面精美，宣传得天花乱坠的HTML 书籍，不幸的是质量优秀的几近于无。我最喜欢的是 <a href="http://www.oreilly.com/catalog/html5/" target="_blank" rel="external">HTML: The Definitive Guide</a>。</p>
<p>但HTML 不是一种完整的编程语言。当你准备开始编程时，我推荐从 Python 起步。 你会听到一大群人推荐 Perl，但是 Perl 要难学得多，而且（以我之见）设计得不是很好。</p>
<p>C 确实重要，但它也比 Python 或 Perl 难多了。不要尝试先学 C。</p>
<p>Windows用户注意：不要满足于 Visual Basic。它会教给你坏习惯，而且它不可以跨平台移植，只能在Windows下运行。因此还是敬而远之为好。</p>
<h2 id="我需要什么样的机器配置？"><a href="#我需要什么样的机器配置？" class="headerlink" title="我需要什么样的机器配置？"></a>我需要什么样的机器配置？</h2><p>过去个人电脑能力相当不足并且内存很小，这给黑客的学习过程设置了人为的障碍。不过 1990 中期以后就不是这样了；任何一台 Intel 486DX50 以上配置的机器都有足够的能力进行开发工作、运行 X 系统、以及进行 Internet 通讯。而且你买到的市面上最小的硬盘都大得足够你使用了。</p>
<p>选择用来学习的机器时重要的一点是注意配件是否是Linux兼容的（或BSD兼容，如果你选择 BSD 的话）。和刚才提到的一样，大多数现在的机器都是符合的；唯一值得注意的区域在于 modem 和打印机；有些具备为Windows设计的配件的机器不会在Linux下工作。</p>
<p>你可以查看这份 <a href="http://en.tldp.org/HOWTO/Hardware-HOWTO/index.html" target="_blank" rel="external">Linux Hardware Compatibility FAQ</a>。</p>
<h2 id="我想贡献社区。你可以帮我选一个问题让我下手吗？"><a href="#我想贡献社区。你可以帮我选一个问题让我下手吗？" class="headerlink" title="我想贡献社区。你可以帮我选一个问题让我下手吗？"></a>我想贡献社区。你可以帮我选一个问题让我下手吗？</h2><p>不行，因为我不知道你的兴趣和擅长领域在哪里。如果你没有内在动力，你就很难坚持下去，所以说，别人只给你的路是行不通的。</p>
<p>试试这么做吧。在 Freshmeat 网站观察几天，看看里边的项目更新，如果你看到一个看上去很酷而且你也很感兴趣的项目，就加入吧。</p>
<h2 id="我得因此憎恨和反对-Microsoft-吗？"><a href="#我得因此憎恨和反对-Microsoft-吗？" class="headerlink" title="我得因此憎恨和反对 Microsoft 吗？"></a>我得因此憎恨和反对 Microsoft 吗？</h2><p>不，你不必如此。不是因为Microsoft不令人讨厌，而是因为黑客文化早在 Microsoft 出现之前就存在了，且将在 Microsoft 成为历史后依然存在。 你耗费在憎恨 Microsoft 的任何力气不如花在爱你的技术上。写好的代码——那会相当有效地打击 Microsoft 又不会让你得到恶报应。</p>
<h2 id="开放源代码软件不会使程序员丢饭碗吗？"><a href="#开放源代码软件不会使程序员丢饭碗吗？" class="headerlink" title="开放源代码软件不会使程序员丢饭碗吗？"></a>开放源代码软件不会使程序员丢饭碗吗？</h2><p>目前看起来不太可能，开放源代码软件产业似乎创造了更多的就业机会而不是减少就业机会。如果写一个程序比起不写来是纯经济收益的话，那么在写完后，程序员应该得到报酬不管程序是否是开放源代码。并且，无论写出多么“免费自由”的软件，都存在更多对新的，定制的软件的需求。我有这方面更多的论述，放在放源代码<a href="http://www.opensource.org/" target="_blank" rel="external">]网站</a>资料中。</p>
<h2 id="我要如何开始？哪里有免费的Unix？"><a href="#我要如何开始？哪里有免费的Unix？" class="headerlink" title="我要如何开始？哪里有免费的Unix？"></a>我要如何开始？哪里有免费的Unix？</h2><p>在本份文档的某个地方我已经提到过何处可以得到最常用的免费 Unix。要做一名黑客，你需要自己找到激励和动力，还要有自学的能力。现在就开始努力吧……</p>
<h1 id="How-To-Become-A-Hacker"><a href="#How-To-Become-A-Hacker" class="headerlink" title="How To Become A Hacker"></a>How To Become A Hacker</h1><p>Eric Steven Raymond</p>
<p>Thyrsus Enterprises</p>
<pre><code>&lt;esr@thyrsus.com&gt;
</code></pre><p>Copyright © 2001 Eric S. Raymond</p>
<p>Revision History<br>Revision 1.50    19 July 2015    esr<br>Added link to “Let’s Go Larval”.<br>Revision 1.49    21 November 2014    esr<br>Added link to “How To Learn Hacking”.<br>Revision 1.48    19 June 2014    esr<br>freshmeat/freecode is dead, alas.<br>Revision 1.47    20 May 2014    esr<br>Fix up various stale links. Join a hackerspace!<br>Revision 1.46    25 Sep 2013    esr<br>Add micropatronage explanation and gittip link. Why you should not ask me for advice on how to get started.<br>Revision 1.45    12 May 2013    esr<br>Open Solaris isn’t, and Unity screwed the pooch.<br>Revision 1.44    20 May 2012    esr<br>Updated the critique of Java.<br>Revision 1.43    07 Feb 2011    esr<br>Python passed Perl in popularity in 2010.<br>Revision 1.42    22 Oct 2010    esr<br>Added “Historical note”.<br>Revision 1.40    3 Nov 2008    esr<br>Link fixes.<br>Revision 1.39    14 Aug 2008    esr<br>Link fixes.<br>Revision 1.38    8 Jan 2008    esr<br>Deprecate Java as a language to learn early.<br>Revision 1.37    4 Oct 2007    esr<br>Recommend Ubuntu as a Unix distro for newbies.<br>Table of Contents</p>
<p>Why This Document?<br>What Is a Hacker?<br>The Hacker Attitude</p>
<ol>
<li>The world is full of fascinating problems waiting to be solved.</li>
<li>No problem should ever have to be solved twice.</li>
<li>Boredom and drudgery are evil.</li>
<li>Freedom is good.</li>
<li>Attitude is no substitute for competence.<br>Basic Hacking Skills</li>
<li>Learn how to program.</li>
<li>Get one of the open-source Unixes and learn to use and run it.</li>
<li>Learn how to use the World Wide Web and write HTML.</li>
<li>If you don’t have functional English, learn it.<br>Status in the Hacker Culture</li>
<li>Write open-source software</li>
<li>Help test and debug open-source software</li>
<li>Publish useful information</li>
<li>Help keep the infrastructure working</li>
<li>Serve the hacker culture itself<br>The Hacker/Nerd Connection<br>Points For Style<br>Historical Note: Hacking, Open Source, and Free Software<br>Other Resources<br>Frequently Asked Questions</li>
</ol>
<p>Why This Document?</p>
<p>As editor of the Jargon File and author of a few other well-known documents of similar nature, I often get email requests from enthusiastic network newbies asking (in effect) “how can I learn to be a wizardly hacker?”. Back in 1996 I noticed that there didn’t seem to be any other FAQs or web documents that addressed this vital question, so I started this one. A lot of hackers now consider it definitive, and I suppose that means it is. Still, I don’t claim to be the exclusive authority on this topic; if you don’t like what you read here, write your own.</p>
<p>If you are reading a snapshot of this document offline, the current version lives at <a href="http://catb.org/~esr/faqs/hacker-howto.html" target="_blank" rel="external">http://catb.org/~esr/faqs/hacker-howto.html</a>.</p>
<p>Note: there is a list of Frequently Asked Questions at the end of this document. Please read these—twice—before mailing me any questions about this document.</p>
<p>Numerous translations of this document are available: Arabic Belorussian Bulgarian Chinese, Danish Dutch Estonian French German, Greek Italian Hebrew, Japanese Lithuanian Norwegian, Persian Polish Portuguese (Brazilian), Romanian Spanish, Turkish, and Swedish. Note that since this document changes occasionally, they may be out of date to varying degrees.</p>
<p>The five-dots-in-nine-squares diagram that decorates this document is called a glider. It is a simple pattern with some surprising properties in a mathematical simulation called Life that has fascinated hackers for many years. I think it makes a good visual emblem for what hackers are like — abstract, at first a bit mysterious-seeming, but a gateway to a whole world with an intricate logic of its own. Read more about the glider emblem here.</p>
<p>If you find this document valuable, please support me on Patreon. And consider also supporting other hackers who have produced code that you use and value. Lots of small but continuing donations add up quickly, and can free the people who have given you gifts of their labor to create more value.</p>
<p>What Is a Hacker?</p>
<p>The Jargon File contains a bunch of definitions of the term ‘hacker’, most having to do with technical adeptness and a delight in solving problems and overcoming limits. If you want to know how to become a hacker, though, only two are really relevant.</p>
<p>There is a community, a shared culture, of expert programmers and networking wizards that traces its history back through decades to the first time-sharing minicomputers and the earliest ARPAnet experiments. The members of this culture originated the term ‘hacker’. Hackers built the Internet. Hackers made the Unix operating system what it is today. Hackers make the World Wide Web work. If you are part of this culture, if you have contributed to it and other people in it know who you are and call you a hacker, you’re a hacker.</p>
<p>The hacker mind-set is not confined to this software-hacker culture. There are people who apply the hacker attitude to other things, like electronics or music — actually, you can find it at the highest levels of any science or art. Software hackers recognize these kindred spirits elsewhere and may call them ‘hackers’ too — and some claim that the hacker nature is really independent of the particular medium the hacker works in. But in the rest of this document we will focus on the skills and attitudes of software hackers, and the traditions of the shared culture that originated the term ‘hacker’.</p>
<p>There is another group of people who loudly call themselves hackers, but aren’t. These are people (mainly adolescent males) who get a kick out of breaking into computers and phreaking the phone system. Real hackers call these people ‘crackers’ and want nothing to do with them. Real hackers mostly think crackers are lazy, irresponsible, and not very bright, and object that being able to break security doesn’t make you a hacker any more than being able to hotwire cars makes you an automotive engineer. Unfortunately, many journalists and writers have been fooled into using the word ‘hacker’ to describe crackers; this irritates real hackers no end.</p>
<p>The basic difference is this: hackers build things, crackers break them.</p>
<p>If you want to be a hacker, keep reading. If you want to be a cracker, go read the alt.2600 newsgroup and get ready to do five to ten in the slammer after finding out you aren’t as smart as you think you are. And that’s all I’m going to say about crackers.</p>
<p>The Hacker Attitude</p>
<ol>
<li>The world is full of fascinating problems waiting to be solved.</li>
<li>No problem should ever have to be solved twice.</li>
<li>Boredom and drudgery are evil.</li>
<li>Freedom is good.</li>
<li>Attitude is no substitute for competence.<br>Hackers solve problems and build things, and they believe in freedom and voluntary mutual help. To be accepted as a hacker, you have to behave as though you have this kind of attitude yourself. And to behave as though you have the attitude, you have to really believe the attitude.</li>
</ol>
<p>But if you think of cultivating hacker attitudes as just a way to gain acceptance in the culture, you’ll miss the point. Becoming the kind of person who believes these things is important for you — for helping you learn and keeping you motivated. As with all creative arts, the most effective way to become a master is to imitate the mind-set of masters — not just intellectually but emotionally as well.</p>
<p>Or, as the following modern Zen poem has it:</p>
<pre><code>To follow the path:
look to the master,
follow the master,
walk with the master,
see through the master,
become the master.
</code></pre><p>So, if you want to be a hacker, repeat the following things until you believe them:</p>
<ol>
<li>The world is full of fascinating problems waiting to be solved.</li>
</ol>
<p>Being a hacker is lots of fun, but it’s a kind of fun that takes lots of effort. The effort takes motivation. Successful athletes get their motivation from a kind of physical delight in making their bodies perform, in pushing themselves past their own physical limits. Similarly, to be a hacker you have to get a basic thrill from solving problems, sharpening your skills, and exercising your intelligence.</p>
<p>If you aren’t the kind of person that feels this way naturally, you’ll need to become one in order to make it as a hacker. Otherwise you’ll find your hacking energy is sapped by distractions like sex, money, and social approval.</p>
<p>(You also have to develop a kind of faith in your own learning capacity — a belief that even though you may not know all of what you need to solve a problem, if you tackle just a piece of it and learn from that, you’ll learn enough to solve the next piece — and so on, until you’re done.)</p>
<ol>
<li>No problem should ever have to be solved twice.</li>
</ol>
<p>Creative brains are a valuable, limited resource. They shouldn’t be wasted on re-inventing the wheel when there are so many fascinating new problems waiting out there.</p>
<p>To behave like a hacker, you have to believe that the thinking time of other hackers is precious — so much so that it’s almost a moral duty for you to share information, solve problems and then give the solutions away just so other hackers can solve new problems instead of having to perpetually re-address old ones.</p>
<p>Note, however, that “No problem should ever have to be solved twice.” does not imply that you have to consider all existing solutions sacred, or that there is only one right solution to any given problem. Often, we learn a lot about the problem that we didn’t know before by studying the first cut at a solution. It’s OK, and often necessary, to decide that we can do better. What’s not OK is artificial technical, legal, or institutional barriers (like closed-source code) that prevent a good solution from being re-used and force people to re-invent wheels.</p>
<p>(You don’t have to believe that you’re obligated to give all your creative product away, though the hackers that do are the ones that get most respect from other hackers. It’s consistent with hacker values to sell enough of it to keep you in food and rent and computers. It’s fine to use your hacking skills to support a family or even get rich, as long as you don’t forget your loyalty to your art and your fellow hackers while doing it.)</p>
<ol>
<li>Boredom and drudgery are evil.</li>
</ol>
<p>Hackers (and creative people in general) should never be bored or have to drudge at stupid repetitive work, because when this happens it means they aren’t doing what only they can do — solve new problems. This wastefulness hurts everybody. Therefore boredom and drudgery are not just unpleasant but actually evil.</p>
<p>To behave like a hacker, you have to believe this enough to want to automate away the boring bits as much as possible, not just for yourself but for everybody else (especially other hackers).</p>
<p>(There is one apparent exception to this. Hackers will sometimes do things that may seem repetitive or boring to an observer as a mind-clearing exercise, or in order to acquire a skill or have some particular kind of experience you can’t have otherwise. But this is by choice — nobody who can think should ever be forced into a situation that bores them.)</p>
<ol>
<li>Freedom is good.</li>
</ol>
<p>Hackers are naturally anti-authoritarian. Anyone who can give you orders can stop you from solving whatever problem you’re being fascinated by — and, given the way authoritarian minds work, will generally find some appallingly stupid reason to do so. So the authoritarian attitude has to be fought wherever you find it, lest it smother you and other hackers.</p>
<p>(This isn’t the same as fighting all authority. Children need to be guided and criminals restrained. A hacker may agree to accept some kinds of authority in order to get something he wants more than the time he spends following orders. But that’s a limited, conscious bargain; the kind of personal surrender authoritarians want is not on offer.)</p>
<p>Authoritarians thrive on censorship and secrecy. And they distrust voluntary cooperation and information-sharing — they only like ‘cooperation’ that they control. So to behave like a hacker, you have to develop an instinctive hostility to censorship, secrecy, and the use of force or deception to compel responsible adults. And you have to be willing to act on that belief.</p>
<ol>
<li>Attitude is no substitute for competence.</li>
</ol>
<p>To be a hacker, you have to develop some of these attitudes. But copping an attitude alone won’t make you a hacker, any more than it will make you a champion athlete or a rock star. Becoming a hacker will take intelligence, practice, dedication, and hard work.</p>
<p>Therefore, you have to learn to distrust attitude and respect competence of every kind. Hackers won’t let posers waste their time, but they worship competence — especially competence at hacking, but competence at anything is valued. Competence at demanding skills that few can master is especially good, and competence at demanding skills that involve mental acuteness, craft, and concentration is best.</p>
<p>If you revere competence, you’ll enjoy developing it in yourself — the hard work and dedication will become a kind of intense play rather than drudgery. That attitude is vital to becoming a hacker.</p>
<p>Basic Hacking Skills</p>
<ol>
<li>Learn how to program.</li>
<li>Get one of the open-source Unixes and learn to use and run it.</li>
<li>Learn how to use the World Wide Web and write HTML.</li>
<li>If you don’t have functional English, learn it.<br>The hacker attitude is vital, but skills are even more vital. Attitude is no substitute for competence, and there’s a certain basic toolkit of skills which you have to have before any hacker will dream of calling you one.</li>
</ol>
<p>This toolkit changes slowly over time as technology creates new skills and makes old ones obsolete. For example, it used to include programming in machine language, and didn’t until recently involve HTML. But right now it pretty clearly includes the following:</p>
<ol>
<li>Learn how to program.</li>
</ol>
<p>This, of course, is the fundamental hacking skill. If you don’t know any computer languages, I recommend starting with Python. It is cleanly designed, well documented, and relatively kind to beginners. Despite being a good first language, it is not just a toy; it is very powerful and flexible and well suited for large projects. I have written a more detailed evaluation of Python. Good tutorials are available at the Python web site; there’s an excellent third-party one at Computer Science Circles.</p>
<p>I used to recommend Java as a good language to learn early, but this critique has changed my mind (search for “The Pitfalls of Java as a First Programming Language” within it). A hacker cannot, as they devastatingly put it “approach problem-solving like a plumber in a hardware store”; you have to know what the components actually do. Now I think it is probably best to learn C and Lisp first, then Java.</p>
<p>There is perhaps a more general point here. If a language does too much for you, it may be simultaneously a good tool for production and a bad one for learning. It’s not only languages that have this problem; web application frameworks like RubyOnRails, CakePHP, Django may make it too easy to reach a superficial sort of understanding that will leave you without resources when you have to tackle a hard problem, or even just debug the solution to an easy one.</p>
<p>If you get into serious programming, you will have to learn C, the core language of Unix. C++ is very closely related to C; if you know one, learning the other will not be difficult. Neither language is a good one to try learning as your first, however. And, actually, the more you can avoid programming in C the more productive you will be.</p>
<p>C is very efficient, and very sparing of your machine’s resources. Unfortunately, C gets that efficiency by requiring you to do a lot of low-level management of resources (like memory) by hand. All that low-level code is complex and bug-prone, and will soak up huge amounts of your time on debugging. With today’s machines as powerful as they are, this is usually a bad tradeoff — it’s smarter to use a language that uses the machine’s time less efficiently, but your time much more efficiently. Thus, Python.</p>
<p>Other languages of particular importance to hackers include Perl and LISP. Perl is worth learning for practical reasons; it’s very widely used for active web pages and system administration, so that even if you never write Perl you should learn to read it. Many people use Perl in the way I suggest you should use Python, to avoid C programming on jobs that don’t require C’s machine efficiency. You will need to be able to understand their code.</p>
<p>LISP is worth learning for a different reason — the profound enlightenment experience you will have when you finally get it. That experience will make you a better programmer for the rest of your days, even if you never actually use LISP itself a lot. (You can get some beginning experience with LISP fairly easily by writing and modifying editing modes for the Emacs text editor, or Script-Fu plugins for the GIMP.)</p>
<p>It’s best, actually, to learn all five of Python, C/C++, Java, Perl, and LISP. Besides being the most important hacking languages, they represent very different approaches to programming, and each will educate you in valuable ways.</p>
<p>But be aware that you won’t reach the skill level of a hacker or even merely a programmer simply by accumulating languages — you need to learn how to think about programming problems in a general way, independent of any one language. To be a real hacker, you need to get to the point where you can learn a new language in days by relating what’s in the manual to what you already know. This means you should learn several very different languages.</p>
<p>I can’t give complete instructions on how to learn to program here — it’s a complex skill. But I can tell you that books and courses won’t do it — many, maybe most of the best hackers are self-taught. You can learn language features — bits of knowledge — from books, but the mind-set that makes that knowledge into living skill can be learned only by practice and apprenticeship. What will do it is (a) reading code and (b) writing code.</p>
<p>Peter Norvig, who is one of Google’s top hackers and the co-author of the most widely used textbook on AI, has written an excellent essay called Teach Yourself Programming in Ten Years. His “recipe for programming success” is worth careful attention.</p>
<p>Learning to program is like learning to write good natural language. The best way to do it is to read some stuff written by masters of the form, write some things yourself, read a lot more, write a little more, read a lot more, write some more … and repeat until your writing begins to develop the kind of strength and economy you see in your models.</p>
<p>I have had more to say about this learning process in How To Learn Hacking. It’s a simple set of instructions, but not an easy one.</p>
<p>Finding good code to read used to be hard, because there were few large programs available in source for fledgeling hackers to read and tinker with. This has changed dramatically; open-source software, programming tools, and operating systems (all built by hackers) are now widely available. Which brings me neatly to our next topic…</p>
<ol>
<li>Get one of the open-source Unixes and learn to use and run it.</li>
</ol>
<p>I’ll assume you have a personal computer or can get access to one. (Take a moment to appreciate how much that means. The hacker culture originally evolved back when computers were so expensive that individuals could not own them.) The single most important step any newbie can take toward acquiring hacker skills is to get a copy of Linux or one of the BSD-Unixes, install it on a personal machine, and run it.</p>
<p>Yes, there are other operating systems in the world besides Unix. But they’re distributed in binary — you can’t read the code, and you can’t modify it. Trying to learn to hack on a Microsoft Windows machine or under any other closed-source system is like trying to learn to dance while wearing a body cast.</p>
<p>Under Mac OS X it’s possible, but only part of the system is open source — you’re likely to hit a lot of walls, and you have to be careful not to develop the bad habit of depending on Apple’s proprietary code. If you concentrate on the Unix under the hood you can learn some useful things.</p>
<p>Unix is the operating system of the Internet. While you can learn to use the Internet without knowing Unix, you can’t be an Internet hacker without understanding Unix. For this reason, the hacker culture today is pretty strongly Unix-centered. (This wasn’t always true, and some old-time hackers still aren’t happy about it, but the symbiosis between Unix and the Internet has become strong enough that even Microsoft’s muscle doesn’t seem able to seriously dent it.)</p>
<p>So, bring up a Unix — I like Linux myself but there are other ways (and yes, you can run both Linux and Microsoft Windows on the same machine). Learn it. Run it. Tinker with it. Talk to the Internet with it. Read the code. Modify the code. You’ll get better programming tools (including C, LISP, Python, and Perl) than any Microsoft operating system can dream of hosting, you’ll have fun, and you’ll soak up more knowledge than you realize you’re learning until you look back on it as a master hacker.</p>
<p>For more about learning Unix, see The Loginataka. You might also want to have a look at The Art Of Unix Programming.</p>
<p>The blog Let’s Go Larval! is a window on the learning process of a a new Linux user that I think is unusually lucid and helpful. The post How I Learned Linux makes a good starting point.</p>
<p>To get your hands on a Linux, see the Linux Online! site; you can download from there or (better idea) find a local Linux user group to help you with installation.</p>
<p>During the first ten years of this HOWTO’s life, I reported that from a new user’s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable “Unity” desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better.</p>
<p>You can find BSD Unix help and resources at www.bsd.org.</p>
<p>A good way to dip your toes in the water is to boot up what Linux fans call a live CD, a distribution that runs entirely off a CD or USB stick without having to modify your hard disk. This may be slow, because CDs are slow, but it’s a way to get a look at the possibilities without having to do anything drastic.</p>
<p>I have written a primer on the basics of Unix and the Internet.</p>
<p>I used to recommend against installing either Linux or BSD as a solo project if you’re a newbie. Nowadays the installers have gotten good enough that doing it entirely on your own is possible, even for a newbie. Nevertheless, I still recommend making contact with your local Linux user’s group and asking for help. It can’t hurt, and may smooth the process.</p>
<ol>
<li>Learn how to use the World Wide Web and write HTML.</li>
</ol>
<p>Most of the things the hacker culture has built do their work out of sight, helping run factories and offices and universities without any obvious impact on how non-hackers live. The Web is the one big exception, the huge shiny hacker toy that even politicians admit has changed the world. For this reason alone (and a lot of other good ones as well) you need to learn how to work the Web.</p>
<p>This doesn’t just mean learning how to drive a browser (anyone can do that), but learning how to write HTML, the Web’s markup language. If you don’t know how to program, writing HTML will teach you some mental habits that will help you learn. So build a home page.</p>
<p>But just having a home page isn’t anywhere near good enough to make you a hacker. The Web is full of home pages. Most of them are pointless, zero-content sludge — very snazzy-looking sludge, mind you, but sludge all the same (for more on this see The HTML Hell Page).</p>
<p>To be worthwhile, your page must have content — it must be interesting and/or useful to other hackers. And that brings us to the next topic…</p>
<ol>
<li>If you don’t have functional English, learn it.</li>
</ol>
<p>As an American and native English-speaker myself, I have previously been reluctant to suggest this, lest it be taken as a sort of cultural imperialism. But several native speakers of other languages have urged me to point out that English is the working language of the hacker culture and the Internet, and that you will need to know it to function in the hacker community.</p>
<p>Back around 1991 I learned that many hackers who have English as a second language use it in technical discussions even when they share a birth tongue; it was reported to me at the time that English has a richer technical vocabulary than any other language and is therefore simply a better tool for the job. For similar reasons, translations of technical books written in English are often unsatisfactory (when they get done at all).</p>
<p>Linus Torvalds, a Finn, comments his code in English (it apparently never occurred to him to do otherwise). His fluency in English has been an important factor in his ability to recruit a worldwide community of developers for Linux. It’s an example worth following.</p>
<p>Being a native English-speaker does not guarantee that you have language skills good enough to function as a hacker. If your writing is semi-literate, ungrammatical, and riddled with misspellings, many hackers (including myself) will tend to ignore you. While sloppy writing does not invariably mean sloppy thinking, we’ve generally found the correlation to be strong — and we have no use for sloppy thinkers. If you can’t yet write competently, learn to.</p>
<p>Status in the Hacker Culture</p>
<ol>
<li>Write open-source software</li>
<li>Help test and debug open-source software</li>
<li>Publish useful information</li>
<li>Help keep the infrastructure working</li>
<li>Serve the hacker culture itself<br>Like most cultures without a money economy, hackerdom runs on reputation. You’re trying to solve interesting problems, but how interesting they are, and whether your solutions are really good, is something that only your technical peers or superiors are normally equipped to judge.</li>
</ol>
<p>Accordingly, when you play the hacker game, you learn to keep score primarily by what other hackers think of your skill (this is why you aren’t really a hacker until other hackers consistently call you one). This fact is obscured by the image of hacking as solitary work; also by a hacker-cultural taboo (gradually decaying since the late 1990s but still potent) against admitting that ego or external validation are involved in one’s motivation at all.</p>
<p>Specifically, hackerdom is what anthropologists call a gift culture. You gain status and reputation in it not by dominating other people, nor by being beautiful, nor by having things other people want, but rather by giving things away. Specifically, by giving away your time, your creativity, and the results of your skill.</p>
<p>There are basically five kinds of things you can do to be respected by hackers:</p>
<ol>
<li>Write open-source software</li>
</ol>
<p>The first (the most central and most traditional) is to write programs that other hackers think are fun or useful, and give the program sources away to the whole hacker culture to use.</p>
<p>(We used to call these works “free software”, but this confused too many people who weren’t sure exactly what “free” was supposed to mean. Most of us now prefer the term “open-source” software).</p>
<p>Hackerdom’s most revered demigods are people who have written large, capable programs that met a widespread need and given them away, so that now everyone uses them.</p>
<p>But there’s a bit of a fine historical point here. While hackers have always looked up to the open-source developers among them as our community’s hardest core, before the mid-1990s most hackers most of the time worked on closed source. This was still true when I wrote the first version of this HOWTO in 1996; it took the mainstreaming of open-source software after 1997 to change things. Today, “the hacker community” and “open-source developers” are two descriptions for what is essentially the same culture and population — but it is worth remembering that this was not always so. (For more on this, see the section called “Historical Note: Hacking, Open Source, and Free Software”.)</p>
<ol>
<li>Help test and debug open-source software</li>
</ol>
<p>They also serve who stand and debug open-source software. In this imperfect world, we will inevitably spend most of our software development time in the debugging phase. That’s why any open-source author who’s thinking will tell you that good beta-testers (who know how to describe symptoms clearly, localize problems well, can tolerate bugs in a quickie release, and are willing to apply a few simple diagnostic routines) are worth their weight in rubies. Even one of these can make the difference between a debugging phase that’s a protracted, exhausting nightmare and one that’s merely a salutary nuisance.</p>
<p>If you’re a newbie, try to find a program under development that you’re interested in and be a good beta-tester. There’s a natural progression from helping test programs to helping debug them to helping modify them. You’ll learn a lot this way, and generate good karma with people who will help you later on.</p>
<ol>
<li>Publish useful information</li>
</ol>
<p>Another good thing is to collect and filter useful and interesting information into web pages or documents like Frequently Asked Questions (FAQ) lists, and make those generally available.</p>
<p>Maintainers of major technical FAQs get almost as much respect as open-source authors.</p>
<ol>
<li>Help keep the infrastructure working</li>
</ol>
<p>The hacker culture (and the engineering development of the Internet, for that matter) is run by volunteers. There’s a lot of necessary but unglamorous work that needs done to keep it going — administering mailing lists, moderating newsgroups, maintaining large software archive sites, developing RFCs and other technical standards.</p>
<p>People who do this sort of thing well get a lot of respect, because everybody knows these jobs are huge time sinks and not as much fun as playing with code. Doing them shows dedication.</p>
<ol>
<li>Serve the hacker culture itself</li>
</ol>
<p>Finally, you can serve and propagate the culture itself (by, for example, writing an accurate primer on how to become a hacker :-)). This is not something you’ll be positioned to do until you’ve been around for while and become well-known for one of the first four things.</p>
<p>The hacker culture doesn’t have leaders, exactly, but it does have culture heroes and tribal elders and historians and spokespeople. When you’ve been in the trenches long enough, you may grow into one of these. Beware: hackers distrust blatant ego in their tribal elders, so visibly reaching for this kind of fame is dangerous. Rather than striving for it, you have to sort of position yourself so it drops in your lap, and then be modest and gracious about your status.</p>
<p>The Hacker/Nerd Connection</p>
<p>Contrary to popular myth, you don’t have to be a nerd to be a hacker. It does help, however, and many hackers are in fact nerds. Being something of a social outcast helps you stay concentrated on the really important things, like thinking and hacking.</p>
<p>For this reason, many hackers have adopted the label ‘geek’ as a badge of pride — it’s a way of declaring their independence from normal social expectations (as well as a fondness for other things like science fiction and strategy games that often go with being a hacker). The term ‘nerd’ used to be used this way back in the 1990s, back when ‘nerd’ was a mild pejorative and ‘geek’ a rather harsher one; sometime after 2000 they switched places, at least in U.S. popular culture, and there is now even a significant geek-pride culture among people who aren’t techies.</p>
<p>If you can manage to concentrate enough on hacking to be good at it and still have a life, that’s fine. This is a lot easier today than it was when I was a newbie in the 1970s; mainstream culture is much friendlier to techno-nerds now. There are even growing numbers of people who realize that hackers are often high-quality lover and spouse material.</p>
<p>If you’re attracted to hacking because you don’t have a life, that’s OK too — at least you won’t have trouble concentrating. Maybe you’ll get a life later on.</p>
<p>Points For Style</p>
<p>Again, to be a hacker, you have to enter the hacker mindset. There are some things you can do when you’re not at a computer that seem to help. They’re not substitutes for hacking (nothing is) but many hackers do them, and feel that they connect in some basic way with the essence of hacking.</p>
<p>Learn to write your native language well. Though it’s a common stereotype that programmers can’t write, a surprising number of hackers (including all the most accomplished ones I know of) are very able writers.</p>
<p>Read science fiction. Go to science fiction conventions (a good way to meet hackers and proto-hackers).</p>
<p>Join a hackerspace and make things (another good way to meet hackers and proto-hackers).</p>
<p>Train in a martial-arts form. The kind of mental discipline required for martial arts seems to be similar in important ways to what hackers do. The most popular forms among hackers are definitely Asian empty-hand arts such as Tae Kwon Do, various forms of Karate, Kung Fu, Aikido, or Ju Jitsu. Western fencing and Asian sword arts also have visible followings. In places where it’s legal, pistol shooting has been rising in popularity since the late 1990s. The most hackerly martial arts are those which emphasize mental discipline, relaxed awareness, and precise control, rather than raw strength, athleticism, or physical toughness.</p>
<p>Study an actual meditation discipline. The perennial favorite among hackers is Zen (importantly, it is possible to benefit from Zen without acquiring a religion or discarding one you already have). Other styles may work as well, but be careful to choose one that doesn’t require you to believe crazy things.</p>
<p>Develop an analytical ear for music. Learn to appreciate peculiar kinds of music. Learn to play some musical instrument well, or how to sing.</p>
<p>Develop your appreciation of puns and wordplay.</p>
<p>The more of these things you already do, the more likely it is that you are natural hacker material. Why these things in particular is not completely clear, but they’re connected with a mix of left- and right-brain skills that seems to be important; hackers need to be able to both reason logically and step outside the apparent logic of a problem at a moment’s notice.</p>
<p>Work as intensely as you play and play as intensely as you work. For true hackers, the boundaries between “play”, “work”, “science” and “art” all tend to disappear, or to merge into a high-level creative playfulness. Also, don’t be content with a narrow range of skills. Though most hackers self-describe as programmers, they are very likely to be more than competent in several related skills — system administration, web design, and PC hardware troubleshooting are common ones. A hacker who’s a system administrator, on the other hand, is likely to be quite skilled at script programming and web design. Hackers don’t do things by halves; if they invest in a skill at all, they tend to get very good at it.</p>
<p>Finally, a few things not to do.</p>
<p>Don’t use a silly, grandiose user ID or screen name.</p>
<p>Don’t get in flame wars on Usenet (or anywhere else).</p>
<p>Don’t call yourself a ‘cyberpunk’, and don’t waste your time on anybody who does.</p>
<p>Don’t post or email writing that’s full of spelling errors and bad grammar.</p>
<p>The only reputation you’ll make doing any of these things is as a twit. Hackers have long memories — it could take you years to live your early blunders down enough to be accepted.</p>
<p>The problem with screen names or handles deserves some amplification. Concealing your identity behind a handle is a juvenile and silly behavior characteristic of crackers, warez d00dz, and other lower life forms. Hackers don’t do this; they’re proud of what they do and want it associated with their real names. So if you have a handle, drop it. In the hacker culture it will only mark you as a loser.</p>
<p>Historical Note: Hacking, Open Source, and Free Software</p>
<p>When I originally wrote this how-to in late 1996, some of the conditions around it were very different from the way they look today. A few words about these changes may help clarify matters for people who are confused about the relationship of open source, free software, and Linux to the hacker community. If you are not curious about this, you can skip straight to the FAQ and bibliography from here.</p>
<p>The hacker ethos and community as I have described it here long predates the emergence of Linux after 1990; I first became involved with it around 1976, and, its roots are readily traceable back to the early 1960s. But before Linux, most hacking was done on either proprietary operating systems or a handful of quasi-experimental homegrown systems like MIT’s ITS that were never deployed outside of their original academic niches. While there had been some earlier (pre-Linux) attempts to change this situation, their impact was at best very marginal and confined to communities of dedicated true believers which were tiny minorities even within the hacker community, let alone with respect to the larger world of software in general.</p>
<p>What is now called “open source” goes back as far as the hacker community does, but until 1985 it was an unnamed folk practice rather than a conscious movement with theories and manifestos attached to it. This prehistory ended when, in 1985, arch-hacker Richard Stallman (“RMS”) tried to give it a name — “free software”. But his act of naming was also an act of claiming; he attached ideological baggage to the “free software” label which much of the existing hacker community never accepted. As a result, the “free software” label was loudly rejected by a substantial minority of the hacker community (especially among those associated with BSD Unix), and used with serious but silent reservations by a majority of the remainder (including myself).</p>
<p>Despite these reservations, RMS’s claim to define and lead the hacker community under the “free software” banner broadly held until the mid-1990s. It was seriously challenged only by the rise of Linux. Linux gave open-source development a natural home. Many projects issued under terms we would now call open-source migrated from proprietary Unixes to Linux. The community around Linux grew explosively, becoming far larger and more heterogenous than the pre-Linux hacker culture. RMS determinedly attempted to co-opt all this activity into his “free software” movement, but was thwarted by both the exploding diversity of the Linux community and the public skepticism of its founder, Linus Torvalds. Torvalds continued to use the term “free software” for lack of any alternative, but publicly rejected RMS’s ideological baggage. Many younger hackers followed suit.</p>
<p>In 1996, when I first published this Hacker HOWTO, the hacker community was rapidly reorganizing around Linux and a handful of other open-source operating systems (notably those descended from BSD Unix). Community memory of the fact that most of us had spent decades developing closed-source software on closed-source operating systems had not yet begun to fade, but that fact was already beginning to seem like part of a dead past; hackers were, increasingly, defining themselves as hackers by their attachments to open-source projects such as Linux or Apache.</p>
<p>The term “open source”, however, had not yet emerged; it would not do so until early 1998. When it did, most of the hacker community adopted it within the following six months; the exceptions were a minority ideologically attached to the term “free software”. Since 1998, and especially after about 2003, the identification of ‘hacking’ with ‘open-source (and free software) development’ has become extremely close. Today there is little point in attempting to distinguish between these categories, and it seems unlikely that will change in the future.</p>
<p>It is worth remembering, however, that this was not always so.</p>
<p>Other Resources</p>
<p>Paul Graham has written an essay called Great Hackers, and another on Undergraduation, in which he speaks much wisdom.</p>
<p>Younger hackers might find Things Every Hacker Once Knew interesting and useful.</p>
<p>I have also written A Brief History Of Hackerdom.</p>
<p>I have written a paper, The Cathedral and the Bazaar, which explains a lot about how the Linux and open-source cultures work. I have addressed this topic even more directly in its sequel Homesteading the Noosphere.</p>
<p>Rick Moen has written an excellent document on how to run a Linux user group.</p>
<p>Rick Moen and I have collaborated on another document on How To Ask Smart Questions. This will help you seek assistance in a way that makes it more likely that you will actually get it.</p>
<p>If you need instruction in the basics of how personal computers, Unix, and the Internet work, see The Unix and Internet Fundamentals HOWTO.</p>
<p>When you release software or write patches for software, try to follow the guidelines in the Software Release Practice HOWTO.</p>
<p>If you enjoyed the Zen poem, you might also like Rootless Root: The Unix Koans of Master Foo.</p>
<p>Frequently Asked Questions</p>
<p>Q: How do I tell if I am already a hacker?<br>Q: Will you teach me how to hack?<br>Q: How can I get started, then?<br>Q: When do you have to start? Is it too late for me to learn?<br>Q: How long will it take me to learn to hack?<br>Q: Is Visual Basic a good language to start with?<br>Q: Would you help me to crack a system, or teach me how to crack?<br>Q: How can I get the password for someone else’s account?<br>Q: How can I break into/read/monitor someone else’s email?<br>Q: How can I steal channel op privileges on IRC?<br>Q: I’ve been cracked. Will you help me fend off further attacks?<br>Q: I’m having problems with my Windows software. Will you help me?<br>Q: Where can I find some real hackers to talk with?<br>Q: Can you recommend useful books about hacking-related subjects?<br>Q: Do I need to be good at math to become a hacker?<br>Q: What language should I learn first?<br>Q: What kind of hardware do I need?<br>Q: I want to contribute. Can you help me pick a problem to work on?<br>Q: Do I need to hate and bash Microsoft?<br>Q: But won’t open-source software leave programmers unable to make a living?<br>Q: Where can I get a free Unix?<br>Q:</p>
<p>How do I tell if I am already a hacker?</p>
<p>A:</p>
<p>Ask yourself the following three questions:</p>
<p>Do you speak code, fluently?</p>
<p>Do you identify with the goals and values of the hacker community?</p>
<p>Has a well-established member of the hacker community ever called you a hacker?</p>
<p>If you can answer yes to all three of these questions, you are already a hacker. No two alone are sufficient.</p>
<p>The first test is about skills. You probably pass it if you have the minimum technical skills described earlier in this document. You blow right through it if you have had a substantial amount of code accepted by an open-source development project.</p>
<p>The second test is about attitude. If the five principles of the hacker mindset seemed obvious to you, more like a description of the way you already live than anything novel, you are already halfway to passing it. That’s the inward half; the other, outward half is the degree to which you identify with the hacker community’s long-term projects.</p>
<p>Here is an incomplete but indicative list of some of those projects: Does it matter to you that Linux improve and spread? Are you passionate about software freedom? Hostile to monopolies? Do you act on the belief that computers can be instruments of empowerment that make the world a richer and more humane place?</p>
<p>But a note of caution is in order here. The hacker community has some specific, primarily defensive political interests — two of them are defending free-speech rights and fending off “intellectual-property” power grabs that would make open source illegal. Some of those long-term projects are civil-liberties organizations like the Electronic Frontier Foundation, and the outward attitude properly includes support of them. But beyond that, most hackers view attempts to systematize the hacker attitude into an explicit political program with suspicion; we’ve learned, the hard way, that these attempts are divisive and distracting. If someone tries to recruit you to march on your capitol in the name of the hacker attitude, they’ve missed the point. The right response is probably “Shut up and show them the code.”</p>
<p>The third test has a tricky element of recursiveness about it. I observed in the section called “What Is a Hacker?” that being a hacker is partly a matter of belonging to a particular subculture or social network with a shared history, an inside and an outside. In the far past, hackers were a much less cohesive and self-aware group than they are today. But the importance of the social-network aspect has increased over the last thirty years as the Internet has made connections with the core of the hacker subculture easier to develop and maintain. One easy behavioral index of the change is that, in this century, we have our own T-shirts.</p>
<p>Sociologists, who study networks like those of the hacker culture under the general rubric of “invisible colleges”, have noted that one characteristic of such networks is that they have gatekeepers — core members with the social authority to endorse new members into the network. Because the “invisible college” that is hacker culture is a loose and informal one, the role of gatekeeper is informal too. But one thing that all hackers understand in their bones is that not every hacker is a gatekeeper. Gatekeepers have to have a certain degree of seniority and accomplishment before they can bestow the title. How much is hard to quantify, but every hacker knows it when they see it.</p>
<p>Q:</p>
<p>Will you teach me how to hack?</p>
<p>A:</p>
<p>Since first publishing this page, I’ve gotten several requests a week (often several a day) from people to “teach me all about hacking”. Unfortunately, I don’t have the time or energy to do this; my own hacking projects, and working as an open-source advocate, take up 110% of my time.</p>
<p>Even if I did, hacking is an attitude and skill you basically have to teach yourself. You’ll find that while real hackers want to help you, they won’t respect you if you beg to be spoon-fed everything they know.</p>
<p>Learn a few things first. Show that you’re trying, that you’re capable of learning on your own. Then go to the hackers you meet with specific questions.</p>
<p>If you do email a hacker asking for advice, here are two things to know up front. First, we’ve found that people who are lazy or careless in their writing are usually too lazy and careless in their thinking to make good hackers — so take care to spell correctly, and use good grammar and punctuation, otherwise you’ll probably be ignored. Secondly, don’t dare ask for a reply to an ISP account that’s different from the account you’re sending from; we find people who do that are usually thieves using stolen accounts, and we have no interest in rewarding or assisting thievery.</p>
<p>Q:</p>
<p>How can I get started, then?</p>
<p>A:</p>
<p>The best way for you to get started would probably be to go to a LUG (Linux user group) meeting. You can find such groups on the LDP General Linux Information Page; there is probably one near you, possibly associated with a college or university. LUG members will probably give you a Linux if you ask, and will certainly help you install one and get started.</p>
<p>Your next step (and your first step if you can’t find a LUG nearby) should be to find an open-source project that interests you. Start reading code and reviewing bugs. Learn to contribute, and work your way in.</p>
<p>The only way in is by working to improve your skills. If you ask me personally for advice on how to get started, I will tell you these exact same things, because I don’t have any magic shortcuts for you. I will also mentally write you off as a probable loser - because if you lacked the stamina to read this FAQ and the intelligence to understand from it that the only way in is by working to improve your skills, you’re hopeless.</p>
<p>Another interesting possibility is to go visit a hackerspace. There is a burgeoning movement of people creating physical locations - maker’s clubs - where they can hang out to work on hardware and software projects together, or work solo in a cogenial atmosphere. Hackerspaces often collect tools and specialized equipment that would be too expensive or logistically inconvenient for individuals to own. Hackerspaces are easy to find on the Internet; one may be located near you.</p>
<p>Q:</p>
<p>When do you have to start? Is it too late for me to learn?</p>
<p>A:</p>
<p>Any age at which you are motivated to start is a good age. Most people seem to get interested between ages 15 and 20, but I know of exceptions in both directions.</p>
<p>Q:</p>
<p>How long will it take me to learn to hack?</p>
<p>A:</p>
<p>That depends on how talented you are and how hard you work at it. Most people who try can acquire a respectable skill set in eighteen months to two years, if they concentrate. Don’t think it ends there, though; in hacking (as in many other fields) it takes about ten years to achieve mastery. And if you are a real hacker, you will spend the rest of your life learning and perfecting your craft.</p>
<p>Q:</p>
<p>Is Visual Basic a good language to start with?</p>
<p>A:</p>
<p>If you’re asking this question, it almost certainly means you’re thinking about trying to hack under Microsoft Windows. This is a bad idea in itself. When I compared trying to learn to hack under Windows to trying to learn to dance while wearing a body cast, I wasn’t kidding. Don’t go there. It’s ugly, and it never stops being ugly.</p>
<p>There is a specific problem with Visual Basic; mainly that it’s not portable. Though there is a prototype open-source implementations of Visual Basic, the applicable ECMA standards don’t cover more than a small set of its programming interfaces. On Windows most of its library support is proprietary to a single vendor (Microsoft); if you aren’t extremely careful about which features you use — more careful than any newbie is really capable of being — you’ll end up locked into only those platforms Microsoft chooses to support. If you’re starting on a Unix, much better languages with better libraries are available. Python, for example.</p>
<p>Also, like other Basics, Visual Basic is a poorly-designed language that will teach you bad programming habits. No, don’t ask me to describe them in detail; that explanation would fill a book. Learn a well-designed language instead.</p>
<p>One of those bad habits is becoming dependent on a single vendor’s libraries, widgets, and development tools. In general, any language that isn’t fully supported under at least Linux or one of the BSDs, and/or at least three different vendors’ operating systems, is a poor one to learn to hack in.</p>
<p>Q:</p>
<p>Would you help me to crack a system, or teach me how to crack?</p>
<p>A:</p>
<p>No. Anyone who can still ask such a question after reading this FAQ is too stupid to be educable even if I had the time for tutoring. Any emailed requests of this kind that I get will be ignored or answered with extreme rudeness.</p>
<p>Q:</p>
<p>How can I get the password for someone else’s account?</p>
<p>A:</p>
<p>This is cracking. Go away, idiot.</p>
<p>Q:</p>
<p>How can I break into/read/monitor someone else’s email?</p>
<p>A:</p>
<p>This is cracking. Get lost, moron.</p>
<p>Q:</p>
<p>How can I steal channel op privileges on IRC?</p>
<p>A:</p>
<p>This is cracking. Begone, cretin.</p>
<p>Q:</p>
<p>I’ve been cracked. Will you help me fend off further attacks?</p>
<p>A:</p>
<p>No. Every time I’ve been asked this question so far, it’s been from some poor sap running Microsoft Windows. It is not possible to effectively secure Windows systems against crack attacks; the code and architecture simply have too many flaws, which makes securing Windows like trying to bail out a boat with a sieve. The only reliable prevention starts with switching to Linux or some other operating system that is designed to at least be capable of security.</p>
<p>Q:</p>
<p>I’m having problems with my Windows software. Will you help me?</p>
<p>A:</p>
<p>Yes. Go to a DOS prompt and type “format c:”. Any problems you are experiencing will cease within a few minutes.</p>
<p>Q:</p>
<p>Where can I find some real hackers to talk with?</p>
<p>A:</p>
<p>The best way is to find a Unix or Linux user’s group local to you and go to their meetings (you can find links to several lists of user groups on the LDP site at ibiblio).</p>
<p>(I used to say here that you wouldn’t find any real hackers on IRC, but I’m given to understand this is changing. Apparently some real hacker communities, attached to things like GIMP and Perl, have IRC channels now.)</p>
<p>Q:</p>
<p>Can you recommend useful books about hacking-related subjects?</p>
<p>A:</p>
<p>I maintain a Linux Reading List HOWTO that you may find helpful. The Loginataka may also be interesting.</p>
<p>For an introduction to Python, see the tutorial on the Python site.</p>
<p>Q:</p>
<p>Do I need to be good at math to become a hacker?</p>
<p>A:</p>
<p>No. Hacking uses very little formal mathematics or arithmetic. In particular, you won’t usually need trigonometry, calculus or analysis (there are exceptions to this in a handful of specific application areas like 3-D computer graphics). Knowing some formal logic and Boolean algebra is good. Some grounding in finite mathematics (including finite-set theory, combinatorics, and graph theory) can be helpful.</p>
<p>Much more importantly: you need to be able to think logically and follow chains of exact reasoning, the way mathematicians do. While the content of most mathematics won’t help you, you will need the discipline and intelligence to handle mathematics. If you lack the intelligence, there is little hope for you as a hacker; if you lack the discipline, you’d better grow it.</p>
<p>I think a good way to find out if you have what it takes is to pick up a copy of Raymond Smullyan’s book What Is The Name Of This Book?. Smullyan’s playful logical conundrums are very much in the hacker spirit. Being able to solve them is a good sign; enjoying solving them is an even better one.</p>
<p>Q:</p>
<p>What language should I learn first?</p>
<p>A:</p>
<p>HTML if you don’t already know it. There are a lot of glossy, hype-intensive bad HTML books out there, and distressingly few good ones. The one I like best is HTML: The Definitive Guide.</p>
<p>But HTML is not a full programming language. When you’re ready to start programming, I would recommend starting with Python. You will hear a lot of people recommending Perl, but it’s harder to learn and (in my opinion) less well designed.</p>
<p>C is really important, but it’s also much more difficult than either Python or Perl. Don’t try to learn it first.</p>
<p>Windows users, do not settle for Visual Basic. It will teach you bad habits, and it’s not portable off Windows. Avoid.</p>
<p>Q:</p>
<p>What kind of hardware do I need?</p>
<p>A:</p>
<p>It used to be that personal computers were rather underpowered and memory-poor, enough so that they placed artificial limits on a hacker’s learning process. This stopped being true in the mid-1990s; any machine from an Intel 486DX50 up is more than powerful enough for development work, X, and Internet communications, and the smallest disks you can buy today are plenty big enough.</p>
<p>The important thing in choosing a machine on which to learn is whether its hardware is Linux-compatible (or BSD-compatible, should you choose to go that route). Again, this will be true for almost all modern machines. The only really sticky areas are modems and wireless cards; some machines have Windows-specific hardware that won’t work with Linux.</p>
<p>There’s a FAQ on hardware compatibility; the latest version is here.</p>
<p>Q:</p>
<p>I want to contribute. Can you help me pick a problem to work on?</p>
<p>A:</p>
<p>No, because I don’t know your talents or interests. You have to be self-motivated or you won’t stick, which is why having other people choose your direction almost never works.</p>
<p>Q:</p>
<p>Do I need to hate and bash Microsoft?</p>
<p>A:</p>
<p>No, you don’t. Not that Microsoft isn’t loathsome, but there was a hacker culture long before Microsoft and there will still be one long after Microsoft is history. Any energy you spend hating Microsoft would be better spent on loving your craft. Write good code — that will bash Microsoft quite sufficiently without polluting your karma.</p>
<p>Q:</p>
<p>But won’t open-source software leave programmers unable to make a living?</p>
<p>A:</p>
<p>This seems unlikely — so far, the open-source software industry seems to be creating jobs rather than taking them away. If having a program written is a net economic gain over not having it written, a programmer will get paid whether or not the program is going to be open-source after it’s done. And, no matter how much “free” software gets written, there always seems to be more demand for new and customized applications. I’ve written more about this at the Open Source pages.</p>
<p>Q:</p>
<p>Where can I get a free Unix?</p>
<p>A:</p>
<p>If you don’t have a Unix installed on your machine yet, elsewhere on this page I include pointers to where to get the most commonly used free Unix. To be a hacker you need motivation and initiative and the ability to educate yourself. Start now…</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何成为一名黑客&lt;br&gt;——Eric S. Raymond &lt;a href=&quot;&amp;#109;&amp;#x61;&amp;#x69;&amp;#x6c;&amp;#116;&amp;#x6f;&amp;#58;&amp;#x65;&amp;#x73;&amp;#x72;&amp;#x40;&amp;#x74;&amp;#x68;&amp;#121;&amp;#114;&amp;#x73;&amp;#x75;&amp;#x73;&amp;#46;&amp;#x63;&amp;#x6f;&amp;#109;&quot;&gt;&amp;#x65;&amp;#x73;&amp;#x72;&amp;#x40;&amp;#x74;&amp;#x68;&amp;#121;&amp;#114;&amp;#x73;&amp;#x75;&amp;#x73;&amp;#46;&amp;#x63;&amp;#x6f;&amp;#109;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://translations.readthedocs.io/en/latest/hacker_howto.html&quot;&gt;Wang Dingwei &lt;a href=&quot;&amp;#x6d;&amp;#x61;&amp;#105;&amp;#108;&amp;#116;&amp;#x6f;&amp;#58;&amp;#x77;&amp;#x61;&amp;#x6e;&amp;#x67;&amp;#100;&amp;#105;&amp;#x6e;&amp;#x67;&amp;#x77;&amp;#x65;&amp;#x69;&amp;#x38;&amp;#50;&amp;#64;&amp;#x67;&amp;#x6d;&amp;#x61;&amp;#105;&amp;#x6c;&amp;#46;&amp;#x63;&amp;#x6f;&amp;#x6d;&quot;&gt;&amp;#x77;&amp;#x61;&amp;#x6e;&amp;#x67;&amp;#100;&amp;#105;&amp;#x6e;&amp;#x67;&amp;#x77;&amp;#x65;&amp;#x69;&amp;#x38;&amp;#50;&amp;#64;&amp;#x67;&amp;#x6d;&amp;#x61;&amp;#105;&amp;#x6c;&amp;#46;&amp;#x63;&amp;#x6f;&amp;#x6d;&lt;/a&gt;&lt;/a&gt; 基于 Barret 的翻译更正而成。转载请注明出处。&lt;/p&gt;
&lt;p&gt;目录&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为什么会有这份文档？&lt;/li&gt;
&lt;li&gt;什么是黑客？&lt;/li&gt;
&lt;li&gt;黑客的态度&lt;/li&gt;
&lt;li&gt;黑客的基本技能&lt;/li&gt;
&lt;li&gt;提高自己在黑客圈中的地位&lt;/li&gt;
&lt;li&gt;黑客和书呆子(Nerd)的联系&lt;/li&gt;
&lt;li&gt;向黑客的格调靠拢&lt;/li&gt;
&lt;li&gt;关于黑客、开源、以及自由软件的历史&lt;/li&gt;
&lt;li&gt;其它资源&lt;/li&gt;
&lt;li&gt;FAQ（常见问题解答）&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
  </entry>
  
  <entry>
    <title>提问的智慧</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/how-to-ask-questions-the-smart-way/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/how-to-ask-questions-the-smart-way/</id>
    <published>2017-01-20T12:28:06.000Z</published>
    <updated>2017-02-15T13:04:45.417Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.catb.org/~esr/faqs/smart-questions.html" target="_blank" rel="external">How To Ask Questions The Smart Way</a><br>Eric S. Raymond, Rick Moen</p>
<p>翻译者：<a href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/master/README-zh_CN.md" target="_blank" rel="external">2010 by Gasolin, 2015 by Ryan Wu</a></p>
<p>在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。</p>
<a id="more"></a>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>声明<br>简介<br>在提问之前<br>当你提问时<br>慎选提问的论坛<br>Stack Overflow<br>网站和 IRC 论坛</p>
<p>第二步，使用项目邮件列表<br>使用有意义且描述明确的标题<br>使问题容易回复<br>用清晰、正确、精准并合法语法的语句<br>使用易于读取且标准的文件格式发送问题<br>精确的描述问题并言之有物<br>话不在多而在精<br>别动辄声称找到 Bug<br>可以低声下气，但还是要先做功课<br>描述问题症状而非猜测<br>按发生时间先后列出问题症状<br>描述目标而不是过程<br>别要求使用私人电邮回复<br>清楚明确的表达你的问题以及需求<br>询问有关代码的问题时<br>别把自己家庭作业的问题贴上来<br>去掉无意义的提问句<br>即使你很急也不要在标题写紧急<br>礼多人不怪，而且有时还很有帮助<br>问题解决后，加个简短的补充说明</p>
<p>如何解读答案<br>RTFM 和 STFW：如何知道你已完全搞砸了<br>如果还是搞不懂<br>处理无礼的回应<br>如何避免扮演失败者<br>不该问的问题<br>好问题与蠢问题<br>如果得不到回答<br>如何更好地回答问题<br>相关资源<br>鸣谢</p>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>许多项目在他们的使用协助/说明网页中链接了本指南，这么做很好，我们也鼓励大家都这么做。但如果你是负责管理这个项目网页的人，请在超链接附近的显著位置上注明：</p>
<p>本指南不提供此项目的实际支持服务！</p>
<p>我们已经深刻领教到少了上述声明所带来的痛苦。因为少了这点声明，我们不停地被一些白痴纠缠。这些白痴认为既然我们发布了这本指南，那么我们就有责任解决世上所有的技术问题。</p>
<p>如果你是因为需要某些协助而正在阅读这本指南，并且最后离开是因为发现从本指南作者们身上得不到直接的协助，那么你就是我们所说的那些白痴之一。别问我们问题，我们只会忽略你。我们在这本指南中是教你如何从那些真正懂得你所遇到软件或硬件问题的人取得协助，而 99% 的情况下那不会是我们。除非你确定本指南的作者之一刚好是你所遇到的问题领域的专家，否则请不要打扰我们，这样大家都会开心一点。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。</strong> 本指南将教你如何正确的提问以获得你满意的答案。</p>
<p>不只是黑客，现在开放源代码（Open Source）软件已经相当盛行，你常常也可以由其他有经验的使用者身上得到好答案，这是件好事；使用者比起黑客来，往往对那些新手常遇到的问题更宽容一些。然而，将有经验的使用者视为黑客，并采用本指南所提的方法与他们沟通，同样也是能从他们身上得到满意回答的最有效方式。</p>
<p>首先你应该明白，黑客们喜爱有挑战性的问题，或者能激发我们思维的好问题。如果我们并非如此，那我们也不会成为你想询问的对象。如果你给了我们一个值得反复咀嚼玩味的好问题，我们自会对你感激不尽。<strong>好问题是激励，是厚礼。好问题可以提高我们的理解力，而且通常会暴露我们以前从没意识到或者思考过的问题。对黑客而言，”好问题！”是诚挚的大力称赞。</strong></p>
<p>尽管如此，黑客们有着蔑视或傲慢面对简单问题的坏名声，这有时让我们看起来对新手、无知者似乎较有敌意，但其实不是那样的。</p>
<p>我们不讳言我们对那些不愿思考、或者在发问前不做他们该做的事的人的蔑视。那些人是时间杀手 -– 他们只想索取，从不付出，消耗我们可用在更有趣的问题或更值得回答的人身上的时间。我们称这样的人为 失败者（撸瑟） （由于历史原因，我们有时把它拼作 lusers）。</p>
<p>我们意识到许多人只是想使用我们写的软件，他们对学习技术细节没有兴趣。对大多数人而言，电脑只是种工具，是种达到目的的手段而已。他们有自己的生活并且有更要紧的事要做。我们了解这点，也从不指望每个人都对这些让我们着迷的技术问题感兴趣。尽管如此，我们回答问题的风格是指向那些真正对此有兴趣并愿意主动参与解决问题的人，这一点不会变，也不该变。如果连这都变了，我们就是在降低做自己最擅长的事情上的效率。</p>
<p>我们（在很大程度上）是自愿的，从繁忙的生活中抽出时间来解答疑惑，而且时常被提问淹没。所以我们无情的滤掉一些话题，特别是拋弃那些看起来像失败者的家伙，以便更高效的利用时间来回答赢家（winner）的问题。</p>
<p>如果你厌恶我们的态度，高高在上，或过于傲慢，不妨也设身处地想想。我们并没有要求你向我们屈服 – 事实上，我们大多数人非常乐意与你平等地交流，只要你付出小小努力来满足基本要求，我们就会欢迎你加入我们的文化。但让我们帮助那些不愿意帮助自己的人是没有效率的。无知没有关系，但装白痴就是不行。</p>
<p>所以，你不必在技术上很在行才能吸引我们的注意，但你必须表现出能引导你变得在行的特质 – 机敏、有想法、善于观察、乐于主动参与解决问题。如果你做不到这些使你与众不同的事情，我们建议你花点钱找家商业公司签个技术支持服务合同，而不是要求黑客个人无偿地帮助你。</p>
<p>如果你决定向我们求助，当然你也不希望被视为失败者，更不愿成为失败者中的一员。能立刻得到快速并有效答案的最好方法，就是像赢家那样提问 – 聪明、自信、有解决问题的思路，只是偶尔在特定的问题上需要获得一点帮助。</p>
<p>（欢迎对本指南提出改进意见。你可以 email 你的建议至 esr@thyrsus.com 或 respond-auto@linuxmafia.com。然而请注意，本文并非网络礼节的通用指南，而我们通常会拒绝无助于在技术论坛得到有用答案的建议。）</p>
<h2 id="在提问之前"><a href="#在提问之前" class="headerlink" title="在提问之前"></a>在提问之前</h2><p>在你准备要通过电子邮件、新闻群组或者聊天室提出技术问题前，请先做到以下事情：</p>
<ul>
<li>尝试在你准备提问的论坛的旧文章中搜索答案。</li>
<li>尝试上网搜索以找到答案。</li>
<li>尝试阅读手册以找到答案。</li>
<li>尝试阅读常见问题文件（FAQ）以找到答案。</li>
<li>尝试自己检查或试验以找到答案</li>
<li>向你身边的强者朋友打听以找到答案。</li>
<li>如果你是程序开发者，请尝试阅读源代码以找到答案。</li>
</ul>
<p>当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并 <strong>不是一个不劳而获且浪费别人的时间的提问者。</strong> 如果你能一并表达在做了上述努力的过程中所学到的东西会更好，因为我们更乐于回答那些表现出能从答案中学习的人的问题。</p>
<p>运用某些策略，比如先用 Google 搜索你所遇到的各种错误信息（既搜索 Google 论坛，也搜索网页），这样很可能直接就找到了能解决问题的文件或邮件列表线索。即使没有结果，在邮件列表或新闻组寻求帮助时加上一句 我在 Google 中搜过下列句子但没有找到什么有用的东西 也是件好事，即使它只是表明了搜索引擎不能提供哪些帮助。这么做（加上搜索过的字串）也让遇到相似问题的其他人能被搜索引擎引导到你的提问来。</p>
<p>别着急，不要指望几秒钟的 Google 搜索就能解决一个复杂的问题。在向专家求助之前，再阅读一下常见问题文件（FAQ）、放轻松、坐舒服一些，再花点时间思考一下这个问题。相信我们，他们 <strong>能从你的提问看出你做了多少阅读与思考</strong>，如果你是有备而来，将更有可能得到解答。不要将所有问题一股脑拋出，只因你的第一次搜索没有找到答案（或者找到太多答案）。</p>
<p>准备好你的问题，再将问题仔细的思考过一遍，因为 <strong>草率的发问只能得到草率的回答，或者根本得不到任何答案。越是能表现出在寻求帮助前你为解决问题所付出的努力，你越有可能得到实质性的帮助。</strong></p>
<p>小心别问错了问题。如果你的问题基于错误的假设，某个普通黑客（J. Random Hacker）多半会一边在心里想着蠢问题…， 一边用无意义的字面解释来答复你，希望着你会从问题的回答（而非你想得到的答案）中汲取教训。</p>
<p>绝不要自以为够格得到答案，你没有；你并没有。毕竟你没有为这种服务支付任何报酬。你将会是 <strong>自己去挣到一个答案，靠提出有内涵的、有趣的、有思维激励作用的问题 –一个有潜力能贡献社区经验的问题，而不仅仅是被动的从他人处索取知识。</strong></p>
<p>另一方面，表明你愿意在找答案的过程中做点什么是一个非常好的开端。谁能给点提示？、我的这个例子里缺了什么？以及我应该检查什么地方比请把我需要的确切的过程贴出来更容易得到答复。因为你表现出只要有人能指个正确方向，你就有完成它的能力和决心。</p>
<h2 id="当你提问时"><a href="#当你提问时" class="headerlink" title="当你提问时"></a>当你提问时</h2><p>慎选提问的论坛</p>
<p>小心选择你要提问的场合。如果你做了下述的事情，你很可能被忽略掉或者被看作失败者：</p>
<ul>
<li>在与主题不合的论坛上贴出你的问题</li>
<li>在探讨进阶技术问题的论坛张贴非常初级的问题；反之亦然</li>
<li>在太多的不同新闻群组上重复转贴同样的问题（cross-post）</li>
<li>向既非熟人也没有义务解决你问题的人发送私人电邮</li>
</ul>
<p>黑客会剔除掉那些搞错场合的问题，以保护他们沟通的渠道不被无关的东西淹没。你不会想让这种事发生在自己身上的。</p>
<p>因此，第一步是找到对的论坛。再说一次，Google 和其它搜索引擎还是你的朋友，用它们来找到与你遭遇到困难的软硬件问题最相关的网站。通常那儿都有常见问题（FAQ）、邮件列表及相关说明文件的链接。如果你的努力（包括阅读 FAQ）都没有结果，网站上也许还有报告 Bug（Bug-reporting）的流程或链接，如果是这样，连过去看看。</p>
<p>向陌生的人或论坛发送邮件最可能是风险最大的事情。举例来说，别假设一个提供丰富内容的网页的作者会想充当你的免费顾问。不要对你的问题是否会受到欢迎做太乐观的估计 – 如果你不确定，那就向别处发送，或者压根别发。</p>
<p>在选择论坛、新闻群组或邮件列表时，别太相信名字，先看看 FAQ 或者许可书以弄清楚你的问题是否切题。发文前先翻翻已有的话题，这样可以让你感受一下那里的文化。事实上，事先在新闻组或邮件列表的历史记录中搜索与你问题相关的关键词是个极好的主意，也许这样就找到答案了。即使没有，也能帮助你归纳出更好的问题。</p>
<p>别像机关枪似的一次”扫射”所有的帮助渠道，这就像大喊大叫一样会使人不快。要一个一个地来。</p>
<p>搞清楚你的主题！最典型的错误之一是在某种致力于跨平台可移植的语言、套件或工具的论坛中提关于 Unix 或 Windows 操作系统程序界面的问题。如果你不明白为什么这是大错，最好在搞清楚这之间差异之前什么也别问。</p>
<p>一般来说，在仔细挑选的公共论坛中提问，会比在私有论坛中提同样的问题更容易得到有用的回答。有几个理由可以支持这点，一是看潜在的回复者有多少，二是看观众有多少。黑客较愿意回答那些能帮助到许多人的问题。</p>
<p>可以理解的是，老练的黑客和一些热门软件的作者正在接受过多的错发信息。就像那根最后压垮骆驼背的稻草一样，你的加入也有可能使情况走向极端 – 已经好几次了，一些热门软件的作者从自己软件的支持中抽身出来，因为伴随而来涌入其私人邮箱的无用邮件变得无法忍受。</p>
<h2 id="Stack-Overflow"><a href="#Stack-Overflow" class="headerlink" title="Stack Overflow"></a>Stack Overflow</h2><p>搜索，然后 在 Stack Exchange 问。</p>
<p>近年来，Stack Exchange community 社区已经成为回答技术及其他问题的主要渠道，尤其是那些开放源码的项目。</p>
<p>因为 Google 索引是即时的，在看 Stack Exchange 之前先在 Google 搜索。有很高的机率某人已经问了一个类似的问题，而且 Stack Exchange 网站们往往会是搜索结果中最前面几个。如果你在 Google 上没有找到任何答案，你再到特定相关主题的网站去找。用标签（Tag）搜索能让你更缩小你的搜索结果。</p>
<p>Stack Exchange 已经成长到超过一百个网站，以下是最常用的几个站：</p>
<p>Super User 是问一些通用的电脑问题，如果你的问题跟代码或是写程序无关，只是一些网络连线之类的，请到这里。<br>Stack Overflow 是问写程序有关的问题。<br>Server Fault 是问服务器和网管相关的问题。</p>
<p>网站和 IRC 论坛</p>
<p>本地的使用者群组（user group），或者你所用的 Linux 发行版本也许正在宣传他们的网页论坛或 IRC 频道，并提供新手帮助（在一些非英语国家，新手论坛很可能还是邮件列表）， 这些地方是开始提问的好首选，特别是当你觉得遇到的也许只是相对简单或者很普通的问题时。有广告赞助的 IRC 频道是公开欢迎提问的地方，通常可以即时得到回应。</p>
<p>事实上，如果程序出的问题只发生在特定 Linux 发行版提供的版本（这很常见），最好先去该发行版的论坛或邮件列表中提问，再到程序本身的论坛或邮件列表提问。（否则）该项目的黑客可能仅仅回复 “用我们的版本”。</p>
<p>在任何论坛发文以前，先确认一下有没有搜索功能。如果有，就试着搜索一下问题的几个关键词，也许这会有帮助。如果在此之前你已做过通用的网页搜索（你也该这样做），还是再搜索一下论坛，搜索引擎有可能没来得及索引此论坛的全部内容。</p>
<p>通过论坛或 IRC 频道来提供使用者支持服务有增长的趋势，电子邮件则大多为项目开发者间的交流而保留。所以最好先在论坛或 IRC 中寻求与该项目相关的协助。</p>
<p>在使用 IRC 的时候，首先最好不要发布很长的问题描述，有些人称之为频道洪水。最好通过一句话的问题描述来开始聊天。</p>
<h2 id="第二步，使用项目邮件列表"><a href="#第二步，使用项目邮件列表" class="headerlink" title="第二步，使用项目邮件列表"></a>第二步，使用项目邮件列表</h2><p>当某个项目提供开发者邮件列表时，要向列表而不是其中的个别成员提问，即使你确信他能最好地回答你的问题。查一查项目的文件和首页，找到项目的邮件列表并使用它。有几个很好的理由支持我们采用这种办法：</p>
<ul>
<li>任何好到需要向个别开发者提出的问题，也将对整个项目群组有益。反之，如果你认为自己的问题对整个项目群组来说太愚蠢，也不能成为骚扰个别开发者的理由。</li>
<li>向列表提问可以分散开发者的负担，个别开发者（尤其是项目领导人）也许太忙以至于没法回答你的问题。</li>
<li>大多数邮件列表都会被存档，那些被存档的内容将被搜索引擎索引。如果你向列表提问并得到解答，将来其它人可以通过网页搜索找到你的问题和答案，也就不用再次发问了。</li>
<li>如果某些问题经常被问到，开发者可以利用此信息来改进说明文件或软件本身，以使其更清楚。如果只是私下提问，就没有人能看到最常见问题的完整场景。</li>
<li>如果一个项目既有”使用者” 也有”开发者”（或”黑客”）邮件列表或论坛，而你又不会动到那些源代码，那么就向”使用者”列表或论坛提问。不要假设自己会在开发者列表中受到欢迎，那些人多半会将你的提问视为干扰他们开发的噪音。</li>
</ul>
<p>然而，如果你确信你的问题很特别，而且在”使用者” 列表或论坛中几天都没有回复，可以试试前往”开发者”列表或论坛发问。建议你在张贴前最好先暗地里观察几天以了解那里的行事方式（事实上这是参与任何私有或半私有列表的好主意）</p>
<p>如果你找不到一个项目的邮件列表，而只能查到项目维护者的电子邮件地址，尽管向他发信。即使是在这种情况下，也别假设（项目）邮件列表不存在。在你的电子邮件中，请陈述你已经试过但没有找到合适的邮件列表，也提及你不反对将自己的邮件转发给他人（许多人认为，即使没什么秘密，私人电子邮件也不应该被公开。通过允许将你的电子邮件转发他人，你给了相应人员处置你邮件的选择）。</p>
<h2 id="使用有意义且描述明确的标题"><a href="#使用有意义且描述明确的标题" class="headerlink" title="使用有意义且描述明确的标题"></a>使用有意义且描述明确的标题</h2><p>在邮件列表、新闻群组或论坛中，大约 50 字以内的标题是抓住资深专家注意力的好机会。别用喋喋不休的帮帮忙、跪求、急（更别说救命啊！！！！这样让人反感的话，用这种标题会被条件反射式地忽略）来浪费这个机会。不要妄想用你的痛苦程度来打动我们，而是在这点空间中使用极简单扼要的描述方式来提出问题。</p>
<p><strong>一个好标题范例是目标 – 差异式的描述，许多技术支持组织就是这样做的。在目标部分指出是哪一个或哪一组东西有问题，在差异部分则描述与期望的行为不一致的地方。</strong></p>
<p>蠢问题：救命啊！我的笔电不能正常显示了！</p>
<p>聪明问题：X.org 6.8.1 的鼠标游标会变形，某牌显卡 MV1005 芯片组。</p>
<p>更聪明问题：X.org 6.8.1 的鼠标游标，在某牌显卡 MV1005 芯片组环境下 - 会变形。</p>
<p><strong>编写目标 – 差异 式描述的过程有助于你组织对问题的细致思考。</strong> 是什么被影响了？ 仅仅是鼠标游标或者还有其它图形？只在 X.org 的 X 版中出现？或只是出现在 6.8.1 版中？ 是针对某牌显卡芯片组？或者只是其中的 MV1005 型号？ 一个黑客只需瞄一眼就能够立即明白你的环境和你遇到的问题。</p>
<p>总而言之，请想像一下你正在一个只显示标题的存档讨论串（Thread）索引中查寻。让你的标题更好地反映问题，可使下一个搜索类似问题的人能够关注这个讨论串，而不用再次提问相同的问题。</p>
<p>如果你想在回复中提出问题，记得要修改内容标题，以表明你是在问一个问题， 一个看起来像 Re: 测试 或者 Re: 新 bug 的标题很难引起足够重视。另外，在不影响连贯性之下，适当引用并删减前文的内容，能给新来的读者留下线索。</p>
<p>对于讨论串，不要直接点击回复来开始一个全新的讨论串，这将限制你的观众。因为有些邮件阅读程序，比如 mutt ，允许使用者按讨论串排序并通过折叠讨论串来隐藏消息，这样做的人永远看不到你发的消息。</p>
<p>仅仅改变标题还不够。mutt 和其它一些邮件阅读程序还会检查邮件标题以外的其它信息，以便为其指定讨论串。所以宁可发一个全新的邮件。</p>
<p>在网页论坛上，好的提问方式稍有不同，因为讨论串与特定的信息紧密结合，并且通常在讨论串外就看不到里面的内容，故通过回复提问，而非改变标题是可接受的。不是所有论坛都允许在回复中出现分离的标题，而且这样做了基本上没有人会去看。不过，通过回复提问，这本身就是暧昧的做法，因为它们只会被正在查看该标题的人读到。所以，除非你只想在该讨论串当前活跃的人群中提问，不然还是另起炉灶比较好。</p>
<p>使问题容易回复</p>
<p>以请将你的回复寄到……来结束你的问题多半会使你得不到回答。如果你觉得花几秒钟在邮件客户端设置一下回复地址都麻烦，我们也觉得花几秒钟思考你的问题更麻烦。如果你的邮件程序不支持这样做，换个好点的；如果是操作系统不支持这种邮件程序，也换个好点的。</p>
<p>在论坛，要求通过电子邮件回复是非常无礼的，除非你相信回复的信息可能比较敏感（而且有人会为了某些未知的原因，只让你而不是整个论坛知道答案）。如果你只是想在有人回复讨论串时得到电子邮件提醒，可以要求网页论坛发送给你。几乎所有论坛都支持诸如追踪此讨论串、有回复时发送邮件提醒等功能。</p>
<h2 id="用清晰、正确、精准并语法正确的语句"><a href="#用清晰、正确、精准并语法正确的语句" class="headerlink" title="用清晰、正确、精准并语法正确的语句"></a>用清晰、正确、精准并语法正确的语句</h2><p>我们从经验中发现，粗心的提问者通常也会粗心的写程序与思考（我敢打包票）。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。</p>
<p>正确的拼字、标点符号和大小写是很重要的。一般来说，如果你觉得这样做很麻烦，不想在乎这些，那我们也觉得麻烦，不想在乎你的提问。花点额外的精力斟酌一下字句，用不着太僵硬与正式 – 事实上，黑客文化很看重能准确地使用非正式、俚语和幽默的语句。但它必须很准确，而且有迹象表明你是在思考和关注问题。</p>
<p>正确地拼写、使用标点和大小写，不要将its混淆为it’s，loose搞成lose或者将discrete弄成discreet。不要全部用大写，这会被视为无礼的大声嚷嚷（全部小写也好不到哪去，因为不易阅读。Alan Cox 也许可以这样做，但你不行。）</p>
<p>更白话的说，如果你写得像是个半文盲[译注：小白]，那多半得不到理睬。也不要使用即时通讯中的简写或火星文，如将的简化为ㄉ会使你看起来像一个为了少打几个键而省字的小白。更糟的是，如果像个小孩似地鬼画符那绝对是在找死，可以肯定没人会理你（或者最多是给你一大堆指责与挖苦）。</p>
<p>如果在使用非母语的论坛提问，你可以犯点拼写和语法上的小错，但决不能在思考上马虎（没错，我们通常能弄清两者的分别）。同时，除非你知道回复者使用的语言，否则请使用英语书写。繁忙的黑客一般会直接删除用他们看不懂语言写的消息。在网络上英语是通用语言，用英语书写可以将你的问题在尚未被阅读就被直接删除的可能性降到最低。</p>
<p>如果英文是你的外语（Second language），提示潜在回复者你有潜在的语言困难是很好的： [译注：以下附上原文以供使用]</p>
<p>English is not my native language; please excuse typing errors.<br>英文不是我的母语，请原谅我的错字或语法</p>
<p>If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question.<br>如果你说某语言，请寄信/私讯给我；我需要有人协助我翻译我的问题</p>
<p>I am familiar with the technical terms, but some slang expressions and idioms are difficult for me.<br>我对技术名词很熟悉，但对于俗语或是特别用法比较不甚了解。</p>
<p>I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other.<br>我把我的问题用某语言和英文写出来，如果你只用一种语言回答，我会乐意将其翻译成另一种。</p>
<h2 id="使用易于读取且标准的文件格式发送问题"><a href="#使用易于读取且标准的文件格式发送问题" class="headerlink" title="使用易于读取且标准的文件格式发送问题"></a>使用易于读取且标准的文件格式发送问题</h2><p>如果你人为地将问题搞得难以阅读，它多半会被忽略，人们更愿读易懂的问题，所以：</p>
<ul>
<li>使用纯文字而不是 HTML (关闭 HTML 并不难）。</li>
<li>使用 MIME 附件通常是可以的，前提是真正有内容（譬如附带的源代码或 patch），而不仅仅是邮件程序生成的模板（譬如只是信件内容的拷贝）。</li>
<li>不要发送一段文字只是一行句子但自动换行后会变成多行的邮件（这使得回复部分内容非常困难）。设想你的读者是在 80 个字符宽的终端机上阅读邮件，最好设置你的换行分割点小于 80 字。<br>但是，对一些特殊的文件不要设置固定宽度（譬如日志档案拷贝或会话记录）。数据应该原样包含，让回复者有信心他们看到的是和你看到的一样的东西。</li>
<li>在英语论坛中，不要使用Quoted-Printable MIME 编码发送消息。这种编码对于张贴非 ASCII 语言可能是必须的，但很多邮件程序并不支持这种编码。当它们处理换行时，那些文本中四处散布的=20符号既难看也分散注意力，甚至有可能破坏内容的语意。<br>绝对，永远不要指望黑客们阅读使用封闭格式编写的文档，像微软公司的 Word 或 Excel 文件等。大多数黑客对此的反应就像有人将还在冒热气的猪粪倒在你家门口时你的反应一样。即便他们能够处理，他们也很厌恶这么做。</li>
<li>如果你从使用 Windows 的电脑发送电子邮件，关闭微软愚蠢的智能引号功能 （从[选项] &gt; [校订] &gt; [自动校正选项]，勾选掉智能引号单选框），以免在你的邮件中到处散布垃圾字符。</li>
<li>在论坛，勿滥用表情符号和HTML功能（当它们提供时）。一两个表情符号通常没有问题，但花哨的彩色文本倾向于使人认为你是个无能之辈。<strong>过滥地使用表情符号、色彩和字体会使你看来像个傻笑的小姑娘。这通常不是个好主意，除非你只是对性而不是对答案感兴趣。</strong></li>
<li>如果你使用图形用户界面的邮件程序（如微软公司的 Outlook 或者其它类似的），注意它们的默认设置不一定满足这些要求。大多数这类程序有基于选单的查看源代码命令，用它来检查发送文件夹中的邮件，以确保发送的是纯文本文件同时没有一些奇怪的字符。</li>
</ul>
<h2 id="精确的描述问题并言之有物"><a href="#精确的描述问题并言之有物" class="headerlink" title="精确的描述问题并言之有物"></a>精确的描述问题并言之有物</h2><ul>
<li>仔细、清楚地描述你的问题或 Bug 的症状。</li>
<li>描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：Fedora Core 4、Slackware 9.1等）。</li>
<li>描述在提问前你是怎样去研究和理解这个问题的。</li>
<li>描述在提问前为确定问题而采取的诊断步骤。</li>
<li>描述最近做过什么可能相关的硬件或软件变更。</li>
<li>尽可能的提供一个可以重现这个问题的可控环境的方法。</li>
<li>尽量去揣测一个黑客会怎样反问你，在你提问之前预先将黑客们可能遇到的问题回答一遍。</li>
</ul>
<p>以上几点中，当你报告的是你认为可能在代码中的问题时，给黑客一个可以重现你的问题的环境尤其重要。当你这么做时，你得到有效的回答的机会和速度都会大大的提升。</p>
<p>Simon Tatham 写过一篇名为<a href="http://www.chiark.greenend.org.uk/~sgtatham/bugs.html" target="_blank" rel="external">《如何有效的报告 Bug》</a>的出色文章。强力推荐你也读一读。</p>
<p><strong>话不在多而在精</strong></p>
<p>你需要提供精确有内容的信息。这并不是要求你简单的把成堆的出错代码或者资料完全转录到你的提问中。如果你有庞大而复杂的测试样例能重现程序挂掉的情境，尽量将它剪裁得越小越好。</p>
<p>这样做的用处至少有三点。<br>第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加；<br>第二，简化问题使你更有可能得到有用的答案；<br>第三，在精炼你的 bug 报告的过程中，你很可能就自己找到了解决方法或权宜之计。</p>
<p><strong>别动辄声称找到 Bug</strong></p>
<p>当你在使用软件中遇到问题，除非你非常、非常的有根据，不要动辄声称找到了 Bug。提示：除非你能提供解决问题的源代码补丁，或者提供回归测试来表明前一版本中行为不正确，否则你都多半不够完全确信。这同样适用在网页和文件，如果你（声称）发现了文件的Bug，你应该能提供相应位置的修正或替代文件。</p>
<p>请记得，还有许多其它使用者没遇到你发现的问题，否则你在阅读文件或搜索网页时就应该发现了（你在抱怨前已经做了这些，是吧？）。这也意味着很有可能是你弄错了而不是软件本身有问题。</p>
<p>编写软件的人总是非常辛苦地使它尽可能完美。如果你声称找到了 Bug，也就是在质疑他们的能力，即使你是对的，也有可能会冒犯到其中某部分人。当你在标题中嚷嚷着有Bug时，这尤其严重。</p>
<p>提问时，即使你私下非常确信已经发现一个真正的 Bug，最好写得像是你做错了什么。如果真的有 Bug，你会在回复中看到这点。这样做的话，如果真有 Bug，维护者就会向你道歉，这总比你惹恼别人然后欠别人一个道歉要好一点。</p>
<p><strong>低声下气不能代替你的功课</strong></p>
<p>有些人明白他们不该粗鲁或傲慢的提问并要求得到答复，但他们选择另一个极端 – 低声下气：我知道我只是个可悲的新手，一个撸瑟，但…。这既使人困扰，也没有用，尤其是伴随着与实际问题含糊不清的描述时更令人反感。</p>
<p>别用原始灵长类动物的把戏来浪费你我的时间。取而代之的是，尽可能清楚地描述背景条件和你的问题情况。这比低声下气更好地定位了你的位置。</p>
<p>有时网页论坛会设有专为新手提问的版面，如果你真的认为遇到了初学者的问题，到那去就是了，但一样别那么低声下气。</p>
<p><strong>描述问题症状而非你的猜测</strong></p>
<p>告诉黑客们你认为问题是怎样造成的并没什么帮助。（如果你的推断如此有效，还用向别人求助吗？），因此要确信你原原本本告诉了他们问题的症状，而不是你的解释和理论；让黑客们来推测和诊断。如果你认为陈述自己的猜测很重要，清楚地说明这只是你的猜测，并描述为什么它们不起作用。</p>
<p>蠢问题</p>
<p>我在编译内核时接连遇到 SIG11 错误， 我怀疑某条飞线搭在主板的走线上了，这种情况应该怎样检查最好？</p>
<p>聪明问题</p>
<p>我的组装电脑是 FIC-PA2007 主机板搭载 AMD K6/233 CPU（威盛 Apollo VP2 芯片组）， 256MB Corsair PC133 SDRAM 内存，在编译内核时，从开机 20 分钟以后就频频产生 SIG11 错误， 但是在头 20 分钟内从没发生过相同的问题。重新启动也没有用，但是关机一晚上就又能工作 20 分钟。 所有内存都换过了，没有效果。相关部分的标准编译记录如下…。</p>
<p>由于以上这点似乎让许多人觉得难以配合，这里有句话可以提醒你：所有的诊断专家都来自密苏里州。 美国国务院的官方座右铭则是：让我看看（出自国会议员 Willard D. Vandiver 在 1899 年时的讲话：我来自一个出产玉米，棉花，牛蒡和民主党人的国家，滔滔雄辩既不能说服我，也不会让我满意。我来自密苏里州，你必须让我看看。） 针对诊断者而言，这并不是一种怀疑，而只是一种真实而有用的需求，以便让他们看到的是与你看到的原始证据尽可能一致的东西，而不是你的猜测与归纳的结论。所以，大方的展示给我们看吧！</p>
<p><strong>按发生时间先后列出问题症状</strong></p>
<p>问题发生前的一系列操作，往往就是对找出问题最有帮助的线索。因此，你的说明里应该包含你的操作步骤，以及机器和软件的反应，直到问题发生。在命令行处理的情况下，提供一段操作记录（例如运行脚本工具所生成的），并引用相关的若干行（如 20 行）记录会非常有帮助。</p>
<p>如果挂掉的程序有诊断选项（如 -v 的详述开关），试着选择这些能在记录中增加调试信息的选项。记住，多不等于好。试着选取适当的调试级别以便提供有用的信息而不是让读者淹没在垃圾中。</p>
<p>如果你的说明很长（如超过四个段落），在开头简述问题，接下来再按时间顺序详述会有所帮助。这样黑客们在读你的记录时就知道该注意哪些内容了。</p>
<p><strong>描述目标而不是过程</strong></p>
<p>如果你想弄清楚如何做某事（而不是报告一个 Bug），在开头就描述你的目标，然后才陈述重现你所卡住的特定步骤。</p>
<p>经常寻求技术帮助的人在心中有个更高层次的目标，而他们在自以为能达到目标的特定道路上被卡住了，然后跑来问该怎么走，但没有意识到这条路本身就有问题。结果要费很大的劲才能搞定。</p>
<p>蠢问题</p>
<p>我怎样才能从某绘图程序的颜色选择器中取得十六进制的的 RGB 值？</p>
<p>聪明问题</p>
<p>我正试着用替换一幅图片的色码（color table）成自己选定的色码，我现在知道的唯一方法是编辑每个色码区块（table slot）， 但却无法从某绘图程序的颜色选择器取得十六进制的的 RGB 值。</p>
<p>第二种提问法比较聪明，你可能得到像是建议采用另一个更合适的工具的回复。</p>
<p><strong>别要求使用私人电邮回复</strong></p>
<p>黑客们认为问题的解决过程应该公开、透明，此过程中如果更有经验的人注意到不完整或者不当之处，最初的回复才能够、也应该被纠正。同时，作为提供帮助者可以得到一些奖励，奖励就是他的能力和学识被其他同行看到。</p>
<p>当你要求私下回复时，这个过程和奖励都被中止。别这样做，让回复者来决定是否私下回答 – 如果他真这么做了，通常是因为他认为问题编写太差或者太肤浅，以至于对其它人没有兴趣。</p>
<p>这条规则存在一条有限的例外，如果你确信提问可能会引来大量雷同的回复时，那么这个神奇的提问句会是向我发电邮，我将为论坛归纳这些回复。试着将邮件列表或新闻群组从洪水般的雷同回复中解救出来是非常有礼貌的 – 但你必须信守诺言。</p>
<p><strong>清楚明确的表达你的问题以及需求</strong></p>
<p>漫无边际的提问是近乎无休无止的时间黑洞。最有可能给你有用答案的人通常也正是最忙的人（他们忙是因为要亲自完成大部分工作）。这样的人对无节制的时间黑洞相当厌恶，所以他们也倾向于厌恶那些漫无边际的提问。</p>
<p>如果你明确表述需要回答者做什么（如提供指点、发送一段代码、检查你的补丁、或是其他等等），就最有可能得到有用的答案。因为这会定出一个时间和精力的上限，便于回答者能集中精力来帮你。这么做很棒。</p>
<p>要理解专家们所处的世界，请把 <strong>专业技能想像为充裕的资源，而回复的时间则是稀缺的资源。</strong> 你要求他们奉献的时间越少，你越有可能从真正专业而且很忙的专家那里得到解答。</p>
<p>所以，界定一下你的问题，使专家花在辨识你的问题和回答所需要付出的时间减到最少，这技巧对你有用答案相当有帮助 – 但这技巧通常和简化问题有所区别。因此，问我想更好的理解 X，可否指点一下哪有好一点说明？通常比问你能解释一下 X 吗？更好。如果你的代码不能运作，通常请别人看看哪里有问题，比要求别人替你改正要明智得多。</p>
<h2 id="询问有关代码的问题时"><a href="#询问有关代码的问题时" class="headerlink" title="询问有关代码的问题时"></a>询问有关代码的问题时</h2><p>别要求他人帮你调试有问题的代码，不提示一下应该从何入手。张贴几百行的代码，然后说一声：它不能工作会让你完全被忽略。只贴几十行代码，然后说一句：在第七行以后，我期待它显示 <x>，但实际出现的是 <y>比较有可能让你得到回应。</y></x></p>
<p>最有效描述程序问题的方法是提供最精简的 Bug 展示测试示例（bug-demonstrating test case）。什么是最精简的测试示例？那是问题的缩影；一小个程序片段能刚好展示出程序的异常行为，而不包含其他令人分散注意力的内容。怎么制作最精简的测试示例？如果你知道哪一行或哪一段代码会造成异常的行为，复制下来并加入足够重现这个状况的代码（例如，足以让这段代码能被编译/直译/被应用程序处理）。如果你无法将问题缩减到一个特定区块，就复制一份代码并移除不影响产生问题行为的部分。总之，测试示例越小越好（查看话不在多而在精一节）。</p>
<p>一般而言，要得到一段相当精简的测试示例并不太容易，但永远先尝试这样做的是种好习惯。这种方式可以帮助你了解如何自行解决这个问题 —- 而且即使你的尝试不成功，黑客们也会看到你在尝试取得答案的过程中付出了努力，这可以让他们更愿意与你合作。</p>
<p>如果你只是想让别人帮忙审查（Review）一下代码，在信的开头就要说出来，并且一定要提到你认为哪一部分特别需要关注以及为什么。</p>
<p><strong>别把自己家庭作业的问题贴上来</strong></p>
<p>黑客们很擅长分辨哪些问题是家庭作业式的问题；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由你来搞定，你会从中学到东西。你可以要求给点提示，但别要求得到完整的解决方案。</p>
<p>如果你怀疑自己碰到了一个家庭作业式的问题，但仍然无法解决，试试在使用者群组，论坛或（最后一招）在项目的使用者邮件列表或论坛中提问。尽管黑客们会看出来，但一些有经验的使用者也许仍会给你一些提示。</p>
<p><strong>去掉无意义的提问句</strong></p>
<p>避免用无意义的话结束提问，例如有人能帮我吗？或者这有答案吗？。</p>
<p>首先：如果你对问题的描述不是很好，这样问更是画蛇添足。</p>
<p>其次：由于这样问是画蛇添足，黑客们会很厌烦你 – 而且通常会用逻辑上正确，但毫无意义的回答来表示他们的蔑视， 例如：没错，有人能帮你或者不，没答案。</p>
<p>一般来说，避免用 是或否、对或错、有或没有类型的问句，除非你想得到是或否类型的回答。</p>
<p><strong>即使你很急也不要在标题写紧急</strong></p>
<p>这是你的问题，不是我们的。宣称紧急极有可能事与愿违：大多数黑客会直接删除无礼和自私地企图即时引起关注的问题。更严重的是，紧急这个字（或是其他企图引起关注的标题）通常会被垃圾信过滤器过滤掉 – 你希望能看到你问题的人可能永远也看不到。</p>
<p>有半个例外的情况是，如果你是在一些很高调，会使黑客们兴奋的地方，也许值得这样去做。在这种情况下，如果你有时间压力，也很有礼貌地提到这点，人们也许会有兴趣回答快一点。</p>
<p>当然，这风险很大，因为黑客们兴奋的点多半与你的不同。譬如从 NASA 国际空间站（International Space Station）发这样的标题没有问题，但用自我感觉良好的慈善行为或政治原因发肯定不行。事实上，张贴诸如紧急：帮我救救这个毛绒绒的小海豹！肯定让你被黑客忽略或惹恼他们，即使他们认为毛绒绒的小海豹很重要。</p>
<p>如果你觉得这点很不可思议，最好再把这份指南剩下的内容多读几遍，直到你弄懂了再发文。</p>
<p><strong>礼多人不怪，而且有时还很有帮助</strong></p>
<p>彬彬有礼，多用请和谢谢您的关注，或谢谢你的关照。让大家都知道你对他们花时间免费提供帮助心存感激。</p>
<p>坦白说，这一点并没有比清晰、正确、精准并合法语法和避免使用专用格式重要（也不能取而代之）。黑客们一般宁可读有点唐突但技术上鲜明的 Bug 报告，而不是那种有礼但含糊的报告。（如果这点让你不解，记住我们是按问题能教给我们什么来评价问题的价值的）</p>
<p>然而，如果你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。</p>
<p>（我们注意到，自从本指南发布后，从资深黑客那里得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些黑客觉得先谢了意味着事后就不用再感谢任何人的暗示。我们的建议是要么先说先谢了，然后事后再对回复者表示感谢，或者换种方式表达感激，譬如用谢谢你的关注或谢谢你的关照。）</p>
<p><strong>问题解决后，加个简短的补充说明</strong></p>
<p>问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个说明比较恰当。</p>
<p>最理想的方式是向最初提问的话题回复此消息，并在标题中包含已修正，已解决或其它同等含义的明显标记。在人来人往的邮件列表里，一个看见讨论串问题 X和问题 X - 已解决的潜在回复者就明白不用再浪费时间了（除非他个人觉得问题 X的有趣），因此可以利用此时间去解决其它问题。</p>
<p>补充说明不必很长或是很深入；简单的一句你好，原来是网线出了问题！谢谢大家 – Bill比什么也不说要来的好。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇大论更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。</p>
<p>对于有深度的问题，张贴调试记录的摘要是有帮助的。描述问题的最终状态，说明是什么解决了问题，在此之后才指明可以避免的盲点。避免盲点的部分应放在正确的解决方案和其它总结材料之后，而不要将此信息搞成侦探推理小说。列出那些帮助过你的名字，会让你交到更多朋友。</p>
<p>除了有礼貌和有内涵以外，这种类型的补充也有助于他人在邮件列表/新闻群组/论坛中搜索到真正解决你问题的方案，让他们也从中受益。</p>
<p>至少，这种补充有助于让每位参与协助的人因问题的解决而从中得到满足感。如果你自己不是技术专家或者黑客，那就相信我们，这种感觉对于那些你向他们求助的大师或者专家而言，是非常重要的。问题悬而未决会让人灰心；黑客们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次提问时尝到甜头。</p>
<p>思考一下怎样才能避免他人将来也遇到类似的问题，自问写一份文件或加个常见问题（FAQ）会不会有帮助。如果是的话就将它们发给维护者。</p>
<p>在黑客中，这种良好的后继行动实际上比传统的礼节更为重要，也是你如何透过善待他人而赢得声誉的方式，这是非常有价值的资产。</p>
<h2 id="如何解读答案"><a href="#如何解读答案" class="headerlink" title="如何解读答案"></a>如何解读答案</h2><p>RTFM 和 STFW：如何知道你已完全搞砸了</p>
<p>有一个古老而神圣的传统：如果你收到 <strong>RTFM （Read The Fucking Manual）</strong> 的回应，回答者认为你应该去读他妈的手册。当然，基本上他是对的，你应该去读一读。</p>
<p>RTFM 有一个年轻的亲戚。如果你收到 <strong>STFW（Search The Fucking Web）</strong> 的回应，回答者认为你应该到他妈的网上搜索过了。那人多半也是对的，去搜索一下吧。（更温和一点的说法是 Google 是你的朋友！）</p>
<p>在论坛，你也可能被要求去爬爬论坛的旧文。事实上，有人甚至可能热心地为你提供以前解决此问题的讨论串。但不要依赖这种关照，提问前应该先搜索一下旧文。</p>
<p>通常，用这两句之一回答你的人会给你一份包含你需要内容的手册或者一个网址，而且他们打这些字的时候也正在读着。这些答复意味着回答者认为</p>
<ul>
<li>你需要的信息非常容易获得；</li>
<li>你自己去搜索这些信息比灌给你，能让你学到更多。</li>
<li>你不应该因此不爽；依照黑客的标准，他已经表示了对你一定程度的关注，而没有对你的要求视而不见。你应该对他祖母般的慈祥表示感谢。</li>
</ul>
<p>如果还是搞不懂</p>
<p>如果你看不懂回应，别立刻要求对方解释。像你以前试着自己解决问题时那样（利用手册，FAQ，网络，身边的高手），先试着去搞懂他的回应。如果你真的需要对方解释，记得表现出你已经从中学到了点什么。</p>
<p>比方说，如果我回答你：看来似乎是 zentry 卡住了；你应该先清除它。，然后，这是一个很糟的后续问题回应：zentry 是什么？ 好的问法应该是这样：哦~~~我看过说明了但是只有 -z 和 -p 两个参数中提到了 zentries，而且还都没有清楚的解释如何清除它。你是指这两个中的哪一个吗？还是我看漏了什么？</p>
<p>处理无礼的回应</p>
<p>很多黑客圈子中看似无礼的行为并不是存心冒犯。相反，它是直接了当，一针见血式的交流风格，这种风格更注重解决问题，而不是使人感觉舒服而却模模糊糊。</p>
<p>如果你觉得被冒犯了，试着平静地反应。如果有人真的做了出格的事，邮件列表、新闻群组或论坛中的前辈多半会招呼他。如果这没有发生而你却发火了，那么你发火对象的言语可能在黑客社区中看起来是正常的，而你将被视为有错的一方，这将伤害到你获取信息或帮助的机会。</p>
<p>另一方面，你偶而真的会碰到无礼和无聊的言行。与上述相反，对真正的冒犯者狠狠地打击，用犀利的语言将其驳得体无完肤都是可以接受的。然而，在行事之前一定要非常非常的有根据。纠正无礼的言论与开始一场毫无意义的口水战仅一线之隔，黑客们自己莽撞地越线的情况并不鲜见。如果你是新手或外人，避开这种莽撞的机会并不高。如果你想得到的是信息而不是消磨时光，这时最好不要把手放在键盘上以免冒险。</p>
<p>（有些人断言很多黑客都有轻度的自闭症或亚斯伯格综合症，缺少用于润滑人类社会正常交往所需的神经。这既可能是真也可能是假的。如果你自己不是黑客，兴许你认为我们脑袋有问题还能帮助你应付我们的古怪行为。只管这么干好了，我们不在乎。我们喜欢我们现在这个样子，并且通常对病患标记都有站得住脚的怀疑。）</p>
<p>Jeff Bigler 的观察总结和这个相关也值得一读 (<a href="http://www.mit.edu/~jcb/tact.html" target="_blank" rel="external">tact filters</a>)。</p>
<p>在下一节，我们会谈到另一个问题，当你行为不当时所会受到的冒犯。</p>
<h2 id="如何避免扮演失败者"><a href="#如何避免扮演失败者" class="headerlink" title="如何避免扮演失败者"></a>如何避免扮演失败者</h2><p>在黑客社区的论坛中有那么几次你可能会搞砸 – 以本指南所描述到的或类似的方式。而你会在公开场合中被告知你是如何搞砸的，也许攻击的言语中还会带点夹七夹八的颜色。</p>
<p>这种事发生以后，你能做的最糟糕的事莫过于哀嚎你的遭遇、宣称被口头攻击、要求道歉、高声尖叫、憋闷气、威胁诉诸法律、向其雇主报怨、忘了关马桶盖等等。相反地，你该这么做：</p>
<p>熬过去，这很正常。事实上，它是有益健康且合理的。</p>
<p>社区的标准不会自行维持，它们是通过参与者积极而公开地执行来维持的。不要哭嚎所有的批评都应该通过私下的邮件传送，它不是这样运作的。当有人评论你的一个说法有误或者提出不同看法时，坚持声称受到个人攻击也毫无益处，这些都是失败者的态度。</p>
<p>也有其它的黑客论坛，受过高礼节要求的误导，禁止参与者张贴任何对别人帖子挑毛病的消息，并声称如果你不想帮助用户就闭嘴。 结果造成有想法的参与者纷纷离开，这么做只会使它们沦为毫无意义的唠叨与无用的技术论坛。</p>
<p>夸张的讲法是：你要的是友善（以上述方式）还是有用？两个里面挑一个。</p>
<p>记着：当黑客说你搞砸了，并且（无论多么刺耳）告诉你别再这样做时，他正在为关心你和他的社区而行动。对他而言，不理你并将你从他的生活中滤掉更简单。如果你无法做到感谢，至少要表现得有点尊严，别大声哀嚎，也别因为自己是个有戏剧性超级敏感的灵魂和自以为有资格的新来者，就指望别人像对待脆弱的洋娃娃那样对你。</p>
<p>有时候，即使你没有搞砸（或者只是在他的想像中你搞砸了），有些人也会无缘无故地攻击你本人。在这种情况下，抱怨倒是真的会把问题搞砸。</p>
<p>这些来找麻烦的人要么是毫无办法但自以为是专家的不中用家伙，要么就是测试你是否真会搞砸的心理专家。其它读者要么不理睬，要么用自己的方式对付他们。这些来找麻烦的人在给他们自己找麻烦，这点你不用操心。</p>
<p>也别让自己卷入口水战，最好不要理睬大多数的口水战 – 当然，这是在你检验它们只是口水战，并且未指出你有搞砸的地方，同时也没有巧妙地将问题真正的答案藏于其后（这也是有可能的）。</p>
<p><strong>不该问的问题</strong></p>
<p>以下是几个经典蠢问题，以及黑客没回答时心中所想的：</p>
<p>问题：我能在哪找到 X 程序或 X 资源？</p>
<p>问题：我怎样用 X 做 Y？</p>
<p>问题：如何设定我的 shell 提示？</p>
<p>问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？</p>
<p>问题：我的程序/设定/SQL 语句没有用</p>
<p>问题：我的 Windows 电脑有问题，你能帮我吗？</p>
<p>问题：我的程序不会动了，我认为系统工具 X 有问题</p>
<p>问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？</p>
<p>问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？</p>
<p>问题：我能在哪找到 X 程序或 X 资源？<br>回答：就在我找到它的地方啊，白痴 – 搜索引擎的那一头。天哪！难道还有人不会用 Google 吗？</p>
<p>问题：我怎样用 X 做 Y？<br>回答：如果你想解决的是 Y ，提问时别给出可能并不恰当的方法。这种问题说明提问者不但对 X 完全无知，也对 Y 要解决的问题糊涂，还被特定形势禁锢了思维。最好忽略这种人，等他们把问题搞清楚了再说。</p>
<p>问题：如何设定我的 shell 提示？？<br>回答：如果你有足够的智慧提这个问题，你也该有足够的智慧去 RTFM，然后自己去找出来。</p>
<p>问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？<br>回答：试试看就知道了。如果你试过，你既知道了答案，就不用浪费我的时间了。</p>
<p>问题：我的{程序/设定/SQL 语句}不工作<br>回答：这不算是问题吧，我对要我问你二十个问题才找得出你真正问题的问题没兴趣 – 我有更有意思的事要做呢。在看到这类问题的时候，我的反应通常不外如下三种</p>
<p>你还有什么要补充的吗？<br>真糟糕，希望你能搞定。<br>这关我有什么屁事？</p>
<p>问题：我的 Windows 电脑有问题，你能帮我吗？<br>回答：能啊，扔掉微软的垃圾，换个像 Linux 或 BSD 的开放源代码操作系统吧。</p>
<p>注意：如果程序有官方版 Windows 或者与 Windows 有互动（如 Samba），你可以问与 Windows 相关的问题， 只是别对问题是由 Windows 操作系统而不是程序本身造成的回复感到惊讶， 因为 Windows 一般来说实在太烂，这种说法通常都是对的。</p>
<p>问题：我的程序不会动了，我认为系统工具 X 有问题<br>回答：你完全有可能是第一个注意到被成千上万用户反复使用的系统调用与函数库档案有明显缺陷的人，更有可能的是你完全没有根据。不同凡响的说法需要不同凡响的证据，当你这样声称时，你必须有清楚而详尽的缺陷说明文件作后盾。</p>
<p>问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？<br>回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的 Linux 使用群组者寻求实际的指导吧（你能在这儿找到使用者群组的清单）。</p>
<p>注意：如果安装问题与某 Linux 的发行版有关，在它的邮件列表、论坛或本地使用者群组中提问也许是恰当的。此时，应描述问题的准确细节。在此之前，先用 Linux 和所有被怀疑的硬件作关键词仔细搜索。</p>
<p>问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？<br>回答：想要这样做，说明了你是个卑鄙小人；想找个黑客帮你，说明你是个白痴！</p>
<h2 id="好问题与蠢问题"><a href="#好问题与蠢问题" class="headerlink" title="好问题与蠢问题"></a>好问题与蠢问题</h2><p>最后，我将透过举一些例子，来说明怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。</p>
<p>蠢问题：</p>
<p>我可以在哪儿找到关于 Foonly Flurbamatic 的资料？<br>这种问法无非想得到 STFW 这样的回答。</p>
<p>聪明问题：</p>
<p>我用 Google 搜索过 “Foonly Flurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？<br>这个问题已经 STFW 过了，看起来他真的遇到了麻烦。</p>
<p>蠢问题</p>
<p>我从 foo 项目找来的源码没法编译。它怎么这么烂？<br>他觉得都是别人的错，这个傲慢自大的提问者。</p>
<p>聪明问题</p>
<p>foo 项目代码在 Nulix 6.2 版下无法编译通过。我读过了 FAQ，但里面没有提到跟 Nulix 有关的问题。这是我编译过程的记录，我有什么做的不对的地方吗？<br>提问者已经指明了环境，也读过了 FAQ，还列出了错误，并且他没有把问题的责任推到别人头上，他的问题值得被关注。</p>
<p>蠢问题</p>
<p>我的主机板有问题了，谁来帮我？<br>某黑客对这类问题的回答通常是：好的，还要帮你拍拍背和换尿布吗？，然后按下删除键。</p>
<p>聪明问题</p>
<p>我在 S2464 主机板上试过了 X 、 Y 和 Z ，但没什么作用，我又试了 A 、 B 和 C 。请注意当我尝试 C 时的奇怪现象。显然 florbish 正在 grommicking，但结果出人意料。通常在 Athlon MP 主机板上引起 grommicking 的原因是什么？有谁知道接下来我该做些什么测试才能找出问题？<br>这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。</p>
<p>在最后一个问题中，注意告诉我答案和给我启示，指出我还应该做什么诊断工作之间微妙而又重要的区别。</p>
<p>事实上，后一个问题源自于 2001 年 8 月在 Linux 内核邮件列表（lkml）上的一个真实的提问。我（Eric）就是那个提出问题的人。我在 Tyan S2464 主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决这一问题的重要信息。</p>
<p>通过我的提问方法，我给了别人可以咀嚼玩味的东西；我设法让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，并邀请他们与我共同探讨。通过告诉他们我所走过的弯路，以避免他们再浪费时间，我也表明了对他们宝贵时间的尊重。</p>
<p>事后，当我向每个人表示感谢，并且赞赏这次良好的讨论经历的时候， 一个 Linux 内核邮件列表的成员表示，他觉得我的问题得到解决并非由于我是这个列表中的名人，而是因为我用了正确的方式来提问。</p>
<p>黑客从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我像个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，这直接导致了本指南的出现。</p>
<h2 id="如果得不到回答"><a href="#如果得不到回答" class="headerlink" title="如果得不到回答"></a>如果得不到回答</h2><p>如果仍得不到回答，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。</p>
<p>总的来说，简单的重复张贴问题是个很糟的点子。这将被视为无意义的喧闹。有点耐心，知道你问题答案的人可能生活在不同的时区，可能正在睡觉，也有可能你的问题一开始就没有组织好。</p>
<p>你可以通过其他渠道获得帮助，这些渠道通常更适合初学者的需要。</p>
<p>有许多网上的以及本地的使用者群组，由热情的软件爱好者（即使他们可能从没亲自写过任何软件）组成。通常人们组建这样的团体来互相帮助并帮助新手。</p>
<p>另外，你可以向很多商业公司寻求帮助，不论公司大还是小。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了– 完全可能如此 –你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。</p>
<p>对像是 Linux 这种大众化的软件，每个开发者至少会对应到上万名使用者。根本不可能由一个人来处理来自上万名使用者的求助电话。要知道，即使你要为这些协助付费，和你所购买的同类软件相比，你所付出的也是微不足道的（通常封闭源代码软件的技术支持费用比开放源代码软件的要高得多，且内容也没那么丰富）。</p>
<h2 id="如何更好地回答问题"><a href="#如何更好地回答问题" class="headerlink" title="如何更好地回答问题"></a>如何更好地回答问题</h2><p>态度和善一点。问题带来的压力常使人显得无礼或愚蠢，其实并不是这样。</p>
<p>对初犯者私下回复。对那些坦诚犯错之人没有必要当众羞辱，一个真正的新手也许连怎么搜索或在哪找常见问题都不知道。</p>
<p>如果你不确定，一定要说出来！一个听起来权威的错误回复比没有还要糟，别因为听起来像个专家很好玩，就给别人乱指路。要谦虚和诚实，给提问者与同行都树个好榜样。</p>
<p>如果帮不了忙，也别妨碍他。不要在实际步骤上开玩笑，那样也许会毁了使用者的设置 –有些可怜的呆瓜会把它当成真的指令。</p>
<p>试探性的反问以引出更多的细节。如果你做得好，提问者可以学到点东西 –你也可以。试试将蠢问题转变成好问题，别忘了我们都曾是新手。</p>
<p>尽管对那些懒虫抱怨一声 RTFM 是正当的，能指出文件的位置（即使只是建议个 Google 搜索关键词）会更好。</p>
<p>如果你决定回答，就请给出好的答案。当别人正在用错误的工具或方法时别建议笨拙的权宜之计（wordaround），应推荐更好的工具，重新界定问题。</p>
<p>正面的回答问题！如果这个提问者已经很深入的研究而且也表明已经试过 X 、 Y 、 Z 、 A 、 B 、 C 但没得到结果，回答 试试看 A 或是 B 或者 试试 X 、 Y 、 Z 、 A 、 B 、 C 并附上一个链接一点用都没有。</p>
<p>帮助你的社区从问题中学习。当回复一个好问题时，问问自己如何修改相关文件或常见问题文件以免再次解答同样的问题？，接着再向文件维护者发一份补丁。</p>
<p>如果你是在研究一番后才做出的回答，展现你的技巧而不是直接端出结果。毕竟 <strong>授人以鱼不如授人以渔。</strong></p>
<p>相关资源</p>
<p>如果你需要个人电脑、Unix 系统和网络如何运作的基础知识，参阅 <a href="http://en.tldp.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/" target="_blank" rel="external">Unix 系统和网络基本原理</a>。</p>
<p>当你发布软件或补丁时，试着按<a href="http://en.tldp.org/HOWTO/Software-Release-Practice-HOWTO/index.html" target="_blank" rel="external">软件发布实践操作</a>。</p>
<p>鸣谢</p>
<p>Evelyn Mitchel 贡献了一些愚蠢问题例子并启发了编写如何更好地回答问题这一节， Mikhail Ramendik 贡献了一些特别有价值的建议和改进。</p>
<h1 id="How-To-Ask-Questions-The-Smart-Way"><a href="#How-To-Ask-Questions-The-Smart-Way" class="headerlink" title="How To Ask Questions The Smart Way"></a><a href="http://www.catb.org/~esr/faqs/smart-questions.html" target="_blank" rel="external">How To Ask Questions The Smart Way</a></h1><p>Eric Steven Raymond</p>
<p>Thyrsus Enterprises</p>
<pre><code>&lt;esr@thyrsus.com&gt;
</code></pre><p>Rick Moen</p>
<pre><code>&lt;respond-auto@linuxmafia.com&gt;
</code></pre><p>Copyright © 2001,2006,2014 Eric S. Raymond, Rick Moen</p>
<p>Revision History<br>Revision 3.10    21 May 2014    esr<br>New section on Stack Overflow.<br>Revision 3.9    23 Apr 2013    esr<br>URL fixes.<br>Revision 3.8    19 Jun 2012    esr<br>URL fix.<br>Revision 3.7    06 Dec 2010    esr<br>Helpful hints for ESL speakers.<br>Revision 3.7    02 Nov 2010    esr<br>Several translations have disappeared.<br>Revision 3.6    19 Mar 2008    esr<br>Minor update and new links.<br>Revision 3.5    2 Jan 2008    esr<br>Typo fix and some translation links.<br>Revision 3.4    24 Mar 2007    esr<br>New section, “When asking about code”.<br>Revision 3.3    29 Sep 2006    esr<br>Folded in a good suggestion from Kai Niggemann.<br>Revision 3.2    10 Jan 2006    esr<br>Folded in edits from Rick Moen.<br>Revision 3.1    28 Oct 2004    esr<br>Document ‘Google is your friend!’<br>Revision 3.0    2 Feb 2004    esr<br>Major addition of stuff about proper etiquette on Web forums.<br>Table of Contents</p>
<p>Translations<br>Disclaimer<br>Introduction<br>Before You Ask<br>When You Ask<br>Choose your forum carefully<br>Stack Overflow<br>Web and IRC forums<br>As a second step, use project mailing lists<br>Use meaningful, specific subject headers<br>Make it easy to reply<br>Write in clear, grammatical, correctly-spelled language<br>Send questions in accessible, standard formats<br>Be precise and informative about your problem<br>Volume is not precision<br>Don’t rush to claim that you have found a bug<br>Grovelling is not a substitute for doing your homework<br>Describe the problem’s symptoms, not your guesses<br>Describe your problem’s symptoms in chronological order<br>Describe the goal, not the step<br>Don’t ask people to reply by private e-mail<br>Be explicit about your question<br>When asking about code<br>Don’t post homework questions<br>Prune pointless queries<br>Don’t flag your question as “Urgent”, even if it is for you<br>Courtesy never hurts, and sometimes helps<br>Follow up with a brief note on the solution<br>How To Interpret Answers<br>RTFM and STFW: How To Tell You’ve Seriously Screwed Up<br>If you don’t understand…<br>Dealing with rudeness<br>On Not Reacting Like A Loser<br>Questions Not To Ask<br>Good and Bad Questions<br>If You Can’t Get An Answer<br>How To Answer Questions in a Helpful Way<br>Related Resources<br>Acknowledgements<br>Translations</p>
<p>Translations: Bahasa Indonesian Belorussian Brazilo-Portuguese Bulgarian Chinese (Traditional) Croatian Dutch French Georgian German Greek Hindi Irish Gaelic Japanese Lithuanian Polish Portuguese Romanian Russian Serbian Spanish Uzbek If you want to copy, mirror, translate, or excerpt this document, please see my copying policy.</p>
<p>Disclaimer</p>
<p>Many project websites link to this document in their sections on how to get help. That’s fine, it’s the use we intended — but if you are a webmaster creating such a link for your project page, please display prominently near the link notice that we are not a help desk for your project!</p>
<p>We have learned the hard way that without such a notice, we will repeatedly be pestered by idiots who think having published this document makes it our job to solve all the world’s technical problems.</p>
<p>If you’re reading this document because you need help, and you walk away with the impression you can get it directly from the authors of this document, you are one of the idiots we are talking about. Don’t ask us questions. We’ll just ignore you. We are here to show you how to get help from people who actually know about the software or hardware you’re dealing with, but 99.9% of the time that will not be us. Unless you know for certain that one of the authors is an expert on what you’re dealing with, leave us alone and everybody will be happier.</p>
<p>Introduction</p>
<p>In the world of hackers, the kind of answers you get to your technical questions depends as much on the way you ask the questions as on the difficulty of developing the answer. This guide will teach you how to ask questions in a way more likely to get you a satisfactory answer.</p>
<p>Now that use of open source has become widespread, you can often get as good answers from other, more experienced users as from hackers. This is a Good Thing; users tend to be just a little bit more tolerant of the kind of failures newbies often have. Still, treating experienced users like hackers in the ways we recommend here will generally be the most effective way to get useful answers out of them, too.</p>
<p>The first thing to understand is that hackers actually like hard problems and good, thought-provoking questions about them. If we didn’t, we wouldn’t be here. If you give us an interesting question to chew on we’ll be grateful to you; good questions are a stimulus and a gift. Good questions help us develop our understanding, and often reveal problems we might not have noticed or thought about otherwise. Among hackers, “Good question!” is a strong and sincere compliment.</p>
<p>Despite this, hackers have a reputation for meeting simple questions with what looks like hostility or arrogance. It sometimes looks like we’re reflexively rude to newbies and the ignorant. But this isn’t really true.</p>
<p>What we are, unapologetically, is hostile to people who seem to be unwilling to think or to do their own homework before asking questions. People like that are time sinks — they take without giving back, and they waste time we could have spent on another question more interesting and another person more worthy of an answer. We call people like this “losers” (and for historical reasons we sometimes spell it “lusers”).</p>
<p>We realize that there are many people who just want to use the software we write, and who have no interest in learning technical details. For most people, a computer is merely a tool, a means to an end; they have more important things to do and lives to live. We acknowledge that, and don’t expect everyone to take an interest in the technical matters that fascinate us. Nevertheless, our style of answering questions is tuned for people who do take such an interest and are willing to be active participants in problem-solving. That’s not going to change. Nor should it; if it did, we would become less effective at the things we do best.</p>
<p>We’re (largely) volunteers. We take time out of busy lives to answer questions, and at times we’re overwhelmed with them. So we filter ruthlessly. In particular, we throw away questions from people who appear to be losers in order to spend our question-answering time more efficiently, on winners.</p>
<p>If you find this attitude obnoxious, condescending, or arrogant, check your assumptions. We’re not asking you to genuflect to us — in fact, most of us would love nothing more than to deal with you as an equal and welcome you into our culture, if you put in the effort required to make that possible. But it’s simply not efficient for us to try to help people who are not willing to help themselves. It’s OK to be ignorant; it’s not OK to play stupid.</p>
<p>So, while it isn’t necessary to already be technically competent to get attention from us, it is necessary to demonstrate the kind of attitude that leads to competence — alert, thoughtful, observant, willing to be an active partner in developing a solution. If you can’t live with this sort of discrimination, we suggest you pay somebody for a commercial support contract instead of asking hackers to personally donate help to you.</p>
<p>If you decide to come to us for help, you don’t want to be one of the losers. You don’t want to seem like one, either. The best way to get a rapid and responsive answer is to ask it like a person with smarts, confidence, and clues who just happens to need help on one particular problem.</p>
<p>(Improvements to this guide are welcome. You can mail suggestions to esr@thyrsus.com or respond-auto@linuxmafia.com. Note however that this document is not intended to be a general guide to netiquette, and we will generally reject suggestions that are not specifically related to eliciting useful answers in a technical forum.)</p>
<p>Before You Ask</p>
<p>Before asking a technical question by e-mail, or in a newsgroup, or on a website chat board, do the following:</p>
<p>Try to find an answer by searching the archives of the forum or mailing list you plan to post to.</p>
<p>Try to find an answer by searching the Web.</p>
<p>Try to find an answer by reading the manual.</p>
<p>Try to find an answer by reading a FAQ.</p>
<p>Try to find an answer by inspection or experimentation.</p>
<p>Try to find an answer by asking a skilled friend.</p>
<p>If you’re a programmer, try to find an answer by reading the source code.</p>
<p>When you ask your question, display the fact that you have done these things first; this will help establish that you’re not being a lazy sponge and wasting people’s time. Better yet, display what you have learned from doing these things. We like answering questions for people who have demonstrated they can learn from the answers.</p>
<p>Use tactics like doing a Google search on the text of whatever error message you get (searching Google groups as well as Web pages). This might well take you straight to fix documentation or a mailing list thread answering your question. Even if it doesn’t, saying “I googled on the following phrase but didn’t get anything that looked promising” is a good thing to do in e-mail or news postings requesting help, if only because it records what searches won’t help. It will also help to direct other people with similar problems to your thread by linking the search terms to what will hopefully be your problem and resolution thread.</p>
<p>Take your time. Do not expect to be able to solve a complicated problem with a few seconds of Googling. Read and understand the FAQs, sit back, relax and give the problem some thought before approaching experts. Trust us, they will be able to tell from your questions how much reading and thinking you did, and will be more willing to help if you come prepared. Don’t instantly fire your whole arsenal of questions just because your first search turned up no answers (or too many).</p>
<p>Prepare your question. Think it through. Hasty-sounding questions get hasty answers, or none at all. The more you do to demonstrate that having put thought and effort into solving your problem before seeking help, the more likely you are to actually get help.</p>
<p>Beware of asking the wrong question. If you ask one that is based on faulty assumptions, J. Random Hacker is quite likely to reply with a uselessly literal answer while thinking “Stupid question…”, and hoping the experience of getting what you asked for rather than what you needed will teach you a lesson.</p>
<p>Never assume you are entitled to an answer. You are not; you aren’t, after all, paying for the service. You will earn an answer, if you earn it, by asking a substantial, interesting, and thought-provoking question — one that implicitly contributes to the experience of the community rather than merely passively demanding knowledge from others.</p>
<p>On the other hand, making it clear that you are able and willing to help in the process of developing the solution is a very good start. “Would someone provide a pointer?”, “What is my example missing?”, and “What site should I have checked?” are more likely to get answered than “Please post the exact procedure I should use.” because you’re making it clear that you’re truly willing to complete the process if someone can just point you in the right direction.</p>
<p>When You Ask</p>
<p>Choose your forum carefully</p>
<p>Be sensitive in choosing where you ask your question. You are likely to be ignored, or written off as a loser, if you:</p>
<p>post your question to a forum where it’s off topic</p>
<p>post a very elementary question to a forum where advanced technical questions are expected, or vice-versa</p>
<p>cross-post to too many different newsgroups</p>
<p>post a personal e-mail to somebody who is neither an acquaintance of yours nor personally responsible for solving your problem</p>
<p>Hackers blow off questions that are inappropriately targeted in order to try to protect their communications channels from being drowned in irrelevance. You don’t want this to happen to you.</p>
<p>The first step, therefore, is to find the right forum. Again, Google and other Web-searching methods are your friend. Use them to find the project webpage most closely associated with the hardware or software giving you difficulties. Usually it will have links to a FAQ (Frequently Asked Questions) list, and to project mailing lists and their archives. These mailing lists are the final places to go for help, if your own efforts (including reading those FAQs you found) do not find you a solution. The project page may also describe a bug-reporting procedure, or have a link to one; if so, follow it.</p>
<p>Shooting off an e-mail to a person or forum which you are not familiar with is risky at best. For example, do not assume that the author of an informative webpage wants to be your free consultant. Do not make optimistic guesses about whether your question will be welcome — if you’re unsure, send it elsewhere, or refrain from sending it at all.</p>
<p>When selecting a Web forum, newsgroup or mailing list, don’t trust the name by itself too far; look for a FAQ or charter to verify your question is on-topic. Read some of the back traffic before posting so you’ll get a feel for how things are done there. In fact, it’s a very good idea to do a keyword search for words relating to your problem on the newsgroup or mailing list archives before you post. It may find you an answer, and if not it will help you formulate a better question.</p>
<p>Don’t shotgun-blast all the available help channels at once, that’s like yelling and irritates people. Step through them softly.</p>
<p>Know what your topic is! One of the classic mistakes is asking questions about the Unix or Windows programming interface in a forum devoted to a language or library or tool portable across both. If you don’t understand why this is a blunder, you’d be best off not asking any questions at all until you get it.</p>
<p>In general, questions to a well-selected public forum are more likely to get useful answers than equivalent questions to a private one. There are multiple reasons for this. One is simply the size of the pool of potential respondents. Another is the size of the audience; hackers would rather answer questions that educate many people than questions serving only a few.</p>
<p>Understandably, skilled hackers and authors of popular software are already receiving more than their fair share of mis-targeted messages. By adding to the flood, you could in extreme cases even be the straw that breaks the camel’s back — quite a few times, contributors to popular projects have withdrawn their support because collateral damage in the form of useless e-mail traffic to their personal accounts became unbearable.</p>
<p>Stack Overflow</p>
<p>Search, then ask on Stack Exchange</p>
<p>In recent years, the Stack Exchange community of sites has emerged as a major resource for answering technical and other questions and is even the preferred forum for many open-source projects.</p>
<p>Start with a Google search before looking at Stack Exchange; Google indexes it in real time. There’s a very good chance someone has already asked a similar question, and the Stack Exchange sites are often near the top of the search results. If you didn’t find anything through Google, search again on the specific site most relevant to your question (see below). Searching with tags can help narrow down the results.</p>
<p>If you still didn’t find anything, post your question on the one site where it’s most on-topic. Use the formatting tools, especially for code, and add tags that are related to the substance of your question (particularly the name of the programming language, operating system, or library you’re having trouble with). If a commenter asks you for more information, edit your main post to include it. If any answer is helpful, click the up arrow to upvote it; if an answer gives a solution to your problem, click the check under the voting arrows to accept it as correct.</p>
<p>Stack Exchange has grown to over 100 sites, but here are the most likely candidates:</p>
<p>Super User is for questions about general-purpose computing. If your question isn’t about code or programs that you talk to only over a network connection, it probably goes here.</p>
<p>Stack Overflow is for questions about programming.</p>
<p>Server Fault is for questions about server and network administration.</p>
<p>Several projects have their own specific sites, including Android, Ubuntu, TeX/LaTeX, and SharePoint. Check the Stack Exchange site for an up-to-date list.</p>
<p>Web and IRC forums</p>
<p>Your local user group, or your Linux distribution, may advertise a Web forum or IRC channel where newbies can get help. (In non-English-speaking countries newbie forums are still more likely to be mailing lists.) These are good first places to ask, especially if you think you may have tripped over a relatively simple or common problem. An advertised IRC channel is an open invitation to ask questions there and often get answers in real time.</p>
<p>In fact, if you got the program that is giving you problems from a Linux distribution (as is common today), it may be better to ask in the distro’s forum/list before trying the program’s project forum/list. The project’s hackers may just say, “use our build”.</p>
<p>Before posting to any Web forum, check if it has a Search feature. If it does, try a couple of keyword searches for something like your problem; it just might help. If you did a general Web search before (as you should have), search the forum anyway; your Web-wide search engine might not have all of this forum indexed recently.</p>
<p>There is an increasing tendency for projects to do user support over a Web forum or IRC channel, with e-mail reserved more for development traffic. So look for those channels first when seeking project-specific help.</p>
<p>In IRC, it’s probably best not to dump a long problem description on the channel first thing; some people interpret this as channel-flooding. Best to utter a one-line problem description in a way pitched to start a conversation on the channel.</p>
<p>As a second step, use project mailing lists</p>
<p>When a project has a development mailing list, write to the mailing list, not to individual developers, even if you believe you know who can best answer your question. Check the documentation of the project and its homepage for the address of a project mailing list, and use it. There are several good reasons for this policy:</p>
<p>Any question good enough to be asked of one developer will also be of value to the whole group. Contrariwise, if you suspect your question is too dumb for a mailing list, it’s not an excuse to harass individual developers.</p>
<p>Asking questions on the list distributes load among developers. The individual developer (especially if he’s the project leader) may be too busy to answer your questions.</p>
<p>Most mailing lists are archived and the archives are indexed by search engines. If you ask your question on-list and it is answered, a future querent could find your question and the answer on the Web instead of asking it again.</p>
<p>If certain questions are seen to be asked often, developers can use that information to improve the documentation or the software itself to be less confusing. But if those questions are asked in private, nobody has the complete picture of what questions are asked most often.</p>
<p>If a project has both a “user” and a “developer” (or “hacker”) mailing list or Web forum, and you are not hacking on the code, ask in the “user” list/forum. Do not assume that you will be welcome on the developer list, where they’re likely to experience your question as noise disrupting their developer traffic.</p>
<p>However, if you are sure your question is non-trivial, and you get no answer in the “user” list/forum for several days, try the “developer” one. You would be well advised to lurk there for a few daysor at least review the last few days of archived messages, to learn the local folkways before posting (actually this is good advice on any private or semi-private list).</p>
<p>If you cannot find a project’s mailing list address, but only see the address of the maintainer of the project, go ahead and write to the maintainer. But even in that case, don’t assume that the mailing list doesn’t exist. Mention in your e-mail that you tried and could not find the appropriate mailing list. Also mention that you don’t object to having your message forwarded to other people. (Many people believe that private e-mail should remain private, even if there is nothing secret in it. By allowing your message to be forwarded you give your correspondent a choice about how to handle your e-mail.)</p>
<p>Use meaningful, specific subject headers</p>
<p>On mailing lists, newsgroups or Web forums, the subject header is your golden opportunity to attract qualified experts’ attention in around 50 characters or fewer. Don’t waste it on babble like “Please help me” (let alone “PLEASE HELP ME!!!!”; messages with subjects like that get discarded by reflex). Don’t try to impress us with the depth of your anguish; use the space for a super-concise problem description instead.</p>
<p>One good convention for subject headers, used by many tech support organizations, is “object - deviation”. The “object” part specifies what thing or group of things is having a problem, and the “deviation” part describes the deviation from expected behavior.</p>
<p>Stupid:<br>HELP! Video doesn’t work properly on my laptop!</p>
<p>Smart:<br>X.org 6.8.1 misshapen mouse cursor, Fooware MV1005 vid. chipset</p>
<p>Smarter:<br>X.org 6.8.1 mouse cursor on Fooware MV1005 vid. chipset - is misshapen</p>
<p>The process of writing an “object-deviation” description will help you organize your thinking about the problem in more detail. What is affected? Just the mouse cursor or other graphics too? Is this specific to the X.org version of X? To version 6.8.1? Is this specific to Fooware video chipsets? To model MV1005? A hacker who sees the result can immediately understand what it is that you are having a problem with and the problem you are having, at a glance.</p>
<p>More generally, imagine looking at the index of an archive of questions, with just the subject lines showing. Make your subject line reflect your question well enough that the next person searching the archive with a question similar to yours will be able to follow the thread to an answer rather than posting the question again.</p>
<p>If you ask a question in a reply, be sure to change the subject line to indicate that you’re asking a question. A Subject line that looks like “Re: test” or “Re: new bug” is less likely to attract useful amounts of attention. Also, pare quotation of previous messages to the minimum consistent with cluing in new readers.</p>
<p>Do not simply hit reply to a list message in order to start an entirely new thread. This will limit your audience. Some mail readers, like mutt, allow the user to sort by thread and then hide messages in a thread by folding the thread. Folks who do that will never see your message.</p>
<p>Changing the subject is not sufficient. Mutt, and probably other mail readers, looks at other information in the e-mail’s headers to assign it to a thread, not the subject line. Instead start an entirely new e-mail.</p>
<p>On Web forums the rules of good practice are slightly different, because messages are usually much more tightly bound to specific discussion threads and often invisible outside those threads. Changing the subject when asking a question in reply is not essential. Not all forums even allow separate subject lines on replies, and nearly nobody reads them when they do. However, asking a question in a reply is a dubious practice in itself, because it will only be seen by those who are watching this thread. So, unless you are sure you want to ask only the people currently active in the thread, start a new one.</p>
<p>Make it easy to reply</p>
<p>Finishing your query with “Please send your reply to… ” makes it quite unlikely you will get an answer. If you can’t be bothered to take even the few seconds required to set up a correct Reply-To header in your mail agent, we can’t be bothered to take even a few seconds to think about your problem. If your mail program doesn’t permit this, get a better mail program. If your operating system doesn’t support any e-mail programs that permit this, get a better operating system.</p>
<p>In Web forums, asking for a reply by e-mail is outright rude, unless you believe the information may be sensitive (and somebody will, for some unknown reason, let you but not the whole forum know it). If you want an e-mail copy when somebody replies in the thread, request that the Web forum send it; this feature is supported almost everywhere under options like “watch this thread”, “send e-mail on answers”, etc.</p>
<p>Write in clear, grammatical, correctly-spelled language</p>
<p>We’ve found by experience that people who are careless and sloppy writers are usually also careless and sloppy at thinking and coding (often enough to bet on, anyway). Answering questions for careless and sloppy thinkers is not rewarding; we’d rather spend our time elsewhere.</p>
<p>So expressing your question clearly and well is important. If you can’t be bothered to do that, we can’t be bothered to pay attention. Spend the extra effort to polish your language. It doesn’t have to be stiff or formal — in fact, hacker culture values informal, slangy and humorous language used with precision. But it has to be precise; there has to be some indication that you’re thinking and paying attention.</p>
<p>Spell, punctuate, and capitalize correctly. Don’t confuse “its” with “it’s”, “loose” with “lose”, or “discrete” with “discreet”. Don’t TYPE IN ALL CAPS; this is read as shouting and considered rude. (All-smalls is only slightly less annoying, as it’s difficult to read. Alan Cox can get away with it, but you can’t.)</p>
<p>More generally, if you write like a semi-literate boob you will very likely be ignored. So don’t use instant-messaging shortcuts. Spelling “you” as “u” makes you look like a semi-literate boob to save two entire keystrokes. Worse: writing like a l33t script kiddie hax0r is the absolute kiss of death and guarantees you will receive nothing but stony silence (or, at best, a heaping helping of scorn and sarcasm) in return.</p>
<p>If you are asking questions in a forum that does not use your native language, you will get a limited amount of slack for spelling and grammar errors — but no extra slack at all for laziness (and yes, we can usually spot that difference). Also, unless you know what your respondent’s languages are, write in English. Busy hackers tend to simply flush questions in languages they don’t understand, and English is the working language of the Internet. By writing in English you minimize your chances that your question will be discarded unread.</p>
<p>If you are writing in English but it is a second language for you, it is good form to alert potential respondents to potential language difficulties and options for getting around them. Examples:</p>
<p>English is not my native language; please excuse typing errors.</p>
<p>If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question.</p>
<p>I am familiar with the technical terms, but some slang expressions and idioms are difficult for me.</p>
<p>I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other.</p>
<p>Send questions in accessible, standard formats</p>
<p>If you make your question artificially hard to read, it is more likely to be passed over in favor of one that isn’t. So:</p>
<p>Send plain text mail, not HTML. (It’s not hard to turn off HTML.)</p>
<p>MIME attachments are usually OK, but only if they are real content (such as an attached source file or patch), and not merely boilerplate generated by your mail client (such as another copy of your message).</p>
<p>Don’t send e-mail in which entire paragraphs are single multiply-wrapped lines. (This makes it too difficult to reply to just part of the message.) Assume that your respondents will be reading mail on 80-character-wide text displays and set your line wrap accordingly, to something less than 80.</p>
<p>However, do not wrap data (such as log file dumps or session transcripts) at any fixed column width. Data should be included as-is, so respondents can have confidence that they are seeing what you saw.</p>
<p>Don’t send MIME Quoted-Printable encoding to an English-language forum. This encoding can be necessary when you’re posting in a language ASCII doesn’t cover, but many e-mail agents don’t support it. When they break, all those =20 glyphs scattered through the text are ugly and distracting — or may actively sabotage the semantics of your text.</p>
<p>Never, ever expect hackers to be able to read closed proprietary document formats like Microsoft Word or Excel. Most hackers react to these about as well as you would to having a pile of steaming pig manure dumped on your doorstep. Even when they can cope, they resent having to do so.</p>
<p>If you’re sending e-mail from a Windows machine, turn off Microsoft’s problematic “Smart Quotes” feature (From Tools &gt; AutoCorrect Options, clear the smart quotes checkbox under AutoFormat As You Type.). This is so you’ll avoid sprinkling garbage characters through your mail.</p>
<p>In Web forums, do not abuse “smiley” and “HTML” features (when they are present). A smiley or two is usually OK, but colored fancy text tends to make people think you are lame. Seriously overusing smileys and color and fonts will make you come off like a giggly teenage girl, which is not generally a good idea unless you are more interested in sex than answers.</p>
<p>If you’re using a graphical-user-interface mail client such as Netscape Messenger, MS Outlook, or their ilk, beware that it may violate these rules when used with its default settings. Most such clients have a menu-based “View Source” command. Use this on something in your sent-mail folder, verifying sending of plain text without unnecessary attached crud.</p>
<p>Be precise and informative about your problem</p>
<p>Describe the symptoms of your problem or bug carefully and clearly.</p>
<p>Describe the environment in which it occurs (machine, OS, application, whatever). Provide your vendor’s distribution and release level (e.g.: “Fedora Core 7”, “Slackware 9.1”, etc.).</p>
<p>Describe the research you did to try and understand the problem before you asked the question.</p>
<p>Describe the diagnostic steps you took to try and pin down the problem yourself before you asked the question.</p>
<p>Describe any possibly relevant recent changes in your computer or software configuration.</p>
<p>If at all possible, provide a way to reproduce the problem in a controlled environment.</p>
<p>Do the best you can to anticipate the questions a hacker will ask, and answer them in advance in your request for help.</p>
<p>Giving hackers the ability to reproduce the problem in a controlled environment is especially important if you are reporting something you think is a bug in code. When you do this, your odds of getting a useful answer and the speed with which you are likely to get that answer both improve tremendously.</p>
<p>Simon Tatham has written an excellent essay entitled How to Report Bugs Effectively. I strongly recommend that you read it.</p>
<p>Volume is not precision</p>
<p>You need to be precise and informative. This end is not served by simply dumping huge volumes of code or data into a help request. If you have a large, complicated test case that is breaking a program, try to trim it and make it as small as possible.</p>
<p>This is useful for at least three reasons. One: being seen to invest effort in simplifying the question makes it more likely you’ll get an answer, Two: simplifying the question makes it more likely you’ll get a useful answer. Three: In the process of refining your bug report, you may develop a fix or workaround yourself.</p>
<p>Don’t rush to claim that you have found a bug</p>
<p>When you are having problems with a piece of software, don’t claim you have found a bug unless you are very, very sure of your ground. Hint: unless you can provide a source-code patch that fixes the problem, or a regression test against a previous version that demonstrates incorrect behavior, you are probably not sure enough. This applies to webpages and documentation, too; if you have found a documentation “bug”, you should supply replacement text and which pages it should go on.</p>
<p>Remember, there are many other users that are not experiencing your problem. Otherwise you would have learned about it while reading the documentation and searching the Web (you did do that before complaining, didn’t you?). This means that very probably it is you who are doing something wrong, not the software.</p>
<p>The people who wrote the software work very hard to make it work as well as possible. If you claim you have found a bug, you’ll be impugning their competence, which may offend some of them even if you are correct. It’s especially undiplomatic to yell “bug” in the Subject line.</p>
<p>When asking your question, it is best to write as though you assume you are doing something wrong, even if you are privately pretty sure you have found an actual bug. If there really is a bug, you will hear about it in the answer. Play it so the maintainers will want to apologize to you if the bug is real, rather than so that you will owe them an apology if you have messed up.</p>
<p>Grovelling is not a substitute for doing your homework</p>
<p>Some people who get that they shouldn’t behave rudely or arrogantly, demanding an answer, retreat to the opposite extreme of grovelling. “I know I’m just a pathetic newbie loser, but…”. This is distracting and unhelpful. It’s especially annoying when it’s coupled with vagueness about the actual problem.</p>
<p>Don’t waste your time, or ours, on crude primate politics. Instead, present the background facts and your question as clearly as you can. That is a better way to position yourself than by grovelling.</p>
<p>Sometimes Web forums have separate places for newbie questions. If you feel you do have a newbie question, just go there. But don’t grovel there either.</p>
<p>Describe the problem’s symptoms, not your guesses</p>
<p>It’s not useful to tell hackers what you think is causing your problem. (If your diagnostic theories were such hot stuff, would you be consulting others for help?) So, make sure you’re telling them the raw symptoms of what goes wrong, rather than your interpretations and theories. Let them do the interpretation and diagnosis. If you feel it’s important to state your guess, clearly label it as such and describe why that answer isn’t working for you.</p>
<p>Stupid:<br>I’m getting back-to-back SIG11 errors on kernel compiles, and suspect a hairline crack on one of the motherboard traces. What’s the best way to check for those?</p>
<p>Smart:<br>My home-built K6/233 on an FIC-PA2007 motherboard (VIA Apollo VP2 chipset) with 256MB Corsair PC133 SDRAM starts getting frequent SIG11 errors about 20 minutes after power-on during the course of kernel compiles, but never in the first 20 minutes. Rebooting doesn’t restart the clock, but powering down overnight does. Swapping out all RAM didn’t help. The relevant part of a typical compile session log follows.</p>
<p>Since the preceding point seems to be a tough one for many people to grasp, here’s a phrase to remind you: “All diagnosticians are from Missouri.” That US state’s official motto is “Show me” (earned in 1899, when Congressman Willard D. Vandiver said “I come from a country that raises corn and cotton and cockleburs and Democrats, and frothy eloquence neither convinces nor satisfies me. I’m from Missouri. You’ve got to show me.”) In diagnosticians’ case, it’s not a matter of skepticism, but rather a literal, functional need to see whatever is as close as possible to the same raw evidence that you see, rather than your surmises and summaries. Show us.</p>
<p>Describe your problem’s symptoms in chronological order</p>
<p>The clues most useful in figuring out something that went wrong often lie in the events immediately prior. So, your account should describe precisely what you did, and what the machine and software did, leading up to the blowup. In the case of command-line processes, having a session log (e.g., using the script utility) and quoting the relevant twenty or so lines is very useful.</p>
<p>If the program that blew up on you has diagnostic options (such as -v for verbose), try to select options that will add useful debugging information to the transcript. Remember that more is not necessarily better; try to choose a debug level that will inform rather than drowning the reader in junk.</p>
<p>If your account ends up being long (more than about four paragraphs), it might be useful to succinctly state the problem up top, then follow with the chronological tale. That way, hackers will know what to watch for in reading your account.</p>
<p>Describe the goal, not the step</p>
<p>If you are trying to find out how to do something (as opposed to reporting a bug), begin by describing the goal. Only then describe the particular step towards it that you are blocked on.</p>
<p>Often, people who need technical help have a high-level goal in mind and get stuck on what they think is one particular path towards the goal. They come for help with the step, but don’t realize that the path is wrong. It can take substantial effort to get past this.</p>
<p>Stupid:<br>How do I get the color-picker on the FooDraw program to take a hexadecimal RGB value?</p>
<p>Smart:<br>I’m trying to replace the color table on an image with values of my choosing. Right now the only way I can see to do this is by editing each table slot, but I can’t get FooDraw’s color picker to take a hexadecimal RGB value.</p>
<p>The second version of the question is smart. It allows an answer that suggests a tool better suited to the task.</p>
<p>Don’t ask people to reply by private e-mail</p>
<p>Hackers believe solving problems should be a public, transparent process during which a first try at an answer can and should be corrected if someone more knowledgeable notices that it is incomplete or incorrect. Also, helpers get some of their reward for being respondents from being seen to be competent and knowledgeable by their peers.</p>
<p>When you ask for a private reply, you are disrupting both the process and the reward. Don’t do this. It’s the respondent’s choice whether to reply privately — and if he or she does, it’s usually because he or she thinks the question is too ill-formed or obvious to be interesting to others.</p>
<p>There is one limited exception to this rule. If you think the question is such that you are likely to get many answers that are all closely similar, then the magic words are “e-mail me and I’ll summarize the answers for the group”. It is courteous to try and save the mailing list or newsgroup a flood of substantially identical postings — but you have to keep the promise to summarize.</p>
<p>Be explicit about your question</p>
<p>Open-ended questions tend to be perceived as open-ended time sinks. Those people most likely to be able to give you a useful answer are also the busiest people (if only because they take on the most work themselves). People like that are allergic to open-ended time sinks, thus they tend to be allergic to open-ended questions.</p>
<p>You are more likely to get a useful response if you are explicit about what you want respondents to do (provide pointers, send code, check your patch, whatever). This will focus their effort and implicitly put an upper bound on the time and energy a respondent must allocate to helping you. This is good.</p>
<p>To understand the world the experts live in, think of expertise as an abundant resource and time to respond as a scarce one. The less of a time commitment you implicitly ask for, the more likely you are to get an answer from someone really good and really busy.</p>
<p>So it is useful to frame your question to minimize the time commitment required for an expert to field it — but this is often not the same thing as simplifying the question. Thus, for example, “Would you give me a pointer to a good explanation of X?” is usually a smarter question than “Would you explain X, please?”. If you have some malfunctioning code, it is usually smarter to ask for someone to explain what’s wrong with it than it is to ask someone to fix it.</p>
<p>When asking about code</p>
<p>Don’t ask others to debug your broken code without giving a hint what sort of problem they should be searching for. Posting a few hundred lines of code, saying “it doesn’t work”, will get you ignored. Posting a dozen lines of code, saying “after line 7 I was expecting to see <x>, but <y> occurred instead” is much more likely to get you a response.</y></x></p>
<p>The most effective way to be precise about a code problem is to provide a minimal bug-demonstrating test case. What’s a minimal test case? It’s an illustration of the problem; just enough code to exhibit the undesirable behavior and no more. How do you make a minimal test case? If you know what line or section of code is producing the problematic behavior, make a copy of it and add just enough supporting code to produce a complete example (i.e. enough that the source is acceptable to the compiler/interpreter/whatever application processes it). If you can’t narrow it down to a particular section, make a copy of the source and start removing chunks that don’t affect the problematic behavior. The smaller your minimal test case is, the better (see the section called “Volume is not precision”).</p>
<p>Generating a really small minimal test case will not always be possible, but trying to is good discipline. It may help you learn what you need to solve the problem on your own — and even when it doesn’t, hackers like to see that you have tried. It will make them more cooperative.</p>
<p>If you simply want a code review, say as much up front, and be sure to mention what areas you think might particularly need review and why.</p>
<p>Don’t post homework questions</p>
<p>Hackers are good at spotting homework questions; most of us have done them ourselves. Those questions are for you to work out, so that you will learn from the experience. It is OK to ask for hints, but not for entire solutions.</p>
<p>If you suspect you have been passed a homework question, but can’t solve it anyway, try asking in a user group forum or (as a last resort) in a “user” list/forum of a project. While the hackers will spot it, some of the advanced users may at least give you a hint.</p>
<p>Prune pointless queries</p>
<p>Resist the temptation to close your request for help with semantically-null questions like “Can anyone help me?” or “Is there an answer?” First: if you’ve written your problem description halfway competently, such tacked-on questions are at best superfluous. Second: because they are superfluous, hackers find them annoying — and are likely to return logically impeccable but dismissive answers like “Yes, you can be helped” and “No, there is no help for you.”</p>
<p>In general, asking yes-or-no questions is a good thing to avoid unless you want a yes-or-no answer.</p>
<p>Don’t flag your question as “Urgent”, even if it is for you</p>
<p>That’s your problem, not ours. Claiming urgency is very likely to be counter-productive: most hackers will simply delete such messages as rude and selfish attempts to elicit immediate and special attention. Furthermore, the word ‘Urgent’ (and other similar attempts to grab attention in the subject line) often triggers spam filters - your intended recipients might never see it at all!</p>
<p>There is one semi-exception. It can be worth mentioning if you’re using the program in some high-profile place, one that the hackers will get excited about; in such a case, if you’re under time pressure, and you say so politely, people may get interested enough to answer faster.</p>
<p>This is a very risky thing to do, however, because the hackers’ metric for what is exciting probably differs from yours. Posting from the International Space Station would qualify, for example, but posting on behalf of a feel-good charitable or political cause would almost certainly not. In fact, posting “Urgent: Help me save the fuzzy baby seals!” will reliably get you shunned or flamed even by hackers who think fuzzy baby seals are important.</p>
<p>If you find this mysterious, re-read the rest of this how-to repeatedly until you understand it before posting anything at all.</p>
<p>Courtesy never hurts, and sometimes helps</p>
<p>Be courteous. Use “Please” and “Thanks for your attention” or “Thanks for your consideration”. Make it clear you appreciate the time people spend helping you for free.</p>
<p>To be honest, this isn’t as important as (and cannot substitute for) being grammatical, clear, precise and descriptive, avoiding proprietary formats etc.; hackers in general would rather get somewhat brusque but technically sharp bug reports than polite vagueness. (If this puzzles you, remember that we value a question by what it teaches us.)</p>
<p>However, if you’ve got your technical ducks in a row, politeness does increase your chances of getting a useful answer.</p>
<p>(We must note that the only serious objection we’ve received from veteran hackers to this HOWTO is with respect to our previous recommendation to use “Thanks in advance”. Some hackers feel this connotes an intention not to thank anybody afterwards. Our recommendation is to either say “Thanks in advance” first and thank respondents afterwards, or express courtesy in a different way, such as by saying “Thanks for your attention” or “Thanks for your consideration”.)</p>
<p>Follow up with a brief note on the solution</p>
<p>Send a note after the problem has been solved to all who helped you; let them know how it came out and thank them again for their help. If the problem attracted general interest in a mailing list or newsgroup, it’s appropriate to post the followup there.</p>
<p>Optimally, the reply should be to the thread started by the original question posting, and should have ‘FIXED’, ‘RESOLVED’ or an equally obvious tag in the subject line. On mailing lists with fast turnaround, a potential respondent who sees a thread about “Problem X” ending with “Problem X - FIXED” knows not to waste his/her time even reading the thread (unless (s)he personally finds Problem X interesting) and can therefore use that time solving a different problem.</p>
<p>Your followup doesn’t have to be long and involved; a simple “Howdy — it was a failed network cable! Thanks, everyone. - Bill” would be better than nothing. In fact, a short and sweet summary is better than a long dissertation unless the solution has real technical depth. Say what action solved the problem, but you need not replay the whole troubleshooting sequence.</p>
<p>For problems with some depth, it is appropriate to post a summary of the troubleshooting history. Describe your final problem statement. Describe what worked as a solution, and indicate avoidable blind alleys after that. The blind alleys should come after the correct solution and other summary material, rather than turning the follow-up into a detective story. Name the names of people who helped you; you’ll make friends that way.</p>
<p>Besides being courteous and informative, this sort of followup will help others searching the archive of the mailing-list/newsgroup/forum to know exactly which solution helped you and thus may also help them.</p>
<p>Last, and not least, this sort of followup helps everybody who assisted feel a satisfying sense of closure about the problem. If you are not a techie or hacker yourself, trust us that this feeling is very important to the gurus and experts you tapped for help. Problem narratives that trail off into unresolved nothingness are frustrating things; hackers itch to see them resolved. The goodwill that scratching that itch earns you will be very, very helpful to you next time you need to pose a question.</p>
<p>Consider how you might be able to prevent others from having the same problem in the future. Ask yourself if a documentation or FAQ patch would help, and if the answer is yes send that patch to the maintainer.</p>
<p>Among hackers, this sort of good followup behavior is actually more important than conventional politeness. It’s how you get a reputation for playing well with others, which can be a very valuable asset.</p>
<p>How To Interpret Answers</p>
<p>RTFM and STFW: How To Tell You’ve Seriously Screwed Up</p>
<p>There is an ancient and hallowed tradition: if you get a reply that reads “RTFM”, the person who sent it thinks you should have Read The Fucking Manual. He or she is almost certainly right. Go read it.</p>
<p>RTFM has a younger relative. If you get a reply that reads “STFW”, the person who sent it thinks you should have Searched The Fucking Web. He or she is almost certainly right. Go search it. (The milder version of this is when you are told “Google is your friend!”)</p>
<p>In Web forums, you may also be told to search the forum archives. In fact, someone may even be so kind as to provide a pointer to the previous thread where this problem was solved. But do not rely on this consideration; do your archive-searching before asking.</p>
<p>Often, the person telling you to do a search has the manual or the web page with the information you need open, and is looking at it as he or she types. These replies mean that the responder thinks (a) the information you need is easy to find, and (b) you will learn more if you seek out the information than if you have it spoon-fed to you.</p>
<p>You shouldn’t be offended by this; by hacker standards, your respondent is showing you a rough kind of respect simply by not ignoring you. You should instead be thankful for this grandmotherly kindness.</p>
<p>If you don’t understand…</p>
<p>If you don’t understand the answer, do not immediately bounce back a demand for clarification. Use the same tools that you used to try and answer your original question (manuals, FAQs, the Web, skilled friends) to understand the answer. Then, if you still need to ask for clarification, exhibit what you have learned.</p>
<p>For example, suppose I tell you: “It sounds like you’ve got a stuck zentry; you’ll need to clear it.” Then: here’s a bad followup question: “What’s a zentry?” Here’s a good followup question: “OK, I read the man page and zentries are only mentioned under the -z and -p switches. Neither of them says anything about clearing zentries. Is it one of these or am I missing something here?”</p>
<p>Dealing with rudeness</p>
<p>Much of what looks like rudeness in hacker circles is not intended to give offense. Rather, it’s the product of the direct, cut-through-the-bullshit communications style that is natural to people who are more concerned about solving problems than making others feel warm and fuzzy.</p>
<p>When you perceive rudeness, try to react calmly. If someone is really acting out, it is very likely a senior person on the list or newsgroup or forum will call him or her on it. If that doesn’t happen and you lose your temper, it is likely that the person you lose it at was behaving within the hacker community’s norms and you will be considered at fault. This will hurt your chances of getting the information or help you want.</p>
<p>On the other hand, you will occasionally run across rudeness and posturing that is quite gratuitous. The flip-side of the above is that it is acceptable form to slam real offenders quite hard, dissecting their misbehavior with a sharp verbal scalpel. Be very, very sure of your ground before you try this, however. The line between correcting an incivility and starting a pointless flamewar is thin enough that hackers themselves not infrequently blunder across it; if you are a newbie or an outsider, your chances of avoiding such a blunder are low. If you’re after information rather than entertainment, it’s better to keep your fingers off the keyboard than to risk this.</p>
<p>(Some people assert that many hackers have a mild form of autism or Asperger’s Syndrome, and are actually missing some of the brain circuitry that lubricates “normal” human social interaction. This may or may not be true. If you are not a hacker yourself, it may help you cope with our eccentricities if you think of us as being brain-damaged. Go right ahead. We won’t care; we like being whatever it is we are, and generally have a healthy skepticism about clinical labels.)</p>
<p>Jeff Bigler’s observations about tact filters are also relevant and worth reading.</p>
<p>In the next section, we’ll talk about a different issue; the kind of “rudeness” you’ll see when you misbehave.</p>
<p>On Not Reacting Like A Loser</p>
<p>Odds are you’ll screw up a few times on hacker community forums — in ways detailed in this article, or similar. And you’ll be told exactly how you screwed up, possibly with colourful asides. In public.</p>
<p>When this happens, the worst thing you can do is whine about the experience, claim to have been verbally assaulted, demand apologies, scream, hold your breath, threaten lawsuits, complain to people’s employers, leave the toilet seat up, etc. Instead, here’s what you do:</p>
<p>Get over it. It’s normal. In fact, it’s healthy and appropriate.</p>
<p>Community standards do not maintain themselves: They’re maintained by people actively applying them, visibly, in public. Don’t whine that all criticism should have been conveyed via private e-mail: That’s not how it works. Nor is it useful to insist you’ve been personally insulted when someone comments that one of your claims was wrong, or that his views differ. Those are loser attitudes.</p>
<p>There have been hacker forums where, out of some misguided sense of hyper-courtesy, participants are banned from posting any fault-finding with another’s posts, and told “Don’t say anything if you’re unwilling to help the user.” The resulting departure of clueful participants to elsewhere causes them to descend into meaningless babble and become useless as technical forums.</p>
<p>Exaggeratedly “friendly” (in that fashion) or useful: Pick one.</p>
<p>Remember: When that hacker tells you that you’ve screwed up, and (no matter how gruffly) tells you not to do it again, he’s acting out of concern for (1) you and (2) his community. It would be much easier for him to ignore you and filter you out of his life. If you can’t manage to be grateful, at least have a little dignity, don’t whine, and don’t expect to be treated like a fragile doll just because you’re a newcomer with a theatrically hypersensitive soul and delusions of entitlement.</p>
<p>Sometimes people will attack you personally, flame without an apparent reason, etc., even if you don’t screw up (or have only screwed up in their imagination). In this case, complaining is the way to really screw up.</p>
<p>These flamers are either lamers who don’t have a clue but believe themselves to be experts, or would-be psychologists testing whether you’ll screw up. The other readers either ignore them, or find ways to deal with them on their own. The flamers’ behavior creates problems for themselves, which don’t have to concern you.</p>
<p>Don’t let yourself be drawn into a flamewar, either. Most flames are best ignored — after you’ve checked whether they are really flames, not pointers to the ways in which you have screwed up, and not cleverly ciphered answers to your real question (this happens as well).</p>
<p>Questions Not To Ask</p>
<p>Here are some classic stupid questions, and what hackers are thinking when they don’t answer them.</p>
<p>Q: Where can I find program or resource X?<br>Q: How can I use X to do Y?<br>Q: How can I configure my shell prompt?<br>Q: Can I convert an AcmeCorp document into a TeX file using the Bass-o-matic file converter?<br>Q: My {program, configuration, SQL statement} doesn’t work<br>Q: I’m having problems with my Windows machine. Can you help?<br>Q: My program doesn’t work. I think system facility X is broken.<br>Q: I’m having problems installing Linux or X. Can you help?<br>Q: How can I crack root/steal channel-ops privileges/read someone’s e-mail?<br>Q:</p>
<p>Where can I find program or resource X?</p>
<p>A:</p>
<p>The same place I’d find it, fool — at the other end of a web search. Ghod, doesn’t everybody know how to use Google yet?</p>
<p>Q:</p>
<p>How can I use X to do Y?</p>
<p>A:</p>
<p>If what you want is to do Y, you should ask that question without pre-supposing the use of a method that may not be appropriate. Questions of this form often indicate a person who is not merely ignorant about X, but confused about what problem Y they are solving and too fixated on the details of their particular situation. It is generally best to ignore such people until they define their problem better.</p>
<p>Q:</p>
<p>How can I configure my shell prompt?</p>
<p>A:</p>
<p>If you’re smart enough to ask this question, you’re smart enough to RTFM and find out yourself.</p>
<p>Q:</p>
<p>Can I convert an AcmeCorp document into a TeX file using the Bass-o-matic file converter?</p>
<p>A:</p>
<p>Try it and see. If you did that, you’d (a) learn the answer, and (b) stop wasting my time.</p>
<p>Q:</p>
<p>My {program, configuration, SQL statement} doesn’t work</p>
<p>A:</p>
<p>This is not a question, and I’m not interested in playing Twenty Questions to pry your actual question out of you — I have better things to do. On seeing something like this, my reaction is normally of one of the following:</p>
<p>do you have anything else to add to that?</p>
<p>oh, that’s too bad, I hope you get it fixed.</p>
<p>and this has exactly what to do with me?</p>
<p>Q:</p>
<p>I’m having problems with my Windows machine. Can you help?</p>
<p>A:</p>
<p>Yes. Throw out that Microsoft trash and install an open-source operating system like Linux or BSD.</p>
<p>Note: you can ask questions related to Windows machines if they are about a program that does have an official Windows build, or interacts with Windows machines (i.e., Samba). Just don’t be surprised by the reply that the problem is with Windows and not the program, because Windows is so broken in general that this is very often the case.</p>
<p>Q:</p>
<p>My program doesn’t work. I think system facility X is broken.</p>
<p>A:</p>
<p>While it is possible that you are the first person to notice an obvious deficiency in system calls and libraries heavily used by hundreds or thousands of people, it is rather more likely that you are utterly clueless. Extraordinary claims require extraordinary evidence; when you make a claim like this one, you must back it up with clear and exhaustive documentation of the failure case.</p>
<p>Q:</p>
<p>I’m having problems installing Linux or X. Can you help?</p>
<p>A:</p>
<p>No. I’d need hands-on access to your machine to troubleshoot this. Go ask your local Linux user group for hands-on help. (You can find a list of user groups here.)</p>
<p>Note: questions about installing Linux may be appropriate if you’re on a forum or mailing list about a particular distribution, and the problem is with that distro; or on local user groups forums. In this case, be sure to describe the exact details of the failure. But do careful searching first, with “linux” and all suspicious pieces of hardware.</p>
<p>Q:</p>
<p>How can I crack root/steal channel-ops privileges/read someone’s e-mail?</p>
<p>A:</p>
<p>You’re a lowlife for wanting to do such things and a moron for asking a hacker to help you.</p>
<p>Good and Bad Questions</p>
<p>Finally, I’m going to illustrate how to ask questions in a smart way by example; pairs of questions about the same problem, one asked in a stupid way and one in a smart way.</p>
<p>Stupid: Where can I find out stuff about the Foonly Flurbamatic?<br>This question just begs for “STFW” as a reply.</p>
<p>Smart: I used Google to try to find “Foonly Flurbamatic 2600” on the Web, but I got no useful hits. Can I get a pointer to programming information on this device?<br>This one has already STFWed, and sounds like there might be a real problem.</p>
<p>Stupid: I can’t get the code from project foo to compile. Why is it broken?<br>The querent assumes that somebody else screwed up. Arrogant git…</p>
<p>Smart: The code from project foo doesn’t compile under Nulix version 6.2. I’ve read the FAQ, but it doesn’t have anything in it about Nulix-related problems. Here’s a transcript of my compilation attempt; is it something I did?<br>The querent has specified the environment, read the FAQ, is showing the error, and is not assuming his problems are someone else’s fault. This one might be worth some attention.</p>
<p>Stupid: I’m having problems with my motherboard. Can anybody help?<br>J. Random Hacker’s response to this is likely to be “Right. Do you need burping and diapering, too?” followed by a punch of the delete key.</p>
<p>Smart: I tried X, Y, and Z on the S2464 motherboard. When that didn’t work, I tried A, B, and C. Note the curious symptom when I tried C. Obviously the florbish is grommicking, but the results aren’t what one might expect. What are the usual causes of grommicking on Athlon MP motherboards? Anybody got ideas for more tests I can run to pin down the problem?<br>This person, on the other hand, seems worthy of an answer. He/she has exhibited problem-solving intelligence rather than passively waiting for an answer to drop from on high.</p>
<p>In the last question, notice the subtle but important difference between demanding “Give me an answer” and “Please help me figure out what additional diagnostics I can run to achieve enlightenment.”</p>
<p>In fact, the form of that last question is closely based on a real incident that happened in August 2001 on the linux-kernel mailing list (lkml). I (Eric) was the one asking the question that time. I was seeing mysterious lockups on a Tyan S2462 motherboard. The list members supplied the critical information I needed to solve them.</p>
<p>By asking the question in the way I did, I gave people something to chew on; I made it easy and attractive for them to get involved. I demonstrated respect for my peers’ ability and invited them to consult with me as a peer. I also demonstrated respect for the value of their time by telling them the blind alleys I had already run down.</p>
<p>Afterwards, when I thanked everyone and remarked how well the process had worked, an lkml member observed that he thought it had worked not because I’m a “name” on that list, but because I asked the question in the proper form.</p>
<p>Hackers are in some ways a very ruthless meritocracy; I’m certain he was right, and that if I had behaved like a sponge I would have been flamed or ignored no matter who I was. His suggestion that I write up the whole incident as instruction to others led directly to the composition of this guide.</p>
<p>If You Can’t Get An Answer</p>
<p>If you can’t get an answer, please don’t take it personally that we don’t feel we can help you. Sometimes the members of the asked group may simply not know the answer. No response is not the same as being ignored, though admittedly it’s hard to spot the difference from outside.</p>
<p>In general, simply re-posting your question is a bad idea. This will be seen as pointlessly annoying. Have patience: the person with your answer may be in a different time-zone and asleep. Or it may be that your question wasn’t well-formed to begin with.</p>
<p>There are other sources of help you can go to, often sources better adapted to a novice’s needs.</p>
<p>There are many online and local user groups who are enthusiasts about the software, even though they may never have written any software themselves. These groups often form so that people can help each other and help new users.</p>
<p>There are also plenty of commercial companies you can contract with for help, both large and small. Don’t be dismayed at the idea of having to pay for a bit of help! After all, if your car engine blows a head gasket, chances are you would take it to a repair shop and pay to get it fixed. Even if the software didn’t cost you anything, you can’t expect that support to always come for free.</p>
<p>For popular software like Linux, there are at least 10,000 users per developer. It’s just not possible for one person to handle the support calls from over 10,000 users. Remember that even if you have to pay for support, you are still paying much less than if you had to buy the software as well (and support for closed-source software is usually more expensive and less competent than support for open-source software).</p>
<p>How To Answer Questions in a Helpful Way</p>
<p>Be gentle. Problem-related stress can make people seem rude or stupid even when they’re not.</p>
<p>Reply to a first offender off-line. There is no need of public humiliation for someone who may have made an honest mistake. A real newbie may not know how to search archives or where the FAQ is stored or posted.</p>
<p>If you don’t know for sure, say so! A wrong but authoritative-sounding answer is worse than none at all. Don’t point anyone down a wrong path simply because it’s fun to sound like an expert. Be humble and honest; set a good example for both the querent and your peers.</p>
<p>If you can’t help, don’t hinder. Don’t make jokes about procedures that could trash the user’s setup — the poor sap might interpret these as instructions.</p>
<p>Ask probing questions to elicit more details. If you’re good at this, the querent will learn something — and so might you. Try to turn the bad question into a good one; remember we were all newbies once.</p>
<p>While muttering RTFM is sometimes justified when replying to someone who is just a lazy slob, a pointer to documentation (even if it’s just a suggestion to google for a key phrase) is better.</p>
<p>If you’re going to answer the question at all, give good value. Don’t suggest kludgy workarounds when somebody is using the wrong tool or approach. Suggest good tools. Reframe the question.</p>
<p>Answer the actual question! If the querent has been so thorough as to do his or her research and has included in the query that X, Y, Z, A, B, and C have already been tried without good result, it is supremely unhelpful to respond with “Try A or B,” or with a link to something that only says, “Try X, Y, Z, A, B, or C.”.</p>
<p>Help your community learn from the question. When you field a good question, ask yourself “How would the relevant documentation or FAQ have to change so that nobody has to answer this again?” Then send a patch to the document maintainer.</p>
<p>If you did research to answer the question, demonstrate your skills rather than writing as though you pulled the answer out of your butt. Answering one good question is like feeding a hungry person one meal, but teaching them research skills by example is showing them how to grow food for a lifetime.</p>
<p>Related Resources</p>
<p>If you need instruction in the basics of how personal computers, Unix, and the Internet work, see The Unix and Internet Fundamentals HOWTO.</p>
<p>When you release software or write patches for software, try to follow the guidelines in the Software Release Practice HOWTO.</p>
<p>Acknowledgements</p>
<p>Evelyn Mitchell contributed some example stupid questions and inspired the “How To Give A Good Answer” section. Mikhail Ramendik contributed some particularly valuable suggestions for improvements.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.catb.org/~esr/faqs/smart-questions.html&quot;&gt;How To Ask Questions The Smart Way&lt;/a&gt;&lt;br&gt;Eric S. Raymond, Rick Moen&lt;/p&gt;
&lt;p&gt;翻译者：&lt;a href=&quot;https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/master/README-zh_CN.md&quot;&gt;2010 by Gasolin, 2015 by Ryan Wu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
  </entry>
  
  <entry>
    <title>如何有效地报告 Bug</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/how-to-report-bugs-effectively/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/how-to-report-bugs-effectively/</id>
    <published>2017-01-20T12:23:06.000Z</published>
    <updated>2017-02-27T03:50:54.944Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="http://www.chiark.greenend.org.uk/~sgtatham/bugs.html" target="_blank" rel="external">Simon Tatham</a> 专业的自由软件程序员<br>翻译：Dasn</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>为公众写过软件的人，大概都收到过很拙劣的bug（计算机程序代码中的错误或程序运行时的瑕疵——译者注）报告，例如：</p>
<ul>
<li>在报告中说“不好用”；</li>
<li>所报告内容毫无意义；</li>
<li>在报告中用户没有提供足够的信息；</li>
<li>在报告中提供了错误信息；</li>
<li>所报告的问题是由于用户的过失而产生的；</li>
<li>所报告的问题是由于其他程序的错误而产生的；</li>
<li>所报告的问题是由于网络错误而产生的；</li>
</ul>
<p>这便是为什么“技术支持”被认为是一件可怕的工作，因为有拙劣的bug报告需要处理。然而并不是所有的bug报告都令人生厌：我在业余时间维护自由软件，有时我会收到非常清晰、有帮助并且“有内容”的bug报告。在这里我会尽力阐明如何写一个好的bug报告。我非常希望每一个人在报告bug之前都读一下这篇短文，当然我也希望用户在给我报告bug之前已经读过这篇文章。</p>
<a id="more"></a>
<p>简单地说，报告bug的目的是为了让程序员看到程序的错误。您可以亲自示范，也可以给出能导致程序出错的、详尽的操作步骤。如果程序出错了，程序员会收集额外的信息直到找到错误的原因；如果程序没有出错，那么他们会请您继续关注这个问题，收集相关的信息。</p>
<p>在bug报告里，要设法搞清什么是事实（例如：“我在电脑旁”和“XX出现了”）什么是推测（例如：“我想问题可能是出在……”）。如果愿意的话，您可以省去推测，但是千万别省略事实。</p>
<p>当您报告bug的时候（既然您已经这么做了），一定是希望bug得到及时修正。所以此时针对程序员的任何过激或亵渎的言语（甚至谩骂）都是与事无补的——因为这可能是程序员的错误，也有可能是您的错误，也许您有权对他们发火，但是如果您能多提供一些有用的信息（而不是激愤之词）或许bug会被更快的修正。除此以外，请记住：如果是免费软件，作者提供给我们已经是出于好心，所以要是太多的人对他们无礼，他们可能就要“收起”这份好心了。</p>
<p>##“程序不好用”</p>
<p>程序员不是弱智：如果程序一点都不好用，他们不可能不知道。他们不知道一定是因为程序在他们看来工作得很正常。所以，或者是您作过一些与他们不同的操作，或者是您的环境与他们不同。他们需要信息，报告bug也是为了提供信息。信息总是越多越好。</p>
<p>许多程序，特别是自由软件，会公布一个“已知bug列表”。如果您找到的bug在列表里已经有了，那就不必再报告了，但是如果您认为自己掌握的信息比列表中的丰富，那无论如何也要与程序员联系。您提供的信息可能会使他们更简单地修复bug。</p>
<p>本文中提到的都是一些指导方针，没有哪一条是必须恪守的准则。不同的程序员会喜欢不同形式的bug报告。如果程序附带了一套报告bug的准则，一定要读。如果它与本文中提到的规则相抵触，那么请以它为准。</p>
<p>如果您不是报告bug，而是寻求帮助，您应该说明您曾经到哪里找过答案，（例如：我看了第四章和第五章的第二节，但我找不到解决的办法。）这会使程序员了解用户喜欢到哪里去找答案，从而使程序员把帮助文档做得更容易使用。</p>
<p>##“演示给我看”</p>
<p>报告bug的最好的方法之一是“演示”给程序员看。让程序员站在电脑前，运行他们的程序，指出程序的错误。让他们看着您启动电脑、运行程序、如何进行操作以及程序对您的输入有何反应。</p>
<p>他们对自己写的软件了如指掌，他们知道哪些地方不会出问题，而哪些地方最可能出问题。他们本能地知道应该注意什么。在程序真的出错之前，他们可能已经注意到某些地方不对劲，这些都会给他们一些线索。他们会观察程序测试中的每一个细节，并且选出他们认为有用的信息。</p>
<p>这些可能还不够。也许他们觉得还需要更多的信息，会请您重复刚才的操作。他们可能在这期间需要与您交流一下，以便在他们需要的时候让bug重新出现。他们可能会改变一些操作，看看这个错误的产生是个别问题还是相关的一类问题。如果您不走运，他们可能需要坐下来，拿出一堆开发工具，花上几个小时来好好地研究一下。但是最重要的是在程序出错的时候让程序员在电脑旁。一旦他们看到了问题，他们通常会找到原因并开始试着修改。</p>
<p>##“告诉我该怎么做”</p>
<p>如今是网络时代，是信息交流的时代。我可以点一下鼠标把自己的程序送到俄罗斯的某个朋友那里，当然他也可以用同样简单的方法给我一些建议。但是如果我的程序出了什么问题，我不可能在他旁边。“演示”是很好的办法，但是常常做不到。</p>
<p>如果您必须报告bug，而此时程序员又不在您身边，那么您就要想办法让bug重现在他们面前。当他们亲眼看到错误时，就能够进行处理了。</p>
<p>确切地告诉程序员您做了些什么。如果是一个图形界面程序，告诉他们您按了哪个按钮，依照什么顺序按的。如果是一个命令行程序，精确的告诉他们您键入了什么命令。您应该尽可能详细地提供您所键入的命令和程序的反应。</p>
<p>把您能想到的所有的输入方式都告诉程序员，如果程序要读取一个文件，您可能需要发一个文件的拷贝给他们。如果程序需要通过网络与另一台电脑通讯，您或许不能把那台电脑复制过去，但至少可以说一下电脑的类型和安装了哪些软件（如果可以的话）。</p>
<p>##“哪儿出错了？在我看来一切正常哦！”</p>
<p>如果您给了程序员一长串输入和指令，他们执行以后没有出现错误，那是因为您没有给他们足够的信息，可能错误不是在每台计算机上都出现，您的系统可能和他们的在某些地方不一样。有时候程序的行为可能和您预想的不一样，这也许是误会，但是您会认为程序出错了，程序员却认为这是对的。</p>
<p>同样也要描述发生了什么。精确的描述您看到了什么。告诉他们为什么您觉得自己所看到的是错误的，最好再告诉他们，您认为自己应该看到什么。如果您只是说：“程序出错了”，那您很可能漏掉了非常重要的信息。</p>
<p>如果您看到了错误消息，一定要仔细、准确的告诉程序员，这确实很重要。在这种情况下，程序员只要修正错误，而不用去找错误。他们需要知道是什么出问题了，系统所报的错误消息正好帮助了他们。如果您没有更好的方法记住这些消息，就把它们写下来。只报告“程序出了一个错”是毫无意义的，除非您把错误消息一块报上来。</p>
<p>特殊情况下，如果有错误消息号，一定要把这些号码告诉程序员。不要以为您看不出任何意义，它就没有意义。错误消息号包含了能被程序员读懂的各种信息，并且很有可能包含重要的线索。给错误消息编号是因为用语言描述计算机错误常常令人费解。用这种方式告诉您错误的所在是一个最好的办法。</p>
<p>在这种情形下，程序员的排错工作会十分高效。他们不知道发生了什么，也不可能到现场去观察，所以他们一直在搜寻有价值的线索。错误消息、错误消息号以及一些莫名其妙的延迟，都是很重要的线索，就像办案时的指纹一样重要，保存好。</p>
<p>如果您使用UNIX系统，程序可能会产生一个内核输出（coredump）。内核输出是特别有用的线索来源，别扔了它们。另一方面，大多数程序员不喜欢收到含有大量内核输出文件的EMAIL，所以在发邮件之前最好先问一下。还有一点要注意：内核输出文件记录了完整的程序状态，也就是说任何秘密（可能当时程序正在处理一些私人信息或秘密数据）都可能包含在内核输出文件里。</p>
<p>##“出了问题之后，我做了……”</p>
<p>当一个错误或bug发生的时候，您可能会做许多事情。但是大多数人会使事情变的更糟。我的一个朋友在学校里误删了她所有的Word文件，在找人帮忙之前她重装了Word，又运行了一遍碎片整理程序，这些操作对于恢复文件是毫无益处的，因为这些操作搞乱了磁盘的文件区块。恐怕在这个世界上没有一种反删除软件能恢复她的文件了。如果她不做任何操作，或许还有一线希望。</p>
<p>这种用户仿佛一只被逼到墙角的鼬（黄鼠狼、紫貂一类的动物——译者注）：背靠墙壁，面对死亡的降临奋起反扑，疯狂攻击。他们认为做点什么总比什么都不做强。然而这些在处理计算机软件问题时并不适用。</p>
<p>不要做鼬，做一只羚羊。当一只羚羊面对料想不到的情况或受到惊吓时，它会一动不动，是为了不吸引任何注意，与此同时也在思考解决问题的最好办法（如果羚羊有一条技术支持热线，此时占线。）。然后，一旦它找到了最安全的行动方案，它便去做。</p>
<p>当程序出毛病的时候，立刻停止正在做的任何操作。不要按任何健。仔细地看一下屏幕，注意那些不正常的地方，记住它或者写下来。然后慎重地点击“确定” 或“取消”，选择一个最安全的。学着养成一种条件反射——一旦电脑出了问题，先不要动。要想摆脱这个问题，关掉受影响的程序或者重新启动计算机都不好，一个解决问题的好办法是让问题再次产生。程序员们喜欢可以被重现的问题，快乐的程序员可以更快而且更有效率的修复bug。</p>
<p>##“我想粒子的跃迁与错误的极化有关”</p>
<p>并不只是非专业的用户才会写出拙劣的bug报告，我见过一些非常差的bug报告出自程序员之手，有些还是非常优秀的程序员。</p>
<p>有一次我与另一个程序员一起工作，他一直在找代码中的bug，他常常遇到一个bug，但是不会解决，于是就叫我帮忙。“出什么毛病了？”我问。而他的回答却总是一些关于bug的意见。如果他的观点正确，那的确是一件好事。这意味着他已经完成了工作的一半，并且我们可以一起完成另一半工作。这是有效率并有用的。</p>
<p>但事实上他常常是错的。这就会使我们花上半个小时在原本正确的代码里来回寻找错误，而实际上问题出在别的地方。我敢肯定他不会对医生这么做。“大夫，我得了Hydroyoyodyne（真是怪病——译者），给我开个方子”，人们知道不该对一位医生说这些。您描述一下症状，哪个地方不舒服，哪里疼、起皮疹、发烧……让医生诊断您得了什么病，应该怎样治疗。否则医生会把您当做疑心病或精神病患者打发了，这似乎没什么不对。</p>
<p>做程序员也是一样。即便您自己的“诊断”有时真的有帮助，也要只说“症状”。“诊断”是可说可不说的，但是“症状”一定要说。同样，在bug报告里面附上一份针对bug而做出修改的源代码是有用处的，但它并不能替代bug报告本身。</p>
<p>如果程序员向您询问额外的信息，千万别应付。曾经有一个人向我报告bug，我让他试一个命令，我知道这个命令不好用，但我是要看看程序会返回一个什么错误（这是很重要的线索）。但是这位老兄根本就没试，他在回复中说“那肯定不好用”，于是我又花了好些时间才说服他试了一下那个命令。</p>
<p>用户多动动脑筋对程序员的工作是有帮助的。即使您的推断是错误的，程序员也应该感谢您，至少您想去帮助他们，使他们的工作变的更简单。不过千万别忘了报告“症状”，否则只会使事情变得更糟。</p>
<p>##“真是奇怪，刚才还不好用，怎么现在又好了？”</p>
<p>“间歇性错误”着实让程序员发愁。相比之下，进行一系列简单的操作便能导致错误发生的问题是简单的。程序员可以在一个便于观察的条件下重复那些操作，观察每一个细节。太多的问题在这种情况下不能解决，例如：程序每星期出一次错，或者偶然出一次错，或者在程序员面前从不出错（程序员一离开就出错。——译者）。当然还有就是程序的截止日期到了，那肯定要出错。</p>
<p>大多数“间歇性错误”并不是真正的“间歇”。其中的大多数错误与某些地方是有联系的。有一些错误可能是内存泄漏产生的，有一些可能是别的程序在不恰当的时候修改某个重要文件造成的，还有一些可能发生在每一个小时的前半个小时中（我确实遇到过这种事情）。</p>
<p>同样，如果您能使bug重现，而程序员不能，那很有可能是他们的计算机和您的计算机在某些地方是不同的，这种不同引起了问题。我曾写过一个程序，它的窗口可以蜷缩成一个小球呆在屏幕的左上角，它在别的计算机上只能在 800x600 的解析度工作，但是在我的机器上却可以在 1024x768 下工作。</p>
<p>程序员想要了解任何与您发现的问题相关的事情。有可能的话您到另一台机器上试试，多试几次，两次，三次，看看问题是不是经常发生。如果问题出现在您进行了一系列操作之后，不是您想让它出现它就会出现，这就有可能是长时间的运行或处理大文件所导致的错误。程序崩溃的时候，您要尽可能的记住您都做了些什么，并且如果您看到任何图形,也别忘了提一下。您提供的任何事情都是有帮助的。即使只是概括性的描述（例如：当后台有EMACS运行时，程序常常出错），这虽然不能提供导致问题的直接线索，但是可能帮助程序员重现问题。</p>
<p>最重要的是：程序员想要确定他们正在处理的是一个真正的“间歇性错误”呢，还是一个在另一类特定的计算机上才出现的错误。他们想知道有关您计算机的许多细节，以便了解您的机器与他们的有什么不同。有许多细节都依仗特定的程序，但是有一件东西您一定要提供——版本号。程序的版本、操作系统的版本以及与问题有关的程序的版本。</p>
<p>##“我把磁盘装进了 Windows……”</p>
<p>表意清楚在一份bug报告里是最基本的要求。如果程序员不知道您说的是什么意思，那您就跟没说一样。我收到的bug报告来自世界各地，有许多是来自非英语国家，他们通常为自己的英文不好而表示歉意。总的来说，这些用户发来的bug报告通常是清晰而且有用的。几乎所有不清晰的bug报告都是来自母语是英语的人，他们总是以为只要自己随便说说，程序员就能明白。</p>
<p>精确。如果做相同的事情有两种方法，请说明您用的是哪一种。例如：“我选择了‘载入’”，可能意味着“我用鼠标点击‘载入’”或“我按下了‘ALT+L’”，说清楚您用了哪种方法，有时候这也有关系。<br>详细。信息宁多毋少！如果您说了很多，程序员可以略去一部分，可是如果您说的太少，他们就不得不回过头再去问您一些问题。有一次我收到了一份bug报告只有一句话，每一次我问他更多事情时，他每次的回复都是一句话，于是我花了几个星期的时间才得到了有用的信息。<br>慎用代词。诸如“它”，“窗体”这些词，当它们指代不清晰的时候不要用。来看看这句话：“我运行了FooApp，它弹出一个警告窗口，我试着关掉它，它就崩溃了。”这种表述并不清晰，用户究竟关掉了哪个窗口？是警告窗口还是整个FooApp程序？您可以这样说，“我运行FooApp程序时弹出一个警告窗口，我试着关闭警告窗口，FooApp崩溃了。”这样虽然罗嗦点，但是很清晰不容易产生误解。</p>
<p>检查。重新读一遍您写的bug报告，您觉得它是否清晰？如果您列出了一系列能导致程序出错的操作，那么照着做一遍，看看您是不是漏写了一步。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul>
<li>bug报告的首要目的是让程序员亲眼看到错误。如果您不能亲自做给他们看，给他们能使程序出错的详细的操作步骤。</li>
<li>如果首要目的不能达成，程序员不能看到程序出错。这就需要bug报告的第二个目的来描述程序的什么地方出毛病了。详细的描述每一件事情：您看到了什么，您想看到什么，把错误消息记下来，尤其是“错误消息号”。</li>
<li>当您的计算机做了什么您料想不到的事，不要动！在您平静下来之前什么都别做。不要做您认为不安全的事。</li>
<li>尽量试着自己“诊断”程序出错的原因（如果您认为自己可以的话）。即使做出了“诊断”，您仍然应该报告“症状”。</li>
<li>如果程序员需要，请准备好额外的信息。如果他们不需要，就不会问您要。他们不会故意为难自己。您手头上一定要有程序的版本号，它很可能是必需品。</li>
<li>表述清楚，确保您的意思不能被曲解。</li>
<li>总的来说，最重要的是要做到精确。程序员喜欢精确。</li>
</ul>
<p>声明：我从没有真的看见过鼬和羚羊，我的比喻可能不恰当。</p>
<p>版权所有 Simon Tatham 1999</p>
<p>本文属于OPL（OpenContent License），请在复制和使用本文时自觉遵守OPL。</p>
<p>对本文的任何意见和批评请发送至：</p>
<p>英文版：anakin@pobox.com</p>
<p>中文版：dasn@users.sf.net</p>
<h1 id="How-to-Report-Bugs-Effectively"><a href="#How-to-Report-Bugs-Effectively" class="headerlink" title="How to Report Bugs Effectively"></a><a href="http://www.chiark.greenend.org.uk/~sgtatham/bugs.html" target="_blank" rel="external">How to Report Bugs Effectively</a></h1><p>by Simon Tatham, professional and free-software programmer</p>
<p>[ English | Português | 简体中文 | Česky | Dansk | Deutsch | Español | Français | Magyar | Italiano | 日本語 | Nederlands | Polski | Русский | 繁體中文 ]</p>
<p>Introduction</p>
<p>Anybody who has written software for public use will probably have received at least one bad bug report. Reports that say nothing (“It doesn’t work!”); reports that make no sense; reports that don’t give enough information; reports that give wrong information. Reports of problems that turn out to be user error; reports of problems that turn out to be the fault of somebody else’s program; reports of problems that turn out to be network failures.</p>
<p>There’s a reason why technical support is seen as a horrible job to be in, and that reason is bad bug reports. However, not all bug reports are unpleasant: I maintain free software, when I’m not earning my living, and sometimes I receive wonderfully clear, helpful, informative bug reports.</p>
<p>In this essay I’ll try to state clearly what makes a good bug report. Ideally I would like everybody in the world to read this essay before reporting any bugs to anybody. Certainly I would like everybody who reports bugs to me to have read it.</p>
<p>In a nutshell, the aim of a bug report is to enable the programmer to see the program failing in front of them. You can either show them in person, or give them careful and detailed instructions on how to make it fail. If they can make it fail, they will try to gather extra information until they know the cause. If they can’t make it fail, they will have to ask you to gather that information for them.</p>
<p>In bug reports, try to make very clear what are actual facts (“I was at the computer and this happened”) and what are speculations (“I think the problem might be this”). Leave out speculations if you want to, but don’t leave out facts.</p>
<p>When you report a bug, you are doing so because you want the bug fixed. There is no point in swearing at the programmer or being deliberately unhelpful: it may be their fault and your problem, and you might be right to be angry with them, but the bug will get fixed faster if you help them by supplying all the information they need. Remember also that if the program is free, then the author is providing it out of kindness, so if too many people are rude to them then they may stop feeling kind.</p>
<p>“It doesn’t work.”</p>
<p>Give the programmer some credit for basic intelligence: if the program really didn’t work at all, they would probably have noticed. Since they haven’t noticed, it must be working for them. Therefore, either you are doing something differently from them, or your environment is different from theirs. They need information; providing this information is the purpose of a bug report. More information is almost always better than less.</p>
<p>Many programs, particularly free ones, publish their list of known bugs. If you can find a list of known bugs, it’s worth reading it to see if the bug you’ve just found is already known or not. If it’s already known, it probably isn’t worth reporting again, but if you think you have more information than the report in the bug list, you might want to contact the programmer anyway. They might be able to fix the bug more easily if you can give them information they didn’t already have.</p>
<p>This essay is full of guidelines. None of them is an absolute rule. Particular programmers have particular ways they like bugs to be reported. If the program comes with its own set of bug-reporting guidelines, read them. If the guidelines that come with the program contradict the guidelines in this essay, follow the ones that come with the program!</p>
<p>If you are not reporting a bug but just asking for help using the program, you should state where you have already looked for the answer to your question. (“I looked in chapter 4 and section 5.2 but couldn’t find anything that told me if this is possible.”) This will let the programmer know where people will expect to find the answer, so they can make the documentation easier to use.</p>
<p>“Show me.”</p>
<p>One of the very best ways you can report a bug is by showing it to the programmer. Stand them in front of your computer, fire up their software, and demonstrate the thing that goes wrong. Let them watch you start the machine, watch you run the software, watch how you interact with the software, and watch what the software does in response to your inputs.</p>
<p>They know that software like the back of their hand. They know which parts they trust, and they know which parts are likely to have faults. They know intuitively what to watch for. By the time the software does something obviously wrong, they may well have already noticed something subtly wrong earlier which might give them a clue. They can observe everything the computer does during the test run, and they can pick out the important bits for themselves.</p>
<p>This may not be enough. They may decide they need more information, and ask you to show them the same thing again. They may ask you to talk them through the procedure, so that they can reproduce the bug for themselves as many times as they want. They might try varying the procedure a few times, to see whether the problem occurs in only one case or in a family of related cases. If you’re unlucky, they may need to sit down for a couple of hours with a set of development tools and really start investigating. But the most important thing is to have the programmer looking at the computer when it goes wrong. Once they can see the problem happening, they can usually take it from there and start trying to fix it.</p>
<p>“Show me how to show myself.”</p>
<p>This is the era of the Internet. This is the era of worldwide communication. This is the era in which I can send my software to somebody in Russia at the touch of a button, and he can send me comments about it just as easily. But if he has a problem with my program, he can’t have me standing in front of it while it fails. “Show me” is good when you can, but often you can’t.</p>
<p>If you have to report a bug to a programmer who can’t be present in person, the aim of the exercise is to enable them to reproduce the problem. You want the programmer to run their own copy of the program, do the same things to it, and make it fail in the same way. When they can see the problem happening in front of their eyes, then they can deal with it.</p>
<p>So tell them exactly what you did. If it’s a graphical program, tell them which buttons you pressed and what order you pressed them in. If it’s a program you run by typing a command, show them precisely what command you typed. Wherever possible, you should provide a verbatim transcript of the session, showing what commands you typed and what the computer output in response.</p>
<p>Give the programmer all the input you can think of. If the program reads from a file, you will probably need to send a copy of the file. If the program talks to another computer over a network, you probably can’t send a copy of that computer, but you can at least say what kind of computer it is, and (if you can) what software is running on it.</p>
<p>“Works for me. So what goes wrong?”</p>
<p>If you give the programmer a long list of inputs and actions, and they fire up their own copy of the program and nothing goes wrong, then you haven’t given them enough information. Possibly the fault doesn’t show up on every computer; your system and theirs may differ in some way. Possibly you have misunderstood what the program is supposed to do, and you are both looking at exactly the same display but you think it’s wrong and they know it’s right.</p>
<p>So also describe what happened. Tell them exactly what you saw. Tell them why you think what you saw is wrong; better still, tell them exactly what you expected to see. If you say “and then it went wrong”, you have left out some very important information.</p>
<p>If you saw error messages then tell the programmer, carefully and precisely, what they were. They are important! At this stage, the programmer is not trying to fix the problem: they’re just trying to find it. They need to know what has gone wrong, and those error messages are the computer’s best effort to tell you that. Write the errors down if you have no other easy way to remember them, but it’s not worth reporting that the program generated an error unless you can also report what the error message was.</p>
<p>In particular, if the error message has numbers in it, do let the programmer have those numbers. Just because you can’t see any meaning in them doesn’t mean there isn’t any. Numbers contain all kinds of information that can be read by programmers, and they are likely to contain vital clues. Numbers in error messages are there because the computer is too confused to report the error in words, but is doing the best it can to get the important information to you somehow.</p>
<p>At this stage, the programmer is effectively doing detective work. They don’t know what’s happened, and they can’t get close enough to watch it happening for themselves, so they are searching for clues that might give it away. Error messages, incomprehensible strings of numbers, and even unexplained delays are all just as important as fingerprints at the scene of a crime. Keep them!</p>
<p>If you are using Unix, the program may have produced a core dump. Core dumps are a particularly good source of clues, so don’t throw them away. On the other hand, most programmers don’t like to receive huge core files by e-mail without warning, so ask before mailing one to anybody. Also, be aware that the core file contains a record of the complete state of the program: any “secrets” involved (maybe the program was handling a personal message, or dealing with confidential data) may be contained in the core file.</p>
<p>“So then I tried . . .”</p>
<p>There are a lot of things you might do when an error or bug comes up. Many of them make the problem worse. A friend of mine at school deleted all her Word documents by mistake, and before calling in any expert help, she tried reinstalling Word, and then she tried running Defrag. Neither of these helped recover her files, and between them they scrambled her disk to the extent that no Undelete program in the world would have been able to recover anything. If she’d only left it alone, she might have had a chance.</p>
<p>Users like this are like a mongoose backed into a corner: with its back to the wall and seeing certain death staring it in the face, it attacks frantically, because doing something has to be better than doing nothing. This is not well adapted to the type of problems computers produce.</p>
<p>Instead of being a mongoose, be an antelope. When an antelope is confronted with something unexpected or frightening, it freezes. It stays absolutely still and tries not to attract any attention, while it stops and thinks and works out the best thing to do. (If antelopes had a technical support line, it would be telephoning it at this point.) Then, once it has decided what the safest thing to do is, it does it.</p>
<p>When something goes wrong, immediately stop doing anything. Don’t touch any buttons at all. Look at the screen and notice everything out of the ordinary, and remember it or write it down. Then perhaps start cautiously pressing “OK” or “Cancel”, whichever seems safest. Try to develop a reflex reaction - if a computer does anything unexpected, freeze.</p>
<p>If you manage to get out of the problem, whether by closing down the affected program or by rebooting the computer, a good thing to do is to try to make it happen again. Programmers like problems that they can reproduce more than once. Happy programmers fix bugs faster and more efficiently.</p>
<p>“I think the tachyon modulation must be wrongly polarised.”</p>
<p>It isn’t only non-programmers who produce bad bug reports. Some of the worst bug reports I’ve ever seen come from programmers, and even from good programmers.</p>
<p>I worked with another programmer once, who kept finding bugs in his own code and trying to fix them. Every so often he’d hit a bug he couldn’t solve, and he’d call me over to help. “What’s gone wrong?” I’d ask. He would reply by telling me his current opinion of what needed to be fixed.</p>
<p>This worked fine when his current opinion was right. It meant he’d already done half the work and we were able to finish the job together. It was efficient and useful.</p>
<p>But quite often he was wrong. We would work for some time trying to figure out why some particular part of the program was producing incorrect data, and eventually we would discover that it wasn’t, that we’d been investigating a perfectly good piece of code for half an hour, and that the actual problem was somewhere else.</p>
<p>I’m sure he wouldn’t do that to a doctor. “Doctor, I need a prescription for Hydroyoyodyne.” People know not to say that to a doctor: you describe the symptoms, the actual discomforts and aches and pains and rashes and fevers, and you let the doctor do the diagnosis of what the problem is and what to do about it. Otherwise the doctor dismisses you as a hypochondriac or crackpot, and quite rightly so.</p>
<p>It’s the same with programmers. Providing your own diagnosis might be helpful sometimes, but always state the symptoms. The diagnosis is an optional extra, and not an alternative to giving the symptoms. Equally, sending a modification to the code to fix the problem is a useful addition to a bug report but not an adequate substitute for one.</p>
<p>If a programmer asks you for extra information, don’t make it up! Somebody reported a bug to me once, and I asked him to try a command that I knew wouldn’t work. The reason I asked him to try it was that I wanted to know which of two different error messages it would give. Knowing which error message came back would give a vital clue. But he didn’t actually try it - he just mailed me back and said “No, that won’t work”. It took me some time to persuade him to try it for real.</p>
<p>Using your intelligence to help the programmer is fine. Even if your deductions are wrong, the programmer should be grateful that you at least tried to make their life easier. But report the symptoms as well, or you may well make their life much more difficult instead.</p>
<p>“That’s funny, it did it a moment ago.”</p>
<p>Say “intermittent fault” to any programmer and watch their face fall. The easy problems are the ones where performing a simple sequence of actions will cause the failure to occur. The programmer can then repeat those actions under closely observed test conditions and watch what happens in great detail. Too many problems simply don’t work that way: there will be programs that fail once a week, or fail once in a blue moon, or never fail when you try them in front of the programmer but always fail when you have a deadline coming up.</p>
<p>Most intermittent faults are not truly intermittent. Most of them have some logic somewhere. Some might occur when the machine is running out of memory, some might occur when another program tries to modify a critical file at the wrong moment, and some might occur only in the first half of every hour! (I’ve actually seen one of these.)</p>
<p>Also, if you can reproduce the bug but the programmer can’t, it could very well be that their computer and your computer are different in some way and this difference is causing the problem. I had a program once whose window curled up into a little ball in the top left corner of the screen, and sat there and sulked. But it only did it on 800x600 screens; it was fine on my 1024x768 monitor.</p>
<p>The programmer will want to know anything you can find out about the problem. Try it on another machine, perhaps. Try it twice or three times and see how often it fails. If it goes wrong when you’re doing serious work but not when you’re trying to demonstrate it, it might be long running times or large files that make it fall over. Try to remember as much detail as you can about what you were doing to it when it did fall over, and if you see any patterns, mention them. Anything you can provide has to be some help. Even if it’s only probabilistic (such as “it tends to crash more often when Emacs is running”), it might not provide direct clues to the cause of the problem, but it might help the programmer reproduce it.</p>
<p>Most importantly, the programmer will want to be sure of whether they’re dealing with a true intermittent fault or a machine-specific fault. They will want to know lots of details about your computer, so they can work out how it differs from theirs. A lot of these details will depend on the particular program, but one thing you should definitely be ready to provide is version numbers. The version number of the program itself, and the version number of the operating system, and probably the version numbers of any other programs that are involved in the problem.</p>
<p>“So I loaded the disk on to my Windows . . .”</p>
<p>Writing clearly is essential in a bug report. If the programmer can’t tell what you meant, you might as well not have said anything.</p>
<p>I get bug reports from all around the world. Many of them are from non-native English speakers, and a lot of those apologise for their poor English. In general, the bug reports with apologies for their poor English are actually very clear and useful. All the most unclear reports come from native English speakers who assume that I will understand them even if they don’t make any effort to be clear or precise.</p>
<p>Be specific. If you can do the same thing two different ways, state which one you used. “I selected Load” might mean “I clicked on Load” or “I pressed Alt-L”. Say which you did. Sometimes it matters.<br>Be verbose. Give more information rather than less. If you say too much, the programmer can ignore some of it. If you say too little, they have to come back and ask more questions. One bug report I received was a single sentence; every time I asked for more information, the reporter would reply with another single sentence. It took me several weeks to get a useful amount of information, because it turned up one short sentence at a time.<br>Be careful of pronouns. Don’t use words like “it”, or references like “the window”, when it’s unclear what they mean. Consider this: “I started FooApp. It put up a warning window. I tried to close it and it crashed.” It isn’t clear what the user tried to close. Did they try to close the warning window, or the whole of FooApp? It makes a difference. Instead, you could say “I started FooApp, which put up a warning window. I tried to close the warning window, and FooApp crashed.” This is longer and more repetitive, but also clearer and less easy to misunderstand.<br>Read what you wrote. Read the report back to yourself, and see if you think it’s clear. If you have listed a sequence of actions which should produce the failure, try following them yourself, to see if you missed a step.<br>Summary</p>
<p>The first aim of a bug report is to let the programmer see the failure with their own eyes. If you can’t be with them to make it fail in front of them, give them detailed instructions so that they can make it fail for themselves.<br>In case the first aim doesn’t succeed, and the programmer can’t see it failing themselves, the second aim of a bug report is to describe what went wrong. Describe everything in detail. State what you saw, and also state what you expected to see. Write down the error messages, especially if they have numbers in.<br>When your computer does something unexpected, freeze. Do nothing until you’re calm, and don’t do anything that you think might be dangerous.<br>By all means try to diagnose the fault yourself if you think you can, but if you do, you should still report the symptoms as well.<br>Be ready to provide extra information if the programmer needs it. If they didn’t need it, they wouldn’t be asking for it. They aren’t being deliberately awkward. Have version numbers at your fingertips, because they will probably be needed.<br>Write clearly. Say what you mean, and make sure it can’t be misinterpreted.<br>Above all, be precise. Programmers like precision.<br>Disclaimer: I’ve never actually seen a mongoose or an antelope. My zoology may be inaccurate.</p>
<p>$Id$</p>
<p>Copyright © 1999 Simon Tatham.<br>This document is OpenContent.<br>You may copy and use the text under the terms of the OpenContent Licence.</p>
<p>This article is not specific to any particular program.</p>
<p>If you have reached this page by following a link from the website for a particular program, DO NOT send bug reports for that program to me. Instead, return to the page you came from to find out where to report bugs in the program.</p>
<p>If you have comments or criticism about this article itself, please send them to anakin@pobox.com.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;http://www.chiark.greenend.org.uk/~sgtatham/bugs.html&quot;&gt;Simon Tatham&lt;/a&gt; 专业的自由软件程序员&lt;br&gt;翻译：Dasn&lt;/p&gt;
&lt;h2 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h2&gt;&lt;p&gt;为公众写过软件的人，大概都收到过很拙劣的bug（计算机程序代码中的错误或程序运行时的瑕疵——译者注）报告，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在报告中说“不好用”；&lt;/li&gt;
&lt;li&gt;所报告内容毫无意义；&lt;/li&gt;
&lt;li&gt;在报告中用户没有提供足够的信息；&lt;/li&gt;
&lt;li&gt;在报告中提供了错误信息；&lt;/li&gt;
&lt;li&gt;所报告的问题是由于用户的过失而产生的；&lt;/li&gt;
&lt;li&gt;所报告的问题是由于其他程序的错误而产生的；&lt;/li&gt;
&lt;li&gt;所报告的问题是由于网络错误而产生的；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这便是为什么“技术支持”被认为是一件可怕的工作，因为有拙劣的bug报告需要处理。然而并不是所有的bug报告都令人生厌：我在业余时间维护自由软件，有时我会收到非常清晰、有帮助并且“有内容”的bug报告。在这里我会尽力阐明如何写一个好的bug报告。我非常希望每一个人在报告bug之前都读一下这篇短文，当然我也希望用户在给我报告bug之前已经读过这篇文章。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
  </entry>
  
  <entry>
    <title>Software Release Practice HOWTO</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/software-release-practice-howto/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/software-release-practice-howto/</id>
    <published>2017-01-20T11:53:06.000Z</published>
    <updated>2017-02-16T00:05:36.074Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://en.tldp.org/HOWTO/Software-Release-Practice-HOWTO/index.html" target="_blank" rel="external">Software Release Practice HOWTO</a></p>
<p>Eric Steven Raymond</p>
<p>This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it.</p>
<p>This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards.</p>
 <a id="more"></a>
<p>Table of Contents</p>
<ol>
<li>Introduction<br>1.1. Why this document?<br>1.2. New versions of this document</li>
<li>Good patching practice<br>2.1. Do send patches, don’t send whole archives or files<br>2.2. Send patches against the current version of the code.<br>2.3. Don’t include patches for generated files.<br>2.4. Don’t send patch bands that just tweak version-control $-symbols.<br>2.5. Do use -c or -u format, don’t use the default (-e) format<br>2.6. Do include documentation with your patch<br>2.7. Do include an explanation with your patch<br>2.8. Do include useful comments in your code<br>2.9. Just one bugfix or new feature per patch.</li>
<li>Good project- and archive- naming practice<br>3.1. Use GNU-style names with a stem and major.minor.patch numbering.<br>3.2. But respect local conventions where appropriate<br>3.3. Try hard to choose a name prefix that is unique and easy to type</li>
<li>Good licensing and copyright practice: the theory<br>4.1. Open source and copyrights<br>4.2. What qualifies as open source</li>
<li>Good licensing and copyright practice: the practice<br>5.1. Make yourself or the FSF the copyright holder<br>5.2. Use a license conformant to the Open Source Definition<br>5.3. Don’t write your own license if you can possibly avoid it.<br>5.4. Make your license visible in a standard place.</li>
<li>Good development practice<br>6.1. Choose the most portable language you can<br>6.2. Don’t rely on proprietary code<br>6.3. Build systems<br>6.4. Test your code before release<br>6.5. Sanity-check your code before release<br>6.6. Sanity-check your documentation and READMEs before release<br>6.7. Recommended C/C++ portability practices</li>
<li>Good distribution-making practice<br>7.1. Make sure tarballs always unpack into a single new directory<br>7.2. Have a README<br>7.3. Respect and follow standard file naming practices<br>7.4. Design for Upgradability<br>7.5. Provide checksums</li>
<li>Good documentation practice<br>8.1. Documentation formats<br>8.2. Good practice recommendations</li>
<li>Good communication practice<br>9.1. Announce to Freecode<br>9.2. Have a website<br>9.3. Host project mailing lists<br>9.4. Release to major archives</li>
<li>Good project-management practice</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://en.tldp.org/HOWTO/Software-Release-Practice-HOWTO/index.html&quot;&gt;Software Release Practice HOWTO&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Eric Steven Raymond&lt;/p&gt;
&lt;p&gt;This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it.&lt;/p&gt;
&lt;p&gt;This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
  </entry>
  
  <entry>
    <title>Advice for Computer Science College Students</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/advice-for-computer-science-college-students/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/advice-for-computer-science-college-students/</id>
    <published>2017-01-20T11:44:06.000Z</published>
    <updated>2017-02-15T13:04:49.261Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.joelonsoftware.com/2005/01/02/advice-for-computer-science-college-students/" target="_blank" rel="external">Joel Spolsky</a> co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow.</p>
<p><img src="https://6602cxue4uk2h2m2-zippykid.netdna-ssl.com/wp-content/uploads/2016/12/Pong.png" alt=""></p>
 <a id="more"></a>
<p>Despite the fact that it was only a year or two ago that I was blubbering about how rich Windows GUI clients were the wave of the future, college students nonetheless do occasionally email me asking for career advice, and since it’s recruiting season, I thought I’d write up my standard advice which they can read, laugh at, and ignore.</p>
<p>Most college students, fortunately, are brash enough never to bother asking their elders for advice, which, in the field of computer science, is a good thing, because their elders are apt to say goofy, antediluvian things like “the demand for keypunch operators will exceed 100,000,000 by the year 2010” and “lisp careers are really very hot right now.”</p>
<p>I, too, have no idea what I’m talking about when I give advice to college students. I’m so hopelessly out of date that I can’t really figure out AIM and still use (horrors!) this quaint old thing called “email” which was popular in the days when music came on flat round plates called “CDs.”</p>
<p>So you’d be better off ignoring what I’m saying here and instead building some kind of online software thing that lets other students find people to go out on dates with.</p>
<p>Nevertheless.</p>
<p>If you enjoy programming computers, count your blessings: you are in a very fortunate minority of people who can make a great living doing work they enjoy. Most people aren’t so lucky. The very idea that you can “love your job” is a modern concept. Work is supposed to be something unpleasant you do to get money to do the things you actually like doing, when you’re 65 and can finally retire, if you can afford it, and if you’re not too old and infirm to do those things, and if those things don’t require reliable knees, good eyes, and the ability to walk twenty feet without being out of breath, etc.</p>
<p>What was I talking about? Oh yeah. Advice.</p>
<p>Without further ado, then, here are Joel’s Seven Pieces of Free Advice for Computer Science College Students (worth what you paid for them):</p>
<ol>
<li>Learn how to write before graduating.</li>
<li>Learn C before graduating.</li>
<li>Learn microeconomics before graduating.</li>
<li>Don’t blow off non-CS classes just because they’re boring.</li>
<li>Take programming-intensive courses.</li>
<li>Stop worrying about all the jobs going to India.</li>
<li>No matter what you do, get a good summer internship.</li>
</ol>
<p>Now for the explanations, unless you’re gullible enough to do all that stuff just because I tell you to, in which case add: 8. Seek professional help for that self-esteem thing.</p>
<h2 id="Learn-how-to-write-before-graduating"><a href="#Learn-how-to-write-before-graduating" class="headerlink" title="Learn how to write before graduating."></a>Learn how to write before graduating.</h2><p>Would Linux have succeeded if Linus Torvalds hadn’t evangelized it? As brilliant a hacker as he is, it was Linus’s ability to convey his ideas in written English via email and mailing lists that made Linux attract a worldwide brigade of volunteers.</p>
<p>Have you heard of the latest fad, Extreme Programming? Well, without getting into what I think about XP, the reason you’ve heard of it is because it is being promoted by people who are very gifted writers and speakers.</p>
<p>Even on the small scale, when you look at any programming organization, the programmers with the most power and influence are the ones who can write and speak in English clearly, convincingly, and comfortably. Also it helps to be tall, but you can’t do anything about that.</p>
<p>The difference between a tolerable programmer and a great programmer is not how many programming languages they know, and it’s not whether they prefer Python or Java. It’s whether they can communicate their ideas. By persuading other people, they get leverage. By writing clear comments and technical specs, they let other programmers understand their code, which means other programmers can use and work with their code instead of rewriting it. Absent this, their code is worthless. By writing clear technical documentation for end users, they allow people to figure out what their code is supposed to do, which is the only way those users can see the value in their code. There’s a lot of wonderful, useful code buried on sourceforge somewhere that nobody uses because it was created by programmers who don’t write very well (or don’t write at all), and so nobody knows what they’ve done and their brilliant code languishes.</p>
<p>I won’t hire a programmer unless they can write, and write well, in English. If you can write, wherever you get hired, you’ll soon find that you’re getting asked to write the specifications and that means you’re already leveraging your influence and getting noticed by management.</p>
<p>Most colleges designate certain classes as “writing intensive,” meaning, you have to write an awful lot to pass them. Look for those classes and take them! Seek out classes in any field that have weekly or daily written assignments.</p>
<p>Start a journal or weblog. The more you write, the easier it will be, and the easier it is to write, the more you’ll write, in a virtuous circle.</p>
<h2 id="Learn-C-before-graduating"><a href="#Learn-C-before-graduating" class="headerlink" title="Learn C before graduating"></a>Learn C before graduating</h2><p>Part two: C. Notice I didn’t say C++. Although C is becoming increasingly rare, it is still the lingua franca of working programmers. It is the language they use to communicate with one another, and, more importantly, it is much closer to the machine than “modern” languages that you’ll be taught in college like ML, Java, Python, whatever trendy junk they teach these days. You need to spend at least a semester getting close to the machine or you’ll never be able to create efficient code in higher level languages. You’ll never be able to work on compilers and operating systems, which are some of the best programming jobs around. You’ll never be trusted to create architectures for large scale projects. I don’t care how much you know about continuations and closures and exception handling: if you can’t explain why while (<em>s++ = </em>t++); copies a string, or if that isn’t the most natural thing in the world to you, well, you’re programming based on superstition, as far as I’m concerned: a medical doctor who doesn’t know basic anatomy, passing out prescriptions based on what the pharma sales babe said would work.</p>
<h2 id="Learn-microeconomics-before-graduating"><a href="#Learn-microeconomics-before-graduating" class="headerlink" title="Learn microeconomics before graduating"></a>Learn microeconomics before graduating</h2><p>Super quick review if you haven’t taken any economics courses: econ is one of those fields that starts off with a bang, with many useful theories and facts that make sense, can be proven in the field, etc., and then it’s all downhill from there. The useful bang at the beginning is microeconomics, which is the foundation for literally every theory in business that matters. After that things start to deteriorate: you get into Macroeconomics (feel free to skip this if you want) with its interesting theories about things like the relationship of interest rates to unemployment which, er, seem to be disproven more often than they are proven, and after that it just gets worse and worse and a lot of econ majors switch out to Physics, which gets them better Wall Street jobs, anyway. But make sure you take Microeconomics, because you have to know about supply and demand, you have to know about competitive advantage, and you have to understand NPVs and discounting and marginal utility before you’ll have any idea why business works the way it does.</p>
<p>Why should CS majors learn econ? Because a programmer who understands the fundamentals of business is going to be a more valuable programmer, to a business, than a programmer who doesn’t. That’s all there is to it. I can’t tell you how many times I’ve been frustrated by programmers with crazy ideas that make sense in code but don’t make sense in capitalism. If you understand this stuff, you’re a more valuable programmer, and you’ll get rewarded for it, for reasons which you’ll also learn in micro.</p>
<h2 id="Don’t-blow-off-non-CS-classes-just-because-they’re-boring"><a href="#Don’t-blow-off-non-CS-classes-just-because-they’re-boring" class="headerlink" title="Don’t blow off non-CS classes just because they’re boring."></a>Don’t blow off non-CS classes just because they’re boring.</h2><p>Blowing off your non-CS courses is a great way to get a lower GPA.</p>
<p>Never underestimate how big a deal your GPA is. Lots and lots of recruiters and hiring managers, myself included, go straight to the GPA when they scan a resume, and we’re not going to apologize for it. Why? Because the GPA, more than any other one number, reflects the sum of what dozens of professors over a long period of time in many different situations think about your work. SAT scores? Ha! That’s one test over a few hours. The GPA reflects hundreds of papers and midterms and classroom participations over four years. Yeah, it’s got its problems. There has been grade inflation over the years. Nothing about your GPA says whether you got that GPA taking easy classes in home economics at Podunk Community College or taking graduate level Quantum Mechanics at Caltech. Eventually, after I screen out all the 2.5 GPAs from Podunk Community, I’m going to ask for transcripts and recommendations. And then I’m going to look for consistently high grades, not just high grades in computer science.</p>
<p>Why should I, as an employer looking for software developers, care about what grade you got in European History? After all, history is boring. Oh, so, you’re saying I should hire you because you don’t work very hard when the work is boring? Well, there’s boring stuff in programming, too. Every job has its boring moments. And I don’t want to hire people that only want to do the fun stuff.</p>
<p>I took this course in college called Cultural Anthropology because I figured, what the heck, I need to learn something about anthropology, and this looked like an interesting survey course.</p>
<p>Interesting? Not even close! I had to read these incredibly monotonous books about Indians in the Brazilian rain forest and Trobriand Islanders, who, with all due respect, are not very interesting to me. At some point, the class was so incredibly wearisome that I longed for something more exciting, like watching grass grow. I had completely lost interest in the subject matter. Completely, and thoroughly. My eyes teared I was so tired of the endless discussions of piling up yams. I don’t know why the Trobriand Islanders spend so much time piling up yams, I can’t remember any more, it’s incredibly boring, but It Was Going To Be On The Midterm, so I plowed through it. I eventually decided that Cultural Anthropology was going to be my Boredom Gauntlet: my personal obstacle course of tedium. If I could get an A in a class where the tests required me to learn all about potlatch blankets, I could handle anything, no matter how boring. The next time I accidentally get stuck in Lincoln Center sitting through all 18 hours of Wagner’s Ring Cycle, I could thank my studies of the Kwakiutl for making it seem pleasant by comparison.</p>
<p>I got an A. And if I could do it, you can do it.</p>
<h2 id="Take-programming-intensive-courses"><a href="#Take-programming-intensive-courses" class="headerlink" title="Take programming-intensive courses."></a>Take programming-intensive courses.</h2><p>I remember the exact moment I vowed never to go to graduate school.</p>
<p>It was in a course on Dynamic Logic, taught by the dynamic Lenore Zuck at Yale, one of the brightest of an array of very bright CS faculty.</p>
<p>Now, my murky recollections are not going to do proper credit to this field, but let me muddle through anyway. The idea of Formal Logic is that you prove things are true because other things are true. For example thanks to Formal Logic, “Everyone who gets good grades will get hired” plus “Johnny got good grades” allows you to discover the new true fact, “Johnny will get hired.” It’s all very quaint and it only takes ten seconds for a deconstructionist to totally tear apart everything useful in Formal Logic so you’re left with something fun, but useless.</p>
<p>Now, dynamic logic is the same thing, with the addition of time. For example, “after you turn the light on, you can see your shoes” plus “The light went on in the past” implies “you can see your shoes.”</p>
<p>Dynamic Logic is appealing to brilliant theoreticians like Professor Zuck because it holds up the hope that you might be able to formally prove things about computer programs, which could be very useful, if, for example, you could formally prove that the Mars Rover’s flash card wouldn’t overflow and cause itself to be rebooted again and again all day long when it’s supposed to be driving around the red planet looking for Marvin the Martian.</p>
<p>So in the first day of that class, Dr. Zuck filled up two entire whiteboards and quite a lot of the wall next to the whiteboards proving that if you have a light switch, and the light was off, and you flip the switch, the light will then be on.</p>
<p>The proof was insanely complicated, and very error-prone. It was harder to prove that the proof was correct than to convince yourself of the fact that switching a light switch turns on the light. Indeed the multiple whiteboards of proof included many skipped steps, skipped because they were too tedious to go into formally. Many steps were reached using the long-cherished method of Proof by Induction, others by Proof by Reductio ad Absurdum, and still others using Proof by Graduate Student.</p>
<p>For our homework, we had to prove the converse: if the light was off, and it’s on now, prove that you flipped it.</p>
<p>I tried, I really did.</p>
<p>I spent hours in the library trying.</p>
<p>After a couple of hours I found a mistake in Dr. Zuck’s original proof which I was trying to emulate. Probably I copied it down wrong, but it made me realize something: if it takes three hours of filling up blackboards to prove something trivial, allowing hundreds of opportunities for mistakes to slip in, this mechanism would never be able to prove things that are interesting.</p>
<p>Not that that matters to dynamic logicians: they’re not in it for useful, they’re in it for tenure.</p>
<p>I dropped the class and vowed never to go to graduate school in Computer Science.</p>
<p>The moral of the story is that computer science is not the same as software development. If you’re really really lucky, your school might have a decent software development curriculum, although, they might not, because elite schools think that teaching practical skills is better left to the technical-vocational institutes and the prison rehabilitation programs. You can learn mere programming anywhere. We are Yale University, and we Mold Future World Leaders. You think your $160,000 tuition entititles you to learn about while loops? What do you think this is, some fly-by-night Java seminar at the Airport Marriott? Pshaw.</p>
<p>The trouble is, we don’t really have professional schools in software development, so if you want to be a programmer, you probably majored in Computer Science. Which is a fine subject to major in, but it’s a different subject than software development.</p>
<p>If you’re lucky, though, you can find lots of programming-intensive courses in the CS department, just like you can find lots of courses in the History department where you’ll write enough to learn how to write. And those are the best classes to take. If you love programming, don’t feel bad if you don’t understand the point of those courses in lambda calculus or linear algebra where you never touch a computer. Look for the 400-level courses with Practicum in the name. This is an attempt to hide a useful (shudder) course from the Liberal Artsy Fartsy Administration by dolling it up with a Latin name.</p>
<h2 id="Stop-worrying-about-all-the-jobs-going-to-India"><a href="#Stop-worrying-about-all-the-jobs-going-to-India" class="headerlink" title="Stop worrying about all the jobs going to India."></a>Stop worrying about all the jobs going to India.</h2><p>Well, OK, first of all, if you’re already in India, you never really had to worry about this, so don’t even start worrying about all the jobs going to India. They’re wonderful jobs, enjoy them in good health.</p>
<p>But I keep hearing that enrollment in CS departments is dropping perilously, and one reason I hear for it is “students are afraid to go into a field where all the jobs are going to India.” That’s so wrong for so many reasons. First, trying to choose a career based on a current business fad is foolish. Second, programming is incredibly good training for all kinds of fabulously interesting jobs, such as business process engineering, even if every single programming job does go to India and China. Third, and trust me on this, there’s still an incredible shortage of the really good programmers, here and in India. Yes, there are a bunch of out of work IT people making a lot of noise about how long they’ve been out of work, but you know what? At the risk of pissing them off, really good programmers do have jobs. Fourth, you got any better ideas? What are you going to do, major in History? Then you’ll have no choice but to go to law school. And there’s one thing I do know: 99% of working lawyers hate their jobs, hate every waking minute of it, and they’re working 90 hour weeks, too. Like I said: if you love to program computers, count your blessings: you are in a very fortunate minority of people who can make a great living doing work they love.</p>
<p>Anyway, I don’t think students really think about this. The drop in CS enrollment is merely a resumption of historically normal levels after a big bubble in enrollment caused by dotcom mania. That bubble consisted of people who didn’t really like programming but thought the sexy high paid jobs and the chances to IPO at age 24 were to be found in the CS department. Those people, thankfully, are long gone.</p>
<h2 id="No-matter-what-you-do-get-a-good-summer-internship"><a href="#No-matter-what-you-do-get-a-good-summer-internship" class="headerlink" title="No matter what you do, get a good summer internship."></a>No matter what you do, get a good summer internship.</h2><p>Smart recruiters know that the people who love programming wrote a database for their dentist in 8th grade, and taught at computer camp for three summers before college, and built the content management system for the campus newspaper, and had summer internships at software companies. That’s what they’re looking for on your resume.</p>
<p>If you enjoy programming, the biggest mistake you can make is to take any kind of job–summer, part time, or otherwise–that is not a programming job. I know, every other 19-year-old wants to work in the mall folding shirts, but you have a skill that is incredibly valuable even when you’re 19, and it’s foolish to waste it folding shirts. By the time you graduate, you really should have a resume that lists a whole bunch of programming jobs. The A&amp;F graduates are going to be working at Enterprise Rent-a-Car “helping people with their rental needs.” (Except for Tom Welling. He plays Superman on TV.)</p>
<p>To make your life really easy, and to underscore just how completely self-serving this whole essay is, my company, Fog Creek Software, has summer internships in software development that look great on resumes. “You will most likely learn more about software coding, development, and business with Fog Creek Software than any other internship out there,” says Ben, one of the interns from last summer, and not entirely because I sent a goon out to his dorm room to get him to say that. The application deadline is February 1st. Get on it.</p>
<p>If you follow my advice, you, too, may end up selling stock in Microsoft way too soon, turning down jobs at Google because you want your own office with a door, and other stupid life decisions, but they won’t be my fault. I told you not to listen to me.</p>
<p>WANT TO KNOW MORE?</p>
<p>You’re reading Joel on Software, stuffed with years and years of completely raving mad articles about software development, managing software teams, designing user interfaces, running successful software companies, and rubber duckies.</p>
<p>ABOUT THE AUTHOR.</p>
<p>I’m Joel Spolsky, co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow. More about me.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.joelonsoftware.com/2005/01/02/advice-for-computer-science-college-students/&quot;&gt;Joel Spolsky&lt;/a&gt; co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://6602cxue4uk2h2m2-zippykid.netdna-ssl.com/wp-content/uploads/2016/12/Pong.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
      <category term="Education" scheme="http://ipcreator.me/tags/Education/"/>
    
  </entry>
  
  <entry>
    <title>Undergraduation, Want to start a startup?</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/want-to-start-a-startup-undergraduate/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/want-to-start-a-startup-undergraduate/</id>
    <published>2017-01-20T11:37:06.000Z</published>
    <updated>2017-02-16T00:13:17.299Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.paulgraham.com/college.html" target="_blank" rel="external">Paul Graham</a> July 2004</p>
<p><img src="http://ep.yimg.com/ca/I/paulgraham_2202_8990551" alt=""></p>
<p>March 2005</p>
<p>(Parts of this essay began as replies to students who wrote to me with questions.)</p>
<p>Recently I’ve had several emails from computer science undergrads asking what to do in college. I might not be the best source of advice, because I was a philosophy major in college. But I took so many CS classes that most CS majors thought I was one. I was certainly a hacker, at least.</p>
 <a id="more"></a>
<p>Hacking</p>
<p>What should you do in college to become a good hacker? There are two main things you can do: become very good at programming, and learn a lot about specific, cool problems. These turn out to be equivalent, because each drives you to do the other.</p>
<p>The way to be good at programming is to work (a) a lot (b) on hard problems. And the way to make yourself work on hard problems is to work on some very engaging project.</p>
<p>Odds are this project won’t be a class assignment. My friend Robert learned a lot by writing network software when he was an undergrad. One of his projects was to connect Harvard to the Arpanet; it had been one of the original nodes, but by 1984 the connection had died. [1] Not only was this work not for a class, but because he spent all his time on it and neglected his studies, he was kicked out of school for a year. [2] It all evened out in the end, and now he’s a professor at MIT. But you’ll probably be happier if you don’t go to that extreme; it caused him a lot of worry at the time.</p>
<p>Another way to be good at programming is to find other people who are good at it, and learn what they know. Programmers tend to sort themselves into tribes according to the type of work they do and the tools they use, and some tribes are smarter than others. Look around you and see what the smart people seem to be working on; there’s usually a reason.</p>
<p>Some of the smartest people around you are professors. So one way to find interesting work is to volunteer as a research assistant. Professors are especially interested in people who can solve tedious system-administration type problems for them, so that is a way to get a foot in the door. What they fear are flakes and resume padders. It’s all too common for an assistant to result in a net increase in work. So you have to make it clear you’ll mean a net decrease.</p>
<p>Don’t be put off if they say no. Rejection is almost always less personal than the rejectee imagines. Just move on to the next. (This applies to dating too.)</p>
<p>Beware, because although most professors are smart, not all of them work on interesting stuff. Professors have to publish novel results to advance their careers, but there is more competition in more interesting areas of research. So what less ambitious professors do is turn out a series of papers whose conclusions are novel because no one else cares about them. You’re better off avoiding these.</p>
<p>I never worked as a research assistant, so I feel a bit dishonest recommending that route. I learned to program by writing stuff of my own, particularly by trying to reverse-engineer Winograd’s SHRDLU. I was as obsessed with that program as a mother with a new baby.</p>
<p>Whatever the disadvantages of working by yourself, the advantage is that the project is all your own. You never have to compromise or ask anyone’s permission, and if you have a new idea you can just sit down and start implementing it.</p>
<p>In your own projects you don’t have to worry about novelty (as professors do) or profitability (as businesses do). All that matters is how hard the project is technically, and that has no correlation to the nature of the application. “Serious” applications like databases are often trivial and dull technically (if you ever suffer from insomnia, try reading the technical literature about databases) while “frivolous” applications like games are often very sophisticated. I’m sure there are game companies out there working on products with more intellectual content than the research at the bottom nine tenths of university CS departments.</p>
<p>If I were in college now I’d probably work on graphics: a network game, for example, or a tool for 3D animation. When I was an undergrad there weren’t enough cycles around to make graphics interesting, but it’s hard to imagine anything more fun to work on now.</p>
<p>Math</p>
<p>When I was in college, a lot of the professors believed (or at least wished) that computer science was a branch of math. This idea was strongest at Harvard, where there wasn’t even a CS major till the 1980s; till then one had to major in applied math. But it was nearly as bad at Cornell. When I told the fearsome Professor Conway that I was interested in AI (a hot topic then), he told me I should major in math. I’m still not sure whether he thought AI required math, or whether he thought AI was nonsense and that majoring in something rigorous would cure me of such stupid ambitions.</p>
<p>In fact, the amount of math you need as a hacker is a lot less than most university departments like to admit. I don’t think you need much more than high school math plus a few concepts from the theory of computation. (You have to know what an n^2 algorithm is if you want to avoid writing them.) Unless you’re planning to write math applications, of course. Robotics, for example, is all math.</p>
<p>But while you don’t literally need math for most kinds of hacking, in the sense of knowing 1001 tricks for differentiating formulas, math is very much worth studying for its own sake. It’s a valuable source of metaphors for almost any kind of work.[3] I wish I’d studied more math in college for that reason.</p>
<p>Like a lot of people, I was mathematically abused as a child. I learned to think of math as a collection of formulas that were neither beautiful nor had any relation to my life (despite attempts to translate them into “word problems”), but had to be memorized in order to do well on tests.</p>
<p>One of the most valuable things you could do in college would be to learn what math is really about. This may not be easy, because a lot of good mathematicians are bad teachers. And while there are many popular books on math, few seem good. The best I can think of are W. W. Sawyer’s. And of course Euclid. [4]</p>
<p>Everything</p>
<p>Thomas Huxley said “Try to learn something about everything and everything about something.” Most universities aim at this ideal.</p>
<p>But what’s everything? To me it means, all that people learn in the course of working honestly on hard problems. All such work tends to be related, in that ideas and techniques from one field can often be transplanted successfully to others. Even others that seem quite distant. For example, I write essays the same way I write software: I sit down and blow out a lame version 1 as fast as I can type, then spend several weeks rewriting it.</p>
<p>Working on hard problems is not, by itself, enough. Medieval alchemists were working on a hard problem, but their approach was so bogus that there was little to learn from studying it, except possibly about people’s ability to delude themselves. Unfortunately the sort of AI I was trying to learn in college had the same flaw: a very hard problem, blithely approached with hopelessly inadequate techniques. Bold? Closer to fraudulent.</p>
<p>The social sciences are also fairly bogus, because they’re so much influenced by intellectual fashions. If a physicist met a colleague from 100 years ago, he could teach him some new things; if a psychologist met a colleague from 100 years ago, they’d just get into an ideological argument. Yes, of course, you’ll learn something by taking a psychology class. The point is, you’ll learn more by taking a class in another department.</p>
<p>The worthwhile departments, in my opinion, are math, the hard sciences, engineering, history (especially economic and social history, and the history of science), architecture, and the classics. A survey course in art history may be worthwhile. Modern literature is important, but the way to learn about it is just to read. I don’t know enough about music to say.</p>
<p>You can skip the social sciences, philosophy, and the various departments created recently in response to political pressures. Many of these fields talk about important problems, certainly. But the way they talk about them is useless. For example, philosophy talks, among other things, about our obligations to one another; but you can learn more about this from a wise grandmother or E. B. White than from an academic philosopher.</p>
<p>I speak here from experience. I should probably have been offended when people laughed at Clinton for saying “It depends on what the meaning of the word ‘is’ is.” I took about five classes in college on what the meaning of “is” is.</p>
<p>Another way to figure out which fields are worth studying is to create the dropout graph. For example, I know many people who switched from math to computer science because they found math too hard, and no one who did the opposite. People don’t do hard things gratuitously; no one will work on a harder problem unless it is proportionately (or at least log(n)) more rewarding. So probably math is more worth studying than computer science. By similar comparisons you can make a graph of all the departments in a university. At the bottom you’ll find the subjects with least intellectual content.</p>
<p>If you use this method, you’ll get roughly the same answer I just gave.</p>
<p>Language courses are an anomaly. I think they’re better considered as extracurricular activities, like pottery classes. They’d be far more useful when combined with some time living in a country where the language is spoken. On a whim I studied Arabic as a freshman. It was a lot of work, and the only lasting benefits were a weird ability to identify semitic roots and some insights into how people recognize words.</p>
<p>Studio art and creative writing courses are wildcards. Usually you don’t get taught much: you just work (or don’t work) on whatever you want, and then sit around offering “crits” of one another’s creations under the vague supervision of the teacher. But writing and art are both very hard problems that (some) people work honestly at, so they’re worth doing, especially if you can find a good teacher.</p>
<p>Jobs</p>
<p>Of course college students have to think about more than just learning. There are also two practical problems to consider: jobs, and graduate school.</p>
<p>In theory a liberal education is not supposed to supply job training. But everyone knows this is a bit of a fib. Hackers at every college learn practical skills, and not by accident.</p>
<p>What you should learn to get a job depends on the kind you want. If you want to work in a big company, learn how to hack Blub on Windows. If you want to work at a cool little company or research lab, you’ll do better to learn Ruby on Linux. And if you want to start your own company, which I think will be more and more common, master the most powerful tools you can find, because you’re going to be in a race against your competitors, and they’ll be your horse.</p>
<p>There is not a direct correlation between the skills you should learn in college and those you’ll use in a job. You should aim slightly high in college.</p>
<p>In workouts a football player may bench press 300 pounds, even though he may never have to exert anything like that much force in the course of a game. Likewise, if your professors try to make you learn stuff that’s more advanced than you’ll need in a job, it may not just be because they’re academics, detached from the real world. They may be trying to make you lift weights with your brain.</p>
<p>The programs you write in classes differ in three critical ways from the ones you’ll write in the real world: they’re small; you get to start from scratch; and the problem is usually artificial and predetermined. In the real world, programs are bigger, tend to involve existing code, and often require you to figure out what the problem is before you can solve it.</p>
<p>You don’t have to wait to leave (or even enter) college to learn these skills. If you want to learn how to deal with existing code, for example, you can contribute to open-source projects. The sort of employer you want to work for will be as impressed by that as good grades on class assignments.</p>
<p>In existing open-source projects you don’t get much practice at the third skill, deciding what problems to solve. But there’s nothing to stop you starting new projects of your own. And good employers will be even more impressed with that.</p>
<p>What sort of problem should you try to solve? One way to answer that is to ask what you need as a user. For example, I stumbled on a good algorithm for spam filtering because I wanted to stop getting spam. Now what I wish I had was a mail reader that somehow prevented my inbox from filling up. I tend to use my inbox as a todo list. But that’s like using a screwdriver to open bottles; what one really wants is a bottle opener.</p>
<p>Grad School</p>
<p>What about grad school? Should you go? And how do you get into a good one?</p>
<p>In principle, grad school is professional training in research, and you shouldn’t go unless you want to do research as a career. And yet half the people who get PhDs in CS don’t go into research. I didn’t go to grad school to become a professor. I went because I wanted to learn more.</p>
<p>So if you’re mainly interested in hacking and you go to grad school, you’ll find a lot of other people who are similarly out of their element. And if half the people around you are out of their element in the same way you are, are you really out of your element?</p>
<p>There’s a fundamental problem in “computer science,” and it surfaces in situations like this. No one is sure what “research” is supposed to be. A lot of research is hacking that had to be crammed into the form of an academic paper to yield one more quantum of publication.</p>
<p>So it’s kind of misleading to ask whether you’ll be at home in grad school, because very few people are quite at home in computer science. The whole field is uncomfortable in its own skin. So the fact that you’re mainly interested in hacking shouldn’t deter you from going to grad school. Just be warned you’ll have to do a lot of stuff you don’t like.</p>
<p>Number one will be your dissertation. Almost everyone hates their dissertation by the time they’re done with it. The process inherently tends to produce an unpleasant result, like a cake made out of whole wheat flour and baked for twelve hours. Few dissertations are read with pleasure, especially by their authors.</p>
<p>But thousands before you have suffered through writing a dissertation. And aside from that, grad school is close to paradise. Many people remember it as the happiest time of their lives. And nearly all the rest, including me, remember it as a period that would have been, if they hadn’t had to write a dissertation. [5]</p>
<p>The danger with grad school is that you don’t see the scary part upfront. PhD programs start out as college part 2, with several years of classes. So by the time you face the horror of writing a dissertation, you’re already several years in. If you quit now, you’ll be a grad-school dropout, and you probably won’t like that idea. When Robert got kicked out of grad school for writing the Internet worm of 1988, I envied him enormously for finding a way out without the stigma of failure.</p>
<p>On the whole, grad school is probably better than most alternatives. You meet a lot of smart people, and your glum procrastination will at least be a powerful common bond. And of course you have a PhD at the end. I forgot about that. I suppose that’s worth something.</p>
<p>The greatest advantage of a PhD (besides being the union card of academia, of course) may be that it gives you some baseline confidence. For example, the Honeywell thermostats in my house have the most atrocious UI. My mother, who has the same model, diligently spent a day reading the user’s manual to learn how to operate hers. She assumed the problem was with her. But I can think to myself “If someone with a PhD in computer science can’t understand this thermostat, it must be badly designed.”</p>
<p>If you still want to go to grad school after this equivocal recommendation, I can give you solid advice about how to get in. A lot of my friends are CS professors now, so I have the inside story about admissions. It’s quite different from college. At most colleges, admissions officers decide who gets in. For PhD programs, the professors do. And they try to do it well, because the people they admit are going to be working for them.</p>
<p>Apparently only recommendations really matter at the best schools. Standardized tests count for nothing, and grades for little. The essay is mostly an opportunity to disqualify yourself by saying something stupid. The only thing professors trust is recommendations, preferably from people they know. [6]</p>
<p>So if you want to get into a PhD program, the key is to impress your professors. And from my friends who are professors I know what impresses them: not merely trying to impress them. They’re not impressed by students who get good grades or want to be their research assistants so they can get into grad school. They’re impressed by students who get good grades and want to be their research assistants because they’re genuinely interested in the topic.</p>
<p>So the best thing you can do in college, whether you want to get into grad school or just be good at hacking, is figure out what you truly like. It’s hard to trick professors into letting you into grad school, and impossible to trick problems into letting you solve them. College is where faking stops working. From this point, unless you want to go work for a big company, which is like reverting to high school, the only way forward is through doing what you love.</p>
<p>Notes</p>
<p>[1] No one seems to have minded, which shows how unimportant the Arpanet (which became the Internet) was as late as 1984.</p>
<p>[2] This is why, when I became an employer, I didn’t care about GPAs. In fact, we actively sought out people who’d failed out of school. We once put up posters around Harvard saying “Did you just get kicked out for doing badly in your classes because you spent all your time working on some project of your own? Come work for us!” We managed to find a kid who had been, and he was a great hacker.</p>
<p>When Harvard kicks undergrads out for a year, they have to get jobs. The idea is to show them how awful the real world is, so they’ll understand how lucky they are to be in college. This plan backfired with the guy who came to work for us, because he had more fun than he’d had in school, and made more that year from stock options than any of his professors did in salary. So instead of crawling back repentant at the end of the year, he took another year off and went to Europe. He did eventually graduate at about 26.</p>
<p>[3] Eric Raymond says the best metaphors for hackers are in set theory, combinatorics, and graph theory.</p>
<p>Trevor Blackwell reminds you to take math classes intended for math majors. “‘Math for engineers’ classes sucked mightily. In fact any ‘x for engineers’ sucks, where x includes math, law, writing and visual design.”</p>
<p>[4] Other highly recommended books: What is Mathematics?, by Courant and Robbins; Geometry and the Imagination by Hilbert and Cohn-Vossen. And for those interested in graphic design, Byrne’s Euclid.</p>
<p>[5] If you wanted to have the perfect life, the thing to do would be to go to grad school, secretly write your dissertation in the first year or two, and then just enjoy yourself for the next three years, dribbling out a chapter at a time. This prospect will make grad students’ mouths water, but I know of no one who’s had the discipline to pull it off.</p>
<p>[6] One professor friend says that 15-20% of the grad students they admit each year are “long shots.” But what he means by long shots are people whose applications are perfect in every way, except that no one on the admissions committee knows the professors who wrote the recommendations.</p>
<p>So if you want to get into grad school in the sciences, you need to go to college somewhere with real research professors. Otherwise you’ll seem a risky bet to admissions committees, no matter how good you are.</p>
<p>Which implies a surprising but apparently inevitable consequence: little liberal arts colleges are doomed. Most smart high school kids at least consider going into the sciences, even if they ultimately choose not to. Why go to a college that limits their options?</p>
<p>Thanks to Trevor Blackwell, Alex Lewin, Jessica Livingston, Robert Morris, Eric Raymond, and several anonymous CS professors for reading drafts of this, and to the students whose questions began it.</p>
<pre><code>Joel Spolsky: [Advice for Computer Science College Students](http://www.joelonsoftware.com/articles/CollegeAdvice.html)
Eric Raymond: [How to Become a Hacker](http://www.catb.org/~esr/faqs/hacker-howto.html)
</code></pre><h2 id="More-Advice-for-Undergrads"><a href="#More-Advice-for-Undergrads" class="headerlink" title="More Advice for Undergrads"></a>More Advice for Undergrads</h2><pre><code>I asked several friends who were professors and/or eminent hackers what they thought of Undergraduation. Their comments were so good that I thought I&apos;d just give them directly to you. I&apos;ve given them all codenames for now, since some may want to remain anonymous.

NT:

The one thing that I felt was missing from your essay was a statement supporting or dispelling the notion that CS is for loners. I disagree with this notion. I love hacking, but I love it even more when it&apos;s a shared experience. The hard problems seem just a bit more surmountable when there&apos;s two of you.

Of course, Fred Brooks&apos;s law about adding manpower comes into play eventually. The rule: work in small groups with good people. Stay away from large bureaucratic organizations where status reports are more important than thinking outside the box. There are many individual aspects to CS, just like art. But, being an individual doesn&apos;t mean that the machine takes the place of good friends, colleagues, and mentors.

TO:

I think you should say &quot;College is where faking starts to stop working.&quot;

FS:

Math is more difficult than CS, no question. However, it is not at all clear to me that math has as much intellectual content as CS. The math hills are individually harder to climb, but CS is a bigger piece of landscape. (Formally, CS has to encompass reasoning about stateful objects with histories. There are important ways in which this is more difficult and general than pure axiomatic systems.)

Empirically, I don&apos;t think the difference between math and CS is very useful for predicting how interesting and effective a thinker will come out the other end. So, while I agree with the spirit of your &quot;dropout graph&quot; heuristic, I think math and CS are an unhelpful choice to explain it with. Much better to note that both are hard subjects with real content, and contrast them with some sort of blatant basket-weaving like political science or (urgh) &quot;ethnic studies.&quot;

&quot;They may be trying to make you lift weights with your brain.&quot; Indeed; I think pure mathematics makes excellent weightlifting.

SA:

The problem with graphics as an application is that doing a decent 3D game has a large component of movie making in it. You need motion capture and an art department for all the textures and backgrounds. Nobody will be impressed with pink cubes and green spheres bouncing around on the screen. I think the technology has pretty much surpassed anyone&apos;s ability to do anything simple and cool with it.

DF:

I found, when I was studying mathematics, that 2 things were true: (1) the teacher was not too good and (2) the book was not too good. So I would always buy a half-dozen books on the topic and try to get the full picture by reading the same sections in each book. The combination helped me understand much more than the sum of the content. Also, I was never opposed to reading something as much as 10 times until I squeezed everything out of it.

I have found mathematics and especially formal logic to be an indispensible tool for structuring ideas. It was like Latin for me. Latin was this very clean natural language and logic was this very clean formal language. I had to teach it to myself because the logic course I had was the first 30 pages of Mendelsohn. When you want to say something unequivocally, describing formally is a good first start.

When you want to understand, for example, the excitement of monads, understanding logic and some category theory helps. Category theory is also quite pretty. It simply says that everything has to be described in terms of function composition and this operator has to satisfy certain properties.

If you think of logic as something alive, which allows you to prove theorems, it is fascinating. Just think about it: prove theorems by computer. It is mind-boggling. It will not likely lead to a start-up being successful, but what a moment when you prove a theorem without heuristics, etc.

I have insisted that all my graduate students minor in logic, so that should say something.

ML:

The real reason to study math is not that it&apos;s useful but that it&apos;s cool. This should be all the reason a would-be hacker needs. Also, with its emphasis on rigor and abstraction, it&apos;s cool in a lot of the same ways as programming at its best. The fact that it&apos;s occasionally useful as well is just lagniappe.

I also disagree that good mathematicians tend to be bad teachers. Having enjoyed the privilege of an expensive education, I am of the opinion that the very best mathematicians are usually (certainly not always) rather good teachers and are sometimes extraordinarily good. The real reason it is hard to learn what math is about is that mathematical understanding requires new and difficult (at least at first) ways of thinking. Cookbook calculus courses sidestep these difficulties and therefore teach little of value. Really understanding calculus was hard for Newton and is hard today.
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.paulgraham.com/college.html&quot;&gt;Paul Graham&lt;/a&gt; July 2004&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ep.yimg.com/ca/I/paulgraham_2202_8990551&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;March 2005&lt;/p&gt;
&lt;p&gt;(Parts of this essay began as replies to students who wrote to me with questions.)&lt;/p&gt;
&lt;p&gt;Recently I’ve had several emails from computer science undergrads asking what to do in college. I might not be the best source of advice, because I was a philosophy major in college. But I took so many CS classes that most CS majors thought I was one. I was certainly a hacker, at least.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
      <category term="Education" scheme="http://ipcreator.me/tags/Education/"/>
    
  </entry>
  
  <entry>
    <title>Great hacker, Want to start a startup?</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/want-to-start-a-startup-great-hacker/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/want-to-start-a-startup-great-hacker/</id>
    <published>2017-01-20T11:37:06.000Z</published>
    <updated>2017-02-15T13:07:10.397Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.paulgraham.com/gh.html" target="_blank" rel="external">Paul Graham</a> July 2004</p>
<p><img src="http://ep.yimg.com/ca/I/paulgraham_2202_9271894" alt=""></p>
<p>(This essay is derived from a talk at Oscon 2004.)</p>
<p>A few months ago I finished a new book, and in reviews I keep noticing words like “provocative’’ and “controversial.’’ To say nothing of “idiotic.’’</p>
<p>I didn’t mean to make the book controversial. I was trying to make it efficient. I didn’t want to waste people’s time telling them things they already knew. It’s more efficient just to give them the diffs. But I suppose that’s bound to yield an alarming book.</p>
 <a id="more"></a>
<p>Edisons</p>
<p>There’s no controversy about which idea is most controversial: the suggestion that variation in wealth might not be as big a problem as we think.</p>
<p>I didn’t say in the book that variation in wealth was in itself a good thing. I said in some situations it might be a sign of good things. A throbbing headache is not a good thing, but it can be a sign of a good thing– for example, that you’re recovering consciousness after being hit on the head.</p>
<p>Variation in wealth can be a sign of variation in productivity. (In a society of one, they’re identical.) And that is almost certainly a good thing: if your society has no variation in productivity, it’s probably not because everyone is Thomas Edison. It’s probably because you have no Thomas Edisons.</p>
<p>In a low-tech society you don’t see much variation in productivity. If you have a tribe of nomads collecting sticks for a fire, how much more productive is the best stick gatherer going to be than the worst? A factor of two? Whereas when you hand people a complex tool like a computer, the variation in what they can do with it is enormous.</p>
<p>That’s not a new idea. Fred Brooks wrote about it in 1974, and the study he quoted was published in 1968. But I think he underestimated the variation between programmers. He wrote about productivity in lines of code: the best programmers can solve a given problem in a tenth the time. But what if the problem isn’t given? In programming, as in many fields, the hard part isn’t solving problems, but deciding what problems to solve. Imagination is hard to measure, but in practice it dominates the kind of productivity that’s measured in lines of code.</p>
<p>Productivity varies in any field, but there are few in which it varies so much. The variation between programmers is so great that it becomes a difference in kind. I don’t think this is something intrinsic to programming, though. In every field, technology magnifies differences in productivity. I think what’s happening in programming is just that we have a lot of technological leverage. But in every field the lever is getting longer, so the variation we see is something that more and more fields will see as time goes on. And the success of companies, and countries, will depend increasingly on how they deal with it.</p>
<p>If variation in productivity increases with technology, then the contribution of the most productive individuals will not only be disproportionately large, but will actually grow with time. When you reach the point where 90% of a group’s output is created by 1% of its members, you lose big if something (whether Viking raids, or central planning) drags their productivity down to the average.</p>
<p>If we want to get the most out of them, we need to understand these especially productive people. What motivates them? What do they need to do their jobs? How do you recognize them? How do you get them to come and work for you? And then of course there’s the question, how do you become one?</p>
<p>More than Money</p>
<p>I know a handful of super-hackers, so I sat down and thought about what they have in common. Their defining quality is probably that they really love to program. Ordinary programmers write code to pay the bills. Great hackers think of it as something they do for fun, and which they’re delighted to find people will pay them for.</p>
<p>Great programmers are sometimes said to be indifferent to money. This isn’t quite true. It is true that all they really care about is doing interesting work. But if you make enough money, you get to work on whatever you want, and for that reason hackers are attracted by the idea of making really large amounts of money. But as long as they still have to show up for work every day, they care more about what they do there than how much they get paid for it.</p>
<p>Economically, this is a fact of the greatest importance, because it means you don’t have to pay great hackers anything like what they’re worth. A great programmer might be ten or a hundred times as productive as an ordinary one, but he’ll consider himself lucky to get paid three times as much. As I’ll explain later, this is partly because great hackers don’t know how good they are. But it’s also because money is not the main thing they want.</p>
<p>What do hackers want? Like all craftsmen, hackers like good tools. In fact, that’s an understatement. Good hackers find it unbearable to use bad tools. They’ll simply refuse to work on projects with the wrong infrastructure.</p>
<p>At a startup I once worked for, one of the things pinned up on our bulletin board was an ad from IBM. It was a picture of an AS400, and the headline read, I think, “hackers despise it.’’ [1]</p>
<p>When you decide what infrastructure to use for a project, you’re not just making a technical decision. You’re also making a social decision, and this may be the more important of the two. For example, if your company wants to write some software, it might seem a prudent choice to write it in Java. But when you choose a language, you’re also choosing a community. The programmers you’ll be able to hire to work on a Java project won’t be as smart as the ones you could get to work on a project written in Python. And the quality of your hackers probably matters more than the language you choose. Though, frankly, the fact that good hackers prefer Python to Java should tell you something about the relative merits of those languages.</p>
<p>Business types prefer the most popular languages because they view languages as standards. They don’t want to bet the company on Betamax. The thing about languages, though, is that they’re not just standards. If you have to move bits over a network, by all means use TCP/IP. But a programming language isn’t just a format. A programming language is a medium of expression.</p>
<p>I’ve read that Java has just overtaken Cobol as the most popular language. As a standard, you couldn’t wish for more. But as a medium of expression, you could do a lot better. Of all the great programmers I can think of, I know of only one who would voluntarily program in Java. And of all the great programmers I can think of who don’t work for Sun, on Java, I know of zero.</p>
<p>Great hackers also generally insist on using open source software. Not just because it’s better, but because it gives them more control. Good hackers insist on control. This is part of what makes them good hackers: when something’s broken, they need to fix it. You want them to feel this way about the software they’re writing for you. You shouldn’t be surprised when they feel the same way about the operating system.</p>
<p>A couple years ago a venture capitalist friend told me about a new startup he was involved with. It sounded promising. But the next time I talked to him, he said they’d decided to build their software on Windows NT, and had just hired a very experienced NT developer to be their chief technical officer. When I heard this, I thought, these guys are doomed. One, the CTO couldn’t be a first rate hacker, because to become an eminent NT developer he would have had to use NT voluntarily, multiple times, and I couldn’t imagine a great hacker doing that; and two, even if he was good, he’d have a hard time hiring anyone good to work for him if the project had to be built on NT. [2]</p>
<p>The Final Frontier</p>
<p>After software, the most important tool to a hacker is probably his office. Big companies think the function of office space is to express rank. But hackers use their offices for more than that: they use their office as a place to think in. And if you’re a technology company, their thoughts are your product. So making hackers work in a noisy, distracting environment is like having a paint factory where the air is full of soot.</p>
<p>The cartoon strip Dilbert has a lot to say about cubicles, and with good reason. All the hackers I know despise them. The mere prospect of being interrupted is enough to prevent hackers from working on hard problems. If you want to get real work done in an office with cubicles, you have two options: work at home, or come in early or late or on a weekend, when no one else is there. Don’t companies realize this is a sign that something is broken? An office environment is supposed to be something that helps you work, not something you work despite.</p>
<p>Companies like Cisco are proud that everyone there has a cubicle, even the CEO. But they’re not so advanced as they think; obviously they still view office space as a badge of rank. Note too that Cisco is famous for doing very little product development in house. They get new technology by buying the startups that created it– where presumably the hackers did have somewhere quiet to work.</p>
<p>One big company that understands what hackers need is Microsoft. I once saw a recruiting ad for Microsoft with a big picture of a door. Work for us, the premise was, and we’ll give you a place to work where you can actually get work done. And you know, Microsoft is remarkable among big companies in that they are able to develop software in house. Not well, perhaps, but well enough.</p>
<p>If companies want hackers to be productive, they should look at what they do at home. At home, hackers can arrange things themselves so they can get the most done. And when they work at home, hackers don’t work in noisy, open spaces; they work in rooms with doors. They work in cosy, neighborhoody places with people around and somewhere to walk when they need to mull something over, instead of in glass boxes set in acres of parking lots. They have a sofa they can take a nap on when they feel tired, instead of sitting in a coma at their desk, pretending to work. There’s no crew of people with vacuum cleaners that roars through every evening during the prime hacking hours. There are no meetings or, God forbid, corporate retreats or team-building exercises. And when you look at what they’re doing on that computer, you’ll find it reinforces what I said earlier about tools. They may have to use Java and Windows at work, but at home, where they can choose for themselves, you’re more likely to find them using Perl and Linux.</p>
<p>Indeed, these statistics about Cobol or Java being the most popular language can be misleading. What we ought to look at, if we want to know what tools are best, is what hackers choose when they can choose freely– that is, in projects of their own. When you ask that question, you find that open source operating systems already have a dominant market share, and the number one language is probably Perl.</p>
<p>Interesting</p>
<p>Along with good tools, hackers want interesting projects. What makes a project interesting? Well, obviously overtly sexy applications like stealth planes or special effects software would be interesting to work on. But any application can be interesting if it poses novel technical challenges. So it’s hard to predict which problems hackers will like, because some become interesting only when the people working on them discover a new kind of solution. Before ITA (who wrote the software inside Orbitz), the people working on airline fare searches probably thought it was one of the most boring applications imaginable. But ITA made it interesting by redefining the problem in a more ambitious way.</p>
<p>I think the same thing happened at Google. When Google was founded, the conventional wisdom among the so-called portals was that search was boring and unimportant. But the guys at Google didn’t think search was boring, and that’s why they do it so well.</p>
<p>This is an area where managers can make a difference. Like a parent saying to a child, I bet you can’t clean up your whole room in ten minutes, a good manager can sometimes redefine a problem as a more interesting one. Steve Jobs seems to be particularly good at this, in part simply by having high standards. There were a lot of small, inexpensive computers before the Mac. He redefined the problem as: make one that’s beautiful. And that probably drove the developers harder than any carrot or stick could.</p>
<p>They certainly delivered. When the Mac first appeared, you didn’t even have to turn it on to know it would be good; you could tell from the case. A few weeks ago I was walking along the street in Cambridge, and in someone’s trash I saw what appeared to be a Mac carrying case. I looked inside, and there was a Mac SE. I carried it home and plugged it in, and it booted. The happy Macintosh face, and then the finder. My God, it was so simple. It was just like … Google.</p>
<p>Hackers like to work for people with high standards. But it’s not enough just to be exacting. You have to insist on the right things. Which usually means that you have to be a hacker yourself. I’ve seen occasional articles about how to manage programmers. Really there should be two articles: one about what to do if you are yourself a programmer, and one about what to do if you’re not. And the second could probably be condensed into two words: give up.</p>
<p>The problem is not so much the day to day management. Really good hackers are practically self-managing. The problem is, if you’re not a hacker, you can’t tell who the good hackers are. A similar problem explains why American cars are so ugly. I call it the design paradox. You might think that you could make your products beautiful just by hiring a great designer to design them. But if you yourself don’t have good taste, how are you going to recognize a good designer? By definition you can’t tell from his portfolio. And you can’t go by the awards he’s won or the jobs he’s had, because in design, as in most fields, those tend to be driven by fashion and schmoozing, with actual ability a distant third. There’s no way around it: you can’t manage a process intended to produce beautiful things without knowing what beautiful is. American cars are ugly because American car companies are run by people with bad taste.</p>
<p>Many people in this country think of taste as something elusive, or even frivolous. It is neither. To drive design, a manager must be the most demanding user of a company’s products. And if you have really good taste, you can, as Steve Jobs does, make satisfying you the kind of problem that good people like to work on.</p>
<p>Nasty Little Problems</p>
<p>It’s pretty easy to say what kinds of problems are not interesting: those where instead of solving a few big, clear, problems, you have to solve a lot of nasty little ones. One of the worst kinds of projects is writing an interface to a piece of software that’s full of bugs. Another is when you have to customize something for an individual client’s complex and ill-defined needs. To hackers these kinds of projects are the death of a thousand cuts.</p>
<p>The distinguishing feature of nasty little problems is that you don’t learn anything from them. Writing a compiler is interesting because it teaches you what a compiler is. But writing an interface to a buggy piece of software doesn’t teach you anything, because the bugs are random. [3] So it’s not just fastidiousness that makes good hackers avoid nasty little problems. It’s more a question of self-preservation. Working on nasty little problems makes you stupid. Good hackers avoid it for the same reason models avoid cheeseburgers.</p>
<p>Of course some problems inherently have this character. And because of supply and demand, they pay especially well. So a company that found a way to get great hackers to work on tedious problems would be very successful. How would you do it?</p>
<p>One place this happens is in startups. At our startup we had Robert Morris working as a system administrator. That’s like having the Rolling Stones play at a bar mitzvah. You can’t hire that kind of talent. But people will do any amount of drudgery for companies of which they’re the founders. [4]</p>
<p>Bigger companies solve the problem by partitioning the company. They get smart people to work for them by establishing a separate R&amp;D department where employees don’t have to work directly on customers’ nasty little problems. [5] In this model, the research department functions like a mine. They produce new ideas; maybe the rest of the company will be able to use them.</p>
<p>You may not have to go to this extreme. Bottom-up programming suggests another way to partition the company: have the smart people work as toolmakers. If your company makes software to do x, have one group that builds tools for writing software of that type, and another that uses these tools to write the applications. This way you might be able to get smart people to write 99% of your code, but still keep them almost as insulated from users as they would be in a traditional research department. The toolmakers would have users, but they’d only be the company’s own developers. [6]</p>
<p>If Microsoft used this approach, their software wouldn’t be so full of security holes, because the less smart people writing the actual applications wouldn’t be doing low-level stuff like allocating memory. Instead of writing Word directly in C, they’d be plugging together big Lego blocks of Word-language. (Duplo, I believe, is the technical term.)</p>
<p>Clumping</p>
<p>Along with interesting problems, what good hackers like is other good hackers. Great hackers tend to clump together– sometimes spectacularly so, as at Xerox Parc. So you won’t attract good hackers in linear proportion to how good an environment you create for them. The tendency to clump means it’s more like the square of the environment. So it’s winner take all. At any given time, there are only about ten or twenty places where hackers most want to work, and if you aren’t one of them, you won’t just have fewer great hackers, you’ll have zero.</p>
<p>Having great hackers is not, by itself, enough to make a company successful. It works well for Google and ITA, which are two of the hot spots right now, but it didn’t help Thinking Machines or Xerox. Sun had a good run for a while, but their business model is a down elevator. In that situation, even the best hackers can’t save you.</p>
<p>I think, though, that all other things being equal, a company that can attract great hackers will have a huge advantage. There are people who would disagree with this. When we were making the rounds of venture capital firms in the 1990s, several told us that software companies didn’t win by writing great software, but through brand, and dominating channels, and doing the right deals.</p>
<p>They really seemed to believe this, and I think I know why. I think what a lot of VCs are looking for, at least unconsciously, is the next Microsoft. And of course if Microsoft is your model, you shouldn’t be looking for companies that hope to win by writing great software. But VCs are mistaken to look for the next Microsoft, because no startup can be the next Microsoft unless some other company is prepared to bend over at just the right moment and be the next IBM.</p>
<p>It’s a mistake to use Microsoft as a model, because their whole culture derives from that one lucky break. Microsoft is a bad data point. If you throw them out, you find that good products do tend to win in the market. What VCs should be looking for is the next Apple, or the next Google.</p>
<p>I think Bill Gates knows this. What worries him about Google is not the power of their brand, but the fact that they have better hackers. [7]</p>
<p>Recognition</p>
<p>So who are the great hackers? How do you know when you meet one? That turns out to be very hard. Even hackers can’t tell. I’m pretty sure now that my friend Trevor Blackwell is a great hacker. You may have read on Slashdot how he made his own Segway. The remarkable thing about this project was that he wrote all the software in one day (in Python, incidentally).</p>
<p>For Trevor, that’s par for the course. But when I first met him, I thought he was a complete idiot. He was standing in Robert Morris’s office babbling at him about something or other, and I remember standing behind him making frantic gestures at Robert to shoo this nut out of his office so we could go to lunch. Robert says he misjudged Trevor at first too. Apparently when Robert first met him, Trevor had just begun a new scheme that involved writing down everything about every aspect of his life on a stack of index cards, which he carried with him everywhere. He’d also just arrived from Canada, and had a strong Canadian accent and a mullet.</p>
<p>The problem is compounded by the fact that hackers, despite their reputation for social obliviousness, sometimes put a good deal of effort into seeming smart. When I was in grad school I used to hang around the MIT AI Lab occasionally. It was kind of intimidating at first. Everyone there spoke so fast. But after a while I learned the trick of speaking fast. You don’t have to think any faster; just use twice as many words to say everything.</p>
<p>With this amount of noise in the signal, it’s hard to tell good hackers when you meet them. I can’t tell, even now. You also can’t tell from their resumes. It seems like the only way to judge a hacker is to work with him on something.</p>
<p>And this is the reason that high-tech areas only happen around universities. The active ingredient here is not so much the professors as the students. Startups grow up around universities because universities bring together promising young people and make them work on the same projects. The smart ones learn who the other smart ones are, and together they cook up new projects of their own.</p>
<p>Because you can’t tell a great hacker except by working with him, hackers themselves can’t tell how good they are. This is true to a degree in most fields. I’ve found that people who are great at something are not so much convinced of their own greatness as mystified at why everyone else seems so incompetent.</p>
<p>But it’s particularly hard for hackers to know how good they are, because it’s hard to compare their work. This is easier in most other fields. In the hundred meters, you know in 10 seconds who’s fastest. Even in math there seems to be a general consensus about which problems are hard to solve, and what constitutes a good solution. But hacking is like writing. Who can say which of two novels is better? Certainly not the authors.</p>
<p>With hackers, at least, other hackers can tell. That’s because, unlike novelists, hackers collaborate on projects. When you get to hit a few difficult problems over the net at someone, you learn pretty quickly how hard they hit them back. But hackers can’t watch themselves at work. So if you ask a great hacker how good he is, he’s almost certain to reply, I don’t know. He’s not just being modest. He really doesn’t know.</p>
<p>And none of us know, except about people we’ve actually worked with. Which puts us in a weird situation: we don’t know who our heroes should be. The hackers who become famous tend to become famous by random accidents of PR. Occasionally I need to give an example of a great hacker, and I never know who to use. The first names that come to mind always tend to be people I know personally, but it seems lame to use them. So, I think, maybe I should say Richard Stallman, or Linus Torvalds, or Alan Kay, or someone famous like that. But I have no idea if these guys are great hackers. I’ve never worked with them on anything.</p>
<p>If there is a Michael Jordan of hacking, no one knows, including him.</p>
<p>Cultivation</p>
<p>Finally, the question the hackers have all been wondering about: how do you become a great hacker? I don’t know if it’s possible to make yourself into one. But it’s certainly possible to do things that make you stupid, and if you can make yourself stupid, you can probably make yourself smart too.</p>
<p>The key to being a good hacker may be to work on what you like. When I think about the great hackers I know, one thing they have in common is the extreme difficulty of making them work on anything they don’t want to. I don’t know if this is cause or effect; it may be both.</p>
<p>To do something well you have to love it. So to the extent you can preserve hacking as something you love, you’re likely to do it well. Try to keep the sense of wonder you had about programming at age 14. If you’re worried that your current job is rotting your brain, it probably is.</p>
<p>The best hackers tend to be smart, of course, but that’s true in a lot of fields. Is there some quality that’s unique to hackers? I asked some friends, and the number one thing they mentioned was curiosity. I’d always supposed that all smart people were curious– that curiosity was simply the first derivative of knowledge. But apparently hackers are particularly curious, especially about how things work. That makes sense, because programs are in effect giant descriptions of how things work.</p>
<p>Several friends mentioned hackers’ ability to concentrate– their ability, as one put it, to “tune out everything outside their own heads.’’ I’ve certainly noticed this. And I’ve heard several hackers say that after drinking even half a beer they can’t program at all. So maybe hacking does require some special ability to focus. Perhaps great hackers can load a large amount of context into their head, so that when they look at a line of code, they see not just that line but the whole program around it. John McPhee wrote that Bill Bradley’s success as a basketball player was due partly to his extraordinary peripheral vision. “Perfect’’ eyesight means about 47 degrees of vertical peripheral vision. Bill Bradley had 70; he could see the basket when he was looking at the floor. Maybe great hackers have some similar inborn ability. (I cheat by using a very dense language, which shrinks the court.)</p>
<p>This could explain the disconnect over cubicles. Maybe the people in charge of facilities, not having any concentration to shatter, have no idea that working in a cubicle feels to a hacker like having one’s brain in a blender. (Whereas Bill, if the rumors of autism are true, knows all too well.)</p>
<p>One difference I’ve noticed between great hackers and smart people in general is that hackers are more politically incorrect. To the extent there is a secret handshake among good hackers, it’s when they know one another well enough to express opinions that would get them stoned to death by the general public. And I can see why political incorrectness would be a useful quality in programming. Programs are very complex and, at least in the hands of good programmers, very fluid. In such situations it’s helpful to have a habit of questioning assumptions.</p>
<p>Can you cultivate these qualities? I don’t know. But you can at least not repress them. So here is my best shot at a recipe. If it is possible to make yourself into a great hacker, the way to do it may be to make the following deal with yourself: you never have to work on boring projects (unless your family will starve otherwise), and in return, you’ll never allow yourself to do a half-assed job. All the great hackers I know seem to have made that deal, though perhaps none of them had any choice in the matter.</p>
<p>Notes</p>
<p>[1] In fairness, I have to say that IBM makes decent hardware. I wrote this on an IBM laptop.</p>
<p>[2] They did turn out to be doomed. They shut down a few months later.</p>
<p>[3] I think this is what people mean when they talk about the “meaning of life.” On the face of it, this seems an odd idea. Life isn’t an expression; how could it have meaning? But it can have a quality that feels a lot like meaning. In a project like a compiler, you have to solve a lot of problems, but the problems all fall into a pattern, as in a signal. Whereas when the problems you have to solve are random, they seem like noise.</p>
<p>[4] Einstein at one point worked designing refrigerators. (He had equity.)</p>
<p>[5] It’s hard to say exactly what constitutes research in the computer world, but as a first approximation, it’s software that doesn’t have users.</p>
<p>I don’t think it’s publication that makes the best hackers want to work in research departments. I think it’s mainly not having to have a three hour meeting with a product manager about problems integrating the Korean version of Word 13.27 with the talking paperclip.</p>
<p>[6] Something similar has been happening for a long time in the construction industry. When you had a house built a couple hundred years ago, the local builders built everything in it. But increasingly what builders do is assemble components designed and manufactured by someone else. This has, like the arrival of desktop publishing, given people the freedom to experiment in disastrous ways, but it is certainly more efficient.</p>
<p>[7] Google is much more dangerous to Microsoft than Netscape was. Probably more dangerous than any other company has ever been. Not least because they’re determined to fight. On their job listing page, they say that one of their “core values’’ is “Don’t be evil.’’ From a company selling soybean oil or mining equipment, such a statement would merely be eccentric. But I think all of us in the computer world recognize who that is a declaration of war on.</p>
<p>Thanks to Jessica Livingston, Robert Morris, and Sarah Harlin for reading earlier versions of this talk.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.paulgraham.com/gh.html&quot;&gt;Paul Graham&lt;/a&gt; July 2004&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ep.yimg.com/ca/I/paulgraham_2202_9271894&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;(This essay is derived from a talk at Oscon 2004.)&lt;/p&gt;
&lt;p&gt;A few months ago I finished a new book, and in reviews I keep noticing words like “provocative’’ and “controversial.’’ To say nothing of “idiotic.’’&lt;/p&gt;
&lt;p&gt;I didn’t mean to make the book controversial. I was trying to make it efficient. I didn’t want to waste people’s time telling them things they already knew. It’s more efficient just to give them the diffs. But I suppose that’s bound to yield an alarming book.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
  </entry>
  
  <entry>
    <title>The Loginataka</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/the-loginataka/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/the-loginataka/</id>
    <published>2017-01-20T11:31:06.000Z</published>
    <updated>2017-02-15T13:06:15.488Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.catb.org/~esr/faqs/loginataka.html" target="_blank" rel="external">The Loginataka</a></p>
<p>by Eric S. Raymond <a href="&#109;&#x61;&#x69;&#108;&#x74;&#x6f;&#x3a;&#x65;&#x73;&#114;&#x40;&#x74;&#104;&#x79;&#x72;&#x73;&#117;&#x73;&#46;&#x63;&#111;&#109;">&#x65;&#x73;&#114;&#x40;&#x74;&#104;&#x79;&#x72;&#x73;&#117;&#x73;&#46;&#x63;&#111;&#109;</a></p>
<p>  Speak, O Guru: How can I become a Unix Wizard?</p>
<p>  O, Nobly Born: know that the Way to Wizardhood is long, and winding, and Fraught with Risks. Thou must Attune thyself with the Source, attaining the arcane Knowledge and Conversation of the System Libraries and Internals. Yea; and such an all-consuming Time and Energy Sink is this as to greatly Imperil thy Grade Point Average (if one thou hast), not to mention thy Sex Life (if one thou hast). But persevere, oh Larval One; rewards beyond the Dreams of Lusers await thee!</p>
  <a id="more"></a>
<p>  Speak, O Guru: What books should I study? Are the O’Reilly “Nutshell” guides a good place to start?</p>
<p>  O, Nobly Born: know that the Nutshell Guides are but the outermost Portal of the True Enlightenment. Worthy are they (and praise to the Name of O’Reilly, whose books show forth the Hacker Spirit in numerous pleasing ways), but the Nutshell Guides are only the Beginning of the Road.</p>
<p>  If thou desirest with True Desire to tread the Path of Wizardly Wisdom, first learn the elementary Postures of Kernighan &amp; Pike’s The Unix Programming Environment; then, absorb the mantic puissance of March Rochkind’s Advanced Unix Programming and W. Richard Stevens’s Advanced Programming In The Unix Environment.</p>
<p>  Immerse thyself, then, in the Pure Light of Maurice J. Bach’s The Design Of The Unix Operating System. Neglect not the Berkelian Way; study also The Design and Implementation Of The 4.4BSD Operating System by Kirk McKusick, Keith Bostic et. al.</p>
<p>  For useful hints, tips, and tricks, see Unix Power Tools, Tim O’Reilly, ed. Consider also the dark Wisdom to be gained from contemplation of the dread Portable C And Unix Systems Programming, e’en though it hath flowed from the keyboard of the mad and doomed Malvernite whom the world of unknowing Man misnames “J. E. Lapin”.</p>
<p>  These tomes shall instruct thy Left Brain in the Nature of the Unix System; to Feed the other half of thy Head, O Nobly Born, embrace also the Lore of its Nurture. Don Libes’s and Sandy Ressler’s Life With Unix will set thy Feet unerringly upon that Path; take as thy Travelling Companion the erratic but illuminating compendium called The New Hacker’s Dictionary (Eric S. Raymond, ed., with Guy L. Steele Jr.).</p>
<p>  (In this wise shalt thou travel the Way of the Camel.)</p>
<p>  Speak, O Guru: To attain Mastery, how many Kernels do I need to take apart and reassemble?</p>
<p>  O Nobly Born: this question reveals that indeed thou hast touched upon an Ineffable Truth about Unix — that thou canst not Plumb its Mysteries by mere Study but must become One with it through Practice. The true Way to the Knowledge of the Source is not the timid and footling way of the Student, but the Divine Foolery of the Hacker. Hack, then; strive against Mighty Problems, have joy in thy Striving, and let the Crashes fall where they may (maintaining the while, for the Good of thy Karma, a Rigorous Backup Policy).</p>
<p>  In this day of Boot-Time Autoconfiguration and Dynamically Loadable Device Drivers, reassembling a Kernel is no longer the daunting Test and Seal of Mastery that once it was. However, writing and verifying thine own Device Driver for some piece of Exotic Hardware is still a worthy challenge to thy Budding Guruhood. Indeed, such Challenge may be found the Crafting of any Program sufficiently Powerful to Extend or Compete with the Tools now available in Open Source.</p>
<p>  Therefore: seek thee out the Open Source Unixes: OpenBSD, FreeBSD, NetBSD, and most Especially Linux in many of its Incarnations. Join the Wizards and Aspirants to Wizardhood who Labor Unceasingly to Improve these. Commune with them in their Great Work, their unceasing Extension and Reinvention of Unix. In this wise may thou become one among the Mighty.</p>
<p>  Speak, O Guru: Some there are who claim that the sole Path to Wizardry and the proper Way of every Right-Thinking Hacker is to rewrite the Unix Kernel from Scratch. Is this not Sacrilege?</p>
<p>  Sacrilege, O Nobly Born? Nay! Certainly the Kernel Source is the Inmost Mystery of Unix — but there is a Mystery beyond that Mystery. The Nature of Unix inhereth not in any one Version but in the Design Tradition of which all Unixes are Evolving Parts.</p>
<p>  The Rite of the Rewrite is not the only Path to Mastery, but it is perhaps the highest and most Sacred of all Paths. Few indeed are those who, travelling it, have crossed the dark and yawning Abyss of Implementation to Delivery. Many, yea, many in truth stagnate yet in the Desert of Delay, or linger ever in the ghastly limbo called Perpetual Beta.</p>
<p>  (In this wise shalt thou travel the Way of the Lion.)</p>
<p>  Speak, O Guru: What, then, is the True Path to Wizardhood?</p>
<p>  O Nobly Born: learn, and seek within thyself. Cultivate the cunning of the Serpent and the courage of the Tiger; sup deeply from the Wisdom of those who came before thee. Hack, and hack again; grow, by trial and by error. Post thy best hacks to the Net and gain in Repute thereby. Also, O Nobly Born, be thou grave and courteous in thy speech; be helpful to those less than thee, quick to succour and slow to flame.</p>
<p>  If thou dost these things faithfully, if thou travellest with high heart and pure intention, soon shall thy callow Newbiehood be shed. By degrees imperceptible to thyself shalt thou gain Power and Wisdom, Striving and Doing all the while. Gradually shall thy Puissance unfold and deepen.</p>
<p>  O Nobly Born, if thou dost all these things, thy Wizardhood shall surely come upon thee; but not of a sudden, and not until after thy arrogant Mind hath more than half Forgotten that such was its Aim. For know this — you may not by thyself in Pride claim the Mantle of Wizardry; that way lies only Bogosity without End.</p>
<p>  Rather must you Become, and Become, and Become, until Hackers respect thy Power, and other Wizards hail thee as a Brother or Sister in Wisdom, and you wake up and realize that the Mantle hath lain unknown upon thy Shoulders since you knew not when.</p>
<p>  (In this wise shalt thou travel the Way of the Child.)</p>
<p>  Hear, O nobly born: Techniques can be taught, but the Way of the Hacker cannot be taught. Skills can be acquired, but the Way of the Hacker is not a checklist of skills. Programming can be accomplished, but the Way of the Hacker is not a place at which you can stop and say “I have arrived!”</p>
<p>  Hear, O nobly born: The Way of the Hacker is a posture of mind; he who seeks a teacher of the Way knows it not, but he is only looking for a mirror. All those competent to teach the Way know that it cannot be taught, only pursued with joyous labor and by emulation of the great hackers of the past.</p>
<p>  Hear, O nobly born: Great were the hackers of the past! Subtle and deep in their thinking, shaggy-bearded and with thunder on their brows! You may seek to become as them, but it will not suffice you to grow a beard.</p>
<p>  Hear, O Nobly Born: The center of the mystery is the act of coding. You have a keyboard before you; pursue the Way through work.</p>
<p>  SHANTIH! SHANTIH! SHANTIH!</p>
<p>  Annotations:</p>
<p>  Most of this (up to “(In this wise shalt thou travel the Way of the Child.)”) was originally a Usenet response to some eager newbie questions; it appears that I wrote it on 21 November 1992 in response to a post by one Ade Barkah. After ten years, I guess it’s time to draw aside the veil of those mysteries. The remainder I wrote in 2010 after I was actually asked to give an answer in the style of the Loginataka.</p>
<p>  For those of you who are not native English speakers, the entirety is written in imitation of the Early Modern English of the late 1500s and early 1600s, the language of the King James Bible. The influence of the King James Bible is such that its dialect has retained connotations of majesty, solemnity, and religious authority. Holy scriptures from other languages are, therefore, often translated into a KJB-like pseudo-archaic English rather than following modern usage.</p>
<p>  Parts of this border on obsolescence now. Portable C And Unix Systems Programming has been out of print for a long time, but the Lovecraft joke was too funny to lose. Life With Unix is history, too, but the other references are still good. In 1998 I changed references to “freeware” and “free software” to “open source”. Otherwise changes have been pretty minor.</p>
<p>  <strong>“Loginataka”  </strong><br>  The title of the document is a play on the name of the Tripitaka, an early compilation of Buddhist scriptures.</p>
<pre><code>**&quot;Oh Nobly Born:&quot;  **
</code></pre><p>  The formulaic use of the salutation is intended to be reminiscent of the Bardo Thödöl — the Tibetan Book Of The Dead.</p>
<pre><code>**&quot;the Name of O&apos;Reilly&quot;  **
</code></pre><p>  A phrase rich with meaning in the clan system of old Scotland and Ireland. It might refer to the reputation of the clan O’Reilly, or to the person of the clan chief. The implied image is of Tim O’Reilly, be-tartaned, surrounded by louring Celts bristling with weapons. It’s worth noting that O’Reilly and Associates was pretty new at the game when I wrote this; it was over the following five years that they built up their remarkable reputation as friends of the hacker community.</p>
<pre><code>**&quot;attaining the arcane Knowledge and Conversation&quot;  **
</code></pre><p>  This is a reference to the occultism of Alesteir Crowley. He wrote of attaining the “Knowledge and Conversation of the Holy Guardian Angel” as the central aim of Thelemic mysticism, and added that he had chosen that term for it because it was the most absurd locution he could think of.</p>
<pre><code>**&quot;the Pure Light&quot;  **
</code></pre><p>  In Buddhist mysticism, the Pure Light of the Void (“void” being the usual English translation of Sanskrit sunyata) is a frequent metaphor for the wisdom that comes from realizing the emptiness of all things.</p>
<pre><code>**&quot;the Berkelian Way&quot;  **
</code></pre><p>  If you caught the previous reference to sunyata, you might also recall that Bishop Berkeley famously denied the existence of objective reality.</p>
<pre><code>**&quot;the mad and doomed Malvernite&quot;  **
</code></pre><p>  This is a play on H.P. Lovecraft’s “mad and doomed Arab”, Abdul al-Hazred, the author of the Necronomicon. And the actual doomed Malvernite was…er…me, in 1987. The “world of unknowing man misnames” because I wrote the book, but was pressured into allowing it to be published under a corporate pseudonym.</p>
<pre><code>**&quot;feed the other half of thy head&quot;  **
</code></pre><p>  Cue Grace Slick, in the last lines of Jefferson Airplane’s White Rabbit, a song about a hallucinogenic drug experience: “Remember…what the dormouse said! FEED YOUR HEAD! FEED YOUR HEAD!”</p>
<pre><code>**&quot;the Way of the Camel&quot;  **
</code></pre><p>  The references to the Ways of the Camel, Lion, and Child are to a mystical rant in Nietzsche’s Thus Spoke Zarathustra.</p>
<pre><code>**&quot;Divine Foolery of the Hacker&quot;  **
</code></pre><p>  The image of the Fool of God is a pervasive one in world mysticism. I was thinking here especially of the Fool card in the Rider-Waite Tarot, showing a clown walking or capering at the edge of a precipice.</p>
<pre><code>**&quot;Great Work&quot;  **
</code></pre><p>  In alchemy, the production of the Philosopher’s Stone that could transmute lead to gold, confer immortality. In some mystical interpretations of alchemy, the transmutation of the adept’s own soul. Modern Hermetic occultism generalizes the second meaning.</p>
<pre><code>**&quot;Desert of Delay&quot;  **
</code></pre><p>  This part is intended to recall the landscapes in Bunyan’s moral allegory Pilgrim’s Progress.</p>
<pre><code>**&quot;cunning of the Serpent and the courage of the Tiger&quot;  **
</code></pre><p>  In the New Testament of the Christian Bible, Matthew 10:16 exhorts Christians to be as cunning as serpents and as harmless as doves. This in turn refers to the “cunning of the serpent” in the Old Testament Book of Genesis.</p>
<pre><code>**&quot;if thou travellest with high heart and pure intention&quot;  **
</code></pre><p>  In the Egyptian Book Of The Dead, “I have travelled here with high heart and pure intention” is part of the ritual one must speak to pass the Weigher of Souls.</p>
<pre><code>**&quot;Shantih!&quot;  **
</code></pre><p>  “Shanti!” is Sanskrit and means “Peace!” I deliberately used the older transliteration “Shantih!” because it’s found at the end of T.S. Eliot’s poem The Wasteland. The threefold repetition is a form of invocatory magic closely equivalent to the Catholic ritual blessing “Peace be with you!”</p>
<p>  If you found this entertaining, you would probably also enjoy Rootless Root: <a href="http://www.catb.org/~esr/writings/unix-koans" target="_blank" rel="external">The Unix Koans of Master Foo.</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.catb.org/~esr/faqs/loginataka.html&quot;&gt;The Loginataka&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;by Eric S. Raymond &lt;a href=&quot;&amp;#109;&amp;#x61;&amp;#x69;&amp;#108;&amp;#x74;&amp;#x6f;&amp;#x3a;&amp;#x65;&amp;#x73;&amp;#114;&amp;#x40;&amp;#x74;&amp;#104;&amp;#x79;&amp;#x72;&amp;#x73;&amp;#117;&amp;#x73;&amp;#46;&amp;#x63;&amp;#111;&amp;#109;&quot;&gt;&amp;#x65;&amp;#x73;&amp;#114;&amp;#x40;&amp;#x74;&amp;#104;&amp;#x79;&amp;#x72;&amp;#x73;&amp;#117;&amp;#x73;&amp;#46;&amp;#x63;&amp;#111;&amp;#109;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  Speak, O Guru: How can I become a Unix Wizard?&lt;/p&gt;
&lt;p&gt;  O, Nobly Born: know that the Way to Wizardhood is long, and winding, and Fraught with Risks. Thou must Attune thyself with the Source, attaining the arcane Knowledge and Conversation of the System Libraries and Internals. Yea; and such an all-consuming Time and Energy Sink is this as to greatly Imperil thy Grade Point Average (if one thou hast), not to mention thy Sex Life (if one thou hast). But persevere, oh Larval One; rewards beyond the Dreams of Lusers await thee!&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
  </entry>
  
  <entry>
    <title>Things Every Hacker Once Knew</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/things-every-hacker-once-knew/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/things-every-hacker-once-knew/</id>
    <published>2017-01-20T11:16:06.000Z</published>
    <updated>2017-02-15T13:06:27.820Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.catb.org/~esr/faqs/things-every-hacker-once-knew/" target="_blank" rel="external">Things Every Hacker Once Knew</a></p>
<p>by Eric S. Raymond <a href="&#109;&#97;&#105;&#x6c;&#x74;&#111;&#x3a;&#x65;&#x73;&#114;&#x40;&#x74;&#x68;&#x79;&#114;&#x73;&#117;&#115;&#x2e;&#99;&#x6f;&#x6d;">&#x65;&#x73;&#114;&#x40;&#x74;&#x68;&#x79;&#114;&#x73;&#117;&#115;&#x2e;&#99;&#x6f;&#x6d;</a></p>
<p>One fine day in January 2017 I was reminded of something I had half-noticed a few times over the previous decade. That is, younger hackers don’t know the bit structure of ASCII and the meaning of the odder control characters in it.</p>
<p>This is knowledge every fledgling hacker used to absorb through their pores. It’s nobody’s fault this changed; the obsolescence of hardware terminals and the near-obsolescence of the RS-232 protocol is what did it. Tools generate culture; sometimes, when a tool becomes obsolete, a bit of cultural commonality quietly evaporates. It can be difficult to notice that this has happened.</p>
<p>This document is a collection of facts about ASCII and related technologies, notably hardware serial terminals and RS-232 and modems. This is lore that was at one time near-universal and is no longer. It’s not likely to be directly useful today - until you trip over some piece of still-functioning technology where it’s relevant (like a GPS puck), or it makes sense of some old-fart war story. Even so, it’s good to know anyway, for cultural-literacy reasons.</p>
<p>One thing this collection has that tends to be indefinite in the minds of older hackers is calendar dates. Those of us who lived through all this tend to have remembered order and dependencies but not exact timing; here, I did the research to pin a lot of that down. I’ve noticed that people have a tendency to retrospectively back-date the technologies that interest them, so even if you did live through the era it describes you might get a few surprises from reading this.</p>
<p>There are lots of references to Unix in here because I am mainly attempting to educate younger open-source hackers working on Unix-derived systems such as Linux and the BSDs. If those terms mean nothing to you, the rest of this document probably won’t either.</p>
  <a id="more"></a>
<h2 id="Hardware-context"><a href="#Hardware-context" class="headerlink" title="Hardware context"></a>Hardware context</h2><p>Nowadays, when two computers talk to each other, it’s usually via TCP/IP over some physical layer you seldom need to care much about. And a “terminal” is actually a “terminal emulator”, a piece of software that manages part of your display and itself speaks TCP/IP.</p>
<p>Before ubiquitous TCP/IP and bit-mapped displays things were very different. For most hackers that transition took place within a few years of 1992 - perhaps somewhat earlier if you had access to then-expensive workstation hardware.</p>
<p>Before then there were video display terminals - VDTs for short. In the mid-1970s these had displaced an earlier generation of printing terminals derived from really old technology called a “teletype”, which had evolved around 1900 from Victorian telegraph networks. The very earliest versions of Unix in the late 1960s were written for these printing terminals, in particular for the Teletype Model 33 (aka ASR-33); the “tty” that shows up in Unix device names was a then-common abbreviation for “teletype”.</p>
<p>In those pre-Internet days computers didn’t talk to each other much, and the way teletypes and terminals talked to computers was a hardware protocol called “RS-232” (or, if you’re being pedantic, “EIA RS-232C”) [1]. Before USB, when people spoke of a “serial” link, they meant RS-232, and sometimes referred to the equipment that spoke it as “serial terminals”.</p>
<p>RS-232 had a very long service life; it was developed in the early 1960s, not originally for computer use but as a way for teletypewriters to talk to modems. Though it has passed out of general use and is no longer common knowledge, it’s not quite dead even today.<br>I’ve been simplifying a bit here. There were other things besides RS-232 and serial terminals going on, notably on IBM mainframes. But they’ve left many fewer traces in current technology and its folklore. This is because the lineage of modern Unix passes back through a now-forgotten hardware category called a “minicomputer”, especially minicomputers made by the Digital Equipment Corporation. ASCII, RS-232 and serial terminals were part of the technology cluster around minicomputers - as was, for that matter, Unix itself.</p>
<p>Minicomputers were wiped out by workstations and workstations by descendants of the IBM PC, but hackers old enough to remember the minicomputer era (mid-1960s to mid-1980s) tend still to get a bit misty-eyed about the DEC hardware they cut their teeth on.</p>
<p>Often, however, nostalgia obscures how very underpowered those machines were. For example: a DEC VAX 11-780 minicomputer in the mid-1980s, used for timesharing and often supporting a dozen simultaneous users, had less than 1/1000 the processing power and less than 1/5000 times as much storage available as a low-end smartphone does in 2017.</p>
<p>In fact, until well into the 1980s microcomputers ran slowly enough (and had poor enough RF shielding) that this was common knowledge: you could put an AM radio next to one and get a clue when it was doing something unusual, because either fundamentals or major subharmonics of the clock frequencies were in the range of human audibility. Nothing has run that slowly since the turn of the 21st century.</p>
<h2 id="The-strange-afterlife-of-the-Hayes-smartmodem"><a href="#The-strange-afterlife-of-the-Hayes-smartmodem" class="headerlink" title="The strange afterlife of the Hayes smartmodem"></a>The strange afterlife of the Hayes smartmodem</h2><p>About those modems: the word is a portmanteau for “modulator/demodulator”. Modems allowed digital signals to pass over copper phone wires - ridiculously slowly by today’s standards, but that’s how we did our primitive wide-area networking in pre-Internet times. It was not generally known back then that modems had first been invented in the late 1950s for use in military communications, notably the SAGE air-defense network; we just took them for granted.</p>
<p>Today modems that speak over copper or optical fiber are embedded invisibly in the Internet access point in your basement; other varieties perform over-the-air signal handling for smartphones and tablets. A variety every hacker used to know about (and most of us owned) was the “outboard” modem, a separate box wired to your computer and your telephone line.</p>
<p>Inboard modems (expansion cards for your computer) were also known, but never sold as well because being located inside the case made them vulnerable to RF noise, and the blinkenlights on an outboard were useful for diagnosing problems. Also, most hackers learned to interpret (at least to some extent) modem song - the beeping and whooshing noises the outboards made while attempting to establish a connection. The happy song of a successful connect was identifiably different from various sad songs of synchronization failure.</p>
<p>These old-fashioned modems were, by today’s standards, unbelievably slow. Modem speeds increased from 110 bits per second back at the beginning of interactive computing to 56 kilobits per second just before the technology was effectively wiped out by wide-area Internet around the end of the 1990s, which brought in speeds of a megabit per second and more (20 times faster). For the longest stable period of modem technology after 1970, about 1984 to 1991, typical speed was 9600bps. This has left some traces; it’s why surviving serial-protocol equipment tends to default to a speed of 9600bps.</p>
<p>There was a line of modems called “Hayes Smartmodems” that could be told to dial a number, or set parameters such as line speed, with command codes sent to the modem over its serial link from the machine. Every hacker used to know the “AT” prefix used for commands and that, for example, ATDT followed by a phone number would dial the number. Other modem manufacturers copied the Hayes command set and variants of it became near universal after 1981.</p>
<p>What was not commonly known then is that the “AT” prefix had a helpful special property. That bit sequence (1+0 1000 0010 1+0 0010 1010 1+, where the plus suffix indicates one or more repetitions of the preceding bit) has a shape that makes it as easy as possible for a receiver to recognize it even if the receiver doesn’t know the transmit-line speed; this, in turn, makes it possible to automatically synchronize to that speed [2].</p>
<p>That property is still useful, and thus in 2017 the AT convention has survived in some interesting places. AT commands have been found to perform control functions on 3G and 4G cellular modems used in smartphones. On one widely deployed variety, “AT+QLINUXCMD=” is a prefix that passes commands to an instance of Linux running in firmware on the chip itself (separately from whatever OS might be running visibly on the phone).</p>
<h2 id="Preserving-core-values"><a href="#Preserving-core-values" class="headerlink" title="Preserving core values"></a>Preserving core values</h2><p>From about 1955 to 1975 - before semiconductors - the dominant technology in computer memory used tiny magnetic doughnuts strung on copper wires. The doughnuts were known as “ferrite cores” and main memory thus known as “core memory” or “core”.</p>
<p>Unix terminology was formed in the early 1970s, and compounds like “in core” and “core dump” survived into the semiconductor era. Until as late as around 1990 it could still be assumed that every hacker knew from where these terms derived; even microcomputer hackers for which memory had always been semiconductor RAM tended to pick up this folklore rapidly on contact with Unix.</p>
<p>After 2000, however, as multiprocessor systems became increasingly common even on desktops, “core” increasingly took on a conflicting meaning as shorthand for “processor core”. In 2017 “core” can still mean either thing, but the reason for the older usage is no longer generally understood and idioms like “in core” may be fading.</p>
<h2 id="36-bit-machines-and-the-persistence-of-octal"><a href="#36-bit-machines-and-the-persistence-of-octal" class="headerlink" title="36-bit machines and the persistence of octal"></a>36-bit machines and the persistence of octal</h2><p>There’a a power-of-two size hierarchy in memory units that we now think of as normal - 8 bit bytes, 16 or 32 or 64-bit words. But this did not become effectively universal until after 1983. There was an earlier tradition of designing computer architectures with 36-bit words.<br>There was a time when 36-bit machines loomed large in hacker folklore and some of the basics about them were ubiquitous common knowledge, though cultural memory of this era began to fade in the early 1990s. Two of the best-known 36-bitters were the DEC PDP-10 and the Symbolics 3600 Lisp machine. The cancellation of the PDP-10 in ‘83 proved to be the death knell for this class of machine, though the 3600 fought a rear-guard action for a decade afterwards.</p>
<p>Hexadecimal is a natural way to represent raw memory contents on machines with the power-of-two size hierarchy. But octal (base-8) representations of machine words were common on 36-bit machines, related to the fact that a 36-bit word naturally divides into 12 3-bit fields naturally represented as octal. In fact, back then we generally assumed you could tell which of the 32- or 36-bit phyla a machine belonged in by whether you could see digits greater than 7 in a memory dump.</p>
<p>Here are a few things every hacker used to know that related to these machines:</p>
<p>36 bits was long enough to represent positive and negative integers to an accuracy of ten decimal digits, as was expected on mechanical calculators of the era. Standardization on 32 bits was unsuccessfully resisted by numerical analysts and people in scientific computing, who really missed that last 4 bits of accuracy.</p>
<p>A “character” might be 9 bits on these machines, with 4 packed to a word. Consequently, keyboards designed for them might have both a meta key to assert bit 8 and a now-extinct extra modifier key (usually but not always called “Super”) that asserted bit 9. Sometimes this selected a tier of non-ASCII characters including Greek letters and mathematical symbols.</p>
<p>It used also to be generally known that 36-bit architectures explained some unfortunate features of the C language. The original Unix machine, the PDP-7, featured 18-bit words corresponding to half-words on larger 36-bit computers. These were more naturally represented as six octal (3-bit) digits.</p>
<p>The immediate ancestor of C was an interpreted language written on the PDP-7 and named B. In it, a numeric literal beginning with 0 was interpreted as octal.</p>
<p>The PDP-7’s successor, and the first workhorse Unix machine was the PDP-11 (first shipped in 1970). It had 16-bit words - but, due to some unusual peculiarities of the instruction set, octal made more sense for its machine code as well. C, first implemented on the PDP-11, thus inherited the B octal syntax. And extended it: when an in-string backslash has a following digit, that was expected to lead an octal literal.</p>
<p>The Interdata 32, VAX, and other later Unix platforms didn’t have those peculiarities; their opcodes expessed more naturally in hex. But C was never adjusted to prefer hex, and the surprising interpretation of leading 0 wasn’t removed.</p>
<p>Because many later languages (Java, Python, etc) copied C’s low-level lexical rules for compatibility reasons, the relatively useless and sometimes dangerous octal syntax besets computing platforms for which three-bit opcode fields are wildly inappropriate, and may never be entirely eradicated [3].</p>
<p>The PDP-11 was so successful that architectures strongly influenced by it (notably, including Intel [4] and ARM microprocessors) eventually took over the world, killing off 36-bit machines.</p>
<h2 id="RS232-and-its-discontents"><a href="#RS232-and-its-discontents" class="headerlink" title="RS232 and its discontents"></a>RS232 and its discontents</h2><p>A TCP/IP link generally behaves like a clean stream of 8-bit bytes (formally, octets). You get your data as fast as the network can run, and error detection/correction is done somewhere down below the layer you can see.</p>
<p>RS-232 was not like that. Two devices speaking it had to agree on a common line speed - also on how the byte framing works (the latter is why you’ll see references to “stop bits” in related documentation). Finally, error detection and correction was done in-stream, sort of. RS232 devices almost always spoke ASCII, and used the fact that ASCII only filled 7 bits. The top bit might be, but was not always, used as a parity bit for error detection. If not used, the top bit could carry data.</p>
<p>You had to set your equipment at both ends for a specific combination of all of these. After about 1984 anything other than “8N1” - eight bits, no parity, one stop bit - became increasingly rare. Before that, all kinds of weird combinations were in use. Even parity (“E”) was more common than odd (“O”) and 1 stop bit more common than 2, but you could see anything come down a wire. And if you weren’t properly set up for it, all you got was “baud barf” - random 8-bit garbage rather than the character data you were expecting.</p>
<p>This, in particular, is one reason the API for the POSIX/Unix terminal interface, termios(3), has a lot of complicated options with no obvious modern-day function. It had to be able to manipulate all these settings, and more.</p>
<p>Another consequence was that passing binary data over an RS-232 link wouldn’t work if parity was enabled - the high bits would get clobbered. Other now-forgotten wide-area network protocols reacted even worse, treating in-band characters with 0x80 on as control codes with results ranging from amusing to dire. We had a term, “8-bit clean”, for networks and software that didn’t clobber the 0x80 bit. And we needed that term…</p>
<p>Even the RS-232 physical connector varied. Standard RS-232 as defined in 1962 used a roughly D-shaped shell with 25 physical pins (DB-25), way more than the physical protocol actually required (you can support a minimal version with just three wires, and this was actually common). Twenty years later, after the IBM PC-AT introduced it in 1984, most manufacturers switched to using a smaller DB-9 connector (which is technically a DE-9 but almost nobody ever called it that). If you look at a PC with a serial port it is most likely to be a DB-9; confusingly, DB-25 came to be used for printer parallel ports (which originally had a very different connector) before those too were obsolesced by USB and Ethernet.</p>
<p>Anybody who worked with this stuff had to keep around a bunch of specialized hardware - gender changers, DB-25-to-DB-9 adapters (and the reverse), breakout boxes, null modems, and other stuff I won’t describe in detail because it’s left no traces in today’s tech. Hackers of a certain age still tend to have these things cluttering their toolboxes or gathering dust in a closet somewhere.</p>
<p>The main reason to still care about any of this (other than understanding greybeard war stories) is that some kinds of sensor and control equipment, routers, and IoT devices still speak RS-232, often wrapped inside a USB emulation. The most common devices that do this are probably GPS sensors designed to talk to computers (as opposed to handheld GPSes or car-navigation systems).</p>
<p>Because of devices like GPSes, you may still occasionally need to know what an RS-232 “handshake line” is. These were originally used to communicate with modems; a terminal, for example, could change the state of the DTR (Data Terminal Ready) line to indicate that it was ready to receive, initiate, or continue a modem session.</p>
<p>Later, handshake lines were used for other equipment-specific kinds of out-of-band signals. The most commonly re-used lines were DCD (data carrier detect) and RI (Ring Indicator).</p>
<p>Three-wire versions of RS-232 omitted these handshake lines entirely. A chronic source of frustration was equipment at one end of your link that failed to supply an out-of-band signal that the equipment at the other end needed. The modern version of this is GPSes that fail to supply their 1PPS (a high-precision top-of-second pulse) over one of the handshake lines.</p>
<p>Another significant problem was that an RS-232 device not actually sending data was undetectable without analog-level monitoring equipment. You couldn’t tell a working but silent device from one that had come unplugged or suffered a connection fault in its wiring. This caused no end of complications when troubleshooting and is a major reason USB was able to displace RS-232 after 1994.<br>A trap for the unwary that opened up after about the year 2000 is that peripheral connectors labeled RS232 could have one of two different sets of voltage levels. If they’re pins or sockets in a DB9 or DB25 shell, the voltage swing between 1 and 0 bits can be as much as 50 volts, and is usually about 26. Bare connectors on a circuit board, or chip pins, increasingly came to use what’s called “TTL serial” - same signalling with a swing of 3.3 or (less often) 5 volts. You can’t wire standard RS232 to TTL serial directly; the link needs a device called a “level shifter”. If you connect without one, components on the TTL side will get fried.</p>
<p>RS-232 passed out of common knowledge in the mid- to late 1990s, but didn’t finally disappear from general-purpose computers until around 2010. Standard RS-232 is still widely used on industrial controllers and in some niche applications, including point-of-sale systems and diagnostic consoles on commercial-grade routers. The TTL serial variant is often used on maker devices.</p>
<h2 id="UUCP-and-BBSes-the-forgotten-pre-Internets"><a href="#UUCP-and-BBSes-the-forgotten-pre-Internets" class="headerlink" title="UUCP and BBSes, the forgotten pre-Internets"></a>UUCP and BBSes, the forgotten pre-Internets</h2><p>Every hacker over a certain age remembers either UUCP or the BBS scene. Many participated in both. In those days access to to the “real” net (ARPANET, which became Internet) was difficult if you weren’t affiliated with one of a select group of federal agencies, military contractors, or university research labs. So we made do with what we had, which was modems and the telephone network.</p>
<p>UUCP stands for Unix to Unix Copy Program. Between its escape from Bell Labs in 1979 and the mass-market Internet explosion of the mid-1990s, it provided slow but very low-cost networking among Unix sites using modems and the phone network.</p>
<p>UUCP was a store-and-forward system originally intended for propagating software updates, but its major uses rapidly became email and a thing called USENET (launched 1981) that was the ur-ancestor of Stack Overflow and other modern web fora. It supported topic groups for messages which, propagated from their point of origin through UUCP, would eventually flood to the whole network.</p>
<p>In part, UUCP and USENET were a hack around the two-tier rate structure that then existed for phone calls, with “local” being flat-rate monthly and “long-distance” being expensively metered by the minute. UUCP traffic could be relayed across long distances by local hops.<br>A direct descendant of USENET still exists, as Google Groups [5], but was much more central to the hacker culture before cheap Internet. Open source as we now know it germinated in USENET groups dedicated to sharing source code. Several conventions still in use today, like having project metadata files named README and NEWS and INSTALL, originated there in the early 1980s.</p>
<p>Two key dates in USENET history were universally known. One was the Great Renaming in 1987, when the name hierarchy of USENET topic groups was reorganized. The other was the “September that never ended” in 1993, when the AOL commercial timesharing services gave its users access to USENET. The resulting vast flood of newbies proved difficult to acculturate.</p>
<p>UUCP explains a quirk you may run across in old mailing-list archives: the bang-path address. UUCP links were point-to-point and you had to actually specify the route of your mail through the UUCP network; this led to people publishing addresses of the form “…!bigsite!foovax!barbox!user”, presuming that people who wanted to reach them would know how to reach bigsite.</p>
<p>UUCP was notoriously difficult to configure, enough so that people who knew how often put that skill on their CVs in the justified expectation that it could land them a job.</p>
<p>Meanwhile, in the microcomputer world, a different kind of store-and-forward evolved - the BBS (Bulletin-Board System). This was software running on a computer (after 1991 usually an MS-DOS machine) with one (or, rarely, more) attached modems that could accept incoming phone calls. Users (typically, just one user at a time!) would access the BBS using a their own modem and a terminal program; the BBS software would allow them to leave messages for each other, upload and download files, and sometimes play games.</p>
<p>The first BBS, patterned after the community notice-board in a supermarket, was fielded in Chicago in 1978. Over the next eighteen years over a hundred thousand BBSes flashed in and out of existence, typically operated out of the sysop’s bedroom or garage with a spare computer.</p>
<p>From 1984 the BBS culture evolved a primitive form of internetworking called “FidoNet” that supported cross-site email and a forum system broadly resembling USENET.</p>
<p>During a very brief period after 1990, just before mass-market Internet, software with BBS-like capabilities but supporting multiple simultaneous modem users (and often offeing USENET access) got written for low-cost Unix systems. The end-stage BBSes, when they survived, moved to the Web and dropped modem access. The history of cellar.org chronicles this period.</p>
<p>A handful of BBSes are still run by nostalgicists, and some artifacts from the culture are still preserved. But, like the UUCP network, the BBS culture as a whole collapsed when inexpensive Internet became widely available.</p>
<p>Almost the only cultural memory of BBSes is around a family of file-transfer protocols - XMODEM, YMODEM, and ZMODEM - developed and used on BBSes. For hackers of that day who did not cut their teeth on minicomputers with native TCP/IP, these were a first introduction to concepts like packetization, error detection, and retransmission. To this day, hardware from at least one commercial router vendor accepts software patches by XMODEM upload through a serial port.</p>
<p>Also roughly contemporaneous with USENET and the BBS culture, and also destroyed or absorbed by cheap Internet, were some commercial timesharing services supporting dialup access by modem, of which the best known were AOL (America Online) CompuServe, and GEnie. These provided BBS-like facilities. Every hacker knew of these, though few used them. They have left no traces at all in today’s hacker culture.<br>Terminal confusion</p>
<p>The software terminal emulators on modern Unix systems are the near-end - and probably final - manifestations of a long and rather confused history. It began with early displays sometimes called “glass TTYs” because they emulated teletypes - but less expensively, because they didn’t require consumables like paper. The phrase “dumb terminal” is equivalent. The first of these was shipped in 1969. The best-remembered of them is probably still the ADM-3 from 1975.</p>
<p>The very earliest VDTs, like the ASR-33, could form only upper-case letters. An interesting hangover from that these devices was that, even though most VDTs made after 1975 could form lower-case letters, for many years afterwards Unix and Linux responded to an all-upper-case login by switching to an mode which upcased all input. If you created an account with an all-upper-case login name and a mixed-case password, hilarity ensued. If the password was also upper-case the hilarity was less desparate but still confusing for the user.<br>The classic “smart terminal” VDT designs that have left a mark on later computing appeared during a relatively short period beginning in 1975. Devices like the Lear-Siegler ADM-3A (1976) and the DEC VT-100 (1978) inherited the 80-character line width of punched cards (longer than the 72-character line length of teletypes) and supported as many lines as could fit on an approximately 4:3 screen; they are the reason your software terminal emulator has a 24x80 or 25x80 default size.</p>
<p>These terminals were called “smart” because they could interpret control codes to do things like addressing the cursor to any point on the screen in order to produce truly 2-dimensional displays [6]. The ability to do bold, underline or reverse-video highlighting also rapidly became common. Colored text and backgrounds, however, only became available a few years before VDTs were obsolesced; before that displays were monochromatic. Some had crude, low-resolution dot graphics; a few types supported black-and-white vector graphics.<br>Early VDTs used a crazy variety of control codes. One of the principal relics of this era is the Unix terminfo database, which tracked these codes so terminal-using applications could do abstracted operations like “move the cursor” without being restricted to working with just one terminal type. The curses(3) library still used with software terminal emulators was originally intended to make this sort of thing easier.</p>
<p>After 1979 there was an ANSI standard for terminal control codes, based on the DEC VT-100 (being supported in the IBM PC’s original screen driver gave it a boost) [7]. By the early 1990s ANSI conformance was close to universal in VDTs, which is why that’s what your software terminal emulator does.</p>
<p>This whole technology category was rapidly wiped out in general-purpose computing, like dinosaurs after the Alvarez strike, when bit-mapped color displays on personal computers that could match the dot pitch of a monochrome VDT became relatively inexpensive, around 1992. The legacy VDT hardware lingered longest in dedicated point-of-sale systems, remaining not uncommon until as late as 2010 or so.<br>It’s not true, as is sometime suggested, that heritage from the VDT era explains the Unix command line - that actually predated VDTs, going back to the last generation of printing terminals in the late 1960s and early 1970s. Every hacker once knew that this is why we often speak of of “printing” output when we mean sending it to standard output that is normally connected to a terminal emulator.<br>What the VDT era does explain is some of our heritage games (see next section) and a few surviving utility programs like vi(1), top(1) and mutt(1). These are what advanced visual interfaces looked like in the VDT era, before bitmapped displays.</p>
<h2 id="Games-before-GUIs"><a href="#Games-before-GUIs" class="headerlink" title="Games before GUIs"></a>Games before GUIs</h2><p>Before bit-mapped color displays became common and made graphics-intensive games the norm, there was a vigorous tradition of games that required only textual interfaces or the character-cell graphics on a VDT.</p>
<p>Every hacker once knew what the phrase “You are in a maze of twisty little passages, all alike” meant, and often used variants about confusing situations in real life (For example, “You are in a maze of twisty little technical standards, all different”). It was from the very first dungeon-crawling adventure game, Colossal Cave Adventure (1976). People who knew this game from its beginnings often thought of it as ADVENT, after its 6-character filename on the PDP-10 where it first ran.</p>
<p>ADVENT had a direct successor that was even more popular - Zork, first released in 1979 by hackers at MIT and later successfully commercialized. This game is why every hacker once knew that a zorkmid was the currency of the Great Underground Empire, and that if you wander around in dark places without your lantern lit you might be eaten by a grue.</p>
<p>There was a another family of games that took a different, more visual approach to dungeon-crawling. They are generally called “roguelikes”, after one of the earliest widely-distributed games in this group, Rogue from 1980. They featured top-down, maplike views of dungeon levels through which the player would wander battling monsters and seeking treasure.</p>
<p>The most widely played games in this group were Hack (1982) and Nethack (1987). Nethack is a notable for having been one of the earliest programs in which the development group was consciously organized as a distributed collaboration over the Internet; at the time, this was a sufficiently novel idea to be advertised in the project’s name.</p>
<p>These games gradually passed out of universal common knowledge after the mid-1990s, but they retain devoted minority followings today. Their fans accurately point out that the primitive state of interface design encouraged concentration on plot and story values, leading to a surprisingly rich imaginative experience.</p>
<h2 id="ASCII"><a href="#ASCII" class="headerlink" title="ASCII"></a>ASCII</h2><p>ASCII, the American Standard Code for Information Interchange, evolved in the early 1960s out of a family of character codes used on teletypes.<br>ASCII, unlike a lot of other early character encodings, is likely to live forever - because by design the low 127 code points of Unicode are ASCII. If you know what UTF-8 is (and you should) every ASCII file is correct UTF-8 as well.<br>The following table describes ASCII-1967, the version in use today.<br>Dec Hex    Dec Hex    Dec Hex  Dec Hex  Dec Hex  Dec Hex   Dec Hex   Dec Hex<br>  0 00 NUL  16 10 DLE  32 20    48 30 0  64 40 @  80 50 P   96 60 `  112 70 p<br>  1 01 SOH  17 11 DC1  33 21 !  49 31 1  65 41 A  81 51 Q   97 61 a  113 71 q<br>  2 02 STX  18 12 DC2  34 22 “  50 32 2  66 42 B  82 52 R   98 62 b  114 72 r<br>  3 03 ETX  19 13 DC3  35 23 #  51 33 3  67 43 C  83 53 S   99 63 c  115 73 s<br>  4 04 EOT  20 14 DC4  36 24 $  52 34 4  68 44 D  84 54 T  100 64 d  116 74 t<br>  5 05 ENQ  21 15 NAK  37 25 %  53 35 5  69 45 E  85 55 U  101 65 e  117 75 u<br>  6 06 ACK  22 16 SYN  38 26 &amp;  54 36 6  70 46 F  86 56 V  102 66 f  118 76 v<br>  7 07 BEL  23 17 ETB  39 27 ‘  55 37 7  71 47 G  87 57 W  103 67 g  119 77 w<br>  8 08 BS   24 18 CAN  40 28 (  56 38 8  72 48 H  88 58 X  104 68 h  120 78 x<br>  9 09 HT   25 19 EM   41 29 )  57 39 9  73 49 I  89 59 Y  105 69 i  121 79 y<br> 10 0A LF   26 1A SUB  42 2A *  58 3A :  74 4A J  90 5A Z  106 6A j  122 7A z<br> 11 0B VT   27 1B ESC  43 2B +  59 3B ;  75 4B K  91 5B [  107 6B k  123 7B {<br> 12 0C FF   28 1C FS   44 2C ,  60 3C &lt;  76 4C L  92 5C \  108 6C l  124 7C |<br> 13 0D CR   29 1D GS   45 2D -  61 3D =  77 4D M  93 5D ]  109 6D m  125 7D }<br> 14 0E SO   30 1E RS   46 2E .  62 3E &gt;  78 4E N  94 5E ^  110 6E n  126 7E ~<br> 15 0F SI   31 1F US   47 2F /  63 3F ?  79 4F O  95 5F _  111 6F o  127 7F DEL</p>
<p>It used to be common knowledge that the original 1963 ASCII had been sightly different. It lacked tilde and vertical bar; 5E was an up-arrow rather than a caret, and 5F was a left arrow rather than underscore. Some early adopters (notably DEC) held to the 1963 version.<br>If you learned your chops after 1990 or so, the mysterious part of this is likely the control characters, code points 0-31. You probably know that C uses NUL as a string terminator. Others, notably LF = Line Feed and HT = Horizontal Tab, show up in plain text. But what about the rest?</p>
<p>Many of these are remnants from teletype protocols that have either been dead for a very long time or, if still live, are completely unknown in computing circles. A few had conventional meanings that were half-forgotten even before Internet times. A very few are still used in binary data protocols today.</p>
<p>Here’s a tour of the meanings these had in older computing, or retain today. If you feel an urge to send me more, remember that the emphasis here is on what was common knowledge back in the day. If I don’t know it now, we probably didn’t generally know it then.</p>
<p>NUL (Null)<br>Survives as the string terminator in C.</p>
<p>SOH (Start of Heading)<br>Rarely used (as Ctrl-A) as a section divider in otherwise textual formats. Some versions of Unix mailbox format used it as a message divider. One very old version-control system (SCCS) did something similar.</p>
<p>STX (Start of Text), ETX (End of Text)<br>Very rarely used as packet or control-sequence delimiters. You will probably never see this, and the only place I’ve ever seen it was on a non-Unix OS in the early 1980s. ETX is Ctrl-C, which is a SIGINT interrupt character on Unix systems, but that has nothing to do with its ASCII meaning per se and probably derives from abbreviating the word “Cancel”.</p>
<p>EOT (End of Transmission)<br>As Ctrl-D, the way you type “End of file” to a Unix terminal.</p>
<p>ENQ (Enquiry)<br>In the days of hardware serial terminals, there was a convention that if a computer sent ENQ to a terminal, it should reply with terminal type identification. While this was not universal, it at least gave computers a fighting chance of autoconfiguring what capabilities it could assume the terminal to have.</p>
<p>ACK (Acknowledge)<br>It used to be common for wire protocols written in ASCII to use ENQ/ACK as a handshake, sometimes with NAK as a failure indication. Hackers used to use ACK in speech as “I hear you” and were a bit put out when this convention was disrupted in the 1980s by Bill The Cat’s “Ack! Thppt!”</p>
<p>BEL (Bell)<br>Make the bell ring on the teletype - an attention signal. This often worked on VDTs as well, but is no longer reliably the default on software terminal emulators. Some map it to a visual indication like flashing the title bar.</p>
<p>BS (Backspace)<br>Still does what it says on the tin, though there has been some historical confusion over whether the backspace key on a keyboard should behave like BS (nondestructive cursor move) or DEL (backspace and delete). Never used in textual data protocols.</p>
<p>HT (Horizontal tab)<br>Still does what it says on the tin. Sometimes used as a field separator in Unix textual file formats, but this is now old-fashioned and declining in usage.</p>
<p>LF (Line Feed)<br>The Unix textual end-of-line. Printing terminals interpreted it as “scroll down one line”; the Unix tty driver would normally wedge in a CR right after it on output.</p>
<p>VT (Vertical Tab)<br>In the days of printing terminals this often caused them to scroll down a configurable number of lines. VDTs had any number of possible behaviors; at least some pre-ANSI ones interpreted VT as “scroll up one line”. The only reason anybody remembers this one at all is that it persisted in Unix definitions of what a whitespace character is, even though it’s now extinct in the wild.</p>
<p>FF (Form Feed)<br>Eject the current page from your printing terminal. Many VDTs interpreted this as a “clear screen” instruction. Software terminal emulators sometimes still do.</p>
<p>CR (Carriage Return)<br>It is now possible that the reader has never seen a typewriter, so this needs explanation: “carriage return” is the operation of moving your print head or cursor to the left margin. Windows, other non-Unix operating systems, and some Internet protocols (such as SMTP) tend to use CR-LF as a line terminator, rather than bare LF. Pre-Unix MacOS used a bare CR.</p>
<p>SO (Shift Out), SI (Shift In)<br>Escapes to and from an alternate character set. Unix software used to emit them to drive pre-ANSI VDTs that interpreted them that way, but native Unix usage is rare to nonexistent.</p>
<p>DLE (Data Link Escape)<br>Sometimes used as a packet-framing character in binary protocols. That is, a packet starts with a DLE, ends with a DLE, and if one of the interior data bytes matches DLE it is doubled.</p>
<p>DC[1234] (Device Control [1234])<br>Never to my knowledge used specially after teletypes. However: there was a common software flow-control protocol, used over ASCII but separate from it, in which XOFF (DC3) was used as a request to pause transmission and XON (DC1) was used as a request to resume transmission. As Ctrl-S and Ctrl-Q these were implemented in the Unix terminal driver and long outlived their origin in the Model 33 Teletype. And not just Unix; this was implemented in CP/M and DOS, too.</p>
<p>NAK (Negative Acknowledge)<br>Never to my knowledge used specially after teletypes, but it would have been unsurprising to anybody if a device-control protocol used it as a negative response to ENQ.</p>
<p>SYN (Synchronous Idle)<br>Never to my knowledge used specially after teletypes. Be careful not to confuse this with the SYN (synchronization) packet used in TCP/IP’s SYN SYN-ACK initialization sequence.</p>
<p>ETB (End of Transmission Block)<br>Never to my knowledge used specially after teletypes.</p>
<p>CAN (Cancel), EM (End of Medium)<br>Never to my knowledge used specially after teletypes.</p>
<p>SUB (Substitute)<br>DOS and Windows use Ctrl-Z (SUB) as an end-of-file character; this is unrelated to its ASCII meaning. It was common knowledge then that this use of ^Z had been inherited from a now largely forgotten earlier OS called CP/M (1974), and into CP/M from earlier DEC minicomputer OSes such as RSX-11 (1972).</p>
<p>ESC (Escape)<br>Still commonly used as a control-sequence introducer. This usage is especially associated with the control sequences recognized by VT100 and ANSI-standard VDTs, and today by essentially all software terminal emulators<br>[FGRU]S ({Field|Group|Record|Unit} Separator)<br>Never to my knowledge used specially after teletypes. FS, as Ctrl-\, sends SIGQUIT under some Unixes, but this has nothing to do with ASCII. Ctrl-] (GS) is the exit character from telnet, but this also has nothing to do with its ASCII meaning.</p>
<p>DEL (Delete)<br>Usually an input character meaning “backspace and delete”. Under older Unix variants, sometimes a SIGINT interrupt character.<br>Not all of these were so well known that any hacker could instantly map from mnemonic to binary, or vice-versa. The well-known set was roughly NUL, BEL, BS, HT, LF, FF, CR, ESC, and DEL.<br>There are a few other bits of ASCII lore worth keeping in mind…<br>The Control modifier on your keyboard basically clears the top three bits of whatever character you type, leaving the bottom five and mapping it to the 0..31 range. So, for example, Ctrl-SPACE, Ctrl-@, and Ctrl-` all mean the same thing: NUL.<br>A Meta or Alt key on a VDT added 128 to the ASCII keycode for whatever it’s modifying (probably - on a few machines with peculiar word lengths they did different things). Software terminal emulators have more variable behavior; many of them now simply insert an ESC before the modified key, which Emacs treats as equivalent to adding 128.<br>Very old keyboards used to do Shift just by toggling the 32 or 16 bit, depending on the key; this is why the relationship between small and capital letters in ASCII is so regular, and the relationship between numbers and symbols, and some pairs of symbols, is sort of regular if you squint at it. The ASR-33, which was an all-uppercase terminal, even let you generate some punctuation characters it didn’t have keys for by shifting the 16 bit; thus, for example, Shift-K (0x4B) became a [ (0x5B)</p>
<h2 id="Key-dates"><a href="#Key-dates" class="headerlink" title="Key dates"></a>Key dates</h2><p>These are dates that every hacker knew were important at the time, or shortly afterwards. I’ve tried to concentrate on milestones for which the date - or the milestone itself - seems to have later passed out of folk memory.<br>1961<br>MIT takes delivery of a PDP-1. The first recognizable ancestor of the hacker culture of today rapidly coalesces around it.<br>1969<br>Ken Thompson begins work on what will become Unix. First commercial VDT ships; it’s a glass TTY. First packets exchanged on the ARPANET, the direct ancestor of today’s Internet.<br>1970<br>DEC PDP-11 first ships; architectural descendants of this machine, including later Intel microprocessors, will come to dominate computing.<br>1973<br>Interdata 32 ships; the long 32-bit era begins [8]. Unix Edition 5 (not yet on the Interdata) escapes Bell Labs to take root at a number of educational institutions. The XEROX Alto pioneers the “workstation” - a networked personal computer with a high-resolution display and a mouse.<br>1975<br>First Altair 8800 ships. Beginning of heroic age of microcomputers. First 24x80 and 25x80 “smart” (addressable-cursor) VDTs. ARPANET declared “operational”, begins to spread to major universities.<br>1976<br>“Lions’ Commentary on UNIX 6th Edition, with Source Code” released. First look into the Unix kernel source for most hackers, and was a huge deal in those pre-open-source days.<br>1977<br>Unix ported to the Interdata. First version with a kernel written largely in C rather than machine-dependent assembler.<br>1978<br>First BBS launched - CBBS, in Chicago.<br>1981<br>First IBM PC ships. End of the heroic age of micros. TCP/IP is implemented on a VAX-11/780 under 4.1BSD Unix; ARPANET and Unix cultures begin to merge.<br>1982<br>Sun Microsystems founded. Era of commercial Unix workstations begins.<br>1983<br>PDP-10 canceled. This is effectively the end of 36-bit architectures anywhere outside of deep mainframe country, though Symbolics Lisp machines hold out a while longer. ARPANET, undergoing some significant technical changes, becomes Internet.<br>1984<br>AT&amp;T begins a largely botched attempt to commercialize Unix, clamping down on access to source code. In the BBS world, FidoNet is invented.<br>1985<br>RMS published GNU Manifesto. This is also roughly the year the C language became the dominant lingua franca of both systems and applications programming, eventually displacing earlier compiled language so completely that they are almost forgotten.<br>1986<br>Intel 386 ships; end of the line for 8- and 16-bit PCs. Consumer-grade hardware in this class wouldn’t be generally available until around 1989, but after that would rapidly surpass earlier 32-bit minicomputers in and workstations capability.<br>1991<br>Linux and the World Wide Web are (separately) launched.<br>1992<br>Bit-mapped color displays with a dot pitch matching that of a monochrome VDT (and a matching ability to display crisp text at 80x25) ship on consumer-grade PCs. Bottom falls out of the VDT market.<br>1993<br>Linux gets TCP/IP capability, moves from hobbyist’s toy to serious OS. America OnLine offers USENET access to its uses; “September That Never Ended” begins.<br>1994<br>Mass-market Internet takes off in the U.S. USB promulgated.<br>1995-1996<br>Peak years of UUCP/USENET and the BBS culture, then collapse under pressure from mass-market Internet.<br>1997<br>I first give the “Cathedral and Bazaar” talk.<br>1999<br>Peak year of the dot-com bubble. End of workstation era: Market for Suns and other proprietary Unix workstations collapses under pressure from Linux running on PCs.<br>2005<br>Major manufacturers cease production of cathode-ray tubes in favor of flat-panel displays. Flat-panels have been ubiquitous on new hardware since about 2003. There is a brief window until about 2007 during which high-end CRTs no longer in production still exceed the resolution of flat-panel displays and are still sought after. Also in 2005, AOL drops USENET support and Endless September ends.<br>2007-2008<br>64-bit transition in mass market PCs. The 32-bit era ends. The first smartphones ship.</p>
<h2 id="Request-to-contributors"><a href="#Request-to-contributors" class="headerlink" title="Request to contributors"></a>Request to contributors</h2><p>A lot of people reading this have been seized by the urge to send me some bit of lore or trivia for inclusion. Thank you, but bear in mind that the most important choice is what to leave out. Here are some guidelines:</p>
<p>I’m trying to describe common knowledge at the time. That means not every bit of fascinating but obscure trivia belongs here.<br>Anything from a tech generation before early minis - in particular the era of mainframes, punched cards, and paper tape - is out of scope. I gotta draw the line somewhere, and it’s there.</p>
<p>Stories about isolated survivals of old tech today are not interesting if the tech wasn’t once common knowledge.<br>Please do not send me timeline entries for dates which you think are important unless you think the date has been generally been forgotten, or is in serious danger of same.</p>
<p>Supporting this work<br>If you enjoyed this, please contribute at my Patreon page so I won’t be forced to get a $DAYJOB and no longer have time to think up or write things like this document. I work on a lot of more serious projects too, including critical network infrastructure. So give generously; the civilization you save could be your own.</p>
<h2 id="Related-Reading"><a href="#Related-Reading" class="headerlink" title="Related Reading"></a>Related Reading</h2><p><a href="http://www.catb.org/~esr/faqs/hacker-howto.html" target="_blank" rel="external">How To Become A Hacker</a><br><a href="http://www.catb.org/esr/structure-packing/" target="_blank" rel="external">The Lost Art of C Structure Packing</a></p>
<h2 id="Change-history"><a href="#Change-history" class="headerlink" title="Change history"></a>Change history</h2><p>1.0: 2017-01-26<br>Initial version.<br>1.1: 2017-01-27<br>Pin down the date DB-9 came in. Added a minor section on the persistence of octal. More on the afterlife of RS-232.<br>1.2: 2017-01-29<br>More about the persistence of octal. Mention current-loop ASR-33s. 36-bit machines and their lingering influence. Explain ASCII shift. A bit more about ASCII-1963. Some error correction.<br>1.3: 2017-01-30<br>Added “Key dates” and “Request to contributors”.<br>1.4: 2017-02-03<br>The curious survival of the Hayes AT command set.<br>1.5: 2017-02-04<br>TTL in serial and maker devices. The AT Hayes prefix explained. UUCP and long distance rates. Reference to space-cadet keyboard removed, as it turned out to ship a 32-bit word. Improved description of ASCII shift.<br>1.6: 2017-02-08<br>How VDTs explain some heritage programs, and how bitmapped displays eventually obsolesced them. Explain why the ADM-3 was called “dumb” even though it was smart.<br>1.7: 2017-02-09<br>The BBS subculture. XMODEM/YMODEM/ZMODEM. Commercial timesharing. Two dates in USENET history.<br>1.8: 2017-02-14<br>Heritage games. The legacy of all-uppercase terminals. Where README came from. What “core” is. The ARPANET. Monitoring your computer with a radio.</p>
<ol>
<li>Actually, there was an even older style of tty interface called “current loop” that the ASR-33 originally used; in the 1970s dual-mode ASR-33s that could also speak RS-232 began to ship, and RS-232 eventually replaced current loop entirely.</li>
<li>A full explanation of the magic of the AT prefix can be found at <a href="http://esr.ibiblio.org/?p=7333&amp;cpage=1#comment-1802568" target="_blank" rel="external">http://esr.ibiblio.org/?p=7333&amp;cpage=1#comment-1802568</a></li>
<li>Python 3 and Perl 6 have at least gotten rid of the dangerous leading-0-for-octal syntax, but Go kept it</li>
<li>Early Intel microprocessors weren’t much like the 11, but the 80286 and later converged with it in important ways.</li>
<li>The old free-floating USENET still exists too, but Google Groups is where you can find what has been preserved of the historical USENET archives.</li>
<li>Confusingly, the ADM-3A (which could address any screen cell) was described in marketing copy as a “dumb” terminal, not a “smart” one. This is because there was a rival definition of “smart” as capable of doing local editing of the screen without involving the remote computer, like an IBM 3270. But since minicomputers never used that capability this definition was never live in the Unix world, and has mostly faded out of use.</li>
<li>It was not commonly known that the VT100 was designed to fit a 1976 stanfard called ECMA-48; ANSI simply adopted it.</li>
<li>There were a few 32-bit minis before the Interdata, but they seem to have been designed for real-time or other non-timesharing uses.</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.catb.org/~esr/faqs/things-every-hacker-once-knew/&quot;&gt;Things Every Hacker Once Knew&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;by Eric S. Raymond &lt;a href=&quot;&amp;#109;&amp;#97;&amp;#105;&amp;#x6c;&amp;#x74;&amp;#111;&amp;#x3a;&amp;#x65;&amp;#x73;&amp;#114;&amp;#x40;&amp;#x74;&amp;#x68;&amp;#x79;&amp;#114;&amp;#x73;&amp;#117;&amp;#115;&amp;#x2e;&amp;#99;&amp;#x6f;&amp;#x6d;&quot;&gt;&amp;#x65;&amp;#x73;&amp;#114;&amp;#x40;&amp;#x74;&amp;#x68;&amp;#x79;&amp;#114;&amp;#x73;&amp;#117;&amp;#115;&amp;#x2e;&amp;#99;&amp;#x6f;&amp;#x6d;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One fine day in January 2017 I was reminded of something I had half-noticed a few times over the previous decade. That is, younger hackers don’t know the bit structure of ASCII and the meaning of the odder control characters in it.&lt;/p&gt;
&lt;p&gt;This is knowledge every fledgling hacker used to absorb through their pores. It’s nobody’s fault this changed; the obsolescence of hardware terminals and the near-obsolescence of the RS-232 protocol is what did it. Tools generate culture; sometimes, when a tool becomes obsolete, a bit of cultural commonality quietly evaporates. It can be difficult to notice that this has happened.&lt;/p&gt;
&lt;p&gt;This document is a collection of facts about ASCII and related technologies, notably hardware serial terminals and RS-232 and modems. This is lore that was at one time near-universal and is no longer. It’s not likely to be directly useful today - until you trip over some piece of still-functioning technology where it’s relevant (like a GPS puck), or it makes sense of some old-fart war story. Even so, it’s good to know anyway, for cultural-literacy reasons.&lt;/p&gt;
&lt;p&gt;One thing this collection has that tends to be indefinite in the minds of older hackers is calendar dates. Those of us who lived through all this tend to have remembered order and dependencies but not exact timing; here, I did the research to pin a lot of that down. I’ve noticed that people have a tendency to retrospectively back-date the technologies that interest them, so even if you did live through the era it describes you might get a few surprises from reading this.&lt;/p&gt;
&lt;p&gt;There are lots of references to Unix in here because I am mainly attempting to educate younger open-source hackers working on Unix-derived systems such as Linux and the BSDs. If those terms mean nothing to you, the rest of this document probably won’t either.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
  </entry>
  
  <entry>
    <title>The Art of Unix Programming</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/the-art-of-unix-programming/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/the-art-of-unix-programming/</id>
    <published>2017-01-20T11:16:06.000Z</published>
    <updated>2017-02-16T00:06:16.386Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://catb.org/~esr/writings/taoup/html/" target="_blank" rel="external">The Art of Unix Programming</a></p>
<p><img src="http://catb.org/~esr/writings/taoup/cover.png" alt=""></p>
<p>Eric Steven Raymond</p>
<p>This book and its on-line version are distributed under the terms of the Creative Commons Attribution-NoDerivs 1.0 license, with the additional proviso that the right to publish it on paper for sale or other for-profit use is reserved to Pearson Education, Inc. A reference copy of this license may be found at <a href="http://creativecommons.org/licenses/by-nd/1.0/legalcode" target="_blank" rel="external">http://creativecommons.org/licenses/by-nd/1.0/legalcode</a>.</p>
  <a id="more"></a>
<p>AIX, AS/400, DB/2, OS/2, System/360, MVS, VM/CMS, and IBM PC are trademarks of IBM. Alpha, DEC, VAX, HP-UX, PDP, TOPS-10, TOPS-20, VMS, and VT-100 are trademarks of Compaq. Amiga and AmigaOS are trademarks of Amiga, Inc. Apple, Macintosh, MacOS, Newton, OpenDoc, and OpenStep are trademarks of Apple Computers, Inc. ClearCase is a trademark of Rational Software, Inc. Ethernet is a trademark of 3COM, Inc. Excel, MS-DOS, Microsoft Windows and PowerPoint are trademarks of Microsoft, Inc. Java. J2EE, JavaScript, NeWS, and Solaris are trademarks of Sun Microsystems. SPARC is a trademark of SPARC international. Informix is a trademark of Informix software. Itanium is a trademark of Intel. Linux is a trademark of Linus Torvalds. Netscape is a trademark of AOL. PDF and PostScript are trademarks of Adobe, Inc. UNIX is a trademark of The Open Group.</p>
<p>The photograph of Ken and Dennis in Chapter 2 appears courtesy of Bell Labs/Lucent Technologies.</p>
<p>The epigraph on the Portability chapter is from the Bell System Technical Journal, v57 #6 part 2 (July-Aug. 1978) pp. 2021-2048 and is reproduced with the permission of Bell Labs/Lucent Technologies.</p>
<p>Revision History<br>Revision 1.0    19 September 2003    esr<br>This is the content that went to Addison-Wesley’s printers.<br>Revision 0.4    5 February 2003    esr<br>Release for public review.<br>Revision 0.3    22 January 2003    esr<br>First eighteen-chapter draft. Manuscript walkthrough at Chapter 12. Limited release for early reviewers.<br>Revision 0.2    2 January 2003    esr<br>First manuscript walkthrough at Chapter 7. Released to Dmitry Kirsanov at AW production.<br>Revision 0.1    16 November 2002    esr<br>First DocBook draft, fifteen chapters. Languages rewritten to incorporate lots of feedback. Transparency, Modularity, Multiprogramming, Configuration, Interfaces, Documentation, and Open Source chapters released. Shipped to Mark Taub at AW.<br>Revision 0.0    1999    esr<br>Public HTML draft, first four chapters only.<br>Dedication</p>
<p>To Ken Thompson and Dennis Ritchie, because you inspired me.</p>
<p>Table of Contents</p>
<p>Preface<br>Who Should Read This Book<br>How to Use This Book<br>Related References<br>Conventions Used in This Book<br>Our Case Studies<br>Author’s Acknowledgements<br>I. Context</p>
<ol>
<li>Philosophy<br>Culture? What Culture?<br>The Durability of Unix<br>The Case against Learning Unix Culture<br>What Unix Gets Wrong<br>What Unix Gets Right<br>Open-Source Software<br>Cross-Platform Portability and Open Standards<br>The Internet and the World Wide Web<br>The Open-Source Community<br>Flexibility All the Way Down<br>Unix Is Fun to Hack<br>The Lessons of Unix Can Be Applied Elsewhere<br>Basics of the Unix Philosophy<br>Rule of Modularity: Write simple parts connected by clean interfaces.<br>Rule of Clarity: Clarity is better than cleverness.<br>Rule of Composition: Design programs to be connected with other programs.<br>Rule of Separation: Separate policy from mechanism; separate interfaces from engines.<br>Rule of Simplicity: Design for simplicity; add complexity only where you must.<br>Rule of Parsimony: Write a big program only when it is clear by demonstration that nothing else will do.<br>Rule of Transparency: Design for visibility to make inspection and debugging easier.<br>Rule of Robustness: Robustness is the child of transparency and simplicity.<br>Rule of Representation: Fold knowledge into data, so program logic can be stupid and robust.<br>Rule of Least Surprise: In interface design, always do the least surprising thing.<br>Rule of Silence: When a program has nothing surprising to say, it should say nothing.<br>Rule of Repair: Repair what you can — but when you must fail, fail noisily and as soon as possible.<br>Rule of Economy: Programmer time is expensive; conserve it in preference to machine time.<br>Rule of Generation: Avoid hand-hacking; write programs to write programs when you can.<br>Rule of Optimization: Prototype before polishing. Get it working before you optimize it.<br>Rule of Diversity: Distrust all claims for one true way.<br>Rule of Extensibility: Design for the future, because it will be here sooner than you think.<br>The Unix Philosophy in One Lesson<br>Applying the Unix Philosophy<br>Attitude Matters Too</li>
<li>History<br>Origins and History of Unix, 1969-1995<br>Genesis: 1969–1971<br>Exodus: 1971–1980<br>TCP/IP and the Unix Wars: 1980-1990<br>Blows against the Empire: 1991-1995<br>Origins and History of the Hackers, 1961-1995<br>At Play in the Groves of Academe: 1961-1980<br>Internet Fusion and the Free Software Movement: 1981-1991<br>Linux and the Pragmatist Reaction: 1991-1998<br>The Open-Source Movement: 1998 and Onward<br>The Lessons of Unix History</li>
<li>Contrasts<br>The Elements of Operating-System Style<br>What Is the Operating System’s Unifying Idea?<br>Multitasking Capability<br>Cooperating Processes<br>Internal Boundaries<br>File Attributes and Record Structures<br>Binary File Formats<br>Preferred User Interface Style<br>Intended Audience<br>Entry Barriers to Development<br>Operating-System Comparisons<br>VMS<br>MacOS<br>OS/2<br>Windows NT<br>BeOS<br>MVS<br>VM/CMS<br>Linux<br>What Goes Around, Comes Around<br>II. Design</li>
<li>Modularity<br>Encapsulation and Optimal Module Size<br>Compactness and Orthogonality<br>Compactness<br>Orthogonality<br>The SPOT Rule<br>Compactness and the Strong Single Center<br>The Value of Detachment<br>Software Is a Many-Layered Thing<br>Top-Down versus Bottom-Up<br>Glue Layers<br>Case Study: C Considered as Thin Glue<br>Libraries<br>Case Study: GIMP Plugins<br>Unix and Object-Oriented Languages<br>Coding for Modularity</li>
<li>Textuality<br>The Importance of Being Textual<br>Case Study: Unix Password File Format<br>Case Study: .newsrc Format<br>Case Study: The PNG Graphics File Format<br>Data File Metaformats<br>DSV Style<br>RFC 822 Format<br>Cookie-Jar Format<br>Record-Jar Format<br>XML<br>Windows INI Format<br>Unix Textual File Format Conventions<br>The Pros and Cons of File Compression<br>Application Protocol Design<br>Case Study: SMTP, the Simple Mail Transfer Protocol<br>Case Study: POP3, the Post Office Protocol<br>Case Study: IMAP, the Internet Message Access Protocol<br>Application Protocol Metaformats<br>The Classical Internet Application Metaprotocol<br>HTTP as a Universal Application Protocol<br>BEEP: Blocks Extensible Exchange Protocol<br>XML-RPC, SOAP, and Jabber</li>
<li>Transparency<br>Studying Cases<br>Case Study: audacity<br>Case Study: fetchmail’s -v option<br>Case Study: GCC<br>Case Study: kmail<br>Case Study: SNG<br>Case Study: The Terminfo Database<br>Case Study: Freeciv Data Files<br>Designing for Transparency and Discoverability<br>The Zen of Transparency<br>Coding for Transparency and Discoverability<br>Transparency and Avoiding Overprotectiveness<br>Transparency and Editable Representations<br>Transparency, Fault Diagnosis, and Fault Recovery<br>Designing for Maintainability</li>
<li>Multiprogramming<br>Separating Complexity Control from Performance Tuning<br>Taxonomy of Unix IPC Methods<br>Handing off Tasks to Specialist Programs<br>Pipes, Redirection, and Filters<br>Wrappers<br>Security Wrappers and Bernstein Chaining<br>Slave Processes<br>Peer-to-Peer Inter-Process Communication<br>Problems and Methods to Avoid<br>Obsolescent Unix IPC Methods<br>Remote Procedure Calls<br>Threads — Threat or Menace?<br>Process Partitioning at the Design Level</li>
<li>Minilanguages<br>Understanding the Taxonomy of Languages<br>Applying Minilanguages<br>Case Study: sng<br>Case Study: Regular Expressions<br>Case Study: Glade<br>Case Study: m4<br>Case Study: XSLT<br>Case Study: The Documenter’s Workbench Tools<br>Case Study: fetchmail Run-Control Syntax<br>Case Study: awk<br>Case Study: PostScript<br>Case Study: bc and dc<br>Case Study: Emacs Lisp<br>Case Study: JavaScript<br>Designing Minilanguages<br>Choosing the Right Complexity Level<br>Extending and Embedding Languages<br>Writing a Custom Grammar<br>Macros — Beware!<br>Language or Application Protocol?</li>
<li>Generation<br>Data-Driven Programming<br>Case Study: ascii<br>Case Study: Statistical Spam Filtering<br>Case Study: Metaclass Hacking in fetchmailconf<br>Ad-hoc Code Generation<br>Case Study: Generating Code for the ascii Displays<br>Case Study: Generating HTML Code for a Tabular List</li>
<li>Configuration<br>What Should Be Configurable?<br>Where Configurations Live<br>Run-Control Files<br>Case Study: The .netrc File<br>Portability to Other Operating Systems<br>Environment Variables<br>System Environment Variables<br>User Environment Variables<br>When to Use Environment Variables<br>Portability to Other Operating Systems<br>Command-Line Options<br>The -a to -z of Command-Line Options<br>Portability to Other Operating Systems<br>How to Choose among the Methods<br>Case Study: fetchmail<br>Case Study: The XFree86 Server<br>On Breaking These Rules</li>
<li>Interfaces<br>Applying the Rule of Least Surprise<br>History of Interface Design on Unix<br>Evaluating Interface Designs<br>Tradeoffs between CLI and Visual Interfaces<br>Case Study: Two Ways to Write a Calculator Program<br>Transparency, Expressiveness, and Configurability<br>Unix Interface Design Patterns<br>The Filter Pattern<br>The Cantrip Pattern<br>The Source Pattern<br>The Sink Pattern<br>The Compiler Pattern<br>The ed pattern<br>The Roguelike Pattern<br>The ‘Separated Engine and Interface’ Pattern<br>The CLI Server Pattern<br>Language-Based Interface Patterns<br>Applying Unix Interface-Design Patterns<br>The Polyvalent-Program Pattern<br>The Web Browser as a Universal Front End<br>Silence Is Golden</li>
<li>Optimization<br>Don’t Just Do Something, Stand There!<br>Measure before Optimizing<br>Nonlocality Considered Harmful<br>Throughput vs. Latency<br>Batching Operations<br>Overlapping Operations<br>Caching Operation Results</li>
<li>Complexity<br>Speaking of Complexity<br>The Three Sources of Complexity<br>Tradeoffs between Interface and Implementation Complexity<br>Essential, Optional, and Accidental Complexity<br>Mapping Complexity<br>When Simplicity Is Not Enough<br>A Tale of Five Editors<br>ed<br>vi<br>Sam<br>Emacs<br>Wily<br>The Right Size for an Editor<br>Identifying the Complexity Problems<br>Compromise Doesn’t Work<br>Is Emacs an Argument against the Unix Tradition?<br>The Right Size of Software<br>III. Implementation</li>
<li>Languages<br>Unix’s Cornucopia of Languages<br>Why Not C?<br>Interpreted Languages and Mixed Strategies<br>Language Evaluations<br>C<br>C++<br>Shell<br>Perl<br>Tcl<br>Python<br>Java<br>Emacs Lisp<br>Trends for the Future<br>Choosing an X Toolkit</li>
<li>Tools<br>A Developer-Friendly Operating System<br>Choosing an Editor<br>Useful Things to Know about vi<br>Useful Things to Know about Emacs<br>The Antireligious Choice: Using Both<br>Special-Purpose Code Generators<br>yacc and lex<br>Case Study: Glade<br>make: Automating Your Recipes<br>Basic Theory of make<br>make in Non-C/C++ Development<br>Utility Productions<br>Generating Makefiles<br>Version-Control Systems<br>Why Version Control?<br>Version Control by Hand<br>Automated Version Control<br>Unix Tools for Version Control<br>Runtime Debugging<br>Profiling<br>Combining Tools with Emacs<br>Emacs and make<br>Emacs and Runtime Debugging<br>Emacs and Version Control<br>Emacs and Profiling<br>Like an IDE, Only Better</li>
<li>Reuse<br>The Tale of J. Random Newbie<br>Transparency as the Key to Reuse<br>From Reuse to Open Source<br>The Best Things in Life Are Open<br>Where to Look?<br>Issues in Using Open-Source Software<br>Licensing Issues<br>What Qualifies as Open Source<br>Standard Open-Source Licenses<br>When You Need a Lawyer<br>IV. Community</li>
<li>Portability<br>Evolution of C<br>Early History of C<br>C Standards<br>Unix Standards<br>Standards and the Unix Wars<br>The Ghost at the Victory Banquet<br>Unix Standards in the Open-Source World<br>IETF and the RFC Standards Process<br>Specifications as DNA, Code as RNA<br>Programming for Portability<br>Portability and Choice of Language<br>Avoiding System Dependencies<br>Tools for Portability<br>Internationalization<br>Portability, Open Standards, and Open Source</li>
<li>Documentation<br>Documentation Concepts<br>The Unix Style<br>The Large-Document Bias<br>Cultural Style<br>The Zoo of Unix Documentation Formats<br>troff and the Documenter’s Workbench Tools<br>TeX<br>Texinfo<br>POD<br>HTML<br>DocBook<br>The Present Chaos and a Possible Way Out<br>DocBook<br>Document Type Definitions<br>Other DTDs<br>The DocBook Toolchain<br>Migration Tools<br>Editing Tools<br>Related Standards and Practices<br>SGML<br>XML-DocBook References<br>Best Practices for Writing Unix Documentation</li>
<li>Open Source<br>Unix and Open Source<br>Best Practices for Working with Open-Source Developers<br>Good Patching Practice<br>Good Project- and Archive-Naming Practice<br>Good Development Practice<br>Good Distribution-Making Practice<br>Good Communication Practice<br>The Logic of Licenses: How to Pick One<br>Why You Should Use a Standard License<br>Varieties of Open-Source Licensing<br>MIT or X Consortium License<br>BSD Classic License<br>Artistic License<br>General Public License<br>Mozilla Public License</li>
<li>Futures<br>Essence and Accident in Unix Tradition<br>Plan 9: The Way the Future Was<br>Problems in the Design of Unix<br>A Unix File Is Just a Big Bag of Bytes<br>Unix Support for GUIs Is Weak<br>File Deletion Is Forever<br>Unix Assumes a Static File System<br>The Design of Job Control Was Badly Botched<br>The Unix API Doesn’t Use Exceptions<br>ioctl2 and fcntl2 Are an Embarrassment<br>The Unix Security Model May Be Too Primitive<br>Unix Has Too Many Different Kinds of Names<br>File Systems Might Be Considered Harmful<br>Towards a Global Internet Address Space<br>Problems in the Environment of Unix<br>Problems in the Culture of Unix<br>Reasons to Believe<br>A. Glossary of Abbreviations<br>B. References<br>C. Contributors<br>D. Rootless Root<br>Editor’s Introduction<br>Master Foo and the Ten Thousand Lines<br>Master Foo and the Script Kiddie<br>Master Foo Discourses on the Two Paths<br>Master Foo and the Methodologist<br>Master Foo Discourses on the Graphical User Interface<br>Master Foo and the Unix Zealot<br>Master Foo Discourses on the Unix-Nature<br>Master Foo and the End User<br>List of Figures</li>
</ol>
<p>2.1. The PDP-7.<br>3.1. Schematic history of timesharing.<br>4.1. Qualitative plot of defect count and density vs. module size.<br>4.2. Caller/callee relationships in GIMP with a plugin loaded.<br>6.1. Screen shot of audacity.<br>6.2. Screen shot of kmail.<br>6.3. Main window of a Freeciv game.<br>8.1. Taxonomy of languages.<br>11.1. The xcalc GUI.<br>11.2. Screen shot of the original Rogue game.<br>11.3. The Xcdroast GUI.<br>11.4. Caller/callee relationships in a polyvalent program.<br>13.1. Sources and kinds of complexity.<br>18.1. Processing structural documents.<br>18.2. Present-day XML-DocBook toolchain.<br>18.3. Future XML-DocBook toolchain with FOP.<br>List of Tables</p>
<p>8.1. Regular-expression examples.<br>8.2. Introduction to regular-expression operations.<br>14.1. Language choices.<br>14.2. Summary of X Toolkits.<br>List of Examples</p>
<p>5.1. Password file example.<br>5.2. A .newsrc example.<br>5.3. A fortune file example.<br>5.4. Basic data for three planets in a record-jar format.<br>5.5. An XML example.<br>5.6. A .INI file example.<br>5.7. An SMTP session example.<br>5.8. A POP3 example session.<br>5.9. An IMAP session example.<br>6.1. An example fetchmail -v transcript.<br>6.2. An SNG Example.<br>7.1. The pic2graph pipeline.<br>8.1. Glade Hello, World.<br>8.2. A sample m4 macro.<br>8.3. A sample XSLT program.<br>8.4. Taxonomy of languages — the pic source.<br>8.5. Synthetic example of a fetchmailrc.<br>8.6. RSA implementation using dc.<br>9.1. Example of fetchmailrc syntax.<br>9.2. Python structure dump of a fetchmail configuration.<br>9.3. copy_instance metaclass code.<br>9.4. Calling context for copy_instance.<br>9.5. ascii usage screen.<br>9.6. Desired output format for the star table.<br>9.7. Master form of the star table.<br>10.1. A .netrc example.<br>10.2. X configuration example.<br>18.1. groff1 markup example.<br>18.2. man markup example.<br>19.1. tar archive maker production.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://catb.org/~esr/writings/taoup/html/&quot;&gt;The Art of Unix Programming&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://catb.org/~esr/writings/taoup/cover.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Eric Steven Raymond&lt;/p&gt;
&lt;p&gt;This book and its on-line version are distributed under the terms of the Creative Commons Attribution-NoDerivs 1.0 license, with the additional proviso that the right to publish it on paper for sale or other for-profit use is reserved to Pearson Education, Inc. A reference copy of this license may be found at &lt;a href=&quot;http://creativecommons.org/licenses/by-nd/1.0/legalcode&quot;&gt;http://creativecommons.org/licenses/by-nd/1.0/legalcode&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
      <category term="Unix" scheme="http://ipcreator.me/tags/Unix/"/>
    
  </entry>
  
  <entry>
    <title>Teach Yourself Programming in Ten Years</title>
    <link href="http://ipcreator.me/2017/01/20/Program/Concepts/teach-yourself-programming-in-ten-years/"/>
    <id>http://ipcreator.me/2017/01/20/Program/Concepts/teach-yourself-programming-in-ten-years/</id>
    <published>2017-01-20T09:22:06.000Z</published>
    <updated>2017-02-15T13:06:00.988Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Teach-Yourself-Programming-in-Ten-Years"><a href="#Teach-Yourself-Programming-in-Ten-Years" class="headerlink" title="Teach Yourself Programming in Ten Years"></a><a href="http://norvig.com/21-days.html" target="_blank" rel="external">Teach Yourself Programming in Ten Years</a></h1><p>Peter Norvig</p>
<p><img src="http://okkntqe2h.bkt.clouddn.com/quote-more-data-beats-clever-algorithms-but-better-data-beats-more-data-peter-norvig-102-7-0712.jpg" alt=""></p>
<h2 id="Why-is-everyone-in-such-a-rush"><a href="#Why-is-everyone-in-such-a-rush" class="headerlink" title="Why is everyone in such a rush?"></a>Why is everyone in such a rush?</h2><p>Walk into any bookstore, and you’ll see how to Teach Yourself Java in 24 Hours alongside endless variations offering to teach C, SQL, Ruby, Algorithms, and so on in a few days or hours. The Amazon advanced search for [title: teach, yourself, hours, since: 2000 and found 512 such books. Of the top ten, nine are programming books (the other is about bookkeeping). Similar results come from replacing “teach yourself” with “learn” or “hours” with “days.”</p>
<p>The conclusion is that either people are in a big rush to learn about programming, or that programming is somehow fabulously easier to learn than anything else. Felleisen et al. give a nod to this trend in their book How to Design Programs, when they say “Bad programming is easy. Idiots can learn it in 21 days, even if they are dummies.” The Abtruse Goose comic also had their take.</p>
  <a id="more"></a>
<p>Let’s analyze what a title like Teach Yourself C++ in 24 Hours could mean:</p>
<p>Teach Yourself: In 24 hours you won’t have time to write several significant programs, and learn from your successes and failures with them. You won’t have time to work with an experienced programmer and understand what it is like to live in a C++ environment. In short, you won’t have time to learn much. So the book can only be talking about a superficial familiarity, not a deep understanding. As Alexander Pope said, <strong>a little learning is a dangerous thing.</strong></p>
<p>C++: In 24 hours you might be able to learn some of the syntax of C++ (if you already know another language), but you couldn’t learn much about how to use the language. In short, if you were, say, a Basic programmer, you could learn to write programs in the style of Basic using C++ syntax, but you couldn’t learn  <strong> what C++ is actually good (and bad) for. </strong>   So what’s the point? <strong>Alan Perlis once said: “A language that doesn’t affect the way you think about programming, is not worth knowing”.</strong> One possible point is that you have to learn a tiny bit of C++ (or more likely, something like JavaScript or Processing) because you need to interface with an existing tool to accomplish a specific task. But then you’re not learning how to program; you’re learning to accomplish that task.</p>
<p>in 24 Hours: Unfortunately, this is not enough, as the next section shows.</p>
<h2 id="Teach-Yourself-Programming-in-Ten-Years-1"><a href="#Teach-Yourself-Programming-in-Ten-Years-1" class="headerlink" title="Teach Yourself Programming in Ten Years"></a>Teach Yourself Programming in Ten Years</h2><p>Researchers (Bloom (1985), Bryan &amp; Harter (1899), Hayes (1989), Simmon &amp; Chase (1973)) have shown it takes about ten years to develop expertise in any of a wide variety of areas, including chess playing, music composition, telegraph operation, painting, piano playing, swimming, tennis, and research in neuropsychology and topology.</p>
<p><strong>The key is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes. Then repeat. And repeat again.</strong></p>
<p> There appear to be no real shortcuts: even Mozart, who was a musical prodigy at age 4, took 13 more years before he began to produce world-class music. In another genre, the Beatles seemed to burst onto the scene with a string of #1 hits and an appearance on the Ed Sullivan show in 1964. But they had been playing small clubs in Liverpool and Hamburg since 1957, and while they had mass appeal early on, their first great critical success, Sgt. Peppers, was released in 1967.</p>
<p>Malcolm Gladwell has popularized the idea, although he concentrates on 10,000 hours, not 10 years. Henri Cartier-Bresson (1908-2004) had another metric: “Your first 10,000 photographs are your worst.” (He didn’t anticipate that with digital cameras, some people can reach that mark in a week.)</p>
<p>True expertise may take a lifetime: Samuel Johnson (1709-1784) said “Excellence in any department can be attained only by the labor of a lifetime; it is not to be purchased at a lesser price.” And Chaucer (1340-1400) complained “the lyf so short, the craft so long to lerne.” Hippocrates (c. 400BC) is known for the excerpt “ars longa, vita brevis”, which is part of the longer quotation “Ars longa, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile”, which in English renders as “Life is short, [the] craft long, opportunity fleeting, experiment treacherous, judgment difficult.” Of course, no single number can be the final answer:</p>
<p> it doesn’t seem reasonable to assume that all skills (e.g., programming, chess playing, checkers playing, and music playing) could all require exactly the same amount of time to master, nor that all people will take exactly the same amount of time. As Prof. K. Anders Ericsson puts it, “In most domains it’s remarkable how much time even the most talented individuals need in order to reach the highest levels of performance. The 10,000 hour number just gives you a sense that we’re talking years of 10 to 20 hours a week which those who some people would argue are the most innately talented individuals still need to get to the highest level.”</p>
<h2 id="So-You-Want-to-be-a-Programmer"><a href="#So-You-Want-to-be-a-Programmer" class="headerlink" title="So You Want to be a Programmer"></a>So You Want to be a Programmer</h2><p>Here’s my recipe for programming success:</p>
<ul>
<li><p>Get interested in programming, and do some because it is fun. Make sure that it keeps being enough fun so that you will be willing to put in your ten years/10,000 hours.</p>
</li>
<li><p>Program. <strong>The best kind of learning is learning by doing. </strong>  To put it more technically, “the maximal level of performance for individuals in a given domain is not attained automatically as a function of extended experience, but the level of performance can be increased even by highly experienced individuals as a result of deliberate efforts to improve.” (p. 366) and “the most effective learning requires a well-defined task with an appropriate difficulty level for the particular individual, informative feedback, and opportunities for repetition and corrections of errors.” (p. 20-21) The book Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life is an interesting reference for this viewpoint.</p>
</li>
<li><p>Talk with other programmers; read other programs. This is more important than any book or training course.<br>If you want, put in four years at a college (or more at a graduate school). This will give you access to some jobs that require credentials, and it will give you a deeper understanding of the field, but if you don’t enjoy school, you can (with some dedication) get similar experience on your own or on the job. In any case, book learning alone won’t be enough.  <strong>“Computer science education cannot make anybody an expert programmer any more than studying brushes and pigment can make somebody an expert painter” says Eric Raymond</strong>, author of The New Hacker’s Dictionary. One of the best programmers I ever hired had only a High School degree; he’s produced a lot of great software, has his own news group, and made enough in stock options to buy his own nightclub.</p>
</li>
<li><p>Work on projects with other programmers. Be the best programmer on some projects; be the worst on some others. When you’re the best, you get to test your abilities to lead a project, and to inspire others with your vision. When you’re the worst, you learn what the masters do, and you learn what they don’t like to do (because they make you do it for them).</p>
</li>
<li><p>Work on projects after other programmers. Understand a program written by someone else. See what it takes to understand and fix it when the original programmers are not around. Think about how to design your programs to make it easier for those who will maintain them after you.</p>
</li>
<li><p>Learn at least a half dozen programming languages. <strong>Include one language that emphasizes class abstractions (like Java or C++), one that emphasizes functional abstraction (like Lisp or ML or Haskell), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), and one that emphasizes parallelism (like Clojure or Go).</strong></p>
</li>
<li><p>Remember that there is a “computer” in “computer science”. Know how long it takes your computer to execute an instruction, fetch a word from memory (with and without a cache miss), read consecutive words from disk, and seek to a new location on disk. (Answers here.)</p>
</li>
<li><p>Get involved in a language standardization effort. It could be the ANSI C++ committee, or it could be deciding if your local coding style will have 2 or 4 space indentation levels. Either way, you learn about what other people like in a language, how deeply they feel so, and perhaps even a little about why they feel so.</p>
</li>
<li><p>Have the good sense to get off the language standardization effort as quickly as possible.<br>With all that in mind, its questionable how far you can get just by book learning. Before my first child was born, I read all the How To books, and still felt like a clueless novice. 30 Months later, when my second child was due, did I go back to the books for a refresher? No. Instead, I relied on my personal experience, which turned out to be far more useful and reassuring to me than the thousands of pages written by experts.</p>
</li>
</ul>
<p>Fred Brooks, in his essay No Silver Bullet identified a three-part plan for finding great software designers:</p>
<ul>
<li>Systematically identify top designers as early as possible.</li>
<li>Assign a career mentor to be responsible for the development of the prospect and carefully keep a career file.</li>
<li>Provide opportunities for growing designers to interact and stimulate each other.</li>
</ul>
<p>This assumes that some people already have the qualities necessary for being a great designer; the job is to properly coax them along. Alan Perlis put it more succinctly: “Everyone can be taught to sculpt: Michelangelo would have had to be taught how not to. So it is with the great programmers”. Perlis is saying that the greats have some internal quality that transcends their training. But where does the quality come from? Is it innate? Or do they develop it through diligence? As Auguste Gusteau (the fictional chef in Ratatouille) puts it, “<strong>anyone can cook, but only the fearless can be great.</strong>“ I think of it more as willingness to devote a large portion of one’s life to deliberative practice. But maybe fearless is a way to summarize that. Or, as Gusteau’s critic, Anton Ego, says: “Not everyone can become a great artist, but a great artist can come from anywhere.”</p>
<p>So go ahead and buy that Java/Ruby/Javascript/PHP book; you’ll probably get some use out of it. But you won’t change your life, or your real overall expertise as a programmer in 24 hours or 21 days. <strong>How about working hard to continually improve over 24 months? Well, now you’re starting to get somewhere…</strong></p>
<p>References</p>
<p>Bloom, Benjamin (ed.) Developing Talent in Young People, Ballantine, 1985.</p>
<p>Brooks, Fred, No Silver Bullets, IEEE Computer, vol. 20, no. 4, 1987, p. 10-19.</p>
<p>Bryan, W.L. &amp; Harter, N. “Studies on the telegraphic language: The acquisition of a hierarchy of habits. Psychology Review, 1899, 8, 345-375</p>
<p>Hayes, John R., Complete Problem Solver Lawrence Erlbaum, 1989.</p>
<p>Chase, William G. &amp; Simon, Herbert A. “Perception in Chess” Cognitive Psychology, 1973, 4, 55-81.</p>
<p>Lave, Jean, Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life, Cambridge University Press, 1988.</p>
<p>Answers</p>
<p>Approximate timing for various operations on a typical PC:<br>execute typical instruction    1/1,000,000,000 sec = 1 nanosec<br>fetch from L1 cache memory    0.5 nanosec<br>branch misprediction    5 nanosec<br>fetch from L2 cache memory    7 nanosec<br>Mutex lock/unlock    25 nanosec<br>fetch from main memory    100 nanosec<br>send 2K bytes over 1Gbps network    20,000 nanosec<br>read 1MB sequentially from memory    250,000 nanosec<br>fetch from new disk location (seek)    8,000,000 nanosec<br>read 1MB sequentially from disk    20,000,000 nanosec<br>send packet US to Europe and back    150 milliseconds = 150,000,000 nanosec<br>Appendix: Language Choice</p>
<p>Several people have asked what programming language they should learn first.</p>
<p>There is no one answer, but consider these points:</p>
<ul>
<li><p>Use your friends. When asked “what operating system should I use, Windows, Unix, or Mac?”, my answer is usually: “use whatever your friends use.” The advantage you get from learning from your friends will offset any intrinsic difference between OS, or between programming languages. Also consider your future friends: the community of programmers that you will be a part of if you continue. Does your chosen language have a large growing community or a small dying one? Are there books, web sites, and online forums to get answers from? Do you like the people in those forums?</p>
</li>
<li><p>Keep it simple. Programming languages such as C++ and Java are designed for professional development by large teams of experienced programmers who are concerned about the run-time efficiency of their code. As a result, these languages have complicated parts designed for these circumstances. You’re concerned with learning to program. You don’t need that complication. You want a language that was designed to be easy to learn and remember by a single new programmer.</p>
</li>
<li><p>Play. Which way would you rather learn to play the piano: the normal, interactive way, in which you hear each note as soon as you hit a key, or “batch” mode, in which you only hear the notes after you finish a whole song? Clearly, interactive mode makes learning easier for the piano, and also for programming. Insist on a language with an interactive mode and use it.</p>
</li>
<li><p>Given these criteria, my recommendations for a first programming language would be Python or Scheme. Another choice is Javascript, not because it is perfectly well-designed for beginners, but because there are so many online tutorials for it, such as Khan Academy’s tutorial. But your circumstances may vary, and there are other good choices. If your age is a single-digit, you might prefer Alice or Squeak or Blockly (older learners might also enjoy these). The important thing is that you choose and get started.</p>
</li>
</ul>
<p>Appendix: Books and Other Resources</p>
<p>Several people have asked what books and web pages they should learn from.</p>
<p> I repeat that “book learning alone won’t be enough” but I can recommend the following:<br><strong>Scheme: <a href="http://www.amazon.com/gp/product/0262011530" target="_blank" rel="external">Structure and Interpretation of Computer Programs</a></strong> (Abelson &amp; Sussman) is probably the best introduction to computer science, and it does teach programming as a way of understanding the computer science. You can see <a href="http://www.swiss.ai.mit.edu/classes/6.001/abelson-sussman-lectures/" target="_blank" rel="external">online videos of lectures</a> on this book, as well as <a href="http://mitpress.mit.edu/sicp/full-text/book/book.html" target="_blank" rel="external">the complete text</a> online. The book is challenging and will weed out some people who perhaps could be successful with another approach.</p>
<p><strong>Scheme: <a href="https://www.amazon.com/gp/product/0262062186" target="_blank" rel="external">How to Design Programs</a></strong> (Felleisen et al.) is one of the best books on how to actually design programs in an elegant and functional way.</p>
<p>Python: <strong><a href="http://www.amazon.com/gp/product/1887902996" target="_blank" rel="external">Python Programming: An Intro to CS</a></strong> (Zelle) is a good introduction using Python.</p>
<p>Python: Several online <a href="http://wiki.python.org/moin/BeginnersGuide" target="_blank" rel="external">tutorials</a> are available at <a href="http://python.org/" target="_blank" rel="external">Python.org</a>.</p>
<p>Oz: <strong><a href="http://www.amazon.com/gp/product/0262220695" target="_blank" rel="external">Concepts, Techniques, and Models of Computer Programming</a></strong> (Van Roy &amp; Haridi) is seen by some as the modern-day successor to Abelson &amp; Sussman. It is a tour through the big ideas of programming, covering a wider range than Abelson &amp; Sussman while being perhaps easier to read and follow. It uses a language, Oz, that is not widely known but serves as a basis for learning other languages. &lt;</p>
<p>Notes</p>
<p>T. Capey points out that the <a href="http://www.amazon.com/exec/obidos/ASIN/0805803092" target="_blank" rel="external">Complete Problem Solver</a> page on Amazon now has the “Teach Yourself Bengali in 21 days” and “Teach Yourself Grammar and Style” books under the “Customers who shopped for this item also shopped for these items” section. I guess that a large portion of the people who look at that book are coming from this page. Thanks to Ross Cohen for help with Hippocrates.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Teach-Yourself-Programming-in-Ten-Years&quot;&gt;&lt;a href=&quot;#Teach-Yourself-Programming-in-Ten-Years&quot; class=&quot;headerlink&quot; title=&quot;Teach Yourself Programming in Ten Years&quot;&gt;&lt;/a&gt;&lt;a href=&quot;http://norvig.com/21-days.html&quot;&gt;Teach Yourself Programming in Ten Years&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Peter Norvig&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://okkntqe2h.bkt.clouddn.com/quote-more-data-beats-clever-algorithms-but-better-data-beats-more-data-peter-norvig-102-7-0712.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Why-is-everyone-in-such-a-rush&quot;&gt;&lt;a href=&quot;#Why-is-everyone-in-such-a-rush&quot; class=&quot;headerlink&quot; title=&quot;Why is everyone in such a rush?&quot;&gt;&lt;/a&gt;Why is everyone in such a rush?&lt;/h2&gt;&lt;p&gt;Walk into any bookstore, and you’ll see how to Teach Yourself Java in 24 Hours alongside endless variations offering to teach C, SQL, Ruby, Algorithms, and so on in a few days or hours. The Amazon advanced search for [title: teach, yourself, hours, since: 2000 and found 512 such books. Of the top ten, nine are programming books (the other is about bookkeeping). Similar results come from replacing “teach yourself” with “learn” or “hours” with “days.”&lt;/p&gt;
&lt;p&gt;The conclusion is that either people are in a big rush to learn about programming, or that programming is somehow fabulously easier to learn than anything else. Felleisen et al. give a nod to this trend in their book How to Design Programs, when they say “Bad programming is easy. Idiots can learn it in 21 days, even if they are dummies.” The Abtruse Goose comic also had their take.&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://ipcreator.me/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Program" scheme="http://ipcreator.me/tags/Program/"/>
    
      <category term="Algorithm" scheme="http://ipcreator.me/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>十分钟后开始使用英语</title>
    <link href="http://ipcreator.me/2017/01/20/MyShare/how-to-use-english/"/>
    <id>http://ipcreator.me/2017/01/20/MyShare/how-to-use-english/</id>
    <published>2017-01-19T18:13:06.000Z</published>
    <updated>2017-02-27T03:46:18.968Z</updated>
    
    <content type="html"><![CDATA[<p>原文作者：李笑来，<a href="http://lixiaolai.com/2016/06/11/makecs-appendix01/" target="_blank" rel="external">十分钟后开始使用英语……</a></p>
<blockquote>
<p>阅读这一篇文章，最多需要十分钟而已，之后你就可以开始使用英语了。<br>学习英语的最少必要知识是什么呢？</p>
<ol>
<li>学会音标</li>
<li>学会查词典</li>
<li>学会查语法书</li>
<li>学会正确地提问</li>
<li>养成最基本语言学习习惯</li>
</ol>
</blockquote>
<a id="more"></a>
<h2 id="学会音标"><a href="#学会音标" class="headerlink" title="学会音标"></a>学会音标</h2><p>音标只是一个符号系统。首先，任何人花上一下午就都可以学会。其次，千万别信那种胡说八道：“外国人都不用音标的”。先说说我们自己的母语，你什么时候见过一个受过教育的人不会用拼音的？遇到生词生字的时候，连拼音都不会的话，就算查到了，也不知道那字或词如何读。英语世界更是如此，要知道英语是目前地球上词汇量最多的语言，也就是说，在英语世界里，任何人遇到生词的概率都要大出许多许多倍 —— 只要是个正常受过教育的人，怎么可能不去查词典？怎么可能甘心于查了词典之后竟然不懂如何发音？</p>
<p>学习音标真的很简单。</p>
<p>从任何一本有文本的有声书中截取一段大约三五分钟的录音，然后把电子书的文本拷贝出来，粘贴复制到这个网站提供的工具里：<a href="http://upodn.com/phon.php" target="_blank" rel="external">http://upodn.com/phon.php</a> ，然后你就会得到一个英语与音标对应的文本。（我是如何知道这个网站的？Google 呗 —— ‘Phonetic Transcription’……）三五分钟的语音中（大约三五百个词）一定包含了所有的音素（辅音、元音）……<br>一边看音标文本文件，一边反复跟读这段文本……<br>一个下午，任何一个正常成年人都能搞定。</p>
<h2 id="学会查词典"><a href="#学会查词典" class="headerlink" title="学会查词典"></a>学会查词典</h2><p><strong>查词典，是学习语言的必需习惯</strong> —— 正如<strong>学习是生活的必需习惯</strong>一样，也正如<strong>翻阅文档是开发者必需习惯</strong>一样，其实，哪个领域都是一样的。</p>
<p>遇到生词就查。对，每一个。查着查着就越查越少了 —— 这是一定的。那些告诉你，“遇到生词（先）不（用）查，先猜”的人，让他们去屎。望文生义的笨蛋说的就是他们。</p>
<p>一句话里感觉没有生词，可就是看不懂，原因可能是某个单词有另外的词义，而你却只知道最常用的词义。比如，“down”这个单词，竟然还可以做名词使用，意思是“小鸟小鸡身上的软毛”……</p>
<p>那可能是有“你全都认识的词构成的你完全猜不到的词义”造成的，比如“purple passage”，“purple”你认识，“紫色的”，“passage”你也认识，“文章”，但“purple passage”是“辞藻过分华丽，金玉其外败絮其中的文章” —— 你可能就不知道了。</p>
<p>还有一种情况是，语法结构弄不明白…… 比如，“as” 有很多用法，到底是哪一个呢？那就走下一步：查语法书。</p>
<h2 id="学会查语法书"><a href="#学会查语法书" class="headerlink" title="学会查语法书"></a>学会查语法书</h2><p><strong>语法书是用来查的，不是用来背的</strong> —— 你啥时候见过人们背地图？</p>
<p>一张地图拿过来，知道“上北下南左西右东”，以及“少量标记符号”（比如，公交线长什么样，地铁线长什么样）这两个最少必要知识之后，就可以开始查地图了，不是吗？</p>
<p>语法书也一样，除了你在初中的时候已经学过的一些基础语法概念，比如“名词”、“动词”、“形容词”、“副词”什么的之外，你还需要知道另外一个概念：“功能词”。什么叫功能词呢？就是那些在语法书的附录里，带着页码编号的词……</p>
<p>你应该找个时间，比如一下午，大概翻翻那些功能词都有哪些，有个印象就好。</p>
<p>然后，在遇到“没有生词、没有不了解的词义、没有不认识的词组，但就是读不懂的句子”的时候，仔细看看那句子里有没有功能词存在？有的话，去查查语法书，在附录里找到对应的页码（可能不止一个），按图索骥地查下去，一定能找到答案……</p>
<p>你以为你遇到过的英语老师啥都懂吗？不是的！他们就是比学生多一个技能：<strong>遇到问题的时候，他们懂得如何查词典，如何查语法书</strong>…… 哪个领域都是一样的 —— 你以为“高级程序员”什么都懂吗？某种意义上，他们只比那些“低级程序员”多一个技能：<strong>遇到问题的时候，他们懂得如何检索文档，如何问 Google</strong>……</p>
<h2 id="学会正确提问"><a href="#学会正确提问" class="headerlink" title="学会正确提问"></a>学会正确提问</h2><p>能问 Google 的，都不要去问别人，这是礼貌。</p>
<p>别问人家这个单词什么意思，别问人家这句话什么意思 —— 自己动手去查！一个词典查不到，再换一个，换一个还查不到，还有 Gooogle 呢！</p>
<p>实在查不明白，还有个办法，去 <strong>Google 那句原文，然后加上一个汉字“的”或者“了”</strong>（这两个字是中文中使用频率最高的词），这个搜索组合很可能让你找到已经有人在网上提问过……</p>
<p>自己折腾过了，还搞不明白，再去问可能帮你的人 —— 他们也搞不定，也有可能，那就记在本子里。很神奇的事情是，<strong>大量的问题，都会在某一天自动出现解决方案的 —— 前提是，你还记得那个问题!</strong></p>
<p>不会正确提问，其实只不过是懒惰的表现，懒人是没救的，所以千万不能做懒人。</p>
<h2 id="养成最基本语言学习习惯"><a href="#养成最基本语言学习习惯" class="headerlink" title="养成最基本语言学习习惯"></a>养成最基本语言学习习惯</h2><p><strong>朗读。天天朗读。每天朗读半小时，坚持两百天</strong>，才 100 小时…… <strong>每天朗读一小时，坚持 100 天</strong>，也就是三个月多一点点 —— 你已经把 90% 的人甩在身后了，真的！</p>
<h2 id="阅读先行是很自然的"><a href="#阅读先行是很自然的" class="headerlink" title="阅读先行是很自然的"></a>阅读先行是很自然的</h2><p>口语难练，这是很正常的，因为在大多数情况下，我们读书、看电影的时候，由于面对的并不是真实的人，所以我们大脑中的“镜像神经元”很难被激发，于是学习能力处于“冬眠状态”。其实每个人都很有语言天赋的，顶多是一点点的好坏差异而已。你看，几乎任何一个人在一个新的城市里住上一周以上，口音就会发生一些微妙的变化，并且根本不是故意的（都没有刻意练习） —— 只是因为镜像神经元被激发了。</p>
<p>可是阅读这东西，用不着镜像神经元过分活跃 —— 只是在小时候启动的时候可能需要（<strong>家长喜欢看书，孩子通常更容易喜欢看书</strong>）。所以，你要相信你的阅读能力可以很快提高的，事实上，确实如此 —— <strong>只需要啃上一本原版书，基本上就过关了。</strong></p>
<p>选择原版书的时候，一定要选择自己感兴趣的领域 —— 英语教科书在这方面几乎是最差的。现在对你来说，这是个很好的机会，你不是对编程感兴趣吗？不是对成为计算机工程师感兴趣吗？那就读这个领域的原版书好了。这样的时候，你的<strong>焦点并不在于英语本，而是在于那语言文字背后的思想，这样的时候，你的大脑会很厉害，它自己会想办法穿透那层“毛玻璃”（英语），看到那玻璃背后的意义</strong>…… 不知不觉之间，那“毛玻璃”就会变成“透明玻璃” —— 就这么简单。</p>
<h2 id="刻意练习永远是必须的"><a href="#刻意练习永远是必须的" class="headerlink" title="刻意练习永远是必须的"></a>刻意练习永远是必须的</h2><p>每天都要挤出一点时间，把今天遇到过的生词复习几遍 —— <strong>上学的时候不懂如何复习的人学习都不好</strong>，现在在成年阶段重新学习的时候，可别再吃这个亏了！而且，这个习惯是会“遗传”的：<strong>你的孩子若是看到你总是通过重复获得进步，他们也会自然而然地习惯于重复获得进步</strong>，这是真理。</p>
<p>没！有！别！的！了！</p>
<p>任何正常人都可以上路了。如果还想让自己更心安一点，那就去读一本书<a href="http://zhibimo.com/read/xiaolai/everyone-can-use-english/" target="_blank" rel="external">《人人都能用英语》</a>，其实只有一个字和一个感叹号：<strong>“用！”</strong></p>
<p>用吧用吧，不是罪。</p>
<p>大多数人的平庸和愚蠢，其实都是当初自己选的 —— 这真是一个残酷的事实。</p>
<p>任务</p>
<ul>
<li>今天就彻底学会音标。</li>
<li>从明天早上就开始坚持朗读。</li>
<li>配置好自己的计算机以便随时查词典，请 Google Mac Dictionary 添加词典。</li>
<li>请 Google 新编英语阅读手册。</li>
<li>请 Google 人人都能用英语。</li>
<li>请 Google how to ask questions，第一个就是 Eric Steven Raymond 写的 <a href="http://www.catb.org/esr/faqs/smart-questions.html" target="_blank" rel="external">How to ask questions the smart way</a>，必须精读。</li>
<li>另外，还有一篇 <a href="https://hbr.org/2009/05/real-leaders-ask.html" target="_blank" rel="external">HBR 的文章</a>，也要细看。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文作者：李笑来，&lt;a href=&quot;http://lixiaolai.com/2016/06/11/makecs-appendix01/&quot;&gt;十分钟后开始使用英语……&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;阅读这一篇文章，最多需要十分钟而已，之后你就可以开始使用英语了。&lt;br&gt;学习英语的最少必要知识是什么呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;学会音标&lt;/li&gt;
&lt;li&gt;学会查词典&lt;/li&gt;
&lt;li&gt;学会查语法书&lt;/li&gt;
&lt;li&gt;学会正确地提问&lt;/li&gt;
&lt;li&gt;养成最基本语言学习习惯&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="英语" scheme="http://ipcreator.me/categories/%E8%8B%B1%E8%AF%AD/"/>
    
    
      <category term="English" scheme="http://ipcreator.me/tags/English/"/>
    
  </entry>
  
</feed>

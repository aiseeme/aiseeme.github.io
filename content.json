[{"title":"猎豹CEO傅盛：关于深度学习的五个思考","date":"2017-02-19T15:59:59.000Z","path":"2017/02/19/SmartAI/BusinessAI/some-thoughts-of-fusheng/","text":"来源：36大数据 作者：傅盛 任何一场革命，绝不是以敲锣打鼓的方式，来到你的身边。等到某一天，你忽然发现快要天翻地覆时，再去看，发现自己已被别人抛弃了。过去以端为中心的技术革命，不能说结束了，但已不再是时代的风口。 技术，进入了一场以数据为驱动的革命。互联网不再只是一张虚拟的网，而更像是一个大数据库。大量的数据，沉甸甸，就在那里。没有人知道，怎么把这些数据，更加完整清晰的表达出来。我们需要重新思考技术的致胜点。 怎么思考呢?我讲几个关键点。 1、数据和运算能力，变得越来越重要。孔子说过一句话：“学而不思则罔，思而不学则殆”。 先说，学而不思则罔。你拿了很多知识，不深度学习，不行。如果你没有运算能力，有了一堆数据，算不出来，没用。不是深度越深，效果越好。这是个复杂的问题。需要不停算，不停实验。 今天，整个深度学习的理论，还不够成熟，依然落后于实践。更多时候，只能靠试。此时，运算能力，就变得非常关键。 假如，别人做一次运算，要两个礼拜，而你只需要一天或2个小时。同样时间内，你可以做更多实验，积累更多宝贵经验，迭代速度也更快。 这就好像，两个人起点一样，但由于迭代速度不同，导致了最后成就的千差万别。每一次迭代，相当于你的一次翻版。你是一天迭代一次，还是一年迭代一次。你对自己翻版本的速度有多快，决定你最后以多大的成果超过对手。 思而不学则殆呢?简单说，如果你没有数据，一点用都没有。 这个时代越来越需要海量数据。数据量越大越好。甚至于，我们以前被认为不是很关键的数据，都有可能灌进去，再看效果。 这才有了一句流行语——Welcome to the GPU world. GPU最早为快速满足增长的图形计算需求而设计。它不同于CPU，在多核多线程处理上浮点性能更佳，使得它在图形界的并行运算，变得超强。 早期，谷歌发表了一篇论文说——深度学习的结果，要跑在英伟达的GPU上。很快，做芯片起家的英伟达，其公司股价开始蹭蹭蹭一路上涨，涨了好几十块。 然而，如果今天，你还以为英伟达是个显卡公司，那就大错特错了。如今汽车的防撞系统，警告系统，以及无人驾驶采用的双目视觉图像处理，英伟达是第一大提供商。它其实变成了一家人工智能公司。 说到这，大家可能也会奇怪——今天关于无人驾驶，辅助驾驶的新闻越来越多，也有越来越多的公司在做，为啥呢? 核心就在于，深度学习极大降低了这一门槛。只要你能拿到足够数据，就可能实现对物体的各种判断。 本质也带来了一个技术上弯道超车的好机会。很多公司辛苦积累的软件技术直接作废了。包括IBM做了语音输入好多年，上来就被深度学习超越了。尤其当谷歌进入语音输入时，一下就超越了IBM多年的技术积累。与此同时，谷歌还有足够多的数据，以及足够多的语音样本，不停输入。 算法为核心的竞争力，正转换成数据为核心竞争力。 我个人觉得，甚至有些算法会消失掉。但，并不是说算法不重要。只是神经网络的核心算法，提升起来太难。 现在大家都把专注度放在了数据和运算。尤其在深度学习里，获取足够多的数据，就有机会产生更好的结果。神经网络本身差异不会很大，关键比的是——谁能把这些数据用好，并快速计算。 数据变得越来越重要。尤其在深度学习里，获取足够多的数据，就有机会产生更好的结果。神经网络本身差异不会很大，关键比的是——谁能把这些数据用好，并快速计算。 2、公司研发结构会发生很多改变，数据获取和数据标注会变得非常重要。中国在这场竞争中，还是有很大机会。能够轻易获取的互联网数据，以及低成本的众包劳动，将为中国公司带来训练所需的计算和人力资源。 第一，数据获取的量级。尽管美国整个技术的前沿性很好，问题在于——硅谷一家小公司拿到的数据，和一家中国高速发展的互联网公司拿到的数据，不可同日而语。 第二，数据标注的成本。在美国，要搞数据标注，肯定很累，多贵啊!但在中国，到珠海或成都随便找300个人，去帮你标注，成本很低。ImageNet图像分类大赛，中国人取得的成绩明显突出。国外，微软或谷歌参赛，都是几个人去做图像标注和算法验证。而中国可以组织足够多的人去做标注。我认为，ImageNet大赛，未来的世界冠军都会来自中国。 3、并行异构计算的人才，变成核心竞争力。过去计算领域都是以CPU为中心的计算模式。深度学习要将CPU和GPU两个加起来。这是两个技术的计算模型，是异构的模型。 为什么要异构? 因为GPU是并行的。它需要用来显示。为了让你的屏幕刷新保持更快更流畅，就要把GPU分成很多个小的运算单元。每一个运算单元，负责屏幕某一块具体区域的刷新。而大量这样的运算单元都包含在一个GPU当中。要想跑得快，就得把计算逻辑放在CPU中，同时再把你准备好的数据拷贝到GPU中。然后呢?GPU再用并行的方式，计算准备好的这些数据。这就是异构的模型。 这个模型，是计算体系，也是硬件体系的一次革命，是真正的技术革命。 举个例子。现在要完成一个复杂的大型任务，需分割在100台机器，让它们分开跑，又同时共同执行同一个全局任务，需要一个数学上严格的方法来完成。这意味着，每一次计算更新的时候，都要把大数据刷一遍，刷几千遍是何其难的事情。几十亿个参数的深度学习模型，每一次迭代都要把参数刷一遍。尤其数据量足够大时，这是很难的。 因此，能否调动大量的运算资源，就会成为核心竞争力。我的判断是，未来整个研发结构——重数据，重运算，这两点，必然出现。 4、语音和视觉，将成为下一代交互模式。可能大家没有注意一个数据，谷歌已经有20%的搜索来自语音。这是很可怕的一个趋势。我认为，语音和视觉会是下一代的交互模式。过去我们从PC时代的十指模式(电脑键盘)，走到今天的拇指模式(手机)，未来一定是自然模式(语音和视觉)。因为，太多的交互都会变得很简单。有多简单呢?只会用接触的方式去完成。今天之所以还没有大规模到来，其实是技术不够成熟。亚马逊发布Echo时，为什么谷歌那么在意?我觉得很重要的一点，就是它通过300万台的设备，不停地拿数据——用户的每一次说话，都是一次新的数据。这个数据足够多，又反过来加深它的语音能力。交互模式的变化，不仅改变了产品，也影响了数据方式。 5、深度学习在各个领域产生的变革才刚刚开始。无论是现阶段的内容个性化推荐，还是未来输入方式的改变，还有太多地方，可以被深度学习改变。比如人脸识别。今天你用支付宝，或招商银行客户端，都会让你扫一扫，准确率已经相当高了。高到什么程度呢?有一家公司专门为海关提供人脸识别服务。以前用人工查看，看两个小时后就会出错，加上深度学习算法的系统，极大降低了人脸识别的出错率。 我认为，只要需求越多，它就会越来越准。 比如小米手机出了面孔功能。根据人脸识别进行照片分类。已经可以达到92%的准确率了。包括猎豹。我们在全球有6亿月度活跃用户，一旦建立起深度学习的核心技术能力，猎豹向很多领域的扩展和应用结合就会变成可能。 如果你把深度学习看成一种“工具”，就会发现——它有很多和其它领域，包括传统行业相互结合的机会。 漫漫长路，才刚刚开始。End.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"},{"name":"Business","slug":"Business","permalink":"http://ipcreator.me/tags/Business/"}]},{"title":"人工智能的黄金时代","date":"2017-02-19T15:59:59.000Z","path":"2017/02/19/SmartAI/BusinessAI/golden-age-of-artificial-intelligence/","text":"“人工智能时代，将是一个比移动互联时代大十倍的市场 —-李开复” 10年后，人工智能能将取代世界上90%的翻译/记者/助理/保安/司机/销售/客服/交易员/会计/保姆。 人工智能也就是这样几个事情，感知、决策、反馈。 人工智能发展的主要里程碑。 近年最大的突破：深度学习深度学习是什么？你丢一大堆数据给它，然后问它，我应该买什么股票？这个人的保险该付多少钱？这个想贷款的该不该贷？这个信用卡的交易是否有欺诈的嫌疑？你还可以问他，这么多的男人你应该找哪一个为对象？你也可以问他，今天晚上这么多好吃的，我应该吃哪些？它都会告诉你一个答案。 深度学习之后还有更新的技术 什么领域适合人工智能海量的数据，清晰领域界限，顶尖的AI科学家，还有自动标注数据，以及超大的计算量。科学家的创业时代来临了，而不是三个小朋友的创业时代。 机器学习在很多领域超越人类、创造巨大价值左上角代表的是在图像识别领域机器超越人类，左下角是语音识别领域机器的错误率低于人类。当人脸识别超越了人类，我们还需要保安吗？当语音识别超越了人类，我们还需要客服吗？还需要打电话推销吗？当自动驾驶超越人类，我们还需要司机吗？当传内容，写新闻，金融稿件的能力超越了人类我们还需要金融界记者吗？90%的金融领域的报道都是传出来的，这些报道以后绝对不是人写的，人写是会犯错的，机器不会犯错，只有深度的报道才需要人写。那到底哪些领域可以做人工智能，可以挣钱呢？实在太多了，这里随便列了三十多个领域，在任何一个领域就是一个商业计划书，如果你能找到一个该领域的超级的商业专家，销售专家，再搭配一个人工智能的科学家，那就是一个黄金创业团队。 简单来说，谁能做人工智能的创业 第一种，谁手中拥有互联网数据的这个是最了不起的，也就是BAT、滴滴、美图等等，他们手中有数据，而且已经标注，只要有科学家就可以产生价值。 第二种是传统企业，比如说股票的数据，比如说保险业、银行业，各种金融的。我觉得数据非常的丰富，而且是非常的狭窄领域，不用跨领域的理解，而且可以快速产生商业价值。再往下医学，如何看片子，看MRI，看CT，看各种人的健康记录一定是超过医生的，现在至少有3种重要的病症人工智能已经超越了医生的平均水平，而且你像这个是要花多少临床的时间，现在三种可能再过5年就是300种，再过10年可能就是3000种。然后90%的医生就都不需要了，至少被机器取代。那这些医生就要做更高等的工作，更深入的工作，去发掘新的医药的工作，或者是做更心理医疗的工作。面对病人，机器还是冷冰冰的，可能还需要一个人脸对着病人，但是90%的医生，在10年以后应该都打不过我们机器的诊断能力了。这对人类是有很大意义的，教育的数据也是很多的，就不多细讲。 最右边是无人驾驶。这是我们特别看好的领域，它是最大颠覆量的，以后都不需要人开车了。再加上电动车和共享经济，以后我们出门的时候，一辆坐一人的车就会出现在我们面前，它带我们去要去的地方，节能低碳，减少雾霾，而且这还会影响整个经济。如果大家谁有投资停车场的，十年以后就没有停车场了。所以，这些都有巨大的颠覆性。如果你们觉得听起来像是天方夜谭，像是科幻小说，那么你们也可以想一想，2009年当我告诉所有人移动互联网时代来临的时候，大部分人也是这样想的。甚至当时的BAT听了移动互联网的预测之后，他们总是认为没有PC大，没有PC赚钱，成长的会很慢。但现在你看他们一个个也都追上来了。所以人工智能是一个特别巨大的领域和机会。 我们到底该和谁学人工智能呢？ 世界上最懂人工智能的绝对是谷歌这个公司了。在一年前他就宣布了要做Alphabet这个母公司。什么是Alphabet呢？其实它就是把谷歌里面做搜索提炼出来的人工智能做成谷歌大脑，然后把它用到各种领域。用在围棋就成了AlphaGo，我们已经看到它的威力有多大了，用在汽车就是Google car，用在健康就是Google house用在基因检测就是Google genetics，所以在Alphabet上面，谷歌的野心就是要把一个谷歌的成功变成26个，这是一个特别有野心的人工智能的公司。 谷歌公司内部也是在用刚才所说的深度学习。这个图是来自谷歌的一个科学家，他对外演讲用的我们可以看到也是在这4年，他们才领悟了人工智能的价值和谷歌大脑的价值，收购了Deep Mind这样的公司。所以很明确的就是，谷歌的Alphabet这样的一个动作，绝对是它看到了机器学习可以进入各种领域的机会，这也是它所进行的一个很有野心的探索。 到底人工智能如何克服挑战产生竞争壁垒呢？ 第一，就是要寻找行业里面有特别大的大数据，然后是垄断性和闭环的。第二是买很多机器，尤其是CPU＋GPU。第三是有很厉害的深度学习的科学家。第四，虽然这些顶尖科学家很有价值，同样的小朋友也有价值。不过小朋友还不能创业，需要培训。人工智能很大的一个特色是速成，他不像是你去找一个化学科学家，或者说生物科技或者甚至是计算机领域的这个Networking 、Database之类的，非常难学。人工智能不一样，它很好学，前提是你一定要是一个数学天才。 怎么样让人工智能快速商业化 第一是做助手，而非取代人。第二是界面要用好，给很多结果，而不只是一个结果。第三草船借箭，要用户提供数据，如果你的数据不够。第四局限你的领域，不要做一个特别伟大的超级的技术。 中国的独特人工智能机会 中国在人工智能领域比移动互联网领域还适合创造世界顶尖的公司。第一个理由就是，中国人很适合做人工智能。第二，训练小朋友非常快速第三，传统企业的人工智能技术非常的弱第四个理由，因为中国市场大，互联网公司多，很多非AI的公司到了一定的规模，就开始需要AI。第五点，美国人工智能现在是绝对领先中国的，但是他们进不了中国，中国上面有各种理由。最后一点是中国对人工智能各方面的约束较少。 创新工场对人工智能有一个很完整的投资蓝图 第一个重点是大数据的机会第二个是语言方面第三呢，是传感器的降价非常的重要。最后是自动驾驶 创新工场在人工智能领域在做什么呢？ wonder workshop，它是一个人工智能的玩具。它可以跟着小朋友，就像现在的这个大疆新的机型，可以让它跟着你一样。甚至两个机器可以在一块玩等等，很有趣的。它是一个没有眼睛、耳朵、手与脚只是几个小轮子做的这样的一个机器人，我们认为这个领域也像Echo音响一样是有机会的。 找一批专家带一批学生，买大量的数据，数据也包括了金融交易的数据。AI时代的创业呢，都是科学家。 如何去做早期公司的投资 第一个怎么投资公司。刚才我已经说过了，要衡量它有没有大数据，然后有没有独特的大数据，不是买来的大数据，有没有科学家，有没有闭环，有没有很多机器。然后他做的这个领域，是不是可以产生商业价值的领域，还是一批科学家在瞎搞。这是第一个。看这些项目要小心，还有看机器人的项目，有眼睛耳朵手与脚的就千万不要再听了，虽然听起来很酷。无人驾驶可以去想想怎么去参与。 这是投公司的，投基金呢？投创新工场和真格基金就可以了。 至于买股票呢？我是美图的董事，可能下面不适合说，但是你应该知道我要说什么，我们看好美图，认可美图。 刚才也分享了，量化AI在国内的投资应该机会特别大，这不是一个人工智能投资，这是一个真的二级市场的投资，当然要避免一些法律所不允许的事情，但是机会还是很多。那么我们现在也在专门看这个量化AI投资，对于这些呢，如果有兴趣的我们也可以一起以后在别的机会一起探索。 我也给大家说了，过去两年，我所有的资产基本都是在创新工场里，除了一栋房子，创新工场，我所有的资产基本上都是交给机器人管理，都是用AI量化来管理。这个也就是告诉你我对这个领域是多么看好和认可。当然三年后这个领域可能就是红海了，只是说现在的机会是非常好的。当然我还有一支股票是例外的，是我孩子决定要投资的。就像如果说在移动互联网时代，二级市场最好的投资标的是ARM，人工智能的时代是什么？大家确实可以看一看NVIDIA。 报告称：被机器人取代的不止低端行业 中产阶级也有风险 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 【网易智能讯 2月7日消息】 该研究分析了在技术发展情况下高薪工作被自动化设备取代的风险。 研究指出，房地产经纪人和信贷分析师 等中产阶级职业被自动化设备取代的风险高达97%，而包括侦探、法官和治安官被取代的风险偏向中等，包括牙医、医生和消防员等职业被自动化取代的风险较低。 总体来说，技术的进步很快就会使几十个中产阶级工作岗位变得岌岌可危。 该研究的作者Carl Frey是牛津大学的一名校长，他之前曾发表过一份研究报告，认为英国有35%的工作处于被机器人取代的危险之中。其主要工作是分析今后哪些收入更高的工作可能会消失。 通过对诸多年薪超过4万美元的工作进行深入调查分析，Frey编制了一份风险清单，显示了哪些工作最容易被自动化所替代，同时哪些工作最有可能存续下去。 研究指出，由于计算机技术的不断发展，保险公司和房地产中介等高收入中产阶级正在面临被取代的风险。该类工作有97%的概率将会被计算机所替代，也会引发相关中产阶级的担忧。 Frey告诉《时代周刊》，“在未来几十年内，对专业技能要求较低的工作岗位自动化程度会越来越高，但中等收入的工作岗位同样面临会面临着被自动化取代的风险。” 信用分析师也被归于Frey的高风险列表，其职位有97%的概率会被机器人所取代。邮政服务工作者岗位被取代的概率是95%，而实验室技术人员的风险为89%。 此外，研究指出，地铁或有轨电车的工作人员有93%的概率被自动化。 这些数据表明了一项客观的评估，即科技如何取代人类完成工作和任务的交互，并不是说在不久的将来人类工作将变得多余。另一方面，这项研究也表明各类工作有被自动化的风险。 研究人员称，消防员、牙医和医生等专业岗位被自动化的概率不到1%。这项研究也表明，长期来看此类工作相对安全。其中包括诸如牙医、精神病医生和营养师等医疗保健岗位。总体来看，整个医疗保健行业的岗位普遍“低风险”。此外还包括营养师、营养学家、精神病医生、足疗医生和药剂师等职位。 根据这项研究，包括侦探、法官和地方官员等岗位属于中期内安全职业——这或许表明，虽然理论上这些工作可以自动化，但技术的复杂性还无法满足现实需求。 长期以来，人们认为传统的低技能工作将逐渐被淘汰，因为随着经济的发展计算机技术的应用更加具备成本效益，技术的发展将使那些看似脆弱的工作岗位变得更加脆弱。 尽管这项研究分析的是美国岗位，但Frey指出，由于行业相似，发展阶段相同，这项研究也适用于英国。 （英文来源：每日邮报编译：机器小易 校对：晗冰）。 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 停车库、浏览器、提款机、十字路口与办公室，都将由AI控制 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月6日消息，如果人工智能（AI）真的在改变我们的日常生活，它会如何改变?仔细想想，你就会发现，像人类这样处理信息的技术依然处于早期阶段，但它已经出现在聊天机器人和像亚马逊Echo这样的扬声器上。然而，我们每天使用的许多服务仍未获得AI支持，这是多么糟糕！ 1.AI停车库 目前正在进行的许多尝试，都希望让泊车变得更容易，其中包括福特的汽车，你可以使用应用来预订停车位，并支付停车费。但我希望的是更先进的方案。 当你驾车到来时，由AI支持的停车库可以识别出你的车，然后查阅你的账户。当它发现你是老顾客时，头顶的扬声器系统就会与你聊天，并引导你到空旷的地方，向你展示你的奥迪的“夜生活”，然后让你自动付款。当你离开时，如果有任何问题，都可以在出口处跟机器人协商处理。 2.网络浏览器 网络浏览器如何能从人工智能中获益呢?这听起来似乎显得有些牵强，但当你在网页上搜索特定主题，比如新的打印机时，AI助理会注意到，并提供最佳选择的链接。它会帮你记住这些网站——不仅仅是把它们放在书签或收藏在浏览历史中，还可以把它们保存在知识库中。 你不需要搜索那个档案——AI可以提醒你这些事实和链接。它可能会关注你在社交媒体上发布的信息，甚至建议你不要和一个在Twitter上攻击别人的人打交道。而且，它可能还可帮助我们进行标签管理，调整我们正在使用的标签宽度，或者提供我们昨天就没有触碰过的标签。 3.自动提款机 这些愚蠢的终端可能会变得更聪明。当然，我们主要需要它们进行存款和提取现金。有些最受欢迎的银行ATM可以记住你通常使用的选项，比如最喜欢的账户。人工智能会更了解你，提醒你(如果你启用了这个功能)关于到期的账单等。 最重要的是，它会使用生物识别技术来识别你，知道你总是在特定的日期存取款。它还可了解你的其他习惯，以使这个过程变得更快、更容易。 4.道路交叉路口 我知道现在正努力让公路变得更加智能化——在不久的将来，我们的汽车将会知道什么时候交通灯会变绿。然而，人工智能将能够随时识别汽车和卡车的确切位置。它可以与信号灯进行交流，以调整交通流量。 如果人工智能可以进行干预(如果我们允许的话)，汽车本身知道如何避免在十字路口发生碰撞，并调整两辆车的方向盘和刹车，其中包括由傻瓜驾驶的汽车。 5.办公桌椅 这看起来可能有些奇怪，但它的确能从AI中受益。假设你的办公器具都有AI支持。你的椅子可以调整，以便符合你的骨骼结构或任何医疗条件。 你的站立式办公桌可以根据你的身高和体重(以及打字风格)来调整，以符合最佳的人体工程学。当你坐得太久时，桌子可能会建议你站立15分钟。如果你没精打采地坐着，椅子可能会轻轻地推你一把。 （英文来源/venturebeat，编译/机器小易，校对/小小 ） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"}]},{"title":"李开复：AI 创业的十个真相","date":"2017-02-19T15:59:58.000Z","path":"2017/02/19/SmartAI/BusinessAI/ten-truths-of-ai-star-up-firm/","text":"作者：史中 “重仓”人工智能，是李开复和创新工场未来几年的方向。但是，他面临一个很重要的问题：现在的 AI 创业，核心是 AI 科学家，而“文能起笔安天下，武能上马定乾坤”的 AI 科学家凤毛麟角，用他的话说“该创业的都创业了”。 这时，产业在面临一步棋。那就是：如何把一个普通的 AI 科学家变成“创业英雄”。 作为三十年前就开始研究人工智能的李开复，觉得自己“技术范儿”的创新工场有能力推动这步棋，并且在这一步棋中获得稳固的战略优势。 李开复告诉雷锋网(公众号：雷锋网)，AI 创业现在是科学家的天下，之后是数学家的天下，将来是普通人的天下。 以下是李开复在《创新工场人工智能战略白皮书》发布会上的闭门分享，雷锋网将其整理成为《李开复：AI 创业的十个真相》，呈现给读者。 AI 科学家都是超级宅男创新工场本身主营的机构是投资和投后的机构，我们当然是看项目，看创始人，他们有 idea、方向，我们就会用基金投资它。 过去的互联网创业模式，已经非常经典地被《精益创业》描述： 几个小朋友随便做个产品上去，能融资就融资，不能融资就拉倒。怎么样去惠及用户，迭代产品，之后变现，成为经典的模式。这个创业的模式，它的红利时代已经过去了。当然以后还会有，但是不会像以前那么多。创业的门槛大大提高了，因为人工智能是下一批创业方向，而人工智能创业里面很核心的人物其实是 AI 科学家， AI 的公司没有 AI 科学家是没戏的。 但是AI科学家往往都是超级宅男，自己宅在房间里面，整天做实验，突然你把他丢到一个残酷野蛮可怕的世界里，他自己创业成功率不是很高。 很多 AI 科学家一般这辈子从来没想过创业，现在突然想创业了，然后发现自己长板特别长，短板特别短： 他也许技术很牛，但是也许执行不够；也许他的产品演示起来很好，但是一做起来都是Bug；也可能他产品做得很不错，但是不懂市场；或者懂市场但是不知道怎么去卖。尤其 AI 本身又是一个 ToB 的业务，所以不是那么容易自己攒一个局。所以 AI 科学家需要懂商业的人，懂 ToB 的人，他需要工程师。 AI 创业“不美好”我们平时都会把 AI 创业讲得很美好，今天我就跟大家讲讲 AI 不美好的地方。 第一个就是：AI 科学家有短板。这一点刚才已经说了，我们要想怎么帮“宅男”补足短板。 第二个就是：AI 创业很贵。刚才讲的“精益创业”很便宜，因为几个小朋友不拿薪水，用零元就可以把第一个 App 推出去。我们刚投资一家公司，投了一个月以后钱就用完了。我说你们不就八个人怎么钱就用完了，给了你好几百万。但他们说，光买机器就用了三百万。 第三个就是：AI 需要数据。识别一张图片，最少需要几十万张样本数据，甚至几百上千万。谁给你弄数据？所以做人工智能投资有一个非常头大的地方：一下顶尖的人就投完了。 过去这两年我们就到处去扫，从最厉害的团队出来的无人驾驶公司投了两个，没投两个。然后就再也找不到团队了，因为有资格的人就那么多。 我们做互联网金融，扫完了以后大概投了三个，然后可能有一两个错过了机会，一两个没投，然后就没有了。 因为AI科学家就那么多，能够创业把事情打造到一个地步的就那么多。 AI 的现状是“僧多粥少”。大家都去抢那几棵树，已经把树拱到天价了。我觉得 AI 这片土地需要“施肥”，而不是抢那些非常少的农作物。 所以我们成立了“人工智能工程院”。我们可能花几千万把机器搞定，然后帮助十家二十家创业公司；我们从各种渠道拿到数据，AI 科学家可以做试验；我们试着让更多有潜力的 AI 科学家，能够考虑来创业这条路，帮他们把可能 95% 的失败率降低到 40%，这样的话我们就能够产生自己的价值。 当然，投靠创新工场，我们帮你解决所有问题，也要求自己的回报。本来可能五百万占股 10%，现在也许给我们 15%，我们觉得这样的话也就足够了。以后如果可以打造出独角兽，我们是有很多回报的。 这个工程院在得到金钱回报的话，至少得花掉两亿元人民币。但如果是我们施肥的，想必相比那些“农作物”会喜欢我们。 两三年之后，AI 会像 Android 一样普及长期来说，真的是永远只能由 AI 科学家来创业吗？其实不一定。 任何技术都有一条发展路径，一个很好的例子就是 Android。当年我们跟 CSDN 的蒋涛一起做移动开发者的大会。第一次大会的时候，我问现场观众：有多少人看好Android？大概有5个手。我问有多少人看好 Symbian？五百个手举起来。 但当时我们坚决相信 Android 才是未来的道路。只是因为平台不够。现在大学里面的 Android、 iOS 培训课程非常普及。你如果是一个计算机的学生，你自己自学也好，去做培训课也好，几个月之内你就可以开始做 Android 了。 AI 也是这样的状态。 要多久时间呢？我们大胆的假设两三年吧。这两三年里，我们工程院孵化科学家会是一个非常独特而有价值的方法。三年以后平台出来了，很多聪明的大学生可以自学。平台、工具越来越多，AI 会变得越来越容易用了。 以后年轻人来创业，我觉得可能比现在的科学家创业更能成功。因为 创业需要有动机，有狼性，愿意拼命。本来就要把自己名声，身家全部赌进去的。 有资格的人六个月就能成为 AI 工程师，有资格的人是指：数学天才 一位老教授，用三十年的功力弄出来一个新算法。这种可能性是存在的。但真正能发力的其实还是年轻人。很多年轻人只是苦于没有一个平台。我告诉大家一个秘密。 如果你是一个有资格的年轻人，我们只需要六个月就可以把你培训成为一个 AI 工程师。绝对不是你想象的二十年，三十年。这不像一个材料科学家、火箭专家——这种专家真的是需要三十年的功力。 那么，什么是有资格呢？ 很不幸，不是所有的人。“有资格”简单来说就是：数学天才。 当然，这其中也涵盖了 统计、自动化、计算机。中国人口这么多，光是数学天才我们应该一年都要产生个几十万了。 假设有十万个数学小天才，那里面对AI有兴趣的可能就会有五万。（因为中国学生是特别愿意去追最热门的东西，最热门的定义是什么呢？很酷，能赚很多钱的。）里面有两万个接触到了一些培训平台，花了六个月去做，这两万人里可能又有两千个是适合的领军人物。比如说他是AI领域的雷军、傅盛等等这些人。这两千人最终才是我们最好的投资对象。我们的工作就是让这些人出现。所以短期我们是抓着科学家来，再过三四年我们要把这些年轻人都培训出来。让他们认知这是创业最好的时机。所以这秘密就是：我们要挖掘中国所有的数学小天才，然后引导他们进入AI创业。 AI 接管人类？我们的问题是科幻小说看多了 我们应该怎样看待 AI 呢？ 有人看到阿法狗战胜了李世石，瞬间就联想到了 AI 要接管人类。实际上，这其中还差十万八千里。 AI里最难的问题之一，是跨领域的自然语言理解。要做到这一点，需要上下文的理解，需要跨领域的知识，还需要人类的“Common Sense”。 例如我突然和你说：“中午还好没吃汉堡，麦当劳不好吃。”这句话所有人都明白什么意思，但是机器很难读懂。它可以把每一个字都识别正确，但仍然无法“理解”。 再例如：熨斗打开的不能去摸，沾了水的手不能碰电。这些东西不用讲我们都知道。但是计算机怎么会知道这些事情呢？你怎么去教一个计算机跨领域的知识？你怎么教会它七情六欲？你怎么教会它什么是美？什么是爱？什么是宗教？什么是信仰？这些东西差得还非常远。 揣测可能发生的事情跟确信一定会发生的事情，这两个还是要分辨得很清楚的。任何刚才讲的 AI 不能做的事情，我们都无法揣测多久会被突破。有人说五年，有人说五十年，也有人说永远不会。 我觉得我们真正应该讨论的事情是 怎么用AI来创造价值，怎么让人类能够没有饥饿和寒冷，让每一个人都能有尊严的活着。 例如，未来很多蓝领和白领的工作都会被取代，也包括了记者。当然有些深度文章机器可能五十年也写的出来。但是如果你从网上攒一些资料，例如科大讯飞发布财报，产品多了30%，分析师说股票怎么样，未来人工智能被看好什么的，这种东西机器已经在写了。 当机器能够把简单的工作取代的时候，当经过五秒以内思考的事情人都不用做的时候，当这么多人将可能失业的时候，这些失业者应该怎么做？我们如何去重新训练他们？孩子的教育是什么样的？怎么让人类继续的去寻找应该做的事情？也许造物者是不希望我们做这种无聊的工作，让我们都做有意义的事情，所以才用机器取代了我们。 刚才讲的这些事情都是十年内会发生的。 当然未来也可能是 AI 养活了全世界，我们也许都成为 AI 的宠物，在家里戴着 VR 头盔玩游戏。机器会不会有自我意识，会不会取代人，会不会成为物种，虽然未必不可能，但这些是未知的。 很不幸的是：我们科幻小说看多了。 “AI 新物种”“取代”“奴役”，这些当然可以被想象，但有更多必然的有意思的问题，更值得我们去思考。 AI “低处的果实”还没摘完 人工智能有很多学派。符号学派、连接学派等等。但是除了深度学习以外的方法，经过多年被验证，是不太有发展的。 模拟人的分析方法，希望把它变成一个规律和专家系统，过去五十年已经证明了这个思路是不行的。当然也许某一天会有一个突破，但是直到那一天为止应该是不行的。 就我自己的背景来说。在1988年，我就开始做语音识别。当年第一套系统就是用完全机器学习的方法来做的非特定人的语音识别。 现在看起来这是一个特别小的方法：世界上有一个人能够从纸上读出语音，我的导师就要把这套方法变成一套专家系统。当年就让我很坚定地认为：机器的构造跟人脑，跟人的思维方式其实是不一样的。我们硬要把A放到B其实是很困难的，就像我们不能逼自己去变成一个深度学习者，去分析事情——我们脑子思维就不是那样的，是不自然的。 用脑科学的方法制造人工智能，是一个未知的领域。未知的东西有它的魅力，你要做研究就要做未知，你要有了突破那就是创新。在学术领域你做每一件事情的衡量标准是：我要做别人从来没做过的东西。我们可以假设脑科学跟未来的 AI 是相关的，我们可以去证明这是或不是。但是从投资的角度来讲，押注的风险就太大了。 当年深度学习也是因为数据的不足，碰到了一些瓶颈。但近年我们看到有好几个特别大的变化： 第一个就是特别大量的数据在某些领域开始产生，而且我觉得我们目前还没有被用完。第二个就是 GPU 的使用让我们能够更高效地、非常快速地做深度学习。现在我觉得，所谓的深度学习的果实还远远没有被摘完。人工智能的应用来说百花齐放，一个一个大果实就在你面前。在这种情况下，你还要去种花，何必呢？ 我们把 GPU 和海量数据在全世界扫一遍，应该还够我们 VC 界吃个五年，所以从投资的角度这是非常清晰的事情。 再往下走，我觉得我们 AI 肯定不可以是只有深度学习。例如现在还有增强学习的方法，也在被探索。AlphaGo 里面也不是只存在一个方法。所以我觉得学术界其实应该开始帮助和探索更多的可能性，当我们把这两年的粮食吃完之后也许还有更好的机会。 我没有 AI 宗教信仰 当然未来 AI 也可能没有进一步的突破了。 如果没有的话，那就说明 AI 的黄金时代过去了。下面就是物联网或者其他什么的。作为投资机构，我们并没有一种 AI 宗教信仰，我们还是要把控灵活度。 就像移动互联网时代，当时我们应该是在业界最高调的移动互联网 VC。但是随后我们根据情况做了调整。 如果学术界跟产业界有一个合理的分工，我对未来五年投资界和产生价值非常乐观，对于所谓AI的泡沫我认为不会发生。当然有个别的案例会有泡沫，但是我认为能吃的粮食实在是太多了。 学术跟产业它的分工大概是这样： 一方面是一个很天然有机的分工；另外一方面又是有一点羡慕嫉妒恨在里面。一般来说学术界是看不起工业界的，但是在某一个时刻突然工业界的一个技术成熟了，在这个技术上学术界就做不到工业界的成就了。于是学术界就被逼的去做新的东西。例如：现在再去做人脸识别，学术界就已经打不过工业界了。所以在人工智能领域，很少见到一个老教授一生只研究一个命题。 AlphaGo 本身没有商业价值 AI 会带给我们什么价值呢？ 我想先说说 AlphaGo。之所以 AlphaGo 如此引人注目，很大程度上是因为我们这样的专家把它讲得太悬。 之前我觉得围棋比国际象棋至少难十年或十五年，但后来结果证明我是过于悲观了。我过于悲观其实有很多理由。我当时认为围棋要比国际象棋难了一个天文数字，但天文数字也是数字。 在AlphaGo之前最好的人工智能棋手达到了业余五段。而 AlphaGo 最新的 Master 和职业九段之间的差距，大致相当于职业九段和业余九段的差距。这确实是很大的跳跃。 那为什么会有这样的现象呢？也就是说，为什么下围棋的人工智能进步幅度这么大呢？ 其实有一个非常现实的理由，就是想挣钱的人不会去做围棋。你看 AlphaGo 的专家队伍也没那么了不起，就是二十个很厉害的机器学习专家。在谷歌里面可能有两千个这样的人，在微软里有一千个这样的人。原因在于微软和谷歌过去没有想拿两千个专家的力量打败围棋手，他们的更多时间都在做语音识别、人脸识别这些有价值的事情。 在这个没有价值的事情上 ，能用二十个专家就不错了。 金融、医疗是有商业价值的 AI有商业价值的 AI，影响就巨大了。 AI 在数据量大的领域最易应用。这些数据最好被准确标注，自动化标注。 AI 在无摩擦的领域最容易应用。一个领域里面如果有制造、测试、物流这类摩擦，那就麻烦了。无摩擦的领域是什么？医疗是无摩擦，金融是无摩擦。 AI 在挣钱最多的领域容易应用。毫无疑问，最挣钱的又是金融。所以 金融毫无疑问会是AI最快征服的领域。因为你的算法可以很快就变成钱。 医疗也是一个特别巨大的领域。而且医疗相对传统，能产生增值的机会很大。而且它不是基于大数据的。最好的医生是什么，就是他自己是一个深度学习的机器，根据他的经验做了好多好多次。 假设他判断了五千个病人，判对了很多，判错了一些，下面他的判断就会非常精准了。但一个好医生可能最多也就判断过五千个病人，但我们的数据是五千万的病人的级别。所以 医疗超越医生应该是一个非常必然的，全球性的趋势。 但是AI 医疗需要突破一些隐私问题，可能会有一些挑战。 机器人世界的大门，要靠智能驾驶来敲开 除了大数据应用之外，还有就是科幻型的应用了。包括机器人，无人驾驶这类领域。 目前看得非常清晰，而且全球达到共识就是无人驾驶。有时候你要做一个科幻型的东西，需要万事俱备，天时地利人和才能推动。但是一旦开始动它就不得了。就像以前我们的移动互联网改造了整个产业链，以前的 SP、诺基亚之类。这样的产业变革来临，基本旧的企业全部会死掉，换成一批新的。 出行就会是下一个产业。我们非常幸运，目前有了共享经济，还有电动车。这两个领域已经在推动了，可推动的过程中遇到了一些阻力。 现在无人驾驶一来，就会改变世界的经济格局。我相信，世界经济10%是和出行和运输相关的。虽然真正的无人驾驶到来可能还要十年，但是有些其他的事情可以更快地被做好。 比如景区游览车，比如运输卡车。你可能会问，如果自动驾驶技术暂时还不成熟，卡车下了高速公路怎么办？没问题，我们把仓库全停在高速公路旁边不就是了。 万一卡车看错路怎么办？那我们就重新修路，在路上放很多标志和传感器，这也不是很困难。 所以我们未来三五年我们就可以打很多补丁，让无人驾驶能够在很多有限的环境之下被使用，所以千万不要认为自动驾驶还有十年才来，现在跟我们无关。 我们很少看到有一个产业从头到尾全部都“投降”了。 哪一家汽车公司还敢不说无人驾驶？每一家都在拼命想办法去解决，整个产业力量都进来了。资本的力量在全球都在投资无人驾驶的公司。最新最酷的创业者，很多都在无人驾驶领域创业。这是一个不可逆的必然趋势，会对各个行业做全新的布局。 例如，所有的司机该怎么办？没有车会停下来，停车场该怎么办？以后的汽车该什么样子？道路要提供什么传感器？哪些领域是最快能够赚最多钱的？ 这些我们其实都不必太担心，因为那些最有商业嗅觉的人和最有科技能力的人已经在每天在推敲这个事情。他们，或者说我们一定会找到解决方案。 当一辆无人驾驶汽车可以在路上运行的时候，汽车之间就可以对话了。例如前面发生了车祸，我的车要做出避让。今天我的主人着急上班，你给我让路，我给你两毛钱行不行？ 在这种情况下机器人就变得可行了。与其期待家里的机器人用陪小孩玩的方式进化，还不如期待无人驾驶汽车促进机器人的进化。 更多人工智能相关内容，请关注雷锋网。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Business","slug":"Business","permalink":"http://ipcreator.me/tags/Business/"}]},{"title":"谷歌发布全新轻型机器学习架构：可直接载于设备端的AI系统","date":"2017-02-19T15:59:56.000Z","path":"2017/02/19/SmartAI/ProductAI/ai-on-terminal-of-google/","text":"作者：雷锋网 亚萌 雷锋网(公众号：雷锋网)消息，谷歌近日发布了全新应用于可穿戴设备的Android Wear 2.0系统和相关设备，而这一批系统和设备，将具有一项新技能：运行谷歌全新的“设备端”机器学习技术。下面是对该项技术的介绍，原文载于Googleblog，由雷锋网编译整理。 设备端的机器智能为了打造会话理解和图像识别领域领先的技术，我们通常将多种先进的机器学习技术（比如深度神经网络和基于图的机器学习）结合起来使用。然而，以上提到的机器学习系统往往需要大量的计算能力和存储空间。可是，如果想 要在不论是否连接到的云端的情况下，个人手机、智能手表和IoT设备都能运行机器智能，又要怎么办呢？ 昨天，我们发布了Android Wear 2.0系统和全新的可穿戴设备，这些设备将会运行 谷歌首个完全“设备端”（on-device）的机器学习技术，首先用于“智能回复”（Smart Reply）这一功能上。这个“设备端”机器学习系统由谷歌Expander研发团队开发，在不需要接入云端的情况下，将“智能回复”功能应用于各第三方的讯息App上。所以现在，你若在手表上收到了一条信息，轻敲回复选项就可以了。 这个系统的研发从去年开始，当时我们的团队正在为Allo和Inbox里的会话理解开发相应的机器学习系统。 Android Wear团队找到我们，并询问将“智能回复”直接应用在智能设备上的可能性。因为智能设备的计算和存储量都是有限的，我们很快就判断这种移植根本不可能。 但我们的产品经理Patrick McGregor意识到这对于Expander团队来说是个独特的挑战和机会，可以从头开始 设计一个全新的、轻型机器学习架构，这不仅让“智能回复”应用于Android Wear系统，还应用于其它众多设备端的移动应用程序。于是，我们与Android Wear团队的Tom Rudick、Nathan Beach等同事一起，开始着手建立这个全新的系统。 与“投影”一起进行学习建立轻型会话理解模型的一个简单策略，就是在设备上 创建一个小型的包含一般规则的字典（输入—&gt;回复映射），并且在推理阶段，使用一个朴素的查找策略。 这个可以执行简单的预测任务，包括使用一些特征进行分类 （比如对文本里的情感进行二元分类，例如“我爱这部电影”传递出一种积极的情感，而“演员的表演很糟糕”则传达一种消极情感）。但是，它的规模并没有大到去执行包含丰富词汇和语言变化的复杂自然语言任务。 另一方面，机器学习模型，比如RNN（如LSTM），结合图学习（graph learning），已经被证明是用于自然语言理解的复杂序列学习里极强悍的工具，包括“智能回复”。 然而，为了适应设备存储空间而将这么丰富的模型进行压缩，并在低计算成本的情况下产生鲁棒的预测（快速按需），这是非常具有挑战性的。在我们的早期实验里，受到限制的模型仅仅预测一小批回复语句，我们还使用其他包括量化（quantization）、字母级别模型等技术，并不能产生有用的结果。 所以，我们为设备端机器学习系统建立了一种不同的解决方法，我们一开始使用了一个快速、有效的机制，将相似的传入讯息聚集起来，并将他们投影到相似的（附近的）位向量表征里。虽然执行这个投影步骤有几种方法，比如使用单词嵌入（word embeddings）或者编码网络（encoder networks），我们应用了局部敏感哈希算法（locality sensitive hashing ，LSH) 的修改版本来降低维度，把数百万个独特的单词转换为短小的、固定长度的位序列。 这允许我们为一条传入讯息的投影进行非常 快速、即时（on-the-fly） 的计算，占用很少的内存，由于我们并不需要存储传入讯息、单词嵌入甚至是用来训练的整个模型。 投影步骤：相似讯息组合在一起，投射到邻近向量里。比如，“hey, how’s it going?”与 “How’s it going buddy?” 这两条讯息内容是相似的，或许会投射到同样的向量 11100011。另一条相似的讯息“Howdy, everything going well?”被映射到一个附近的向量11100110，与前两条相差2位。 接下来，使用我们的 半监督图学习框架 ，我们的系统把传入讯息和投影结合在一起，共同训练一个“讯息投入模型”，学习预测可能的回复语句。图学习框架能够训练一个鲁棒的模型，通过从各种资源里找出的语义关系——讯息/回复互动、单词/短语相似性、语义集群信息——学习有用的投影操作，来映射良好的回复语句预测。 学习步骤：（顶部）的讯息、投射和相应回复语句一起，在一个机器学习框架里，同步学习一个“讯息投射模型”。（底部）讯息投射模型学习，将回复语句与相应传入讯息的投射联系在一起。比如，模型投射两种不同的讯息“Howdy, everything going well?”和“How’s it going buddy?”投射到附近的位向量里，并且学习着将其映射成相关的回复语句（底部左图）。 值得注意的是，就像我们前面提到的，尽管“讯息投影模型”用复杂的机器学习架构和云计算进行训练，但是模型本身在设备上存在和运行。 设备上的App可以传递用户的传入讯息，并从设备端模型上接受回复语句预测选项，而不需要离开设备去获得数据。这个模型也可以适应用户书写风格和个人偏好，从而提供一种个性化的体验。 推理步骤：模型将学习好的映射应用于一条传入讯息（或讯息序列）里，并且推荐相关的多条回复语句。推理过程在设备上运行，使得模型适应用户数据和个性化书写风格。 为了得到开箱即用的设备端系统，我们必须要进行一些额外的改进，比如优化设备上的计算速度、从模型中生成丰富多样的回复语句等等。不久之后，我们将进行一些科学发表，介绍更多设备端机器学习系统工作的细节。 与你的手腕交谈 当我们踏上从无到有打造这项技术的旅程时，一开始我们并不确定，这些模型的预测结果质量是否合格。我们非常惊讶地发现，它能在非常有限的计算能力和存储资源的情况下，在安卓的可穿戴设备上工作良好，对此我们非常兴奋。我们期待继续改善模型，为用户提供共更加愉悦的会话体验，我们将会提升这个设备端的机器学习平台，接下来的几个月里将其应用于新的领域。 现在，你可以在你的Google手表或任何运行Android Wear 2.0系统的手表上使用这一功能。这一功能已经可以在Google Hangouts、Google Messenger和众多第三方App上使用。我们也 会为第三方穿戴设备App的开发者提供API接口。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"智能手机 + 机器学习 = 个人终端的未来","date":"2017-02-19T15:58:06.000Z","path":"2017/02/19/SmartAI/ProductAI/the-future-of-personal-terminal/","text":"作者：陈杨英杰 今天是 iPhone 7 发布的日子，无论你是不是果粉，无论是主动关注还是被动接受，所有人的信息焦点只有一个，那就是苹果。作为技术创新的长期领导者，苹果已经一次又一次给我们带来各种意想不到的新体验，今天的 iPhone 7 更是如此。那么，就让我们从小小的智能手机开始聊一聊机器学习将如何改变个人终端的未来。 尽管新的产品、新的功能层出不穷，但人们不禁好奇，究竟是什么因素在将不可能变为可能。 答案大概可以归结为四个字：“机器学习”。 iPhone 7 发布会 无论我们是否真的意识到，机器学习已经在我们的日常生活中应用很长时间了。事实上，我们没有注意到它的存在反而意味着这个技术非常有效，因为每天当着用户面处理学习如此大量的实时数据却不被察觉，显然这种方式是可以令人接受的。然而，最近这个词频频出现在各种商业和大众媒体上，在人工智能的专业技术人员和消费者中间引发了大量深入的讨论。 苹果公司早就在人工智能领域奠定了坚实的基础。在史蒂文·李维（Steven Levi）发表在 iBrain 上的文章中，其深入剖析了苹果错综复杂的机器学习技术。尽管很大程度上 Siri 只是苹果在机器学习方面的“门面”，但毋庸置疑的是，苹果在这方面的研发并不止于此，机器学习技术已经被应用到苹果的各类设备和应用中。例如，滑动屏幕会出现你想要打开的应用名单，或是指出你预订的酒店在地图的位置。 这个直接面向消费者的人工智能应用，在科技行业树立了一个标杆，不仅成功提升了品牌价值，也让消费者对数字体验有了更高的期待。 Siri 尽管 Siri 是一个非常受欢迎的人工智能应用，但她也不是没有竞争对手。虚拟助手 Cortana（微软小娜）的出现加剧了科技公司之间的竞争，现在鹿死谁手还未可知。这给苹果带来了巨大的压力，苹果很快意识到了问题，并开始不断采取措施加强他们的机器学习部门，目的就是为了在这一领域保持一个领先地位，尤其是要赶在新产品发布之前。最近的例子就是苹果收购了专注于机器学习的人工智能公司 Turi 。此外，苹果公司还宣布，除了已经搭载了 Siri 功能的苹果手机，他们还准备将 Siri 背后的深度学习技术集成到苹果的笔记本电脑、手表和电视上。 iWatch 更深远的影响在于，这些努力是为了把机器学习运用到苹果的整个产品链中，此举标志着苹果的品牌和零售将开始一种全方位的个性化体验服务。用户已经开始期待基于深度学习其实时行为反应的高级定制化内容。苹果公司已经意识了只有机器学习才能满足如此大规模的用户需求。苹果通过增强型机器学习算法提高内容准确性和时效性，为用户提供了一对一的个性化体验服务，这些最终将转化为公司的品牌忠诚度，并为公司增加营收。 消费者对个性化体验服务的期望只会不断增加，而苹果公司已经明确表示他们正在想方设法满足这些需求。这也意味着面对竞争，需要不断努力加强自身的深度学习技术，才能跟上发展。这不仅适用于苹果的竞争对手，也对其合作伙伴提出了更高要求。 通过把机器学习集成到苹果的产品中，品牌和零售商就能轻松地为消费者提供他们一直期待的购物体验。 那些不敢冒险的人终将会被时代所淘汰。 GPU 芯片 具体来说，对于计算机中的神经网络和机器学习中的其他方法的研究自 70 年代就开始了。深度学习是机器学习的一部分，通过算法对数据进行关联和分类。深度学习系统通常需要使用复杂的神经网络和大量的计算资源。GPU芯片是一种专门用于图像计算的芯片，在带有屏幕的个人终端设备上十分常见，神经网络大都在GPU上运行。 麻省理工学院的研究团队研发出了一款名为 Eyeriss 的芯片，将能耗减少到了 GPU 平均水平的 1/10。因此，这为智能手机上的应用打开了新的可能性，可以直接在移动设备上执行强大的人工智能算法，而不需要将数据上传到互联网进行云计算。 这款专为深度学习而优化的计算机芯片，能够让人工智能变得更为流行。 MIT 研发的这款168核的芯片能够识别人脸、其他物体，甚至是声音。该芯片可适用于智能手机、自动驾驶汽车、机器人、无人机和其他设备。普通 GPU 芯片一般是很多处理单元共享一个内存条，而Eyeriss芯片每个处理单元都有自己的内存，而且它可以在向处理单元发送数据前对数据进行压缩。Eyeriss的每个处理单元都可以直接与相邻的处理单元进行交流，如果需要共享数据，不需要将数据传送到主内存。 配备这种新芯片后，未来的智能手机不仅能够更好地执行日常任务，还可以进行原本需要外部资源投入的人工智能和深度学习任务。而 一个内置 Eyeriss 芯片的智能手机可以执行更多的基本任务，诸如追踪用户的偏好、时间表和使用模式，能更好地优化移动体验，这意味着一种截然不同的绝佳用户体验。 AI助理（配图：《钢铁侠》） 我们对普通用户每天的 应用场景进行归类 后，搭载了 AI 助理的智能手机可以 清楚的判断用户的各种使用情况，是在应用商店下载了游戏，还是对已安装的应用进行更新，都一目了然。芯片会查看一些手机信息，比如应用程序的大小，代码特点，用户使用量的统计数据，线上意见等，并向用户 推荐一些可能感兴趣的内容。例如，某个用户在市中心闲逛时突然想找去酒吧玩儿，他们也许对机载 AI 助理说：“推荐一个我没去过的好酒吧。”此时，AI 就会开始查询银行对账单，判断用户多长时间去一次酒吧，每次平均花费多少钱，然后找到评论这些酒吧的关键词，诸如“氛围好”或这“啤酒好”等，最后找到一个附近的新酒吧推荐给用户。目前，所有这些计算都是由异地的服务器统一处理后传回用户的手机，很难将其他数据和应用整合到设备上，并有效管理用户数据。 机载 AI 助理将彻底改变个人终端计算设备的发展，首当其冲的就是智能手机。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Smart Phone","slug":"Smart-Phone","permalink":"http://ipcreator.me/tags/Smart-Phone/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"深度学习框架太抽象？其实不外乎这五大核心组件","date":"2017-02-19T15:57:20.000Z","path":"2017/02/19/SmartAI/ProgramAI/Tensorflow/core-components-from-deep-learning-framework/","text":"本文作者：恒亮 许多初学者觉得深度学习框架抽象，虽然调用了几个函数/方法，计算了几个数学难题，但始终不能理解这些框架的全貌。为了更好地认识深度学习框架，也为了给一些想要自己亲手搭建深度学习框架的朋友提供一些基础性的指导，日前来自苏黎世联邦理工学院计算机科学系的硕士研究生Gokula Krishnan Santhanam在博客上撰文，概括了大部分深度学习框架都会包含的五大核心组件，为我们详细剖析了深度学习框架一般性的内部组织结构。以下由雷锋网(公众号：雷锋网)编译。 Gokula Krishnan Santhanam认为，大部分深度学习框架都包含以下五个核心组件：&gt; 张量（Tensor） 基于张量的各种操作 计算图（Computation Graph） 自动微分（Automatic Differentiation）工具 BLAS、cuBLAS、cuDNN等拓展包 1. 张量（Tensor） 张量是所有深度学习框架中最核心的组件，因为后续的所有运算和优化算法都是基于张量进行的。几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将 标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。 举例来说，我们可以将任意一张RGB彩色图片表示成一个三阶张量（三个维度分别是图片的高度、宽度和色彩数据）。如下图所示是一张普通的水果图片，按照RGB三原色表示，其可以拆分为三张红色、绿色和蓝色的灰度图片，如果将这种表示方法用张量的形式写出来，就是图中最下方的那张表格。 图中只显示了前5行、320列的数据，每个方格代表一个像素点，其中的数据[1.0, 1.0, 1.0]即为颜色。假设用[1.0, 0, 0]表示红色，[0, 1.0, 0]表示绿色，[0, 0, 1.0]表示蓝色，那么如图所示，前面5行的数据则全是白色。 将这一定义进行扩展，我们也可以用四阶张量表示一个包含多张图片的数据集，其中的四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。 将各种各样的数据抽象成张量表示，然后再输入神经网络模型进行后续处理是一种非常必要且高效的策略。因为如果没有这一步骤，我们就需要根据各种不同类型的数据组织形式定义各种不同类型的数据操作，这会浪费大量的开发者精力。更关键的是，当数据处理完成后，我们还可以方便地将张量再转换回想要的格式。例如Python NumPy包中numpy.imread和numpy.imsave两个方法，分别用来将图片转换成张量对象（即代码中的Tensor对象），和将张量再转换成图片保存起来。 2. 基于张量的各种操作 有了张量对象之后，下面一步就是一系列针对这一对象的数学运算和处理过程。 其实，整个神经网络都可以简单视为为了达到某种目的，针对输入张量进行的一系列操作过程。而所谓的“学习”就是不断纠正神经网络的实际输出结果和预期结果之间误差的过程。这里的一系列操作包含的范围很宽，可以是简单的矩阵乘法，也可以是卷积、池化和LSTM等稍复杂的运算。而且各框架支持的张量操作通常也不尽相同，详细情况可以查看其官方文档（如下为NumPy、Theano和TensorFlow的说明文档）。 NumPy：http://www.scipy-lectures.org/intro/numpy/operations.html Theano：http://deeplearning.net/software/theano/library/tensor/basic.html TensorFlow：https://www.tensorflow.org/api_docs/python/math_ops/ 需要指出的是，大部分的张量操作都是基于类实现的（而且是抽象类），而并不是函数（这一点可能要归功于 大部分的深度学习框架都是用面向对象的编程语言实现的）。这种实现思路一方面允许开发者将各种类似的操作汇总在一起，方便组织管理。另一方面也保证了整个代码的复用性、扩展性和对外接口的统一。总体上让整个框架更灵活和易于扩展，为将来的发展预留了空间。 3. 计算图（Computation Graph） 有了张量和基于张量的各种操作之后，下一步就是将各种操作整合起来，输出我们需要的结果。 但不幸的是，随着操作种类和数量的增多，有可能引发各种意想不到的问题，包括多个操作之间应该并行还是顺次执行，如何协同各种不同的底层设备，以及如何避免各种类型的冗余操作等等。这些问题有可能拉低整个深度学习网络的运行效率或者引入不必要的Bug，而计算图正是为解决这一问题产生的。 据雷锋网了解，计算图首次被引入人工智能领域是在2009年的论文《Learning Deep Architectures for AI》。当时的图片如下所示，作者用不同的占位符（*，+，sin）构成操作结点，以字母x、a、b构成变量结点，再以有向线段将这些结点连接起来，组成一个表征运算逻辑关系的清晰明了的“图”型数据结构，这就是最初的计算图。 后来随着技术的不断演进，加上脚本语言和低级语言各自不同的特点（概括地说，脚本语言建模方便但执行缓慢，低级语言则正好相反），因此业界逐渐形成了这样的一种开发框架： 前端用Python等脚本语言建模，后端用C++等低级语言执行（这里低级是就应用层而言），以此综合了两者的优点。 可以看到，这种开发框架大大降低了传统框架做跨设备计算时的代码耦合度，也避免了每次后端变动都需要修改前端的维护开销。而这里，在前端和后端之间起到关键耦合作用的就是计算图。 将计算图作为前后端之间的中间表示（Intermediate Representations）可以带来良好的交互性，开发者可以将Tensor对象作为数据结构，函数/方法作为操作类型，将特定的操作类型应用于特定的数据结构，从而定义出类似MATLAB的强大建模语言。 需要注意的是，通常情况下开发者不会将用于中间表示得到的计算图直接用于模型构造，因为这样的计算图通常包含了大量的冗余求解目标，也没有提取共享变量，因而通常都会经过依赖性剪枝、符号融合、内存共享等方法对计算图进行优化。 目前，各个框架对于计算图的实现机制和侧重点各不相同。例如Theano和MXNet都是以隐式处理的方式在编译中由表达式向计算图过渡。而Caffe则比较直接，可以创建一个Graph对象，然后以类似Graph.Operator(xxx)的方式显示调用。 因为计算图的引入，开发者得以从宏观上俯瞰整个神经网络的内部结构，就好像编译器可以从整个代码的角度决定如何分配寄存器那样，计算图也可以从宏观上决定代码运行时的GPU内存分配，以及分布式环境中不同底层设备间的相互协作方式。 除此之外，现在也有许多深度学习框架将计算图应用于模型调试，可以实时输出当前某一操作类型的文本描述。 4. 自动微分（Automatic Differentiation）工具 计算图带来的另一个好处是让模型训练阶段的梯度计算变得模块化且更为便捷，也就是自动微分法。 正如前面提到的，因为我们可以将神经网络视为由许多非线性过程组成的一个复杂的函数体，而计算图则以模块化的方式完整表征了这一函数体的内部逻辑关系，因此微分这一复杂函数体，即求取模型梯度的方法就变成了在计算图中简单地从输入到输出进行一次完整遍历的过程。与自动微分对应，业内更传统的做法是符号微分。 符号微分即常见的求导分析。针对一些非线性过程（如修正线性单元ReLU）或者大规模的问题，使用符号微分法的成本往往非常高昂，有时甚至不可行（即不可微）。因此，以上述迭代式的自动微分法求解模型梯度已经被广泛采用。并且由于自动微分可以成功应对一些符号微分不适用的场景，目前许多计算图程序包（例如Computation Graph Toolkit）都已经预先实现了自动微分。 另外，由于每个节点处的导数只能相对于其相邻节点计算，因此实现了自动微分的模块一般都可以直接加入任意的操作类中，当然也可以被上层的微分大模块直接调用。 5. BLAS、cuBLAS、cuDNN等拓展包 现在，通过上述所有模块，我们已经可以搭建一个全功能的深度学习框架：将待处理数据转换为张量，针对张量施加各种需要的操作，通过自动微分对模型展开训练，然后得到输出结果开始测试。这时还缺什么呢？答案是运算效率。 由于此前的大部分实现都是基于高级语言的（如Java、Python、Lua等），而即使是执行最简单的操作，高级语言也会比低级语言消耗更多的CPU周期，更何况是结构复杂的深度神经网络，因此运算缓慢就成了高级语言的一个天然的缺陷。 目前针对这一问题有两种解决方案。 第一种方法是模拟传统的编译器。就好像传统编译器会把高级语言编译成特定平台的汇编语言实现高效运行一样，这种方法将高级语言转换为C语言，然后在C语言基础上编译、执行。为了实现这种转换，每一种张量操作的实现代码都会预先加入C语言的转换部分，然后由编译器在编译阶段将这些由C语言实现的张量操作综合在一起。目前pyCUDA和Cython等编译器都已经实现了这一功能。 第二种方法就是前文提到的，利用脚本语言实现前端建模，用低级语言如C++实现后端运行，这意味着高级语言和低级语言之间的交互都发生在框架内部，因此每次的后端变动都不需要修改前端，也不需要完整编译（只需要通过修改编译参数进行部分编译），因此整体速度也就更快。 除此之外，由于低级语言的最优化编程难度很高，而且大部分的基础操作其实也都有公开的最优解决方案，因此另一个显著的加速手段就是利用现成的扩展包。例如最初用Fortran实现的BLAS（基础线性代数子程序），就是一个非常优秀的基本矩阵（张量）运算库，此外还有英特尔的MKL（Math Kernel Library）等，开发者可以根据个人喜好灵活选择。 值得一提的是，一般的BLAS库只是针对普通的CPU场景进行了优化，但目前大部分的深度学习模型都已经开始采用并行GPU的运算模式，因此 利用诸如NVIDIA推出的针对GPU优化的cuBLAS和cuDNN等更据针对性的库可能是更好的选择。 运算速度对于深度学习框架来说至关重要，例如同样训练一个神经网络，不加速需要4天的时间，加速的话可能只要4小时。在快速发展的人工智能领域，特别是对那些成立不久的人工智能初创公司而言，这种差别可能就会决定谁是先驱者，而谁是追随者。 总结 原文作者在文末指出：为了向开发者提供尽量简单的接口，大部分深度学习框架通常都会将普通的概念抽象化，这可能是造成许多用户感知不到上述五点核心组件的重要原因。 而这也正是作者写本文的初衷：他希望开发者能够通过了解不同框架之间的一些相似特性，更好地认识和使用一个深度学习框架。另一方面，对于那些不仅对学会使用深度学习框架感兴趣，还打算亲手搭建一个深度框架的朋友，作者认为了解各框架的内部组成和一些共性的特征也是迈向成功的重要一步。他真诚地相信，一个优秀的工程师不仅应该“知其然”，更应该“知其所以然”。 来源：medium，雷锋网编译 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"技术大牛带你走向机器学习“正道”","date":"2017-02-19T15:57:06.000Z","path":"2017/02/19/SmartAI/ProgramAI/Concepts/right-way-of-master-machine-learning/","text":"作者：雷锋网 亚峰 导语：现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉。 雷锋网按：“算法”这两字在人工智能圈已然成为“高大上”的代名词，由于不少在校生和职场新人对它的过度迷恋，多名 AI 资深人士均对这一现象表示担忧。李开复曾这样说到： 现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉，更缺乏解决实际问题所必须的数据资源。随着开源框架层出不穷，人工智能产品化和商业化进程不断加速，使得算法的门槛逐渐降低，但对工程的要求不断在提高。这种情况下，实际应用和工程能力基础扎实的技术人才变得异常抢手。 其实 AI 新人们在进入职场后也愈发意识到这个问题，那他们该如何提升自己的实战能力？ 雷锋网特邀王刚为大家讲述机器学习的实战与应用，王刚根据工程、产品、业务等多个维度帮大家梳理如何系统地去学习机器学习。 嘉宾介绍： 王刚，前乐视大数据总监，现任某电商平台大数据总监。10 年大数据领域工作经验，具有 Hadoop 和 Spark 生态相关技术的实际应用经验。目前专注于机器学习，搜索和推荐系统的设计和开发。 以下为王刚所撰写的正文： 机器学习对很多初学者来说，最大的学习困难和障碍就是模型、算法、“眼花缭乱”的数学公式所带来的抽象感，无法有效的建立起直觉上的理解。所以本文的目的是尝试给初学者具体的学习方式建议，以帮助初学者打通机器学习的任督二脉，然后通过不断的学习和实践，使得自己在机器学习领域的专业能力持续提升。 机器学习与人工智能、深度学习之间的关系 当前被提及的高频词语是“AI人工智能”、“机器学习”、“深度学习”。那这些词语背后所代表的技术之间到底是什么关系呢？充分的理解这个关系，有利于建立起更加系统的专业学习框架。 首先，我们要搞明白机器学习到底学习的是什么，答案是模型“参数”，比如Y=AX+B是个机器学习的模型，通过样本数据，可以学习出参数A和B的确定值。然后基于这两个参数，对模型进行泛化，即对给定的X对Y进行预测。明白了机器学习到底是学习什么之后，我们一起看看下图来搞清楚机器学习与人工智能和深度学习之间的关系。 技术大牛带你走向机器学习“正道”：小朋友才迷信算法，大人们更重视工程实践 如上图所示，人工智能是最大的一个范畴，人工智能的实现目前看主要有两种途径：一种是基于脑科学的方式来实现智能。另一种是基于机器学习的方式来实现智能，这种方式的假设是当学习的数据足够充分，就可以大概率的逼近事实。 再回到公式Y=AX+B，我们可以看到机器学习是通过X和Y来学习出参数A和B，而在机器学习中，X是人工构造的特征，Y是人工进行标注的标签。一句话，机器学习就是通过构造X和Y来学习参数A和B。但通常情况下，构造X和标注Y需要耗用大量的人力和时间。所以，对于如何更智能的构造X和标注Y是机器学习很重要的研究方向。深度学习的一个重要作用就是能够更智能的构造X，即进行更好的特征表示。所以深度学习是机器学习的一个子集。那如何更好的标注Y呢，当前流行的对抗生成网络（GAN）就是一种解决方案。 机器学习需要的基础知识体系 机器学习的三个关键要素是模型、策略、算法。模型指的是具体的机器学习模型，比如决策树、SVM、神经网络、LDA等具体模型。策略指的是最小化模型结构性风险的手段，即避免模型欠拟合和过拟合的应对策略，在这里专指正则化（Regularization）。算法指的是建立好模型之后，如何对模型中的参数进行学习。也即最优化的方法。所以，初学者需要掌握的基础知识为： 1.导数与微积分，以及还需要对泰勒展开式、拉格朗日等定理和公式有充分的掌握。这是进行算法推导的基础中的基础。 2.线性代数，矩阵运算等要做到熟练掌握，因为机器学习的最优化算法中涉及到的复杂计算需要线性代数好矩阵运算的内容。 3.概率论，概率论的基础知识是理解像极大似然、最大熵、EM算法、贝叶斯网络、概率图模型的基础。 4.最优化，机器学习中的模型训练是通过对模型中参数的学习来进行泛化推广。如何对模型中的参数进行学习是最优化要解决的问题。比如线性优化、非线性优化的各种主要方法（比如梯度下降法、牛顿和拟牛顿法等）要有充分的理解。 5.机器学习模型的思想和具体实现方式要理解透彻。 机器学习的应用实践 特征工程，如上面所说就是造X，机器学习实践中大部分的实践都在处理特征工程上。所以真正有机器学习实践经验的人都知道机器学习更多的时间不是高大上的算法，而是苦逼特征工程。工程师每天更多的是基于对业务的深刻理解，通过构建“更好”的特征，持续提升模型的准确度。 推荐系统与搜索系统 当推荐和搜索这些字眼出现在网页中，专业书籍中，或是大部分的培训课程中，更多的是与机器学习和算法关联起来。这种情况的原因可能是为了迎合机器学习在大部分人认知中的“高大上”吧。 在实际的产品设计和开发中，推荐系统和搜索系统是有着一个更大概念的系统架构，绝非仅仅是只有机器学习和算法。其中UI/UE的重要性占比为40%，业务理解重要性占比为30%，数据重要性占比为20%，模型重要性占比为10%。 以推荐系统举例，整个推荐系统的框架应当如下图所示： 下图是电商平台上推荐系统的框架 所以，建议的推荐系统知识学习体系为： 一、推荐系统之整体架构 1.推荐系统的本质、目标及价值 2.一个好的推荐系统的相貌 3.线下零售的促销员与电商平台的推荐系统的关系 3.推荐系统与搜索的关系 4.主流电商平台上的推荐系统学习 5.推荐系统的整体架构图以及如何学习推荐系统 二、推荐系统之策略及模型 基于规则的推荐算法 基于内容(Content-Based)的推荐算法 基于协同过滤（CF)的推荐算法 基于隐因子（SVD/SVD++/MF/FM/FFM/PLSA/LDA）的推荐算法 推荐结果的排序模型（GBDT+LR，LTR） 数学基础及典型最优化算法 7.不同场景下的推荐策略（如在电商平台上，首页、详情页、购物车页、搜索结果页等不同场景下的推荐策略） 8.推荐系统评估 如何评估线下模型，如何评估线上效果 三、推荐系统之特征工程 1.用户画像如何构建 2.特征工程如何构建，以及如何进行特征分析 四、推荐系统之交互体验 如何向用户展示推荐系统的权威性、取得用户的信任、如何帮助用户决策、如何获取用户反馈。 如何开始机器学习 对于大多数人来说，如果以抽象的方式开始学习一项内容肯定不是最好的方式。相反，先建立起直觉，然后建立具体到抽象的映射，再深入学习抽象部分完成对细节部分的掌握，最后循环到具体的应用是适合大多数人的学习方式。所以对于机器学习初学者建议的学习路径为： 步骤一：先选择一门实战性非常强的机器学习及其应用课程进行学习。目标是通过足够多具体的应用，能够深刻理解机器学习的实际使用方式，从而建立起直觉。 步骤二：学习机器学习的理论课程，包括具体的模型算法，最优化方法，以及相关的公式推导。过了这一关，就完成了对机器学习细节的更好掌控。 步骤三：如果能够立刻参与到机器学习的实际项目中是最好不过了。如果不能，可以去完成Kaggle中的一些比赛项目。 最后，也是最最重要的建议，如果要想“更快速”“更高效”的掌握机器学习，找到合适的培训课程进行学习是最合适的方式。用钱买时间，买别人的经验，以更高效的方式掌握机器学习后，这些付出的费用可能仅仅是你工作之后月薪的很小的一部分。 在任督二脉打通之后，可以适当的对分布式存储和计算相关体系的内容进行学习。即靠的是个人的持续修行，在理论与实践循环提升中，成长为真正的专家。 PS：为了推动 AI 人才全面化，雷锋网将为大家提供一个业界顶级的专业 AI 技术培训平台：1024MOOC 。其中王刚老师也会在1024MOOC 开展系统的机器学习实战培训课程，具体开课时间在年后一周左右，请大家持续关注雷锋网(公众号：雷锋网)信息。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"机器学习年度 20 大开源项目花落谁家？（Python 版）","date":"2017-02-19T15:57:06.000Z","path":"2017/02/19/SmartAI/ProgramAI/OpenSources/20-open-source-projects-of-machine-learning/","text":"作者：雷锋网 小东 如今，开源已经成为创新与技术发展的核心。在本文中，雷锋网(公众号：雷锋网)将介绍 2016 Python 前20大机器学习开源项目。 去年 KDnuggets 评选了前 20 大机器学习开源项目（Python版），今年的评选结果与去年相比，名单中出现了一些新的面孔，有13个新开源项目入围了这个名单。作者 Prasad Pore 将具体介绍这些开源项目，雷锋网编译，未经许可不得转载。 第一名：Scikit-learn Scikit-learn可以说是一款简单而高效的数据挖掘与分析工具，大家可以免费下载安装，使用它处理各种数据，使用时需引入 NumPy, SciPy, and matplotlib这些第三方开源模块。 提交: 21486 贡献: 736 Github URL: Scikit-learn 第二名：Tensorflow Tensorflow是由谷歌大脑与谷歌人工智能实验室的科研人员研发而成的，这个系统用于机器学习的研究，可以简单、快速的实现研究人员的想法。前段时间恰逢Tensorflow一周年，雷锋网也做过报道和回顾。 提交: 10466 贡献: 493 Github URL: Tensorflow 第三名：Theano Theano可以对那些高维数组数学表达式进行定义、优化与评估。 提交: 24108 贡献: 263 Github URL: Theano 第四名：Caffe Caffe是一款具有表达、加速、模块化思想的深度学习框架，由 Berkeley Vision and Learning Center (BVLC)于社区志愿者共同开发维护。 提交: 3801 贡献: 215 Github URL: Caffe 第五名：Gensim Gensim是一个免费的Python库，这个库可以实现文本的情感倾向判断，相似文本检索等功能。 提交: 2702 贡献: 145 Github URL: Gensim 第六名：Pylearn2 Pylearn2 也是一个机器学习的开源库，但它是一个基于Theano的库，所以它有一些Theano的特点，你可以使用数学表达式来写Pylearn2插件，Theano会自动对你写的表达式进行优化，按照你的选择（用CPU或GPU）对这些表达式进行编译。 提交: 7100 贡献: 115 Github URL: Pylearn2 第七名：Statsmodels Statsmodels是一款Python开源工具，可以实现数据探究、统计模型评价、性能测试等功能，扩展性能良好，可对各种类型的数据进行各种处理，例如描述统计、统计测试、绘图、结果统计等等。 提交: 8664 贡献: 108 Github URL: Statsmodels 第八名：Shogun Shogun是一款机器学习工具，其包含了各种机器学习方法。它可以简单的实现多种数据表示、多种算法的无缝融合。 提交: 15172 贡献: 105 Github URL: Shogun 第九名：Chainer Chainer是一个基于Python的开源深度学习框架，它可以让你以一种灵活、简单、快速的方式实现多种深度学习模型，包括RNN与各种自编码。 提交: 6298 贡献: 84 Github URL: Chainer 第十名：NuPIC NuPIC是一个基于Hierarchical Temporal Memory理论的开源项目，目前Hierarchical Temporal Memory这个理论中的部分功能已经实现，并进行了测试与应用，其它部分正在完善中。 提交: 6088 贡献: 76 Github URL: NuPIC 第十一名：Neon Neon是一款深度学习第三方库，在进行高性能计算时它具有简单易用的特点。 提交: 875 贡献: 47 Github URL: Neon 第十二名：NiLearn NiLearn主要用于处理医学图像数据，具有简单、快速的特点。它通过调用scikit-learn进行多元统计分析（例如：预测模型、分类、解码、关联分析）。 提交: 5254 贡献: 46 Github URL: NiLearn 第十三名：Orange3 Orange3是一款机器学习与数据可视化开源工具，可以对数据进行各种交互分析。 提交: 6356 贡献: 40 Github URL: Orange3 第十四名：Pymc Pymc是一个贝叶斯统计模型（包括马尔科夫链）库，具有灵活、扩展性能好的特点。 提交: 2701 贡献: 37 Github URL: Pymc 第十五名：PyBrain： PyBrain是一个机器学习库，它的目标是让算法的实现变的简单、灵活、高效。同时使得在特定环境下对算法的测试与比较也变的简单、灵活、高效。 提交: 984 贡献: 31 Github URL: PyBrain 第十六名：Fuel Fuel主要用于算法与输入数据之间的衔接。它将被Blocks and Pylearn2这两个Python库使用。 提交: 1053 贡献: 29 Github URL: Fuel 第十七名： PyMVPA PyMVPA 适用于大规模的数据集，具有扩展性能好优点，提供多种算法（分类、回归、特征选择、数据导入、数据导出等）接口。 提交: 9258 贡献: 26 Github URL: PyMVPA 第十八名：Annoy Annoy是一个Python可调用的C++库，主要用来对给定数据进行搜索。它可以生成大量的基于文档的可读数据结构，这种数据结构与内存相对应，从而使数据被共享。 提交: 365 贡献: 24 Github URL: Annoy 第十九名：Deap Deap是一款新的计算框架，它使得算法实现与数据结构变得简单明了。它采用的是并行处理机制。 提交: 1854 贡献: 21 Github URL: Deap 第二十名：Pattern Pattern是一款web信息挖掘工具，它集成了各种工具。这些工具可以用来进行数据挖掘、自然语言处理、机器学习、网络分析。 提交: 943 贡献: 20 Github URL: Pattern 如下图所示，PyMVPA的社区贡献率最高，而排名第一的Scikit-learn社区贡献率却很低，究其原因是PyMVPA是还是一个比较新的开源项目，还有一些地方需要完善、修复。而Scikit-learn则是一个相对来说比较成熟的项目，需要修改、完善的地方比较少。 当我们对2015与2016的结果进行对比（下图），我们发现Pattern, PyBrain and Pylearn2这三个项目的贡献人数与提交数均没有变化。贡献的人增加了，提交的次数也才跟着增加，这就是开源社区的神奇所在。这些新增的贡献者与其提交内容导致了新的思想、新的软件的产生。 基于2016年20大机器学习开源项目的贡献人数与提交数，以上是雷锋网整理的简单分析。不知道到明年的评选上，又有怎样的开源平台会登上这个榜单呢？ via Top 20 Python Machine Learning Open Source Project 五个鲜为人知，但又不可不知的机器学习开源项目 本文作者：恒亮 2017-02-09 14:14 导语：本文将介绍的这五个小众项目来自不同的生态系统和编程语言，并且版本更新活跃，具有一定的学习价值。 五个鲜为人知，但又不可不知的机器学习开源项目 借着人工智能的热潮，各种机器学习项目也迎来了一个爆发期。其中有一些因为背后的巨头支持或者稳定可靠的性能而广为人知，例如Tensorflow、Caffe和Theano等。但实际上，有为数更多的项目却并不为人所知。在这些相对小众的项目中，是否隐藏着一些版本迭代积极，且具有一定参考价值的项目？答案显然是肯定的。 本文将介绍的这五个小众项目来自不同的生态系统和编程语言，并且版本更新活跃，具有一定的参考价值。或许你会觉得了解这些小众的项目并没有太多实际意义，但本文的原作者Matthew Mayo，一位资深的数据科学家和无监督学习领域的大牛认为，仔细学习这些项目的实现细节和编码方式，将帮助开发者对他们自己的项目产生一些具有积极意义的想法，因此仍然是大有裨益的。 原文来自KDnuggets，以下项目排名不分先后，雷锋网(公众号：雷锋网)编译。 Hyperopt-sklearn Hyperopt-sklearn是基于scikit-learn项目的一个子集，其全称是：Hyper-parameter optimization for scikit-learn，即针对scikit-learn项目的超级参数优化工具。由于scikit-learn是基于Python的机器学习开源框架，因此Hyperopt-sklearn也基于Python语言。 Hyperopt-sklearn的文档称：对于开发者而言，针对不同的训练数据挑选一个合适的分类器（classifier）通常是困难的。而且即使选好了分类器，后面的参数调试过程也相当乏味和耗时。更严重的是，还有许多情况是开发者好不容易调试好了选定的分类器，却发现一开始的选择本身就是错误的，这本身就浪费了大量的精力和时间。针对该问题，Hyperopt-sklearn提供了一种解决方案。 Hyperopt-sklearn支持各种不同的搜索算法（包括随机搜索、Tree of Parzen Estimators、Annealing等），可以搜索所有支持的分类器（KNeightborsClassifier、KNeightborsClassifier、SGDClassifier等）或者在给定的分类器下搜索所有可能的参数配置，并评估最优选择。并且Hyperopt-sklearn还支持多种预处理流程，包括TfidfVectorizer，Normalzier和OneHotEncoder等。 那么Hyperopt-sklearn的实际效果究竟如何？下表分别展示了使用scikit-learn默认参数和Hyperopt-sklearn优化参数运行的分类器的F-score分数，数据源来自20个不同的新闻组稿件。可以看到，经过优化的分类器的平均得分都要高于默认参数的情况。 另外，Hyperopt-sklearn的编码量也很小，并且维护团队还提供了丰富的参考样例。 主页：http://hyperopt.github.io/hyperopt-sklearn/ Dlib Dlib的目标用户并没有Hyperopt-sklearn细分，它是一个基于C++语言的通用的机器学习和数据分析库。值得一提的是，虽然Dlib的确是由C++实现的，但它却提供了针对Python语言的API。 Dlib的官网称：Dlib是一个现代的C++工具包，实现了大量机器学习的相关算法和工具，可用于在C++环境下创建复杂的软件来解决现实问题。目前，Dlib在工业界和学术界都得到了广泛的应用，包括机器人，嵌入式设备，移动电话和大规模的高性能计算环境等。 Dlib的帮助文档非常规范，针对每个API接口的解释也相当全面，而且Dlib还提供了非常详细的入门参考。更为难能可贵的是，Dlib的博客更新也非常频繁，官方人员经常通过博客分享基于Dlib实现的有趣的应用项目。实际上，Dlib也并非随着近两年的人工智能热潮才发起的项目，相对而言，它的历史非常悠久，早在2002年，Dlib的维护团队就已经开始着手开发了。 鉴于Dlib包含了为数众多的算法实现，因此原文作者认为Dlib的运行效率应该与scikit-learn接近，甚至有可能超越后者。 主页：http://dlib.net/ N++ N++同样基于C++环境，相对其他项目而言，它是一个非常小巧易用的神经网络实现库。这一点主要体现在，N++并不需要复杂的安装过程，使用时只需要在C++代码中通过#include语句对所需的库文件做一个声明就可以了。 其官网称：N++是一个简短、自包含（self-contained）、易于使用的基于C++环境的神经网络工具包。它实现了包括神经网络和基本线性代数运算在内的一些矩阵类。该项目的主要目的是为了相互学习和交流，但基于MNIST数据库的一些初步测试结果却表明N++在某些实际应用项目中的表现同样出色。 N++的配套文档并不多，但它却对矩阵类的相关用法进行了详细解释。另外，N++官方还公布了一些对神经网络进行设置和查询的代码片段，而且由于这些代码相对其他实现都非常简短，因此N++特别适合于那些想要了解简单的神经网络实现或者刚从其他编程语言转到C++环境的开发者。 主页：https://github.com/stagadish/NNplusplus LightGBM LightGBM是基于微软DMTK（Microsoft Distributed Machine Learning Toolkit）开源项目的一个子集，它的全称是：Light Gradient Boosting Machine，专注于各种梯度提升（Gradient Boosting）算法的实现，包括GBDT，GBRT，GBM和MART等。 官网描述称：基于公开数据集的测试结果表明，LightGBM无论在模型训练的速度、准确性还是内存消耗等各方面都要优于其他的梯度提升算法实现。此外，LightGBM还可以通过在特定设置中使用多台机器进行并行训练的方式来实现线性加速（linear speed-up）。 LightGBM本身由C++和Python两种语言实现，微软为开发者提供了完整的帮助文档和入门参考。背靠科技巨头微软的鼎力支持，LightGBM自然也是一个非常值得关注的项目。 主页：https://github.com/Microsoft/LightGBM Sklearn-pandas 与前面的几个项目不同，Sklearn-pandas既可以视为一个通用型的机器学习工具包，也可是视为一些特定算法的实现。它在具体的机器学习任务中主要充当支持者的角色。 这里所谓支持者的角色，按照其官网的解释即是说：Sklearn-pandas在Scikit-Learn和pandas之间提供了一个互通的桥梁（这一点从项目的名称也能看出）。Scikit-Learn上文已经提过，这里pandas是指一个开源的基于Python实现的数据分析工具。 具体的说，Sklearn-pandas的桥梁作用主要体现在以下两个方面： 1) 提供将DataFrame列映射到transformations的方法，这些列此后还可以重新组合成特征（features）； 2) 以pandas DataFrame为输入，为scikit-learn旧版本的管道交叉验证（cross-validate a pipeline）提供兼容性支持。 Sklearn-pandas的版本更新活跃，也是一个非常值得关注的开源项目。 主页：https://github.com/paulgb/sklearn-pandas 来源：kdnuggets，雷锋网编译","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"28款 GitHub 最流行的开源机器学习项目：TensorFlow 排榜首","date":"2017-02-19T15:57:05.000Z","path":"2017/02/19/SmartAI/ProgramAI/OpenSources/28-open-source-projects-of-machine-learning/","text":"作者：云栖社区 readygo 现在机器学习逐渐成为行业热门，经过二十几年的发展，机器学习得到了十分广泛的应用，如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、DNA序列测序、战略游戏和机器人等方面。 云栖社区特意翻译整理了目前GitHub上最受欢迎的28款开源的机器学习项目，以供开参考使用。 1. TensorFlowTensorFlow 是谷歌发布的第二代机器学习系统。据谷歌宣称，在部分基准测试中，TensorFlow的处理速度比第一代的DistBelief加快了2倍之多。具体的讲，TensorFlow是一个利用数据流图（Data Flow Graphs）进行数值计算的开源软件库：图中的节点（ Nodes）代表数学运算操作，同时图中的边（Edges）表示节点之间相互流通的多维数组，即张量（Tensors）。 这种灵活的架构可以让使用者在多样化的将计算部署在台式机、服务器或者移动设备的一个或多个CPU上，而且无需重写代码；同时任一基于梯度的机器学习算法均可够借鉴TensorFlow的自动分化（Auto-differentiation）；此外通过灵活的Python接口，要在TensorFlow中表达想法也变得更为简单。 TensorFlow最初由Google Brain小组（该小组隶属于Google’s Machine Intelligence研究机构）的研究员和工程师开发出来的，开发目的是用于进行机器学习和深度神经网络的研究。但该系统的通用性足以使其广泛用于其他计算领域。 目前Google 内部已在大量使用 AI 技术，包括 Google App 的语音识别、Gmail 的自动回复功能、Google Photos 的图片搜索等都在使用 TensorFlow 。 开发语言：C++许可协议：Apache License 2.0GitHub项目地址：https://github.com/tensorflow/tensorflow 2. Scikit-LearnScikit-Learn是用于机器学习的Python 模块，它建立在SciPy之上。该项目由David Cournapeau 于2007年创立，当时项目名为Google Summer of Code，自此之后，众多志愿者都为此做出了贡献。 主要特点：操作简单、高效的数据挖掘和数据分析无访问限制，在任何情况下可重新使用建立在NumPy、SciPy 和 matplotlib基础上 Scikit-Learn的基本功能主要被分为六个部分：分类、回归、聚类、数据降维、模型选择、数据预处理，具体可以参考官方网站上的文档。经过测试，Scikit-Learn可在 Python 2.6、Python 2.7 和 Python 3.5上运行。除此之外，它也应该可在Python 3.3和Python 3.4上运行。注：Scikit-Learn以前被称为Scikits.Learn。 开发语言：Python许可协议:3-Clause BSD licenseGitHub项目地址: https://github.com/scikit-learn/scikit-learn 3.CaffeCaffe 是由神经网络中的表达式、速度、及模块化产生的深度学习框架。后来它通过伯克利视觉与学习中心（(BVLC）和社区参与者的贡献，得以发展形成了以一个伯克利主导，然后加之Github和Caffe-users邮件所组成的一个比较松散和自由的社区。 Caffe是一个基于C++/CUDA架构框架，开发者能够利用它自由的组织网络，目前支持卷积神经网络和全连接神经网络（人工神经网络）。在Linux上，C++可以通过命令行来操作接口，对于MATLAB、Python也有专门的接口，运算上支持CPU和GPU直接无缝切换。 Caffe的特点 易用性：Caffe的模型与相应优化都是以文本形式而非代码形式给出， Caffe给出了模型的定义、最优化设置以及预训练的权重，方便快速使用；速度快：能够运行最棒的模型与海量的数据；Caffe可与cuDNN结合使用，可用于测试AlexNet模型，在K40上处理一张图片只需要1.17ms；模块化：便于扩展到新的任务和设置上；使用者可通过Caffe提供的各层类型来定义自己的模型；目前Caffe应用实践主要有数据整理、设计网络结构、训练结果、基于现有训练模型，使用Caffe直接识别。 开发语言：C++许可协议： BSD 2-Clause licenseGitHub项目地址: https://github.com/BVLC/caffe 4. PredictionIOPredictionIO 是面向开发人员和数据科学家的开源机器学习服务器。它支持事件采集、算法调度、评估，以及经由REST APIs的预测结果查询。使用者可以通过PredictionIO做一些预测，比如个性化推荐、发现内容等。PredictionIO 提供20个预设算法，开发者可以直接将它们运行于自己的数据上。几乎任何应用与PredictionIO集成都可以变得更“聪明”。其主要特点如下所示： 基于已有数据可预测用户行为；使用者可选择你自己的机器学习算法；无需担心可扩展性，扩展性好。PredictionIO 基于 REST API（应用程序接口）标准，不过它还包含 Ruby、Python、Scala、Java 等编程语言的 SDK（软件开发工具包）。其开发语言是Scala语言，数据库方面使用的是MongoDB数据库，计算系统采用Hadoop系统架构。 开发语言：Scala许可协议： Apache License 2.0GitHub项目地址: https://github.com/PredictionIO/PredictionIO 5. BrainBrain是 JavaScript 中的 神经网络库。以下例子说明使用Brain来近似 XOR 功能： 1234567891011var net = new brain.NeuralNetwork();net.train([&#123;input: [0, 0], output: [0]&#125;, &#123;input: [0, 1], output: [1]&#125;, &#123;input: [1, 0], output: [1]&#125;, &#123;input: [1, 1], output: [0]&#125;]);var output = net.run([1, 0]); // [0.987] 当 brain 用于节点中，可使用npm安装：npm install brain当 brain 用于浏览器，下载最新的 brain.js 文件。训练计算代价比较昂贵，所以应该离线训练网络（或者在 Worker 上），并使用 toFunction() 或者 toJSON()选项，以便将预训练网络插入到网站中。 开发语言：JavaScriptGitHub项目地址: https://github.com/harthur/brain 6. KerasKeras是极其精简并高度模块化的神经网络库，在TensorFlow 或 Theano 上都能够运行，是一个高度模块化的神经网络库，支持GPU和CPU运算。Keras可以说是Python版的Torch7，对于快速构建CNN模型非常方便，同时也包含了一些最新文献的算法，比如Batch Noramlize，文档教程也很全，在官网上作者都是直接给例子浅显易懂。Keras也支持保存训练好的参数，然后加载已经训练好的参数，进行继续训练。 Keras侧重于开发快速实验，用可能最少延迟实现从理念到结果的转变，即为做好一项研究的关键。当需要如下要求的深度学习的库时，就可以考虑使用Keras： 考虑到简单快速的原型法（通过总体模块性、精简性以及可扩展性）；同时支持卷积网络和递归网络，以及两者之间的组合；支持任意连接方案（包括多输入多输出训练）；可在CPU 和 GPU 上无缝运行。Keras目前支持 Python 2.7-3.5。 开发语言：PythonGitHub项目地址:https://github.com/fchollet/keras 7. CNTKCNTK（Computational Network Toolkit ）是一个统一的深度学习工具包，该工具包通过一个有向图将神经网络描述为一系列计算步骤。在有向图中，叶节点表示输入值或网络参数，其他节点表示该节点输入之上的矩阵运算。 CNTK 使得实现和组合如前馈型神经网络DNN、卷积神经网络（CNN）和循环神经网络(RNNs/LSTMs)等流行模式变得非常容易。同时它实现了跨多GPU 和服务器自动分化和并行化的随机梯度下降（SGD，误差反向传播）学习。 下图将CNTK的处理速度（每秒处理的帧数）和其他四个知名的工具包做了比较了。配置采用的是四层全连接的神经网络（参见基准测试脚本）和一个大小是8192 的高效mini batch。在相同的硬件和相应的最新公共软件版本（2015.12.3前的版本）的基础上得到如下结果： CNTK自2015年四月就已开源。 开发语言：C++GitHub项目地址:https://github.com/Microsoft/CNTK 8. ConvnetjsConvNetJS是利用Javascript实现的神经网络，同时还具有非常不错的基于浏览器的Demo。它最重要的用途是帮助深度学习初学者更快、更直观的理解算法。 它目前支持：常见的神经网络模块（全连接层，非线性）；分类（SVM/ SOFTMAX）和回归（L2）的成本函数；指定和训练图像处理的卷积网络；基于Deep Q Learning的实验强化学习模型。 一些在线示例：Convolutional Neural Network on MNIST digitsConvolutional Neural Network on CIFAR-10Toy 2D dataToy 1D regressionTraining an Autoencoder on MNIST digitsDeep Q Learning Reinforcement Learning demo +Image Regression (“Painting”) +Comparison of SGD/Adagrad/Adadelta on MNIST 开发语言：Javascript许可协议：MIT LicenseGitHub项目地址:https://github.com/karpathy/convnetjs 9. Pattern Pattern是Python的一个Web挖掘模块。拥有以下工具：数据挖掘：网络服务（Google、Twitter、Wikipedia）、网络爬虫、HTML DOM解析；自然语言处理：词性标注工具(Part-Of-Speech Tagger)、N元搜索(n-gram search)、情感分析(sentiment analysis)、WordNet；机器学习：向量空间模型、聚类、分类（KNN、SVM、 Perceptron）；网络分析：图形中心性和可视化。其文档完善，目前拥有50多个案例和350多个单元测试。 Pattern目前只支持Python 2.5+（尚不支持Python 3），该模块除了在Pattern.vector模块中使用LSA外没有其他任何外部要求，因此只需安装 NumPy （仅在Mac OS X上默认安装）。 开发语言：Python许可协议：BSD licenseGitHub项目地址:https://github.com/clips/pattern 10. NuPIC NuPIC是一个实现了HTM学习算法的机器智能平台。HTM是一个关于新（大脑）皮质（Neocortex）的详细人工智能算法。HTM的核心是基于时间的连续学习算法，该算法可以存储和调用时间和空间两种模式。NuPIC可以适用于解决各类问题，尤其是异常检测和流数据源预测方面。NuPIC Binaries文件目前可用于：Linux x86 64bitOS X 10.9OS X 10.10Windows 64bitNuPIC 有自己的独特之处。许多机器学习算法无法适应新模式，而NuPIC的运作接近于人脑，当模式变化的时候，它会忘掉旧模式，记忆新模式。 开发语言：PythonGitHub项目地址：https://github.com/numenta/nupic Theano Theano是一个Python库，它允许使用者有效地定义、优化和评估涉及多维数组的数学表达式，同时支持GPUs和高效符号分化操作。Theano具有以下特点：与NumPy紧密相关–在Theano的编译功能中使用了Numpy.ndarray ；透明地使用GPU–执行数据密集型计算比CPU快了140多倍（针对Float32）；高效符号分化–Theano将函数的导数分为一个或多个不同的输入；速度和稳定性的优化–即使输入的x非常小也可以得到log(1+x)正确结果；动态生成 C代码–表达式计算更快；广泛的单元测试和自我验证–多种错误类型的检测和判定。自2007年起，Theano一直致力于大型密集型科学计算研究，但它目前也很被广泛应用在课堂之上（ 如Montreal大学的深度学习/机器学习课程）。 开发语言：PythonGitHub项目地址：https://github.com/Theano/Theano 12. MXNet MXNet是一个兼具效率和灵活性的深度学习框架。它允许使用者将符号编程和命令式编程相结合，以追求效率和生产力的最大化。其核心是动态依赖调度程序，该程序可以动态自动进行并行化符号和命令的操作。其中部署的图形优化层使得符号操作更快和内存利用率更高。该库轻量且便携带，并且可扩展到多个GPU和多台主机上。 主要特点：其设计说明提供了有用的见解，可以被重新应用到其他DL项目中；任意计算图的灵活配置；整合了各种编程方法的优势最大限度地提高灵活性和效率；轻量、高效的内存以及支持便携式的智能设备；多GPU扩展和分布式的自动并行化设置；支持Python、R、C++和 Julia；对“云计算”友好，直接兼容S3、HDFS和Azure。MXNet不仅仅是一个深度学习项目，它更是一个建立深度学习系统的蓝图、指导方针以及黑客们对深度学习系统独特见解的结合体。 开发语言：Jupyter Notebook开源许可：Apache-2.0 licenseGitHub项目地址：https://github.com/dmlc/mxnet 13. Vowpal WabbitVowpal Wabbit是一个机器学习系统，该系统推动了如在线、散列、Allreduce、Learning2search、等方面机器学习前沿技术的发展。 其训练速度很快，在20亿条训练样本，每个训练样本大概100个非零特征的情况下：如果特征的总位数为一万时，训练时间为20分钟；特征总位数为1000万时，训练时间为2个小时。Vowpal Wabbit支持分类、 回归、矩阵分解和LDA。 当在Hadoop上运行Vowpal Wabbit时，有以下优化机制：懒惰初始化：在进行All Reduce之前，可将全部数据加载到内存中并进行缓存。即使某一节点出现了错误，也可以通过在另外一个节点上使用错误节点的数据（通过缓存来获取）来继续训练。Speculative Execution：在大规模集群当中，一两个很慢的Mapper会影响整个Job的性能。Speculative Execution的思想是当大部分节点的任务完成时，Hadoop可以将剩余节点上的任务拷贝到其他节点完成。 开发语言：C++GitHub项目地址：https://github.com/JohnLangford/vowpal_wabbit 14. Ruby Warrior通过设计了一个游戏使得Ruby语言和人工智能学习更加有乐趣和互动起来。使用者扮演了一个勇士通过爬上一座高塔，到达顶层获取珍贵的红宝石（Ruby）。在每一层，需要写一个Ruby脚本指导战士打败敌人、营救俘虏、到达楼梯。使用者对每一层都有一些认识，但是你永远都不知道每层具体会发生什么情况。你必须给战士足够的人工智能，以便让其自行寻找应对的方式。 勇士的动作相关API：Warrior.walk： 用来控制勇士的移动，默认方向是往前；warrior.feel：使用勇士来感知前方的情况，比如是空格，还是有怪物；Warrior.attack：让勇士对怪物进行攻击；Warrior.health：获取勇士当前的生命值；Warrior.rest：让勇士休息一回合，恢复最大生命值的10%。 勇士的感知API:Space.empty：感知前方是否是空格；Space.stairs：感知前方是否是楼梯；Space.enemy： 感知前方是否有怪物；Space.captive：感知前方是否有俘虏；Space.wall：感知前方是否是墙壁。 开发语言：RubyGitHub项目地址：https://github.com/ryanb/ruby-warrior 15. XGBoostXGBoot是设计为高效、灵活、可移植的优化分布式梯度 Boosting库。它实现了 Gradient Boosting 框架下的机器学习算法。XGBoost通过提供并行树Boosting（也被称为GBDT、GBM），以一种快速且准确的方式解决了许多数据科学问题。相同的代码可以运行在大型分布式环境如Hadoop、SGE、MP上。它类似于梯度上升框架，但是更加高效。它兼具线性模型求解器和树学习算法。 XGBoot至少比现有的梯度上升实现有至少10倍的提升，同时还提供了多种目标函数，包括回归、分类和排序。由于它在预测性能上的强大，XGBoot成为很多比赛的理想选择，其还具有做交叉验证和发现关键变量的额外功能。 值得注意的是：XGBoost仅适用于数值型向量，因此在使用时需要将所有其他形式的数据转换为数值型向量；在优化模型时，这个算法还有非常多的参数需要调整。 开发语言：C++开源许可：Apache-2.0 licenseGitHub项目地址：https://github.com/dmlc/xgboost 16. GoLearnGoLearn 是Go 语言中“功能齐全”的机器学习库，简单性及自定义性是其开发目标。 在安装 GoLearn 时，数据作为实例被加载，然后可以在其上操作矩阵，并将操作值传递给估计值。GoLearn 实现了Fit/Predict的Scikit-Learn界面，因此用户可轻松地通过反复试验置换出估计值。此外，GoLearn还包括用于数据的辅助功能，例如交叉验证、训练以及爆裂测试。 开发语言：GoGitHub项目地址: https://github.com/sjwhitworth/golearn 17. ML_for_HackersML_for_Hackers 是针对黑客机器学习的代码库，该库包含了所有针对黑客的机器学习的代码示例（2012）。该代码可能和文中出现的并不完全相同，因为自出版以来，可能又添加了附加的注释和修改部分。所有代码均为R语言，依靠众多的R程序包，涉及主题包括分类(Classification)、排行(Ranking)、以及回归(Regression)的所有常见的任务和主成分分析(PCA)和多维尺度(Multi-dimenstional Scaling)等统计方法。 开发语言：R开源许可：Simplified BSD LicenseGitHub项目地址: https://github.com/johnmyleswhite/ML_for_Hackers 18. H2O-2H2O使得Hadoop能够做数学运算！它可以通过大数据衡量统计数据、机器学习和数学。H2O是可扩展的，用户可以在核心区域使用简单的数学模型构建模块。H2O保留着与R、Excel 和JSON等相类似的熟悉的界面，使得大数据爱好者及专家们可通过使用一系列由简单到高级的算法来对数据集进行探索、变换、建模及评分。采集数据很简单，但判决难度却很大，而H2O却通过更快捷、更优化的预测模型，能够更加简单迅速地从数据中获得深刻见解。0xdata H2O的算法是面向业务流程——欺诈或趋势预测。Hadoop专家可以使用Java与H2O相互作用，但框架还提供了对Python、R以及Scala的捆绑。 开发语言：JavaGitHub项目地址: https://github.com/h2oai/h2o-2 19. neonneon 是 Nervana 基于 Python 语言的深度学习框架，在诸多常见的深层神经网络中都能够获得较高的性能，比如AlexNet、VGG 或者GoogLeNet。在设计 neon 时，开发者充分考虑了如下功能： 支持常用的模型及实例，例如 Convnets、 MLPs、 RNNs、LSTMs、Autoencoders 等，其中许多预训练的实现都可以在模型库中发现；与麦克斯韦GPU中fp16 和 fp32(基准) 的nervanagpu 内核紧密集成；在Titan X（1 GPU ~ 32 hrs上可完整运行）的AlexNet上为3s/macrobatch（3072图像）；快速影像字幕模型（速度比基于 NeuralTalk 的CPU 快200倍）。支持基本自动微分；框架可视化；可交换式硬盘后端：一次编写代码，然后配置到 CPU、GPU、或者 Nervana 硬盘。在 Nervana中，neon被用来解决客户在多个域间存在的各种问题。 开发语言：Python开源许可：Apache-2.0 licenseGitHub项目地址: https://github.com/NervanaSystems/neon 20. Oryx 2开源项目Oryx提供了简单且实时的大规模机器学习、预测分析的基础设施。它可实现一些常用于商业应用的算法类：协作式过滤/推荐、分类/回归、集群等。 此外，Oryx 可利用 Apache Hadoop 在大规模数据流中建立模型，还可以通过HTTP REST API 为这些模型提供实时查询，同时随着新的数据不断流入，可以近似地自动更新模型。这种包括了计算层和服务层的双重设计，能够分别实现一个Lambda 架构。模型在PMML格式交换。 Oryx本质上只做两件事：建模和为模型服务，这就是计算层和服务层两个独立的部分各自的职责。计算层是离线、批量的过程，可从输入数据中建立机器学习模型，它的经营收益在于“代”，即可利用某一点处输入值的快照建模，结果就是随着连续输入的累加，随时间生成一系列输出；服务层也是一个基于Java长期运行的服务器进程，它公开了REST API。使用者可从浏览器中访问，也可利用任何能够发送HTTP请求的语言或工具进行访问。 Oryx的定位不是机器学习算法的程序库，Owen关注的重点有四个：回归、分类、集群和协作式过滤（也就是推荐）。 其中推荐系统非常热门，Owen正在与几个Cloudera的客户合作，帮他们使用Oryx部署推荐系统。 开发语言：JavaGitHub项目地址: https://github.com/cloudera/oryx 21. ShogunShogun是一个机器学习工具箱，由Soeren Sonnenburg 和Gunnar Raetsch（创建，其重点是大尺度上的内核学习方法，特别是支持向量机（SVM，Support Vector Machines）的学习工具箱。它提供了一个通用的连接到几个不同的SVM实现方式中的SVM对象接口，目前发展最先进的LIBSVM和SVMlight 也位于其中，每个SVM都可以与各种内核相结合。工具箱不仅为常用的内核程序（如线性、多项式、高斯和S型核函数）提供了高效的实现途径，还自带了一些近期的字符串内核函数，例如局部性的改进、Fischer、TOP、Spectrum、加权度内核与移位，后来有效的LINADD优化内核函数也已经实现。 此外，Shogun还提供了使用自定义预计算内核工作的自由，其中一个重要特征就是可以通过多个子内核的加权线性组合来构造的组合核，每个子内核无需工作在同一个域中。通过使用多内核学习可知最优子内核的加权。 目前Shogun可以解决SVM 2类的分类和回归问题。此外Shogun也添加了了像线性判别分析（LDA）、线性规划（LPM）、（内核）感知等大量线性方法和一些用于训练隐马尔可夫模型的算法。 开发语言：C/C++、Python许可协议：GPLv3GitHub项目地址: https://github.com/shogun-toolbox/shogun 22. HLearnHLearn是由Haskell语言编写的高性能机器学习库，目前它对任意维度空间有着最快最近邻的实现算法。 HLearn同样也是一个研究型项目。该项目的研究目标是为机器学习发掘“最佳可能”的接口。这就涉及到了两个相互冲突的要求：该库应该像由C/C++/Fortran/Assembly开发的底层库那样运行快速；同时也应该像由Python/R/Matlab开发的高级库那样灵活多变。Julia在这个方向上取得了惊人的进步，但是 HLearn“野心”更大。更值得注意的是，HLearn的目标是比低级语言速度更快，比高级语言更加灵活。 为了实现这一目标，HLearn采用了与标准学习库完全不同的接口。在HLearn中H代表着三个不同的概念，这三个概念也是HLearn设计的基本要求：H代表Haskell。机器学习是从数据中预测函数，所以功能性编程语言适应机器学习是完全说的通的。但功能性编程语言并没广泛应用于机器学习，这是因为它们固来缺乏支持学习算法的快速数值计算能力。HLearn通过采用Haskell中的SubHask库获得了快速数值计算能力； H同时代表着Homomorphisms。Homomorphisms是抽象代数的基本概念，HLearn将该代数结构用于学习系统中； H还代表着History monad。在开发新的学习算法过程中，最为困难的任务之一就是调试优化过程。在此之前，是没有办法减轻调试过程的工作量的，但History monad正在试图解决该问题。它可以让你在整个线程优化代码的过程中无需修改原代码。此外，使用该技术时没有增加其他的运行开销。 开发语言：HaskellGitHub项目地址:https://github.com/mikeizbicki/HLearn 23. MLPNeuralNetMLPNeuralNet是一个针对iOS和Mac OS系统的快速多层感知神经网络库，可通过已训练的神经网络预测新实例。它利用了向量运算和硬盘加速功能（如果可用），其建立在苹果公司的加速框架之上。 若你已经用Matlab（Python或R）设计了一个预测模型，并希望在iOS应用程序加以应用。在这种情况下，正好需要MLP NeuralNet，而MLP NeuralNet只能加载和运行前向传播方式的模型。MLP NeuralNet 有如下几个特点： 分类、多类分类以及回归输出；向量化实现形式；双精度；多重隐含层数或空（此时相当于逻辑学/线性回归）。 开发语言：Objective-C许可协议：BSD licenseGitHub项目地址: https://github.com/nikolaypavlov/MLPNeuralNet 24. Apache MahoutMahout 是Apache Software Foundation（ASF） 旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。Apache Mahout项目的目标是建立一个能够快速创建可扩展、高性能机器学习应用的环境。 虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：Taste CF，Taste是Sean Owen在SourceForge上发起的一个针对CF的开源项目，并在2008年被赠予Mahout；一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift；Distributed Naive Bayes 和 Complementary Naive Bayes 分类实现；针对进化编程的分布式适用性功能；Matrix 和矢量库。使用 Mahout 还可实现内容分类。Mahout 目前支持两种根据贝氏统计来实现内容分类的方法：第一种方法是使用简单的支持 Map-Reduce 的 Naive Bayes 分类器；第二种方法是 Complementary Naive Bayes，它会尝试纠正Naive Bayes方法中的一些问题，同时仍然能够维持简单性和速度。 开发语言：Java许可协议：ApacheGitHub项目地址: https://github.com/apache/mahout 25. Seldon ServerSeldon是一个开放式的预测平台，提供内容建议和一般的功能性预测。它在Kubernetes集群内运行，因此可以调配到Kubernetes范围内的任一地址：内部部署或云部署（例如，AWS、谷歌云平台、Azure）。另外，它还可以衡量大型企业安装的需求。 开发语言：JavaGitHub项目地址: https://github.com/SeldonIO/seldon-server 26. Datumbox - FrameworkDatumbox机器学习框架是用Java编写的一个开源框架，该框架的涵盖大量的机器学习算法和统计方法，并能够处理大尺寸的数据集。 Datumbox API提供了海量的分类器和自然语言处理服务，能够被应用在很多领域的应用，包括了情感分析、话题分类、语言检测、主观分析、垃圾邮件检测、阅读评估、关键词和文本提取等等。目前，Datumbox所有的机器学习服务都能够通过API获取，该框架能够让用户迅速地开发自己的智能应用。目前，基于GPL3.0的Datumbox机器学习框架已经开源并且可以从GitHub上进行下载。 Datumbox的机器学习平台很大程度上已经能够取代普通的智能应用。它具有如下几个显著的优点： 强大并且开源。Datumbox API使用了强大的开源机器学习框架Datumbox，使用其高度精确的算法能够迅速地构建创新的应用；易于使用。平台API十分易于使用，它使用了REST&amp;JSON的技术，对于所有的分类器；迅速使用。Datumbox去掉了那些很花时间的复杂机器学习训练模型。用户能够通过平台直接使用分类器。 Datumbox主要可以应用在四个方面：一个是社交媒体的监视，评估用户观点能够通过机器学习解决，Datumbox能够帮助用户构建自己的社交媒体监视工具；第二是搜索引擎优化，其中非常有效的方法就是文档中重要术语的定位和优化；第三点是质量评估，在在线通讯中，评估用户产生内容的质量对于去除垃圾邮件是非常重要的，Datumbox能够自动的评分并且审核这些内容；最后是文本分析，自然语言处理和文本分析工具推动了网上大量应用的产生，平台API能够很轻松地帮助用户进行这些分析。 开发语言：Java许可协议：Apache License 2.0GitHub项目地址: https://github.com/datumbox/datumbox-framework 27. JubatusJubatus库是一个运行在分布式环境中的在线机器学习框架，即面向大数据数据流的开源框架。它和Storm有些类似，但能够提供更多的功能，主要功能如下：在线机器学习库：包括分类、聚合和推荐；Fv_converter: 数据预处理（用自然语言）；在线机器学习框架，支持容错。 Jubatus认为未来的数据分析平台应该同时向三个方向展开：处理更大的数据，深层次的分析和实时处理。于是Jubatus将在线机器学习，分布式计算和随机算法等的优势结合在一起用于机器学习，并支持分类、回归、推荐等基本元素。根据其设计目的，Jubatus有如下的特点： 可扩展：支持可扩展的机器学习处理。在普通硬件集群上处理数据速度高达100000条/秒； ＋实时计算：实时分析数据和更新模型；深层次的数据分析：支持各种分析计算：分类、回归、统计、推荐等。如果有基于流数据的机器学习方面的需求，Jubatus值得关注。 开发语言：C/C++许可协议：LGPLGitHub项目地址: https://github.com/jubatus/jubatus 28. DeciderDecider 是另一个 Ruby 机器学习库，兼具灵活性和可扩展性。Decider内置了对纯文本和URI、填充词汇、停止词删除、字格等的支持，以上这些都可以很容易地在选项中组合。Decider 可支持Ruby中任何可用的存储机制。如果你喜欢，可以保存到数据库中，实现分布式分类。Decider有几个基准，也兼作集成测试。这些都是定期运行并用于查明CPU和RAM的瓶颈。Decider可以进行大量数学运算，计算相当密集，所以对速度的要求比较高。这是经常使用Ruby1.9和JRuby测试其计算速度。此外，用户的数据集应该完全在内存中，否则将会遇到麻烦。 开发语言：RubyGitHub项目地址: https://github.com/danielsdeleo/Decider 编译自：https://github.com/showcases/machine-learning译者：刘崇鑫 校对：王殿进","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"谷歌机器学习白皮书全解析43条黄金法则","date":"2017-02-19T15:57:00.000Z","path":"2017/02/19/SmartAI/ProgramAI/Concepts/white-paper-of-google-machine-learning/","text":"作者：雷锋网 谷歌白皮书原文地址：http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf 编者按：此白皮书为谷歌总结的机器学习（ML）最优实践方法，浓缩了其多年技术积累与经验，尤其是 Youtube、Google Play 和 Google+ 等平台背后的 ML 算法开发、维护经历。谷歌于白皮书中总结了四十三条 ML 黄金法则，旨在帮助已经掌握了基础知识的开发者少走弯路。鉴于其珍贵程度与技术性，雷锋网逐条做了严格尊重原文的翻译。若你已学习过机器学习课程，抑或有开发 ML 模型的经验，那么应当具备足够的背景知识理解这篇文章。 术语 以下是对文中反复出现的术语的解释。 实例（ Instance）：做预测的对象。比如说，实例可以是一个网页，你想要把它分类为“关于猫”或者“与猫不相关”。 标记（Label）：预测任务的答案。它既可以是机器学习系统生成的答案，也可以是训练数据中提供的正确答案（雷锋网注：比如监督学习中的人工标记）。举例来说，一个网页的标记可以是“关于猫”。 特征（Feature）：预测任务中实例的属性。比如说，某网页可能有“包含关键词‘猫’”的特征 特征栏 （Feature Column）:这是谷歌自创的术语，意为关联特征的集合。比如说，用户的所有可能居住国家的集合。一个样例的特征栏可以有一个或多个特征。特征栏可被看作是 VW 系统（微软、雅虎所用）中的命名空间，或者场（ field）。 样例（Example）：有标记的实例（具备特征）。 模型（Model）：对预测任务的统计表达。你用样例训练模型，然后用模型做预测。 指标（Metric）：你在意的数字。可被直接优化过，也可没有。 目标（Objective）：你的算法试图优化的指标。 流水线（Pipeline）：机器学习算法的基础设施；包括从前端收集数据，把它放入训练数据文档，训练一个或多个模型，以及把模型输出、产品化。 概览： 为了开发出好产品： 做机器学习这一行首先要摆正心态，你是一名（优秀的）工程师，不要拿专家的标准来要求自己。 事实上，你将要面对的大多数难题是工程问题（engineering problems）。即便是一个杰出的ML 专家，坐拥该级别才有的资源，其大多数收获也来自于特征而不是 ML 算法。所以，ML 开发的基本路线是： 保证可靠的端到端流水线 从制定合理的目标着手 用简单的方式，加入符合常识的特征 确保流水线始终可靠 该方法能帮你赚钱养家，并且让很多人满意。只有当无路可走、简单的技巧无法再起作用时，你才需要偏离该路线。但注意，提高复杂度会拖慢将来的产品发布。另外，当你穷尽了简单技巧，或许就到了登堂入室、探索 ML 最前沿技术的时候了。具体请看本文机器学习第三阶。 本文分为四个部分： 第一部分“1.0 做机器学习之前”，会帮你搞清楚，你创建机器学习系统的时机是否已经成熟。 第二部分“2.0 机器学习第一阶”是关于设置你的第一个流水线。 第三部分“3.0 机器学习第二阶”，关乎启动和重复，同时向流水线加入新特征。 最后一部分“4.0 机器学习第三阶”是关于达到瓶颈后怎么办。 43 条黄金法则列表： 对发布一个不含 ML 技术的产品，不要有顾虑 首先要设计和贯彻指标 在机器学习和复杂启发算法之间，选择前者 第一个模型要简单，把基础设施弄好 测试基础设施要与 ML 测试分开 复制流水线时当心数据遗落 把启发式（heuristics）变为特征，不然就对它们做外部处理 了解系统的时效性 在输出模型之前发现问题 于无声处听惊雷：注意没表现出来的故障 注意特征栏的维护者和文件 选择直接优化哪个目标时，不需要想太多 选择一个简单、可观察并且可归属（attributable）的指标来作为第一个目标 用可解释的模型开头，修补漏洞会更简单 用 policy layer（规则层）把垃圾信息过滤和质量排序分来 做好模型被推倒和重建的准备 直接以观察到的或报告的特征开始训练，而不是经过学习的特征 从不同的上下文环境中提取特征 尽量选择更具体的特征 以合理的方式组合、修改现有特征 通过线性模型学到的特征权重的数目，大致与数据量成正比 清理不需要的特征 你并不是一个典型的用户 版本之间存在对等差分（symmetric difference） 选择模型时，性能胜过预测能力 从误差中查找新模式、创建新特征 尝试量化观察到的异常行为 注意短期行为和长期行为的差别 确保训练和服务一样好的最直接办法是：保存服务时使用的特征，然后将这些特征导入日志，以便在训练中使用。 重视采样数据 注意表格中的数据可能改变 尽量在训练和服务流水线中复用代码 训练和测试的数据不能相同 在二进制分类过滤的应用场景中（例如垃圾邮件检测），不要为了纯净的数据做太大的性能牺牲 注意排序问题的固有偏差 避免具有位置特征的反馈回路 测量训练/服务偏差 如果目标之间不搭，并成为问题，就不要在新特征上浪费时间 模型发布决策是长期产品目标的代理 保证集成模型（ensemble）的简洁 当性能达到瓶颈，相比精炼现存信号，不如寻找新性质的信息源 不要期望多样性、个性化、相关性和受欢迎程度之间有紧密联系 不同产品中，你的朋友总是那一个，你的兴趣不会如此 1.0 做机器学习之前 对发布一个不含 ML 技术的产品，不要有顾虑 机器学习很酷，但要有数据。理论上，你可以把另一个相近课题的数据拿来用，调整下模型变成一个新产品。但这么做的实际效果，通常比简单的启发式算法（heuristics）还差。如果你认为机器学习能完成任务的 100%。那么启发式算法能帮你完成 50%。 比如说，若你为应用商店进行 app 排名，不妨直接利用下载率和装机量写个简单算法；若你在检测垃圾邮件，可以先把发送过垃圾邮件的地址过滤掉。也不要在人工编辑上有顾虑。如果机器学习对于你的产品不是必需的，那么在获得数据之前不要用它。 首先要设计和贯彻指标 在定义你的 ML 系统要做什么之前，要尽可能多得追踪你当前的系统。这出于以下原因： 在早期，获得系统用户的许可相对容易。 如果你认为有些东西在将来需要考虑，最好从现在起就收集历史数据。 如果你设计系统时考虑了指标的工具化（ metric instrumentation），会省下将来的许多力气。你绝对不想为了指标而查找日志字符串。 有些东西会改变，有些不会。比如说，假设你想要直接优化每日活跃用户。但是，在你对系统的早期操作中，你也许会发现用户体验的大幅变化并不会显著改变这个指标。 Google+ 团队会衡量每次阅读的扩展数（expands per read）、分享、点赞、评论，以及每用户评论数、分享等等。然后他们利用这些数据计算发布消息的质量。另外要注意，能通过试验把用户分组并整合数据的试验框架非常重要，参考第 12 条。 通过更灵活地收集指标，你能用更大的视角观察系统。发现一个问题？添加一个指标来追踪它！对上一个发布版本的量化变动很兴奋？添加指标来追踪! 在机器学习和复杂启发算法之间，选择前者 一个简单的启发算法能帮助产品走向市场，而复杂启发算法难以维护。一旦你有了数据以及需要实现的目标的蓝图，就可以转去开发 ML。在大多数软件工程任务中，开发者需要不停更新开发方式，不管是启发式算法还是 ML 模型。你会发现后者更加容易更新维护（参考第 16 条）。 2.0 机器学习第一阶2.1 你的第一条流水线 对于第一条流水线，关注你的系统基础设施。虽然，设想你将要做的种种 ML 应用很有趣；但如果你无法信任自己的流水线，你会很难搞清楚状况。 第一个模型要简单，把基础设施弄好 第一个模型为你的产品提供了最大的助力，所以它不需要花哨。而且你会遇到许多想象之外的基础设施问题。在你的新 ML 系统诞生之前，你需要决定： 如何获取学习算法的样例 对于你的系统，“好”、“坏”的定义是什么 如何把模型整合入应用。你可以实时应用模型，也可以在线下预计算模型，并把结果保存好。比如对网页预分类，然后在表格里保存结果。但有的任务可能需要对实时聊天信息进行分类。 选择简单的特征更容易保证： 这些特征正确应用于学习算法 模型学会合理的权重。 这些特征正确应用于服务器模型。 当你有了能可靠做到上述三点的系统，大部分的工作就已完成。简单模型提供给你基础的指标和行为，然后你可以用它们来测试更复杂的模型。有些团队把目标定为“中性”的首发——故意在首次发布不那么重视机器学习成果，以避免分心。 测试基础设施要与 ML 测试分开 要确保基础设施可测试，而且系统的学习部分都被包含在内，使得你能够测试所有相关物。特别是： 测试把数据导入算法。检查可填充的特征栏是不是空的。若条件允许，手工检查训练算法的输入。若可能，把流水线数据与其他地方作比较，比如 RASTA。 测试把数据导出训练算法。确保训练环境的模型与服务环境（serving environment）的模型产生同样的得分（详见第 37 条）。 ML 有不可预测的因素。所以一定要对生成训练、服务样例的代码进行测试；这样你可以在服务中载入、使用固定模型。另外，理解你的数据也十分重要。 复制流水线时当心数据遗落 我们经常复制现成的流水线来创建新流水线（例如 cargo cult 编程），但有时旧流水线遗落了新流水线需要的数据。举个例子， Google Plus What’s Hot（雷锋网按：社交软件 Google+ 的热门新闻版块） 的流水线会遗落旧帖子（因为它试图为新帖子排名）。我们复制该流水线，用于 Google Plus Stream（Google+ 流）。对于后者，旧帖子仍然有意义，但新流水线仍然会丢掉数据。 另一个常见的模式是只记录用户看过的数据。因此，当你需要对为什么用户没有看到某个信息进行建模，该数据完全没用——因为所有反例已经被丢掉了。Google Play 发生过一个类似的问题：当我们开发 Google Play 应用商城主页时，创建出的新流水线包含另外两个登录页面（Play Games Home and Play Home Home，游戏主页和家庭主页）的样例。但是，并没有能够对“样例来自于哪个主页”加以区分的特征。 把启发式（heuristics）变为特征，不然就对它们做外部处理 通常来讲，ML 试图解决的问题并不是什么新问题——一般有现成的排名、分类等各种系统。这意味着有一大堆规则和启发式算法可用。这些启发式能在你调整 ML 时起到帮助。你应该压榨出启发式算法的所有信息，这有两个原因：1. 到 ML 系统的过渡会更顺畅。2. 这些规则通常包含一大堆关于系统的直觉信息，你绝对不想把它们扔掉。有四种利用现成启发式算法的途径： 使用启发式算法预处理。如果该特征非常棒，那么这就是一个选择。举个垃圾邮件过滤器的例子，若发件人已经被加入黑名单，不要试图重新学习“加入黑名单”是啥意思。直接拦截该信息。该方法最适用于二分类任务。 创建特征。直接用启发式创建特征相当棒。比如说，如果你用启发式计算一个问题结果的相关度分值，你可以把该得分作为特征值。之后，你或许想用 ML 技术来操作数值（比如把数值转化为有限个独立值集合，或与其他特征合并），但却拿启发式生成的原始数值来开头。 挖掘启发式的原始输入。如果有面向 APP 的启发式把装机量、文字中字母数目和日期组合到一起，就得考虑把它们分开——把这些输入分开来学习。有些应用于整体的技巧可用在这里（详见第 40 条）。 修正标记。当你发现启发式抓取了标记中未包含的信息时，这是一个选择。举个例子，如果你试图最大化下载量，但却仍然想要高品质内容，那么或许最好的方案是把标记与 APP 的平均星星得分相乘。这里有很大的余地。请参考“2.3 你的第一个目标”部分。 请注意启发式为 ML 系统加入的复杂度。在新 ML 算法中加入旧启发式有助于平滑地过渡，但你需要考虑是否更简单的实现方式。 2.2 监测 总的来讲，养成处理警告（alerts）的好习惯，比如对每个提醒付诸行动，并且建立一个仪表页面（dashboard page）。 了解系统的时效性 当你的模型已经开发出来一天、一周、一季度了，它的效果分别会降低多少？该信息能帮助你理解维护任务的优先级。假设模型一天没更新，你就要损失 10% 的收入。那么你或许要考虑雇佣专人每天维护。许多广告服务系统每天都有需要处理的新广告，因此必须每日更新。再举一个例子，如果 Google Play 的搜索 ML 模型停止更新，一个月内就会造成很大的损失。Google+ What’s Hot（雷锋网注：热门推荐）的一些模型，并没有针对发布信息的身份确认机制，所以不需要频繁导出这些模型。但有身份确认机制的模型就需要非常频繁地更新。另外需注意，时效性会随时间而变化，尤其是为模型添加或移除特征栏的时候。 在输出模型之前发现问题 许多 ML 系统包含该步骤：输出模型到服务端。如果输出的模型有问题，会直接让用户们遇上。而这个环节之前的问题只是训练问题，不会影响用户体验。 在导出模型之前一定要检查，尤其要确保模型在给定数据上有合理的效果。另外，若你对数据有顾虑，不要输出该模型。许多开发团队会在模型输出前检查 ROC 曲线 (或 AUC) 下的区域。未输出的模型存在问题，可能只需要一封 email 提醒一下。但用户端模型出了问题，很可能需要你向上司、同事解释一整页。所以最好多花点时间，在影响到用户之前做到胸有成竹。 于无声处听惊雷：注意没表现出来的故障 这是一个多见于机器学习、而少见于其他系统的问题。设想一个不再更新的特定表格：机器学习系统会调整，其行为仍会有合理表现，但逐渐退化。有时候开发者会发现过期几个月的表格——这时，一个简单的更新所提高的性能，比该季度的所有发布新版本都要高。举个例子，对一个特征的取舍会因为执行情况的变化而变化：覆盖 90% 样例的特征栏可能突然降低到只覆盖 60%。Google Play 曾经就有一个过期了六个月的表格，单单更新那个表格就带来了 2% 的安装率提升。如果你对统计数据进行跟踪，并偶尔人工检查，就能减少这类失误。 注意特征栏的维护者和文件 如果系统很大、有许多特征栏，你需要知道谁创立、维护了每一个特征栏。如果你发现懂得特征栏的那个人要跳槽了，一定要确保团队里有还有人知道这些信息。虽然许多特征栏有描述名称，你仍然需要更详细的解释，知道它是什么、从哪里来、起什么作用。 2.3 你的第一个目标 你有许多关心的系统指标或度量，但 ML 算法通常只需要一个目标——算法试图优化的某个数字。这里，我要区别目标（objectives）和指标（metrics）：指标是系统报告的任何数字，或许重要，或许不重要。详见第二条。 选择直接优化哪个目标时，不需要想太多 你想要赚钱，让用户满意，并且让地球更美好。有许多你关心的指标，你应该全部都去测量（见第二条）。但在 ML 初期，你会注意到它们全都有提升，即便是那些没有直接优化的也是如此。举个例子，假设你关注点击数、浏览时间和每日活跃用户。如果你优化点击数，你会看到浏览时间也在上升。 所以简简单单就好。当你能轻易地提高所有指标，不需要在不同指标之间的平衡上想太多。但也不要误解这条建议：别把目标与系统最终的健康混为一谈（详见第 39 条）。另外，如果你增加了直接优化的指标，但决定不予发布，或许有必要重新修订目标。 选择一个简单、可观察并且可归属（attributable）的指标来作为第一个目标 很多情况下你不知道真正的目标是什么——你以为你知道。但当你仔细观察数据，以及对旧系统和新 ML 系统进行分析，你意识到自己其实想要对原定目标进行修改。团队不同成员也经常无法在真正的目标上取得一致意见。ML 目标应当易于测量，并可作为“真正”目标的代理。所以最好采用简单的 ML 目标训练，然后考虑在这之上设一个 “policy layer”（规则层），允许你加入额外的逻辑（但愿是简单的逻辑）来做最终排名。 最容易建模的是，能被直接观察到、并且可归属于系统中某个行动的用户行为： 这个排名链接被点击了吗? 这个排名对象被下载了吗？ 这个排名对象被 转发/回复/发 email 了吗？ 这个排名对象被打分了吗？ 这个显示的对象被标记为垃圾邮件/色情信息/侮辱性信息了吗？ 一开始要避免对间接作用建模： 用户在第二天访问了吗？ 用户的访问时间是多长？ 每日活跃用户都是谁？ 其实，间接作用是非常不错的指标，并且可在 A/B 测试和发布决定中使用。 最后，不要试图让 ML 搞懂： 用户对使用该产品满意吗? 用户对体验满意吗？ 产品提升了用户的福祉了吗？ 这如何影响公司的整体健康？ 这些都很重要，但是极度困难。你应该用代理来替代：如果用户感到开心，他们会在页面停留更长时间。如果用户满意，他明天会再次访问。目前，当涉及到福祉和公司健康状态，把 ML 目标与产品本质和商业计划之间做关联需要人的判断。 用可解释的模型开头，修补漏洞会更简单 线性回归、逻辑回归、泊松回归（Poisson regression）直接被概率模型驱动，每个预测都可作为概率或期望值解释。这使得相比使用了目标、直接优化分类精度或排序效果的模型（zero­one 损失、各种 hinge 损失等等），它们修补漏洞更加简单。如果通过对比或检查产品系统，发现训练里的概率偏离了预测概率，就可能存在问题。 比如说，在线性回归、逻辑回归、泊松回归之中，有的数据子集里平均预期和平均标签相等（1-­moment 校准，或者普通校准 ）。对于一个值要么是 0 要么是 1 的特征，三个特征值为 1 的样例集就会被校准。同样地，若某特征下所有样例的特征值都是 1，它们都会被校准。 对于简单的模型，处理反馈回路（ feedback loops ）更加容易。我们经常用这些概率预期来做决定：比如以期望值（点击概率/下载量等）为标准对发布消息进行降序排列。但要记住，当决定采用那个模型的时候，你的决定比给定模型数据的可能性（ the likelihood of the data given the model ）更加重要（参考第 21 条）。 用 policy layer（规则层）把垃圾信息过滤和质量排序分来 质量排序是一门高雅的艺术，而垃圾信息过滤是一场战争。对于使用你系统的人，你用来判断高质量消息的信号十分显而易见。然后，他们会据此调整他们的发布信息来获得这些属性。因此，你的质量排序应当专注于有信誉的内容——不应该让质量排序学习器退化到给垃圾信息高排名。同样的，重口味内容应当与质量排序分开。而垃圾信息过滤是另一回事了。你需要创建的特征会不断变化，对此要有心理准备。通常，你加入系统里的规则有些很显而易见（比如，若一个发布信息得到超过三个“垃圾信息”票数，不要恢复它）。任何学习到的模型需要至少每天更新。内容生产者的名誉会起到相当大的作用。 在某个层级，这两个系统的输出需要整合在一起。需要注意的是，在搜索结果里过滤垃圾信息，比过滤垃圾邮件要更加强力。 为了高质量的分类器而去除训练数据中的垃圾，已是行业标准。 3.0 机器学习第二阶段3.1 特征工程 在进行机器学习相关实践的第一阶段，你要关注的主要问题包括以下三个方面：一是将训练数据导入系统，二是确定系统的重点关注指标，三是保证底层基础设施的稳定可靠。当这三个问题都确认无误，即已经搭建了一个端到端的可稳定运行的系统，并且针对系统本身和其中的每个单元都经过了严格测试，这时就可以进入第二阶段了。 应该说，第二阶段将更容易取得成绩。这一阶段会有许多显著的特征（feature）被导入系统，因此，导入并以直观的方式组合这些特征，将是本阶段涉及的主要任务。另外，本阶段也更适合多位工程师协同工作，共同对此前导入的训练数据进行整合和处理，推动所有的指标（metric）在本阶段取得持续性的上升。 做好模型被推倒和重建的准备 不要指望从头到尾只使用一个模型，也不要指望着某一结点之后就不用重建模型了，模型的推倒和重建是机器学习过程中的必修课。另外，每加入一个新特性都必须考虑是否会拉低模型的运行效率。目前，许多团队每三个月或一年就会新建一个模型。这里我们总结了一般情况下引发模型重建的三大原因： 1) 增加新的特征 2) 打算重组旧的特征，或对旧模型正则化 3) 修订建模目标 无论如何，创建模型时多想想并没有什么坏处：例如检查训练数据是否有更合理的组织形式，考虑当前的建模方式是否便于特征的修改和重组，当前的机器学习流水线（pipeline）是否便于创建副本并检验其正确率，以及是否可以创建两到三个副本并行运行等等。最后需要指出的是，并不一定非要在一个机器学习流水线中覆盖所有特征，在下一个版本中实现也是可行的。 直接以观察到的或报告的特征开始训练，而不是经过学习的特征 这一点建议或许存在一些争议，但的确能避免许多潜在的问题。这里经过学习的特征（learned feature）是指由外部系统（例如无监督的聚类系统）或模型本身（例如通过深度学习和因子模型）产生的特征。这两种情况虽然的确可以使用，但并不适合系统的第一个模型。 首先，在使用外部系统创建特征时必须要格外小心。因为外部系统的目标可能与当前系统并不相符，而且从外部系统更新当前系统的特征，其特定的含义也可能改变。 另一方面，因子模型和深度模型的主要问题是它们是非凸的（non-convex），因此它们无法保证可以最终找到或近似找到最优解，它们在每次迭代中产生的局部最小值都可能变化，而且目前无法评估这种变化对系统的影响是有益的还是有害的。通过创建没有深度特征的模型，你就可以获得很好的基准性能。在实现这一基准性能之后，你可以尝试更高阶的方法。 从不同的上下文环境中提取特征 通常情况下，机器学习只占到一个大系统中的很小一部分，因此你必须要试着从不同角度审视一个用户行为。比如热门推荐这一场景，一般情况下论坛里“热门推荐”里的帖子都会有许多评论、分享和阅读量，如果利用这些统计数据对模型展开训练，然后对一个新帖子进行优化，就有可能使其成为热门帖子。另一方面，YouTube上自动播放的下一个视频也有许多选择，例如可以根据大部分用户的观看顺序推荐，或者根据用户评分推荐等。总之，如果你将一个用户行为用作模型的标记（label），那么在不同的上下文条件下审视这一行为，可能会得到更丰富的特征（feature），也就更利于模型的训练。需要注意的是这与个性化不同：个性化是确定用户是否在特定的上下文环境中喜欢某一内容，并发现哪些用户喜欢，喜欢的程度如何。 尽量选择更具体的特征 在海量数据的支持下，即使学习数百万个简单的特征也比仅仅学习几个复杂的特征要容易实现。由于被检索的文本标识与规范化的查询并不会提供太多的归一化信息，只会调整头部查询中的标记排序。因此你不必担心虽然整体的数据覆盖率高达90%以上，但针对每个特征组里的单一特征却没有多少训练数据可用的情况。另外，你也可以尝试正则化的方法来增加每个特征所对应的样例数。 以合理的方式组合、修改现有的特征 目前有多种方法组合、修改现有的特征，由于本文以Google工具为背景，因此在这里推荐两种TensorFlow框架已实现好的方法：“离散化”（discretizations）和“交叉”（crosses）。 离散化主要包含提取连续特征和从连续特征中创建离散特征两个部分。比如对于年龄这一连续的特征，你就可以创建这样的离散特征：当年龄小于18时结果为1，或者当年龄介于18-35之间时为1，等等。另外，不要过分考虑直方图中基本分位数的问题。 在TensorFlow的术语中，特征栏是一组相似的特征，比如{男性，女性}，{美国，加拿大，墨西哥}等。这里的交叉是指将两个或多个特征栏合并，例如{男性，女性}×{美国，加拿大，墨西哥}的结果就是一个交叉（a cross），也就构成了一个新的特征栏。假设你利用TensorFlow框架创建了这样一个交叉，其中也就包含了{男性，加拿大}的特征，因此这一特征也就会出现在男性加拿大人的样例中。需要注意的是，交叉方法中合并的特征栏越多，所需要的训练数据量就越大。 如果通过交叉法生成的特征栏特别庞大，那么就可能引起过拟合。例如，假设你正在进行某种搜索，并且在查询请求和文档中都具有一个包含关键字的特征栏。那么假如你选择用交叉法组合这两个特征栏，这样得到的新特征栏就会非常庞大，它内部包含了许多特征。当这种情况发生在文本搜索场景时，有两种可行的应对方法。最常用的是点乘法（dot produc），点乘法最常见的处理方式就是统计查询请求和文档中共同的所有特征词，然后对特征离散化。另一个方法是交集（intersection），比如当且仅当关键词同时出现在文档和查询结果中时，我们才能获取所需的特征。 通过线性模型学到的特征权重的数目，大致与数据量成正比 许多人都认为从一千个样例中并不能得到什么可靠的训练结果，或者由于选择了某种特定的模型，就必须获取一百万个样例，否则就没法展开模型训练。这里需要指出的是，数据量的大小是和需要训练的特征数是正相关的： 1) 假如你在处理一个搜索排名问题，文档和查询请求中包含了数百万个不同的关键词，并且有一千个被标记的样例，那么你应该用上文提到的点乘法处理这些特征。这样就能得到一千个样例，对应了十几个特征。 2) 如你有一百万个样例，那么通过正则化和特征选择的方式就可以交叉处理文档和查询请求中的特征栏，这可能会产生数百万的特征数，但再次使用正则化可以大大减少冗余特征。这样就可能得到一千万个样例，对应了十万个特征。 3) 如果你有数十亿或数百亿个样例，那同样可以通过特征选择或正则化的方法交叉处理文档和查询请求中的特征栏。这样就可能得到十亿个样例，对应了一千万个特征。 对特征数和样例来说，这些统计学上的结论并不能给出一个具体的比例关系，但却可以从数量级上给出一些指导。另外，这里推荐用户依照第28条建议来选择具体使用哪些特征。 清理不需要的特征 如果你发现有些特征并没有在使用，而且将其与其他特征相结合之后也无法使用的话，就应该清理这些特征。应该保持系统的清洁，这样才能尽快尝试那些最有希望出结果的特征。而且，如果有必要，被删除的特征也可以随时找人加回来。 在考虑增删一个特征时，应该仔细排查其覆盖范围。例如你有一些个性化的特征，但只有大约8%的用户使用了该特征，那么删掉或添加这个特征就不会有太大影响。 另一方面，增删特征时也要考虑其对应的数据量。例如你有一个只覆盖了1%数据的特征，但有90%的包含这一特征的样例都通过了训练，那么这就是一个很好的特征，应该添加。 3.2 对系统的人工分析 在进入机器学习实践的第三阶段之前，关注一些课堂上不曾教授的问题也同样至关重要，比如如何检查一个模型并改进它。要说这一点是一门科学，反而不如说它是一种艺术，这里我们介绍几点反面模式（anti-patterns）。 你并不是一个典型的用户 这可能是让一个团队陷入困境的最简单的方法。虽然fishfooding（只在团队内部使用原型）和dogfooding（只在公司内部使用原型）都有许多优点，但无论哪一种，开发者都应该首先确认这种方式是否符合性能要求。另一方面，应该尽量避免不好的变化，但任何看起来合理的产品策略都应该被进一步验证，例如通过非专业人士在众包平台上的问卷调查，或者请目标用户来实测。 走外部验证渠道的原因来自两个方面：一是作为开发者，你太熟悉代码。例如你可能正在分析数据的某一方面而非全局，或者投入了太多的个人感情色彩，从而引发一些偏见。二是几位工程师开一个小时的讨论会议得到的评估结果，可能远比不上直接交给众包平台来得简单和有效。 如果你真的想要获取用户反馈，那么应该采用用户体验法（user experience methodologies）。 在流程早期创建用户角色（详情见Bill Buxton的《Designing User Experiences》一书），然后进行可用性测试（详情见Steve Krug的《Do not Make Me Think》一书）。这里的用户角色涉及创建假想用户。例如，假设你的团队成员都是男性，现在要针对35岁女性用户研发一款产品，那么基于目标群体创建一个假想角色，肯定比几位25-40岁的男性开发者闭门造车的效果要好。当然，让用户实测产品并观察他们的反应也是很不错的方法。 版本之间存在对等差分（symmetric difference） 将产品交付至用户之前，有时候最简单有效的做法就是评估当前版本与交付版本的差异。例如面对排名问题，你可以在两个版本间利用同一组样例进行测试，然后对比其结果。如果差异很小，那么意味着这个版本没问题。如果差异很大，那么就需要确认进行了哪些修改，为什么进行这些修改。通过查看哪些测试样例造成了这一差异，也有助于定性了解修改具体是怎样的。总之，目标是确保不同版本的模型之间的对等差分做到最小。 选择模型时，性能胜过预测能力 你的模型可能会被用来预测点击率，但更关键问题是：这种预测是应用在什么场景的。如果你用它来排列文档，那么最终排名的质量显然比预测本身更重要。如果你用它来排查垃圾邮件，那么识别精度显然更重要。大多数情况下，这两类功能应该是一致的，如果他们存在不一致，则意味着系统可能存在某种小增益。因此，假如一个改进措施可以解决日志丢失的问题，但却造成了系统性能的下降，那就不要采用它。当这种情况频繁发生时，通常应该重新审视你的建模目标。 从误差中查找新模式、创建新特征 假设你的模型在某个样例中预测错误。在分类任务中，这可能是误报或漏报。在排名任务中，这可能是一个正向判断弱于逆向判断的组。但更重要的是，在这个样例中机器学习系统知道它错了，需要修正。如果你此时给模型一个允许它修复的特征，那么模型将尝试自行修复这个错误。 另一方面，如果你尝试基于未出错的样例创建特征，那么该特征将很可能被系统忽略。例如，假设在谷歌Play商店的应用搜索中，有人搜索“免费游戏”，但其中一个排名靠前的搜索结果却是一款其他App，所以你为其他App创建了一个特征。但如果你将其他App的安装数最大化，即人们在搜索免费游戏时安装了其他App，那么这个其他App的特征就不会产生其应有的效果。 所以，正确的做法是一旦出现样例错误，那么应该在当前的特征集之外寻找解决方案。例如，如果你的系统降低了内容较长的帖子的排名，那就应该普遍增加帖子的长度。而且也不要拘泥于太具体的细节。例如你要增加帖子的长度，就不要猜测长度的具体含义，而应该直接添加几个相关的特征，交给模型自行处理，这才是最简单有效的方法。 尝试量化观察到的异常行为 有时候团队成员会对一些没有被现有的损失函数覆盖的系统属性感到无能为力，但这时抱怨是没用的，而是应该尽一切努力将抱怨转换成实实在在的数字。例如，当有些开发者认为在谷歌Play商店的搜索结果中显示了过多的其他App，就可以选择人工识别的方法剔除这些App（这时是可以选择人工标记数据的，因为相对较小的App查询可能占了很大一部分流量）。首先要确认你的问题是可量化的，然后才可以根据这些问题创建新的特征（features）、目标（objectives）或者指标（metrics）。总之规则是：先量化，再优化。 注意短期行为和长期行为的差别 假设你有一个新系统，它可以查看每个doc_id和exact_query，然后根据每个文档的每次查询行为计算其点击率。你发现它的行为几乎与当前系统的并行和A/B测试结果完全相同，而且它很简单，于是你启动了这个系统。但却没有新的应用显示，为什么？由于你的系统只基于自己的历史查询记录显示文档，所以不知道应该显示一个新的文档。 要了解一个系统在长期行为中如何工作的唯一办法，就是让它只基于当前的模型数据展开训练。这一点非常困难。 3.3 训练服务的偏差（Training­-Serving Skew） 这里训练服务偏差是指系统在训练时的性能表现和服务中的性能表现出现差别。造成这种差别的原因可能有如下三个方面： 1) 在训练和服务中的数据处理流水线不同； 2) 在训练和服务中使用了不同的数据； 3) 模型和算法间的反馈回路引起。 我们注意到谷歌的机器学习系统也存在训练服务偏差，而且会对性能产生负面影响。这里需要说明的是：最好的解决办法就是明确地监视它，使系统和数据的改变不至于引发潜在的偏差。 确保训练和服务一样好的最直接办法是：保存服务时使用的特征，然后将这些特征导入日志，以便在训练中使用 即使你不能对每个样例都这样做，做一小部分也比什么也不做好，这样你就可以验证服务和训练之间的一致性（见规则37）。在谷歌采取了这项措施的团队有时候会对其效果感到惊讶。比如YouTube主页在服务时会切换到日志记录特征，这不仅大大提高了服务质量，而且减少了代码复杂度。目前有许多团队都已经在其基础设施上采用了这种策略。 重视采样数据 当数据太多时，有些团队可能会选择丢弃一部分以减轻负担。这是一个明显的错误：历史经验证明在训练过程中丢弃数据将引发一系列问题（详见规则6）。当然，有时候的确可以丢弃数据，比如那些从未向用户显示过的，但重要性加权却是更好的选择。重要性加权意味着，如果你决定以30%的概率对样例X进行抽样，则权重应该是3/10。值得一提的是，使用重要性加权并不影响规则14中讨论的校准属性。 注意表格中的数据可能改变 假设你通过包含文件特征的表格（表格中还可能包含评论或点击的次数）加入文件的ID信息，那么需要注意表格中的特征可能会在训练和服务的不同时间点发生一些变化，造成模型对同一文档的预测也跟着改变。避免此类问题的最简单方法是在服务时记录特征（请参阅规则32）。如果表格的变化足够缓慢的话，你可以每天或每小时都记录一次表格以获得非常接近的数据，但需要注意的是，这并不能完全解决问题。 尽量在训练和服务流水线中复用代码 首先需要明确的一点是：批处理与在线处理不同。在线处理中，你必须在每个请求到达时及时处理（例如必须为每个查询单独查找）；而在批处理中，你可以组合任务（例如建立联结）。类似的，可以将服务视为在线处理过程，而训练视为批处理过程，而其中有许多代码是可以复用的。比如说，你可以创建特定于系统的对象，其中的所有联结和查询结果都以人类可读的方式存储，错误也可以被简单地测试。然后，一旦在服务或训练期间收集了所有信息，你就可以通过一种通用方法在这个特定对象和机器学习系统需要的格式之间形成互通，训练和服务的偏差也得以消除。另外，由此推知：最好不要在训练和服务期间使用不同的编程语言（因为不同的语言间几乎无法复用）。 训练和测试的数据不能相同 一般来说，最好用不同的数据对模型进行训练和测试，例如你用1月5日之前的数据训练了一个模型，那么最好用1月6日之后的数据对模型展开测试。可能模型对新数据的性能表现不如训练数据，但也不会太糟。由于可能会产生每日效应（daily effects），因此你可能无法预测平均点击率或转化率，但曲线下方的面积（表示正面样例的分数高于反面样例的可能性）应该是接近的。 在二进制分类过滤的应用场景中（例如垃圾邮件检测），不要为了纯净的数据做太大的性能牺牲 一般在过滤应用场景中，反面样例并不会对用户展示。不过假如你的过滤器在服务过程中阻止了75%的反面样例，那么你可能需要从向用户显示的实例中提取额外的训练数据并展开训练。比如说，用户将系统认可的邮件标记为垃圾邮件，那么你可能就需要从中学习。 但这种方法同时也引入了采样偏差。如果改为在服务期间将所有流量的1%标记为“暂停”，并将所有这样的样例发送给用户，那你就能收集更纯净的数据。现在你的过滤器阻止了至少74％的反面样例，这些样例可以成为训练数据。 需要注意的是，如果你的过滤器阻止了95%或更多的反面样例，那这种方法可能就不太适用。不过即使如此，如果你想衡量服务的性能，可以选择做出更细致的采样（例如0.1%或0.001%），一万个例子足以准确地估计性能。 注意排序问题的固有偏差 当你彻底改变排序算法时，一方面会引起完全不同的排序结果，另一方面也可能在很大程度上改变算法未来可能要处理的数据。这会引入一些固有偏差，因此你必须事先充分认识到这一点。以下这些方法可以有效帮你优化训练数据。 1) 对涵盖更多查询的特征进行更高的正则化，而不是那些只覆盖单一查询的特征。这样，模型将偏好于那些基于一个或几个特定查询的特征，而不是所有的特征。这种方式可以有效防止那些最常见的查询结果泄漏到不相关的查询中。需要注意的是，这与一条更传统的建议相左：更多地正则化一些具有单一值的特征栏。 2) 只允许特征具有正向权重，这样一来就能保证任何好特征都会比未知特征合适。 3) 不要选择那些只处理文档数据的特征。例如，不管搜索请求是什么，即使一个给定的应用程序是当前的热门下载，你也不会想在所有地方都显示它。没有文档特征的话，这一点会很容易做到。 避免具有位置特征的反馈回路 内容的位置会显著影响用户与它交互的可能性。很明显，如果你把一个App置顶，那它一定会更频繁地被点击。处理这类问题的一个有效方法是加入位置特征，即关于页面中的内容的位置特征。假如你用正向特征来训练模型，那模型就会更偏向“1st-position”这类的特征。因而模型对其他因素的权重就会相应地减小，例如对“1st-position = true”这种样例。在服务的时候，你可以选择不提供任何位置特征的实例，或者为所有位置特征设置相同的初始值，因为在决定以怎样的顺序显示它们之前，你具有决策权。 需要注意的是，因为训练和测试的不对称性，所以最好在一些位置特征和模型之间保持一定的分离性，这一点很重要。让模型成为位置特征函数和其他特征函数的和，是理想的状态。比如说，最好不要交叉任何文档特征和位置特征。 测量训练/服务偏差 许多情况都会引起偏差，但它们大多可以分为如下三类： 1) 训练数据和测试数据的性能之间的差异。一般来说，这总是存在的，但并不会太严重。 2) 测试数据的性能与“第二天数据”（next-day data）之间的差异。同样，这也会一直存在。你可以不同程度地正则化以最大限度地提高第二天的性能（next-day performance）。然而，如果在测试数据和第二天数据之间存在很大的性能下降，这有可能意味着某些特征是时间敏感的，而且整个模型的性能也会跟着下降。 3) “第二天数据”和实时数据的性能之间的差异。如果你将模型应用于训练数据的样例，也应用于相同的服务样例，则它们应该给出完全相同的结果（详见规则5）。因此，这里的差异可能是指工程误差。 4.0 机器学习第三阶4.1 减慢的增速，精细优化和复杂模型 第二阶段将要结束的时候，一定会有些信号。首先，你每月的收益开始降低。你开始要在指标之间做牺牲：一些试验中有的上升有的下降。从此情况变得更有趣。由于更难产生效益，机器学习不得不变得更复杂。 警告：这部分有许多开放式的实践法则。我们亲眼看着很多团队走过第一阶段和第二阶段的幸福期——一旦到达第三阶段，开发团队就不得不找出他们自己的路。 如果目标之间不搭，并成为问题，就不要在新特征上浪费时间 当达到度量瓶颈，你的团队开始关注 ML 系统目标范围之外的问题。如同之前提到的，如果产品目标没有包括在算法目标之内，你就得修改其中一个。比如说，你也许优化的是点击数、点赞或者下载量，但发布决策部分依赖于人类评估者。 模型发布决策是长期产品目标的代理 （雷锋网注：谷歌工程师在这里举了个例子）Alice 有一个关于降低安装预测的逻辑损失的想法。她加入一个特征。逻辑损失下降。当她实时测试时，安装量上升了。但在公司的发布会议上，有人指出每日活跃用户数降低了 5%。团队决定不发布该模型。Alice 很失望，但意识到发布决策取决于多个标准，其中只有一部分能够被 ML 直接优化。 事实是，现实世界并不是网络游戏：没有“攻击值”和“血量”来衡量产品的健康。团队需要利用收集的数据，来试图预测将来系统的表现会怎样。他们需要操心用户黏性、每日活跃用户、每月活跃用户、收入和广告主的收益。这些 A/B 测试中的指标，实际上只是长期目标的代理：让用户满意、增加用户、让合作方满意还有利润；即便这时你还可以考虑高品质、有使用价值的产品的代理，以及五年后一个繁荣的企业的代理。 做出发布决策变得容易的唯一一种情况是：所有指标都变好了（起码没有变差的）。如果团队在复杂 ML 算法和简单启发式算法之间有的选择；如果简单的启发式算法在这些指标上做得更好；那么应当选择后者。另外，所有指标数值并没有明确的排序。更具体的，考虑以下两种情形： 谷歌机器学习白皮书全解析 43条黄金法则（四） 雷锋网注：标题栏（自左至右）为试验，每日活跃用户以及每日收入 如果现有系统是 A ，团队不会想要转移到 B。如果现有系统是 B，团队也不会想要转到 A。这看起来与理性决策相抵触：但是，对指标变化的预期情形或许会发生，或许不会。因此任意一种改变都有相当大的风险。每一个指标覆盖了一些团队所关注的风险。但没有指标能覆盖团队的首要关切——“我的产品在五年后会怎样？” 另一方面，个体倾向于选择能直接优化的目标。大多数 ML 工具喜欢这样的环境。这样的环境下，一个能快速创建新特征的工程师能稳定输出一系列产品发布。有一种叫“多目标学习”（multi­objective learning）的机器学习开始解决这一问题。比如说，可以制定一个在每个指标上有下限的约束满意度问题（constraint satisfaction problem），然后优化指标的一些线性组合。但即便那时，也不是所有指标都能轻易表达为 ML 目标：如果一个文件被点击，或者 APP 被安装，这是因为有内容被展示出来。但搞清楚用户为什么访问你的页面就更加难了。如何预测一个页面在将来是否成功，是一项 AI­-complete 问题（雷锋网注：意味着完成它的难度相当于解决 AI 问题），与计算机视觉和自然语言处理一样难。 保证集成模型（ensemble）的简洁 接收原始特征、直接对内容排序的统一模型，是最容易理解、最容易修补漏洞的模型。但是，一个集成模型（一个把其他模型得分组合在一起的“模型”）的效果会更好。为保持简洁，每个模型应该要么是一个只接收其他模型的输入的集成模型，要么是一个有多种特征的基础模型，但不能两者皆是。如果你有单独训练、基于其它模型的模型，把它们组合到一起会导致不好的行为。 只用简单模型来集成：那些只把基础模型的输入作为输出、进行接收的模型。你或许想要为这些集成模型强加上属性。比如，基础模型生成得分的提高，不应该降低集成模型的分数。另外，如果连入模型在语义上可解释（比如校准了的）会更好，这样其下层模型不会与集成模型混淆。再者，强行让下层分类器预测的概率升高，不会降低集成模型的预测概率。 当性能达到瓶颈，相比精炼现存信号，不如寻找新性质（qualitatively）的信息源 你已经加入了一些关于用户的人口统计信息，还有文件中的词语。你经历了模板探索，和正则化（regularization）调参。但连续几个季度的发布，你都没有看到核心指标有超过 1% 的提升。现在怎么办？ 你已经到了为不同寻常（雷锋网注：很不一样）的特征，创建基础设施的时候了。比如用户昨天、上周、去年检索的文档，或是另一种属性的数据。为你的公司使用维基数据（wikidata）实体或者一些内部的东西（比如谷歌的知识图，Google’s knowledge graph）。你或许需要使用深度学习。开始调整你对投资回报的期望，并作出相应努力。如同所有工程项目，你需要平衡新增加的特征与提高的复杂度。 不要期望多样性、个性化、相关性和受欢迎程度之间有紧密联系 一系列内容的多样性能意味着许多东西，内容来源的多样性最为普遍。个性化意味着每个用户得到属于他们自己的结果。相关性意味着一个特定检索的结果，对应它比对应其他检索更合适。因此，这三个属性的定义都有别于“标准”。 但标准更难被打败。 注意：如果你的系统在统计点击量、耗费时间、浏览数、点赞数、分享数等等，你事实上在衡量内容的受欢迎程度。有团队试图学习具备多样性的个性化模型。为个性化，他们加入允许系统进行个性化的特征（有的特征代表用户兴趣），或者加入多样性（表示该文档与其它返回文档有相同特征的特征，比如作者和内容），然后发现这些特征比他们预想的得到更低的权重（有时是不同的信号）。 这不意味着多样性、个性化和相关性就不重要。如同上个法则所指出的，你可以通过后处理来提高多样性或相关性。如果你看到长期目标的进步，那么你可以宣布在受欢迎程度之外，多样性和相关性是有价值的。你可以继续采用后处理，或者直接根据多样性或相关性修改目标。 不同产品中，你的朋友总是同一个，你的兴趣不会如此 谷歌的 ML 团队 常常把一个预测某产品联系紧密程度（the closeness of a connection in one product）的模型，应用在另一个产品上，然后发现效果很好。另一方面，我见过好几个在产品线的个性化特征上苦苦挣扎的团队。是的，之前看起来它应该能奏效。但现在看来它不会了。有时候起作用的是——用某属性的原始数据来预测另一个属性的行为。即便知道某用户存在另一个属性能凑效的历史，也要记住这一点。比如说，两个产品上用户活动的存在或许就自身说明了问题。 全文结束。感谢您对雷锋网(公众号：雷锋网)的支持。 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"Awesome Machine Learning","date":"2017-02-19T15:56:06.000Z","path":"2017/02/19/SmartAI/ProgramAI/Resources/awesome-machine-learning/","text":"作者：Joseph Misiti/josephmisiti A curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by awesome-php. If you want to contribute to this list (please do), send me a pull request or contact me @josephmisitiAlso, a listed repository should be deprecated if: Repository’s owner explicitly say that “this library is not maintained”.Not committed for long time (2~3 years). For a list of free machine learning books available for download, go here. For a list of free-to-attend meetups and local events, go here. Table of Contents APLGeneral-Purpose Machine LearningCGeneral-Purpose Machine LearningComputer VisionC++Computer VisionGeneral-Purpose Machine LearningNatural Language ProcessingSequence AnalysisGesture RecognitionCommon LispGeneral-Purpose Machine LearningClojureNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationElixirGeneral-Purpose Machine LearningNatural Language ProcessingErlangGeneral-Purpose Machine LearningGoNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationHaskellGeneral-Purpose Machine LearningJavaNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationDeep LearningJavascriptNatural Language ProcessingData Analysis / Data VisualizationGeneral-Purpose Machine LearningMiscJuliaGeneral-Purpose Machine LearningNatural Language ProcessingData Analysis / Data VisualizationMisc Stuff / PresentationsLuaGeneral-Purpose Machine LearningDemos and ScriptsMatlabComputer VisionNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data Visualization.NETComputer VisionNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationObjective CGeneral-Purpose Machine LearningOCamlGeneral-Purpose Machine LearningPHPNatural Language ProcessingGeneral-Purpose Machine LearningPythonComputer VisionNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationMisc Scripts / iPython Notebooks / CodebasesKaggle Competition Source CodeNeural networksRubyNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationMiscRustGeneral-Purpose Machine LearningRGeneral-Purpose Machine LearningData Analysis / Data VisualizationSASGeneral-Purpose Machine LearningData Analysis / Data VisualizationHigh Performance Machine Learning (MPP)Natural Language ProcessingDemos and ScriptsScalaNatural Language ProcessingData Analysis / Data VisualizationGeneral-Purpose Machine LearningSwiftGeneral-Purpose Machine LearningTensorFlowGeneral-Purpose Machine LearningCredits APL General-Purpose Machine Learning naive-apl - Naive Bayesian Classifier implementation in APL C General-Purpose Machine Learning Darknet - Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation. Recommender - A C library for product recommendations/suggestions using collaborative filtering (CF). Hybrid Recommender System - A hybrid recomender system based upon scikit-learn algorithms. Computer Vision CCV - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library VLFeat - VLFeat is an open and portable library of computer vision algorithms, which has Matlab toolbox Speech Recognition HTK -The Hidden Markov Model Toolkit (HTK) is a portable toolkit for building and manipulating hidden Markov models. C++ Computer Vision DLib - DLib has C++ and Python interfaces for face detection and training general object detectors. EBLearn - Eblearn is an object-oriented C++ library that implements various machine learning models OpenCV - OpenCV has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS. VIGRA - VIGRA is a generic cross-platform C++ computer vision and machine learning library for volumes of arbitrary dimensionality with Python bindings. General-Purpose Machine Learning BanditLib - A simple Multi-armed Bandit library. Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind. [DEEP LEARNING] CNTK - The Computational Network Toolkit (CNTK) by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph. CUDA - This is a fast C++/CUDA implementation of convolutional [DEEP LEARNING] CXXNET - Yet another deep learning framework with less than 1000 lines core code [DEEP LEARNING] DeepDetect - A machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications. Disrtibuted Machine learning Tool Kit (DMTK) - A distributed machine learning (parameter server) framework by Microsoft. Enables training models on large data sets across multiple machines. Current tools bundled with it include: LightLDA and Distributed (Multisense) Word Embedding. DLib - A suite of ML tools designed to be easy to imbed in other applications DSSTNE - A software library created by Amazon for training and deploying deep neural networks using GPUs which emphasizes speed and scale over experimental flexibility. DyNet - A dynamic neural network library working well with networks that have dynamic structures that change for every training instance. Written in C++ with bindings in Python. encog-cpp Fido - A highly-modular C++ machine learning library for embedded electronics and robotics. igraph - General purpose graph library Intel(R) DAAL - A high performance software library developed by Intel and optimized for Intel’s architectures. Library provides algorithmic building blocks for all stages of data analytics and allows to process data in batch, online and distributed modes. LightGBM - Microsoft’s fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks. MLDB - The Machine Learning Database is a database designed for machine learning. Send it commands over a RESTful API to store data, explore it using SQL, then train machine learning models and expose them as APIs. mlpack - A scalable C++ machine learning library Regularized Greedy Forest - Regularized greedy forest (RGF) tree ensemble learning method. ROOT - A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualization and storage. shark - A fast, modular, feature-rich open-source C++ machine learning library. Shogun - The Shogun Machine Learning Toolbox sofia-ml - Suite of fast incremental algorithms. Stan - A probabilistic programming language implementing full Bayesian statistical inference with Hamiltonian Monte Carlo sampling Timbl - A software package/C++ library implementing several memory-based learning algorithms, among which IB1-IG, an implementation of k-nearest neighbor classification, and IGTree, a decision-tree approximation of IB1-IG. Commonly used for NLP. Vowpal Wabbit (VW) - A fast out-of-core learning system. Warp-CTC - A fast parallel implementation of Connectionist Temporal Classification (CTC), on both CPU and GPU. XGBoost - A parallelized optimized general purpose gradient boosting library. Natural Language Processing BLLIP Parser - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser) colibri-core - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way. CRF++ - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data &amp; other Natural Language Processing tasks. CRFsuite - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. frog - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer. libfolia - C++ library for the FoLiA format MeTA - MeTA : ModErn Text Analysis is a C++ Data Sciences Toolkit that facilitates mining big text data. MIT Information Extraction Toolkit - C, C++, and Python tools for named entity recognition and relation extraction ucto - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format. Speech Recognition Kaldi - Kaldi is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers. Sequence Analysis ToPS - This is an objected-oriented framework that facilitates the integration of probabilistic models for sequences over a user defined alphabet. Gesture Detection grt - The Gesture Recognition Toolkit (GRT) is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition. Common Lisp General-Purpose Machine Learning mgl - Neural networks (boltzmann machines, feed-forward and recurrent nets), Gaussian Processes mgl-gpr - Evolutionary algorithms cl-libsvm - Wrapper for the libsvm support vector machine library Clojure Natural Language Processing Clojure-openNLP - Natural Language Processing in Clojure (opennlp) Infections-clj - Rails-like inflection library for Clojure and ClojureScript General-Purpose Machine Learning Touchstone - Clojure A/B testing library Clojush - The Push programming language and the PushGP genetic programming system implemented in Clojure Infer - Inference and machine learning in clojure Clj-ML - A machine learning library for Clojure built on top of Weka and friends Encog - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets) Fungp - A genetic programming library for Clojure Statistiker - Basic Machine Learning algorithms in Clojure. clortex - General Machine Learning library using Numenta’s Cortical Learning Algorithm comportex - Functionally composable Machine Learning library using Numenta’s Cortical Learning Algorithm cortex - Neural networks, regression and feature learning in Clojure. lambda-ml - Simple, concise implementations of machine learning techniques and utilities in Clojure. Data Analysis / Data Visualization Incanter - Incanter is a Clojure-based, R-like platform for statistical computing and graphics. PigPen - Map-Reduce for Clojure. Envision - Clojure Data Visualisation library, based on Statistiker and D3 Elixir General-Purpose Machine Learning Simple Bayes - A Simple Bayes / Naive Bayes implementation in Elixir. Natural Language Processing Stemmer - An English (Porter2) stemming implementation in Elixir. Erlang General-Purpose Machine Learning Disco - Map Reduce in Erlang Go Natural Language Processing go-porterstemmer - A native Go clean room implementation of the Porter Stemming algorithm. paicehusk - Golang implementation of the Paice/Husk Stemming Algorithm. snowball - Snowball Stemmer for Go. go-ngram - In-memory n-gram index with compression. General-Purpose Machine Learning gago - Multi-population, flexible, parallel genetic algorithm. Go Learn - Machine Learning for Go go-pr - Pattern recognition package in Go lang. go-ml - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution bayesian - Naive Bayesian Classification for Golang. go-galib - Genetic Algorithms library written in Go / golang Cloudforest - Ensembles of decision trees in go/golang. gobrain - Neural Networks written in go GoNN - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. go-mxnet-predictor - Go binding for MXNet c_predict_api to do inference with pre-trained model Data Analysis / Data Visualization go-graph - Graph library for Go/golang language. SVGo - The Go Language library for SVG generation RF - Random forests implementation in Go Haskell General-Purpose Machine Learning haskell-ml - Haskell implementations of various ML algorithms. HLearn - a suite of libraries for interpreting machine learning models according to their algebraic structure. hnn - Haskell Neural Network library. hopfield-networks - Hopfield Networks for unsupervised learning in Haskell. caffegraph - A DSL for deep neural networks LambdaNet - Configurable Neural Networks in Haskell Java Natural Language Processing Cortical.io - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc…) as quickly and intuitively as the brain. CoreNLP - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words Stanford Parser - A natural language parser is a program that works out the grammatical structure of sentences Stanford POS Tagger - A Part-Of-Speech Tagger (POS Tagger Stanford Name Entity Recognizer - Stanford NER is a Java implementation of a Named Entity Recognizer. Stanford Word Segmenter - Tokenization of raw text is a standard pre-processing step for many NLP tasks. Tregex, Tsurgeon and Semgrex - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for “tree regular expressions”). Stanford Phrasal: A Phrase-Based Translation System Stanford English Tokenizer - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java. Stanford Tokens Regex - A tokenizer divides text into a sequence of tokens, which roughly correspond to “words” Stanford Temporal Tagger - SUTime is a library for recognizing and normalizing time expressions. Stanford SPIED - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion Stanford Topic Modeling Toolbox - Topic modeling tools to social scientists and others who wish to perform analysis on datasets Twitter Text Java - A Java implementation of Twitter’s text processing library MALLET - A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text. OpenNLP - a machine learning based toolkit for the processing of natural language text. LingPipe - A tool kit for processing text using computational linguistics. ClearTK - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA. Apache cTAKES - Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text. ClearNLP - The ClearNLP project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. This project is under the Apache 2 license. CogcompNLP - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois’ Cognitive Computation Group, for example illinois-core-utilities which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, illinois-edison a library for feature extraction from illinois-core-utilities data structures and many other packages. General-Purpose Machine Learning aerosolve - A machine learning library by Airbnb designed from the ground up to be human friendly. Datumbox - Machine Learning framework for rapid development of Machine Learning and Statistical applications ELKI - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.) Encog - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks. FlinkML in Apache Flink - Distributed machine learning library in Flink H2O - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON. htm.java - General Machine Learning library using Numenta’s Cortical Learning Algorithm java-deeplearning - Distributed Deep Learning Platform for Java, Clojure,Scala Mahout - Distributed machine learning Meka - An open source implementation of methods for multi-label classification and evaluation (extension to Weka). MLlib in Apache Spark - Distributed machine learning library in Spark Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services. Neuroph - Neuroph is lightweight Java neural network framework ORYX - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning. Samoa SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms. RankLib - RankLib is a library of learning to rank algorithms rapaio - statistics, data mining and machine learning toolbox in Java RapidMiner - RapidMiner integration into Java code Stanford Classifier - A classifier is a machine learning tool that will take data items and place them into one of k classes. SmileMiner - Statistical Machine Intelligence &amp; Learning Engine SystemML - flexible, scalable machine learning (ML) language. WalnutiQ - object oriented model of the human brain Weka - Weka is a collection of machine learning algorithms for data mining tasks LBJava - Learning Based Java is a modeling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer’s application. Speech Recognition CMU Sphinx - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library. Data Analysis / Data Visualization Flink - Open source platform for distributed stream and batch data processing. Hadoop - Hadoop/HDFS Spark - Spark is a fast and general engine for large-scale data processing. Storm - Storm is a distributed realtime computation system. Impala - Real-time Query for Hadoop DataMelt - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization. Dr. Michael Thomas Flanagan’s Java Scientific Library Deep Learning Deeplearning4j - Scalable deep learning for industry with parallel GPUs Javascript Natural Language Processing Twitter-text - A JavaScript implementation of Twitter’s text processing library NLP.js - NLP utilities in javascript and coffeescript natural - General natural language facilities for node Knwl.js - A Natural Language Processor in JS Retext - Extensible system for analyzing and manipulating natural language TextProcessing - Sentiment analysis, stemming and lemmatization, part-of-speech tagging and chunking, phrase extraction and named entity recognition. NLP Compromise - Natural Language processing in the browser Data Analysis / Data Visualization D3.js High Charts NVD3.js dc.js chartjs dimple amCharts D3xter - Straight forward plotting built on D3 statkit - Statistics kit for JavaScript datakit - A lightweight framework for data analysis in JavaScript science.js - Scientific and statistical computing in JavaScript. Z3d - Easily make interactive 3d plots built on Three.js Sigma.js - JavaScript library dedicated to graph drawing. C3.js- customizable library based on D3.js for easy chart drawing. Datamaps- Customizable SVG map/geo visualizations using D3.js. ZingChart- library written on Vanilla JS for big data visualization. cheminfo - Platform for data visualization and analysis, using the visualizer project. General-Purpose Machine Learning Convnet.js - ConvNetJS is a Javascript library for training Deep Learning models[DEEP LEARNING] Clusterfck - Agglomerative hierarchical clustering implemented in Javascript for Node.js and the browser Clustering.js - Clustering algorithms implemented in Javascript for Node.js and the browser Decision Trees - NodeJS Implementation of Decision Tree using ID3 Algorithm DN2A - Digital Neural Networks Architecture figue - K-means, fuzzy c-means and agglomerative clustering Node-fann - FANN (Fast Artificial Neural Network Library) bindings for Node.js Kmeans.js - Simple Javascript implementation of the k-means algorithm, for node.js and the browser LDA.js - LDA topic modeling for node.js Learning.js - Javascript implementation of logistic regression/c4.5 decision tree Machine Learning - Machine learning library for Node.js machineJS - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file! mil-tokyo - List of several machine learning libraries Node-SVM - Support Vector Machine for nodejs Brain - Neural networks in JavaScript [Deprecated] Bayesian-Bandit - Bayesian bandit implementation for Node and the browser. Synaptic - Architecture-free neural network library for node.js and the browser kNear - JavaScript implementation of the k nearest neighbors algorithm for supervised learning NeuralN - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training. kalman - Kalman filter for Javascript. shaman - node.js library with support for both simple and multiple linear regression. ml.js - Machine learning and numerical analysis tools for Node.js and the Browser! Pavlov.js - Reinforcement learning using Markov Decision Processes MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. Misc sylvester - Vector and Matrix math for JavaScript. simple-statistics - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in node.js. regression-js - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data. Lyric - Linear Regression library. GreatCircle - Library for calculating great circle distance. Julia General-Purpose Machine Learning MachineLearning - Julia Machine Learning library MLBase - A set of functions to support the development of machine learning algorithms PGM - A Julia framework for probabilistic graphical models. DA - Julia package for Regularized Discriminant Analysis Regression - Algorithms for regression analysis (e.g. linear regression and logistic regression) Local Regression - Local regression, so smooooth! Naive Bayes - Simple Naive Bayes implementation in Julia Mixed Models - A Julia package for fitting (statistical) mixed-effects models Simple MCMC - basic mcmc sampler implemented in Julia Distance - Julia module for Distance evaluation Decision Tree - Decision Tree Classifier and Regressor Neural - A neural network in Julia MCMC - MCMC tools for Julia Mamba - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia GLM - Generalized linear models in Julia Online Learning GLMNet - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet Clustering - Basic functions for clustering data: k-means, dp-means, etc. SVM - SVM’s for Julia Kernal Density - Kernel density estimators for julia Dimensionality Reduction - Methods for dimensionality reduction NMF - A Julia package for non-negative matrix factorization ANN - Julia artificial neural networks Mocha - Deep Learning framework for Julia inspired by Caffe XGBoost - eXtreme Gradient Boosting Package in Julia ManifoldLearning - A Julia package for manifold learning and nonlinear dimensionality reduction MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. Merlin - Flexible Deep Learning Framework in Julia ROCAnalysis - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers GaussianMixtures - Large scale Gaussian Mixture Models ScikitLearn - Julia implementation of the scikit-learn API Knet - Koç University Deep Learning Framework Natural Language Processing Topic Models - TopicModels for Julia Text Analysis - Julia package for text analysis Data Analysis / Data Visualization Graph Layout - Graph layout algorithms in pure Julia Data Frames Meta - Metaprogramming tools for DataFrames Julia Data - library for working with tabular data in Julia Data Read - Read files from Stata, SAS, and SPSS Hypothesis Tests - Hypothesis tests for Julia Gadfly - Crafty statistical graphics for Julia. Stats - Statistical tests for Julia RDataSets - Julia package for loading many of the data sets available in R DataFrames - library for working with tabular data in Julia Distributions - A Julia package for probability distributions and associated functions. Data Arrays - Data structures that allow missing values Time Series - Time series toolkit for Julia Sampling - Basic sampling algorithms for Julia Misc Stuff / Presentations DSP - Digital Signal Processing (filtering, periodograms, spectrograms, window functions). JuliaCon Presentations - Presentations for JuliaCon SignalProcessing - Signal Processing tools for Julia Images - An image library for Julia Lua General-Purpose Machine Learning Torch7 cephes - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy.autograd - Autograd automatically differentiates native Torch code. Inspired by the original Python version.graph - Graph package for Torchrandomkit - Numpy’s randomkit, wrapped for Torchsignal - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stftnn - Neural Network package for Torchtorchnet - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programmingnngraph - This package provides graphical computation for nn library in Torch7.nnx - A completely unstable and experimental package that extends Torch’s builtin nn libraryrnn - A Recurrent Neural Network library that extends Torch’s nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.dpnn - Many useful features that aren’t part of the main nn package.dp - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns.optim - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.unsup - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, …), and self-contained algorithms (k-means, PCA).manifold - A package to manipulate manifoldssvm - Torch-SVM librarylbfgs - FFI Wrapper for liblbfgsvowpalwabbit - An old vowpalwabbit interface to torch.OpenGM - OpenGM is a C++ library for graphical modeling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM.sphagetti - Spaghetti (sparse linear) module for torch7 by @MichaelMathieuLuaSHKit - A lua wrapper around the Locality sensitive hashing library SHKitkernel smoothing - KNN, kernel-weighted average, local linear regression smootherscutorch - Torch CUDA Implementationcunn - Torch CUDA Neural Network Implementationimgraph - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images.videograph - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos.saliency - code and tools around integral images. A library for finding interest points based on fast integral histograms.stitch - allows us to use hugin to stitch images and apply same stitching to a video sequencesfm - A bundle adjustment/structure from motion packagefex - A package for feature extraction in Torch. Provides SIFT and dSIFT modules.OverFeat - A state-of-the-art generic dense feature extractorNumeric LuaLunatic PythonSciLuaLua - Numerical AlgorithmsLunum Demos and Scripts Core torch7 demos repository. linear-regression, logistic-regressionface detector (training and detection as separate demos)mst-based-segmentertrain-a-digit-classifiertrain-autoencoderoptical flow demotrain-on-housenumberstrain-on-cifartracking with deep netskinect demofilter-bank visualizationsaliency-networksTraining a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)Music Tagging - Music Tagging scripts for torch7torch-datasets - Scripts to load several popular datasets including:BSR 500CIFAR-10COILStreet View House NumbersMNISTNORBAtari2600 - Scripts to generate a dataset with static frames from the Arcade Learning Environment Matlab Computer Vision Contourlets - MATLAB source code that implements the contourlet transform and its utility functions. Shearlets - MATLAB code for shearlet transform Curvelets - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles. Bandlets - MATLAB code for bandlet transform mexopencv - Collection and a development kit of MATLAB mex functions for OpenCV library Natural Language Processing NLP - An NLP library for Matlab General-Purpose Machine Learning Training a deep autoencoder or a classifieron MNIST digits - Training a deep autoencoder or a classifieron MNIST digits[DEEP LEARNING] Convolutional-Recursive Deep Learning for 3D Object Classification - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING] t-Distributed Stochastic Neighbor Embedding - t-Distributed Stochastic Neighbor Embedding (t-SNE) is a (prize-winning) technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. Spider - The spider is intended to be a complete object orientated environment for machine learning in Matlab. LibSVM - A Library for Support Vector Machines LibLinear - A Library for Large Linear Classification Machine Learning Module - Class on machine w/ PDF,lectures,code Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind. Pattern Recognition Toolbox - A complete object-oriented environment for machine learning in Matlab. Pattern Recognition and Machine Learning - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop. Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB. Data Analysis / Data Visualization matlab_gbl - MatlabBGL is a Matlab package for working with graphs. gamic - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL’s mex functions. .NET Computer Vision OpenCVDotNet - A wrapper for the OpenCV project to be used with .NET applications. Emgu CV - Cross platform wrapper of OpenCV which can be compiled in Mono to e run on Windows, Linus, Mac OS X, iOS, and Android. AForge.NET - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub. Accord.NET - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android. Natural Language Processing Stanford.NLP for .NET - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package. General-Purpose Machine Learning Accord-Framework -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications. Accord.MachineLearning - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework. DiffSharp - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization. Vulpes - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase. Encog - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks. Neural Network Designer - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feed back. The chat bots can even scrape the internet for information to return in their output as well as to use for learning. Data Analysis / Data Visualization numl - numl is a machine learning library intended to ease the use of using standard modeling techniques for both prediction and clustering. Math.NET Numerics - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and every day use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin. Sho - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development. Objective C General-Purpose Machine Learning YCML - A Machine Learning framework for Objective-C and Swift (OS X / iOS). MLPNeuralNet - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural network. It is built on top of the Apple’s Accelerate Framework, using vectorized operations and hardware acceleration if available. MAChineLearning - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it’s 20 times faster than its Java equivalent. Includes sample code for use from Swift. BPN-NeuralNetwork - It implemented 3 layers neural network ( Input Layer, Hidden Layer and Output Layer ) and it named Back Propagation Neural Network (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis. Multi-Perceptron-NeuralNetwork - it implemented multi-perceptrons neural network (ニューラルネットワーク) based on Back Propagation Neural Network (BPN) and designed unlimited-hidden-layers. KRHebbian-Algorithm - It is a non-supervisor and self-learning algorithm (adjust the weights) in neural network of Machine Learning. KRKmeans-Algorithm - It implemented K-Means the clustering and classification algorithm. It could be used in data mining and image compression. KRFuzzyCMeans-Algorithm - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression. OCaml General-Purpose Machine Learning Oml - A general statistics and machine learning library. GPR - Efficient Gaussian Process Regression in OCaml. Libra-Tk - Algorithms for learning and inference with discrete probabilistic models. PHP Natural Language Processing jieba-php - Chinese Words Segmentation Utilities. General-Purpose Machine Learning PHP-ML - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library. PredictionBuilder - A library for machine learning that builds predictions using a linear regression. Python Computer Vision Scikit-Image - A collection of algorithms for image processing in Python. SimpleCV - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux. Vigranumpy - Python bindings for the VIGRA C++ computer vision library. OpenFace - Free and open source face recognition with deep neural networks. PCV - Open source Python module for computer vision Natural Language Processing NLTK - A leading platform for building Python programs to work with human language data. Pattern - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others. Quepy - A python framework to transform natural language questions to queries in a database query language TextBlob - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both. YAlign - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora. jieba - Chinese Words Segmentation Utilities. SnowNLP - A library for processing Chinese text. spammy - A library for email Spam filtering built on top of nltk loso - Another Chinese segmentation library. genius - A Chinese segment base on Conditional Random Field. KoNLPy - A Python package for Korean natural language processing. nut - Natural language Understanding Toolkit Rosetta - Text processing tools and wrappers (e.g. Vowpal Wabbit) BLLIP Parser - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser) PyNLPl - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for FoLiA, but also ARPA language models, Moses phrasetables, GIZA++ alignments. python-ucto - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages) python-frog - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER) python-zpar - Python bindings for ZPar, a statistical part-of-speech-tagger, constiuency parser, and dependency parser for English. colibri-core - Python binding to C++ library for extracting and working with with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way. spaCy - Industrial strength NLP with Python and Cython. PyStanfordDependencies - Python interface for converting Penn Treebank trees to Stanford Dependencies. Distance - Levenshtein and Hamming distance computation Fuzzy Wuzzy - Fuzzy String Matching in Python jellyfish - a python library for doing approximate and phonetic matching of strings. editdistance - fast implementation of edit distance textacy - higher-level NLP built on Spacy stanford-corenlp-python - Python wrapper for Stanford CoreNLP General-Purpose Machine Learning auto_ml - Automated machine learning pipelines for analytics and production. Handles some standard feature engineering, feature selection, model selection, model tuning, ensembling, and advanced scoring, in addition to logging output for analysts trying to understand their datasets. machine learning - automated build consisting of a web-interface, and set of programmatic-interface API, for support vector machines. Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore. XGBoost - Python bindings for eXtreme Gradient Boosting (Tree) Library Bayesian Methods for Hackers - Book/iPython notebooks on Probabilistic Programming in Python Featureforge A set of tools for creating and testing machine learning features, with a scikit-learn compatible API MLlib in Apache Spark - Distributed machine learning library in Spark Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services. scikit-learn - A Python module for machine learning built on top of SciPy. metric-learn - A Python module for metric learning. SimpleAI Python implementation of many of the artificial intelligence algorithms described on the book “Artificial Intelligence, a Modern Approach”. It focuses on providing an easy to use, well documented and tested library. astroML - Machine Learning and Data Mining for Astronomy. graphlab-create - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame. BigML - A library that contacts external servers. pattern - Web mining module for Python. NuPIC - Numenta Platform for Intelligent Computing. Pylearn2 - A Machine Learning library based on Theano. keras - Modular neural network library based on Theano. Lasagne - Lightweight library to build and train neural networks in Theano. hebel - GPU-Accelerated Deep Learning Library in Python. Chainer - Flexible neural network framework gensim - Topic Modelling for Humans. topik - Topic modelling toolkit PyBrain - Another Python Machine Learning Library. Brainstorm - Fast, flexible and fun neural networks. This is the successor of PyBrain. Crab - A ﬂexible, fast recommender engine. python-recsys - A Python library for implementing a Recommender System. thinking bayes - Book on Bayesian Analysis Restricted Boltzmann Machines -Restricted Boltzmann Machines in Python. [DEEP LEARNING] Bolt - Bolt Online Learning Toolbox CoverTree - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree nilearn - Machine learning for NeuroImaging in Python imbalanced-learn - Python module to perform under sampling and over sampling with various techniques. Shogun - The Shogun Machine Learning Toolbox Pyevolve - Genetic algorithm framework. Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind. breze - Theano based library for deep and recurrent neural networks pyhsmm - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations. mrjob - A library to let Python program run on Hadoop. SKLL - A wrapper around scikit-learn that makes it simpler to conduct experiments. neurolab - https://github.com/zueve/neurolab Spearmint - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012. Pebl - Python Environment for Bayesian Learning Theano - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python TensorFlow - Open source software library for numerical computation using data flow graphs yahmm - Hidden Markov Models for Python, implemented in Cython for speed and efficiency. python-timbl - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit. deap - Evolutionary algorithm framework. pydeep - Deep Learning In Python mlxtend - A library consisting of useful tools for data science and machine learning tasks. neon - Nervana’s high-performance Python-based Deep Learning framework [DEEP LEARNING] Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Neural Networks and Deep Learning - Code samples for my book “Neural Networks and Deep Learning” [DEEP LEARNING] Annoy - Approximate nearest neighbours implementation skflow - Simplified interface for TensorFlow, mimicking Scikit Learn. TPOT - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning. pgmpy A python library for working with Probabilistic Graphical Models. DIGITS - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models. Orange - Open source data visualization and data analysis for novices and experts. MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. milk - Machine learning toolkit focused on supervised classification. TFLearn - Deep learning library featuring a higher-level API for TensorFlow. REP - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience. rgf_python - Python bindings for Regularized Greedy Forest (Tree) Library. gym - OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms. skbayes - Python package for Bayesian Machine Learning with scikit-learn API Data Analysis / Data Visualization SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering. NumPy - A fundamental package for scientific computing with Python. Numba - Python JIT (just in time) complier to LLVM aimed at scientific Python by the developers of Cython and NumPy. NetworkX - A high-productivity software for complex networks. igraph - binding to igraph library - General purpose graph library Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools. Open Mining - Business Intelligence (BI) in Python (Pandas web interface) PyMC - Markov Chain Monte Carlo sampling toolkit. zipline - A Pythonic algorithmic trading library. PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib. SymPy - A Python library for symbolic mathematics. statsmodels - Statistical modeling and econometrics in Python. astropy - A community Python library for Astronomy. matplotlib - A Python 2D plotting library. bokeh - Interactive Web Plotting for Python. plotly - Collaborative web plotting for Python and matplotlib. vincent - A Python to Vega translator. d3py - A plotting library for Python, based on D3.js. PyDexter - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser. ggplot - Same API as ggplot2 for R. ggfortify - Unified interface to ggplot2 popular R packages. Kartograph.py - Rendering beautiful SVG maps in Python. pygal - A Python SVG Charts Creator. PyQtGraph - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy. pycascading Petrel - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python. Blaze - NumPy and Pandas interface to Big Data. emcee - The Python ensemble sampling toolkit for affine-invariant MCMC. windML - A Python Framework for Wind Energy Analysis and Prediction vispy - GPU-based high-performance interactive OpenGL 2D/3D data visualization library cerebro2 A web-based visualization and debugging platform for NuPIC. NuPIC Studio An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool! SparklingPandas Pandas on PySpark (POPS) Seaborn - A python visualization library based on matplotlib bqplot - An API for plotting in Jupyter (IPython) pastalog - Simple, realtime visualization of neural network training performance. caravel - A data exploration platform designed to be visual, intuitive, and interactive. Dora - Tools for exploratory data analysis in Python. Ruffus - Computation Pipeline library for python. SOMPY - Self Organizing Map written in Python (Uses neural networks for data analysis). somoclu Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API. HDBScan - implementation of the hdbscan algorithm in Python - used for clustering visualize_ML - A python package for data exploration and data analysis. Misc Scripts / iPython Notebooks / Codebases BioPy - Biologically-Inspired and Machine Learning Algorithms in Python. pattern_classification thinking stats 2 hyperopt numpic 2012-paper-diginorm A gallery of interesting IPython notebooks ipython-notebooks data-science-ipython-notebooks - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines. decision-weights Sarah Palin LDA - Topic Modeling the Sarah Palin emails. Diffusion Segmentation - A collection of image segmentation algorithms based on diffusion methods Scipy Tutorials - SciPy tutorials. This is outdated, check out scipy-lecture-notes Crab - A recommendation engine library for Python BayesPy - Bayesian Inference Tools in Python scikit-learn tutorials - Series of notebooks for learning scikit-learn sentiment-analyzer - Tweets Sentiment Analyzer sentiment_classifier - Sentiment classifier using word sense disambiguation. group-lasso - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model jProcessing - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary &amp; parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO–8859-1 configured) in Python. mne-python-notebooks - IPython notebooks for EEG/MEG data processing using mne-python Neon Course - IPython notebooks for a complete course around understanding Nervana’s Neon pandas cookbook - Recipes for using Python’s pandas library climin - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others Allen Downey’s Data Science Course - Code for Data Science at Olin College, Spring 2014. Allen Downey’s Think Bayes Code - Code repository for Think Bayes. Allen Downey’s Think Complexity Code - Code for Allen Downey’s book Think Complexity. Allen Downey’s Think OS Code - Text and supporting code for Think OS: A Brief Introduction to Operating Systems. Python Programming for the Humanities - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP. GreatCircle - Library for calculating great circle distance. Optunity examples - Examples demonstrating how to use Optunity in synergy with machine learning libraries. Dive into Machine Learning with Python Jupyter notebook and scikit-learn - “I learned Python by hacking first, and getting serious later. I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.” TDB - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow. Suiron - Machine Learning for RC Cars. Introduction to machine learning with scikit-learn - IPython notebooks from Data School’s video tutorials on scikit-learn. Practical XGBoost in Python - comprehensive online course about using XGBoost in Python Neural networks Neural networks - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences. Neuron - Neuron is simple class for time series predictions. It’s utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg–Marquardt algorithm. Data Driven Code - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments. Kaggle Competition Source Code wiki challenge - An implementation of Dell Zhang’s solution to Wikipedia’s Participation Challenge on Kaggle kaggle insults - Kaggle Submission for “Detecting Insults in Social Commentary” kaggle_acquire-valued-shoppers-challenge - Code for the Kaggle acquire valued shoppers challenge kaggle-cifar - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet kaggle-blackbox - Deep learning made easy kaggle-accelerometer - Code for Accelerometer Biometric Competition at Kaggle kaggle-advertised-salaries - Predicting job salaries from ads - a Kaggle competition kaggle amazon - Amazon access control challenge kaggle-bestbuy_big - Code for the Best Buy competition at Kaggle kaggle-bestbuy_small Kaggle Dogs vs. Cats - Code for Kaggle Dogs vs. Cats competition Kaggle Galaxy Challenge - Winning solution for the Galaxy Challenge on Kaggle Kaggle Gender - A Kaggle competition: discriminate gender based on handwriting Kaggle Merck - Merck challenge at Kaggle Kaggle Stackoverflow - Predicting closed questions on Stack Overflow kaggle_acquire-valued-shoppers-challenge - Code for the Kaggle acquire valued shoppers challenge wine-quality - Predicting wine quality Ruby Natural Language Processing Treat - Text REtrieval and Annotation Toolkit, definitely the most comprehensive toolkit I’ve encountered so far for Ruby Ruby Linguistics - Linguistics is a framework for building linguistic utilities for Ruby objects in any language. It includes a generic language-independent front end, a module for mapping language codes into language names, and a module which contains various English-language utilities. Stemmer - Expose libstemmer_c to Ruby Ruby Wordnet - This library is a Ruby interface to WordNet Raspel - raspell is an interface binding for ruby UEA Stemmer - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing Twitter-text-rb - A library that does auto linking and extraction of usernames, lists and hashtags in tweets General-Purpose Machine Learning Ruby Machine Learning - Some Machine Learning algorithms, implemented in Ruby Machine Learning Ruby jRuby Mahout - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby. CardMagic-Classifier - A general classifier module to allow Bayesian and other types of classifications. rb-libsvm - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines Data Analysis / Data Visualization rsruby - Ruby - R bridge data-visualization-ruby - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby ruby-plot - gnuplot wrapper for ruby, especially for plotting roc curves into svg files plot-rb - A plotting library in Ruby built on top of Vega and D3. scruffy - A beautiful graphing toolkit for Ruby SciRuby Glean - A data management tool for humans Bioruby Arel Misc Big Data For Chimps Listof - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, json or hash. Demo/Search for a list Rust General-Purpose Machine Learning deeplearn-rs - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license. rustlearn - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests. rusty-machine - a pure-rust machine learning library. leaf - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe. Available under the MIT license. [Deprecated] RustNN - RustNN is a feedforward neural network library. R General-Purpose Machine Learning ahaz - ahaz: Regularization for semiparametric additive hazards regression arules - arules: Mining Association Rules and Frequent Itemsets biglasso - biglasso: Extending Lasso Model Fitting to Big Data in R bigrf - bigrf: Big Random Forests: Classification and Regression Forests for Large Data Sets bigRR - bigRR: Generalized Ridge Regression (with special advantage for p &gt;&gt; n cases) bmrm - bmrm: Bundle Methods for Regularized Risk Minimization Package Boruta - Boruta: A wrapper algorithm for all-relevant feature selection bst - bst: Gradient Boosting C50 - C50: C5.0 Decision Trees and Rule-Based Models caret - Classification and Regression Training: Unified interface to ~150 ML algorithms in R. caretEnsemble - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models. Clever Algorithms For Machine Learning CORElearn - CORElearn: Classification, regression, feature evaluation and ordinal evaluation CoxBoost - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks Cubist - Cubist: Rule- and Instance-Based Regression Modeling e1071 - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien earth - earth: Multivariate Adaptive Regression Spline Models elasticnet - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA ElemStatLearn - ElemStatLearn: Data sets, functions and examples from the book: “The Elements of Statistical Learning, Data Mining, Inference, and Prediction” by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction” by Trevor Hastie, Robert Tibshirani and Jerome Friedman evtree - evtree: Evolutionary Learning of Globally Optimal Trees forecast - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models forecastHybrid - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the “forecast” package fpc - fpc: Flexible procedures for clustering frbs - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks GAMBoost - GAMBoost: Generalized linear and additive models by likelihood based boosting gamboostLSS - gamboostLSS: Boosting Methods for GAMLSS gbm - gbm: Generalized Boosted Regression Models glmnet - glmnet: Lasso and elastic-net regularized generalized linear models glmpath - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model GMMBoost - GMMBoost: Likelihood-based Boosting for Generalized mixed models grplasso - grplasso: Fitting user specified models with Group Lasso penalty grpreg - grpreg: Regularization paths for regression models with grouped covariates h2o - A framework for fast, parallel, and distributed machine learning algorithms at scale – Deeplearning, Random forests, GBM, KMeans, PCA, GLM hda - hda: Heteroscedastic Discriminant Analysis Introduction to Statistical Learning ipred - ipred: Improved Predictors kernlab - kernlab: Kernel-based Machine Learning Lab klaR - klaR: Classification and visualization lars - lars: Least Angle Regression, Lasso and Forward Stagewise lasso2 - lasso2: L1 constrained estimation aka ‘lasso’ LiblineaR - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library LogicReg - LogicReg: Logic Regression Machine Learning For Hackers maptree - maptree: Mapping, pruning, and graphing tree models mboost - mboost: Model-Based Boosting medley - medley: Blending regression models, using a greedy stepwise approach mlr - mlr: Machine Learning in R mvpart - mvpart: Multivariate partitioning ncvreg - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models nnet - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models oblique.tree - oblique.tree: Oblique Trees for Classification Data pamr - pamr: Pam: prediction analysis for microarrays party - party: A Laboratory for Recursive Partytioning partykit - partykit: A Toolkit for Recursive Partytioning penalized - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model penalizedLDA - penalizedLDA: Penalized classification using Fisher’s linear discriminant penalizedSVM - penalizedSVM: Feature Selection SVM using penalty functions quantregForest - quantregForest: Quantile Regression Forests randomForest - randomForest: Breiman and Cutler’s random forests for classification and regression randomForestSRC - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC) rattle - rattle: Graphical user interface for data mining in R rda - rda: Shrunken Centroids Regularized Discriminant Analysis rdetools - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces REEMtree - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data relaxo - relaxo: Relaxed Lasso rgenoud - rgenoud: R version of GENetic Optimization Using Derivatives rgp - rgp: R genetic programming framework Rmalschains - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R rminer - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression ROCR - ROCR: Visualizing the performance of scoring classifiers RoughSets - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories rpart - rpart: Recursive Partitioning and Regression Trees RPMM - RPMM: Recursively Partitioned Mixture Model RSNNS - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS) RWeka - RWeka: R/Weka interface RXshrink - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression sda - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection SDDA - SDDA: Stepwise Diagonal Discriminant Analysis SuperLearner and subsemble - Multi-algorithm ensemble learning packages. svmpath - svmpath: svmpath: the SVM Path algorithm tgp - tgp: Bayesian treed Gaussian process models tree - tree: Classification and regression trees varSelRF - varSelRF: Variable selection using random forests XGBoost.R - R binding for eXtreme Gradient Boosting (Tree) Library Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R. igraph - binding to igraph library - General purpose graph library MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. TDSP-Utilities - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modeling and Reporting (AMR). Data Analysis / Data Visualization ggplot2 - A data visualization package based on the grammar of graphics. SAS General-Purpose Machine Learning Enterprise Miner - Data mining and machine learning that creates deployable models using a GUI or code. Factory Miner - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI. Data Analysis / Data Visualization SAS/STAT - For conducting advanced statistical analysis. University Edition - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses. High Performance Machine Learning High Performance Data Mining - Data mining and machine learning that creates deployable models using a GUI or code in an MPP environment, including Hadoop. High Performance Text Mining - Text mining using a GUI or code in an MPP environment, including Hadoop. Natural Language Processing Contextual Analysis - Add structure to unstructured text using a GUI. Sentiment Analysis - Extract sentiment from text using a GUI. Text Miner - Text mining using a GUI or code. Demos and Scripts ML_Tables - Concise cheat sheets containing machine learning best practices. enlighten-apply - Example code and materials that illustrate applications of SAS machine learning techniques. enlighten-integration - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R. enlighten-deep - Example code and materials that illustrate using neural networks with several hidden layers in SAS. dm-flow - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics. Scala Natural Language Processing ScalaNLP - ScalaNLP is a suite of machine learning and numerical computing libraries. Breeze - Breeze is a numerical processing library for Scala. Chalk - Chalk is a natural language processing library. FACTORIE - FACTORIE is a toolkit for deployable probabilistic modeling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference. Data Analysis / Data Visualization MLlib in Apache Spark - Distributed machine learning library in Spark Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services. Scalding - A Scala API for Cascading Summing Bird - Streaming MapReduce with Scalding and Storm Algebird - Abstract Algebra for Scala xerial - Data management utilities for Scala simmer - Reduce your data. A unix filter for algebird-powered aggregation. PredictionIO - PredictionIO, a machine learning server for software developers and data engineers. BIDMat - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis. Wolfe Declarative Machine Learning Flink - Open source platform for distributed stream and batch data processing. Spark Notebook - Interactive and Reactive Data Science using Scala and Spark. General-Purpose Machine Learning Conjecture - Scalable Machine Learning in Scalding brushfire - Distributed decision tree ensemble learning in Scala ganitha - scalding powered machine learning adam - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed. bioscala - Bioinformatics for the Scala programming language BIDMach - CPU and GPU-accelerated Machine Learning Library. Figaro - a Scala library for constructing probabilistic models. H2O Sparkling Water - H2O and Spark interoperability. FlinkML in Apache Flink - Distributed machine learning library in Flink DynaML - Scala Library/REPL for Machine Learning Research Saul - Flexible Declarative Learning-Based Programming. SwiftLearner - Simply written algorithms to help study ML or write your own implementations. Swift General-Purpose Machine Learning Swift AI - Highly optimized artificial intelligence and machine learning library written in Swift. BrainCore - The iOS and OS X neural network framework swix - A bare bones library thatincludes a general matrix language and wraps some OpenCV for iOS development. DeepLearningKit an Open Source Deep Learning Framework for Apple’s iOS, OS X and tvOS.It currently allows using deep convolutional neural network models trained in Caffe on Apple operating systems. AIToolbox - A toolbox framework of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians. MLKit - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression. Swift Brain - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc.. TensorFlow General-Purpose Machine Learning Awesome TensorFlow - A list of all things related to TensorFlow Credits Some of the python libraries were cut-and-pasted from vinta The few go reference I found where pulled from this page","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"Awesome Deep Learning","date":"2017-02-19T15:56:00.000Z","path":"2017/02/19/SmartAI/ProgramAI/Resources/awesome-deep-learning/","text":"作者：Joseph Misiti/josephmisiti A curated list of awesome Deep Learning tutorials, projects and communities. Free Online Books Deep Learning by Yoshua Bengio, Ian Goodfellow and Aaron Courville (01/01/2015) Neural Networks and Deep Learning by Michael Nielsen (Dec 2014) Deep Learning by Microsoft Research (2013) Deep Learning Tutorial by LISA lab, University of Montreal (Jan 6 2015)Courses Machine Learning - Stanford by Andrew Ng in Coursera (2010-2014) Machine Learning - Caltech by Yaser Abu-Mostafa (2012-2014) Machine Learning - Carnegie Mellon by Tom Mitchell (Spring 2011) Neural Networks for Machine Learning by Geoffrey Hinton in Coursera (2012) Neural networks class by Hugo Larochelle from Université de Sherbrooke (2013) Deep Learning Course by CILVR lab @ NYU (2014) A.I - Berkeley by Dan Klein and Pieter Abbeel (2013) A.I - MIT by Patrick Henry Winston (2010) Vision and learning - computers and brains by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)Video and Lectures How To Create A Mind By Ray Kurzweil Deep Learning, Self-Taught Learning and Unsupervised Feature Learning By Andrew Ng Recent Developments in Deep Learning By Geoff Hinton The Unreasonable Effectiveness of Deep Learning by Yann LeCun Deep Learning of Representations by Yoshua bengio Principles of Hierarchical Temporal Memory by Jeff Hawkins Machine Learning Discussion Group - Deep Learning w/ Stanford AI Lab by Adam Coates Making Sense of the World with Deep Learning By Adam Coates Demystifying Unsupervised Feature Learning By Adam Coates Visual Perception with Deep Learning By Yann LeCun The Next Generation of Neural Networks By Geoffrey Hinton at GoogleTechTalks The wonderful and terrifying implications of computers that can learn By Jeremy Howard at TEDxBrusselsPapers ImageNet Classification with Deep Convolutional Neural Networks Using Very Deep Autoencoders for Content Based Image Retrieval Learning Deep Architectures for AI CMU’s list of papersTutorials UFLDL Tutorial 1 UFLDL Tutorial 2 Deep Learning for NLP (without Magic) A Deep Learning Tutorial: From Perceptrons to Deep Networks Deep Learning from the Bottom upWebSites deeplearning.net deeplearning.stanford.eduDatasets MNIST Handwritten digits Google House Numbers from street view CIFAR-10 and CIFAR-1004. IMAGENET Tiny Images 80 Million tiny images6. Flickr Data 100 Million Yahoo dataset Berkeley Segmentation Dataset 500Frameworks Caffe Torch7 Theano cuda-convnet Ccv NuPIC DeepLearning4J BrainMiscellaneous Google Plus - Deep Learning Community Caffe Webinar 100 Best Github Resources in Github for DL Word2Vec Caffe DockerFile TorontoDeepLEarning convnet Vision data sets Fantastic Torch Tutorial gfx.jsTorch7 Cheat sheetMisc from MIT’s ‘Advanced Natural Language Processing’ courseMisc from MIT’s ‘Machine Learning’ courseMisc from MIT’s ‘Networks for Learning: Regression and Classification’ courseMisc from MIT’s ‘Neural Coding and Perception of Sound’ courseImplementing a Distributed Deep Learning Network over SparkContributingHave anything in mind that you think is awesome and would fit in this list? Feel free to send a pull request.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"25个Java机器学习工具&库","date":"2017-02-19T15:50:06.000Z","path":"2017/02/19/SmartAI/ProgramAI/OpenSources/25-open-source-projects-of-machine-learning-java/","text":"转自：CSDN 本列表总结了25个Java机器学习工具&amp;库 本列表总结了25个Java机器学习工具&amp;库：1.&nbsp;Weka集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。2.Massive&nbsp;Online&nbsp;Analysis（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。3.MEKA项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。4.&nbsp;Advanced&nbsp;Data&nbsp;mining&nbsp;And&nbsp;Machine&nbsp;learning&nbsp;System（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。5.&nbsp;Environment&nbsp;for&nbsp;Developing&nbsp;KDD-Applications&nbsp;Supported&nbsp;by&nbsp;Index-Structure（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。6.&nbsp;Mallet是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。7.&nbsp;Encog是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。8.&nbsp;Datumbox机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。9.&nbsp;Deeplearning4j是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。10.&nbsp;Mahout是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。11.Rapid&nbsp;Miner是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java&nbsp;API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。12.&nbsp;Apache&nbsp;SAMOA是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache&nbsp;Storm、Apache&nbsp;S4和Apache&nbsp;samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。13.&nbsp;Neuroph通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。14.&nbsp;Oryx&nbsp;2是一个建立在Apache&nbsp;Spark和Apache&nbsp;Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。15.&nbsp;Stanford&nbsp;Classifier是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。16.io是一个Retina&nbsp;API，有着快速精确的类&#20284;大脑的自然语言处理算法。17.JSAT是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。18.&nbsp;N-Dimensional&nbsp;Arrays&nbsp;for&nbsp;Java(ND4J)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。19.&nbsp;Java&nbsp;Machine&nbsp;Learning&nbsp;Library（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。20.&nbsp;Java-ML是一个使用Java编写的一系列机器学习算法的Java&nbsp;API。它只提供了一个标准的算法接口。21.&nbsp;MLlib&nbsp;(Spark)是Apache&nbsp;Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。22.&nbsp;H2O是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。23.&nbsp;WalnutiQ是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。24.&nbsp;RankLib是一个排名学习算法库。目前已经实现八种流行的算法。25.&nbsp;htm.java（基于Java的Hierarchical&nbsp;Temporal&nbsp;Memory算法实现）是一个面向智能计算的Numenta平台的Java接口","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"},{"name":"Java","slug":"Java","permalink":"http://ipcreator.me/tags/Java/"}]},{"title":"Scikit-learn入门指南","date":"2017-02-18T05:04:06.000Z","path":"2017/02/18/SmartAI/ProgramAI/Resources/basic-knowledge-of-scikit-learn/","text":"作者：雷锋网 恒亮 对Python语言有所了解的科研人员可能都知道SciPy——一个开源的基于Python的科学计算工具包。基于SciPy，目前开发者们针对不同的应用领域已经发展出了为数众多的分支版本，它们被统一称为Scikits，即SciPy工具包的意思。而在这些分支版本中，最有名，也是专门面向机器学习的一个就是Scikit-learn。 Scikit-learn项目最早由数据科学家 David Cournapeau 在 2007 年发起，需要NumPy和SciPy等其他包的支持，是Python语言中专门针对机器学习应用而发展起来的一款开源框架。 和其他众多的开源项目一样，Scikit-learn目前主要由社区成员自发进行维护。可能是由于维护成本的限制，Scikit-learn相比其他项目要显得更为保守。这主要体现在两个方面：一是Scikit-learn从来不做除机器学习领域之外的其他扩展，二是Scikit-learn从来不采用未经广泛验证的算法。 本文将简单介绍Scikit-learn框架的六大功能，安装和运行Scikit-learn的大概步骤，同时为后续各更深入地学习Scikit-learn提供参考。原文来自infoworld网站的特约撰稿人Martin Heller，他曾在1986-2010年间做过长达20多年的数据库、通用软件和网页开发，具有丰富的开发经验。 Scikit-learn的六大功能 Scikit-learn的基本功能主要被分为六大部分：分类，回归，聚类，数据降维，模型选择和数据预处理。 分类是指识别给定对象的所属类别，属于监督学习的范畴，最常见的应用场景包括垃圾邮件检测和图像识别等。目前Scikit-learn已经实现的算法包括：支持向量机（SVM），最近邻，逻辑回归，随机森林，决策树以及多层感知器（MLP）神经网络等等。 需要指出的是，由于Scikit-learn本身不支持深度学习，也不支持GPU加速，因此这里对于MLP的实现并不适合于处理大规模问题。有相关需求的读者可以查看同样对Python有良好支持的Keras和Theano等框架。 回归是指预测与给定对象相关联的连续值属性，最常见的应用场景包括预测药物反应和预测股票价格等。目前Scikit-learn已经实现的算法包括：支持向量回归（SVR），脊回归，Lasso回归，弹性网络（Elastic Net），最小角回归（LARS ），贝叶斯回归，以及各种不同的鲁棒回归算法等。可以看到，这里实现的回归算法几乎涵盖了所有开发者的需求范围，而且更重要的是，Scikit-learn还针对每种算法都提供了简单明了的用例参考。 聚类是指自动识别具有相似属性的给定对象，并将其分组为集合，属于无监督学习的范畴，最常见的应用场景包括顾客细分和试验结果分组。目前Scikit-learn已经实现的算法包括：K-均值聚类，谱聚类，均值偏移，分层聚类，DBSCAN聚类等。 数据降维是指使用主成分分析（PCA）、非负矩阵分解（NMF）或特征选择等降维技术来减少要考虑的随机变量的个数，其主要应用场景包括可视化处理和效率提升。 模型选择是指对于给定参数和模型的比较、验证和选择，其主要目的是通过参数调整来提升精度。目前Scikit-learn实现的模块包括：格点搜索，交叉验证和各种针对预测误差评估的度量函数。 数据预处理是指数据的特征提取和归一化，是机器学习过程中的第一个也是最重要的一个环节。这里归一化是指将输入数据转换为具有零均值和单位权方差的新变量，但因为大多数时候都做不到精确等于零，因此会设置一个可接受的范围，一般都要求落在0-1之间。而特征提取是指将文本或图像数据转换为可用于机器学习的数字变量。 需要特别注意的是，这里的特征提取与上文在数据降维中提到的特征选择非常不同。特征选择是指通过去除不变、协变或其他统计上不重要的特征量来改进机器学习的一种方法。 总结来说，Scikit-learn实现了一整套用于数据降维，模型选择，特征提取和归一化的完整算法/模块，虽然缺少按步骤操作的参考教程，但Scikit-learn针对每个算法和模块都提供了丰富的参考样例和详细的说明文档。 安装和运行Scikit-learn 如前所述，Scikit-learn需要NumPy和SciPy等其他包的支持，因此在安装Scikit-learn之前需要提前安装一些支持包，具体列表和教程可以查看Scikit-learn的官方文档： http://scikit-learn.org/stable/install.html ，以下仅列出Python、NumPy和SciPy等三个必备包的安装说明。 Python：https://www.python.org/about/gettingstarted/ NumPy：http://www.numpy.org/ SciPy：http://www.scipy.org/install.html 假定已经完整安装了所有支持包，那么利用安装Scikit-learn只需要简单的一条简单的pip命令（也可以用conda命令，详见官方文档）： $ sudo pip install -U scikit-learn 这里加上sudo是为了避免安装过程中出现一些权限问题，如果用户已经确保了管理员权限也可以省略。 当然，开发者也可以选择自己到GitHub开源平台上下载Scikit-learn的源代码，解压后在根目录键入make自行编译和连接可执行文件，效果是一样的。另外，为了确保测试方便，高级用户还可以选择安装针对Python的测试框架nose，安装方法详见其官方说明： http://nose.readthedocs.io/en/latest/ 。 通过Jupyter Notebook工具运行Scikit-learn样例的过程也很简单，用户只需要在官方给出的样例库： http://scikit-learn.org/stable/auto_examples/index.html#general-examples 选择一个样例，然后在页面中下载其Python源码和IPython notebook文件，借着通过Jupyter Notebook工具运行就可以了。假如选择了交叉验证预测的样例，那么其运行情况的截图如下所示。 原作者在这里表示，Scikit-learn是他测试过的最简单易用的机器学习框架。他表示，Scikit-learn样例的运行结果和文档描述一模一样，API接口的设计合理且一致性高，而且几乎不存在“阻抗不匹配”的数据结构，使用这种功能完善且几乎没有Bug的开源框架进行机器学习研究，无疑是一件值得高兴的事。 更深入地学习Scikit-learn 如前所述，Scikit-learn针对每个算法和模块都提供了丰富的参考样例和详细的说明文档，据官方的统计大约有200多个。而且为了清晰明白，绝大多数样例都至少给出了一张由Matplotlib绘制的数据图表。这些都是官方提供的学习Scikit-learn框架最直接有效的学习材料。 针对科学数据处理的应用场景，官方还给出了一个更为详细和全面的参考教程：A tutorial on statistical-learning for scientific data processing，其中包括统计学习、监督学习、模型选择和无监督学习等若干部分，内容覆盖全面，讲解细致，并且使用了真实的数据、代码和图表。 另外，教程中还调用了与文本相关的样例，例如下图所示的四个不同SVM分类器的比较。 这里需要指出的是，虽然运行Scikit-learn官方给出的样例后通常都能得到一致的结果，但大多数情况下系统都会抛出警告信息。作者认为抛出警告信息的原因来自两个方面：一是苹果vecLib框架本身对Scikit-learn支持不好（作者用的是MacOS），二是样例中使用的Python版本可能是早期的版本，而实际运行中是最新的版本。例如下图中是使用Python 2.7.10版本抛出的警告信息，而Scikit-learn官方页面上并没有出现。 总体上来说，作为专门面向机器学习的Python开源框架，Scikit-learn可以在一定范围内为开发者提供非常好的帮助。它内部实现了各种各样成熟的算法，容易安装和使用，样例丰富，而且教程和文档也非常详细。 另一方面，Scikit-learn也有缺点。例如它不支持深度学习和强化学习，这在今天已经是应用非常广泛的技术，例如准确的图像分类和可靠的实时语音识别和语义理解等。此外，它也不支持图模型和序列预测，不支持Python之外的语言，不支持PyPy，也不支持GPU加速。 看到这里可能会有人担心Scikit-learn的性能表现，这里需要指出的是：如果不考虑多层神经网络的相关应用，Scikit-learn的性能表现是非常不错的。究其原因，一方面是因为其内部算法的实现十分高效，另一方面或许可以归功于Cython编译器：通过Cython在Scikit-learn框架内部生成C语言代码的运行方式，Scikit-learn消除了大部分的性能瓶颈。 应该明确的一点是：虽然概括地说Scikit-learn并不适合深度学习问题，但对于某些特殊场景而言，使用Scikit-learn仍然是明智的选择。例如要创建连接不同对象的预测函数时，或者在未标记的数据集中为了训练模型对不同的对象进行分类时，面对这些场景Scikit-learn只通过普通的旧机器学习模型就能很好地解决，而并不需要建立数十层的复杂神经网络。 就好像喜欢Scala语言的人会选择Spark ML，喜欢绘制图表和偶尔编写少量Python/R语言代码的人会选择微软Cortana和Azure一样，对于那些Python语言的死忠粉而言，Scikit-learn可能是各种机器学习库中的最好选择。雷锋网(公众号：雷锋网)雷锋网 来源：infoworld，雷锋网编译 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Scikit","slug":"Scikit","permalink":"http://ipcreator.me/tags/Scikit/"}]},{"title":"大数据/数据挖掘/推荐系统/机器学习相关资源","date":"2017-02-18T04:23:06.000Z","path":"2017/02/18/SmartAI/ProgramAI/Resources/big-data-resources/","text":"作者：Zhe Yu/Flowerowl 大数据/数据挖掘/推荐系统/机器学习相关资源 Share my personal resources 书籍 各种书~各种ppt~更新中~ https://pan.baidu.com/s/1c1Xp6Pa机器学习经典书籍小结 http://www.cnblogs.com/snake-hand/archive/2013/06/10/3131145.html机器学习&amp;深度学习经典资料汇总 http://www.thebigdata.cn/JiShuBoKe/13299.html 视频 浙大数据挖掘系列 http://v.youku.com/v_show/id_XNTgzNDYzMjg=.html?f=2740765用Python做科学计算 http://www.tudou.com/listplay/fLDkg5e1pYM.htmlR语言视频 http://pan.baidu.com/s/1koSpZHadoop视频 http://pan.baidu.com/s/1b1xYd42区 . 技术 . 创业 . 第二讲 http://v.youku.com/v_show/id_XMzAyMDYxODUy.html加州理工学院公开课：机器学习与数据挖掘 http://v.163.com/special/opencourse/learningfromdata.htmlWilliam Huang教授–BI和数据挖掘技术 https://www.youtube.com/watch?v=gPm8SOJ1NaoJingyuan Wang王静远-北航-机器学习工具在城市数据分析中的应用https://www.youtube.com/watch?v=H2_BATE8uokTensor Flow 介紹 (1/2)https://www.youtube.com/watch?v=jA4Bh-xj_mETensor Flow 介紹 (2/2)https://www.youtube.com/watch?v=YUCsOgkFqpk 课程 机器学习 Machine Learning Stanford University https://www.coursera.org/learn/machine-learning機器學習基石 (Machine Learning Foundations) National Taiwan University https://www.coursera.org/course/ntumlone 会议 数据挖掘 ACM SigKDD http://www.kdd.orgICDM http://icdm2015.stonybrook.edu/SIAM http://www.siam.org/ QQ群 机器学习&amp;模式识别 246159753数据挖掘机器学习 236347059推荐系统 274750470 Github 推荐系统 推荐系统开源软件列表汇总和评点 http://in.sdo.com/?p=1707Mrec(Python) https://github.com/mendeley/mrecCrab(Python) https://github.com/muricoca/crabPython-recsys(Python) https://github.com/ocelma/python-recsysCofiRank(C++) https://github.com/markusweimer/cofirankGraphLab(C++) https://github.com/graphlab-code/graphlabEasyRec(Java) https://github.com/hernad/easyrecLenskit(Java) https://github.com/grouplens/lenskitMahout(Java) https://github.com/apache/mahoutRecommendable(Ruby) https://github.com/davidcelis/recommendable 库 NLTK https://github.com/nltk/nltkPattern https://github.com/clips/patternPyrallel https://github.com/pydata/pyrallelTheano https://github.com/Theano/TheanoPylearn2 https://github.com/lisa-lab/pylearn2TextBlob https://github.com/sloria/TextBlobMBSP https://github.com/clips/MBSPGensim https://github.com/piskvorky/gensimLangid.py https://github.com/saffsd/langid.pyJieba https://github.com/fxsjy/jiebaxTAS https://github.com/NLeSC/xtasNumPy https://github.com/numpy/numpySciPy https://github.com/scipy/scipyMatplotlib https://github.com/matplotlib/matplotlibscikit-learn https://github.com/scikit-learn/scikit-learnPandas https://github.com/pydata/pandasMDP http://mdp-toolkit.sourceforge.net/PyBrain https://github.com/pybrain/pybrainPyML http://pyml.sourceforge.net/Milk https://github.com/luispedro/milkPyMVPA https://github.com/PyMVPA/PyMVPATensorFlow https://github.com/tensorflow/tensorflow 博客 周涛 http://blog.sciencenet.cn/home.php?mod=space&amp;uid=3075Greg Linden http://glinden.blogspot.com/ Marcel Caraciolo http://aimotion.blogspot.com/RsysChina http://weibo.com/p/1005051686952981推荐系统人人小站 http://zhan.renren.com/recommendersystem阿稳 http://www.wentrue.net梁斌 http://weibo.com/pennyliang刁瑞 http://diaorui.netguwendong http://www.guwendong.comxlvector http://xlvector.net懒惰啊我 http://www.cnblogs.com/flclain/free mind http://blog.pluskid.org/lovebingkuai http://lovebingkuai.diandian.com/LeftNotEasy http://www.cnblogs.com/LeftNotEasyLSRS 2013 http://graphlab.org/lsrs2013/program/ Google小组 https://groups.google.com/forum/#!forum/resysJournal of Machine Learning Research http://jmlr.org/在线的机器学习社区 http://www.52ml.net/16336.html清华大学信息检索组 http://www.thuir.cn我爱自然语言处理 http://www.52nlp.cn/数据挖掘与数据分析http://spss-market.r.blog.163.com/ 文章 心中永远的正能量 http://blog.csdn.net/yunlong34574机器学习最佳入门学习资料汇总 http://article.yeeyan.org/view/22139/410514Books for Machine Learning with R http://www.52ml.net/16312.html是什么阻碍了你的机器学习目标？ http://www.52ml.net/16436.htm推荐系统初探 http://yongfeng.me/attach/rs-survey-zhang-slices.pdf推荐系统中协同过滤算法若干问题的研究 http://pan.baidu.com/s/1bnjDBYZNetflix 推荐系统：第一部分 http://blog.csdn.net/bornhe/article/details/8222450Netflix 推荐系统：第二部分 http://blog.csdn.net/bornhe/article/details/8222497探索推荐引擎内部的秘密 http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html推荐系统resys小组线下活动见闻2009-08-22 http://www.tuicool.com/articles/vUvQVnRecommendation Engines Seminar Paper, Thomas Hess, 2009: 推荐引擎的总结性文章 http://www.slideshare.net/antiraum/recommender-engines-seminar-paperToward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions, Adomavicius, G.; Tuzhilin, A., 2005 http://dl.acm.org/citation.cfm?id=1070751A Taxonomy of RecommenderAgents on the Internet, Montaner, M.; Lopez, B.; de la Rosa, J. L., 2003 http://www.springerlink.com/index/KK844421T5466K35.pdfA Course in Machine Learning http://ciml.info/基于mahout构建社会化推荐引擎 http://www.doc88.com/p-745821989892.html个性化推荐技术漫谈 http://blog.csdn.net/java060515/archive/2007/04/19/1570243.aspxDesign of Recommender System http://www.slideshare.net/rashmi/design-of-recommender-systemsHow to build a recommender system http://www.slideshare.net/blueace/how-to-build-a-recommender-system-presentation推荐系统架构小结 http://blog.csdn.net/idonot/article/details/7996733System Architectures for Personalization and Recommendation http://techblog.netflix.com/2013/03/system-architectures-for.htmlThe Netflix Tech Blog http://techblog.netflix.com/百分点推荐引擎——从需求到架构http://www.infoq.com/cn/articles/baifendian-recommendation-engine推荐系统 在InfoQ上的内容 http://www.infoq.com/cn/recommend推荐系统实时化的实践和思考 http://www.infoq.com/cn/presentations/recommended-system-real-time-practice-thinking质量保证的推荐实践 http://www.infoq.com/cn/news/2013/10/testing-practice/ 推荐系统的工程挑战 http://www.infoq.com/cn/presentations/Recommend-system-engineering社会化推荐在人人网的应用 http://www.infoq.com/cn/articles/zyy-social-recommendation-in-renren/利用20%时间开发推荐引擎 http://www.infoq.com/cn/presentations/twenty-percent-time-to-develop-recommendation-engine使用Hadoop和 Mahout实现推荐引擎 http://www.jdon.com/44747SVD 简介 http://www.cnblogs.com/FengYan/archive/2012/05/06/2480664.htmlNetflix推荐系统：从评分预测到消费者法则 http://blog.csdn.net/lzt1983/article/details/7696578关于数据挖掘学习的讨论https://www.zhihu.com/question/20751219 论文 《推荐系统实战》引用 P1A Guide to Recommender System P4Cross Selling P6课程：Data Mining and E-Business: The Social Data Revolution P7)An Introduction to Search Engines and Web Navigation p7 p8p9(The Youtube video recommendation system) p9 (PPT: Music Recommendation and Discovery) p12P13 (Digg Recommendation Engine Updates) P16(The Learning Behind Gmail Priority Inbox)p17 (Accurate is not always good: How Accuracy Metrics have hurt Recommender Systems) P20(Don’t Look Stupid: Avoiding Pitfalls when Recommending Research Papers)P23 (Major componets of the gravity recommender system) P25(What is a Good Recomendation Algorithm?) P26(Evaluation Recommendation Systems) P27 (Music Recommendation and Discovery in the Long Tail) P29 (Internation Workshop on Novelty and Diversity in Recommender Systems) p29(Auralist: Introducing Serendipity into Music Recommendation ) P30 (Metrics for evaluating the serendipity of recommendation lists) P30(The effects of transparency on trust in and acceptance of a content-based art recommender) P31 (Trust-aware recommender systems) P31(Tutorial on robutness of recommender system) P32(Five Stars Dominate Ratings) P37 (Book-Crossing Dataset) P38 (Lastfm Dataset) P39 浅谈网络世界的Power Law现象 P39 (MovieLens Dataset) P42(Empirical Analysis of Predictive Algorithms for Collaborative Filtering) P49(Digg Vedio) P50(Amazon.com Recommendations Item-to-Item Collaborative Filtering) P59 (Greg Linden Blog) P63(One-Class Collaborative Filtering) P67(Stochastic Gradient Descent) P68 (Latent Factor Models for Web Recommender Systems) P70 (Bipatite Graph) P73(Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation) P74(Topic Sensitive Pagerank) P74 (FAST ALGORITHMS FOR SPARSE MATRIX INVERSE COMPUTATIONS) P77(LIFESTYLE FINDER: Intelligent User Profiling Using Large-Scale Demographic Data) P80( adaptive bootstrapping of recommender systems using decision trees) P87 (Vector Space Model) P90(冷启动问题的比赛) P92(Latent Dirichlet Allocation) P92(Kullback–Leibler divergence) P93(About The Music Genome Project) P94(Pandora Music Genome Project Attributes) P94(Jinni Movie Genome) P94 (Tagsplanations: Explaining Recommendations Using Tags) P96(Tag Wikipedia) P96(Nurturing Tagging Communities) P100(Why We Tag: Motivations for Annotation in Mobile and Online Media ) P100(Delicious Dataset) P101(Finding Advertising Keywords on Web Pages) P118(基于标签的推荐系统比赛) P119(Tag recommendations based on tensor dimensionality reduction）P119(latent dirichlet allocation for tag recommendation) P119(Folkrank: A ranking algorithm for folksonomies) P119 (Tagommenders: Connecting Users to Items through Tags) P119 (The Quest for Quality Tags) P120(Challenge on Context-aware Movie Recommendation) P123(The Lifespan of a link) P125(Temporal Diversity in Recommender Systems) P129(Evaluating Collaborative Filtering Over Time) P129(Hotpot) P139 (Google Launches Hotpot, A Recommendation Engine for Places) P139 (geolocated recommendations) P140(A Peek Into Netflix Queues) P141(Distance Browsing in Spatial Databases1) P142(Efﬁcient Evaluation of k-Range Nearest Neighbor Queries in Road Networks) P143(Global Advertising: Consumers Trust Real Friends and Virtual Strangers the Most) P144 (Suggesting Friends Using the Implicit Social Graph) P145(Friends &amp; Frenemies: Why We Add and Remove Facebook Friends) P147(Stanford Large Network Dataset Collection) P149 (Workshop on Context-awareness in Retrieval and Recommendation) P151(Factorization vs. Regularization: Fusing Heterogeneous Social Relationships in Top-N Recommendation) P153 (Twitter, an Evolving Architecture) P154(Recommendations in taste related domains) P155(Comparing Recommendations Made by Online Systems and Friends) P155 (EdgeRank: The Secret Sauce That Makes Facebook’s News Feed Tick) P157(Speak Little and Well: Recommending Conversations in Online Social Streams) P158(Learn more about “People You May Know”) P160(“Make New Friends, but Keep the Old” – Recommending People on Social Networking Sites) P164 (SoRec: Social Recommendation Using Probabilistic Matrix) P165 (A Dynamic Bayesian Network Click Model for Web Search Ranking) P177(Online Learning from Click Data for Sponsored Search) P177(Contextual Advertising by Combining Relevance with Click Feedback) P177 (Hulu 推荐系统架构) P178(MyMedia Project) P178(item-based collaborative filtering recommendation algorithms) P185(Learning Collaborative Information Filters) P186 (Simon Funk Blog:Funk SVD) P187 (Factor in the Neighbors: Scalable and Accurate Collaborative Filtering) P190 (Time-dependent Models in Collaborative Filtering based Recommender System) P193 (Collaborative filtering with temporal dynamics) P193(Least Squares Wikipedia) P195(Improving regularized singular value decomposition for collaborative filtering) P195(Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model) P195 【CIKM 2012 Best Stu Paper】Incorporating Occupancy into Frequent Pattern Mini.pdf 【CIKM 2012 poster】A Latent Pairwise Preference Learning Approach for Recomme.pdf 【CIKM 2012 poster】An Effective Category Classification Method Based on a Lan.pdf 【CIKM 2012 poster】Learning to Rank for Hybrid Recommendation.pdf 【CIKM 2012 poster】Learning to Recommend with Social Relation Ensemble.pdf 【CIKM 2012 poster】Maximizing Revenue from Strategic Recommendations under De.pdf 【CIKM 2012 poster】On Using Category Experts for Improving the Performance an.pdf 【CIKM 2012 poster】Relation Regularized Subspace Recommending for Related Sci.pdf 【CIKM 2012 poster】Top-N Recommendation through Belief Propagation.pdf 【CIKM 2012 poster】Twitter Hyperlink Recommendation with User-Tweet-Hyperlink.pdf 【CIKM 2012 short】Automatic Query Expansion Based on Tag Recommendation.pdf 【CIKM 2012 short】Graph-Based Workflow Recommendation- On Improving Business .pdf 【CIKM 2012 short】Location-Sensitive Resources Recommendation in Social Taggi.pdf 【CIKM 2012 short】More Than Relevance- High Utility Query Recommendation By M.pdf 【CIKM 2012 short】PathRank- A Novel Node Ranking Measure on a Heterogeneous G.pdf 【CIKM 2012 short】PRemiSE- Personalized News Recommendation via Implicit Soci.pdf 【CIKM 2012 short】Query Recommendation for Children.pdf 【CIKM 2012 short】The Early-Adopter Graph and its Application to Web-Page Rec.pdf 【CIKM 2012 short】Time-aware Topic Recommendation Based on Micro-blogs.pdf 【CIKM 2012 short】Using Program Synthesis for Social Recommendations.pdf 【CIKM 2012】A Decentralized Recommender System for Effective Web Credibility .pdf 【CIKM 2012】A Generalized Framework for Reciprocal Recommender Systems.pdf 【CIKM 2012】Dynamic Covering for Recommendation Systems.pdf 【CIKM 2012】Efficient Retrieval of Recommendations in a Matrix Factorization .pdf 【CIKM 2012】Exploring Personal Impact for Group Recommendation.pdf 【CIKM 2012】LogUCB- An Explore-Exploit Algorithm For Comments Recommendation.pdf 【CIKM 2012】Metaphor- A System for Related Search Recommendations.pdf 【CIKM 2012】Social Contextual Recommendation.pdf 【CIKM 2012】Social Recommendation Across Multiple Relational Domains.pdf 【COMMUNICATIONS OF THE ACM】Recommender Systems.pdf 【ICDM 2012 short___】Multiplicative Algorithms for Constrained Non-negative M.pdf 【ICDM 2012 short】Collaborative Filtering with Aspect-based Opinion Mining- A.pdf 【ICDM 2012 short】Learning Heterogeneous Similarity Measures for Hybrid-Recom.pdf 【ICDM 2012 short】Mining Personal Context-Aware Preferences for Mobile Users.pdf 【ICDM 2012】Link Prediction and Recommendation across Heterogenous Social Networks.pdf 【IEEE Computer Society 2009】Matrix factorization techniques for recommender .pdf 【IEEE Consumer Communications and Networking Conference 2006】FilmTrust movie.pdf 【IEEE Trans on Audio, Speech and Laguage Processing 2010】Personalized music .pdf 【IEEE Transactions on Knowledge and Data Engineering 2005】Toward the next ge.pdf 【INFOCOM 2011】Bayesian-inference Based Recommendation in Online Social Network.pdf 【KDD 2009】Learning optimal ranking with tensor factorization for tag recomme.pdf 【SIGIR 2009】Learning to Recommend with Social Trust Ensemble.pdf 【SIGIR 2012】Adaptive Diversification of Recommendation Results via Latent Fa.pdf 【SIGIR 2012】Collaborative Personalized Tweet Recommendation.pdf 【SIGIR 2012】Dual Role Model for Question Recommendation in Community Questio.pdf 【SIGIR 2012】Exploring Social Influence for Recommendation - A Generative Mod.pdf 【SIGIR 2012】Increasing Temporal Diversity with Purchase Intervals.pdf 【SIGIR 2012】Learning to Rank Social Update Streams.pdf 【SIGIR 2012】Personalized Click Shaping through Lagrangian Duality for Online.pdf 【SIGIR 2012】Predicting the Ratings of Multimedia Items for Making Personaliz.pdf 【SIGIR 2012】TFMAP-Optimizing MAP for Top-N Context-aware Recommendation.pdf 【SIGIR 2012】What Reviews are Satisfactory- Novel Features for Automatic Help.pdf 【SIGKDD 2012】 A Semi-Supervised Hybrid Shilling Attack Detector for Trustwor.pdf 【SIGKDD 2012】 RecMax- Exploiting Recommender Systems for Fun and Profit.pdf 【SIGKDD 2012】Circle-based Recommendation in Online Social Networks.pdf 【SIGKDD 2012】Cross-domain Collaboration Recommendation.pdf 【SIGKDD 2012】Finding Trending Local Topics in Search Queries for Personaliza.pdf 【SIGKDD 2012】GetJar Mobile Application Recommendations with Very Sparse Datasets.pdf 【SIGKDD 2012】Incorporating Heterogenous Information for Personalized Tag Rec.pdf 【SIGKDD 2012】Learning Personal+Social Latent Factor Model for Social Recomme.pdf 【VLDB 2012】Challenging the Long Tail Recommendation.pdf 【VLDB 2012】Supercharging Recommender Systems using Taxonomies for Learning U.pdf 【WWW 2012 Best paper】Build Your Own Music Recommender by Modeling Internet R.pdf 【WWW 2013】A Personalized Recommender System Based on User’s Informatio.pdf 【WWW 2013】Diversified Recommendation on Graphs-Pitfalls, Measures, and Algorithms.pdf 【WWW 2013】Do Social Explanations Work-Studying and Modeling the Effects of S.pdf 【WWW 2013】Generation of Coalition Structures to Provide Proper Groups’.pdf 【WWW 2013】Learning to Recommend with Multi-Faceted Trust in Social Networks.pdf 【WWW 2013】Multi-Label Learning with Millions of Labels-Recommending Advertis.pdf 【WWW 2013】Personalized Recommendation via Cross-Domain Triadic Factorization.pdf 【WWW 2013】Profile Deversity in Search and Recommendation.pdf 【WWW 2013】Real-Time Recommendation of Deverse Related Articles.pdf 【WWW 2013】Recommendation for Online Social Feeds by Exploiting User Response.pdf 【WWW 2013】Recommending Collaborators Using Keywords.pdf 【WWW 2013】Signal-Based User Recommendation on Twitter.pdf 【WWW 2013】SoCo- A Social Network Aided Context-Aware Recommender System.pdf 【WWW 2013】Tailored News in the Palm of Your HAND-A Multi-Perspective Transpa.pdf 【WWW 2013】TopRec-Domain-Specific Recommendation through Community Topic Mini.pdf 【WWW 2013】User’s Satisfaction in Recommendation Systems for Groups-an .pdf 【WWW 2013】Using Link Semantics to Recommend Collaborations in Academic Socia.pdf 【WWW 2013】Whom to Mention-Expand the Diffusion of Tweets by @ Recommendation.pdf Recommender+Systems+Handbook.pdf tutorial.pdf 各个领域的推荐系统 图书 Amazon豆瓣读书当当网 新闻 Google NewsGenieoGetprismatic http://getprismatic.com/ 电影 NetflixJinniMovieLensRotten TomatoesFlixsterMTime 音乐 豆瓣电台LastfmPandoraMufinLalaEMusicPing虾米电台Jing.FM 视频 YoutubeHuluClciker 文章 CiteULikeGoogle ReaderStumbleUpon 旅游 WanderflyTripAdvisor 社会网络 FacebookTwitter 综合 AmazonGetGlueStrandsHunch 欢迎贡献资源~~待续","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://ipcreator.me/tags/Big-Data/"},{"name":"Data Mining","slug":"Data-Mining","permalink":"http://ipcreator.me/tags/Data-Mining/"}]},{"title":"谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革","date":"2017-02-18T01:02:06.000Z","path":"2017/02/18/SmartAI/ProgramAI/Tensorflow/changes-by-google-tensorflow/","text":"谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革 摘要：在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。 谷歌宣布将其最重要的创新项目之一 —— 人工智能引擎 ——作为开源项目发布到网上供大家免费使用，这展示了计算机软件行业正进行着什么样的变革。 最近，互联网巨头们接二连三地将自己线上核心业务所用的软件开源。项目开源加快了技术发展的进程。随着人工智能引擎TensorFlow的开源，谷歌能以各种方式为公司范围之外的机器学习研究提供支持，这些研究成果也将反馈给谷歌。 不过谷歌的人工智能引擎也反映了当今计算机硬件行业的发展趋势。在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。 根据负责谷歌AI项目的工程师Jeff Dean的说法，谷歌不仅用GPU训练其AI服务，而且还运行这些服务产品 —— 将它们植入用户手中的智能电话。 那是一次重大的转变。目前，Facebook在其庞大的计算机数据中心里用GPU训练人脸识别模型，但在为用户提供服务时 —— 真刀实战地在社交网站上识别人脸 —— 还是使用传统的处理器，或者CPU。Facebook的CTO Mike “Schrep” Schroepfer近日在公司总部举行的一次简短的记者见面会上指出，这种基本配置是目前的行业标准。但谷歌为了追求更高层次的效率，某些时候在数据中心里GPU既用来训练AI模型，又用来执行模型。谷歌也并不是踽踽独行。中国搜索引擎巨头百度也正在搭建一套类似的AI系统。“这是一次巨大的模式变革”，百度首席科学家Andrew Ng说道。 这一变革对于专注于GPU的芯片巨头NVIDIA来说是件好事。而且这也是世界最大的芯片制造商Intel产品的空白区。Intel不生产GPU。一些互联网企业和研究院开始关注可编程逻辑阵列FPGA了，将它作为AI领域的GPU替代品，并且Intel最近收购了一家专门生产可编程芯片的公司。 AI在全球的在线服务业务中扮演了越来越重要的角色 —— 备选芯片架构在AI中的地位也越来越重要。目前，在我们提供线上服务的计算机数据中心里已经如此了，若干年内，同样的现象也将会在移动设备上出现，因为我们使用的服务其实是相同的。 深度学习实践在谷歌、Facebook、微软、百度等公司，GPU被证明对“深度学习”非常有效，因为它可以并行处理许多小数据集。深度学习依赖于神经网络 —— 一种模拟人类大脑中神经元的系统 —— 这些网络是用来快速分析大量的数据。举个例子，为了教会神经网络识别一只猫，你就需要输入无数张猫的图像。GPU擅长处理这类任务。另外，它们的能耗也没有CPU这么高。 但是，这些公司在实际应用中使用深度学习技术时 —— 比如识别猫的手机App —— 这个App是由运行在CPU上的数据系统驱动的。根据在百度AI团队负责高性能计算系统的Bryan Catanzaro介绍，这是因为GPU只在持续不断输入数据的时候效率才高，而通常用来驱动手机App的数据服务器软件并不以这种方式往芯片传输数据。通常情况下，当收到手机App发来的请求后，服务器每次处理一个请求。Catanzaro解释道，如果你使用GPU分别处理收到的每个请求，“很难保证GPU有足够多的任务，让它能够有效运行。GPU从未真正发挥出作用。” 就是说，如果在执行环节你能不断地给GPU传入数据，那么它的效率比CPU高得多。百度正在其新的AI平台做这方面尝试。简单说来，就是请求发送到数据中心，然后将多个请求打包传入GPU。“我们打包这些请求，不再让处理器每次处理一个请求，而是每次处理多个请求，”Catanzaro说道。“别让GPU闲下来。” 目前还不清楚谷歌将如何处理这个问题。但是他们表示已经有TensorFlow在执行阶段使用GPU的案例。“基于不同的问题，我们有时候把GPU既用于训练，又用于识别，”谷歌发言人Jason Freidenfelds证实。 这似乎显得微不足道。事实上却是一项大工程。驱动这些AI应用产品的系统包括数十台、数百台、甚至上千台的机器。而且这些系统在我们日常生活中的地位日益重要。现在谷歌的深度学习技术不仅用来识别照片、识别语音、机器翻译，还用来提高搜索质量。其它公司也将同样的技术用于精准广告投放、计算机安全，甚至理解自然语言的应用。换句话说，像谷歌和百度这样的公司还需要大量的GPU。 无处不在的AI与此同时，TensorFlow也将其中一些AI产品从数据中心推向了智能手机端。 一般来说，如果在手机端使用深度学习相关的App，必须往数据中心回传信息。所有的AI都在服务器端。例如，你在安卓手机上执行了一个命令，这条命令必须传到谷歌的数据中心，在那里用巨大的CPU或者GPU网络来处理。 但是，谷歌也一直在提升自己的AI引擎，某些情况下可以在手机端执行完成。“你能使用一个模型描述，并且在手机端上运行”，Dean说，“而且你并不需要真的对模型描述或是代码做改动。” 谷歌的翻译App正是这么搭建的。谷歌在数据中心训练模型来识别单词和完成翻译，一旦训练完成，App就能独立地运行 —— 不需要网络连接。你可以把手机对准一块法语路牌，立即就能显示出英语翻译。 这要做好很困难。毕竟，手机的处理能力有限。随着时间推进，越来越多的这类任务会被迁移到手机端。深度学习软件会改进，移动设备硬件也在发展。“深度学习的未来在小巧灵活的移动设备上”，深度学习创业公司的创始人Chris Nicholson如是说。 举例来说，GPU正在试图寻找置入手机的方式，硬件制造商也在不断改进CPU的速度和效率。同时，IBM也在开发专为AI任务定制的“neuromorphic”芯片，使用过的人觉得它非常适合移动设备。 如今，谷歌的AI引擎不仅运行在服务器的CPU和GPU上，还运行在常规的智能手机芯片上。但据谷歌工程师Rajat Monga称，他们开发的TensorFlow能让工程师们轻而易举地迁移到其它硬件平台上。现在工具已经开源，外部人员也可以使用了。Dean如此描述TensorFlow：“它应该可以移植到各种硬件。”没错，硬件界也在经历变革 —— 和软件界并驾齐驱。 原文链接：TensorFlow, Google’s Open Source AI, Signals Big Changes in Hardware Too（译者/赵屹华 审校/刘帝伟、朱正贵 责编/周建丁） 译者简介：赵屹华，计算广告工程师@搜狗，前生物医学工程师，关注推荐算法、机器学习领域。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Python 资源大全中文版","date":"2017-02-18T01:02:06.000Z","path":"2017/02/18/SmartAI/ProgramAI/Tools/tools-of-python/","text":"作者：litai wong/wangaicc 我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-python 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。 Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。 我们要做什么？ 基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。 整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容： 《Scrapy：Python的爬虫框架》 《Flask：一个使用Python编写的轻量级Web应用框架》 如何参与本项目？从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。 不过加入前，有几个小要求： 英文还不错，能读懂英文并用自己的话复述； 在用 Python； 如有兴趣，请加 QQ：50872495。加 Q 时请注明「Python大全」 本项目的参与者 维护者： 贡献者：艾凌风、Namco、Daetalus、黄利民、atupal、rainbow、木头lbj 注：名单不分排名，不定期补充更新 奖励计划虽然奖励可能并不是你加入的主要原因，但还是有必要提一下： 整理超过 20 个资源后，可在伯乐在线上开通打赏； 每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品； 奖励详情 环境管理管理 Python 版本和环境的工具 p：非常简单的交互式 python 版本管理工具。官网 pyenv：简单的 Python 版本管理工具。官网 Vex：可以在虚拟环境中执行命令。官网 virtualenv：创建独立 Python 环境的工具。官网 virtualenvwrapper：virtualenv 的一组扩展。官网 包管理管理包和依赖的工具。 pip：Python 包和依赖关系管理工具。官网 pip-tools：保证 Python 包依赖关系更新的一组工具。官网 conda：跨平台，Python 二进制包管理工具。官网 Curdling：管理 Python 包的命令行工具。官网 wheel：Python 分发的新标准，意在取代 eggs。官网 包仓库本地 PyPI 仓库服务和代理。 warehouse：下一代 PyPI。官网 Warehouse：PyPA 提供的 PyPI 镜像工具。官网 bandersnatch devpi：PyPI 服务和打包/测试/分发工具。官网 localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。官网 分发打包为可执行文件以便分发。 PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。官网 dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。官网 Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。官网 py2app：将 Python 脚本变为独立软件包（Mac OS X）。官网 py2exe：将 Python 脚本变为独立软件包（Windows）。官网 pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python本身。官网 构建工具将源码编译成软件。 buildout：一个构建系统，从多个组件来创建，组装和部署应用。官网 BitBake：针对嵌入式 Linux 的类似 make 的构建工具。官网 fabricate：对任何语言自动找到依赖关系的构建工具。官网 PlatformIO：多平台命令行构建工具。官网 PyBuilder：纯 Python 实现的持续化构建工具。官网 SCons：软件构建工具。官网 交互式解析器交互式 Python 解析器。 IPython：功能丰富的工具，非常有效的使用交互式 Python。官网 bpython：界面丰富的 Python 解析器。官网 ptpython：高级交互式Python解析器， 构建于python-prompt-toolkit 之上。官网 文件文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。 imghdr：（Python 标准库）检测图片类型。官网 mimetypes：（Python 标准库）将文件名映射为 MIME 类型。官网 path.py：对 os.path 进行封装的模块。官网 pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。官网 python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。官网 Unipath：用面向对象的方式操作文件和目录。官网 watchdog：管理文件系统事件的 API 和 shell 工具官网 日期和时间操作日期和时间的类库。 arrow：更好的 Python 日期时间操作类库。官网 Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。官网 dateutil：Python datetime 模块的扩展。官网 delorean：解决 Python 中有关日期处理的棘手问题的库。官网 moment：一个用来处理时间和日期的Python库。灵感来自于Moment.js。官网 PyTime：一个简单易用的Python模块，用于通过字符串来操作日期/时间。官网 pytz：现代以及历史版本的世界时区定义。将时区数据库引入Python。官网 when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。官网 文本处理用于解析和操作文本的库。 通用 chardet：字符编码检测器，兼容 Python2 和 Python3。官网 difflib：(Python 标准库)帮助我们进行差异化比较。官网 ftfy：让Unicode文本更完整更连贯。官网 fuzzywuzzy：模糊字符串匹配。官网 Levenshtein：快速计算编辑距离以及字符串的相似度。官网 pangu.py：在中日韩语字符和数字字母之间添加空格。官网 yfiglet-figlet：pyfiglet -figlet 的 Python实现。 shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。官网 unidecode：Unicode 文本的 ASCII 转换形式 。官网 uniout：打印可读的字符，而不是转义的字符串。官网 xpinyin：一个用于把汉字转换为拼音的库。官网 Slug化 awesome-slugify：一个 Python slug 化库，可以保持 Unicode。官网 python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。官网 unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。官网 解析器 phonenumbers：解析，格式化，储存，验证电话号码。官网 PLY：lex 和 yacc 解析工具的 Python 实现。官网 Pygments：通用语法高亮工具。官网 pyparsing：生成通用解析器的框架。官网 python-nameparser：把一个人名分解为几个独立的部分。官网 python-user-agents：浏览器 user agent 解析器。官网 sqlparse：一个无验证的 SQL 解析器。官网 特殊文本格式处理一些用来解析和操作特殊文本格式的库。 通用 tablib：一个用来处理中表格数据的模块。官网 Office Marmir：把输入的Python 数据结构转换为电子表单。官网 openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。官网 python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。官网 unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。官网 XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。官网 xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。官网 xlwt：读写 Excel 文件的数据和格式信息。官网 / xlrd relatorio：模板化OpenDocument 文件。官网 PDF PDFMiner：一个用于从PDF文档中抽取信息的工具。官网 PyPDF2：一个可以分割，合并和转换 PDF 页面的库。官网 ReportLab：快速创建富文本 PDF 文档。官网 Markdown Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。官网 Python-Markdown：John Gruber’s Markdown 的 Python 版实现。官网 YAML PyYAML：Python 版本的 YAML 解析器。官网 CSV csvkit：用于转换和操作 CSV 的工具。官网 Archive unp：一个用来方便解包归档文件的命令行工具。官网 自然语言处理用来处理人类语言的库。 NLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。官网 jieba：中文分词工具。官网 langid.py：独立的语言识别系统。官网 Pattern：Python 网络信息挖掘模块。官网 SnowNLP：一个用来处理中文文本的库。官网 TextBlob：为进行普通自然语言处理任务提供一致的 API。官网 TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。官网 文档用以生成项目文档的库。 Sphinx：Python 文档生成器。官网 awesome-sphinxdoc：官网 MkDocs：对 Markdown 友好的文档生成器。官网 pdoc：一个可以替换Epydoc 的库，可以自动生成 Python 库的 API 文档。官网 Pycco：文学编程（literate-programming）风格的文档生成器。官网 配置用来保存和解析配置的库。 config：logging 模块作者写的分级配置模块。官网 ConfigObj：INI 文件解析器，带验证功能。官网 ConfigParser：(Python 标准库) INI 文件解析器。官网 profig：通过多种格式进行配置，具有数值转换功能。官网 python-decouple：将设置和代码完全隔离。官网 命令行工具用于创建命令行程序的库。 命令行程序开发 cement：Python 的命令行程序框架。官网 click：一个通过组合的方式来创建精美命令行界面的包。官网 cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。官网 clint：Python 命令行程序工具。官网 colorama：跨平台彩色终端文本。官网 docopt：Python 风格的命令行参数解析器。官网 Gooey：一条命令，将命令行程序变成一个 GUI 程序。官网 python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。官网 Pythonpy：在命令行中直接执行任何Python指令。官网 生产力工具 aws-cli：Amazon Web Services 的通用命令行界面。官网 bashplotlib：在终端中进行基本绘图。官网 caniusepython3：判断是哪个项目妨碍你你移植到 Python 3。官网 cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。官网 doitlive：一个用来在终端中进行现场演示的工具。官网 howdoi：通过命令行获取即时的编程问题解答。官网 httpie：一个命令行HTTP 客户端，cURL 的替代品，易用性更好。官网 PathPicker：从bash输出中选出文件。官网 percol：向UNIX shell 传统管道概念中加入交互式选择功能。官网 SAWS：一个加强版的 AWS 命令行。官网 thefuck：修正你之前的命令行指令。官网 mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。官网 pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。官网 下载器用来进行下载的库. s3cmd：一个用来管理Amazon S3 和 CloudFront 的命令行工具。官网 s4cmd：超级 S3 命令行工具，性能更加强劲。官网 you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。官网 youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。官网 图像处理用来操作图像的库. pillow：Pillow 是一个更加易用版的 PIL。官网 hmap：图像直方图映射。官网 imgSeek：一个使用视觉相似性搜索一组图片集合的项目。官网 nude.py：裸体检测。官网 pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。官网 pygram：类似 Instagram 的图像滤镜。官网 python-qrcode：一个纯 Python 实现的二维码生成器。官网 Quads：基于四叉树的计算机艺术。官网 scikit-image：一个用于（科学）图像处理的 Python 库。官网 thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。官网 wand：MagickWand的Python 绑定。MagickWand 是 ImageMagick的 C API 。官网 OCR光学字符识别库。 pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。官网 pytesseract：Google Tesseract OCR 的另一个封装(wrapper)。官网 python-tesseract - Google Tesseract OCR 的一个包装类。 音频用来操作音频的库 audiolazy：Python 的数字信号处理包。官网 audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。官网 beets：一个音乐库管理工具及 MusicBrainz 标签添加工具官网 dejavu：音频指纹提取和识别官网 django-elastic-transcoder：Django + Amazon Elastic Transcoder。官网 eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。官网 id3reader：一个用来读取 MP3 元数据的 Python 模块。官网 m3u8：一个用来解析 m3u8 文件的模块。官网 mutagen：一个用来处理音频元数据的 Python 模块。官网 pydub：通过简单、简洁的高层接口来操作音频文件。官网 pyechonest：Echo Nest API 的 Python 客户端官网 talkbox：一个用来处理演讲/信号的 Python 库官网 TimeSide：开源 web 音频处理框架。官网 tinytag：一个用来读取MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。官网 mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。官网 Video用来操作视频和GIF的库。 moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。官网 scikit-video：SciPy 视频处理常用程序。官网 地理位置地理编码地址以及用来处理经纬度的库。 GeoDjango：世界级地理图形 web 框架。官网 GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。官网 geojson：GeoJSON 的 Python 绑定及工具。官网 geopy：Python 地址编码工具箱。官网 pygeoip：纯 Python GeoIP API。官网 django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。官网 HTTP使用HTTP的库。 requests：人性化的HTTP请求库。官网 grequests：requests 库 + gevent ，用于异步 HTTP 请求.官网 httplib2：全面的 HTTP 客户端库。官网 treq：类似 requests 的Python API 构建于 Twisted HTTP 客户端之上。官网 urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。官网 数据库Python实现的数据库。 pickleDB：一个简单，轻量级键值储存数据库。官网 PipelineDB：流式 SQL 数据库。官网 TinyDB：一个微型的，面向文档型数据库。官网 ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。官网 数据库驱动用来连接和操作数据库的库。 ySQL：awesome-mysql系列 mysql-python：Python 的 MySQL 数据库连接器。官网 ysqlclient：mysql-python 分支，支持 Python 3。 oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs.官网 PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。官网 PostgreSQL psycopg2：Python 中最流行的 PostgreSQL 适配器。官网 queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。官网 txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。官网 其他关系型数据库 apsw：另一个 Python SQLite封装。官网 dataset：在数据库中存储Python字典 pymssql：一个简单的Microsoft SQL Server数据库接口。官网 NoSQL 数据库 cassandra-python-driver：Cassandra 的 Python 驱动。官网 HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。官网 Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。官网 py2neo：Neo4j restful 接口的Python 封装客户端。官网 pycassa：Cassandra 的 Python Thrift 驱动。官网 PyMongo：MongoDB 的官方 Python 客户端。官网 redis-py：Redis 的 Python 客户端。官网 telephus：基于 Twisted 的 Cassandra 客户端。官网 txRedis：基于 Twisted 的 Redis 客户端。官网 ORM实现对象关系映射或数据映射技术的库。 关系型数据库 Django Models：Django 的一部分。官网 SQLAlchemy：Python SQL 工具以及对象关系映射工具。官网 awesome-sqlalchemy系列 Peewee：一个小巧，富有表达力的 ORM。官网 PonyORM：提供面向生成器的 SQL 接口的 ORM。官网 python-sql：编写 Python 风格的 SQL 查询。官网 NoSQL 数据库 django-mongodb-engine：Django MongoDB 后端。官网 PynamoDB：Amazon DynamoDB 的一个 Python 风格接口。官网 flywheel：Amazon DynamoDB 的对象映射工具。官网 MongoEngine：一个Python 对象文档映射工具，用于 MongoDB。官网 hot-redis：为 Redis 提供 Python 丰富的数据类型。官网 redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。官网 其他 butterdb：Google Drive 电子表格的 Python ORM。官网 Web 框架全栈 Web 框架。 Django：Python 界最流行的 web 框架。官网 awesome-django系列 Flask：一个 Python 微型框架。官网 awesome-flask系列 yramid：一个小巧，快速，接地气的开源Python web 框架。 awesome-pyramid系列 Bottle：一个快速小巧，轻量级的 WSGI 微型 web 框架。官网 CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有WSGI 线程池。官网 TurboGears：一个可以扩展为全栈解决方案的微型框架。官网 web.py：一个 Python 的 web 框架，既简单，又强大。官网 web2py：一个全栈 web 框架和平台，专注于简单易用。官网 Tornado：一个web 框架和异步网络库。官网 权限允许或拒绝用户访问数据或功能的库。 Carteblanche：Module to align code with thoughts of users and designers. Also magically handles navigation and permissions.官网 django-guardian：Django 1.2+ 实现了单个对象权限。官网 django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。官网 CMS内容管理系统 django-cms：一个开源的，企业级 CMS，基于 Django。官网 djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。官网 FeinCMS：基于 Django 构建的最先进的内容管理系统之一。官网 Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。官网 Mezzanine：一个强大的，持续的，灵活的内容管理平台。官网 Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。官网 Plone：一个构建于开源应用服务器 Zope 之上的 CMS。官网 Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。官网 Wagtail：一个 Django 内容管理系统。官网 Widgy：最新的 CMS 框架，基于 Django。官网 电子商务用于电子商务以及支付的框架和库。 django-oscar：一个用于 Django 的开源的电子商务框架。官网 django-shop：一个基于 Django 的店铺系统。官网 Cartridge：一个基于 Mezzanine 构建的购物车应用。官网 shoop：一个基于 Django 的开源电子商务平台。官网 alipay：非官方的 Python 支付宝 API。官网 merchant：一个可以接收来自多种支付平台支付的 Django 应用。官网 money：货币类库with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.官网 python-currencies：显示货币格式以及它的数值。官网 RESTful API用来开发RESTful APIs的库 Django django-rest-framework：一个强大灵活的工具，用来构建 web API。官网 django-tastypie：为Django 应用开发API。官网 django-formapi：为 Django 的表单验证，创建 JSON APIs 。官网 Flask flask-api：为 flask 开发的，可浏览 Web APIs 。官网 flask-restful：为 flask 快速创建REST APIs 。官网 flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。官网 flask-api-utils：为 Flask 处理 API 表示和验证。官网 eve：REST API 框架，由 Flask, MongoDB 等驱动。官网 Pyramid cornice：一个Pyramid 的 REST 框架 。官网 与框架无关的 falcon：一个用来建立云 API 和 web app 后端的噶性能框架。官网 sandman：为现存的数据库驱动系统自动创建 REST APIs 。官网 restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。官网 ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。官网 验证实现验证方案的库。 OAuth Authomatic：简单但是强大的框架，身份验证/授权客户端。官网 django-allauth：Django 的验证应用。官网 django-oauth-toolkit：为 Django 用户准备的 OAuth2。官网 django-oauth2-provider：为 Django 应用提供 OAuth2 接入。官网 Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。官网 OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。官网 python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。官网 python-social-auth：一个设置简单的社会化验证方式。官网 rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。官网 sanction：一个超级简单的OAuth2 客户端实现。官网 其他 jose：JavaScript 对象签名和加密草案的实现。官网 PyJWT：JSON Web 令牌草案 01。官网 python-jws：JSON Web 签名草案 02 的实现。官网 python-jwt：一个用来生成和验证 JSON Web 令牌的模块。官网 模板引擎模板生成和词法解析的库和工具。 Jinja2：一个现代的，对设计师友好的模板引擎。官网 Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。官网 Genshi：Python 模板工具，用以生成 web 感知的结果。官网 Mako：Python 平台的超高速轻量级模板。官网 Queue处理事件以及任务队列的库。 celery：一个异步任务队列/作业队列，基于分布式消息传递。官网 huey：小型多线程任务队列。官网 mrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。官网 rq：简单的 Python 作业队列。官网 simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。官网 搜索对数据进行索引和执行搜索查询的库和软件。 django-haystack：Django 模块化搜索。官网 elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。官网 elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。官网 solrpy：solr的 Python 客户端。官网 Whoosh：一个快速的纯 Python 搜索引擎库。官网 动态消息用来创建用户活动的库。 django-activity-stream：从你的站点行为中生成通用活动信息流。官网 Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。官网 资源管理管理、压缩、缩小网站资源的工具。 django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。官网 django-storages：一个针对 Django 的自定义存储后端的工具集合。官网 fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。官网 File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。官网 Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。官网 jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。官网 webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。官网 缓存缓存数据的库。 Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python脚本和应用上。官网 django-cache-machine：Django 模型的自动缓存和失效。官网 django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。官网 django-viewlet：渲染模板，同时具有额外的缓存控制功能。官网 dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。官网 HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。官网 johnny-cache：django应用缓存框架。官网 pylibmc：libmemcached 接口的 Python 封装。官网 电子邮件用来发送和解析电子邮件的库。 django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。官网 envelopes：供人类使用的电子邮件库。官网 flanker：一个 email 地址和 Mime 解析库。官网 imbox：Python IMAP 库官网 inbox.py：Python SMTP 服务器。官网 inbox：一个开源电子邮件工具箱。官网 lamson：Python 风格的 SMTP 应用服务器。官网 mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。官网 marrow.mailer：高性能可扩展邮件分发框架。官网 modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。官网 pyzmail：创建，发送和解析电子邮件。官网 Talon：Mailgun 库，用来抽取信息和签名。官网 国际化用来进行国际化的库。 Babel：一个Python 的国际化库。官网 Korean：一个韩语词态库。官网 URL处理解析URLs的库 furl：一个让处理 URL 更简单小型 Python 库。官网 purl：一个简单的，不可变的URL类，具有简洁的 API 来进行询问和处理。官网 pyshorteners：一个纯 Python URL 缩短库。官网 shorturl：生成短小 URL 和类似 bit.ly 短链的Python 实现。官网 webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado和 Pyramid。官网 HTML处理处理 HTML和XML的库。 BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。官网 bleach：一个基于白名单的 HTML 清理和文本链接库。官网 cssutils：一个 Python 的 CSS 库。官网 html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。官网 lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。官网 MarkupSafe：为Python 实现 XML/HTML/XHTML 标记安全字符串。官网 pyquery：一个解析 HTML 的库，类似 jQuery。官网 untangle：将XML文档转换为Python对象，使其可以方便的访问。官网 xhtml2pdf：HTML/CSS 转 PDF 工具。官网 xmltodict：像处理 JSON 一样处理 XML。官网 爬取网络站点的库 Scrapy：一个快速高级的屏幕爬取及网页采集框架。官网 cola：一个分布式爬虫框架。官网 Demiurge：基于PyQuery 的爬虫微型框架。官网 feedparser：通用 feed 解析器。官网 Grab：站点爬取框架。官网 MechanicalSoup：用于自动和网络站点交互的 Python 库。官网 portia：Scrapy 可视化爬取。官网 pyspider：一个强大的爬虫系统。官网 RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。官网 网页内容提取用于进行网页内容提取的库。 Haul：一个可以扩展的图像爬取工具。官网 html2text：将 HTML 转换为 Markdown 格式文本官网 lassie：人性化的网页内容检索库。官网 micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。官网 newspaper：使用 Python 进行新闻提取，文章提取以及内容策展。官网 opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python模块。官网 python-goose：HTML内容/文章提取器。官网 python-readability：arc90 公司 readability 工具的 Python 高速端口。官网 sanitize：为杂乱的数据世界带来调理性。官网 sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。官网 textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。官网 表单进行表单操作的库。 Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。官网 django-bootstrap3：集成了 Bootstrap 3 的 Django。官网 django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don’t repeat yourself） 的方式来创建美观的表单。官网 django-remote-forms：一个平台独立的 Django 表单序列化工具。官网 WTForms：一个灵活的表单验证和呈现库。官网 WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。官网 数据验证数据验证库。多用于表单验证。 Cerberus：A mappings-validator with a variety of rules, normalization-features and simple customization that uses a pythonic schema-definition.官网 colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。官网 kmatch：一种用于匹配/验证/筛选 Python 字典的语言。官网 schema：一个用于对 Python 数据结构进行验证的库。官网 Schematics：数据结构验证。官网 valideer：轻量级可扩展的数据验证和适配库。官网 voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python的 JSON，YAML 等数据。官网 反垃圾技术帮助你和电子垃圾进行战斗的库。 django-simple-captcha：一个简单、高度可定制的Django 应用，可以为任何Django表单添加验证码。官网 django-simple-spam-blocker：一个用于Django的简单的电子垃圾屏蔽工具。官网 标记用来进行标记的库。 django-taggit：简单的 Django 标记工具。官网 管理面板管理界面库。 Ajenti：一个你的服务器值得拥有的管理面板。官网 django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。官网 django-xadmin：Django admin 的一个替代品，具有很多不错的功能。官网 flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。官网 flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。官网 Grappelli：Django 管理界面的一个漂亮的皮肤。官网 Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。官网 静态站点生成器静态站点生成器是一个软件，它把文本和模板作为输入，然后输出HTML文件。 Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。官网 Cactus：为设计师设计的静态站点生成器。官网 Hyde：基于 Jinja2 的静态站点生成器。官网 Nikola：一个静态网站和博客生成器。官网 Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由Sphinx驱动。官网 Lektor：一个简单易用的静态 CMS 和博客引擎。官网 进程操作系统进程启动及通信库。 envoy：比 Python subprocess 模块更人性化。官网 sarge：另一 种 subprocess 模块的封装。官网 sh：一个完备的 subprocess 替代库。官网 并发和并行用以进行并发和并行操作的库。 multiprocessing：(Python 标准库) 基于进程的“线程”接口。官网 threading：(Python 标准库)更高层的线程接口。官网 eventlet：支持 WSGI 的异步框架。官网 gevent：一个基于协程的 Python 网络库，使用greenlet。官网 Tomorrow：用于产生异步代码的神奇的装饰器语法实现。官网 网络用于网络编程的库。 asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。官网 Twisted：一个事件驱动的网络引擎。官网 pulsar：事件驱动的并发框架。官网 diesel：基于Greenlet 的事件 I/O 框架。官网 pyzmq：一个 ZeroMQ 消息库的 Python 封装。官网 txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。官网 WebSocket帮助使用WebSocket的库。 AutobahnPython：给 Python 、使用的 WebSocket &amp; WAMP 基于 Twisted 和 asyncio。官网 Crossbar：开源统一应用路由(Websocket &amp; WAMP for Python on Autobahn).官网 django-socketio：给 Django 用的 WebSockets。官网 WebSocket-for-Python：为Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。官网 WSGI 服务器兼容 WSGI 的 web 服务器 gunicorn：Pre-forked, 部分是由 C 语言编写的。官网 uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。官网 bjoern：异步，非常快速，由 C 语言编写。官网 fapws3：异步 (仅对于网络端)，由 C 语言编写。官网 meinheld：异步，部分是由 C 语言编写的。官网 netius：异步，非常快速。官网 paste：多线程，稳定，久经考验。官网 rocket：多线程。官网 waitress：多线程, 是它驱动着 Pyramid 框架。官网 Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。官网 RPC 服务器兼容 RPC 的服务器。 SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。官网 SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。官网 zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。官网 密码学 cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。官网 hashids：在 Python 中实现 hashids 。官网 Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。官网 Passlib：安全密码存储／哈希库，官网 PyCrypto：Python 密码学工具箱。官网 PyNacl：网络和密码学(NaCl) 库的 Python 绑定。官网 图形用户界面用来创建图形用户界面程序的库。 curses：内建的 ncurses 封装，用来创建终端图形用户界面。官网 enaml：使用类似 QML 的Declaratic语法来创建美观的用户界面。官网 kivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS平台上。官网 pyglet：一个Python 的跨平台窗口及多媒体库。官网 PyQt：跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4 和 Qt v5。官网 PySide：P跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4。官网 Tkinter：Tkinter 是 Python GUI 的一个事实标准库。官网 Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。官网 urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。官网 wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。官网 PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定官网 Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。官网 游戏开发超赞的游戏开发库。 Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。官网 Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用C++编写, 针对 Python 进行了完全的封装。官网 Pygame：Pygame 是一组 Python 模块，用来编写游戏。官网 PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。官网 PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。官网 PySDL2：SDL2 库的封装，基于 ctypes。官网 RenPy：一个视觉小说（visual novel）引擎。官网 日志用来生成和操作日志的库。 logging：(Python 标准库) 为 Python 提供日志功能。官网 logbook：Logging 库的替代品。官网 Eliot：为复杂的和分布式系统创建日志。官网 Raven：Sentry的 Python 客户端。官网 Sentry：实时记录和收集日志的服务器。官网 Testing进行代码库测试和生成测试数据的库。 测试框架 unittest：(Python 标准库) 单元测试框架。官网 nose：nose 扩展了 unittest 的功能。官网 contexts：一个 Python 3.3+ 的 BDD 框架。受到C# hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。官网 mamba：Python 的终极测试工具， 拥护BDD。官网 PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。官网 pyshould：Should 风格的断言，基于 PyHamcrest。官网 pytest：一个成熟的全功能 Python 测试工具。官网 green：干净，多彩的测试工具。官网 pyvows：BDD 风格的测试工具，受Vows.js的启发。官网- Robot Framework：一个通用的自动化测试框架。官网 Web 测试 Selenium：Selenium WebDriver 的 Python 绑定。官网 locust：使用 Python 编写的，可扩展的用户加载测试工具。官网 sixpack：一个和语言无关的 A/B 测试框架。官网 splinter：开源的 web 应用测试工具。官网 Mock测试 mock：(Python 标准库) 一个用于伪造测试的库。官网 doublex：Python 的一个功能强大的 doubles 测试框架。官网 freezegun：通过伪造日期模块来生成不同的时间。官网 httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。官网 httpretty：Python 的 HTTP 请求 mock 工具。官网 responses：伪造 Python 中的 requests 库的一个通用库。官网 VCR.py：在你的测试中记录和重放 HTTP 交互。官网 对象工厂 factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。官网 mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。官网 modelmommy：为 Django 测试创建随机固件官网 代码覆盖率 coverage：代码覆盖率测量。官网 伪数据 faker：一个 Python 库，用来生成伪数据。官网 fake2db：伪数据库生成器。官网 radar：生成随机的日期/时间。官网 错误处理 FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。官网 代码分析和Lint工具进行代码分析，解析和操作代码库的库和工具。 代码分析 code2flow：把你的 Python 和 JavaScript 代码转换为流程图。官网 pycallgraph：这个库可以把你的Python 应用的流程(调用图)进行可视化。官网 pysonar2：Python 类型推断和检索工具。官网 Lint工具 Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。官网 Pylint：一个完全可定制的源码分析器。官网 pylama：Python 和 JavaScript 的代码审查工具。官网 Debugging Tools用来进行代码调试的库。 调试器 ipdb：IPython 启用的 pdb。官网 pudb：全屏，基于控制台的 Python 调试器。官网 pyringe：可以在 Python 进程中附加和注入代码的调试器。官网 wdb：一个奇异的 web 调试器，通过 WebSockets 工作。官网 winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。官网 django-debug-toolbar：为 Django 显示各种调试信息。官网 django-devserver：一个 Django 运行服务器的替代品。官网 flask-debugtoolbar：django-debug-toolbar 的 flask 版。官网 性能分析器 lineprofiler：逐行性能分析。官网 memoryprofiler：监控 Python 代码的内存使用。官网 profiling：一个交互式 Python 性能分析工具。官网 其他 pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。官网 python-statsd：statsd 服务器的 Python 客户端。官网 Science and Data Analysis用来进行科学计算和数据分析的库。 astropy：一个天文学 Python 库。官网 bcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。官网 bccb：生物分析相关代码集合官网 Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。官网 blaze：NumPy 和 Pandas 的大数据接口。官网 cclib：一个用来解析和解释计算化学软件包输出结果的库。官网 NetworkX：一个为复杂网络设计的高性能软件。官网 Neupy：执行和测试各种不同的人工神经网络算法。官网 Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由Cython 和 NumPy 的开发者开发。官网 NumPy：使用 Python 进行科学计算的基础包。官网 Open Babel：一个化学工具箱，用来描述多种化学数据。官网 Open Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。官网 orange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。官网 Pandas：提供高性能，易用的数据结构和数据分析工具。官网 PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。官网 PyMC：马尔科夫链蒙特卡洛采样工具。官网 RDKit：化学信息学和机器学习软件。官网 SciPy：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。官网 statsmodels：统计建模和计量经济学。官网 SymPy：一个用于符号数学的 Python 库。官网 zipline：一个 Python 算法交易库。官网 数据可视化进行数据可视化的库。 参见: awesome-javascript。 matplotlib：一个 Python 2D 绘图库。官网 bokeh：用 Python 进行交互式 web 绘图。官网 ggplot：ggplot2 给 R 提供的 API 的 Python 版本。官网 plotly：协同 Python 和 matplotlib 工作的 web 绘图库。官网 pygal：一个 Python SVG 图表创建工具。官网 pygraphviz：Graphviz 的 Python 接口。官网 PyQtGraph：交互式实时2D/3D/图像绘制及科学/工程学组件。官网 SnakeViz：一个基于浏览器的 Python’s cProfile 模块输出结果查看工具。官网 vincent：把 Python 转换为 Vega 语法的转换工具。官网 VisPy：基于 OpenGL 的高性能科学可视化工具。官网 计算机视觉计算机视觉库。 OpenCV：开源计算机视觉库。官网 SimpleCV：一个用来创建计算机视觉应用的开源框架。官网 机器学习机器学习库。 参见: awesome-machine-learning. Crab：灵活、快速的推荐引擎。官网 gensim：人性化的话题建模库。官网 hebel：GPU 加速的深度学习库。官网 NuPIC：智能计算 Numenta 平台。官网 pattern：Python 网络挖掘模块。官网 PyBrain：另一个 Python 机器学习库。官网 Pylearn2：一个基于 Theano 的机器学习库。官网 python-recsys：一个用来实现推荐系统的 Python 库。官网 scikit-learn：基于 SciPy 构建的机器学习 Python 模块。官网 pydeep：Python 深度学习库。官网 vowpalporpoise：轻量级 Vowpal Wabbit 的 Python 封装。官网 skflow：一个 TensorFlow 的简化接口(模仿 scikit-learn)。官网 MapReduceMapReduce 框架和库。 dpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。官网 dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。官网 luigi：这个模块帮你构建批处理作业的复杂流水线。官网 mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。官网 PySpark：Spark 的 Python API 。官网 streamparse：运行针对事实数据流的 Python 代码。集成了Apache Storm。官网 函数式编程使用 Python 进行函数式编程。 CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。官网 fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。官网 funcy：炫酷又实用的函数式工具。官网 Toolz：一组用于迭代器，函数和字典的函数式编程工具。官网 第三方 API用来访问第三方 API的库。 参见： List of Python API Wrappers and Libraries。 apache-libcloud：一个为各种云设计的 Python 库。官网 boto：Amazon Web Services 的 Python 接口。官网 django-wordpress：WordPress models and views for Django.官网 facebook-sdk：Facebook 平台的 Python SDK.官网 facepy：Facepy 让和 Facebook’s Graph API 的交互变得更容易。官网 gmail：Gmail 的 Python 接口。官网 google-api-python-client：Python 用的 Google APIs 客户端库。官网 gspread：Google 电子表格的 Python API.官网 twython：Twitter API 的封装。官网 DevOps 工具用于 DevOps 的软件和库。 Ansible：一个非常简单的 IT 自动化平台。官网 SaltStack：基础设施自动化和管理系统。官网 OpenStack：用于构建私有和公有云的开源软件。官网 Docker Compose：快速，分离的开发环境，使用 Docker。官网 Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。官网 cuisine：为 Fabric 提供一系列高级函数。官网 Fabtools：一个用来编写超赞的 Fabric 文件的工具。官网 gitapi：Git 的纯 Python API。官网 hgapi：Mercurial 的纯 Python API。官网 honcho：Foreman的 Python 克隆版，用来管理基于Procfile的应用。官网 pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。官网 psutil：一个跨平台进程和系统工具模块。官网 supervisor：UNIX 的进程控制系统。官网 任务调度任务调度库。 APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。官网 django-schedule：一个 Django 排程应用。官网 doit：一个任务执行和构建工具。官网 gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。官网 Joblib：一组为 Python 提供轻量级作业流水线的工具。官网 Plan：如有神助地编写 crontab 文件。官网 schedule：人性化的 Python 任务调度库。官网 Spiff：使用纯 Python 实现的强大的工作流引擎。官网 TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。官网 外来函数接口使用外来函数接口的库。 cffi：用来调用 C 代码的外来函数接口。官网 ctypes：(Python 标准库) 用来调用 C 代码的外来函数接口。官网 PyCUDA：Nvidia CUDA API 的封装。官网 SWIG：简化的封装和接口生成器。官网 高性能让 Python 更快的库。 Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。官网 PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。官网 PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。官网 Pyston：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。官网 Stackless Python：一个强化版的 Python。官网 微软的 Windows平台在 Windows 平台上进行 Python 编程。 Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。官网 pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。官网 PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。官网 PyWin32：针对 Windows 的Python 扩展。官网 WinPython：Windows 7/8 系统下便携式开发环境。官网 网络可视化和SDN用来进行网络可视化和SDN(软件定义网络)的工具和库。 Mininet：一款流行的网络模拟器以及用 Python 编写的 API。官网 POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。官网 Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。官网 SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。官网 硬件用来对硬件进行编程的库。 ino：操作Arduino的命令行工具。官网 Pyro：Python 机器人编程库。官网 PyUserInput：跨平台的，控制鼠标和键盘的模块。官网 scapy：一个非常棒的操作数据包的库。官网 wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作WiFi。官网 Pingo：Pingo 为类似Raspberry Pi，pcDuino， Intel Galileo等设备提供统一的API用以编程。官网 兼容性帮助从 Python 2 向 Python 3迁移的库。 Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。官网 Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。官网 Six：Python 2 和 3 的兼容性工具。官网 杂项不属于上面任何一个类别，但是非常有用的库。 blinker：一个快速的 Python 进程内信号/事件分发系统。官网 itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。官网 pluginbase：一个简单但是非常灵活的 Python 插件系统。官网 Pychievements：一个用来创建和追踪成就的 Python 框架。官网 Tryton：一个通用商务框架。官网 算法和设计模式Python 实现的算法和设计模式。 algorithms：一个 Python 算法模块。官网 python-patterns：Python 设计模式的集合。官网 sortedcontainers：快速，纯 Python 实现的SortedList，SortedDict 和 SortedSet 类型。官网 编辑器插件编辑器和 IDE 的插件 Emacs Elpy：Emacs Python 开发环境。官网 Sublime Text SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。官网 Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。官网 Vim YouCompleteMe：引入基于 Jedi 的 Python 自动补全引擎。官网 Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。官网 Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。官网 Visual Studio PTVS：Visual Studio 的 Python 工具官网 集成开发环境流行的 Python 集成开发环境。 PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。官网 LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。官网 Spyder：开源 Python IDE。官网 服务在线工具和简化开发的 API 。 持续集成参见: awesome-CIandCD. Travis CI：一个流行的工具，为你的开源和私人项目提供持续集成服务。(仅支持 GitHub)官网 CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)官网 Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。官网 Wercker：基于 Docker 平台，用来构建和部署微服务。官网 代码质量 Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。官网 QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。官网 资源在这里可以找到新的 Python 库。 网站 r/Python CoolGithubProjects Django Packages Full Stack Python Python 3 Wall of Superpowers Python Hackers Python ZEEF Trending Python repositories on GitHub today PyPI Ranking 周刊 Import Python Newsletter Pycoder’s Weekly Python Weekly Twitter @codetengu @getpy @planetpython @pycoders @pypi @pythontrending @PythonWeekly 学习指南 Scipy-lecture-notes：如何用Python来做学术？官网 SScientific-python-lectures：Python科学计算的资料。官网 Mario-Level-1：用Python和Pygame写的超级马里奥第一关。官网 Python Koans：Python的交互式学习工具。官网 Minecraft：用python写的Minecraft游戏。官网 pycrumbs：Python资源大全。官网 python-patterns：使用python实现设计模式。官网 Projects：Python项目大集合。官网 The Hitchhiker’s Guide to Python：旅行者的Python学习指南。官网 知名网站值得关注的 Python 技术站点。 中文站点 伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。官网 英文站点 待补充 微博、微信公众号 Python开发者 微博：@Python开发者 Python开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享Python技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://ipcreator.me/tags/Python/"}]},{"title":"超智能体","date":"2017-02-17T23:53:06.000Z","path":"2017/02/18/SmartAI/ProgramAI/Concepts/super-intelligence-individual/","text":"作者：yjango 生命不限于个体。并非所有生命拥有意识，但所有生命都拥有智能。这些智能体通过大量并行和多层迭代的方式形成新的智能体。细胞、器官、个体、国家、地球，不论从哪个层级上观察，都是一个“智能体”。人类作为智能的一环，需跳出自身层级，用超出人类自身感知、情感和意识的方式去理解生命。 关于本书该书最终的目的是：通过理解智能，学习如何学习。 如何机器学习 如何大脑学习 如何阅读 智能并非人类所特有，而是自生命诞生时起就产生了。没有智能就没有生命。智能又并非单一状态，它和宇宙一样，都在不断的扩张。不同阶段的智能表现出的能力不同。神经元、蚁群、人类、社会、国家、地球，乃至整个宇宙都可被视为智能体。它们通过组合和迭代来形成更高级的智能功能。智能从未停止发展，而我们人类也只不过是其中一个“细胞”。这本书将从智能的角度展示对世界的不同理解。 核心知识：并非每个章节的内容本身（读者完全可以找到很多对应内容的经典书籍）。真正有价值的是将这些知识以何种方式排列和表达。 传达方式：语言是交流的工具，而交流的前提是双方的脑中都有相同内容。但是读者和作者的信息是不对等的。语言作为教学手段本身就有限。所以我描述的方式也并非直接告诉读者一个结论，打上这就是真理的标签，而是结合图，结合例子尽可能的消除信息的不等。我不是以教学者的身份来分享知识，而是引出一个问题让读者一起思考。虽然我提供了我的见解，但我相信会有很多读者能提出比我更好的见解。 行文风格 行文分很多部分，彼此的关系是递进或并列。每个部分通常会以一个问题的引入开始，结合若干实例对该问题进行思考，经过描述，最后得出总结性概括。文中带链接的内容请打开观看。 表达格式问题：一、斜线文字 实例： 例子（情景、方式等）：普通格式 描述：普通格式 结论： 引用格式 例如 猫咪觉得自己属于人类吗？ 实例1：实例内容 实例2：实例内容 描述内容 猫咪觉得人类属于自己 智能的起源我们对智能的探索陷入了错误的方式中。 一、如果某天所有人类突然失忆，在不拆开计算机的情况下，我们该如何弄清计算机的工作原理，并给计算机下一个定义？ 方式：从计算机软件开始研究，描述各种软件的功能，并找一个可以概括所有功能的定义。人们会发现计算机可以产生图像。但很快又发现很多软件并没有图形界面。有的软件可以玩射击游戏，有的却可以操控机械。各式各样的功能会被人们发现并逐一分类，使得用一个定义概括所有功能成为不可能。更不用说这些软件的功能还在持续增长。 显然我们并不以具体功能，而是以计算机最基本的工作原理去定义计算机。如今人们对智能的探索正是陷入了以功能来研究智能的方式中。人们把智能划分成了认知、理解、思考、学习等各式各样的功能并研究着，使得研究不同功能的专家对智能的定义都不相同。 如果我们能够知道宇宙自大爆炸之后是以何种方式进行扩张的。我们就可以从起点开始，推测出所有星系可能的形状甚至它们在未来可能的形状。 所以要想搞清智能的本质，不妨先试着找出智能的源头，思考一下为什么会产生智能。 智能的研究需要从智能的源头开始 智能的本质一、生命是如何产生的？在漫漫的宇宙演变中，我想很多星球都有产生生命的概率。 情景：想象某刻火星上产生了生命，但却遇到高温又被分解成了无机物。 第二个产生的生命却因为找不到支持机体的能源而再次化成了无机物。 第三个有机体幸运的诞生在大量能源旁，却由于能源的耗尽而前功尽弃。 问题的关键并非生命能否产生，而是产生的生命能否存活。 二、究竟是什么阻碍了生命，生命又该如何存活？如果世界是静止的，那么生命自然不朽。然而我们的世界在时时刻刻发生着变化，会从一个状态变化到另一个状态。生物无从知道下一刻等待它的究竟是毁灭还是幸存？这种未来的不确定性（uncertainty）阻碍了生命的延续。 实例： 植物会因为干旱而枯萎；野兽会因为捕不到猎物而饿死；每天又有约160中国人死于交通事故。 阻碍生命的正是这种不可预测性（随机），它还有另一个名字，叫做熵（entropy）。而热力学第二定律表述孤立系统会自发的朝向最大熵状态演化。 实例： 我们房间会越来越乱，掉在地上的杯子的碎片会随处散落，熵会自发性的不断增加。我们从未见过房间自己越来越整洁，将杯子碎片会摔出一个完整的杯子的情况。说明了熵增在孤立系统下并不可逆。 熵增不可逆的现象也意味着世界持续的发生变化。在过去可能产生过无数个生命，但只有那些可以根据变化而做出相应变化的生命才能躲避危险从而幸存。这种能力就是智能，同时也是生命得以延续的原因。 智能：可以根据环境变化而做出相应变化的能力 由于阻止生命延续的实际是不确定性（随机性、不可预测性），那生命所做的就是减少该不确定性来延续。 奥地利物理学家薛定谔在《生命是什么》首次提出负熵的概念，并认为生命以负熵为生，所以智能也可被描述是： 智能：熵减的能力 线性代数 一、什么是线性代数？不断变化的世界使我们产生时间观念。正确描述事物状态及其不同时间下的变化至关重要。我们知道在三维空间下如何描述物体的位置。然而除了长宽高，世界上还有很多决定事物状态的因素。如决定股票价钱的因素、决定天气的因素。这些因素又该如何合理的描述？线性代数给了我们答案。推荐读物《Linear Algebra and Its Applications》。 线性代数是有关任意维度空间下事物状态和状态变化的规则。 矩阵乘法 二、矩阵是什么？矩阵乘法又是什么？ 带着这个问题我们开始对矩阵及其乘法进行第一遍理解。 向量点乘 全篇将会以一个实例进行讨论，请观看一遍视频PPAP洗脑全球。 三、视频的内容涉及到很多种状态及变换。用线性代数应该如何描述？ 视频内容可以写成3个向量乘法： 1、I have a pen, I have an apple—-&gt;apple pen [applepen][applepen][applepen] = [11]⋅[penapple][11]⋅[penapple][][11]⋅[penapple] （eq.1） https://yjango.gitbooks.io/superorganism/content/applepen.jpg 2、I have a pen, I have a pineapple—-&gt;pineapple pen[pineapplepen][pineapplepen][pineapplepen] = [11]⋅[penpineapple][11]⋅[penpineapple][][11]⋅[penpineapple] （eq.2） 1 https://yjango.gitbooks.io/superorganism/content/pineapplepen.jpg 3、apple pen, pineapple pen—-&gt;pen pineapple apple pen[penpineappleapplepen][penpineappleapplepen][penpineappleapplepen] = [11]⋅[applepenpineapplepen][11]⋅[applepenpineapplepen][][11]⋅[applepenpineapplepen] （eq.3） https://yjango.gitbooks.io/superorganism/content/allpen.jpg 每个等式右边的第二个向量表示变化前拥有什么，右边的第一个向量表示变化时各拿几个，而等式的左边表示变化后获得了什么。从中可以看出来： 向量点乘(dot product)是一种组合(combination) 矩阵乘向量 四、有没有其他描述方式？ 可以把（eq.1）（eq.2）合二为一，表示为（eq.4）：（eq.1）I have a pen, I have an apple—-&gt;apple pen，（eq.2）I have a pen, I have a pineapple—-&gt;pineapple pen [applepenpineapplepen][applepenpineapplepen][][applepenpineapplepen] = [100111]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[100111][]⋅[applepineapplepen][101011]⋅[applepineapplepen] （eq.4） 1 此时，表示各拿几个的向量变成了两行（两组）向量，也就成了矩阵（向量是只有一行或一列的矩阵）。 每个向量也叫一组权重(weights)。 在 [101][101][101] 中，第一个1对应着apple，第二个0对应着pineapple，第三个1对应着pen。不可以随意调换位置，所以， 向量是有顺序的一组数字，每个数字是向量的一个因素(element)因素横着排列的向量叫做行向量(row vector)因素竖着排列的向量叫做列向量(column vector)更具体的描述一下第一个结论。向量点乘是一种组合，但向量点乘是一个向量中各个因素的一个组合 五、如何计算矩阵乘向量？（eq.4）可分两步：计算第一行权重形成的组合： [101]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[101]⋅[applepineapplepen][101]⋅[applepineapplepen] 得到的组合apple pen后，放到第一行 [applepen][applepen][][applepen] 。计算第二行权重形成的组合： [011]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[011]⋅[applepineapplepen][011]⋅[applepineapplepen] 得到的组合pineapple pen后，放到第二行 [pineapplepen][pineapplepen][][pineapplepen] 。行成的 [applepenpineapplepen][applepenpineapplepen][][applepenpineapplepen] 依然有顺序，仍然是一个向量。比较向量点乘，可以看出 矩阵乘向量是向量中各个因素有顺序的多个组合 向量乘矩阵 六、形成组合的成分一定是元素（数）吗？形成组合的成分并非一定是向量中的各个元素，也可以是不同向量之间形成组合。可以把（eq.1）（eq.2）（eq.3）所完成的行为改写成（eq.5）（eq.6）：[applepenpineapplepen][applepenpineapplepen][applepenpineapplepen] = [11]⋅[penapplepenpineapple][11]⋅[penapplepenpineapple][][11]⋅[penpenapplepineapple] （eq.5）[penpineappleapplepen][penpineappleapplepen][penpineappleapplepen] = [pineapplepenapplepen]⋅[11][pineapplepenapplepen]⋅[11][][pineapplepenapplepen]⋅[11] （eq.6）（eq.5）等式右侧的矩阵由两个行向量组成。 矩阵中的第一个行向量表示两次组合中分别先拿什么，第二个行向量表示两次组合中分别后拿什么。 权重 [11][11][11] 的第一个因素对应着矩阵中第一个行向量的个数，第二个因素表示右侧第二个行向量的个数。 矩阵中每个行向量内部因素的比例不变，整体完成矩阵内向量与向量之间的组合。 向量乘矩阵可以是矩阵中各个行向量有顺的多个组合 你会发现（eq.6）不同于（eq.5），要形成组合的向量被拿到了乘法点(dot)的左边，而权重被拿到了右边。 效果是拿一个penpineapple和一个applepen形成组合。 因为当行向量的因素作为组合成分时，乘法点右侧的矩阵（向量）是权重的信息。可以看出矩阵乘法并不满足乘法交换律，因为交换了两个矩阵的位置，就交换了权重与要形成组合的向量的位置。 矩阵乘法不满足乘法交换律：commutative law: AB =! BA 矩阵乘矩阵 七、可以进行批量组合吗？矩阵乘矩阵就可以看作是对一个矩阵中各个向量的批量线性组合。如果视频中跳了两遍舞蹈。第二遍跳舞时，他在两次组合中，首次拿的东西都是两个，那么就可以把（eq.5）等式右侧的行向量变成两个行向量，形成了一个矩阵。[applepenapple+2∗penpineapplepenpineapple+2∗pen][applepenapple+2∗penpineapplepenpineapple+2∗pen][][applepenpineapplepenapple+2∗penpineapple+2∗pen] = [1211]⋅[penapplepenpineapple][1211][]⋅[penapplepenpineapple][][1121]⋅[penpenapplepineapple] 在唱第二遍时，就要唱：I have two pens. I have an apple. Apple-2pens!I have two pens. I have a pineapple. Pineapple-2pens! 之前仅仅是把单词放在一起，并没有说明他们是如何组合的。而上式中终于写出了：pineapple +2*pen。 也就是只有乘法来控制数量，加法来组合不同向量。这样的组合方式才是线性代数讨论的组合，即线性组合。 所以所有已概括的结论中，组合前面都要加上“线性”两个字。同时控制数量的数是属于什么数要事先规定好（经常被规定为是实数 ∈R∈R∈R ，也有虚数域）。不过这还没有结束，严谨性是数学的特点。上文所说的“加法”和“乘法”也只不过是个名字而已。它们到底指的是什么运算，遵循什么样的规则需要明确规定。当你看线性代数教材的时候，你就会发现这8条规则。 x+y=y+x x+(y+z)=(x+y)+z 有一个唯一的“零向量” 对任意 x 都能使 x+0=x 每个 x都有一个唯一的相反数使得 x+(−x)=0 1x=x (c1c2)x=c1(c2x) c(x+y)=cx+cy (c1+c2)x=c1x+c2x(c1+c2)x=c1x+c2x 不需要去记它们。只需要知道，它们是用于描述和约束在线性代数中的加法，乘法的运算。 特别要注意的是，这些运算都有一个原点（0），为了允许正负的出现。 线性组合：向量乘上各自对应的标量后再相加所形成的组合。（满足上述对乘法、加法的规则） ##矩阵是什么## 八、熟悉了各个乘法后，矩阵到底是什么？ 线性代数是用来描述状态和变化的，而矩阵是存储状态和变化的信息的媒介。 矩阵的信息可以分为状态（静态）和变化（动态）信息来看待。 矩阵的静态信息 当把矩阵以静态信息来看待时，其信息的侧重点在于状态二字。向量可用于描述一个事物的状态，该事物的状态由向量内各个因素来描述。而矩阵可以视为多个维度（因素的个数）相同的向量的有序排列。同时矩阵也可以视为一个“向量”，用于描述一个事物的状态，内部的每个向量就是矩阵的“因素”，该事物的状态由矩阵内各个向量来描述。 多个标量有序排列后形成向量，多个向量有序排列后形成矩阵，多个矩阵有序排列后形成三维张量（3D tensor）。 所以标量可以视为因素个数为1的向量，向量可以视为因素个数为1的矩阵，矩阵可以视为因素个数为1的三维张量（3D tensor）。 坐标值与坐标系： 描述一个事物的状态需要在一个选好的坐标系中进行，所以矩阵所包含的信息从来都是成对出现。 向量举例来说，这个向量并没有被赋予任何数值。但已经确定了我们要在apple的数量和pen的数量的两个因素（两个维度）下描述数据。换句话说，坐标系已被规定好。所以当写出任何具有实际数值的向量，如时，坐标系（二维向量空间）和坐标值就同时被确定了。它实际上是和的缩写。二者无法分割。即使是，虽然pen，apple前没有任何具体数字。但依然包含所有因素间的比例相同的隐含信息。调换2和1的顺序同时也表示坐标轴之间的调换。 矩阵的动态信息 当把矩阵以动态信息来看待时，其信息的侧重点在于变化二字。这时的矩阵可以看做是一个方程。变化可以理解为由于矩阵的作用，事物本身的变化，也可以理解为坐标系的变化。向量可用于控制变化时所用成分的数量，即一组权重。矩阵可以视为多个维度（因素的个数）相同的权重的有序排列。可对另一个矩阵的静态信息进行批量变化。 矩阵乘法是什么 矩阵可以被视为载有状态和变化两种信息的媒介。而矩阵乘法就是变化的行为。在一个矩阵内，把矩阵内的向量理解为向量或权重都可以。但是当两个矩阵进行矩阵乘法时，一旦选择以动态信息理解其中一个矩阵，另一个矩阵的信息就会被瞬间静态信息。 两个矩阵相乘，一个矩阵提供状态信息，另个矩阵提供变化信息。 两个矩阵相乘 时， 当把前者矩阵(A)中行向量理解成若干组权重，后者矩阵(B)中的行向量就是要形成组合的成分。 当把后者矩阵(B)中列向量理解成若干组权重，前者矩阵(A)中的列向量就是要形成组合的成分。 注意对应行向量与列向量。 转置一个矩阵可以理解为调换一个矩阵的动态与静态信息。 单位矩阵可以被理解为动态与静态信息相同。 回想线性组合的描述（向量乘上各自对应的标量后再相加所形成的组合），因为向量的维度和权重的维度要一一对应。所以， 矩阵A(m by n)和矩阵B(p by q)能够做乘法的条件是 n = p 向量空间很多线性代数教材所引入的第一个概念就是线性空间（linear space）。可见它的地位。虽然它有些抽象，但是却是自然而然推演出来的一个概念。 九、空间是什么？ 空间的本质是集合。而且是一个能够容纳所有要描述状态的集合。若超过空间范围，就该寻找正确的空间。 对“要描述内容”进行进一步说明，需从如何理解线性代数这四个字开始。 我们已经知道了 什么是线性（那8个条件约束的加法和乘法）。那什么是代数？意思是指你可以把任何概念都代入其中。 看视频的时候，人们自然而然的会把苹果菠萝换成其他事物，比如PPAP河南话版。也可以换成任何宇宙上有的物体。不仅仅是物体，甚至可以是一个抽象的概念。 我个人最喜欢的描述是： 向量空间是描述状态(state)的线性空间。再加上之前的约束，于是我们就有了向量空间是能够容纳所有线性组合的状态空间 十、什么样的状态空间能够容纳所有的线性组合？ 情景：假如要描述一个人的两个状态（下图中的行向位置和纵向位置），向量的维度就是二维。那么一个大圆盘够不够容纳所有的线性组合？答案是不够。 因为线性组合是向量乘以各自对应的标量后再相加所形成的组合，而这个标量是实数域的时候，由于实数域无线延伸，那么乘以标量后的状态也会无限延伸。所以 向量空间一定是各个维度都像实数轴一样可以无线延伸。最终得到的将不会是一维下的线段，二维下的圆盘。而一定是一维下的无限延伸的直线，二维下的无限延伸的平面。 向量空间的基本特点是各个维度都可以无限延伸，且过原点。之所以用状态二字，是因为刚才的两个维度，可以用于描述速度和体温。这时两个维度所展开的依然是一个平面，但却不是描述位置的平面。 子空间子空间（subspace）可以被想成是向量空间内的向量空间，同样要满足能够容纳线性组合的条件。 十一、最小的子空间是什么？只有一个状态的空间（集合）。这个状态不是其他状态，就是0。只有这样才可以在乘以标量后依然不会跑出空间外。 十二、其次空集可不可以是向量空间？不可以，空集是没有任何元素的集合，既然什么状态都没有，又怎么能够容纳线性组合。最小的向量空间是只包含零向量的空间 十三、假如上图的圆盘是个无线延伸的平面，那平面的子空间可以是平面上所有直线吗？不可以，8个运算规则中明确规定了，一定要有原点，这样才可以包含正负。所以这个平面的子空间是所有过原点的直线，加上中心的那个原点自己所组成的最小子空间，再加上这个平面自身（最大的子空间）。 线性无关十四、该如何选择因素？ 在视频的例子中，当要把（eq.1）（eq.2）合为（eq.4）时，是这个样子： = （eq.4），但最右侧的向量并不是4个维度。而是三个。因为pen 和pen是一个东西。 我们想用的是 若干个毫不相关的因素去描述状态。在线性空间下的毫不相关，叫做线性无关。 十五、要描述的状态是由向量来描述时怎么办？ 判断两个向量是否线性无关时，可以看他是否在空间下平行。 但怎么判断几个向量之间（不一定是两个）是否线性无关？我们需要可靠的依据。线性无关（linearly independent）: 当表示权重，表示向量时，只发生在when 全都等于零时。 换句话说，这些向量不可以通过线性组合形成彼此。形成彼此的情况只能是他们都是零向量。 张成注意词的属性和关联词。张成（spanning）是一个动词，动词的主语是一组向量（a set of vectors）。描述的是一组向量通过线性组合所能形成子空间。描述的内容并不是形成的这个空间，而是形成的这个行为。 ，是4个向量，但只可以张成一个三维空间。（因为有两维线性相关，所以并不能张成4维） 基底 一个向量空间的一个基底（A basis for a vector space V）是一串有顺序的向量（a sequence of vectors），满足：A、向量之间彼此线性无关 （不可多余）B、这些向量可以张成向量空间V （不可过少）刚刚好可以张成向量空间V的一串向量是该向量空间V的一个基底.基底是一个类似people的复数名词，是从属于某个空间的，而不是矩阵，也不是向量。 维度一个向量空间可以有无数个基底。但每个基底所包含的向量的个数（the number of vectors in every basis）是一个空间的维度。 注意：维度是空间的概念，而不是描述一个具体的向量。人们常说的n维向量实际是指n维向量空间内的向量，由于在讨论时并未给向量指定任何实际的数值，所以可以是任何值，可以张成整个空间。所以其真正描述的依旧是一个空间。并且，维度是站在观察者角度，希望在某个向量空间下尽可能的描述物体状态而选择的，并不一定是被描述者真实处在的空间。 但若是你觉得理解起来有困难。就简单记住：互不相关的因素的个数是一个向量空间的维度 秩矩阵可以视为动态和静态信息的媒介。而 一个具体的矩阵到底涵盖了多少信息可以由秩（rank）来描述。指的是一个矩阵的所有列向量所能张成的空间的维度。矩阵的所有列向量所张成的空间叫做列空间（column space）矩阵的所有行向量所张成的空间叫做行空间（row space）一个矩阵的列空间的维度是这个矩阵的秩，同时也等于该矩阵行空间的维度秩是用于描述矩阵所包含信息量的。 线性变换最终我们想要做的就是描述事物的变化。上文所有的内容都可以说是为此刻所做的铺垫。矩阵乘以矩阵可以视作一个矩阵内部向量的批量线性变换（linear transformation）。 所以可以仅讨论由矩阵乘以向量所形成的一次线性变换。 十六、什么是变换？这里写图片描述 by David C.Lay 一个从n维实数域（）到m维实数域（）的变换（transformation or mapping or function）是将n维实数域（）空间下任意一个向量转换成为在m维实数域（）空间下对应向量其中n维实数域（）空间叫做变换的domain，m维实数域（）空间叫做该变换的codomain。向量叫做向量的image（变换行为下的）所有image组成的集合叫做变换的range 而线性变换是是指线性规则所造成的变换，是由一个矩阵来实现的。此时你就会看到无处不在的式子： y=Ax ：列向量 xx 左乘一个矩阵 AA 后得到列向量 yy = （eq.4）举例来说， 是三维空间的向量（即的domain是三维），而经过线性变换后，变成了二维空间的向量（即的codomain是二维）。 矩阵可以被理解成一个函数(function)，将三维空间下的每个向量投到二维空间下。y=Ax 也可以理解为经由一个外力，使其状态发生了改变。同时也是深层神经网络每层变换中的核心：y=a(Ax+b)","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://ipcreator.me/tags/Algorithm/"}]},{"title":"A Visual and Interactive Guide to the Basics of Neural Networks","date":"2017-02-17T02:36:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/visual-interactive-guide-basics-neural-networks/","text":"J Alammar MotivationI’m not a machine learning expert. I’m a software engineer by training and I’ve had little interaction with AI. I had always wanted to delve deeper into machine learning, but never really found my “in”. That’s why when Google open sourced TensorFlow in November 2015, I got super excited and knew it was time to jump in and start the learning journey. Not to sound dramatic, but to me, it actually felt kind of like Prometheus handing down fire to mankind from the Mount Olympus of machine learning. In the back of my head was the idea that the entire field of Big Data and technologies like Hadoop were vastly accelerated when Google researchers released their Map Reduce paper. This time it’s not a paper – it’s the actual software they use internally after years and years of evolution. So I started learning what I can about the basics of the topic, and saw the need for gentler resources for people with no experience in the field. This is my attempt at that. Start hereLet’s start with a simple example. Say you’re helping a friend who wants to buy a house. She was quoted $400,000 for a 2000 sq ft house (185 meters). Is this a good price or not?It’s not easy to tell without a frame of reference. So you ask your friends who have bought houses in that same neighborhoods, and you end up with three data points: Area (sq ft) (x) Price (y) 2,104 399,900 1,600 329,900 2,400 369,000 Personally, my first instinct would be to get the average price per sq ft. That comes to $180 per sq ft.Welcome to your first neural network! Now it’s not quite at Siri level yet, but now you know the fundamental building block. And it looks like this: Diagrams like this show you the structure of the network and how it calculates a prediction. The calculation starts from the input node at the left. The input value flows to the right. It gets multiplied by the weight and the result becomes our output.Multiplying 2,000 sq ft by 180 gives us $360,000. That’s all there is to it at this level. Calculating the prediction is simple multiplication. But before that, we needed to think about the weight we’ll be multiplying by. Here we started with an average, later we’ll look at better algorithms that can scale as we get more inputs and more complicated models. Finding the weight is our “training” stage. So whenever you hear of someone “training” a neural network, it just means finding the weights we use to calculate the prediction. This is a form of prediction. This is a simple predictive model that takes an input, does a calculation, and gives an output (since the output can be of continuous values, the technical name for what we have would be a “regression model”)Let us visualize this process (for simplicity, let’s switch our price unit from $1 to $1000. Now our weight is 0.180 rather than 180):Harder, Better, Faster, Stronger Can we do better than estimate the price based on the average of our data points? Let’s try. Let’s first define what it means to be better in this scenario. If we apply our model to the three data points we have, how good of a job would it do? That’s quite a bit of yellow. Yellow is bad. Yellow is error. We want to shrink yellow as much as we can. Area (x) Price ($1000) (y) Prediction (y) &lt;span class=”y“&gt;y-y (&lt;span class=”y“&gt;y_-y)² 2,104 399.9 379 21 449 1,600 329.9 288 42 1756 2,400 369 432 -63 3969 Average: 2,058 Here we can see the actual price value, the predicted price value, and the difference between them. Then we’ll need to average these differences so we have a number that tells us how much error there is in this prediction model. The problem is, the 3rd row has -63 as its value. We have to deal with this negative value if we want to use the difference between the prediction and price as our error measuring stick. That’s one reason why we introduce an additional column that shows the error squared, thus getting rid of the negative value. This is now our definition of doing better – a better model is one that has less error. Error is measured as the average of the errors for each point in our data set. For each point, the error is measured by the difference between the actual value and the predicted value, raised to the power of 2. This is called Mean Square Error. Using it as a guide to train our model makes it our loss function (also, cost function). Now that we defined our measuring stick for what makes a better model, let’s experiment with a couple more weight values and compare them with our average pick: We can’t improve much on the model by varying the weight any more. But if we add a bias we can find values that improve the model.Our lines can better approximate our values now that we have this b value added to the line formula. In this context, we call it a “bias”. This makes our neural network look like this: We can generalize it by saying that a neural network with one input and one output (spoiler warning: and no hidden layers) looks like this: In this graph, W and b are values we find during the training process. X is the input we plug into the formula (area in sq ft in our example). Y is the predicted price.Calculating a prediction now uses this formula: So our current model calculates predictions by plugging in the area of house as x in this formula: Train Your DragonHow about you take a crack at training our toy neural network? Minimize the loss function by tweaking the weight and bias dials. Can you get an error value below 799? Error &nbsp; Weight 0 Bias 0 AutomationCongratulations on manually training your first neural network! Let’s look at how to automate this training process. Below is another example with an additional autopilot-like functionality. These are the GD Step buttons. They use an algorithm called “Gradient Descent” to try to step towards the correct weight and bias values that minimize the loss function. Error &nbsp; Weight 0 Bias 0 The two new graphs are to help you track the error values as you fiddle with the parameters (weight and bias) of the model. It’s important to keep track of the error as the training process is all about reducing this error as much possible.How does gradient descent know where its next step should be? Calculus. You see, knowing the function we’re minimizing (our loss function, the average of (y_ - y)² for all our data points), and knowing the current inputs into it (the current weight and bias), the derivatives of the loss function tell us which direction to nudge W and b in order to minimize the error.Learn more about gradient descent and how to use it to calculate the new weights &amp; bias in the first lectures of Coursera’s Machine Learning course.And Then There Were Two Is the size of the house the only variable that goes into how much it costs? Obviously there are many other factors. Let’s add another variable and see how we can adjust our neural network to it. Say your friend does a bit more research and finds a bunch more data points. She also finds out how many bathrooms each house has: Area (sq ft) (x1) Bathrooms (x2) Price (y) 2,104 3 399,900 1,600 3 329,900 2,400 3 369,000 1,416 2 232,000 3,000 4 539,900 1,985 4 299,900 1,534 3 314,900 1,427 3 198,999 1,380 3 212,000 1,494 3 242,500 Our neural network with two variables looks like this: We now have to find two weights (one for each input) and one bias to create our new model. Calculating Y looks like this: But how do we find w1 and w2? This is a little trickier than when we only had to worry about one weight value. How much does having an extra bathroom change how we predict the value of a home? Take a stab at finding the right weights and bias. You will start here to see the complexity we start getting into as the number of our inputs increase. We start losing the ability to create simple 2d shapes that allow us to visualize the model at a glance. Instead, we’ll have to mainly rely on how the error value is evolving as we tweak our model parameters. &lt;/div&gt; &lt;div class=&quot;col-sm-6&quot;&gt; &lt;table id=&quot;training-two-table&quot; class=&quot;training-table&quot;&gt; &lt;tr&gt; &lt;td colspan=&quot;3&quot; class=&quot;gd-buttons&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;GD Step&quot; id=&quot;gradient-descent-button&quot; class=&quot;btn btn-primary&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;10 GD Steps &quot; id=&quot;gradient-descent-10-button&quot; class=&quot;btn btn-primary&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;100 GD Steps &quot; id=&quot;gradient-descent-100-button&quot; class=&quot;btn btn-primary&quot; /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Error &lt;/td&gt; &lt;td colspan=&quot;2&quot;&gt; &lt;span id=&quot;error-value&quot;&gt;&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;error-cell&quot; colspan=&quot;3&quot;&gt; &lt;span id=&quot;error-value-message&quot;&gt;&lt;/span&gt;&amp;nbsp; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Weight #1 &lt;/td&gt; &lt;td&gt; &lt;input id=&quot;weight0Slider&quot; type=&quot;range&quot; class=&quot;weight&quot; min=&quot;-0.4&quot; max=&quot;0.4&quot; step=&quot;0.0001&quot; /&gt; &lt;/td&gt; &lt;td class=&quot;slider-value&quot;&gt; &lt;span id=&quot;weight0&quot; class=&quot;weight&quot;&gt;0&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Weight #2 &lt;/td&gt; &lt;td&gt; &lt;input id=&quot;weight1Slider&quot; type=&quot;range&quot; class=&quot;weight&quot; min=&quot;-100&quot; max=&quot;200&quot; step=&quot;0.0001&quot; /&gt; &lt;/td&gt; &lt;td class=&quot;slider-value&quot;&gt; &lt;span id=&quot;weight1&quot; class=&quot;weight&quot;&gt;0&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Bias &lt;/td&gt; &lt;td&gt; &lt;input id=&quot;biasSlider&quot; type=&quot;range&quot; class=&quot;bias&quot; min=&quot;-100&quot; max=&quot;300&quot; step=&quot;0.1&quot; /&gt; &lt;/td&gt; &lt;td class=&quot;slider-value&quot;&gt; &lt;span id=&quot;bias&quot; class=&quot;bias&quot;&gt;0&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;div id=&quot;neural-network-two-graph&quot; class=&quot;nn-graph-area&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; Our trusty gradient descent is here to help once again. It still is valuable in helping us find the right weights and bias. FeaturesNow that you’ve seen neural networks with one and two features, you can sort of figure out how to add additional features and use them to calculate your predictions. The number of weights will continue to grow, and our implementation of gradient descent will have to be tweaked as we add each feature so that it can update the new weights associated with the new feature.It’s important to note here that we don’t blindly feed the network everything we know about our examples. We have to be selective about which features we feed the model. Feature selection/processing is an entire discipline with its own set of best practices and considerations. If you want to see an example of the process of examining a dataset to choose which features to feed a prediction model, check out A Journey Through Titanic. It’s a notebook where Omar EL Gabry narrates his process for solving Kaggle’s Titanic challenge. Kaggle makes available the passenger’s manifest of the Titanic including data like name, sex, age, cabin, and whether the person survived or not. The challenge is to build a model that predicts whether a person survived or not given their other information.Classification Let’s continue to tweak our example. Assume your friend gives you a list of houses. This time, she has labeled which ones she thinks have a good size and number of bathrooms: Area (sq ft) (x1) Bathrooms (x2) Label (y) 2,104 3 Good 1,600 3 Good 2,400 3 Good 1,416 2 Bad 3,000 4 Bad 1,985 4 Good 1,534 3 Bad 1,427 3 Good 1,380 3 Good 1,494 3 Good She needs you to use this to create a model to predict whether she would like a house or not given its size and number of bathrooms. You will use this list above to build the model, then she will use the model to classify many other houses. One additional change in the process, is that she has another list of 10 houses she has labeled, but she’s keeping it from you. That other list would be used to evaluate your model after you’ve trained it – thus trying to ensure your model grasps the conditions that actually make her like the features of the house. The neural networks we’ve been toying around with until now are all doing “regression” – they calculate and output a “continuous” value (the output can be 4, or 100.6, or 2143.342343). In practice, however, neural networks are more often used in “classification” type problems. In these problems, the neural network’s output has to be from a set of discrete values (or “classes”) like “Good” or “Bad”. How this works out in practice, is that we’ll have a model that will say that it’s 75% sure that a house is “Good” rather than just spit out “good” or “bad”. The TensorFlow app I discussed in my previous post is a good example for a classification model in practice. One way we can transform the network we’ve seen into a classification network is to have it output two values – one for each class (our classes now being “good” and “bad”). We then pass these values through an operation called “softmax”. The output of softmax is the probability of each class. For example, say that layer of the network outputs 2 for “good” and 4 for “bad”, if we feed [2, 4] to softmax, it will return [0.11, 0.88] as the output. Which translates the values to say the network is 88% sure that the inputted value is “bad” and our friend would not like that house. Softmax takes an array and outputs an array of the same length. Notice that its outputs are all positive and sum up to 1 – which is useful when we’re outputting a probability value. Also notice that even though 4 is double 2, its probability is not only double, but is eight times that of 2. This is a useful property that exaggerates the difference in output thus improving our training process. output softmax([ 1 ]) [ 1 ] softmax([ 1, 1 ]) [ 0.5, 0.5 ] softmax([ 0, 1 ]) [ 0.26, 0.73 ] softmax([ 2, 4 ]) [ 0.11, 0.88 ] softmax([ 5, 10 ]) [ 0.007, 0.993 ] softmax([ -1, 0, 1 ]) [ 0.09, 0.24, 0.66 ] softmax([ 1, 2, 4 ]) [ 0.04, 0.11, 0.84 ] As you can see in the last two rows, softmax extends to any number of inputs. So now if our friend adds a third label (say “Good, but I’ll have to airbnb one room”), softmax scales to accomedate that change. Take a second to explore the shape of the network as you vary the number of features (x1, x2, x3…etc) (which can be area, number of bathrooms, price, proximity to school/work…etc) and vary the number of classes (y1, y2, y3…etc) (which can be “too expensive”, “good deal”, “good if I airbnb”, “too small”): Features (x): Classes (y): You can see an example of how to create and train this network using TensorFlow in this notebook I created to accompany this post. True Motivation If you have reached this far, I have to reveal to you another motivation of mine to write this post. This post is meant as an even gentler intro to TensorFlow tutorials. If you start working through MNIST For ML Beginners now, and come across this graph: I wrote this post to prepare people without machine learning experience for this graph in the TensorFlow introductory tutorial. That’s why I simulated its visual style. I hope you would feel prepared and that you have an understanding of this system and how it works. If you want to start tinkering with code, feel free to pick up from the intro tutorial and teach a neural network how to detect handwritten digits. You should also continue your education by learning the theoretical and mathematical underpinnings of the concepts we discussed here. Good questions to ask now include: What other kinds of cost functions exist? Which are better for which applications? What’s the algorithm to actually calculate new weights using gradient descent? What are the applications for machine learning in the fields you’re already knowledgeable about? What new magic can you wield by mixing this spell with others in your spell book? Great learning resources include: Coursera’s Machine Learning course by Andrew Ng. This is the one I started with. Starts with regression then moves to classification and neural networks. Coursera’s Neural Networks for Machine Learning by Geoffrey Hinton. More focused on neural networks and its visual applications. Stanford’s CS231n: Convolutional Neural Networks for Visual Recognition by Andrej Karpathy. It’s interesting to see some advanced concepts and the state of the art in visual recognition using deep neural networks. The Neural Network Zoo is a great resource to learn more about the different types of neural networks. Acknowledgements Thanks to Yasmine Alfouzan, Ammar Alammar, Khalid Alnuaim, Fahad Alhazmi, Mazen Melibari, and Hadeel Al-Negheimish for their assistance in reviewing previous versions of this post. Please contact me on Twitter with any corrections or feedback.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Neural Networks","slug":"Neural-Networks","permalink":"http://ipcreator.me/tags/Neural-Networks/"}]},{"title":"Supercharging Android Apps With TensorFlow","date":"2017-02-17T02:26:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/supercharging-android-apps-with-tensorflow/","text":"J Alammar Supercharging Android Apps With TensorFlow (Google’s Open Source Machine Learning Library)In November 2015, Google announced and open sourced TensorFlow, its latest and greatest machine learning library. This is a big deal for three reasons: Machine Learning expertise: Google is a dominant force in machine learning. Its prominence in search owes a lot to the strides it achieved in machine learning. Scalability: the announcement noted that TensorFlow was initially designed for internal use and that it’s already in production for some live product features. Ability to run on Mobile. This last reason is the operating reason for this post since we’ll be focusing on Android. If you examine the tensorflow repo on GitHub, you’ll find a little tensorflow/examples/android directory. I’ll try to shed some light on the Android TensorFlow example and some of the things going on under the hood. A Look of RecognitionThe app glances out through your camera and tries to identify the objects it sees. Sometimes it does a good job, other times it can’t quite pin down the object, and at times it leads to thought provoking guesses! Overall, it feels pretty magical. android_tensorflow_classifier_results.jpg The app accomplishes this feat using a bundled machine learning model running in TensorFlow on the device (no network calls to a backend service). The model is trained against millions of images so that it can look at the photos the camera feeds it and classify the object into its best guess (from the 1000 object classifications it knows). Along with its best guess, it shows a confidence score to indicate how sure it is about its guess. The Android example page gives you an idea on how to build the app, and ultimately culminates in producing this APK (I built and uploaded the APK to save you some time since the building process requires installing the Android NDK and Bazel, Google’s build tool). NOTE: Android 5.0 or later required since the example uses the Camera2 package introduced in Android 5.0. NOTE: if your device runs Android 6.0 or later, you have to install the app with the following command (It gives the app the appropriate permissions it needs to run): adb install -r -g /path/to/apk.apk App Structure Walkthroughandroid-tensorflow-app-structure_1.png The core TensorFlow engine is built with C++, but programmers can write their TensorFlow software in either C++ or Python. The Android TensorFlow example uses the C++ interface in the following manner: On startup, the app launches an Android activity (CameraActivity.java) which then starts a fragment (CameraConnectionFragment.java)The fragment does some setup to basically start the camera and feed the incoming stream of images to an object it instantiates (TensorflowImageListener.java)The listener consults the classifier (TensorflowClassifier.java) about each image it gets, and receives the classification and confidence score for each image.The good thing is that most of this logic is in normal Android Java SDK territory – so this should be familiar to most Android devs. So where is the C++?android-tensorflow-app-structure_2.png If you look closely at TensorflowClassifier, you may notice the following methods: public native int initializeTensorflow( ); private native String classifyImageBmp(Bitmap bitmap); The native keywords in these method signatures indicate that these methods are implemented in native C++ code. Look for them under the “android/jni” directory and true enough, you’ll find tensorflow_jni.cc JNIEXPORT jint JNICALL TENSORFLOW_METHOD(initializeTensorflow)(...) { ... } JNIEXPORT jstring JNICALL TENSORFLOW_METHOD(classifyImageBmp)(...) { ... } JNI (short for Java Native Interface) is a way in which the Java parts of an Android app can communicate with the native C++ parts. So when we call classifyImageBmp(bitmap) in our Java code, it will actually invoke the C++ function exported in tensorflow_jni.cc and return the value it returns. A Bitmap file cannot directly be sent to TensorFlow as input. It has be transformed into an input tensor that we’d send in step #2 in the flow above. A tensor is an n-dimensional array of values, and is the motif TensorFlow uses to send data between all of its different parts/operations. This model expect a 3-dimensional array that supplies the Red/Green/Blue value of each pixel in the image. The dimensions are: X-index of the pixel Y-index of the pixel indication of which value this cell holds (0 for red, 1 for green, 2 for blue)And the value of the cell would be the actual value of R or G or B channel for that pixel.input_tensor.png (This is somewhat oversimplified. I glanced over two things for simplicity’s sake. First is the conversion from the YUV format that the Android camera exports to the RGB format the model expects. Second is that the model actually takes a 4-dimensional tensor, but these three are the ones we care about) The ModelAs you read the example’s README.md, you’ll notice that it instructs you to download a zip file containing the TensorFlow model and add it to the assets directory. This zip file contains two files that are important for us: tensorflow_inception_graph.pb- At 54 MBs unzipped, this file constitutes the majority of the APK size (58 MBs). This is our trained machine learning model and where the magic comes from. It’s a pre-built TensorFlow Graph describing the exact operations needed to compute a classification from input image data. This Graph is serialized and encoded into binary with Google’s Protocol Buffers so it can be deserialized across different platforms (think of it as a binary-encoded JSON file). imagenet_comp_graph_label_strings.txt- this contains the 1000 classifications that the output of the model corresponds to (e.g. “vending machine”, “water bottle”, “coffee mug”). These classifications are defined by the ImageNet Large Scale Visual Recognition Challenge which the model was built to compete in. The model here is what’s known as a deep convolutional neural network. It is built in the Inception architecture described in Going Deeper with Convolutions. Convolutional neural networks are some of the most popular models in deep learning. They have been very successful in image recognition (so much so, that most highly ranked teams in the competition used them). The model is read from the file and fed into TensorFlow when the app starts up. This code is actually really interesting to read and see how to communicate with tensorflow (if you run the app with your device connected to your computer, you can see these helpful log messages printed in logcat). Build SystemThe Android app example is not built the traditional Gradle way. Because the app has to contain NDK elements as well as TensorFlow itself, a more elaborate build system was utilized. The example is configured to be built with Google’s Bazel build system running from the TensorFlow root directory. The WORKSPACE file in the root directory specifies the main parameters of the project. The BUILD file in the Android directory instructs the build system to build the Java and C++ files of the app. The PossibilitiesUsing a trained model in your app seems to be the lowest hanging fruit for mobile TensorFlow apps at the moment. While you can probably train a model on Android, mobile devices are not well suited for the intensive processing required by complex models with larger training sets. Want to learn more about machine learning? Consider checking out the Machine Learning course on Coursera. There’s also a good discussion in /r/MachineLearning here: In your experience, which machine learning course on Coursera (or other MOOC web site) was the best?. Want to comment? /r/androiddev, Hacker News. Written on January 6, 2016","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow Android Camera Demo","date":"2017-02-17T02:26:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/tensorflow-android-camera-demo/","text":"作者：tensorflow This folder contains an example application utilizing TensorFlow for Android devices. DescriptionThe demos in this folder are designed to give straightforward samples of using TensorFlow in mobile applications. Inference is done using the TensorFlow Android Inference Interface, which may be built separately if you want a standalone library to drop into your existing application. A device running Android 5.0 (API 21) or higher is required to run the demo. Current samples:TF Classify: Uses the Google Inception model to classify camera frames in real-time, displaying the top results in an overlay on the camera image. TF Detect: Demonstrates a model based on Scalable Object Detection using Deep Neural Networks to localize and track people in the camera preview in real-time. TF Stylize: Uses a model based on A Learned Representation For Artistic Style to restyle the camera preview image to that of a number of different artists. Prebuilt APK:If you just want the fastest path to trying the demo, you may download the nightly build here. Expand the &quot;View&quot; and then the &quot;out&quot; folders under &quot;Last Successful Artifacts to find tensorflow_demo.apk. Also available are precompiled native libraries that you may drop into your own applications. See tensorflow/contrib/android/README.md for more details. Running the DemoOnce the app is installed it can be started via the &quot;TF Classify&quot;, &quot;TF Detect&quot; and &quot;TF Stylize&quot; icons, which have the orange TensorFlow logo as their icon. While running the activities, pressing the volume keys on your device will toggle debug visualizations on/off, rendering additional info to the screen that may be useful for development purposes. Building the Demo from SourcePick your preferred approach below. At the moment, we have full support for Bazel, and partial support for gradle, cmake, make, and Android Studio. As a first step for all build types, clone the TensorFlow repo with: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git Note that --recurse-submodules is necessary to prevent some issues with protobuf compilation. BazelInstall Bazel and Android Prerequisites Bazel is the primary build system for TensorFlow. To build with Bazel, it and the Android NDK and SDK must be installed on your system. Get the recommended Bazel version listed in os_setup.html The Android NDK is required to build the native (C/C++) TensorFlow code. The current recommended version is 12b, which may be found here. The Android SDK and build tools may be obtained here, or alternatively as part of Android Studio. Build tools API &gt;= 23 is required to build the TF Android demo. Edit WORKSPACE The Android entries in &lt;workspace_root&gt;/WORKSPACE must be uncommented with the paths filled in appropriately depending on where you installed the NDK and SDK. Otherwise an error such as: &quot;The external label &apos;//external:android/sdk&apos; is not bound to anything&quot; will be reported. Also edit the API levels for the SDK in WORKSPACE to the highest level you have installed in your SDK. This must be &gt;= 23 (this is completely independent of the API level of the demo, which is defined in AndroidManifest.xml). The NDK API level may remain at 21. Install Model Files (optional) The TensorFlow GraphDefs that contain the model definitions and weights are not packaged in the repo because of their size. They are downloaded automatically and packaged with the APK by Bazel via a new_http_archive defined in WORKSPACE during the build process. Optional: If you wish to place the models in your assets manually (E.g. for non-Bazel builds), remove all of the model_files entries from the assets list in tensorflow_demo found in the [BUILD](BUILD) file. Then download and extract the archives yourself to the assets directory in thesource tree: BASE_URL=https://storage.googleapis.com/download.tensorflow.org/models for MODEL_ZIP in inception5h.zip mobile_multibox_v1a.zip stylize_v1.zip do curl -L ${BASE_URL}/${MODEL_ZIP} -o /tmp/${MODEL_ZIP} unzip /tmp/${MODEL_ZIP} -d tensorflow/examples/android/assets/ done This will extract the models and their associated metadata files to the local assets/ directory. Build After editing your WORKSPACE file to update the SDK/NDK configuration, you may build the APK. Run this from your workspace root: bazel build -c opt //tensorflow/examples/android:tensorflow_demo If you get build errors about protocol buffers, run git submodule update --init and make sure that you&apos;ve modified your WORKSPACE file as instructed, then try building again. Install Make sure that adb debugging is enabled on your Android 5.0 (API 21) or later device, then after building use the following command from your workspace root to install the APK: adb install -r bazel-bin/tensorflow/examples/android/tensorflow_demo.apk Android StudioAndroid Studio may be used to build the demo in conjunction with Bazel. First, make sure that you can build with Bazel following the above directions. Then, look at build.gradle and make sure that the path to Bazel matches that of your system. At this point you can add the tensorflow/examples/android directory as a new Android Studio project. Click through installing all the Gradle extensions it requests, and you should be able to have Android Studio build the demo like any other application (it will call out to Bazel to build the native code with the NDK). CMakeFull CMake support for the demo is coming soon, but for now it is possible to build the TensorFlow Android Inference library using tensorflow/contrib/android/cmake.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow Android stand-alone demo","date":"2017-02-17T02:16:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/tensorflow-android-stand-alone-demo/","text":"作者：miyosuda Android demo source files extracted from original TensorFlow source. (TensorFlow r0.10) To build this demo, you don’t need to prepare build environment with Bazel, and it only requires AndroidStudio. If you would like to build jni codes, only NDK is requied to build it. How to build jni codes First install NDK, and set path for NDK tools, and then type commands below to create .so file. 123$ cd jni-build$ make$ make install","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow的技术应用","date":"2017-02-17T02:06:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/applications-of-tensorflow/","text":"作者：AI研习社 通过一些TensorFlow实际应用，让大家对TensorFlow有理性和感性的双层认知。 随着谷歌2015年发布开源人工系统TensorFlow，让本就如火如荼的深度学习再添一把火，截至现在，TensorFlow已经历了多个版本演进，功能不断完善，AI开发者也能灵活自如的运用TensorFlow解决一些实际问题，下面雷锋网(公众号：雷锋网)会对一些比较实用的TensorFlow应用做相关整理，让大家对TensorFlow有理性和感性的双层认知。 TensorFlow在图像识别中的应用 对人类而言，区分画面、图像就如同与生俱来一样简单，例如我们能够轻松的识别老虎与雄狮的区别，但如果把这个问题交给计算机看上去并不简单。 在过去几年里，机器学习在解决这些难题方面取得了巨大的进步。其中，我们发现一种称为深度卷积神经网络的模型在困难的视觉识别任务中取得了理想的效果 —— 达到人类水平，在某些领域甚至超过。下面这篇文章雷锋网重点整理了TensorFlow在图像识别中的应用，看计算机如何识别图像。 地址：http://www.csdn.net/article/2015-12-16/2826496 除了认识TensorFlow在图像识别中的应用，关于如何搭建图像识别系统雷锋网也有相关教程： 手把手教你用TensorFlow搭建图像识别系统（一） 手把手教你用TensorFlow搭建图像识别系统（二） 手把手教你用TensorFlow搭建图像识别系统（三） 农场主与TensorFlow的邂逅，AI告诉你一根优秀的黄瓜应该具备什么素质 一根优秀的黄瓜应该具备什么素质？相信这是很多人不可描述的问题，而对于黄瓜农场主而言，同一个品种的黄瓜可以根据颜色、刺、体态等因素分成9类，但分检工作对于人来说恰好是一个枯燥繁琐的过程。 一位日本农场主 Makoto 为解决这一难题，利用TensorFlow制作了一款黄瓜分类机，通过机器就能够完成黄瓜的分类工作，但识别准确率目前只有70%，Makoto 目前正打算使用谷歌的云机器学习（Cloud Machine Learning）平台，来进一步改善他的黄瓜分类机。 地址：http://www.leiphone.com/news/201609/dHgxLbz96OQqVN8z.html（来源雷锋网） 用TensorFlow搭建图像分类器 本文将详细介绍如何通过TensorFlow搭建图像分类器，从安装、优化、编码、和使用等方面手把手教你用TensorFlow搭建图像分类器。 地址：http://www.leiphone.com/news/201702/JdaLcpYO59zTTF06.html 如何使用Tensorflow实现快速风格迁移？ 风格迁移（Style Transfer）是深度学习众多应用中非常有趣的一种，如图，我们可以使用这种方法把一张图片的风格“迁移”到另一张图片上，但原始的风格迁移的速度是非常慢的。在GPU上，生成一张图片都需要10分钟左右，而如果只使用CPU而不使用GPU运行程序，甚至需要几个小时。这个时间还会随着图片尺寸的增大而迅速增大，那么能否实现使用Tensorflow实现快速风格迁移？ 地址：http://www.leiphone.com/news/201701/tGlVRXWShwe7ffHW.html 运用TensorFlow处理简单的NLP问题 当前互联网每天都在产生大量的文本和音频数据，通过挖掘这些数据，我们可以做一些更加便捷的应用，例如机器翻译、语音识别、词性标注以及信息检索等，这些都属于NLP范畴。而在NLP领域中，语言模型是最基本的一个环节，本文主要围绕语言模型展开，首先介绍其基本原理，进而引出词向量(word2vec)、循环神经网络(RNN)、长短时记忆网络(LSTM)等深度学习相关模型，并详细介绍如何利用 TensorFlow 实现上述模型。 地址：http://blog.csdn.net/frankiegu/article/details/52133763 在TensorFlow中用深度度学习修复图像 生活中经常会遇到图片缺失问题，设计师和摄影师用内容自动填补来补充图像中不想要的或缺失的部分，本文将介绍通过一个 DCGAN 用深度学习进行图像修复。 地址：http://blog.csdn.net/whiteboy1999/article/details/53727376?locationNum=1&amp;fps=1 基于Tensorflow的CNN/CRF图像分割技术 本篇文章验证了卷积神经网络应用于图像分割领域时存在的一个问题——粗糙的分割结果。根据像素间交叉熵损失的定义，我们在简化的场景下进行了模型的训练，并使用后向传播来更新权重。我们使用条件随机场（CRFs）来解决分割结果粗糙的问题，并取得了很好的效果。 地址：https://yq.aliyun.com/articles/67189?spm=5176.8067842.tagmain.47.W3YH1h 利用Docker和阿里云容器服务轻松搭建分布式TensorFlow训练集群 由于在现实世界里，单机训练大型神经网络的速度非常缓慢，这就需要运行分布式TensorFlow集群并行化的训练模型。但是TensorFlow本身只是计算框架，要将其应用在生产环境，还是需要集群管理工具的资源调度，监控以及生命周期管理等能力。 本文将分两个部分介绍如何在阿里云容器服务上玩转TensorFlow训练集群。 第一部分：https://yq.aliyun.com/articles/68337?spm=5176.100239.blogcont60894.15.tOeTKV 第二部分：https://yq.aliyun.com/articles/60894?spm=5176.8067842.tagmain.29.W3YH1h 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Tensorflow 的入门与安装","date":"2017-02-17T01:56:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/setup-of-tensorflow/","text":"作者：AI研习社 作为AI 领域最受关注和使用率最高的开源框架之一，TensorFlow 究竟是如何安装的呢？这篇汇总资料你不得不看！ 自2015年11月发布以来，谷歌旗下的机器学习开源框架TensorFlow已经在图像识别，大数据分析，语音识别和语义理解，机器翻译等各个领域得到了广泛应用，同时也得到了业内人士的普遍认可，成为了目前最受关注和使用率最高的开源框架之一。 本文将重点整理TensorFlow框架的入门和安装教程。更多关于TensorFlow的深入介绍、应用项目以及各机器学习开源框架之间的对比等内容，请见雷锋网(公众号：雷锋网)的系列文章。 下面是本文整理的资料内容： 在安装之前，这里先列出一些对TensorFlow给出大略介绍的文章，其中包括一些重要的概念解释，TensorFlow的具体含义和优点，以及TensorFlow的基本工作原理等。 《TensorFlow极速入门》链接：http://www.leiphone.com/news/201702/vJpJqREn7EyoAd09.html本文介绍了 graph 与 session 等基本组件，解释了 rank 和 shape 等基础数据结构概念，讲解了一些 variable 需要注意的地方并介绍了 placeholders 与 feed_dict 。最终以一个手写数字识别的实例将这些点串起来进行了具体说明。 《TensorFlow学习笔记1：入门》链接：http://www.jeyzhang.com/tensorflow-learning-notes.html本文与上一篇的行文思路基本一致，首先概括了TensorFlow的特性，然后介绍了graph、session、variable 等基本概念的含义，以具体代码的形式针对每个概念给出了进一步的解释。最后通过手写数字识别的实例将这些点串起来进行了具体说明。需要指出的是，两篇文章覆盖的基础概念不尽相同，并且举例用的代码也不一样。 《TensorFlow入门》链接：http://www.jianshu.com/p/6766fbcd43b9#与上面两篇不同，本文简单介绍了 TensorFlow 的含义、优点、安装和基本工作原理之后，直接通过代码示例的方式讲解了 TensorFlow 的简单用法，包括生成三维数据，然后用一个平面拟合它，以及通过 variable 实现一个简单的计数器等。 值得一提的是，以上第二和第三篇分别来自两个系列文章，这两个系列也都是关于 TensorFlow 入门和实践的优秀博客。第二篇的后续文章讲述了卷积神经网络（CNN）模型构建，以及利用 TensorFlow 生成词向量 (Word Embedding) 的具体过程。第三篇则实际上是基于斯坦福大学基于深度学习的自然语言处理课程的学习笔记，该系列其他的文章还讲述了循环神经网络（RNN）和 word2vec 模型等更深入的知识，感兴趣的读者可以从文章的作者页找到更多文章。 上述文章都更倾向于 TensorFlow 的简单介绍了基础用法，但对于TensorFlow具体安装过程的讲述则不够细致。因此这里专门针对TensorFlow的安装过程推荐一篇教程。 《真正从零开始，TensorFlow详细安装入门图文教程！》链接：http://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html上文来自雷锋网小编的亲身实践，真正做到了从零开始，详细介绍了在Linux环境下如何通过pip命令安装TensorFlow框架的完整流程，以及面对一些常见问题的处理办法。值得一提的是，本文在讲解完框架安装之后，还针对Komodo开发环境进行了简单介绍。 经过了以上来自民间的实践教程之后，相信各位读者对TensorFlow的大致情况和具体安装方法已经有了自己的理解。下面对于那些想要更全面和深入地了解TensorFlow的读者，我们推荐几个官方的教程。 谷歌官方入门教程链接：https://www.tensorflow.org/get_started/ 谷歌教程翻译https://github.com/jikexueyuanwiki/tensorflow-zh 这里谷歌给出的入门教程内容十分丰富，除了最基本的安装、名词解释和代码示例之外，还给出了 API 接口的详细解释和说明。但考虑到内容全是英文，因此雷锋网在这里给出了国内志愿者对谷歌内容的中文翻译版，可以为那些英文不好的读者提供参考。 TensorFlow中文社区http://www.tensorfly.cn/最后我们在这里推荐一个 TensorFlow 的中文社区，该网站几乎可以认为是 TensorFlow 的中文官网，除了上述谷歌官方教程的中文翻译之外，该网站还包括进阶指南、API中文手册、精华文章和TF社区等诸多板块。 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"框架平台的综合对比","date":"2017-02-17T01:56:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/platforms-of-tensorflow/","text":"作者：AI研习社 TensorFlow 与其他平台、框架对比，具有哪些优点及劣势？ 作为机器学习领域、尤其是 Python 生态圈最受欢迎的框架平台，TensorFlow 具有许多吸引开发者的优点。其中最显而易见的是谷歌的技术支持和完善的社区（庞大用户群）。这些都为 TensorFlow 的普及打下了基础。但是，开发者需要了解 Tensorflow 在技术上有哪些值得一提的优势，又有哪些不足，以便在处理特定任务时进行工具选择。而这些，必须要在与其他平台、框架的对比中才能凸显。顺便说一句老生常谈的话，没有万能的工具，只有在不同应用场景下最合适的选择。 因此，雷锋网(公众号：雷锋网)整理了介绍 Tensorflow、Caffe、Microsoft Cognitive Toolkit （CNTK）、MXnet、Torch 等平台框架，以及对它们做横向对比的文章，供读者按图索骥。 ## 综合介绍 这部分的文章，对 TensorFlow 和其它主流深度学习框架、平台做了概括性介绍，归纳它们的主要特点。有经验的开发者可跳过。 **谷歌、微软、OpenAI 等巨头的七大机器学习开源项目 看这篇就够了** 对 Tensorflow、DeepMind Lab、Universe、FastText、CNTK、MXNet、SystemML 这七个开源机器学习平台、框架做了介绍。它们都是谷歌、微软、亚马逊、IBM 等国际互联网巨头开发或维护的平台，在一定程度上反应了巨头们的 ML 布局以及研究倾向。 注意：该文章发布时 Facebook 尚未推出 Pytorch。现在看来，Pytorch 是脸书在 ML 领域的关键项目。 地址：http://www.leiphone.com/news/201612/rFVygnQf4WjogJQR.html **深度学习——你需要了解的八大开源框架** 对 TensorFlow、Torch、Caffe、Theano、Deeplearning4j 等主流开源框架作了简要介绍，总结了它们的核心优势及特点。 地址：http://www.leiphone.com/news/201608/5kCJ4Vim3wMjpBPU.html （来源雷锋网） **对比深度学习十大框架：TensorFlow 最流行但并不是最好** 这篇文章翻译自 Medium，同样是对开源框架的综合性介绍。它出自 BEEVA Labs 的数据分析师 Ricardo Guerrero Gomez-Ol 之手，对 TensorFlow、Theano、Keras、Lasagne 等框架和工具做了简要介绍。 地址：http://geek.csdn.net/news/detail/132553 ## 横向对比 **这几天 AI 圈都在关注的深度学习库评测** 整理自香港浸会大学褚晓文教授研究团队的论文。褚教授在论文中对 Caffe、CNTK、MXNet、TensorFlow、Torch 几大工具在 CPU、GPU 平台上的性能表现做了深度评测。该论文一经发表便受到广泛关注，堪称是迄今为止，对上述几个主流深度学习框架最深入、客观的计算性能对比。其研究结果，简明扼要得归纳了这几大平台分别最适合处理何种神经网络任务。雷锋网强力推荐。 地址：http://www.leiphone.com/news/201701/OlEiX6kZLKHVUyW2.html （来源雷锋网） **机器学习和深度学习的最佳框架大比拼** 这篇文章翻译自 Infoworld，对 TensorFlow、Caffe、CNTK、MXNet、Scikit-learning、Spark MLlib 等几大框架的优缺点进行了点评，以及实践总结。本文针对不同背景、习惯的开发者，提供了平台选择上的建议。 地址：https://news.cnblogs.com/n/562250/ **TensorFlow 等主流深度学习框架比较分析** 这篇文章罗列了 TensorFlow、Theano、MXnet 三者的主要属性和技术规格，做了简明扼要的对比。 地址：http://www.tuicool.com/articles/BVFb6bb **Caffe、TensorFlow、MXnet 三个开源库对比** 这是国内一名为陈汝丹的开发者的实操心得，对三个框架发表了自己的看法。文章对技术的讨论较为细致，适合做实践参考。 地址：http://chenrudan.github.io/blog/2015/11/18/comparethreeopenlib.html#0-tsina-1-2654-397232819ff9a47a7b7e80a40613cfe1 ## 与其它框架的对比 **如何评价百度刚刚开源的 Paddle 平台？** 2016 年下半年开源的 PaddlePaddle 是百度的诚意之作，或许还是国内诞生的最具重量级的机器学习框架。这篇文章对其做了介绍，并邀请行业人士对 PaddlePaddle 相对于 TensorFlow、Caffe 的优缺点做了简要评论。 地址：http://www.leiphone.com/news/201608/TfDtMfbKkUOEieWm.html（来源雷锋网） **应该选择 TensorFlow 还是 Theano？** 由于 TensorFlow 与 Theano 有替代关系，两者之间的比较是个相对热门的话题。这是知乎上的问答，直接对比了这两个深度学习框架。 地址：https://www.zhihu.com/question/41907061 ## 补充 **TensorFlow 与 Apache Spark 结合：雅虎开源“TensorFlowOnSpark”** 最后，说到 TensorFlow 就不得不提最近的一个大新闻——“TensorFlowOnSpark”。该框架使得 TensorFlow 兼容于 Apache Spark，能直接获取后者的数据集，为开发者减少大量麻烦。 地址：http://www.leiphone.com/news/201702/XwhHugKHTk86WQso.html 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Tensorflow的迭代更新","date":"2017-02-17T01:49:06.000Z","path":"2017/02/17/SmartAI/ProgramAI/Tensorflow/history-of-tensorflow/","text":"作者：AI研习社 谷歌于2015年11月发布了全新人工智能系统TensorFlow，距今已有15个月时间，在这期间发生了哪些变化？ 谷歌于2015年11月发布了全新人工智能系统TensorFlow。该系统可被用于语音识别或照片识别等多项机器深度学习领域，主要针对2011年开发的深度学习基础架构DistBelief进行了各方面的改进，它可在小到一部智能手机、大到数千台数据中心服务器的各种设备上运行。 那么为什么会产生TensorFlow系统，以及谷歌为何将其开源？这个问题可以看雷锋网文章[《Google开源TensorFlow系统，这背后都有什么门道？》](http://www.leiphone.com/news/201511/Voza1pFNQB4bzKdR.html)。 2016年4月14日，Google发布了分布式TensorFlow，版本号为0.8，这是TensorFlow发布之后的比较重大的版本更新。Google的博文介绍了TensorFlow在图像分类的任务中，在100个GPUs和不到65小时的训练时间下，达到了78%的正确率。在激烈的商业竞争中，更快的训练速度是人工智能企业的核心竞争力。而分布式TensorFlow意味着它能够真正大规模进入到人工智能产业中，产生实质的影响。 详情可以阅读雷锋网文章《开源后5个月，Google的深度学习系统都有哪些改变？》。 在2016年6月，TensorFlow发布了新版本的早期版本，版本号为0.9，增加了对iOS的支持。 随着谷歌增加了TensorFlow对iOS的支持，应用程序将能够在更聪明的神经网络功能集成到它们的应用程序，最终使它们更聪明相当能干。具体更新内容可以在《谷歌AI平台发布早期版本，并登陆iOS》中看到。 在2017年1月底，TensorFlow 终于将迎来史上最重大更新：TensorFlow 1.0。Tensorflow它已成为 GitHub 最受欢迎的机器学习开源项目。因其高度普及率，尤其是在 Python 生态圈中，TensorFlow 的功能变化会对全世界的机器学习开发者造成重大影响。 上月初，谷歌公布了 TensorFlow 1.0.0-alpha ，即 TensorFlow 1.0 的第一个“草稿”版本。近日，新的候选版本 TensorFlow 1.0.0-rc0 被发布出来，披露了更多技术细节，标志着我们离 “完全体”的 TensorFlow 1.0 更近一步。 1.0 版本不仅为 TensorFlow 机器学习函数库带来多重升级，而且为 Python 和 Java 用户使用 TensorFlow 做开发降低了难度。另外，新版本的漏洞修补也得到了改善。更有意思的是，由于对 TensorFlow 计算做优化的新编译器，在智能手机上运行基于 TensorFlow 的机器学习 APP 将成为可能。 具体更新内容可以看雷锋网(公众号：雷锋网)文章《TensorFlow 1.0 要来了！它将带来哪些革命性变化？》 在2月7日谷歌通过博客正式发布了 TensorFlow Fold，该库针对 TensorFlow 1.0 框架量身打造，可以帮助深度学习开发者根据不同结构的输入数据建立动态的计算图（Dynamic Computation Graphs），简化了模型训练阶段对输入数据的预处理过程，提升了系统的运行效率。这个库的更多信息可以在《谷歌刚发布的深度学习动态计算图工具TensorFlow Fold是什么？》中看到。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"人工智能 VS 机器学习","date":"2017-02-15T14:49:06.000Z","path":"2017/02/15/SmartAI/ProgramAI/Concepts/ai-vs-machine-learning/","text":"作者：网易AI研究院 对于企业而言，该投资人工智能还是机器学习呢？国外媒体发表Avanade高级总监贾马尔·赫瓦贾（Jamal Khawaja）的文章对这一问题进行了深入解析。 在过去的一年里，笔者一直在研究两种在如何利用大数据上相互矛盾的方法：人工智能（AI）和机器学习（ML）。毕竟，大数据没什么令人兴奋的，除非你有个机制去处理它。经过数周的深入研究后，我意识到大家对于一切的定义都是不一致的。另外，二者之间的区别相当无趣乏味。因此，我将尝试用一种既不讨好供应商也不讨好学术界的语言，来解析我对未来十年行业的发展的看法。 不过，在展开讨论之前，我们首先说明一些背景信息。先来谈谈AI和ML与大数据相关的定义： 人工智能：AI的目标是理解神经功能，模拟大脑的神经功能来从给定的情境中学习。在很多情况下，大脑实质上就是鲁布·戈德堡机器（即极为复杂的机器设备）。有了这种进化性的构建模块，我们就能够达到一种复杂的终端状态。 早在1980年代，AI在科学家当中是一个热门研究领域：专家们是如何做他们的工作的，如何将他们的那些任务简化成一系列的规则，如何通过编程给计算机引入那些规则，进而取代那些专家。研究人员想要教导计算机诊断疾病，翻译各种语言，甚至推断我们想要但不自知的东西。从根本上说，AI寻求构造在一个系统内进行逻辑推理的能力。 这种努力并没有成功。 在被宣告失败之前，传统的AI项目吸引了数亿美元的风投资金。当时，AI的问题在于，我们没有足够有成本效率的计算能力去完成那些目标。但得益于Map Reduce和云技术，我们现在有足够充裕的计算能力去做AI。 机器学习：ML实际上是数项技术的集合，其中包括计算统计学、算法设计和数学，旨在尝试进行数据挖掘分析，以发现模式，再将模式转化成语言。这种技术会给系统提供初始的指令组，然后系统进行数据归纳，发现或者推断出模式，以期将那些信息应用到新的解决方案。 ML是从AI进化而来的。当AI的挑战变得非常显著，变得无法克服时，理论家们寻求一种更加定制化的归纳计算决策方法。这种模式有不同的种类。供应商们将它们的系统称为“机器智能”或者“监督式学习”。 除了更容易构造以外，机器学习的好处都显而易见。ML始于一个界定的问题，以及描述对给定数据集的恰当分析的规则组。 AI与ML的相似之处 - 迭代算法：尽管机制上存在差异，但ML和AI有着共同的主要组成部分：迭代学习。在ML中，迭代学习是从所描述的参数组中定义不确定边界的过程。在AI中，迭代学习通过通常随时间变动的非线性序列发生。 - 数据越多，迭代越快：系统本身会从学习中构造和优化算法模型。 - 可应用在明确算法不能实行的地方（垃圾邮件过滤、OCM和计算机视觉）。本质上，当物体、动作或者任何其它的东西的定义无法精确描述出来的时候，就需要更加复杂的指令组（通常是概率建模）来分析和理解。 -两种系统都依靠基于归纳推理的“学会学习”能力：二者的运作过程存在着很大的差异，但最终的效果都取决于系统从经验中学习的能力。那种学习可以是外显的，有指导的（典型的例子就是机器学习），也可以是基于一系列的先验知识，由系统本身进行推测（典型例子就是人工智能）。 人工智能 - AI的目标是推理。系统不仅仅要鉴别需要估算什么，还要鉴别如何进行估算，即便在不确定的情况下也是如此。这是一项困难的任务，很多人都缺乏这种能力。 - 所基于的神经网络：AI执行最常见的解决方案机制是人工神经网络。从根本上说，不同抽象层次的互联神经元会权衡受观察或者被计算的行为的价值，会通过使用输入的非线性函数来调整驱动系统的算法。 - 在不同的抽象层次学习：AI算法会在信号从输入层传送到输出层的过程中将信号遇到的转变参数化。该转变是有可训练的考量因素的处理单元，如权重和阈值。层数反映神经网络的复杂性，参数的权重反映它背后的逻辑。 - 寻找方差的转变，以识别变化：在神经网络中，有机制识别方差的实际转变和变化的程度。这是AI的基石之一；量化方差和推断其影响的能力对于AI而言必不可少。 机器学习 - ML专注于根据已知属性预测未知属性，这反过来是依据概率分布。这反映出ML的两个主要目标： 1. 目标是解决问题；利用给定的带有定义输入的数据组和监督式误差反向传播，鉴别和解决问题 2. ML并不是寻求思考的能力；相反，它是寻求做会思考的实体能够做的事情的能力 -ML方面有两类函数：能够被学习的东西和不能够被学习的东西。这种机制是通过围绕与前馈控制系统相关的复杂性建模建立起来的，该系统负责将来自来源的控制信号向外部环境进行例示。这表明理解的层次不仅仅是围绕系统扰动，还围绕基于数学建模的系统中的预期变化。相反地，反馈系统会反应性地改变控制信号。这些系统无法使得行为有理化时，则会将函数渲染为无法学习的东西，以及在机器学习环境范畴之外的东西。 关于ML，值得注意的是量子机器开始被引入系统的学习过程。理论上，量子计算可给给定环境提供无限量的前馈系统。人们可能会断定，量子学习本质上不是确定性的；量子计算（量子位）的基本计算元素创造了一种模糊的逻辑模型。这可能会带来已知物理定律下最具创造性的问题解决过程。目前，它正被应用于图像识别，但未来的实施会考虑训练基于难解运算的概率模型。 然而，不管使用哪一种系统： - 你最终都会得出经过优化的结果。你不一定理解你是如何将其进化的，但结果不言而喻。你只能够理解过程和界面。 - 学习的中心从产品转向过程：不改动最终产品，而是改动过程。 - 这两种模型都不仅仅涉及工程设计：我们试图创造的东西比我们想象的要多。 那么，该投资AI还是ML呢？说到底，这取决于你的业务需求。ML可提供大量的企业友好型工具，这使得它成为很多企业项目的首选解决方案：它能够受到已知技术的约束；它能够解决特定的问题，所出现的问题能够通过调整输入信息、数据结构或者输出值来解决。事实上，AI在1980年代失宠是有原因的：无法将专家的能力转化成可外推到更加复杂的场景的规则组。 然而，我认为AI才是未来。推理能力包含比商业需要重要的智力能力和情感能力。这是程序员、理论家和科学家们自统计学分析创立以来一直在竭力追求的东西；我们如何才能创造出能够解答我们不知道的问题的机器呢？IBM在这一领域进行了巨额投资，微软，特斯拉，甲骨文，谷歌，地球上的每一家医疗保健公司，大多数的银行，每一位想要找到赚更多钱的窍门且精通技术的企业家亦然。 如果你是位普通的企业家，那就投资机器学习。它会给你带来好处。但如果你是有远见的人，那就投资人工智能，你可能会改变世界。（皓慧） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 AI研究院 | 科普：人工智能与机器学习到底有什么区别？ 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月10日消息，人们常常把人工智能与机器学习混为一谈，其实这两者之间有着很大的区别。 机器学习和人工智能是当前科技领域的两大趋势。实际上，这两个术语经常可以互换使用。然而，两者之间仍然存在着微妙却重大的差异。 从很多方面来说，机器学习是人工智能的一部分。而且，人工智能这个术语也比机器学习出现得更早。 它们之间的区别到底是什么呢? 人工智能的核心是试图让机器以人脑的方式进行思考。 著名的图灵测试表明，如果人类不能将一个系统的行为与人类的行为区别开来，那么这个系统就可以说是智能的。然而，目前的技术远未达到这一目标，所以人工智能目前也只是意味着创造出能够做出人类擅长的行为的系统。但这只是个笼统的说法。 机器学习也可以追溯到20世纪中期。阿瑟塞缪尔将机器学习定义为“在没有进行明确编程的情况下的学习能力”。 使用及应用 机器学习 机器学习的原理几十年来一直没有得到重视(这一点与人工智能很像)，但随着上个世纪末之前数据挖掘工作的兴起，人们 需要一种算法来寻找每一个数据集的模式。机器学习做到了这一点，但它又更进一步，从过程中学习，而它的性能也会随着不断学习而提高。 机器学习的另一种用途是图像识别。这些应用最初是由人类训练的，先观察图像，然后进行描述。在使用了成千上万的图像进行训练之后，机器学习系统就可以根据像素分辨出画面中是一条狗、一座房子、一束鲜花还是一个人。 机器学习也可以在推荐引擎中使用。这些算法可以帮助Facebook决定在新闻中显示什么信息，或者帮助亚马逊决定向用户推送什么广告。 随着大数据分析越来越普及，企业正在向依靠机器学习来驱动预测分析转变。与统计数据、数据挖掘和预测分析的联系已经足够让人认为机器学习是人工智能的一个领域。 原因就在于，诸如自然语言处理或自动推理的人工智能技术可以在没有机器学习能力的情况下完成。机器学习系统并不需要具有人工智能的其他特征。 人工智能 人工智能目前有数百个使用案例，而随着企业不断采用人工智能来应对商业挑战，人工智能的案例也开始为人所知。 当前最受欢迎的人工智能应用之一是语音助手。微软的Cortana、Siri、谷歌助理和亚马逊Alexa都是智能家居和智能手机的核心部分，用户可以通过聊天机器人预约午餐会议，或者用语音助手来控制家里的照明开关。但是，Alexa现在站在另一个行业的前沿。聊天机器人和davis可以让IT管理员通过询问davis问题来识别和修复IT基础架构的问题。 人们有充分的理由担心人工智能将取代人类的工作岗位，如数据输入。牛津大学预计，在未来20年，英国约有35%的就业机会将被自动化取代。 将两个术语混淆 还有一些与这一主题相关的其他的术语。人工神经网络处理信息的方式与人脑类似。但是人工神经网络也相当擅长机器学习，这就让事情变得更加复杂了。 这种神经网络构成了深度学习的基础，而 深度学习本身就是机器学习的一种形式。 大量的机器学习算法能够利用成百上千的GPU瞬间处理大量数据。 如果你对这些感到困惑，不要担心，科学家们仍在探讨机器学习和人工智能的确切定义，探讨可能会一直持续下去。 （英文来源：ITPRO 编译：机器小易 审校：日月沉香） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"Atom编辑器入门到精通","date":"2017-02-15T13:38:06.000Z","path":"2017/02/15/SmartAI/ProgramAI/Tools/techniques-of-atom-editor/","text":"原文作者：PeterHo Atom是GitHub推出的一款编辑器, 被称为21世纪的黑客编辑器. 其主要的特点是现代, 易用, 可定制. 命令面板命令面板是Atom中最常用的功能之一, 当你在编辑器中使用快捷键Ctrl+Shift+P时, 就会看到它在控制面板中可以输入Atom中和插件中定义的所有命令, 并且支持模糊搜索比如说当你输入cboo时, 所有包含有这4个字符的命令就都列出来了在列出的命令后还显示了此命令对应的快捷键(如果有的话) 保存文件 快捷键 Ctrl+S保存所有文件: File-&gt;Save All 打开文件夹是一个很实用的功能, 可以像IDE一样打开一个项目的根目录可以通过在主菜单选择File-&gt;Add Project Folder…来打开或者添加一个目录,也可以使用快捷键Ctrl+Alt+O.在打开一个文件夹以后该文件夹下的所有子目录和文件就会如下图一样以目录树的方式显示在主窗口左边你可以通过在目录树栏中右键菜单或选中文件时使用快捷键a,m,delete来对文件进行新建,重命名,删除等操作如果要切换目录树栏的显示与隐藏可以使用快捷键Ctrl+\\或输入命令Tree View:Toggle目录树中右键菜单中还能实现文件的复制粘贴等功能 查找文件 当打开一个或多个目录时,你可以: 通过Ctrl+T或Ctrl+P来搜索目录中的文件 通过Ctrl+B来搜索一个当前打开的文件 通过Ctrl+Shift+B来搜索一个新建的或更改过的文件 文本编辑基础使用Ctrl+F进行文件内查找使用Ctrl+Shift+F进行工程内查找 代码片段(Snippets)代码片段(Snippets) 片段（Snippet）是一个编程用语，指的是源代码、机器码、文本中可重复使用的小区块。通常它们是有正式定义的执行单位，以纳入更大的编程模块。片段经常用来明晰其他“凌乱”函式的功用，或尽量减少使用与其他函式共用的重复代码。 片段管理是某些文本编辑器、程式源代码编辑器、IDE、与相关软件的其中一项功能。其使得使用者能够在反复的编辑作业中保持和使用这些片段。 让我们通过一个实验来感受一下Snippets给我们带来的便利体验 打开Atom编辑器 使用Cmd+N新建一个文件 使用Cmd+S保存文件,将文件名改为new.html 在new.html中键入html四个字符,然后按tab键,这时你会发现html这段文本被扩展成了12345678&lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt;&lt;/html&gt; 并且光标被移到了标签之间,方便你直接输入这个html文件的标题 在标签之间输入完成html页面标题以后,再次键入tab键你会发现光标又被移到了标签下面了 Snippets,它让你可以很方便地通过一个关键词来插入一段代码块,并且还能通过tab键在这段代码块的输入点之间移动光标,达到快速编码的目的不同类型的文件有不同的Snippets,你可以通过控制面板输入Snippets:available来列出当前文件所提供的所有的Snippets 预览在进行Markdown文档的编辑时, 我们经常想要看一看编辑的效果. Atom默认就支持这一功能.我们只需要在编辑md文件时使用Ctrl+Shift+M, 就能显示一个预览窗口, 方便我们随时查看md编辑的效果. 并且这个预览窗口还能随着我们的编辑自动刷新预览的内容和效果. Snippets(代码片段) Atom中内置了多个Snippets来方便Markdown文档的编辑.比如img(插入图片), table(插入表格), b(插入粗体), i(插入斜体), code(插入代码)等.关于Snippets的详细使用方法请参考本系列文章的第四章Atom使用进阶. CSONCSON(CoffeeScript Object Notation)是Atom配置文件的文件格式, 它使用键值对的格式来存储数据. 就像下面这个样子 key: key: value key: value key: [value, value] 跟Python类似, CSON使用缩进来标识语句块. CSON的key的名字不能重复, 如果CSON中包含了多个同名的key, 那么最后的那个key的值会覆盖之前同名的key.因此不能这样配置 只有第二个snippet会被载入‘.source.js’: ‘console.log’: ‘prefix’: ‘log’ ‘body’: ‘console.log(${1:”crash”});$2’‘.source.js’: ‘console.error’: ‘prefix’: ‘error’ ‘body’: ‘console.error(${1:”crash”});$2’ 而应该这样配置 两个snippets都会被载入‘.source.js’: ‘console.log’: ‘prefix’: ‘log’ ‘body’: ‘console.log(${1:”crash”});$2’ ‘console.error’: ‘prefix’: ‘error’ ‘body’: ‘console.error(${1:”crash”});$2’ value可以是字符串, 数字, 对象, 布尔值, null, 或数组. 配置热键在Atom中热键的配置方式与主题类似, 举个例子: 12345'atom-text-editor': 'enter': 'editor:newline''atom-text-editor[mini] input': 'enter': 'core:confirm' 上面的代码定义了Enter键在不同环境中的不同表现. 在正常的编辑窗口中按enter键触发editor:newline命令, 也即是普通的回车. 而当在一个编辑框中键入enter时, 则会触发core:confirm命令. 在默认情况下, 当Atom启动时会加载keymap.cson文件来获取自定义热键, 并且keymap.cson是最后被加载的配置文件, 这样可以保证我们配置的热键可以覆盖Atom自身或其插件定义的热键. 这个文件同样位于~/.atom目录下, 当然也可以通过主菜单Edit-&gt;Keymap…来直接编辑这个文件. 我们也可以在设置窗口的Keybindings页面查看当前所有的快捷键. Atom还提供了一个窗口来帮助我们调试热键的设置, 可以使用Ctrl+.或命令Key Binding Resolver: Toggle来呼出该窗口. 此窗口可以实时显示我们按下的热键所对应的处理方法.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Atom","slug":"Atom","permalink":"http://ipcreator.me/tags/Atom/"}]},{"title":"吴恩达 NIPS 2016：利用深度学习开发人工智能应用的基本要点","date":"2017-02-14T06:39:06.000Z","path":"2017/02/14/SmartAI/ProgramAI/Concepts/ppt-of-andrew-ng/","text":"作者：雷锋网 亚峰 雷锋网(公众号：雷锋网)按：为了方便读者学习和收藏，雷锋网特地把吴恩达教授在NIPS 2016大会中的PPT做为中文版，由三川和亚峰联合编译并制作。 今日，在第 30 届神经信息处理系统大会（NIPS 2016）中，百度首席科学家吴恩达教授发表演讲：《利用深度学习开发人工智能应用的基本要点（Nuts and Bolts of Building Applications using Deep Learning）》。 此外，吴恩达教授曾在今年 9 月 24/25 日也发表过同为《Nuts and Bolts of Applying Deep Learning》的演讲(1小时20分钟)，以下是 YouTube 链接： https://www.youtube.com/watch?v=F1ka6a13S9I 一、深度学习为何崛起 吴恩达在开场提到：深度学习为何这么火？ 答案很简单： 第一是因为规模正在推动深度学习的进步。 从传统算法到小型神经网络、中型神经网络最后演化为现在的大型神经网络。 第二：端到端学习的崛起 从下图中的上半部分可以看出，传统端到端学习是把实体数据表达成数字数据，输出数字值作为结果。如退昂识别最后以整数标签输出为结果。 而现在的端对端学习更为直接纯粹，如机器翻译：输入英语文本，输出法语文本；语音识别：输入音频，输出文本。但端对端学习需要大量的训练集。 吴恩达先讲述了常见的深度学习模型，然后再着分析端到端学习的具体应用。 二、主要的深度学习模型 普通神经网络 顺序模型 (1D 顺序) RNN, GRU, LSTM, CTC, 注意力模型 图像模型 2D 和 3D 卷积神经网络 先进/未来 技术：无监督学习（稀疏编码 ICA, SFA,）增强学习 三、端到端学习应用案例 语音识别 传统模型：语音→运算特征—（人工设计的 MFCC 特征）→音素识别器—（音素识别）→最终识别器→输出。 端到端学习：音频→学习算法→转录结果；在给定了足够的有标注数据（音频、转录结果）时，这种方法的效果会很好。 自动驾驶 传统模型：摄像头图像→检测汽车+检测行人→路径规划→方向控制。 端到端学习：摄像头图像→学习算法→方向控制。 自动驾驶对安全有极高要求，因此需要极高的精确度。采取纯粹的端到端学习十分有挑战性。只在有足够（x，y）的数据，来学习足够复杂的函数的情况下，端到端学习才有效果。 四、机器学习策略 你经常有很多改进 AI 系统的主意，应该怎么做？好的战略能避免浪费数月精力做无用的事。 以语音识别为例，可以把原语音数据分割成： 60% 训练集（训练模型） 20% 开发集（开发过程中用于调参、验证等步骤的数据集） 20% 测试集（测试时所使用的数据集） 这里面普及几个概念： 人类水平的误差与训练集的误差之间的差距是可避免的偏差，这部分误差可以通过进一步的学习/模型调整优化来避免。 训练集和开发集之间的差距称为方差，其因为跑了不同的数据从而导致误差率变化。 上述两种偏差合在一起，就是偏差-方差权衡（bias-variance trade-off）。 机器学习的基本方案 自动数据合成示例 不同训练、测试集的分布 假设你想要为一个汽车后视镜产品，开发语音识别系统。你有 5000 小时的普通语音数据，还有 10 小时的车内数据。你怎么对数据分组呢？这是一个不恰当的方式： 不同训练和测试集分配 更好的方式：让开发和测试集来自同样的分配机制。 五、机器学习新方案 普通人类、偏差、方差分析 人类的表现水平 当机器学习在处理某项任务上比人类表现还差时，你经常会看到最快的进步。 机器学习超越人后，很快就会靠近贝叶斯最优误差线。 可以依靠人类的直觉：（i）人类提供加标签的数据。（ii）进行错误分析，来理解人是怎么对样本正确处理的（iii）预估偏差/方差。比如，一项图像识别任务的训练误差 8%， 开发误差 10%，你应该怎么处理？ 六、人工智能产品管理 新的监督DL算法的存在，意味着对使用 DL开发应用的团队合作，我们在重新思考工作流程。产品经理能帮助 AI 团队，优先进行最出成果的机器学习任务。比如，对于汽车噪音、咖啡馆的谈话声、低带宽音频、带口音的语音，你是应该提高语音效果呢，还是改善延迟，缩小二进制，还是做别的什么？ 今天的人工智能能做什么呢？这里给产品经理一些启发： 如果一个普通人完成一项智力任务只需不到一秒的思考时间，我们很可能现在，或者不远的将来，用 AI 把该任务自动化。 对于我们观察到的具体的、重复性的事件（比如用户点击广告；快递花费的时间），我们可以合理地预测下一个事件的结果（用户是否点击下一个此类广告）。 产品经理和研究员、工程师该如何分工 七、吴恩达新书推荐 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"Facebook 发布开源框架 PyTorch","date":"2017-02-14T05:11:06.000Z","path":"2017/02/14/SmartAI/ProgramAI/Resources/pytorch-of-facebook/","text":"作者：雷锋网 三川 本周，Facebook 的 AI 研究团队发布了一个 Python 工具包，专门针对 GPU 加速的深度神经网络（DNN）编程。它有望辅助、或在一定程度上替代，现有的 Python 数学、统计库（比如 NumPy）。它实现了机器学习框架 Torch 在 Python 语言环境的执行。开发团队表示，除 Facebook之外，它还已经被推特、卡内基梅隆大学和 Salesforce 等机构采用。 Torch 是一个十分老牌、对多维矩阵数据进行操作的张量（tensor ）库，在机器学习和其他数学密集型应用有广泛应用。但由于其语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。如今，作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。雷锋网此前对 Torch 做过介绍。详情请看盘点四大民间机器学习开源框架：Theano、Caffe、Torch 和 SciKit-learn 。 PyTorch 的特点和优势 PyTorch 提供了： 运行在 GPU 或 CPU 之上、基础的张量操作库， 内置的神经网络库 模型训练功能 支持共享内存的多进程并发（multiprocessing ）库。PyTorch 开发团队表示：这对数据载入和 hogwild 训练十分有帮助。 PyTorch 的首要优势是，它处于机器学习第一大语言 Python 的生态圈之中，使得开发者能接入广大的 Python 库和软件。因此，Python 开发者能够用他们熟悉的风格写代码，而不需要针对外部 C 语言或 C++ 库的 wrapper，使用它的专门语言。雷锋网获知，现有的工具包可以与 PyTorch 一起运行，比如 NumPy、SciPy 和 Cython（为了速度把 Python 编译成 C 语言）。 PyTorch 还为改进现有的神经网络，提供了更快速的方法——不需要从头重新构建整个网络。这是由于 PyTorch 采用了动态计算图（dynamic computational graph）结构，而不是大多数开源框架，比如 TensorFlow、Caffe、CNTK、Theano 等采用的静态计算图。雷锋网(公众号：雷锋网)获知，该技术从另一个 Python 的神经网络框架——Chainer 那里借用。开发者团队还强调 PyTorch 优越的内存效率，因为它采用了定制的 GPU 内存分配器。这使得开发者的深度学习模型能够有“最大限度的内存效能”，训练比从前更大的深度神经网络。 虽然 PyTorch 为机器学习应用而优化，这并不是它的唯一使用场景。比如说，相比 NumPy ，PyTorch 的张量计算可作为它对应功能的替代。PyTorch 为这些功能提供了 GPU 加速的版本。在没有强力 GPU 加持的情况下，开发者能使用 CPU 运行。 这是 PyTorch 中包含的工具包列表： torch ：类似 NumPy 的张量库，强 GPU 支持 torch.autograd ：基于 tape 的自动区别库，支持 torch 之中的所有可区分张量运行。 torch.nn ：为最大化灵活性未涉及、与 autograd 深度整合的神经网络库 torch.optim：与 torch.nn 一起使用的优化包，包含 SGD, RMSProp, LBFGS, Adam 等标准优化方式 torch.multiprocessing： python 多进程并发，进程之间 torch Tensors 的内存共享。 torch.utils：数据载入器。具有训练器和其他便利功能。 Trainer and other utility functions for convenience torch.legacy(.nn/.optim) ：处于向后兼容性考虑，从 Torch 移植来的 legacy 代码。 via infoworld","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"如何训练深度神经网络？老司机的 15 点建议","date":"2017-02-13T23:54:06.000Z","path":"2017/02/14/SmartAI/ProgramAI/Tensorflow/how-to-train-deep-neural-network/","text":"作者：雷锋网 本文为印度深度学习专家、创业者 Rishabh Shukla 在 GitHub 上发表的长博文，总结了他过去的开发经验，旨在给新入门的开发者提供指导。雷锋网做了不改变原意的编译。 在深度学习领域，为了高效训练深度神经网络，有些实践方法被过来人强烈推荐。 在这篇博文中，我会覆盖几种最常使用的实践方法，从高品质训练数据的重要性、超参数（hyperparameters）到更快创建 DNN（深度神经网络） 原型模型的一般性建议。这些推荐方法中的大多数，已被学术界的研究所证实，并在论文中展示了相关实验、数学证据，比如 Efficient BackProp(Yann LeCun et al.) 和 Practical Recommendations for Deep Architectures(Yoshua Bengio)。 训练数据 许多 ML 开发者习惯把原始训练数据直接扔给 DNN——为什么不这么做呢？既然任何 DNN （大多数人的假设）仍然能够给出不错的结果，不是吗？但是，有句老话叫“给定恰当的数据类型，一个简单的模型能比复杂 DNN 提供更好、更快的结果”。虽然这有一些例外，但在今天，这句话仍然没有过时。因此，不管你是在计算机视觉（ CV），自然语言处理（NLP）还是统计建模（Statistical Modelling）等领域，想要对原始数据预处理，有几个方法可以得到更好的训练数据： 获取越大的数据库越好。DNN 对数据很饥渴，越多越好。 去除所有包含损坏数据的训练样本，比如短文字，高度扭曲的图像，假输出标签，包含许多虚值（null values）的属性。 Data Augmentation（数据扩张）——生成新样例。以图像为例，重新调节，增加噪声等等。 选择恰当的激励函数（activation function） 激励函数是所有神经网络的核心部分之一。 激励函数把渴望已久的非线性（non-linearity）加入了模型。多年来，Sigmoid 函数 一直是多数人倾向的选择。但是，Sigmoid 函数不可避免地存在两个缺陷：1. 尾部 sigmoids 的饱和，进一步导致梯度消失。2. 不以 0 为中心（输出在 0 到 1 之间）。 一个更好的替代选择是 Tanh 函数。数学上来说，Tanh 只是调整、平移过的 Sigmoid 函数：tanh(x) = 2*sigmoid(x) - 1。虽然 Tanh 仍旧存在梯度消失的缺陷，但好消息是：Tanh 以 0 为中心。因此，把 Tanh 作为激励函数能更快地收敛（converge）。我发现使用 Tanh 通常比 Sigmoid 效果更好。 你还可以探索其他选择，比如 ReLU, SoftSign 等等。对于一些特定任务， 它们能够改善上述问题。 隐藏单元和隐层（Hidden Units and Layers）的数量 如何训练深度神经网络？老司机的 15 点建议 保留超出最优数量的隐藏单元，一般是比较保险的做法。这是因为任何正则化方法（ regularization method）都会处理好超出的单元，至少在某种程度上是这样。在另一方面，保留比最优数量更少的隐藏单元，会导致更高的模型欠拟合（underfitting）几率。 另外，当采用无监督预训练的表示时（unsupervised pre-trained representations，下文会做进一步解释），隐藏单元的最优数目一般会变得更大。因此，预训练的表示可能会包含许多不相关信息（对于特定任务）。通过增加隐藏单元的数目，模型会得到所需的灵活性，以在预训练表示中过滤出最合适的信息。 选择隐层的最优数目比较直接。正如 Yoshua Bengio 在 Quora 中提到的： “你只需不停增加层，直到测试误差不再减少。” 权重初始化 （Weight Initialization） 永远用小的随机数字初始化权重，以打破不同单元间的对称性（symmetry）。但权重应该是多小呢？推荐的上限是多少？用什么概率分布产生随机数字？ 当使用 Sigmoid 激励函数时，如果权重初始化为很大的数字，那么 sigmoid 会饱和（尾部区域），导致死神经元（dead neurons）。如果权重特别小，梯度也会很小。因此，最好是在中间区域选择权重，比如说那些围绕平均值均衡分布的数值。 幸运的是，已经有许多关于初始权重合适取值的研究。这对于高效的收敛非常重要。为初始化均衡分布的权重，均匀分布（uniform distribution ）或许是最好的选择之一。另外，就像论文中所展示的（Glorot and Bengio, 2010），有更多输入连接（fan_in）的单位，应该有相对更小的权重。 多亏这些十分透彻的试验，现在我们已经有了经过检验的公式，可以直接用来权重的初始化。 比如说在 ~ Uniform(-r, r) 提取的权重，对于 tanh 激励 r=sqrt(6/(fan_in+fan_out))；对于 sigmoid 激励 r=4*(sqrt(6/fan_in+fan_out)) 。fan_in 是上一层的大小， 而 fan_out 是下一层的。 学习率 这或许是最重要的超参数之一，调节着学习过程。如果学习率设置得太小，你的模型很可能需要 n 年来收敛。设置得太大，再加上不多的初始训练样本，你的损失可能会极高。一般来说，0.01 的学习率比较保险。但雷锋网(公众号：雷锋网)提醒各位读者，这不是一个严格的标准。最优学习率与特定任务的属性息息相关。 相比固定学习率，在每个周期、或每几千个样例后逐渐降低学习率是另一个选择。虽然这能更快地训练，但需要人工决定新的学习率。一般来说，学习率可以在每个周期后减半。几年前，这种策略十分普遍。 幸运的是，我们现在有了更好的、基于动能（momentum based）的方法，来调整学习率。这取决于误差函数的曲率。另外，既然有些参数有更快、或更慢的学习速率；它或许能帮助我们针对模型中的单独参数，设定不同的学习率。 最近有大量关于优化方法的研究，导致了自适应学习率（adaptive learning rates）。目前我们有许多选择，从老式动能方法（ Momentum Method ），到 Adagrad、Adam （个人最爱）、 RMSProp 等等。；类似于 Adagrad 或 Adam 的方法，能替我们省去人工选择初始学习率的麻烦；给定合适的时间，模型会开始平滑地收敛。当然，选择一个特别合适的初始学习率仍然能起到帮助作用。 超参数调参：扔掉网格搜索，拥抱随机搜索 网格搜索（Grid Search ）在经典机器学习中十分普遍。但它在寻找 DNN 的最优超参数方面一点也不高效。这主要是由于 DNN 尝试不同超参数组合所耗费的时间。随着超参数不断增长，网格搜索需要的计算性能会指数级增长。 有两种解决办法： 取决于你之前的经验，你可以人工对部分常见超参数调参，比如学习率、隐层数目。 采用随机搜索（random search），或者随机采样代替网格搜索，来选择最优超参数。 超参数组合通常在期望范围之内、从均匀分布中被选择出来。加入之前获得的知识来进一步缩小搜寻空间，也是有可能的（比如，学习率不应该太大也不应该太小）。大家发现，随机搜索比网格搜索高效地多。 学习方法 随机梯度下降（ Stochastic Gradient Descent ）的老方法也许对于 DNN 不是那么有效率（有例外）。最近，有许多研究聚焦于开发更灵活的优化算法，比如 Adagrad、Adam,、AdaDelta,、RMSProp 等等。在提供自适应学习率之外，这些复杂的方法还对于模型的不同参数使用不同的学习率，通常能有更平滑的收敛。把这些当做超参数是件好事，你应该每次都在训练数据的子集上试试它们。 权重的维度保持为 2 的幂 即便是运行最先进的深度学习模型，使用最新、最强大的计算硬件，内存管理仍然在字节（byte）级别上进行。所以，把参数保持在 64, 128, 512, 1024 等 2 的次方永远是件好事。这也许能帮助分割矩阵和权重，导致学习效率的提升。当用 GPU 运算，这变得更明显。 无监督预训练（Unsupervised Pretraining ） 不管你进行的是 NLP（自然语言处理）、计算机视觉还是语音识别等任务，无监督预训练永远能帮助你训练监督、或其他无监督模型：NLP 中词向量就（Word Vectors）无所不在；你可以用 ImageNet 的数据库，使用无监督方式对你的模型预训练，或是对于两个类别的监督分类；或是更大频域的音频样本，来在扬声器消崎模型（speaker disambiguation model）中使用该信息。 Mini-Batch（小批量） 对比随机学习（Stochastic Learning） 训练一个模型的主要目的是学习合适的参数，即产生输入到输出的最优映射。这些参数利用每个训练样本进行调参，不管你决定使用 batch, mini-batch 还是随机学习。当采用随机学习方法时，学习每个训练样本后权重的梯度都会进行调参，向梯度加入噪音（随机学习中“随机”的由来）。这样做的结果十分理想，比如说，训练中加入的噪音使得模型更不容易过拟合。 但是，随机学习方法也许效率不高。如今的计算设备有非常可观的运算能力，随机学习很可能会浪费其中的一大部分。如果我们能计算矩阵相乘，那么为什么要限制自己，重复单个矢量组之间的乘法呢？因此，为了更高的吞吐率和更快的学习，我推荐使用 mini-batch 而不是随机学习。 但是，选择适当的 batch 规模同样重要。所以我们能保留一些噪音（相比大规模 batch），与此同时更高效地利用计算性能。一般来说，包含 16 个到 128 个样例的 batch（2 的幂）是不错的选择。通常，一旦你发现了更重要的超参数（通过随机搜索或是人工搜索），batch 规模就会确性下来。但是，有些场景中模型得到训练数据流（比如网络学习），那么采用随机学习就是不错的选择。 打乱训练样本 这来自于信息理论（Information Theory）——“学习到一件不太可能发生的事却发生了，比学习一件很可能发生的事已经发生，包含更多的信息。”同样的，把训练样例的顺序随机化（在不同周期，或者 mini-batch），会导致更快的收敛。如果模型看到的很多样例不在同一种顺序下，运算速度会有小幅提升。 使用 Dropout 正则化 如果有数百万的参数需要学习，正则化就是避免 DNN 过拟合的必须手段。你也可以继续使用 L1/L2 正则化，但 Dropout 是检查 DNN 过拟合的更好方式（雷锋网按：Dropout 是指随机让网络某些隐层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重会保留下来）。执行 Dropout 很容易，并且通常能带来更快地学习。0.5 的默认值是一个不错的选择，当然，这取决于具体任务。如果模型不太复杂，0.2 的 Dropout 值或许就够了。 在测试阶段，Dropout 应该被关闭，权重要调整到相应大小。只要对一个模型进行 Dropout 正则化，多一点训练时间，误差一定会降低。 周期 / 训练迭代次数 “对深度学习模型进行多个周期的训练，会得到更好的模型”——我们经常听到这句话。但多少周期才是“多”呢？其实，这里有一个简单的策略：继续按照一个固定的样例数或者周期训练模型，比如两万个样例或者一个周期。在每批样例之后，比较测试误差（test error）和训练误差（train error），如果它们的差距在缩小，那么继续训练。另外，记得在每批训练之后，保存模型的参数，所以训练好之后你可以从多个模型中做选择。 可视化 训练深度学习模型有上千种出差错的方式。我猜大家都遇到过这样的场景：模型已经训练了几个小时或者好几天，然而在训练完成之后，才意识到某个地方出问题了。为了不让你自己神经错乱，一定要对训练过程作可视化处理。比较显而易见的措施是保存或打印损失值、训练误差、测试误差等项目的日志。 在此之外，一个很好的措施是采用可视化库（visualization library ），在几个训练样例之后、或者周期之间，生成权重柱状图。这或许能帮助我们追踪深度学习模型中的一些常见问题，比如梯度消失与梯度爆发（Exploding Gradient）。 使用支持 GPU 和自动微分法 (Automatic Differentiation）的库 谢天谢地，对于快速创建原型模型，我们已经有了相当不错的库，比如 Theano, Tensorflow, Keras 等等。几乎所有这些深度学习库支持 GPU 计算和自动微分法。所以，你不需要深入研究核心 GPU 编程技术（除非你想——这绝对很有意思）。你也不需要写自己的微分代码——在非常复杂的模型上这相当费劲（但若需要，你应该有能力去做）。 Tensorflow还提供了分布式计算的支持——如果你是土豪的话。 最后雷锋网提醒，这并不是训练 DNN 的完整注意事项表。为了容纳最常见的实践方法，作者去除了一些概念，比如 Normalization of inputs, Batch/Layer Normalization, Gradient Check 等。 via github","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Neural Network","slug":"Neural-Network","permalink":"http://ipcreator.me/tags/Neural-Network/"}]},{"title":"脑芯编：窥脑究竟，织网造芯","date":"2017-02-13T23:14:06.000Z","path":"2017/02/14/SmartAI/ProgramAI/Concepts/brain-and-chips/","text":"作者：雷锋网：本文作者痴笑，矽说（微信号：silicon_talks）主笔。 你信不信有一天，硅工造的芯片会写诗？ 如果信，那说好的“诗三百，一言以蔽之，思无邪”，还真的是“无邪”么？如果不信，请读下面这一首：脑芯编：窥脑究竟，织网造芯（一） 如果要给这诗一个赏析，大概可以是一个忧伤的故事。 天边云的变换复杂，而我却是半梦半醒，我在想一个人，想第一次和他相见，想他的风流倜傥，想他的英雄飒爽。如果你是个文科生，或许你会嘲笑这首连平仄都不满足的劣质诗歌，韵脚也押的有些蹩脚，故事更是为赋新词强说愁。 如果你是理科男，或许对这种思春的小情怀不以为然。 不过，那是因为你们并没有看懂这首诗。 因为这诗暗藏了一个密码，藏着人工智能遇到摩尔定律后蹭出的火花。 另外，这诗不是人工智能的产物，只是矽说在这个人工智能横行的年代里特有的小情怀。 但可能在不远的将来，人工智能将会开车，会翻译，会调情，也会写下更美的篇章。想解开这个人工智能与集成电路的秘密？关注雷锋网(公众号：雷锋网)后期更新，我们一句一句地读下去。 〈一〉昨夜神风送层云在我读书的时候，人工智能（Artifical Intelligence, AI）从来就是CS (Computer Science)的天下，哪有电路撺掇的份。那时候的码农们或许会挂着机器学习，数据挖掘，支持向量机，压缩感知……但从来没有一次，电路的突破是由人工智能推动的。可是在今天，如果你打开半导体行业的利好消息，有多少不是和人工智能，深度学习相关的？ 过去几个月，光在半导体巨头们发生的人工智能的故事就足以吊足大家的胃口。何况，这还是只是很多硅工心目中的人工智能元年。 是什么导致了半导体行业”AI一出惊天下“的巨大改变？矽说推出“脑芯编”系列，为你揭秘类脑芯片的过去，现在与未来。 从人工智能到神经网络神经网络 在人工智能改变半导体行业之前，在AI领域发生过一场“华山论剑”，耗时数载，最终以“深度学习神经网络（Deep Learning Neural Network）”一统江湖落下帷幕。该过程腥风血雨，而主角“神经网络”的遭遇更堪比张无忌、杨过，历经少年时的悲惨遭遇，被无数号称时代“大侠”嗤之以鼻，但终究是主角光环加持，加之得外家指点，十年一剑终成大器，号令天下，谁敢不从。 本篇对这里其中的故事，按下不表，有好事者，可以去各处搜搜，剧情精彩不容错过。但是这里还是要感谢，在神经网络经历最寒冬的时候，一众大牛如 Yann LeCun (读作杨雷昆，不是严立春！！)，Geoffrey Hinton等的默默坚守，才有神经网络的今天。不过他们也早已是Facebook / Google的首席科学家，如今功成名就，也是吾等小辈无法企及的高度。 Yann LeCun, Geoffrey Hinton 神经网络在人工智能领域，属于机器学习一路的分支。所谓机器学习，就是让电脑经过学习后代替人脑做出判断，理解，甚至决定（还记得赢了李世石的AlphaGo么？）。而所谓深度学习和浅学习的区别在于设计者是否告诉电脑的学习策略。最常见的例子是大家电子邮件系统里的垃圾邮件分类，一般一份邮件是否是垃圾邮件，在于它是否满足一些标准，比如是不是群发的，有没有叫你买东西的广告，是不是图片占有比例很高，然后发信人有没有被举报过等等……这些标准都是一个个特征，如果一种机器学习方法规定了学习的特征与策略，那就是浅学习，如果没有规定，需要算法本身去挖掘策略，那就是深度学习。 所以，深度学习的一大隐忧就是——人类并不知道算法本身究竟在想什么？所以如果哪天他在他负责的算法下隐藏了一个暗算/统治人类的bug，那我们就被彻底奴役了。 不过，所谓“庄生晓梦迷蝴蝶”，人类自己究竟是不是被另外一个物种开发出来的一种新智慧呢？然后，那个物种是不是已经被我们灭绝了呢？我们并没有答案。 码农老师教的生物课 为了弄清这横扫千军的神经网络，首先让我们来上一堂不污的生物课。既然叫神经网络，那起源就是生物脑科学。很久以前，人们发现一个单神经细胞（也叫神经元）包括输入（树突dendrites），激活判断（细胞核nucleus），输出（轴突axon）和与下一个神经元的连接关系（突触synapse）。如果用数学抽象出来过程，就是把一堆输入经过线性组合以后经过一个阈值判断，然后输出给下一级。这样一个简单的神经元就形成。把足够多个神经元连起来就能实现神经网络了。 上面两个图就是真实的神经元和它的数学模型。不过我还是要吐槽下： 从上述神经元的提出，到许多仿生的算法结构的研究，如多层感知器(Multilayer Perceptron) ，脉冲神经元(Spiking Neural)之类的，经过了一个甲子的时间，特别但都没没什么巨大的成功，原因有两个： （1）当时的集成电路计算规模与资源远没有达到面向实际应用的需求，仔细去研究神经元的数学模型，会发现每个神经元有若干个权重和成累加计算 。他对应汇编可以大致是如下流程： 累加器清零 (mov)– 循环开始 (branch) 从存储器中加载权重 (load) 从存储器/外设中加载输入 (load) 权重 乘以 输入 (multiply) 累加 (add)– 判断是否重新循环 (goto) 激活函数 (??)输出 存储 (store)对于一个N输入的神经元要走N个循环，这对于上个世纪的单核单线程的CPU，实在是操作难度太复杂。这也就是为什么当流水线与并行处理 不断壮大的近十年，神经网络的发展得到了迅猛发展。 （2）连得不对。这短短四个字，虽说的轻巧，但要找到连连看的窍门，着实花费了多少人的青春？关于怎么连，各位看官先别着急，且听脑芯编下回分解。 作为脑芯编的开篇，今天就到这里，所谓“神风送层云”指的就是集成电路的下一个增长点或许就在在人工智能领域取得巨大成功的神经网络硬件实现上。 〈二〉几重卷积几重生蜘蛛结网，是为了捕食昆虫；蜘蛛侠结网，是为了拯救世界；码农Data Scientist (~ds~) 结网，是为了——换一个角度看世界，英语叫做： Representation。如果你只想知道一个关于神经网络的常识，我认为上面这个单词是最不应该错过的。就像每个学模拟电子学的人，其实归根结底就是学了两个字——放大。 话接上回，我们说到，通过一系列乘累加和非线性激活函数，我们就可以实现一个神经元。而关键的问题就是如何把神经元们连起来。解决这个问题之前，我们先要明白神经网络的作用——通过一系列线性和非线性的变化重新将输入信息映射成为表达事物的本质的简化特征。 如果你觉得上面一句的每个字都认识，却不知道他在说什么，那么我们来看一个经典的例子——人类的视觉皮层（Visual Cortex）。 视觉皮层, 一场生物与AI的伟大握手 码农老师的生物课又来了…… 你有没有想过当你看到生命中一个重要的人的时候，比如说基友（码农怎么会有妹纸？），你是看到是他/她的鼻子，眼睛，脸上的痘痘，昨晚熬夜的黑眼圈……但是这些东西最后都只留下了一个映像——我面基了。可是你有没有想过从你看到图像，到你得到的结论，无数的信息都已经没有过滤，你的脑子完成了一次将4K3D图像压缩成两个字的过程，到底发生了什么事？ 这个过程就是从信息经过视觉皮层（神经网络？？）的过程。从前到后，他经过了几站： （1）始发站——视网膜 ，比较像是一个电子系统的传感器，用来接收信号； （2）快速交流道——LGN，他是将左右眼看到的信号重新编码后传递给视觉皮层，像是一个电子系统中的主控处理器与总线（请原谅我不说LGN的中文，因为说了你也记 不住） ； （3）第一站——主视觉区V1，第一层神经网络，司“边界检测（Edge Detection）”一职，这可能是神经元数量最丰富的一个区域； （4）第二站——次视觉区V2，第二层神经网络，司“基础特征提取”一职，归纳视觉信号的形状、大小、颜色、频率…… （5）第三站—— V3，司“位置“，也是个过渡区，一条线上你有些站你不知道为什么会停~ （6）第四站——V4/V5（MT）分支，深度神经网络，各司“色彩/运动”； （6）V4分支终点站1——换乘inferotemporal Cortex，近深度智能TE区，司 ”目标识别“ ~终于终于我认出基友来了，撒花 （7）V5分支终点站2——换乘Parietal Cortex, 进深度智能MST区，司“空间运动分析”。 视觉皮层可能是目前为止人类认识的最透彻的大脑部分，不过，好像建立在无数的活体实验上。。。即使如此，还是有很多未知的空间亟待生物学家探索。 不知道读到这里，对人工智能略有了解的你有没有觉得这堂生物课在哪里见过？ 先做边界检测，在再做特征提取，在进行分类识别，这不就是大名鼎鼎的 卷积，让加速成为一种可能 其实在神经网络领域里，目前为止唯一能算的上前所未有成功的就是CNN （Convolution Neural Network，卷积神经网络）。最早的CNN可以追溯到98年Yann LeCun的一篇如何识别手写数字的paper，这里出现了第一个CNN的雏形LeNet： 从结构上来，CNN继承了视觉皮层中对信号处理“层”的概念，虽然不是那么的100%的吻合，但是CNN的初级层往往用来做“边界检测”这样的简单的特征提取，而在深度层重新组合初级层的信息成为抽象的再表达（Representation）,最后交给事件的发生的相关概率归纳出事物的本质。 另外，一个比较不太准确的趋势是神经元的数量随层的深度逐渐减少，但是单个神经元的粗壮程度（输入数量）随层的深度逐渐增加。视觉皮层也具有相似的规律，V1的数量多，但是结构比较简单，但到了V4/V5，链接变得很复杂，但占的区域却比V1小的多。 然而，这些都不是做电路的人重点。 对于硅工们而言，CNN获得巨大成功的原因在于：它极大地节省了神经网络的硬件开销，使神经元为单位作加速器成为了可能。 （1） CNN定义了一种更高能效的元操作——卷积核 关于卷积是什么，大家可以去参考一篇《一文读懂卷积神经网络》（广泛地转载于各大公众号间），下图是我目前看到的最形象的卷积描述。 该图片源自网络，感谢原gif作者 其本质就是对于一个区块，判断和自己系数组成的“基”区块的相似程度，得到的分数越高就越相似。这样，当一种“基区块”被赋予一种特征是，即使用于整张图片的特征提取，他的系数也是固定的，因此大量的系数加载操作可以被省略。同时，一个固定大小的“卷积核”成为了比“乘累加”更高阶、更高效的原子操作，在现代计算机体系结构中，实现越复杂，但操作越固定的加速器，其效率和速度的提升也就越大。 （2） Pooling —— 是垃圾就要扔掉 CNN网络的另一个巨大贡献就是在卷积层和层之间，设置了一个”垃圾箱“，把上一层产生的无效信息都扔掉，避免了超大规模的数据传输和存储。大家把这叫做Pooling，我又要来吐槽那个中国人给他取了个”池化“的名字，虽然我也找不到更好的名字，但根本无法帮助理解。Pooling的策略很多，最常见的是max pooling就是留个最大的，然后又其他都扔掉。 （3） “乱撸”？ (ReLU) LeNet后期发展到AlexNet后，激活函数也从sigmoid变成了ReLu，他们的图形曲线大概如下所示。用脚趾头也知道，Relu操作的实现就是把符号位为负置0就好了。至于sigmoid么，传承自经典机器学习回归理论，是e指数的除法操作，编译后简直就是一场噩梦，我们先把他当作一个古老的神话就好了。 以上种种硬件实现的简化，加上CNN的巨大胜利，都当让硅工们看到了直接从电路角度优化的角度切入人工智能芯片的可能。但是，也发现了一个问题，传统的硬件加速的算法往往是做死的，比如椭圆加密，浮点乘除等等。但是CNN的元操作——卷积核——虽然模式固定，但是其每一层的卷积核数量和层数却是纷繁复杂，固定的硬件并不能实现网络的可塑性（structual plasticity）？ 那该怎么办？下一次，如何利用具有高度可编程性的CPU来配置不同结构的神经网络——计算机的”形与令“。就到这里，且听下回分解。 〈三〉梦里不问形与令世界上有两种管家： 一种是Batman的Alfred能服务能做饭能伪装能打架狠起来超人也不是干不过另一种是天朝的大内总管掌印秉笔，啥事不会老大又吩咐了就去传个话你脑子里的CPU是哪一种？ 有了神经元，知道了怎么把神经元连成网络，这个系列终于进入了主题——怎么实现神经网络。如果在这个问题上加一个条件，那就是“怎样用芯片实现神经网络的计算”？ 在回答这个问题以前，让我们先去拜访两位长者——Alan Turing和John Von Neumann，目前大家公认的计算机之父。话说前者才是真的“苟利国家生死以，岂因祸福避趋之”，详见卷福主演的奥斯卡获奖电影《模仿游戏》。 Turing-Von-Neumann架构 为了表达对大师的尊敬，我起了个很干脆的标题。大师之所以是大师，是因为他们定义了在80年前定义了通用计算机的数学模型和体系结构。在这过去的80年里，任何试图推翻这些结构的“投机”分子几乎都没什么好下场。但是，总有人希望推翻这个架构。先简单的描述下两位长者干了什么。 Alan Turing在1936年提出了一种具有普适性的逻辑计算模型，证明通过有限状态机完成输入数据的操作，可以实现任意复杂的逻辑运算。图灵机本身描述的场景在现在看来已经没什么意义，但是他第一次完整的定义普适计算机体系机构——一卷很长很长的带子（infinite lengthtape）通过一个有磁头(head)的有限状态表(finite state table)进行读取/处理/改写的机器。 9年后，Von Neumann把带子改叫做“Memory”，状态表叫做“CPU”，磁头改叫做“Connection (Bus) ”，换了一副图，就有了史称“冯诺依曼架构”的现代计算机体系结构。 教科书上会说这个结构有啥特点，这是让你背的。其实很简单，图灵-冯诺依曼架构最大的特点是把计算任务分为了2个部分——数据存储(memory)和数据处理(processor)。处理器几乎不能存数据，存储器几乎不能算数据。两部分用一种连接方式(bus)按一定规则通信。泾渭分明的特点让冯诺依曼架构处理事情起来特别有条理，就像“男主外女主内”的家庭角色分配一样，在硬件资源极度受限的情况下，成为了自动化发展的中坚力量。 冯诺依曼架构有一个升级版，叫做哈佛(Harvard)架构，把存储空间分为了指令(instruction)存储和数据存储，对应不一样的操作。目前的主流嵌入式微处理器基本采用这个架构，但Anyway这并不重要。 冯诺依曼架构在过去的60年称霸人间，如果这项专利申请成功的话，这一定是史上最赚钱的专利。可是，冯诺依曼架构在经历了各种法院撕逼后，被判定为一项没有收益人的专利……（Youyou Tu和青蒿素在这面前简直不值一提） 成也萧何 - x86的不可一世 虽然冯老爷子在自己的架构下发明了人类第一台计算机，ENIAC和EDVAC，但诺依曼的真正崛起还是要归功于x86。如果你不知道80x86是什么，那只能说明我们已经有代沟了，嗯，很深深的代沟。 Intel自1978年推出8086后，x86体系架构就一直是电脑（上到服务器，下到平板电脑）核心处理芯片的不二选择。 Intel x86 i7 版图 顺便做个普及，在冯诺依曼架构下，每个处理器会干的事情是有限制的，通常这个限制叫做指令集。它规定CPU的基本操作，没有指令集(instruction set)定义的复杂操作可以通过基本操作的组合来完成，比如指令集里没有乘法，那我们可以通过一定数量的加法来完成。 在冯老爷子的机构里，谁的指令集越大，可以访问的存储空间越大，谁就越牛逼。x86的指令集从8086到i7不断扩张与膨胀，最终成为了一个会算双精单精、矢量图像，多核多线程多Cache的巨无霸。简单的说，到2013年的时候，史上最强core已经无所不能了。可是历史不断在重演一幕就是，当绝顶高手号称要独孤求败的时候，不知道哪里窜出来的毛小伙子可能一个起手式就把你撂倒了。圣经里大卫王这么干掉了Goliath，《倚天屠龙记》里，张无忌这么称霸了光明顶。 那谁是x86的张无忌呢？ 移动设备，RISC的春天 独孤求败的x86其实有个致命的缺陷——能效，通俗地说就是“做一次”要花费的能量。可是每块肌肉都很发达的muscleman总是要比一般人多吃几碗饭吧。我们现在能买到的i7即使在省电模式也要消费超过47W的功耗。本身47W不算什么，但是苹果乔大叔的出现，让47W一下子很麻烦。 Iphone/Ipad和一系列手持的充电设备对瓦级以上的功耗是非常敏感的！x86的功耗导致它“充电2小时使用5分钟”的悲惨结局。肌肉男瘦身变成筋肉男的必然的命运。 这时，x86，或者说是intel的张无忌出现了—ARM Cortex RISC. 所谓RSIC就是精简指令集（Reduced Instruction Set），他能干的事情很有限，但是他的功耗低。X86在其巅峰时期无数次地战胜过RISC，以至于ARM出现时并有没足够重视他，那时候Intel还在和AMD抢64位x86的主导权呢。 为什么无数次败下阵来的RISC可以最终成功呢？因为这次，他寻找到了一个partner——加速器。在移动端的应用设备里，其实也有很对需要强大计算消耗的进程，这是RISC本身无法胜任的。但是，实际应用上，往往这些进程是有固定的模式和使用场景的。比如手机在通话时的语音编解码，拍照时的图像处理（俗称“美颜”）和无线通信是的编解码。对于这样一个经常重复，且模式固定的高通量计算，可以在总线上加入一个专用模块（ASIC）加速，在处理专用任务是ASIC的能效又比通用处理器高很多。下图就是ARM有名的产品之一A9，除了CPU外，它的浮点与超标量计算（NEON）都被移到了CPU外（一般来说，这不能算作加速器） 这就是开头的那个故事，你每天充的电不够“超人”吃的，与只能换个块头小，但是能够指挥其他人的总管 败也萧何 – 冯诺依曼瓶颈 “泾渭分明，靠总线连”的冯诺依曼架构带来了单核/少核时代计算机的春天，但冯诺依曼架构的致命缺陷——冯诺依曼瓶颈——也悄悄地增长。随着摩尔定律的发展，远距离的搬移大规模数据早已取代了计算本身，成为制约高效计算的重要瓶颈，对于x86结构，有太多指令可以直接穿过总线访问存储空间。 在RISC+加速器的体系结构里，总线作为“总管”和“内务府”、“上书房”、“御膳房”间的桥梁，更是好不吃紧。当瓶颈出现在通信上时，冯诺依曼架构就体现出了它垂垂老矣的一面。 这个问题，在实时处理的人工智能场景下显得格外突出，信号从入到出，都是按照是数据流(Data flow)的传输模式一帧一帧地来。这一特征在类脑的神经网络实现中就更加明显。如果每一个卷积的系数都要去云深不知处的存储海洋里去寻找，那神经元的处理效率会非常低。简单地说： 谁脑子TM的是一半纯记忆一半纯分析的呢？ 脑子么，都是左右开工的。边走边忘，雁过留痕，却也是旧相识，恢复不出来一个一毛一样的。 所以，摆在类脑芯面前的路有三条： （1） 采用冯诺依曼经典架构，把神经元计算写在指令集里，反正是超人，技多不压身； （2） 采用RISC+神经元/神经网络加速器，给“总管”再开个府呗； （3） 放弃冯诺依曼架构，完全分布式硬件，像“数据流“一样的风骚走位。 这三个选项都有不错的代表，我们慢慢来。 梦里不问形与令，你知道计算机形（体系结构）和令（指令集）了么？ 如何对神经网络人工智能硬件进行优化设计？有三种方式，可以在传统体系结构的基础上面向神经网络人工智能硬件进行优化设计。 本文为《脑芯编：窥脑究竟，织网造芯》系列第四篇。 写这篇的时候想到哥哥的《我》，因为这次的主角就是，那个特里独行的我： 我就是我，是长度不一样的开拓天空海阔，要讨最并行的生活我喜欢我，让矢量算出一种结果简单的指令集，一样加速的很妥妥他的名字，叫做SIMDSingle Instruction Multiple Data话接上回《窥脑究竟，结网造芯（三）》我们说到，有三种方式，可以在传统体系结构的基础上面向神经网络人工智能硬件进行优化设计。这次，我们先来提第一种——在简单指令集（RISC）中增加指令的方式来达到性能的优化。我们将着重介绍如何加速卷积核的计算（忘了（一）和（二）？点这里！） 这次的故事，要从并行计算机体系结构讲起。说到并行计算机体系结构，就要掉一个书袋—— 我从上的第一门计算机体系结构课，到并行提算计体系机构，到高级计算机体系结构都在用这一本书。不得不感谢作者让我少买了好多教科书钱。当然，牛x书的作者也很牛x，这里就不八卦了。有人愿意把这本书叫做计算机体系结构的bible，我不评论，但是下面我们所讲的，好多都出自这本书。 言归正传，这个特立独行的故事从这里开先，我们要认识一个老爷爷（还活着好像），他叫Michael Flynn。老人家生于大萧条时代的扭腰城，一不小心提出了一个分类法，叫做Flynn Taxonomy（1966）。然后计算机体系机构就被Flynn taxonomy的五指山给压几十年。 Flynn Taxonomy的五指山把计算机结构分为两个部分：指令与数据。在时间轴上指令与数据可以单步执行或多次运行进行分类，即单指令单数据（SISD），单指令多数据（SIMD），多指令单数据（MISD）和多指令多数据（MIMD）。 并行，从Pipeline到SIMD Flynn taxonomy给并行计算机体系结构指了两条明路——指令级并行和数据级并行。 首先来看下指令与数据的关系。指令是处理器单步可以实现的操作的集合。指令集里的每一条指令，都包含两个部分：（1）什么操作；（2）对什么数据进行操作。专业地，我们把前者叫做opcode，后者叫做operand（也就是数据）。当然，并不是所有的命令都有数据操作。传统定义的指令集里面，对应的operand不超过2。比如，加减乘除都是典型的二元操作。数据读写就是一元的，还有些就是没有任何数据的操作，比如一个条件判断（if）发生了，根据判断结果程序何去何从，只是一个jump操作，他并不需要任何数据输入。 指令级并行的第一种、也是最经典的办法叫做时间上并行，这是所有的体系结构教科书最喜欢教的流水线架构（pipeline）。简而言之，在发明流水线以前，处理器里面只有一个老司机，什么事情都得他来干，但是下一条指令得等老司机干完上一个~但是，流水线就是把一个老死机变成了三个臭皮匠，每个人干三分之一就给下一个，这样下一条指令只需在上一条被干完1/3后就可以进来了。虽然老司机体力好，但赶不上年轻的臭皮匠干的快啊。这样，流水线可以实现时间上的指令集并行，成倍提高实际指令的处理效率。 经典MIPS-5 级流水线 有一就有二，有时间当然就有空间。所以，第二种办法是空间上的并行。空间并行基于一个观察——对数据的操作有很多种——加减乘除移位、整数操作、浮点操作……每一个模块的处理（ALU/EXU）是独立的，所以，就空间上，一个浮点加法在处理的时候，完全可以同时进行一个整数移位操作，像老顽童教小龙女的左右互搏分心二用。所以，在计算机体系的历史上，练成“左右互博”术的处理器包括超标量（Superscalar）/超长指令(Very Long Instruction Word, VLIW)处理器。具体我们先不展开。 相比于流水线／超标量复杂的修炼过程（黄蓉都练不会“左右互博”），数据级并行就是简单纯粹的叠加硬件，打造并行处理的“千手观音”： “千手观音”的学名叫做SIMD，Single Instruction Multiple Data，单指令多数据（流）处理器。其实，说白了就是原来有处理单元（ALU/EXU）现在一个加法器，现在变成了N个了。对应神经网络的计算，原来要M次展开的乘累加，现在只要M/N次，对应的时钟和时间都显著地降低。 简单粗暴的并行，不仅提高了让每个指令的数据吞吐率，还让本身单一的标量处理进化成阵列式的“矢量型”处理，于是就有SIMD又有了“矢量处理”指令的称呼。其实，SIMD并不是到了神经网络再兴起的新玩样儿，早在MP3的年代，SIMD处理器就广泛地使用在各类信号处理芯片中。所以关于SIMD指令也早有了需要行业标准。以下，我们就来看一个SIMD指令集实例—— ARM NEON，厉害了word令 在上一编中，我们简单提到了史上第一个攻城掠地的RISC-ARM。为手机、平板等便携式的最重要处理器，ARM的SIMD指令也是王者风范，从它的名字开始——NEON。 NEON的指令的操作的输入（operand）是一组128位位宽的寄存器，但这个寄存器存着的几个数，就由码农自己去预定义了，可以是4个32位的浮点，或者定点，或者8个16位定点，或者16个8位定点……整个指令集宽泛地定义了输入、输出的位宽，供变成者自由支配，考虑到在神经网络中，前馈网络往往只要16位、8位整数位宽，所以最高效的NEON命令可以一次实现16个乘累加计算（16个Synapse）。 仅仅是SIMD怎能彰显NEON的侠者风范？ NEON还充分应用了指令级并行，采用10级流水线（4级decode+6级运算单元）,可以简单地理解为把卷积计算的吞吐率由提高了10倍。加起来，相比与传统的单指令5级流水，提高至少32倍的效率。再辅以ARM Cortex A7以上的超标量核心处理单元,筑起了第一条通用并行计算的快车道。 当神经网络遇上SIMD，滑起吧！ 流水线和SIMD都是在神经网络还没羽翼丰满的时候就已经称霸江湖的大侠。在神经网络不可一世的今天，这两者还是固步自封么？答案显然是否定的。 当通用SIMD处理器遇上神经网络，他们既碰撞出了火花，也开始相互埋怨。我们先说埋怨——存储空间管理。我们知道，在NN中通常每个卷积核都需要先load系数与输入数据，再算出部分的乘累加结果，再store回存储空间。而指令执行与存储空间的通信就是我们上一编讲到的——冯诺伊曼瓶颈。对于神经网络来说，如此多次的存储读写是制约性能的关键。减少数据的载入与中间结果是面向神经网络的SIMD指令的主要问题。 那火花是什么？ 这就给SIMD带来了一个面向神经网络的新机遇——部分更新与数据滑行（sliding）。我们来看下面这张动图「原作为MIT Eyeriss项目研究组」。 对于一个采用SIMD的卷积核，有一组输入是固定——系数矢量，而另一组输入像一个FIFO，在起始填满后，每次注入一个单元（也排出一个单元）进行乘雷佳，另外上一次累加的结果在保存在执行单元的寄存器内，只有最终的卷积核结果会写回到存储器中。 这样，在神经网络中，无论是数据导入、还是结果输出，起对存储空间的访问都会大大降低。当然，上述示意图仅仅是一维的。当卷积核的维度达到二三维时，情况会复杂很多。这里推荐大家可以去读读MIT的Eyeriss，Kaist的MIMD，或者IMEC的2D-SIMD（ENVISION）。这里就不太多展开了。 好了，这次就到这里。所谓“烛台簇华照单影”就是那一粒粒自由定义的小数据，在同一声SIMD的指令下，排成队，集成行，成为了一个孤独的矢量运算。 脑芯编：分手？摆脱冯诺依曼的深度学习硬件本文作者：矽说 2017-01-21 12:26 导语：“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。很多人把TrueNorth看作深度学习硬件发展史上打得最响的水花。 雷锋网(公众号：雷锋网)按：本文作者痴笑，矽说（微信号：silicon_talks）主笔。本文为《脑芯编：窥脑究竟，织网造芯》系列第五篇。 不知不觉，《脑芯编》已经走过了上半阙。默默挥手告别那些弃剧的看官，也由衷感谢仍然愿意用手指点进来的您。你们是撑住脑芯编不烂尾的重要力量，与其肉麻，不如再念一遍诗的上半阙： 昨夜神风送层云，（神经元与网络） 几重卷积几重生。（卷积神经网络） 梦里不知形与令，（计算体系结构） 烛台簇华照单影。（单指令多数据） 上次我们讲到，现行的计算机体系结构——“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。其计算和存储分离的特点，使得神经元计算的效率低下。合理改变指令集，加入乘累加指令和SIMD（单指令多数据）指令可以缓解该问题，但仍然指标不治本。 此时，革“冯诺依曼”的命变成了很多懵逼骚年（讲的是心态，年纪可是很大哦）的选项。非冯架构的深度学习硬件一时间成为了洛阳纸贵的一时之选。这个过程自然有资本主义的糖衣炮弹加持，美国国防部先进项目研究局（传说中的DARPA，可以理解为神盾局？）便在非冯架构上与世界顶级研究机构——IBM合作，搞了个叫SyNAPSE （System of Neuromophic Adaptive Plastic Scalable Electronics，其实synapse在字面上也“突触”的拼法）的项目。从第一阶段到最终，DARPA赞助了IBM 4千2百万刀，打响了深度学习抗冯的第一枪——TrueNorth（真北）。 当然，很多人也把TrueNorth看作深度学习硬件发展史上打得最响的水花。 Neuromophic，替天行道？ 任何革命都要师出有名，就算水泊梁山也有个“替天行道”的名头。那真北的“名”在哪里呢？很简单，我们要造一个真“大脑”，而不是计算机这样给冯老爷子当傀儡的“伪电脑”。英语叫做Neuromophic，神经形态的硬件。于是就有了这张图： 真北的设计理念，以人脑为起蓝本，依葫芦画瓢，不带点儿差的。 IBM的工程狮从微观到宏观，将人的大脑分成三个层次——神经核团、脑功能区和脑皮层。每个核团由很多个神经元组成，每个功能区由很多核团组成，一个能完整地进行一项任务的皮层由很多个功能区组成。（是不是好久没有上过码农老师的生物课了，有没有点怀念呢？下面还有。） 对应的，真北架构下，也分为这三个层次。先做了一个核团对应的硬件——neurosynaptic core，每个core由256个输出与输入、以及对应的系数存储，并集成了神经信号的路由器（router）使得信号可以在长距离上游走；在此基础上，一块芯片有64乘64个这样的核团，共4096个，组成了一个“功能区”。而很多完整的应用和复杂的任务，还需要芯片与芯片间的互联，实现一个完整的皮层功能。看，这才是真正的神经形态的“电脑”。 TrueNorth还追求了一个大脑的特点，没有全局时钟控制的信号传递。真北只有帧时钟（1KHz，和intel的3.6GHz比慢了几百万倍哦~），并没有控制信号流的时钟，数据和数据之间采用异步的方式进行通讯，寻求高能效和低功耗。 这里留给读者一个问题：为什么是非冯呢？（提示：memory在哪里？）如果各位看官到这里眼皮还没有搭起来，可以考虑去读读TrueNorth的Science原著，保证一夜睡到天明。 SpikeNN，致命缺陷？ 如果有一件事情，可以把昏昏欲睡的人们从周公的世界里拉回来，那一定是——撕逼。 当所有人都觉得TrueNorth要改变人类的时候，惊天一声雷从华山之巅劈下来。出手的，是在神经网络中有“东邪西毒南帝北丐”之称呼的Yann LeCun。（我们在脑芯编（一）中提到过他。） 深度学习的“东邪西毒南帝北丐”F4 Yann大人在Facebook上发了一篇长长的博客来表达自己对True North的不屑。这里节录部分。（冬天了，小编最近比较懒，所以靠复制黏贴凑字数） Now, what wrong with TrueNorth? My main criticism is that TrueNorth implements networks of integrate-and-fire spiking neurons. This type of neural net that has never been shown to yield accuracy anywhere close to state of the art on any task of interest (like, say recognizing objects from the ImageNet dataset).简单的说，问题出在Spiking Neural Networks。Spiking的中文可以叫做脉冲，用现代的生物医学技术发现，spike是人脑中信息传递的真实电学过程。下图就是人脑中一个神经元附近测到spike信号： 医学上，也叫这个信号为细胞膜动作电位（Action Potential）。事事以脑科学为准绳的TrueNorth，自然在这基础理论上一定是向生物学看齐的。可是，问题便在于，在神经网络被提出来的前几十年，就是这spike NN的英魂不散，才导致了其早期“食之无味，弃之可惜”的尴尬地位。 就像那个最有名的比喻：因为鸟的翅膀，让人类渴望飞翔；但放弃对翅膀的模仿，才让飞机真正飞上蓝天。很多事物只能赐予灵感，却无法100%照搬，否则下场就是那些个鸟人。（这话也不是我这种小辈敢说的，同样来自Yann大人） Memristor，吴下阿蒙? 一方面，如果spike完成神经信号的传递与运算真的有问题，那人类为什么聪明？ 另一方面，如果SpikeNN真的100%模仿了我们的脑子，为什么连个ImageNet分类都分不清楚？一定是哪里出了问题。答案是后者。 首先，在我们通常使用的神经网络里面有个假设——系数（Weight）在训练完成后是固定，不改变的。这个假设在CNN/RNN等一系列架构中显得天下太平，因为系数位宽大么。但是到了SpikeNN就是个大麻烦，所有的信号是二进制的，所谓的系数只改变链接关系、延时，不改变幅度，自由度大大衰减。那我们的脑子真的是这样的么？ 唉，生物课又来了。 虽然我们的大脑的神经元看上去是二元的，但是神经元通路还有一个可塑性维度，叫STDP （Spike Timing Dependent Plasticity），就是突触的连接强度（Plasticity，可塑性）收到输入输出脉冲（Spikie）间的时间先后（Time Dependent）关系，其本质核心如下图。 如果输入将将早于输出，代表输入输出间是完美的因果关系，神经元联系会被增强；如果输入的脉冲稍晚于输出，那么他们之间是果因关系，神经元的联系应该要减弱。STDP被认为是我们大脑的主要学习机制，而且在不同动物上都经过了实验验证。 问题来了，这种学习机制和CS里面主流的学习机制——Stochastic Gradient Descent (SGD，中文叫做随机梯度最速下降？) 的后馈算法有着天壤之别。小编觉得这也是目前神经网络算法与神经科学的最大分歧。 没有STDP的真北就这样陷入了SpikeNN的坑。但话说回来，STDP这么高级的操作模型，用传统模数混合集成电路实现是非常浪费面积，且不划算的。好巧不巧，人类突然造出了一个除了电阻电容电感之外的第四类电学器件——Memristor，忆阻器。仿佛是上帝要有光，就有一缕阳光照进SpikeNN的黑暗的胡同里。 对于一个电阻，两端的电压和电流成正比，对于一个电容，两段的电荷和电压正比，对于一个电感，两端的磁通量和电流正比，对于一个忆阻器，就应该是两端的磁通量和电荷成正比。虽然很抽象，但是忆阻器的实际效果就是其电阻（导通强度）受流过的电流调制。这个效果已经非常接近STDP了。 试想，连在忆阻器两端的突触，当设定为上一层的神经元先发生spike，而下一层后发生spike，那一个正向的电路流过忆阻器，减小忆阻器阻值，加强链接。反之，负向电流流过忆阻器，增大阻值，减缓链接。 于是，大家逐渐开始相信，在真北架构上如果能用可随摩尔定律减小的微纳尺寸忆阻器，或许才是Brain Inspired Computer真正焕发春天时候。 于是，兼容先进集成电路的高性能忆阻器就成了问题的关键。但是，作为memristor的发明者和最努力的推广者——HP，最近好像有点无奈。 但是也不要太灰心，最近intel和micron联合推得风声水起的3D Xpoint Memory被认为是某种程度的RRAM/memristor。究竟忆阻器是吴下阿蒙，还是未来的江左梅郎，还在未定之天呢。 这一期可能是脑心编目前为止最为干货满满的一期，牵涉好多paper，如果看官您的目光移驾到这里，小编我也是要这厢有礼的，不容易啊。 ”真北路上初相见“，告诉你采用非冯架构的IBM TrueNorth（真北）的出生、虐缘和不明亮也不灰暗的未来。下一次，我们要来讲讲以GPU为代表的协处理器深度学习架构——“一见泰坦误终身”。 特别鸣谢复旦大学脑芯片研究中心提供技术咨询，欢迎有志青年报考。 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"}]},{"title":"Google RAISR技术落地应用 可节约75%流量","date":"2017-02-13T06:30:06.000Z","path":"2017/02/13/SmartAI/ProductAI/google-raisr/","text":"作者：网易AI研究院 谷歌在11月推出了一项新技术 RAISR，全称为“Rapid and Accurate Image Super-Resolution”，意即“快速、精确的超解析度技术”。RAISR利用机器学习将低分辨率图像转化为高分辨率图像。 RAISR首先制作较小版本的图像，使用传统方法将至拉伸，然后将拉伸后的模糊图像同原本的高分辨率图像进行对比。算法习得两者之间的差异，这允许它在保留图像的底层结构之上构建信息。 （谷歌RAISR流程图） 谷歌已经在自家社交平台Google+上应用RAISR技术。RAISR也能够在手机上工作，帮助用户在传输信息时节省数据流量。 使用RAISR之后，Google +能够节省高达75%的网络带宽。通过网络传送低分辨率的图像，图像在接受之后又能恢复高清。 相当于只有1/4的文件体积需要网络传输。 图像的传输对网络带宽具有很高的要求，在网络连接昂贵或连接状态不稳定的情况下尤其如此。在这种情况下通过网络加载图像是让人头痛的事，很多人甚至选择关闭图像，纯文本浏览网页。如今RAISR技术可以大幅度减少图像传输对网络带宽的需求。 该功能正被逐步推广到安卓用户中去。从用户的角度来看，RAISR的整个运行过程几乎难以察觉，无形地帮用户节约流量。现在每周有十亿张图像经过RAISR处理，为用户减少了1/3的网络消耗。谷歌计划在未来更广泛地推广这项技术，并表示将进一步努力减少图像传输所需的时间和带宽要求。 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"}]},{"title":"大数据深度学习下车辆厂牌型号识别","date":"2017-02-13T06:30:01.000Z","path":"2017/02/13/SmartAI/ProductAI/recognize-license-number-of-car/","text":"作者：36大数据 数控小V 2015年3月，北京文安公司发布了基于大数据下深度学习的机动车厂牌型号识别技术。 车辆身份识别系统是智能交通的重要分支，它需要人工智能、图像处理、计算机视觉、模式识别等相关技术的综合应用。目前国内的车牌识别技术已经日益成熟，随着智能交通技术应用的不断加深，业界迫切希望提取更多元的车辆信息，除车牌号码外，还需要车辆的厂牌、型号以及颜色等信息特征。这些特征在停车场无人管理、交通事故处理、交通肇事逃逸、违章车辆自动记录等领域具有广泛而迫切的应用需求。 ## 技术实现途径 机动车厂牌型号识别技术分为多个环节，一般是通过对摄像机采集的数字图像进行去噪、增强、车标定位、特征提取、识别等分析完成。为了得到较高的识别率，要求每一个处理步骤要有很高的准确率，而实际背景复杂，四季、昼夜、晴雨等不同情况的光照以及车辆运动速度的快慢等直接影响车辆图像的成像环节，造成车辆图像颜色失真、车身及车标区域灰度不均匀、边缘模糊、粘连等问题，增加了处理难度；反光、逆光、夜晚光照不足、树荫、车身颜色显著区域分布位置不同等情况又增加车身颜色识别难度；再加上车辆类别繁多以及车身本身的污损、遮挡、模糊，也为进一步提高识别率带来诸多困难。 北京文安自05年起，在行业里深耕多年，掌握了大量的实际数据与丰富的算法经验，针对诸多问题，公司综合采用了国际先进的人工智能、计算机视觉、图像处理、模式识别、大数据训练、深度学习等等技术来，通过从视频流中检测车辆、车头区域的定位、变形和倾斜校正、去除运动和成像造成的模糊、车辆特征的定位和识别、海量特征的选取和决策等多个环节来实现。 ## 1. 百万级大数据训练，特征提取更丰富 在系统的设计和实现过程中，公司开发应用了当今国际上最先进的计算机视觉技术，并通过超百万的大数据学习样本进行训练，大量实地数据的系统调整和测试，还采集了描述车头、车灯、散热格栅等各个部分的外形轮廓、相对位置、颜色、纹理等多种特征，组成了海量的辅助分类信息，与厂牌型号识别的结果一起最终通过可在线学习的特征决策模块，得到综合可信度评价，从而得到最终的识别结果。 ## 2. 深度学习算法，提高数据精准性 浩瀚如海的大数据，结构复杂，种类繁多，单纯依靠人力定义的过程无法处理这海量数据。于是我们采用基于模仿人类神经网络的人工智能算法，让机器从海量数据当中自我学。深度学习的实质，就是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。我们通过利用大数据来深度学习各类信息、特征，更能够刻画数据的丰富内在信息。从而得出更多元更精准的厂牌型号及其他信息。 ## 3. 并行计算，使算法不断优化 系统还通过利用北京文安强大的并行计算能力，极大的加快了计算速度和数据处理速度，使算法不断优化，目前厂牌识别种类已达632种。常规情况下，识别率在92%以上，识别车身颜色包括黑白灰红等十余种。在样本大数据不断增加的同时，通过模型训练及深度学习，指标将不断提升。 ![](http://www.36dsj.com/wp-content/uploads/2015/03/337.jpg) 机动车厂牌型号的识别为违法车辆以及套牌车辆的有效监测提供了有力的手段，为保障人民人身安全和打击违法犯罪行为提供了有效的工具。机动车厂牌型作为车辆识别的重要属性，在大数据深度学习背景下，未来将不断完善，并将推动为智能交通向更加精准、高效发展，使我们的生活更加智能、高效、便捷。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"基于char-rnn和tensorflow生成周杰伦歌词","date":"2017-02-13T06:30:00.000Z","path":"2017/02/13/SmartAI/ProductAI/generate-lyric-from-lyric-of-jay/","text":"作者：leido 最近深度学习在机器视觉CV、自然语言处理NLP领域表现出强大的潜力，各种深度学习/机器学习框架也层出不穷。TensorFlow是google于去年(2015.11)开源的深度学习框架，截止目前(2016-11-28)Github上已经有38000+的star数，称之为最近最受欢迎的深度学习框架一点也不过分。 本着学习TensorFlow和RNN的目的，前些天发现了char-rnn这个有趣的项目，具体就是基于字符预测下一个字符，比日说已知hello的前四个字母hell，那我们就可以据此预测下一个字符很可能是o,因为是字符char级别的，并没有单词或句子层次上的特征提取，相对而言比较简单易学。 因为原作者的代码是基于torch写的，为了熟悉tensorflow，我就仔细地研究了一下具体代码，然后改写成基于tf的代码，github上也有基于TensorFlow的char-rnn-tensorflow，恕我直言，有以下三点比较膈应： 代码写的不够直观简洁另外因为最新tensorflow的部分api有所变化中英文之间有一些差异，看能否成功移植到处理中文上于是打算基于以上两个项目，自己重写! 基本原理 拿中文举例来说，每个字与每个字并不是统计上独立的，比如说如果不爱就不要再伤害长度为10的序列，如果我们知道如，下一个字有可能是果，如果知道前两个字如果，第三个字就是不的可能性大些，依次类推，如果知道前9个字如果不爱就不要再伤，那么最后一个就有可能是害字。用图直观的表示如下。 总的来说，这是一个seq2seq的模型，训练数据用的是周杰伦01年到11年所有歌的歌词，训练数据和代码我都放到Github上，可以从这里下载 全部代码如下： python3 gen_lyrics 0训练差不多10几分钟，然后运行python3 gen_lyrics.py 1生成的歌词如下： End.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"新型耳机将要拉开AI增强人耳听觉序幕？","date":"2017-02-13T06:21:06.000Z","path":"2017/02/13/SmartAI/ProductAI/ai-on-ear-phone/","text":"作者：网易AI研究院 据国外媒体报道，有家新公司在打造一种经过人工智能（AI）技术增强的耳机产品，其背后的理念是 AI人耳比普通的人耳要好使。 我们往往要在喧闹环境中专注于特定的声音——如孩子的哭喊声，在嘈杂的俱乐部中听朋友说话等等——这并不容易做到。要是人工智能能够让我们的耳朵变得更加智能呢？有家公司打算明年初推出这种智能平台：售价299美元的蓝牙耳机。他们的真正目的是什么呢？揭开AI增强的人耳听觉的序幕。（这可能也预示着手机的末日。） 该款耳机名为Here One。 其背后的新公司Doppler Labs对即将推出的产品的演示令人印象深刻。它的功能清单令人大开眼界，既能够让人一窥人耳听觉被强化的未来，也能够呈现各种有待征服的技术挑战。该产品是那种基于技术的个性化人类增强型设备的一个例子，未来可能将会出现更多这样的设备。 以下是Doppler希望Here One和相配的手机应用在推出之时能够提供的功能。而它明显将会配备的功能则包括：无线流式音频，无线电话，控制Siri、Google Voice等虚拟助手。 用户能够同时听到混合串流音乐和周围的声音 之前尝试捕捉环境声音的一些产品听上去很怪异，声音有点滞后。而Doppler的产品则显然终于解决了这一问题。刚刚戴上Here One耳机时，《连线》杂志撰稿人大卫·皮尔斯（David Pierce）发现，Here One版的真实世界相当通透，相当即时，以至于他一开始都意识不到自己已经戴上耳机开始听。该功能背后的理念在于，在给人们提供收听美妙音乐的方式的同时，确保没有将他们与周围的世界隔绝。 放大或减弱用户需要倾听的说话者的声音 在戴上Here One耳机后，《连线》撰稿人与Doppler高管的对话持续正常进行，直至后者突然将自己在Here One耳机中的声音停掉。专注于你想要倾听的人和屏蔽不想要听的那些人的声音，这我们可以尝试去做到，但我们的器官是做不到这一点的。 减弱噪音音量，或者完全将其消除 Here One的智能过滤功能依赖于机器学习技术。 它需要在用户可能遇到的声音上有广泛的数据，日常生活中有着各种各样的声音。Doppler的弗里茨·拉恩曼（Fritz Lanman）向Quartz表示，“婴儿的哭喊声极其多变，它们属于宽频带噪声，变化莫测，非常特别。” 为了实现那一目标，Doppler一直在收集音频样本——截至目前已经超过100万份，它们收集自五大洲——收集过后它会将那些样本转化成供Here One使用的声音检测算法。该公司目前在做的一件很有意思的事情是，在全球各地从卖出的Here One耳机收集音频数据，并持续以新算法形式将那些数据反馈回用户。（Doppler表示那些数据都有进行匿名化处理。）也就是说，该公司实质上是在众包其系统的声音检测算法，他们卖出的耳机越多，覆盖的受众就越多。 倾听不同方向的声音 通过设置，Here One耳机可以变得只倾听你身前或者身后的东西，完全隔绝其它方向的声音。Doppler在决定如何称呼向后倾听功能，考虑将其称作“窃听”或者“间谍”模式。从根本上说，它就像是转耳“猫”模式。我们再也不用羡慕会180度转耳的猫了。 定制用户周围的声音 一系列的控制功能让用户改变听到的世界，让用户都能够享有自己的音景。这是一种新型的泡沫现实——这可能是好事，也有可能是坏事。不管怎么样，用户都将能够调整那些声音的音量——智能过滤器让你可以锁定它们——用均衡器（EQ）改变它们的音调特点，又或者给它们增加音频效果。 创建个人收听档案 Here One能够注意用户的收听习惯，当用户进入不同的声音环境时，它会根据用户的习惯提供调整建议。这是让用户走出刺耳的环境，进入属于自己的定制化音频环境的又一种方式。 Doppler还让媒体看了一下其它的一些还没有完善的功能特性。 实时翻译 在演示中，Doppler用西班牙语给《连线》的皮尔斯讲了一个笑话，而后者听到的是用英语说出的笑话。这应该是得益于人工智能技术。该功能目前尚不完善——比如，笑话延时了大概五秒钟——但这种功能的价值显而易见。可以说，这是旅行者们期盼已久的功能，它有望促进世界各地文化背景不同的人之间的沟通交流。 自动识别和提高你在乎的人的声音 这种功能在很多时候都很有帮助，比如在嘈杂的环境中听到你疼爱的婴儿在哭。当然，若能够自动识别和屏蔽用户讨厌的人的声音，也是很不错的：用户可以让Here One自动屏蔽一个烦人的朋友的声音。但从AI角度来看，在现实世界中鉴别声音的身份是件非常困难的事情。Siri、Echo、Google Voice和Cortana能够轻松做到这一点：他们只需在安静的环境中听几次你的声音，就能够根据声音辨认出来。而从混乱而不断变化的音景中鉴别出某人的声音则要困难得多，Doppler还没有走到这一步。 关于用户的手机的未来 要是用户可以直接通过蓝牙耳机打电话，用户还有什么理由需要手机上的应用呢？未来我们还需要手机屏幕和应用吗？我们可能还是需要的：对于复杂的信息，视觉体验可让用户更容易理解。《连线》指出，技术专家克里斯·诺赛尔（Chris Noessel）曾这么说到《她》（Her）科幻电影中AI操作系统Samantha与人类的沟通方式，“Samantha经常通过耳机跟西奥多说话。而当她需要向他展示某样东西时，她会让他注意手机或者桌面屏幕。” 不过，Doppler还是想要将手机完全剔除出去。“我们知道，用户从口袋中掏出手机这一步，就是体验的阻力部分。”Doppler用户体验与用户界面主管西恩·弗尔（Sean Furr）指出。 这涉及很多重要的问题，如我们是什么，我们该如何互动，我们该如何体验和穿梭于这个世界。我们所有人都生活在自己的声音世界是好事情吗？这会让人们更难对现实产生共鸣吗？在这种技术真正整合到我们的生活中之前，这些问题都不会有答案。（皓慧） 车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统本文作者：李子湃 2017-02-10 23:22 导语：在汽车传感器检测到将要发生不可避免的碰撞时，粉红噪声（Pink Noise）刺激耳内镫骨肌收缩，保护内耳和鼓膜。 车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统 从制动辅助系统(BAS)到电子感应制动系统（SBC），主动安全技术已经从避免车辆碰撞发展到避免更加微小的人身伤害。 奔驰在近日公布了应对车祸造成听力损伤的解决方案：通过检测不可避免的车祸并发出安全的粉色噪声（最大80分贝），让声音刺激耳内肌肉收缩，预防车辆碰撞甚至是气囊弹开所发出的巨大噪声造成的听力受损。 粉色噪声是自然界最常见的噪音，简单说来，粉红噪音的频率分量功率主要分布在中低频段。根据IEEE的数据，奔驰采用的粉色噪声强度大约是 80 分贝，相当于一台洗碗机工作的声音，对于人耳来说比较安全。而在车祸发生时产生的高达 145 分贝的声音，有极大几率对听力造成损害，安全气囊弹开的时候，声音更高达 165 分贝。雷锋网(公众号：雷锋网)查阅到的数据显示，曾遭受车祸并得到安全气囊保护的被调查者中，有 17% 的人受到永久性的听力损伤。 这种听觉保护技术加入奔驰称之为 PRE-SAFE的主动安全系统之后，这套系统几乎已经覆盖了目前车祸发生时大部分人员受伤的情况，包括正副驾驶之间的碰撞，甚至是汽车最忌讳的侧面撞击。 此前奔驰公布的一项PRE-SAFE技术显示，车辆在预警到侧面撞击之后，会主动将撞击一侧的乘客“推”向中间位置，整个过程的响应速度在毫秒级别。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。 ]我如何用深度学习改造母亲的助听器？本文作者：小东 2016-12-20 10:12 导语：深度学习重新定义助听设备，过滤杂音效果良好。 雷锋网(公众号：雷锋网)按：目前的人造听力系统存在一个关键问题：无法过滤背景噪音。尽管用户对倾听的需求十分强烈，然而硬件只是单纯地将声音放大——自然也包括噪音。英国认知科学家Colin Cherry于1953年首次将这一问题称为”cocktail party problem”（鸡尾酒会难题）。 作者 DeLiang Wang 是一名俄亥俄州立大学的教授，他主要关注计算机科学及工程领域，此外，他也在学校的认知及大脑科学研究中心工作。本文是他基于自己亲人的切身体会，利用深度学习改造助听器的自述，雷锋网编译，未经许可不得转载。 我如何用深度学习改造母亲的助听器？ 我上大学的时候，母亲的听力逐渐下降。不过一直以来，我很愿意回家将我所学的东西与她分享，她也很乐意倾听。但渐渐地我发现，如果多个人同时说话，那么母亲很难分清到底是哪个人在和她讲话。尽管她使用了助听器，但对她来说区分这些声音仍旧很难。在我们家庭聚餐的时候，我母亲不希望我们同时和他说话，希望每次只有一个人和她说话。 我母亲的痛苦遭遇反应了目前助听设备面临的一个主要问题，即助听器滤音效果不好。尽管信号处理专家、人工智能专家、听力专家已经努力了几十年，但现在的人造听力系统仍不能很好滤掉背景噪音。 据估计，六十年后将会有约25%的人需要佩戴助听设备，如果这些设备去除杂音的效果不好，那么我们可以想象这样一个场景： 当一个人和佩戴助听设备的人谈话时，此时一辆汽车呼啸而过，但这些助听设备只是简单的将杂音与话音放大，却无法很好去除汽车杂音，此时对于用户的听力将会造成多么大的伤害，他们将听不清对方的讲话。是时候该解决这个问题了，我在俄亥俄州立大学的实验室目前尝试使用深度学习模型实现杂音与声音分离，此外我们还尝试了多种用于去除杂音的数字滤波器。 我们相信基于深度学习模型的听力修复可以使听力受损人的听力理解能力达到甚至超过正常人。实际上，我们的早期模型效果一直在提升。由原来听清 10% 提高到 90%。在现实生活中，即使人们没有听清一句话中的每一词，他们也可以理解这句话的意思。所以这实际上已经意味着，人们已经从“一句都听不懂”变成了“能听懂一句话”的状态。 对于有听觉问题的人，没有好的助听设备，人的听力只会越来越糟。世界卫生组织估计约 15%（776百万人）患有听觉问题，随着老年人口的增多，这一数字将会逐渐变大，并且高级听力设备的潜在市场不仅局限于听觉受损用户。开发商可以将这一技术用于智能手机，以提升智能手机的通话质量。一些人的工作环境背景噪音复杂，这个设备可以解决这问题。处于战争环境中的士兵也可以佩戴这个设备使得他们之间的通话更加顺畅。 语音清洗与过滤 助听设备的市场广阔，据印度MarketsandMarkets研究发现，目前助听行业规模大约为60亿美金，市场规模在2020年以前预计以每年6%的速度递增。为了满足新用户需求，我们需要解决‘鸡尾酒会难题’，那么如何解决呢？深度学习给我们提供了一个很好的解决思路。 语音清洗流程如下： 信号转换：机器学习程序首先将语音信号转换为时域信号。 特征表示：在时域范围内用85个特征表示语音信号， 语音分类：将这些用特征表示的语音信号传入深度学习模型中，找出语音信号与杂音信号， 杂音过滤：使用滤波器去除杂音信号，保留语音信号。 数十年来，电子与计算机专家尝试从信号处理的角度实现语音与杂音的分离，但均以失败告终。目前最有效的方法就是语音活动检测器，用于识别不同人之间的说话。在这种方法下，系统检测出不同的语音信号，然后滤去这些声音信号，留下理想的、无杂音信号。不幸的是，这种方法效果很不好，它通常会滤去很多语音或只滤去少量杂音。即便经过了几十年的发展，这项技术的实际效果仍然不太理想。 我觉得我们得使用新的方法解决这个问题，我们首先研究了 Albert Bregman（ McGill University）的关于人类听力系统的理论，他认为人类的听觉系统将不同的声音分成不同的声音流，一个声音流对应一个音源，每一个声音流据有不同的音高、音量、方向。 上图展示了声音场景是如何形成的 总之，许多音流（像曲棍球比赛中朋友们的呐喊）组成 Bregman 所谓的听觉场景。如果不同音波的音频一样，那么音量最大那个将会盖过其它声音，这一现象被称作听觉掩蔽效应。例如，下雨的的时候没人会听到钟表的滴答声。这原理也用在了MP3的文件中，它通过压缩被掩蔽的声音，使得文件大小变为了原来的十分之一，文件虽然缩小了，但用户却没有任何感觉。 回顾了Bregman的工作，我们设想我们是否可以构建一个滤波器，在特定时刻对于特定音频，这个滤波器可以找到主声波。听觉感知专家Psychoacousticians将人类的听觉频率（20Hz到20000Hz）分成24份，那么问题就变成了我们需要一个滤波器，在某一时刻这个滤波器可以告诉我们是否存在一个包含比其它语音或杂音都大的声音，然后江这个大的声音进行分离出来。 我的实验室在2001年就开始了这项工作，并给音流打标签，以表明他们的主音流是语音流还是杂音流。有了这些标记数据，然后我们基于机器学习的方法，训练一个能区分主音流是声音还是杂音的分类器，这些特征包括音量、音调等。 原始过滤器是一个二元过滤器，用于对特定时刻特定频率的声音进行标识，这个过滤器在时域范围对声音信号进行0、1标识，如果主音为声音，标1；主音为杂音，标0。最后生成一个主音为声音与主音为杂音的样本集合，滤波器除去标识为0的声音，保留标识为1的声音。为了保证句子能够被理解，必须保证标识为1的语音占有一定的比例。 2006年，在美国空军实验室我们对声音滤波器进行测试，与此同时，另外一家机构也队我们的产品进行独立的第三方评估，在这些试验中，我们的产品性能优异。不仅有助于提高听觉受损者的听力水平，还有助于提高正常人的听力水平。 我们创造了一款在实验室中表现优良的听力设备，在设计过程中，我们训练的时候是将语音信号与杂音信号分开的。测试的时候将这两者混合在一起，然后测试。由于这些信息均为为标记信息，所以过滤器知道什么情况下语音信号要大于杂音信号，所以我们称之为理想滤波器。但实际情况是滤波器应该能靠自己进行判断，而不是靠我们提前告诉它。 不过，理想滤波器确实能提高听觉受损者与正常者的听力理解水平。这表明我们可以将分类方法用于区分语音与噪音。分类方法实际上是一种机器学习的方法，通过训练、反馈、惩罚等一些列类似于人的学习过程，来实现对声音信号的正确分类。 在接下来的几年中，我们实验室开始尝试使用分类方法来模仿我们滤波器，同时，我们基于机器学习设计新的分类器，提高自动语音识别的质量。后来一组来自University of Texas的研究人员使用一种不同的方法首次实现语音可懂性的实质意义上的进步，这种方法仅使用了单声道特征。 但是对于助听设备来说，这些分类方法的效果与精度还不够，这些方法还不能处理现实世界中复杂环境下的声音信息。因此，我们需要更好的方法。 如何进一步改善系统？ 我们决定进一步改善系统效果，使我们的系统可以应用在现实环境中且不需训练。为了解决这个问题，我们构建了一个以前从未构建过的机器学习系统，经过复杂的训练，这个神经网络系统，可以用于声音与杂音的分离。在24个测试样本中，这套系统提高听力受损人员的听力理解力约50%。效果良好。 神经网络是由一些简单的神经元组成，这些简单那神经元组合在一起就可以处理复杂的问题。当一个新的神经网络模型构建好以后，这个模型需要利用数据不断的调整神经元与神经元之间的权重（类似于人脑学习），以达到实现语音信号分类的目的。 如上图所示：左侧为为输入层，右侧为输出层，通过调节层与层之间的神经元之间的链接权重提高系统性能。 神经网络有不同的形状、大小、深度。隐层多余两层的就可以称为深度神经网络，上一层的输出是下一层的输入，就好比给下一个隐层增加一些先验知识。 例如，我们通过数据训练一个签名识别网络，如果此时有一个新的签名，这个签名与数据集中的签名是一个人写的，却与数据集中的签名不完全一样，但我们的网络仍可以识别出来，因为我们的网络层是可以识别出同一人签名的不同特征的，只要特征相同，就可以认为是同一个人写的，这些特征包括文字的倾斜角度，字母i的点是否点上等。 为了构建我们自己的深度学习网络，我们开始编写基于音频、振幅的特征抽取器，我们定义了数十个特征用以区别声音与杂音。最终我们确定了85个特征。其中最重要的特征是音频与音强。抽完特征以后，我们用这85个特征对神经网络进行训练。我们的训练包含两个阶段： 一、通过无监督方法训练系统参数。二、用杂音数据对模型进行训练，这一步是有监督训练。我们用标记好的正例与负例对我们的系统进行测试与改善。具体流程如下：输入一个新数据，系统首先对数据进行特征提取，特征表示，对数据进行分类（是声音还是杂音），与正确结果进行比较。如果结果有误，对神经网络进行调参，使得我们的输出在下一次的训练中尽可能与正确结果相接近。 为了实现神经元与神经元之间的权重调整（调参），我们首先计算神经网络的输出误差，我们有一个误差函数，这个函数用来计算神经网络的输出结果误差。根据这个结果误差，我们对神经元之间的连接权重进行调整，以降低误差，这个训练过程需要重复上千次。最终实现一个较好的训练模型。 为了使得结果更好，我们在前面深度学习的基础上在构建一个深度学习模型，将第一个的输出做为第二模型的输入，对结果进行细粒度的调优，第一层的关注的是声音单元本身的特征，第二层检验的是声音单元‘邻居’的特征。那么为什么对周围声音进行检测也有用呢？道理很简单，第一层好比是一个正在销售的房屋，我们对它的各个房间进行查看，第二层就好比这个屋子的‘邻居’，我们对它的‘邻居’进行检验。换句话说，第二层为第一层提供了声音信号的上下文信息，有助于提高分类的准确率。例如，一个音节可能包含几个时域，背景噪音可能只在突然出现音节的起始阶段，后面就没有了。在这个例子中，上下文信息就可以使我们更好的从杂音中提取出声音。 在完成训练后，我们的深度学习分类器要比我们原先的分类器好很多，事实上，这是我们首次在算法上取得突破，使得我们的助听设备可以提高听觉受损人员的听力水平。为了测试我们的设备性能，我们对12名听障人员、12名听力正常人员进行测试，测试用例是成对出现的，第一次声音与杂音混在一起，第二次是经过我们神经网络处理过的声音。例如包含“It’s getting cold in here”和“They ate the lemon pie,”的句子有两种杂音，一种是嗡嗡声，另一种背景杂音是很多人在一起说话。这个嗡嗡声很像冰箱压缩机工作的声音，而另一种杂音是是我们生成的，是四男四女的说话声，以此来模仿鸡尾酒会的这一类背景噪音。 在对背景噪音进行处理后，无论是听觉受损人员还是听觉正常人员其听力理解能力均有大幅提升，在未经处理的声音中，听觉受损人员只可以听清29%的单词，但在处理过的声音中，他们可以理解84%的内容。在一些例子中，一开始只能听清10%，经过处理后就可以理解90%的内容了。在有嗡嗡杂音环境下，听觉受损人员的理解力从未经处理时的36%提升到82%。 对于听力正常的人，我们的系统同样有效，它可以使正常人在有杂音的环境下听到的更多，这就意味着将来的某一天，我们的系统可以帮助更多的人。在嗡嗡杂音下，未经处理，正常人只能听懂37%，处理后可以听懂80%，在鸡尾酒会的这一类背景噪音下，其听力理解力由42%提升到78%。 我们实验中最有意思的结果是，如果一个听力受损的人使用我们的助听设备，那么他的听力能否超过正常人？答案是肯定的。在嗡嗡环境下，听力受损的人（使用我们的助听设备）可以比正常人多听懂15%内容，在聚会噪音背景下可以多听懂20%。以这个结果来看，可以说我们的系统是最接近解决‘鸡尾酒会问题’的系统。 局限自然有，展望依然在 尽管如此，我们的算法仍有局限，在测试样例中，我们的背景噪声与我们训练用的背景噪声很相似。但实际情况却不是这样的，所以在实际应用中，系统需要快速学习周围环境中的各种背景噪声，并将其滤掉。例如通风系统的声音、房间内回音等。 我们购买了一个包含10000种杂音的数据集（这个数据集起初是为电影制造商准备的），用其来训练我们模型。今年，我们发现经过训练的程序可以处理以前从未遇到过的杂音了，并且去杂音效果得到了及具现实意义的提高（无论对听觉受损者还是听觉正常者），现在，由于得到了全国失聪及其他沟通障碍研究所（ National Institute on Deafness and Other Communication Disorders ）的支持，我们决定在更多环境下，使用更多的听障人员来测试我们的系统。 最后，我相信我们系统可以在性能更加强大的计算机上进行训练，并且移植到人听障人士身上，或者与智能手机进行配对使用。商家会周期性的对新数据进行训练，并发布新的版本以便让用户升级他们的助听设备，从而使其能够滤去新的杂音。我们已经申请了数个专利并且与多个合作伙伴进行了商业化应用。 使用这个方法，鸡尾酒会难题看起来不在是那么难以解决。我们坚信，只要有更多杂音数据、更加广泛的训练，我们终究可以解决这个难题。事实上，我认为我们现在处理声音的流程与小孩早期区分杂音与声音的过成是很类似的。都是在不断的重复中提升性能的。总之，经验越多，方法就变得越好。 雷锋网小编也设想到，如果一个有着听力障碍的热心读者参加了明年雷锋网举办的GAIR大会，在人头攒动的会场，他可能一直会被会展播放的背景音乐所打扰，无法专心与新结识的大牛们聊天。如果有了硬件相关的技术提升，那么想必会让活动的效果更好，而这也是科技尤其是人工智能所带给我们的福祉：让智能与未来伴随我们的生活，并使之变得更加美好。 via Deep Learning Reinvents the Hearing Aid","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Product","slug":"Product","permalink":"http://ipcreator.me/tags/Product/"}]},{"title":"TensorFlow极速入门","date":"2017-02-13T01:20:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Tensorflow/quick-learning-of-tensorflow/","text":"AI研习社 目前，深度学习已经广泛应用于各个领域，很多童鞋想要一探究竟，这里抛砖引玉的介绍下最火的深度学习开源框架tensorflow。 雷锋网按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于深度学习技术的探索，对新事物有着强烈的好奇心。 雷锋网(公众号：雷锋网)按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于深度学习技术的探索，对新事物有着强烈的好奇心。一、前言目前，深度学习已经广泛应用于各个领域，比如图像识别，图形定位与检测，语音识别，机器翻译等等，对于这个神奇的领域，很多童鞋想要一探究竟，这里抛砖引玉的简单介绍下最火的深度学习开源框架 tensorflow。本教程不是 cookbook，所以不会将所有的东西都事无巨细的讲到，所有的示例都将使用 python。那么本篇教程会讲到什么？首先是一些基础概念，包括计算图，graph 与 session，基础数据结构，Variable，placeholder 与 feed_dict 以及使用它们时需要注意的点。最后给出了在 tensorflow 中建立一个机器学习模型步骤，并用一个手写数字识别的例子进行演示。1、tensorflow是什么？tensorflow 是 google 开源的机器学习工具，在2015年11月其实现正式开源，开源协议Apache 2.0。下图是 query 词频时序图，从中可以看出 tensorflow 的火爆程度。2、 why tensorflow?Tensorflow 拥有易用的 python 接口，而且可以部署在一台或多台 cpu , gpu 上，兼容多个平台，包括但不限于 安卓/windows/linux 等等平台上，而且拥有 tensorboard这种可视化工具，可以使用 checkpoint 进行实验管理，得益于图计算，它可以进行自动微分计算，拥有庞大的社区，而且很多优秀的项目已经使用 tensorflow 进行开发了。3、 易用的tensorflow工具如果不想去研究 tensorflow 繁杂的API,仅想快速的实现些什么，可以使用其他高层工具。比如 tf.contrib.learn，tf.contrib.slim，Keras 等，它们都提供了高层封装。这里是 tflearn 的样例集（github链接 &nbsp;https://github.com/tflearn/tflearn/tree/master/examples）。4、 tensorflow安装目前 tensorflow 的安装已经十分方便，有兴趣可以参考官方文档 （https://www.tensorflow.org/get_started/os_setup）。二、 tensorflow基础实际上编写tensorflow可以总结为两步.（1）组装一个graph;（2）使用session去执行graph中的operation。因此我们从 graph 与 session 说起。1、 graph与session（1）计算图Tensorflow 是基于计算图的框架，因此理解 graph 与 session 显得尤为重要。不过在讲解 graph 与 session 之前首先介绍下什么是计算图。假设我们有这样一个需要计算的表达式。该表达式包括了两个加法与一个乘法，为了更好讲述引入中间变量c与d。由此该表达式可以表示为：当需要计算e时就需要计算c与d，而计算c就需要计算a与b，计算d需要计算b。这样就形成了依赖关系。这种有向无环图就叫做计算图，因为对于图中的每一个节点其微分都很容易得出，因此应用链式法则求得一个复杂的表达式的导数就成为可能，所以它会应用在类似tensorflow这种需要应用反向传播算法的框架中。（2）概念说明下面是 graph , session , operation , tensor 四个概念的简介。Tensor：类型化的多维数组，图的边；Operation:执行计算的单元，图的节点；Graph：一张有边与点的图，其表示了需要进行计算的任务；Session:称之为会话的上下文，用于执行图。Graph仅仅定义了所有 operation 与 tensor 流向，没有进行任何计算。而session根据 graph 的定义分配资源，计算 operation，得出结果。既然是图就会有点与边，在图计算中 operation 就是点而 tensor 就是边。Operation 可以是加减乘除等数学运算，也可以是各种各样的优化算法。每个 operation 都会有零个或多个输入，零个或多个输出。 tensor 就是其输入与输出，其可以表示一维二维多维向量或者常量。而且除了Variables指向的 tensor 外所有的 tensor 在流入下一个节点后都不再保存。（3）举例下面首先定义一个图（其实没有必要，tensorflow会默认定义一个），并做一些计算。import &nbsp;tensorflow as tfgraph &nbsp;= tf.Graph()with &nbsp;graph.as_default():&nbsp;&nbsp;&nbsp; foo = tf.Variable(3,name=&#39;foo&#39;)&nbsp;&nbsp;&nbsp; bar = tf.Variable(2,name=&#39;bar&#39;)&nbsp;&nbsp;&nbsp; result = foo + bar&nbsp;&nbsp;&nbsp; initialize = &nbsp;tf.global_variables_initializer()这段代码，首先会载入tensorflow，定义一个graph类，并在这张图上定义了foo与bar的两个变量，最后对这个值求和，并初始化所有变量。其中，Variable是定义变量并赋予初值。让我们看下result（下方代码）。后面是输出，可以看到并没有输出实际的结果，由此可见在定义图的时候其实没有进行任何实际的计算。print(result) &nbsp;#Tensor(&quot;add:0&quot;, shape=(), dtype=int32)下面定义一个session，并进行真正的计算。with &nbsp;tf.Session(graph=graph) as sess:&nbsp;&nbsp;&nbsp; sess.run(initialize)&nbsp;&nbsp;&nbsp; res = sess.run(result)&nbsp;&nbsp;&nbsp;print(res)&nbsp; # 5这段代码中，定义了session，并在session中执行了真正的初始化，并且求得result的值并打印出来。可以看到，在session中产生了真正的计算，得出值为5。下图是该graph在tensorboard中的显示。这张图整体是一个graph,其中foo,bar,add这些节点都是operation，而foo和bar与add连接边的就是tensor。当session运行result时，实际就是求得add这个operation流出的tensor值，那么add的所有上游节点都会进行计算，如果图中有非add上游节点（本例中没有）那么该节点将不会进行计算，这也是图计算的优势之一。2、数据结构Tensorflow的数据结构有着rank,shape,data types的概念，下面来分别讲解。（1）rankRank一般是指数据的维度，其与线性代数中的rank不是一个概念。其常用rank举例如下。（2）shapeShape指tensor每个维度数据的个数，可以用python的list/tuple表示。下图表示了rank,shape的关系。（3）data typeData type，是指单个数据的类型。常用DT_FLOAT，也就是32位的浮点数。下图表示了所有的types。3、 Variables（1）介绍当训练模型时，需要使用Variables保存与更新参数。Variables会保存在内存当中，所有tensor一旦拥有Variables的指向就不会在session中丢失。其必须明确的初始化而且可以通过Saver保存到磁盘上。Variables可以通过Variables初始化。weights &nbsp;= tf.Variable(tf.random_normal([784, 200], stddev=0.35),name=&quot;weights&quot;)biases &nbsp;= tf.Variable(tf.zeros([200]), name=&quot;biases&quot;)其中，tf.random_normal是随机生成一个正态分布的tensor，其shape是第一个参数，stddev是其标准差。tf.zeros是生成一个全零的tensor。之后将这个tensor的值赋值给Variable。（2）初始化实际在其初始化过程中做了很多的操作，比如初始化空间，赋初值（等价于tf.assign），并把Variable添加到graph中等操作。注意在计算前需要初始化所有的Variable。一般会在定义graph时定义global_variables_initializer，其会在session运算时初始化所有变量。直接调用global_variables_initializer会初始化所有的Variable，如果仅想初始化部分Variable可以调用tf.variables_initializer。Init_ab &nbsp;= tf.variables_initializer([a,b],name=”init_ab”)Variables可以通过eval显示其值，也可以通过assign进行赋值。Variables支持很多数学运算，具体可以参照官方文档 （https://www.tensorflow.org/api_docs/python/math_ops/）。（3）Variables与constant的区别值得注意的是Variables与constant的区别。Constant一般是常量，可以被赋值给Variables，constant保存在graph中，如果graph重复载入那么constant也会重复载入，其非常浪费资源，如非必要尽量不使用其保存大量数据。而Variables在每个session中都是单独保存的，甚至可以单独存在一个参数服务器上。可以通过代码观察到constant实际是保存在graph中，具体如下。const &nbsp;= tf.constant(1.0,name=&quot;constant&quot;)print(tf.get_default_graph().as_graph_def())这里第二行是打印出图的定义，其输出如下。node {&nbsp; name: &quot;constant&quot;&nbsp; op: &quot;Const&quot;&nbsp; attr {&nbsp;&nbsp;&nbsp; key: &quot;dtype&quot;&nbsp;&nbsp;&nbsp; value {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; type: DT_FLOAT&nbsp;&nbsp;&nbsp; }&nbsp; }&nbsp; attr {&nbsp;&nbsp;&nbsp; key: &quot;value&quot;&nbsp;&nbsp;&nbsp; value {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tensor {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dtype: DT_FLOAT&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tensor_shape {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float_val: 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }&nbsp;&nbsp;&nbsp; }&nbsp; }}versions {&nbsp; producer: 17}（4）命名另外一个值得注意的地方是尽量每一个变量都明确的命名，这样易于管理命令空间，而且在导入模型的时候不会造成不同模型之间的命名冲突，这样就可以在一张graph中容纳很多个模型。4、 placeholders与feed_dict当我们定义一张graph时，有时候并不知道需要计算的值，比如模型的输入数据，其只有在训练与预测时才会有值。这时就需要placeholder与feed_dict的帮助。定义一个placeholder，可以使用tf.placeholder(dtype,shape=None,name=None)函数。foo = &nbsp;tf.placeholder(tf.int32,shape=[1],name=&#39;foo&#39;)bar = tf.constant(2,name=&#39;bar&#39;)result = foo + barwith tf.Session() as sess:&nbsp;&nbsp;&nbsp; print(sess.run(result))在上面的代码中，会抛出错误（InvalidArgumentError），因为计算result需要foo的具体值，而在代码中并没有给出。这时候需要将实际值赋给foo。最后一行修改如下:print(sess.run(result,{foo:[3]}))其中最后的dict就是一个feed_dict，一般会使用python读入一些值后传入，当使用minbatch的情况下，每次输入的值都不同。三、mnist识别实例介绍了一些tensorflow基础后，我们用一个完整的例子将这些串起来。首先，需要下载数据集，mnist数据可以在Yann LeCun&#39;s website（&nbsp;http://yann.lecun.com/exdb/mnist/&nbsp;）下载到，也可以通过如下两行代码得到。from &nbsp;tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, &nbsp;one_hot=True)该数据集中一共有55000个样本，其中50000用于训练，5000用于验证。每个样本分为X与y两部分，其中X如下图所示，是2828的图像，在使用时需要拉伸成784维的向量。整体的X可以表示为。y为X真实的类别，其数据可以看做如下图的形式。因此，问题可以看成一个10分类的问题。而本次演示所使用的模型为逻辑回归，其可以表示为用图形可以表示为下图，具体原理这里不再阐述，更多细节参考&nbsp;该链接&nbsp;（http://tech.meituan.com/intro_to_logistic_regression.html）。那么 let&#39;s coding。当使用tensorflow进行graph构建时，大体可以分为五部分：&nbsp; &nbsp;1、 为 输入X与 输出y 定义placeholder；&nbsp;&nbsp;&nbsp;&nbsp;2、定义权重W；&nbsp;&nbsp;&nbsp;&nbsp;3、定义模型结构；&nbsp;&nbsp;&nbsp;&nbsp;4、定义损失函数；&nbsp;&nbsp;&nbsp;&nbsp;5、定义优化算法。首先导入需要的包，定义X与y的placeholder以及 W,b 的 Variables。其中None表示任意维度，一般是min-batch的 batch size。而 W 定义是 shape 为784,10，rank为2的Variable，b是shape为10，rank为1的Variable。import tensorflow as tfx = tf.placeholder(tf.float32, &nbsp;[None, 784])y_ = tf.placeholder(tf.float32, &nbsp;[None, 10])W = tf.Variable(tf.zeros([784, &nbsp;10]))b = tf.Variable(tf.zeros([10]))之后是定义模型。x与W矩阵乘法后与b求和，经过softmax得到y。y = tf.nn.softmax(tf.matmul(x, &nbsp;W) + b)求逻辑回归的损失函数，这里使用了cross entropy，其公式可以表示为：这里的 cross entropy 取了均值。定义了学习步长为0.5，使用了梯度下降算法（GradientDescentOptimizer）最小化损失函数。不要忘记初始化 Variables。cross_entropy=tf.reduce_mean(-tf.reducesum(ytf.log(y),reduction_indices=[1]))train_step = &nbsp;tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)init = &nbsp;tf.global_variables_initializer()最后，我们的 graph 至此定义完毕，下面就可以进行真正的计算，包括初始化变量，输入数据，并计算损失函数与利用优化算法更新参数。with tf.Session() as sess:&nbsp;&nbsp;&nbsp; sess.run(init)&nbsp;&nbsp;&nbsp; for i in range(1000):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; batch_xs, batch_ys = &nbsp;mnist.train.next_batch(100)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(train_step, feed_dict={x: &nbsp;batchxs, y: batch_ys})其中，迭代了1000次，每次输入了100个样本。mnist.train.next_batch 就是生成下一个 batch 的数据，这里知道它在干什么就可以。那么训练结果如何呢，需要进行评估。这里使用单纯的正确率，正确率是用取最大值索引是否相等的方式，因为正确的 label 最大值为1，而预测的 label 最大值为最大概率。correctprediction = &nbsp;tf.equal(tf.argmax(y,1), tf.argmax(y,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, &nbsp;tf.float32))print(sess.run(accuracy, &nbsp;feeddict={x: mnist.test.images, y: mnist.test.labels}))至此，我们开发了一个简单的手写数字识别模型。总结总结全文，我们首先介绍了 graph 与 session，并解释了基础数据结构，讲解了一些Variable需要注意的地方并介绍了 placeholders 与 feed_dict 。最终以一个手写数字识别的实例将这些点串起来，希望可以给想要入门的你一丢丢的帮助。雷锋网雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow基本用法","date":"2017-02-13T01:10:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Tensorflow/simple-understanding-of-tensorflow/","text":"yjango 目前主流的TensorFlow。用tensorflow这样工具的原因是：它允许我们用计算图（Computational Graphs）的方式建立网络。同时又可以非常方便的对网络进行操作。下面就是对计算图的直观讲解。 注：看完这部分内容的人，可以紧接着实现一个神经网络：代码演示LV1。 比喻说明：结构：而计算图所建立的只是一个网络框架。在编程时，并不会有任何实际值出现在框架中。所有权重和偏移都是框架中的一部分，初始时至少给定初始值才能形成框架。因此需要initialization初始化。 比喻：计算图就是一个管道。编写网络就是搭建一个管道结构。在投入实际使用前，不会有任何液体进入管道。而神经网络中的权重和偏移就是管道中的阀门，可以控制液体的流动强弱和方向。在神经网络的训练中，阀门会根据数据进行自我调节、更新。但是使用之前至少要给所有阀门一个初始的状态才能形成结构。用计算图又允许我们可以从任意一个节点处取出液体。 用法说明：请类比管道构建来理解计算图的用法 构造阶段（construction phase）：组装计算图（管道）计算图（graph）：要组装的结构。由许多操作组成。操作（ops）：接受（流入）零个或多个输入（液体），返回（流出）零个或多个输出。数据类型：主要分为张量（tensor）、变量（variable）和常量（constant）张量：多维array或list（管道中的液体）创建语句： tensor_name=tf.placeholder(type, shape, name)变量：在同一时刻对图中所有其他操作都保持静态的数据（管道中的阀门）创建语句： name_variable = tf.Variable(value, name)初始化语句： #个别变量init_op=variable.initializer() #所有变量init_op=tf.initialize_all_variables() #注意：init_op的类型是操作（ops），加载之前并不执行更新语句： update_op=tf.assign(variable to be updated, new_value)常量：无需初始化的变量创建语句：name_constant=tf.constant(value) 执行阶段（execution phase）：使用计算图（获取液体）会话：执行（launch）构建的计算图。可选择执行设备：单个电脑的CPU、GPU，或电脑分布式甚至手机。创建语句： #常规sess = tf.Session() #交互sess = tf.InteractiveSession() #交互方式可用tensor.eval()获取值，ops.run()执行操作 #关闭sess.close()执行操作：使用创建的会话执行操作执行语句：sess.run(op)送值（feed）：输入操作的输入值（输入液体）语句：sess.run([output], feed_dict={input1:value1, input2:value1}) 取值（fetch）：获取操作的输出值（得到液体） 语句**： #单值获取sess.run(one op) #多值获取sess.run([a list of ops])","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"这一年来，数据科学家都用了哪些算法玩转人工智能？","date":"2017-02-13T00:58:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Concepts/ai-and-algorithms/","text":"作者：刘志勇 在“数据为王”的今天，越来越多的人对数据科学产生了兴趣。数据科学家离不开算法的使用，那么，数据科学家最常用的算法，都是哪些呢？ 最近，著名的资料探勘信息网站KDnuggets策划了十大算法调查，这次调查对数据科学家常用的算法进行排名，并发现最“产业”和最“学术”的算法，还对这些算法在过去5年间（2011~2016）的变化，做了一番详细的介绍。 这次调查结果，是基于844名受访者投票整理出来。 KDnuggets总结出十大算法及其投票份额如下： 图1：数据科学家使用的十大算法和方法。 请参阅文末的所有算法和方法的完整列表。 从调查中得知，受访者平均使用8.1个算法，与2011年的一项类似调查相比大幅提高。 与用于数据分析/数据挖掘的2011年投票算法相比，我们注意到流行的算法仍然是 回归算法、聚类算法、决策树和可视化。相对来说最大的增长是以(pct2016/pct2011-1)测定的以下算法： Boosting，从2011年的23.5％至2016年的32.8％，同比增长40％ 文本挖掘，从2011年的从27.7％至2016年的35.9％，同比增长30％ 可视化，从2011年的从38.3％至2016年的48.7％，同比增长27％ 时间序列分析，从2011年的从29.6％至2016年的37.0％，同比增长25％ 异常/偏差检测，从2011年的从16.4％至2016年的19.5％，同比增长19％ 集合方法，从2011年的从28.3％至2016年的33.6％，同比增长19％ 支持向量机，从2011年的从28.6%至2016年的33.6%，同比增长18% 回归算法，从2011年的从57.9%至2016年的67.1%，同比增长16% 在2016年最受欢迎的新算法是： K-近邻算法（K-nearest neighbors，KNN），46%份额 主成分分析（Principal Commponent Analysis，PCA），43% 随机森林算法（Random Forests，RF），38% 最优化算法（Optimization），24% 神经网络-深度学习（Neural networks-Deep Learning），19% 奇异值矩阵分解（Singular Value Decomposition，SVD）， 16% 跌幅最大的算法分别为： 关联规则（Association rules），从2011年的28.6%至2016年的15.3%，同比下降47% 增量建模（Uplift modeling），从2011年的4.8%至2016年的3.1%，同比下降36% 因子分析（Factor Analysis），从2011年的18.6%至2016年的14.2%，同比下降24% 生存分析（Survival Analysis），从2011年的9.3%至2016年的7.9%，同比下降15% 下表显示了不同算法类型的用途：监督学习、无监督学习、元分析和其他算法类型。我们排除了NA（4.5%）和其他（3%）的算法。 表1：按行业类型的算法使用 我们注意到，几乎所有人都在使用监督学习算法。 政府和产业的数据科学家们比学生或学术界使用了更多的不同类型的算法，产业数据科学家更倾向使用元算法。 接下来，我们分析深度学习的十大算法按行业类型的使用。 表2：深度学习的十大算法按就业类型的使用 Table 2: Top 10 Algorithms + Deep Learning usage by Employment Type 为了使差异更为醒目，我们计算特定行业类型相关的平均算法使用量设计算法为Bias(Alg,Type)=Usage(Alg,Type)/Usage(Alg,All)-1。 图2：按行业的算法使用偏差 我们注意到产业界数据科学家更倾向使用回归算法、可视化、统计算法、随机森林算法和时间序列。政府/非盈利组织更倾向使用可视化、主成分分析和时间序列。学术研究人员更倾向使用主成分分析和深度学习。学生通常使用算法较少，但他们用的更多的是文本挖掘和深度学习。 接下来，我们看看代表整体KDnuggets访客的地区参与情况。 参与投票者的地区分布如下： 北美，40% 欧洲，32% 亚洲8% 拉美，5.0% 非洲/中东，3.4% 澳洲/新西兰，2.2% 与2011年的调查一样，我们将产业/政府合并为同一个组，将学术研究人员/学生合并为第二组，并计算算法对产业/ 政府的“亲切度”： N(Alg,Ind_Gov) / N(Alg,Aca_Stu) ——————————- - 1 N(Ind_Gov) / N(Aca_Stu) 亲切度为0的算法在产业/政府和学术研究人员/学生的使用情况相同。IG亲切度约稿表示该算法越“产业”，越低则表示越“学术”。 其中最“产业”的算法”是： 增量建模（Uplift modeling），2.01 异常检测（Anomaly Detection），1.61 生存分析（Survival Analysis），1.39 因子分析（Factor Analysis），0.83 时间序列（Time series/Sequences），0.69 关联规则（Association Rules），0.5 虽然增量建模又一次成为最“产业”的算法，但出乎意料的是它的使用率如此低：区区3.1%，在这次调查中，是使用率最低的算法。 最“学术”的算法是： 神经网络（Neural networks - regular），-0.35 朴素贝叶斯（Naive Bayes），-0.35 支持向量机（SVM），-0.24 深度学习（Deep Learning），-0.19 最大期望算法（EM），-0.17 下图显示了所有算法以及它们在产业界/学术界的亲切度： 图3：Kdnugets调查：数据科学家使用的流行算法：产业界vs学术界 下表包含了算法的详细信息，在2016年和2011年使用它们的受访者百分比调查，变化（％2016 /％2011 - 1）和行业亲切度如上所述。 表3：KDnuggets2016调查：数据科学家使用的算法 下表包含各个算法的详细信息： N: 根据使用度排名 Algorithm: 算法名称 Type：类型。S - 监督，U - 无监督，M - 元，Z - 其他， 2016 % used：2016年调查中使用该算法的受访者比例 2011 % used：2011年调查中使用该算法的受访者比例 %Change：变动 (%2016 / %2011 - 1) Industry Affinity：产业亲切度（上文已提到） 感谢杜小芳对本文的审校。 AI研究院 | AI学习方式越来越像人 却越来越不靠谱？ 【AI研究院 | 网易智能工作室倾力打造的人工智能行业专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月4日报道，据《连线》杂志报道，神经网络正风靡整个硅谷，无数的互联网服务中嵌入各种各样的人工智能（AI）。令人感到激动的是，最好的AI已经可以识别网络照片中的猫咪。但AI研究人员知道，神经网络依然存在许多缺陷。实际上，它们的缺陷非常多，以至于有些人怀疑这些模式识别系统是否是实现AI的可行、可靠方式。 神经网络可以通过分析大量数据来学习和了解任务，比如帮助Facebook进行面部识别、帮助微软进行翻译、帮助谷歌进行互联网搜索等。它们甚至已经开始帮助聊天机器人学习对话艺术。它们正成为无人驾驶汽车和其他自动化机器的重要组成部分。但是在没有大量经过仔细标注的数据的帮助下，它们就无法理解世界的意义，它们不适合执行任何任务。AI研究人员很想知道，为何神经网络在做出具体决定时受到如此多的限制？在很多情况下，它们实际上就是“黑盒子”。这种不透明会引发严重问题：如果无人驾驶汽车向着某人撞去，结果会如何？ 卡内基梅隆大学计算机学教授、帮助开发顶级扑克人工智能系统Libratus的托马斯·桑德霍尔姆（Tuomas Sandholm）说：“深度学习已经受到许多关注，它当之无愧。但是深度学习并不能给你提供任何保证。”这是真的，但也正是因为神经网络存在这些明显弱点，许多世界上最大的科技公司正在扩展它们的AI思维，从最近的招聘、收购、研究动向中作出判断，许多初创企业也正涌往相同的方向。 你可能认为这是贝叶斯算法(bayesian)的崛起，这类研究人员通常以科学方法研究AI，他们最初从假设开始，然后基于数据更新这个假设，而非像人经网络那样依赖数据去驱动结论。贝叶斯算法的研究人员寻找处理不确定性的方法，将新的证据输入到现有模型中，可以执行神经网络不擅长的工作。 与神经网络相似的是，贝叶斯算法也可以通过数据进行学习，但是这种机器学习可通过不同的方式进行。AI初创企业Gamalon创始人本·魏格达（Ben Vigoda）说：“令我们感兴趣的是自动化科学方法。”他的公司正通过所谓的“概率规划”计划推动这种趋势。 这再次提醒我们，神经网络的快速崛起也将生命注入到许多其他技术中，这些技术可帮助机器变得更加聪明，从强化学习到进化计算等。有许多方法，可以帮助机器进行学习。 神秘技术 2016年12月份，当加里·马库斯（Gary Marcus）将15人的初创企业卖给Uber时，他带着全新的AI到来。至少他是那样说的。他的公司叫做几何智能（Geometric Intelligence），一个小小的操作就能做出巨大改变。这位现年47岁的纽约大学心理学教授说，他与同事们正在开发能够从很少数据中学习任务的系统，这与人类十分相似，同时超越了深度神经网络的力量。 马库斯认为，小数据系统是建造机器必不可少的部分。这些机器可自主进行交谈，汽车也可以自己在公路上行驶。当Uber宣布收购Geometric Intelligence时，马库斯说：“在语言领域和无人驾驶汽车领域，你永远不会有足够数据像深度学习那样产生野蛮之力，这会产生许多问题。毕竟，你不能在繁忙的公路上撞车以便数据，用以预防将来发生车祸。你也不能购买它，它根本不存在。” 马库斯和他的联合创始人、剑桥大学信息工程学教授左斌·加拉玛尼(Zoubin Ghahramani)依然没有探讨他们正在开发的技术的具体细节。就像技术界常见的情况，特别是AI领域，这种保密性通常会催生“神秘感”。但是加拉玛尼是贝叶斯算法的支持者之一。他专门从事名为“高斯过程（Gaussian process）”的特殊统计模型，而这种模型在马库斯开发的技术中发挥了重要作用。 高斯过程 在某种层次上，高斯过程是寻找特定问题最优解决方案的方式。同时，它也是另一种名为贝叶斯优化的数学技术的基础。 到目前为止，高斯过程已经帮助网站确定应该显示哪些广告，以及它们的网页应该如何排版。Uber已经招募擅长高斯过程的专家，改善其拼车服务。在谷歌，高斯过程帮助控制该公司的高空联网气球。 从根本上说，高斯过程是确定不确定性的最佳方式。 爱丁堡大学AI研究员克里斯·威廉姆斯（Chris Williams）说：“知道你不知道的事情是件好事，而犯下自信的错误是你能做到的最糟糕的事情。” 在2015年被Twitter收购的初创企业Whetlab，该技术提供了设计神经网络的更好方式。设计神经网络是个充满错误的实验过程，你没有编写软件那么多的编码，以便于从海量数据中学习。这是个困难、耗时的过程，但高斯过程和贝叶斯优化可帮助自动化这些任务。正如WhetLab创始人、哈佛大学计算机科学家赖安·亚当斯（Ryan Adams）所说，他的公司使用机器学习技术改善机器学习技术。神经网络可能会遇到“信心错误”问题，在识别不确定性方面，这种优化可帮助处理问题。亚当斯已经离开Twitter，加盟了谷歌AI团队Google Brain。 有些研究人员还认为，小数据驱动的高斯过程在推动AI自动化方面可能会发挥关键作用。AI初创企业Prowler首席执行官维沙尔·查特拉斯（Vishal Chatrath）说：“为了开发真正的自动化代理人，它必须能够非常迅速地适应环境。这意味着，它需要以高效的方式学习。高斯过程可轻松胜任。与神经网络不同，它们没有‘黑盒子’问题的负担。如果发生意外，你可以追踪到源头。” 不要恐慌 在Prowler，查特拉斯已经招募了3名技术专家。之所以将总部选在剑桥，因为这里有许多人是高斯过程及其相关技术的专家。这家公司正开发新的AI系统，它可以学习浏览大型多人游戏和其他数字数节。这是个复杂的过程，但他们希望将来AI系统能出现在真实世界中 与此同时，亚马逊也招募了擅长贝叶斯算法技术的AI研究人员，即舍费尔德大学计算机科学家尼尔·劳伦斯（Neil Lawrence）。劳伦斯最近在帖文中指出：“无需感到惊慌，通过使用我们的数学工具可以探索新一轮的深度学习方法。我们可以保证，它们大多数都是无害的。”（小小） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 识别假新闻与NLP有何不同 为何连FB都搞不定？ 【网易智能讯 1月16日消息】假新闻成为新闻头条已达几个月，现在一组研究人员试图运用AI技术来解决假新闻难题。 卡内基梅隆大学副教授迪恩·波美勒（Dean Pomerleau）发起一项挑战，声称如果有人开发出能准确发现假新闻的AI算法，他将奖赏研究者2000美元。 与此同时一些硅谷大公司——比如谷歌和Facebook——也在解决努力解决这个问题。开发AI算法来解决假新闻。 但识别假新闻与其他AI算法的成功（比如图像识别和自然语言处理）不同，假新闻千变万化，本质上的多变性决定其难以抓取模式特征。 制服假新闻要求AI系统多一层判断，而这是今日之AI还不具备的能力。 除了这个问题，竞争或许更能见证AI的进化。未来研究人员能够开发出比今日更优秀的工具。 此外他还更详细地介绍了研究人员在解决假新闻过程中将要面临的挑战和机遇，以及他们的成败如何反映当今AI的发展状态。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://ipcreator.me/tags/Algorithm/"}]},{"title":"避免炒作，如何寻找有价值的人工智能初创企业？","date":"2017-02-13T00:58:06.000Z","path":"2017/02/13/SmartAI/BusinessAI/how-to-find-ai-start-up-firm/","text":"作者：网易AI研究院 据国外媒体报道，毫无疑问现在人工智能概念已经牢牢抓住了公众想象力和媒体的眼球，也带来了大量的业内投资和收购。在新一轮的炒作周期中，投资者该如何辨别相关的人工智能到底是炒作还是真正的现实，这将是一个挑战。 日前，科技网站venturebeat采访了CRV, IA Ventures, Two Sigma等知名投资公司中经验丰富的风险投资人，从而深入探究这些成功的投资者是如何评估一家人工智能初创公司的。如果你也是一名人工智能相关创业公司的创始人，在投资者面前需要回答好以下的关键问题： 人工智能是公司的核心价值所在吗？ 投资公司Qualcomm Ventures的风险投资人Varun Jain坦言，“很多陷入资金困境的公司都会将自己包装成人工智能企业。”Varun Jain列举了从人工智能路由器到人工智能榨汁机等产品和设备。 Varun Jain解释称，在很多情况下，公司所宣传的人工智能仅仅是一个附加功能，而不是公司的核心价值。他指出，“传统的WiFi路由器可以使用人工智能技术来检测网络中的异常数据，但路由器的功能并不会有实质性的改变。” 相比之下，Qualcomm Ventures投资了Clarifai和Cruise Automation等真正的人工智能初创企业，而Cruise Automation已经被通用收购。Cruise Automation通过人工智能技术为自动驾驶汽车供电，而Clarifai则是利用先进的深度学习和计算机视觉技术来识别图像和视频中的特定物体。 技术团队有多可靠？ CRV公司的风险投资人Max Gazor指出，“具备先进人工智能技术的公司往往拥有顶尖的技术人才，他们或者来自业内先进研究实验室，或是来自诸如Google Brain或Facebook人工智能团队等知名行业组织。” CRV对技术的追求直接体现在他们的投资行为中，他们投资的公司创始人普遍具有非凡的技术经验。初创企业Rethink Robotics创始人Rod Brooks是麻省理工学院人工智能实验室的创始主管，也是著名机器人公司iRobot的创始人。而Jibo的Cynthia Breazeal也曾在麻省理工大学媒体实验室成立过机器人小组，是一名世界知名的社交机器人专家。Pullstring公司的创始人Oren Jacob也是如此，他曾是皮克斯的首席技术官，自公司成立初期就与史蒂夫乔布斯共事。 而投资公司DCM Capital的创始人David Cheng则指出，“在整个行业生命周期的这一特定阶段，一个公司拥有一定数量的人工智能专家就能够获得开发技术的必要经验，从而开发真正的创新解决方案。 如果一个团队声称他们的产品使用了领先的人工智能技术却没有相应的团队，那么我们对此将持怀疑态度。” 能够有效解决客户的实际问题吗？ 投资公司GE Ventures投资人Michael Dolbec指出，“就我个人而言，一个公司若是仅仅对人工智能夸夸其谈，而毫不涉及客户问题，那我就没有什么兴趣。我们投资的是宝贵的技术成果，而不是科学实验项目。” 每一位投资者对此都表示认同。 IA Ventures的Brad Gillespie补充称，“如果让我在二者中选择其一时，那么一个公司的业务专业知识将胜过其机器学习专业技能。”IA Ventures曾投资了Vectra Networks，这是一家由经验丰富业内专家领导的网络安全公司，专注于为客户解决重要问题，为安全分析师最大限度提高可用性。而Vectra Networks的竞争对手不断强调他们机器学习技术的复杂性，但客户的反应是“这些家伙很聪明，但他们并不理解我的业务是什么。他们的产品很花哨，但我并不明白它到底是什么。” 有效解决客户的业务痛点需要创始团队能够超越狭隘的技术方法，拥有解决特定业务的能力。投资公司Two Sigma Ventures的Colin Beirne指出，“当然，解决当今大多数困难问题需要不同技术的整合，而在特定业务领域使用人工智能能够在一定程度上降低学习理解的复杂性。” 是否有相关的，自有或可扩展的数据源？ 投资公司Qualcomm Ventures的Jain总习惯于这样问创始人，“你是如何获取数据的？你是依托大公司提供的数据，还是独立获取数据？”当然这两种方法都是可行的，但投资人更倾向于创业公司能够独立获取数据。 传统上。自动驾驶汽车会在郊区等封闭环境中进行测试。而Qualcomm所投资的Cruise Automation则通过在开放城市环境中操作测试车辆，整合人工干预的因素，从而获取更多驾驶数据。同样，Qualcomm所投资的Clarifai通过应用程序能够获取更多的数据，通过此也能够处理更多的业务数据。 投资者除了对数据源的独特性和合理性有要求，此外人工智能数据还必须要与其面对的问题密切相关。投资公司Battery Ventures的Dharmesh Thakker指出，“新一代人工智能技术往往取决于获取数据的复杂程度。诸如图像、音视频等非结构化数据处理要比普通文本困难的多。”在投资决策中，Dharmesh Thakker还会考虑目标公司处理静态数据和快速移动物体数据的能力。诸如自动驾驶汽车获取的实时图像等快速移动物体数据处理算法通常会复杂很多。 最后，创始团队还需要 证实其有根据自有数据不断改进产品性能的能力。Qualcomm的Jain会定期考察团队是否有“快速处理数据并不断优化的能力，从而使系统更加健壮。” 开发独有技术还是依靠开源产品 投资公司Verizon Ventures的投资人Suresh Madhavan指出，相比于开发专有技术，依托开源框架往往就像是一种赠品，“开源的确能够让你分析解决一些表面问题，但无助于从根本上解决有难度的业务问题。” DCM Ventures的Cheng也同意这一点。DCM的投资团队背后拥有一个由行业顾问和技术专家组成的强大网络。“（这些专家）帮我们审查团队技术、数据架构方式，并能够确定创业团队进行数据收集、存储、解析的根本方法。他们也帮助我们擦亮眼睛，找出滥竽充数者。” 产品是否有粘性？ Sumant Mandal是投资公司March Capital的合伙人，也是The Hive的共同创始人，后者是一家专注于人工智能初创企业的孵化器。Mandal坦言，“对于人工智能初创企业来说， 如果效率不能提高5到10倍，那么就很难打入市场，从而为投资者带来价值。”Mandal建议初创企业需要考虑客户的收益。比如要将人工智能用于改进招聘流程，Mandal就建议初创团队要问自己，“如果我能够将相应效率提高5倍，那么能否让客户从雇员身上获得百倍收益？” 此外，Mandal还指出，价值提升必须要以客户可见的方式提供给客户，譬如以仪表盘或是真正有价值的情报等形式展现出来。 Mandal警告称，虽然人工智能在网络安全领域的应用已经很多，但数据和相关人才的缺乏，导致“安全分析师并不需要过多的警报”。 而即便有一个较为理想的产品，仅仅为客户提供单一的解决方案也不是一个可行的商业模式。Woodside Capital的Kartik Gada建议创业公司要寻求收益以及客户的多元化。“你的收入是否稳健？是否常态化？你的客户是否需要相同或更多的解决方案？” 创业团队是否全面？ 最后一点，投资者倾向于寻求那些能够解决人工智能业务的多样化团队。投资公司Monsanto Growth Ventures的Kiersten Stead解释称，“多样化意味着团队包括业内专家、商业领袖以及销售精英，而不仅仅是工程技术人员。” 但是，Stead观察到，很多创业团队，特别是那些仅仅由人工智能研究人员组成的技术团队，并没有特定行业的相关经验，更容易失败。在农业技术开发和遗传育种方面尤为如此。 她强调，“人工智能技术团队在销售上有短板，反之亦然。我们会寻找行业经验丰富的人工智能企业创始人，他们往往有完整成熟的职业生涯，可与各类人组成一个多样化的团队。”人工智能企业往往会忽视销售和营销，但这对于成功非常重要。 投资公司Woodside Capital的Gada也警告称，“很多人工智能初创企业犯下的最大错误就是完全无视营销的重要性。很多客户根本不知道他们需要这些产品。”（晗冰） AI研究院 | 企业做人工智能转型有四大关键要素 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月10日消息，在很多行业我们都已接近人工智能技术发展的临界点，包括自动驾驶汽车、蜂巢无人机、自动售货等。如今一个公司无论规模大小如何，都必须了解人工智能将怎样影响、甚至消灭某个行业，以及学会利用人工智能和机器学习（ML）。 对于企业来说这是一个至关重要的选择——是投身到人工智能领域还是保持现状等着被淘汰，前者可以更有效地帮助企业实现商业目标。人工智能—机器学习将令我们的日常生活更加美好高效，把现有工作提升到更加精确、有效的水平。 像优步、谷歌和Facebook这样的科技创新公司，通过收购和内部组织的转型，在人工智能领域进行了大胆尝试，使它成为一项战略重点。在2017年达沃斯论坛上，世界各国领导人探讨了人工智能对就业的影响，以及哪些行业适合应用这项技术。 事实上，根据互联网数据中心（IDC）的数据显示，到2020年，企业在人工智能方面的投入将从2016年的80亿美元飙升至470亿美元。另外，到2019年，将会有超过1.1亿个安装了嵌入式智能助手的设备走进美国家庭。 Intuit公司的人工智能转型始于4年前，当时业内都在探讨两个问题：金融软件的未来是什么；我们在帮助客户方面扮演怎样的角色。人工智能的趋势在当时是很明显的，包括工作的个性化、自动化、增强和速度等，这些都需要软件来进行辅助。近年来，随着人工智能技术的进步，我们对它的看法也作出了改变。 现在我们将人工智能看作一种为用户提供方便的技术。我们预计人工智能将创造新技术，例如以一种曾经无法想象的高科技方法为消费者处理税务、为小型企业完成账目记录等。但要实现这一目标并非易事。Intuit公司拥有30多种人工智能和机器学习模型，可以在实时体验中接触客户，而且我们还在不断作出新的尝试。我们在实验和成果中不断学习、发展和改进技术。 如果你的公司致力于通过人工智能打造能够满足消费者需求的产品和服务，那么这里有几个关键的问题需要考虑。 1.重视数据 每一家公司的人工智能探索之旅都从数据开始。数据令机器学习和人工智能更强大。如果你一直在考虑如何利用数据，那么现在就可以开始制定和实施计划了。 在Intuit，我们几年前就已经转向了对数据的关注。我们在与业务部门同事进行沟通后制定了技术路线，充分了解了客户需求、行业趋势以及数据能够带来的客户利益。我们的Intuit Analytics Cloud云分析系统打破了一些障碍，让我们能够以更全面地认识产品产生的海量数据。在拥有人工智能或机器学习模型之前，我们就开始专注于数据分析和个性化的基础性工作。可靠、快速、准确的数据是人工智能—机器学习发展的催化剂。 2.展望未来 设想公司的未来是很重要的，同时也要观察人工智能将如何令你更加强大，或者改变你对研发工作的想法。我们在Intuit进行了一场活动，会见了各种各样的组织和个人，包括大学的学者专家、创业公司、风投公司等，探讨了人工智能和机器学习的未来蓝图，以及Intuit公司将如何适应这一转变。规模较小的公司同样可以在相应的资源范围内做出创新。 3.转变心态 在开始阶段向业务部门和产品负责人解释投资人工智能的益处，可能是一件很有挑战性的事情。重要的是每个季度的客户利益需要体现在商业价值上，而不是单纯研究数据。例如，Intuit的税务分析系统就分析了3000万客户的纳税申报表，对分项扣除还是统一扣除作出相应建议，这可以节省40%的税收工作准备时间。这样一个甚至非数据专家都能理解的切实的商业成果。可以说，人工智能—机器学习是一段探索之旅。通过实际产生的影响来预估潜在的成果，这是很重要的。 4.成立团队，选择项目 要在企业中开始发展人工智能，先选择一个容易解决的业务问题，组件一支跨职能员工团队，包括数据科学家、工程师和质量监管人员，同时要注意及时更新团队。在团队中建立起能够理解实验价值的文化。珍惜从人工智能应用中得来的知识。另外，你的团队还应同时拥有专业知识和实战经验。千万不要认为只需要聘请专家。同时，在亟待解决的问题上还需要保持与其他行业科学家的互动，比如其他领域的博士等，他们天生具有好奇心，能够理解科学原理，并且有一套不同的解决方案。真正的人工智能—机器学习可以在应用数据科学方面带来重大成果。 不要低估了它的重要性，同时也要改变心态。 我们才刚刚到达人工智能和机器学习的起步阶段。在公司初创之时紧跟最先进的技术，将有助于你在未来发展中处于优势地位。 （来源/VentureBeat 翻译/机器小易 审校/小ka） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 人工智能的迅速崛起需要警惕这四大风险 【网易智能讯 1月21日消息】大家可以想象一下，一名营销主管深夜翻看公司的幻灯片，该公司承诺利用人工智能（AI）自动化他的评分过程、优化他的广告开支方案、帮助增加他的营销开支回报率，他想要知道，哪里可能出现问题？ 的确有可能出现问题。尽管公司使用AI会让营销人员的工作变得更简单，但我们必须承认，AI的承诺往往言过其实。AI带来的好处是显而易见的，但也存在巨大风险。即使你找到最好的AI，并将其应用到你的营销技术堆栈中，依然存在影响你成功部署AI的风险。我并不担心这些风险，也不想将它们藏起来，我认为最好是直接面对它们，直至最终解决它们。 AI主要存在四大类危险： AI危险一：害怕失去工作这是最容易理解的AI危险，同时也是最容易解决的。人们经常害怕AI，因为他们担心AI会让人类变得多余，最终被拥有机器大脑的AI取代我们独特的技能。对于某些工作来说，这可能是真的。但我认为，AI带来的实际危险可能比人类预想的更低。AI还不够先进，也无法全面取代营销专家。如果营销人员学会有效地使用AI，它们反而会增强人类能力。也就是说，为了促使人们购买AI支持的技术，我们首先需要平抚人们对AI的恐惧。 AI危险二：错位的激励技术传道者有时候会深入企业内部，并利用让人惊叹的创意，阐述他们的产品如何改变每个人。但是有了AI和许多企业技术，这些热情常常会撞墙，因为这些墙将各个部门隔离开。事实证明，公司中拥有大量数据的人，往往不会与其他利益相关者分享数据。无论是出于隐私担忧、部门政策、个人冲突亦或是简单的流程偏差，比如障碍往往可能导致雄心勃勃的AI项目被搁置。 为此，到目前为止，两类公司在部署AI时取得最大成功，一类是初创企业（公司规模较小，刚刚创建还没有僵化思维），一类是像谷歌和Facebook这样的大科技公司（其全部生命线都基于对数据的利用）。介于这两类极端公司之间的其他企业，几乎包括世界上所有公司，部署AI都会遇到更大阻碍。想要利用AI提高效率的营销人员需要意识到部门和监管问题，这些问题可能影响到他们。此外，数据价值链上的所有玩家都需要保持一致。 AI危险三：不可预测性这可能是AI固有的最大危险。所有AI项目都是不可预测的，因为它们正被用于解决未知问题。与传统软件开发不同，目前还没有标准的工程方法，可以通过分步获得可预知的AI结果。在这种情况下，将AI应用到营销数据中就像纯粹的科幻。我们不知道特定的数据集是否能解决特定的问题。就像无法预测科学实验的所有结果那样，AI也很难预测结果。这是有关软件开发的全新思维方式，但对任何营销领域或没有AI经验的人来说，这将是个巨大挑战。 AI危险四：人才匮乏这是AI带来的最后危险，阻碍你的团队引入足够的人才。不幸的是，当前AI领域存在巨大的技术鸿沟。AI领域的绝大多数人才都没有真正处理大规模行业数据的经验。而真正的专家还很少，最新统计显示，数据科学家的职位空缺高达1.6万个。这意味着，找到你需要的专业人士，并让他们帮助部署和执行AI驱动的营销计划非常困难。 由于存在这些风险，你可以看到截止到目前许多AI实验都以失败告终。举例来说，麦肯锡最近做了一项研究，对石油和天然气钻探作业决策中的数据进行实时分析。麦肯锡研究的1家公司在离岸钻井仪器方面投入巨资，并通过RFID标签和内嵌传感器收集到大量数据。不幸的是，他们收集的数据中只有40%能传回到陆地数据中心，只有1%能真正进入数据库中，不到1%能被用于终端用户的产品中。最终，这些数据没有为人们的决策提供任何帮助。 不幸的是，你可能发现同样大的阻力。在使用AI过程中，你会遇到强烈的文化阻碍。许多人不相信机器做出的决定，直到机器算法有机会证明自己的决定。营销高管们部署AI面对的挑战是，需要确保所有相关利益者支持他们。确保人们受到相关训练，确保他们对可能结果产生现实期待，并获得正确的激励奖励。 只有做到这些，你才能开始意识到AI革命为营销领域带来的惊人好处。（小小）","comments":true,"categories":[{"name":"理财","slug":"理财","permalink":"http://ipcreator.me/categories/理财/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Business","slug":"Business","permalink":"http://ipcreator.me/tags/Business/"}]},{"title":"Gentlest Tensorflow","date":"2017-02-13T00:52:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Tensorflow/gentle-understanding-of-tensorflow/","text":"作者：Neth Six GoalTensorflow (TF) is Google’s attempt to put the power of Deep Learning into the hands of developers around the world. It comes with a beginner &amp; an advanced tutorial, as well as a course on Udacity. However, the materials attempt to introduce both ML and TF concurrently to solve a multi-feature problem — character recognition, which albeit interesting, unnecessarily convolutes understanding. Gentlest Tensorflow attempts to overcome that by showing how to do linear regression for a single feature problem, and expand from there. Cheatsheetcheatsheets/tensorflow_cheatsheet_1.pngLinear regression: single feature, single scalar outcomeLinear regression: multi-feature, single scalar outcomeLogistic regression: multi-feature, multi-class outcomeCode All the code are in /code directory:linear_regression_one_feature.py ML with linear regression for a single feature Example: predict house price from house size (single feature) linear_regression_one_feature_with_tensorboard.py Add visualization for ‘ML for single feature’ with Tensorboard Use tf.scalar_summary, tf.histogram_summary to collect data for variables that we want to visualize Use scope to collapse TF network graph in to expandable/collapsible black boxes to faciliate visualization linear_regression_one_feature_using_mini_batch_with_tensorboard.py Perform ‘stochastic/mini-batch/batch’ Gradient Descent with TF The CUSTOMIZABLE section contains all the configurations that we can tweak, e.g., batch size, etc. linear_regression_multi_feature_using_mini_batch_without_matrix_with_tensorboard.py ML with linear regrssion for 2 features without using ‘matrix’ Create additional tf.Variable, tf.placeholder for each feature IMPORTANT: This is a messy way to do ML with multiple features. This is provided as an explanation of multi-feature concept. linear_regression_multi_feature_using_mini_batch_with_tensorboard.py ML with linear regrssion for 2 features Expanding existing W (tf.Variable) in matrix ‘height’, and existing x (tf.placeholder) in matrix ‘width’ to accomodate each feature","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"深度 | 机器学习敲门砖:任何人都能看懂的TensorFlow介绍","date":"2017-02-13T00:51:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Tensorflow/good-understanding-of-tensorflow/","text":"作者：Soon Hin Khor 原文：The Gentlest Introduction to Tensorflow – Part 1The Gentlest Introduction to Tensorflow – Part 2 机器之心编译 参与：Rick、吴攀、李亚洲 本文是日本东京 TensorFlow 聚会联合组织者 Hin Khor 所写的 TensorFlow 系列介绍文章的前两部分，自称给出了关于 TensorFlow 的 gentlest 的介绍。这两部分谈到单一特征问题的线性回归问题以及训练（training）的含义，机器之心将继续关注本系列文章的后续更新。 第一部分 引言 我们要解决的是一个过于简单且不现实的问题，但其好的一面是便于我们了解机器学习和 TensorFlow 的概念。我们要预测一个基于单一特征（房间面积/平方米）的单标量输出（房价/美元）。这样做消除了处理多维数据的需要，使我们能够在 TensorFlow 中只专注于确定、实现以及训练模型。 机器学习简介 我们从一组收集到的数据点开始（见下图），每个数据点代表两个值之间的关系——输出（房价）与影响因素（房子面积）。 然而我们无法预测没有数据点的特征的值（见上图）。 我们可以使用机器学习来挖掘它们之间的关系（见下图的「最佳拟合预测曲线」），即给定一个不属于数据点的特征值，我们可以准确地预测出输出（特征值和预测线的交点）。 步骤一：选择一个模型 1.模型种类 为了使用机器学习来做预测，我们需要选择一个能够拟合收集到的数据的最佳模型。 我们可以选择一个线性（直线）模型，并通过改变其陡度/梯度和位置对其进行调整，从而匹配数据点。 我们也可以选择一个指数（曲线）模型，并通过改变其曲率（curvature）和位置对其进行调整，从而匹配同一数据点集。 2.成本函数 为了比较哪个模型拟合得更严密，数学上我们将最佳拟合定义为一个需要被最小化的成本函数。 成本函数的一个简单样例是每个数据点所代表的实际输出与预测输出之间偏差的绝对值总和（实际结果到最佳拟合曲线的垂直投影）。用图表表示，成本函数被描述为下表中蓝色线段的长度和。 注意：更准确地说，成本函数往往是实际输出和预测输出之间的方差，因为差值有时是负数；这也称为最小二乘法。 3.线性模型简介 秉持简洁精神，我们将使用线性模型来对数据点进行建模。线性模型的数学表示是： y = W.x + b Where: x: house size, in sqm y: predicted house price, in $ 为了调整模型来更好地拟合数据点，我们可以这样做： 调整 W 来改变线性模型的梯度 调整 b 来改变线性模型的位置 通过使用许多个 W、b 的值，最终我们可以找到一个最佳拟合线性模型，能够将成本函数降到最小。 除了随机尝试不同的值，有没有一个更好的方法来快速找到 W、b 的值？ 4.梯度下降 如果你试图从山上下降到最低点，你的视角就是这个样子。 下降趋势并不明显！其最佳方式是执行梯度下降： 在当前位置以最陡的下降梯度确定方向 在该方向上采取步长 X 重复 &amp; 刷新；这就是训练过程 最小化成本函数是类似的，因为成本函数就像是起伏的山，我们想要找到其中的最低点，我们可以通过梯度下降类似地实现。 现在我们有了线性模型、成本函数和梯度下降的概念，可以开始使用 TensorFlow 了。 步骤二：在TensorFlow 中建立模型 1.TensorFlow 中的线性模型 TensorFlow 的2个基本组件是： 占位符（Placeholder）：表示执行梯度下降时将实际数据值输入到模型中的一个入口点。例如房子面积 (x) 和房价 (y_)。 变量：表示我们试图寻找的能够使成本函数降到最小的「good」值的变量，例如 W 和 b。 然后 TensorFlow 中的线性模型 (y = W.x + b) 就是： 2.TensorFlow 中的成本函数 与将数据点的实际房价 (y_) 输入模型类似，我们创建一个占位符。 成本函数的最小方差就是： 3.数据 由于没有房价(y_) 和房子面积 (x) 的实际数据点，我们就生成它们。 简单起见，我们将房价 (ys) 设置成永远是房子面积 (xs) 的 2 倍。 4.梯度下降 有了线性模型、成本函数和数据，我们就可以开始执行梯度下降从而最小化代价函数，以获得 W、b 的「good」值。 0.00001 是我们每次进行训练时在最陡的梯度方向上所采取的「步」长；它也被称作学习率（learning rate）。 步骤三：训练模型 训练包含以预先确定好的次数执行梯度下降，或者是直到成本函数低于某个预先确定的临界值为止。 1.TensorFlow 的怪异 所有变量都需要在训练开始时进行初始化，否则它们可能会带有之前执行过程中的残余值。 2.TensorFlow 会话 虽然 TensorFlow 是一个 Python 库，Python 是一种解释性的语言，但是默认情况下不把 TensorFlow 运算用作解释性能的原因，因此不执行上面的 init 。相反 TensorFlow 是在一个会话中进行；创建一个会话 (sess) 然后使用 sess.run() 去执行。 类似地我们在一个循环中调用 withinsess.run() 来执行上面的 trainstep。 你需要将由 x, y 所组成的实际数据输入再提供给输入，因为 TensorFlow 将 trainstep 分解为它的从属项： 从属项的底部是占位符 x，y；而且正如我们之前提到的，tf.placeholders 是用来表示所要提供的实际数据点值房价 (y_) 和房子面积 (x) 的位置。 结果 循环中的 print 语句将显示 TensorFlow 如何在每次迭代中学习 W 和 b 的「good」值。 小结 我们已经以最简单的形式学习了机器学习；从一个单一特征预测结果。（为简单起见）我们选择了一个线性模型来拟合我们的数据点，定义一个成本函数来表示最佳拟合，并通过反复调整其梯度变量 W 与位置变量 b 来训练我们的模型，使成本函数降到最小。 第二部分 简单回顾 在上一部分，我们使用 TensorFlow 构建并学习了一个带有单一特征的线性回归模型——给定一个特征值（房屋面积/平方米），我们可以预测输出（房价/美元）。 下面是一些总结： 我们有一些房屋面积和房价的数据（灰色点） 我们使用线性回归对这些数据进行了建模（红色虚线） 我们通过训练该线性回归模型的 W（权重）和 b（偏置）找到了最小化「成本」（竖直蓝色实线的长度总和，这些蓝线代表了预测和实际输出之间的差异）的「最好」模型 给定任意房屋面积，我们可以使用该线性模型预测房价（带箭头的蓝色虚线） 一张图解释线性回归 在机器学习文献中，我们常常看到「训练（training）」这个词。在这一部分，我们将在 TensorFlow 中理解「训练」的含义。 线性回归建模 Linear Model (in TF notation): y = tf.matmul(x,W) + b 线性回归的目标是寻找 W 和 b，这样对于给定的任意特征值 x，我们可以通过将 W、b 和 x 的值代入到模型中得到预测 y。 但是为了找到能准确做出预测的 W 和 b 的值，我们需要使用可用的数据（许多实际特征 x 和实际输出 y_ 的配对，注意下划线）来「训练」该模型。 解释「训练」 为了找到最佳的 W 和 b 值，我们可以从任意的 W 和 b 值开始。我们也需要定义一个成本函数，该函数可以衡量对于一个给定特征值 x 预测输出 y 和实际输出 y_ 之间差异。为了简单起见，我们使用最简单的最小均方误差（MSE：minimum squared error）作为我们的成本函数。 Cost function (in TF notation): tf.reducemean(tf.square(y - y)) 通过最小化成本函数，我们可以得到很好的 W 和 b 值。 我们的训练代码实际上非常简单，并且用 [A, B, C, D] 进行了注释，后面我们还会谈到这些代码。完整代码请访问：https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py # … (省略) 变量/常量声明 … # [A] TensorFlow图 y = tf.matmul(x,W) + b cost = tf.reducemean(tf.square(y-y)) # [B] 用固定「学习率（learn_rate）」训练 learn_rate = 0.1 train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost) for i in range(steps): # [C] 准备数据点 # … (省略) 准备作为x和y的数据点的代码 … # [D] 在每个步骤/epoch将数据送入’trainstep’ feed = { x: xs, y: ys } sess.run(train_step, feed_dict=feed) 我们的线性模型和成本函数[A]可以表示成下面的 TensorFlow 图： 创造一个带有模型和成本函数的 TensorFlow 图，并使用一些值初始化 W 和 b 接下来，我们选择一个数据点 (x, y_) [C]，然后将其送入[D] TensorFlow 图，从而得到预测 y 和相应的成本。 使用单个数据点计算预测 y 和成本 为了得到更好的 W 和 b，我们使用TensorFlow 的 tf.train.GradientDescentOptimizer [B]执行梯度下降以降低成本。用非技术的术语来说：给定当前成本，并基于成本岁其它变量（即 W 和 b）的变化方式，优化器（optimizer）将对 W 和 b 执行一些小调整（递增或递减）以使我们的预测更好地契合那个单个数据点。 基于当前的成本，决定如何调整 W 和 b 以提升预测 y 和降低成本 训练周期中的最后步骤是在调整 W 和 b 对它们进行更新。注意这里的「周期」用机器学习的术语来说是「epoch」。 在下一训练 epoch 的迭代前，通过调整 W 和 b 对它们进行更新 在下一训练 epoch 中，重复这些步骤，但使用一个不同的数据点！ 使用不同的数据点进行训练 使用各种数据点泛化（generalize）我们的模型，即学习可被用于预测任何特征值的 W 和 b 值。注意： 在大部分情况下，数据点越多，模型的学习和泛化就越好 如果你训练的 epoch 比数据点还多，你可以重复使用数据点，这不成问题。梯度下降优化总是会同时使用数据点及其成本（根据该 epoch 的 W 和 b 值从数据点中计算得到）来对 W 和 b 值进行调整；该优化器也许之前已经见过了这个数据点，但成本并不一样，因此它还是可以学到新的东西，并以不同的方式调整 W 和 b 值。 你可以用固定数量的 epoch 训练一个模型，直到其达到令人满意的成本阈值。 训练变量 1.随机、mini-batch、batch 在上面的训练中，我们在每个 epoch 送入单个数据点。这被称为随机梯度下降（stochastic gradient descent）。我们也可以在每个 epoch 送入一堆数据点，这被称为 mini-batch 梯度下降，或者甚至在一个 epoch 一次性送入所有的数据点，这被称为 batch 梯度下降。请看下图的比较，注意这 3 张图的 2 处不同： 每个 epoch 送入 TensorFlow 图（TF.Graph）的数据点的数量（图右上方） 梯度下降优化在调整 W 和 b 值时所考虑的数据点的数量（图右下方） 随机梯度下降 mini-batch 梯度下降 batch 梯度下降 每张图中的数据点的数量有 2 个含义。当数据点更多时： 计算成本和执行梯度下降所需的计算资源（减法、平方、加法）会增加 模型的学习和泛化的速度增加 选择随机、mini-batch、batch 梯度下降的优缺点总结在下图中： 选择随机、mini-batch、batch 梯度下降的优缺点 要在随机/mini-batch/batch 梯度下降之间切换，我们只需要在将数据点送入训练步骤[D]之前将这些数据点分成不同的 batch 大小，即为 [C] 使用如下的代码片段： # all_xs: 所有的特征值 # all_ys: 所有的输出值 # datapoint_size: all_xs/all_ys 中点/项的数量 # batch_size: 配置如下: # 1: 随机模型 # integer &lt; datapoint_size: mini-batch模式 # datapoint_size: batch模式 # i: 当前epoch数量 if datapoint_size == batch_size: # Batch 模式，所以选择所有数据点从 index 0 开始 batch_start_idx = 0 elif datapoint_size &lt; batch_size: # 不可能 raise ValueError(“datapoint_size: %d, must be greater than batch_size: %d” % (datapoint_size, batch_size)) else: # 随机/mini-batch模式: 从所有可能的数据点中分批选择数据点 batch_start_idx = (i * batch_size) % (datapoint_size — batch_size) batch_end_idx = batch_start_idx + batch_size batch_xs = all_xs[batch_start_idx:batch_end_idx] batch_ys = all_ys[batch_start_idx:batch_end_idx] # 将分批的数据点定义为xs, ys, 它们会被送入 ‘train_step’训练步骤 xs = np.array(batch_xs) ys = np.array(batch_ys) 2.学习率变化 学习率（learn rate）是指梯度下降调整 W 和 b 递增或递减的速度。学习率较小时，处理过程会更慢，但肯定能得到更小成本；而当学习率更大时，我们可以更快地得到最小成本，但有「冲过头」的风险，导致我们没法找到最小成本。 为了克服这一问题，许多机器学习实践者选择开始时使用较大的学习率（假设开始时的成本离最小成本还很远），然后随每个 epoch 而逐渐降低学习率。 TensorFlow 提供了 2 种方法可以做到这一点，详细解释可参考： train_step = tf.train.GradientDescentOptimizer( learning_rate=learn_rate).minimize(cost) # 修改[D]，包含送入一个’learn_rate’值, # 即 ‘initial_learnrate’（初始学习率）除以’i’ (当前epoch数) # 注: 这是过于简化的，仅用作示例 feed = { x: xs, y: ys, learn_rate: initial_learn_rate/i } sess.run(train_step, feed_dict=feed) 小结 我们解释了机器学习中「训练（training）」的含义，以及在 TensorFlow 中通过模型和成本定义、然后循环通过训练步骤（将数据点送入梯度下降优化器）来进行训练的方式。我们还讨论了训练中的常见变量，即改变模型学习时每个 epoch 所用的数据点的大小和改变梯度下降优化器的学习率。 后续内容 创建 Tensor Board 来可视化 Tensorflow 的执行，从而检测我们的模型、成本函数或梯度下降中的问题 使用多个特征表达线性回归 ©本文由机器之心编译，转载请联系本公众号获得授权。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Tensorflow一些常用基本概念与函数","date":"2017-02-13T00:50:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Tensorflow/basic-concept-and-operation-of-tensorflow/","text":"作者：林海山波 本文主要对tf的一些常用概念与方法进行描述。 1、tensorflow的基本运作 为了快速的熟悉TensorFlow编程，下面从一段简单的代码开始： import tensorflow as tf #定义‘符号’变量，也称为占位符 a = tf.placeholder(\"float\") b = tf.placeholder(\"float\") y = tf.mul(a, b) #构造一个op节点 sess = tf.Session()#建立会话 #运行会话，输入数据，并计算节点，同时打印结果 print sess.run(y, feed_dict={a: 3, b: 3}) # 任务完成, 关闭会话. sess.close() 其中tf.mul(a, b)函数便是tf的一个基本的算数运算，接下来介绍跟多的相关函数。 2、tf函数 TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU。一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测。如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作. 并行计算能让代价大的算法计算加速执行，TensorFlow也在实现上对复杂操作进行了有效的改进。大部分核相关的操作都是设备相关的实现，比如GPU。下面是一些重要的操作/核： 操作组 操作 Maths Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal Array Concat, Slice, Split, Constant, Rank, Shape, Shuffle Matrix MatMul, MatrixInverse, MatrixDeterminant Neuronal Network SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool Checkpointing Save, Restore Queues and syncronizations Enqueue, Dequeue, MutexAcquire, MutexRelease Flow control Merge, Switch, Enter, Leave, NextIteration TensorFlow的算术操作如下： 操作 描述 tf.add(x, y, name=None) 求和 tf.sub(x, y, name=None) 减法 tf.mul(x, y, name=None) 乘法 tf.div(x, y, name=None) 除法 tf.mod(x, y, name=None) 取模 tf.abs(x, name=None) 求绝对值 tf.neg(x, name=None) 取负 (y = -x). tf.sign(x, name=None) 返回符号 y = sign(x) = -1 if x &lt; 0; 0 if x == 0; 1 if x &gt; 0. tf.inv(x, name=None) 取反 tf.square(x, name=None) 计算平方 (y = x * x = x^2). tf.round(x, name=None) 舍入最接近的整数# ‘a’ is [0.9, 2.5, 2.3, -4.4]tf.round(a) ==&gt; [ 1.0, 3.0, 2.0, -4.0 ] tf.sqrt(x, name=None) 开根号 (y = \\sqrt{x} = x^{1/2}). tf.pow(x, y, name=None) 幂次方 # tensor ‘x’ is [[2, 2], [3, 3]]# tensor ‘y’ is [[8, 16], [2, 3]]tf.pow(x, y) ==&gt; [[256, 65536], [9, 27]] tf.exp(x, name=None) 计算e的次方 tf.log(x, name=None) 计算log，一个输入计算e的ln，两输入以第二输入为底 tf.maximum(x, y, name=None) 返回最大值 (x &gt; y ? x : y) tf.minimum(x, y, name=None) 返回最小值 (x &lt; y ? x : y) tf.cos(x, name=None) 三角函数cosine tf.sin(x, name=None) 三角函数sine tf.tan(x, name=None) 三角函数tan tf.atan(x, name=None) 三角函数ctan 张量操作Tensor Transformations 数据类型转换Casting 操作 描述 tf.string_to_number(string_tensor, out_type=None, name=None) 字符串转为数字 tf.to_double(x, name=’ToDouble’) 转为64位浮点类型–float64 tf.to_float(x, name=’ToFloat’) 转为32位浮点类型–float32 tf.to_int32(x, name=’ToInt32’) 转为32位整型–int32 tf.to_int64(x, name=’ToInt64’) 转为64位整型–int64 tf.cast(x, dtype, name=None) 将x或者x.values转换为dtype# tensor a is [1.8, 2.2], dtype=tf.floattf.cast(a, tf.int32) ==&gt; [1, 2] # dtype=tf.int32 形状操作Shapes and Shaping 操作 描述 tf.shape(input, name=None) 返回数据的shape# ‘t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]shape(t) ==&gt; [2, 2, 3] tf.size(input, name=None) 返回数据的元素数量# ‘t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]size(t) ==&gt; 12 tf.rank(input, name=None) 返回tensor的rank注意：此rank不同于矩阵的rank，tensor的rank表示一个tensor需要的索引数目来唯一表示任何一个元素也就是通常所说的 “order”, “degree”或”ndims”#’t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]# shape of tensor ‘t’ is [2, 2, 3]rank(t) ==&gt; 3 tf.reshape(tensor, shape, name=None) 改变tensor的形状# tensor ‘t’ is [1, 2, 3, 4, 5, 6, 7, 8, 9]# tensor ‘t’ has shape [9]reshape(t, [3, 3]) ==&gt; [[1, 2, 3],[4, 5, 6],[7, 8, 9]]#如果shape有元素[-1],表示在该维度打平至一维# -1 将自动推导得为 9:reshape(t, [2, -1]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],[4, 4, 4, 5, 5, 5, 6, 6, 6]] tf.expand_dims(input, dim, name=None) 插入维度1进入一个tensor中#该操作要求-1-input.dims()# ‘t’ is a tensor of shape [2]shape(expand_dims(t, 0)) ==&gt; [1, 2]shape(expand_dims(t, 1)) ==&gt; [2, 1]shape(expand_dims(t, -1)) ==&gt; [2, 1] &lt;= dim &lt;= input.dims() 切片与合并（Slicing and Joining） 操作 描述 tf.slice(input_, begin, size, name=None) 对tensor进行切片操作其中size[i] = input.dim_size(i) - begin[i]该操作要求 0 &lt;= begin[i] &lt;= begin[i] + size[i] &lt;= Di for i in [0, n]#’input’ is #[[[1, 1, 1], [2, 2, 2]],[[3, 3, 3], [4, 4, 4]],[[5, 5, 5], [6, 6, 6]]]tf.slice(input, [1, 0, 0], [1, 1, 3]) ==&gt; [[[3, 3, 3]]]tf.slice(input, [1, 0, 0], [1, 2, 3]) ==&gt; [[[3, 3, 3],[4, 4, 4]]]tf.slice(input, [1, 0, 0], [2, 1, 3]) ==&gt; [[[3, 3, 3]],[[5, 5, 5]]] tf.split(split_dim, num_split, value, name=’split’) 沿着某一维度将tensor分离为num_split tensors# ‘value’ is a tensor with shape [5, 30]# Split ‘value’ into 3 tensors along dimension 1split0, split1, split2 = tf.split(1, 3, value)tf.shape(split0) ==&gt; [5, 10] tf.concat(concat_dim, values, name=’concat’) 沿着某一维度连结tensort1 = [[1, 2, 3], [4, 5, 6]]t2 = [[7, 8, 9], [10, 11, 12]]tf.concat(0, [t1, t2]) ==&gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]tf.concat(1, [t1, t2]) ==&gt; [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]如果想沿着tensor一新轴连结打包,那么可以：tf.concat(axis, [tf.expand_dims(t, axis) for t in tensors])等同于tf.pack(tensors, axis=axis) tf.pack(values, axis=0, name=’pack’) 将一系列rank-R的tensor打包为一个rank-(R+1)的tensor# ‘x’ is [1, 4], ‘y’ is [2, 5], ‘z’ is [3, 6]pack([x, y, z]) =&gt; [[1, 4], [2, 5], [3, 6]] # 沿着第一维packpack([x, y, z], axis=1) =&gt; [[1, 2, 3], [4, 5, 6]]等价于tf.pack([x, y, z]) = np.asarray([x, y, z]) tf.reverse(tensor, dims, name=None) 沿着某维度进行序列反转其中dim为列表，元素为bool型，size等于rank(tensor)# tensor ‘t’ is [[[[ 0, 1, 2, 3],#[ 4, 5, 6, 7],#[ 8, 9, 10, 11]],#[[12, 13, 14, 15],#[16, 17, 18, 19],#[20, 21, 22, 23]]]]# tensor ‘t’ shape is [1, 2, 3, 4]# ‘dims’ is [False, False, False, True]reverse(t, dims) ==&gt; [[[[ 3, 2, 1, 0], [ 7, 6, 5, 4],[ 11, 10, 9, 8]], [[15, 14, 13, 12], [19, 18, 17, 16], [23, 22, 21, 20]]]] tf.transpose(a, perm=None, name=’transpose’) 调换tensor的维度顺序按照列表perm的维度排列调换tensor顺序，如为定义，则perm为(n-1…0)# ‘x’ is [[1 2 3],[4 5 6]]tf.transpose(x) ==&gt; [[1 4], [2 5],[3 6]]# Equivalentlytf.transpose(x, perm=[1, 0]) ==&gt; [[1 4],[2 5], [3 6]] tf.gather(params, indices, validate_indices=None, name=None) 合并索引indices所指示params中的切片 tf.one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None) indices = [0, 2, -1, 1]depth = 3on_value = 5.0 off_value = 0.0 axis = -1 #Then output is [4 x 3]: output = [5.0 0.0 0.0] // one_hot(0) [0.0 0.0 5.0] // one_hot(2) [0.0 0.0 0.0] // one_hot(-1) [0.0 5.0 0.0] // one_hot(1) 矩阵相关运算 操作 描述 tf.diag(diagonal, name=None) 返回一个给定对角值的对角tensor# ‘diagonal’ is [1, 2, 3, 4]tf.diag(diagonal) ==&gt; [[1, 0, 0, 0][0, 2, 0, 0][0, 0, 3, 0][0, 0, 0, 4]] tf.diag_part(input, name=None) 功能与上面相反 tf.trace(x, name=None) 求一个2维tensor足迹，即对角值diagonal之和 tf.transpose(a, perm=None, name=’transpose’) 调换tensor的维度顺序按照列表perm的维度排列调换tensor顺序，如为定义，则perm为(n-1…0)# ‘x’ is [[1 2 3],[4 5 6]]tf.transpose(x) ==&gt; [[1 4], [2 5],[3 6]]# Equivalentlytf.transpose(x, perm=[1, 0]) ==&gt; [[1 4],[2 5], [3 6]] tf.matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None) 矩阵相乘 tf.matrix_determinant(input, name=None) 返回方阵的行列式 tf.matrix_inverse(input, adjoint=None, name=None) 求方阵的逆矩阵，adjoint为True时，计算输入共轭矩阵的逆矩阵 tf.cholesky(input, name=None) 对输入方阵cholesky分解，即把一个对称正定的矩阵表示成一个下三角矩阵L和其转置的乘积的分解A=LL^T tf.matrix_solve(matrix, rhs, adjoint=None, name=None) 求解tf.matrix_solve(matrix, rhs, adjoint=None, name=None)matrix为方阵shape为[M,M],rhs的shape为[M,K]，output为[M,K] 复数操作 操作 描述 tf.complex(real, imag, name=None) 将两实数转换为复数形式# tensor ‘real’ is [2.25, 3.25]# tensor imag is [4.75, 5.75]tf.complex(real, imag) ==&gt; [[2.25 + 4.75j], [3.25 + 5.75j]] tf.complex_abs(x, name=None) 计算复数的绝对值，即长度。# tensor ‘x’ is [[-2.25 + 4.75j], [-3.25 + 5.75j]]tf.complex_abs(x) ==&gt; [5.25594902, 6.60492229] tf.conj(input, name=None) 计算共轭复数 tf.imag(input, name=None)tf.real(input, name=None) 提取复数的虚部和实部 tf.fft(input, name=None) 计算一维的离散傅里叶变换，输入数据类型为complex64 归约计算(Reduction) 操作 描述 tf.reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None) 计算输入tensor元素的和，或者安照reduction_indices指定的轴进行求和# ‘x’ is [[1, 1, 1]# [1, 1, 1]]tf.reduce_sum(x) ==&gt; 6tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]tf.reduce_sum(x, 1) ==&gt; [3, 3]tf.reduce_sum(x, 1, keep_dims=True) ==&gt; [[3], [3]]tf.reduce_sum(x, [0, 1]) ==&gt; 6 tf.reduce_prod(input_tensor, reduction_indices=None, keep_dims=False, name=None) 计算输入tensor元素的乘积，或者安照reduction_indices指定的轴进行求乘积 tf.reduce_min(input_tensor, reduction_indices=None, keep_dims=False, name=None) 求tensor中最小值 tf.reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None) 求tensor中最大值 tf.reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None) 求tensor中平均值 tf.reduce_all(input_tensor, reduction_indices=None, keep_dims=False, name=None) 对tensor中各个元素求逻辑’与’# ‘x’ is # [[True, True]# [False, False]]tf.reduce_all(x) ==&gt; Falsetf.reduce_all(x, 0) ==&gt; [False, False]tf.reduce_all(x, 1) ==&gt; [True, False] tf.reduce_any(input_tensor, reduction_indices=None, keep_dims=False, name=None) 对tensor中各个元素求逻辑’或’ tf.accumulate_n(inputs, shape=None, tensor_dtype=None, name=None) 计算一系列tensor的和# tensor ‘a’ is [[1, 2], [3, 4]]# tensor b is [[5, 0], [0, 6]]tf.accumulate_n([a, b, a]) ==&gt; [[7, 4], [6, 14]] tf.cumsum(x, axis=0, exclusive=False, reverse=False, name=None) 求累积和tf.cumsum([a, b, c]) ==&gt; [a, a + b, a + b + c]tf.cumsum([a, b, c], exclusive=True) ==&gt; [0, a, a + b]tf.cumsum([a, b, c], reverse=True) ==&gt; [a + b + c, b + c, c]tf.cumsum([a, b, c], exclusive=True, reverse=True) ==&gt; [b + c, c, 0] 分割(Segmentation) 操作 描述 tf.segment_sum(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的和其中segment_ids为一个size与data第一维相同的tensor其中id为int型数据，最大id不大于sizec = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])tf.segment_sum(c, tf.constant([0, 0, 1]))==&gt;[[0 0 0 0] [5 6 7 8]]上面例子分为[0,1]两id,对相同id的data相应数据进行求和,并放入结果的相应id中，且segment_ids只升不降 tf.segment_prod(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的积 tf.segment_min(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的最小值 tf.segment_max(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的最大值 tf.segment_mean(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的平均值 tf.unsorted_segment_sum(data, segment_ids, num_segments, name=None) 与tf.segment_sum函数类似，不同在于segment_ids中id顺序可以是无序的 tf.sparse_segment_sum(data, indices, segment_ids, name=None) 输入进行稀疏分割求和c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])# Select two rows, one segment.tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0])) ==&gt; [[0 0 0 0]]对原data的indices为[0,1]位置的进行分割，并按照segment_ids的分组进行求和 序列比较与索引提取(Sequence Comparison and Indexing) 操作 描述 tf.argmin(input, dimension, name=None) 返回input最小值的索引index tf.argmax(input, dimension, name=None) 返回input最大值的索引index tf.listdiff(x, y, name=None) 返回x，y中不同值的索引 tf.where(input, name=None) 返回bool型tensor中为True的位置# ‘input’ tensor is #[[True, False]#[True, False]]# ‘input’ 有两个’True’,那么输出两个坐标值.# ‘input’的rank为2, 所以每个坐标为具有两个维度.where(input) ==&gt; [[0, 0],[1, 0]] tf.unique(x, name=None) 返回一个元组tuple(y,idx)，y为x的列表的唯一化数据列表，idx为x数据对应y元素的index# tensor ‘x’ is [1, 1, 2, 4, 4, 4, 7, 8, 8]y, idx = unique(x)y ==&gt; [1, 2, 4, 7, 8]idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4] tf.invert_permutation(x, name=None) 置换x数据与索引的关系# tensor x is [3, 4, 0, 2, 1]invert_permutation(x) ==&gt; [2, 4, 3, 0, 1] 神经网络(Neural Network) 激活函数（Activation Functions） 操作 描述 tf.nn.relu(features, name=None) 整流函数：max(features, 0) tf.nn.relu6(features, name=None) 以6为阈值的整流函数：min(max(features, 0), 6) tf.nn.elu(features, name=None) elu函数，exp(features) - 1 if &lt; 0,否则featuresExponential Linear Units (ELUs) tf.nn.softplus(features, name=None) 计算softplus：log(exp(features) + 1) tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None) 计算dropout，keep_prob为keep概率noise_shape为噪声的shape tf.nn.bias_add(value, bias, data_format=None, name=None) 对value加一偏置量此函数为tf.add的特殊情况，bias仅为一维，函数通过广播机制进行与value求和,数据格式可以与value不同，返回为与value相同格式 tf.sigmoid(x, name=None) y = 1 / (1 + exp(-x)) tf.tanh(x, name=None) 双曲线切线激活函数 卷积函数（Convolution） 操作 描述 tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None) 在给定的4D input与 filter下计算2D卷积输入shape为 [batch, height, width, in_channels] tf.nn.conv3d(input, filter, strides, padding, name=None) 在给定的5D input与 filter下计算3D卷积输入shape为[batch, in_depth, in_height, in_width, in_channels] 池化函数（Pooling） 操作 描述 tf.nn.avg_pool(value, ksize, strides, padding, data_format=’NHWC’, name=None) 平均方式池化 tf.nn.max_pool(value, ksize, strides, padding, data_format=’NHWC’, name=None) 最大值方法池化 tf.nn.max_pool_with_argmax(input, ksize, strides, padding, Targmax=None, name=None) 返回一个二维元组(output,argmax),最大值pooling，返回最大值及其相应的索引 tf.nn.avg_pool3d(input, ksize, strides, padding, name=None) 3D平均值pooling tf.nn.max_pool3d(input, ksize, strides, padding, name=None) 3D最大值pooling 数据标准化（Normalization） 操作 描述 tf.nn.l2_normalize(x, dim, epsilon=1e-12, name=None) 对维度dim进行L2范式标准化output = x / sqrt(max(sum(x*2), epsilon)) tf.nn.sufficient_statistics(x, axes, shift=None, keep_dims=False, name=None) 计算与均值和方差有关的完全统计量返回4维元组,元素个数，元素总和，元素的平方和，*shift结果参见算法介绍 tf.nn.normalize_moments(counts, mean_ss, variance_ss, shift, name=None) 基于完全统计量计算均值和方差 tf.nn.moments(x, axes, shift=None, name=None, keep_dims=False) 直接计算均值与方差 损失函数（Losses） 操作 描述 tf.nn.l2_loss(t, name=None) output = sum(t ** 2) / 2 分类函数（Classification） 操作 描述 tf.nn.sigmoid_cross_entropy_with_logits(logits, targets, name=None)* 计算输入logits, targets的交叉熵 tf.nn.softmax(logits, name=None) 计算softmaxsoftmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j])) tf.nn.log_softmax(logits, name=None) logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i]))) tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None) 计算logits和labels的softmax交叉熵logits, labels必须为相同的shape与数据类型 tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name=None) 计算logits和labels的softmax交叉熵 tf.nn.weighted_cross_entropy_with_logits(logits, targets, pos_weight, name=None) 与sigmoid_cross_entropy_with_logits()相似，但给正向样本损失加了权重pos_weight 符号嵌入（Embeddings） 操作 描述 tf.nn.embedding_lookup(params, ids, partition_strategy=’mod’, name=None, validate_indices=True) 根据索引ids查询embedding列表params中的tensor值如果len(params) &gt; 1，id将会安照partition_strategy策略进行分割1、如果partition_strategy为”mod”，id所分配到的位置为p = id % len(params)比如有13个ids，分为5个位置，那么分配方案为：[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]2、如果partition_strategy为”div”,那么分配方案为：[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]] tf.nn.embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy=’mod’, name=None, combiner=’mean’) 对给定的ids和权重查询embedding1、sp_ids为一个N x M的稀疏tensor，N为batch大小，M为任意，数据类型int642、sp_weights的shape与sp_ids的稀疏tensor权重，浮点类型，若为None，则权重为全’1’ 循环神经网络（Recurrent Neural Networks） 操作 描述 tf.nn.rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None) 基于RNNCell类的实例cell建立循环神经网络 tf.nn.dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None) 基于RNNCell类的实例cell建立动态循环神经网络与一般rnn不同的是，该函数会根据输入动态展开返回(outputs,state) tf.nn.state_saving_rnn(cell, inputs, state_saver, state_name, sequence_length=None, scope=None) 可储存调试状态的RNN网络 tf.nn.bidirectional_rnn(cell_fw, cell_bw, inputs, initial_state_fw=None, initial_state_bw=None, dtype=None, sequence_length=None, scope=None) 双向RNN, 返回一个3元组tuple(outputs, output_state_fw, output_state_bw) — tf.nn.rnn简要介绍— cell: 一个RNNCell实例 inputs: 一个shape为[batch_size, input_size]的tensor initial_state: 为RNN的state设定初值，可选 sequence_length：制定输入的每一个序列的长度，size为[batch_size],值范围为[0, T)的int型数据 其中T为输入数据序列的长度 @ @针对输入batch中序列长度不同，所设置的动态计算机制 @对于在时间t，和batch的b行，有 (output, state)(b, t) = ? (zeros(cell.output_size), states(b, sequence_length(b) - 1)) : cell(input(b, t), state(b, t - 1)) 求值网络（Evaluation） 操作 描述 tf.nn.top_k(input, k=1, sorted=True, name=None) 返回前k大的值及其对应的索引 tf.nn.in_top_k(predictions, targets, k, name=None) 返回判断是否targets索引的predictions相应的值是否在在predictions前k个位置中，返回数据类型为bool类型，len与predictions同 监督候选采样网络（Candidate Sampling） 对于有巨大量的多分类与多标签模型，如果使用全连接softmax将会占用大量的时间与空间资源，所以采用候选采样方法仅使用一小部分类别与标签作为监督以加速训练。 操作 描述 Sampled Loss Functions tf.nn.nce_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=False, partition_strategy=’mod’, name=’nce_loss’) 返回noise-contrastive的训练损失结果 tf.nn.sampled_softmax_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=True, partition_strategy=’mod’, name=’sampled_softmax_loss’) 返回sampled softmax的训练损失参考- Jean et al., 2014第3部分 Candidate Samplers tf.nn.uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None) 通过均匀分布的采样集合返回三元tuple1、sampled_candidates 候选集合。2、期望的true_classes个数，为浮点值3、期望的sampled_candidates个数，为浮点值 tf.nn.log_uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None) 通过log均匀分布的采样集合，返回三元tuple tf.nn.learned_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None) 根据在训练过程中学习到的分布状况进行采样返回三元tuple tf.nn.fixed_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, vocab_file=”, distortion=1.0, num_reserved_ids=0, num_shards=1, shard=0, unigrams=(), seed=None, name=None) 基于所提供的基本分布进行采样 保存与恢复变量 操作 描述 类tf.train.Saver(Saving and Restoring Variables) tf.train.Saver.init(var_list=None, reshape=False, sharded=False, max_to_keep=5, keep_checkpoint_every_n_hours=10000.0, name=None, restore_sequentially=False, saver_def=None, builder=None) 创建一个存储器Savervar_list定义需要存储和恢复的变量 tf.train.Saver.save(sess, save_path, global_step=None, latest_filename=None, meta_graph_suffix=’meta’, write_meta_graph=True) 保存变量 tf.train.Saver.restore(sess, save_path) 恢复变量 tf.train.Saver.last_checkpoints 列出最近未删除的checkpoint 文件名 tf.train.Saver.set_last_checkpoints(last_checkpoints) 设置checkpoint文件名列表 tf.train.Saver.set_last_checkpoints_with_time(last_checkpoints_with_time) 设置checkpoint文件名列表和时间戳 相关链接： [1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 摘要：本文主要对tf的一些常用概念与方法进行描述。为‘Tensorflow一些常用基本概念与函数’系列之二。1、tensorflow的基本运作为了快速的熟悉TensorFlow编程，下面从一段简单的代码开始：import tensorflow as tf #定义‘符号’变量，也称为占位符 a = tf.placeholder(“float”) b = tf.placeholder(“float”) y = tf.mul(a, b) #构造一个op节点 sess = tf.Session()#建立会话 #运行会话，输入数据，并计算节点，同时打印结果 print sess.run(y, feed_dict={a: 3, b: 3}) # 任务完成, 关闭会话. sess.close()其中tf.mul(a, b)函数便是tf的一个基本的算数运算，接下来介绍跟多的相关函数。2、tf函数TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU。一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测。如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作.并行计算能让代价大的算法计算加速执行，TensorFlow也在实现上对复杂操作进行了有效的改进。大部分核相关的操作都是设备相关的实现，比如GPU。本文主要涉及的相关概念或操作有以下内容： 操作组 操作 Building Graphs Core graph data structures，Tensor types，Utility functions Inputs and Readers Placeholders，Readers，Converting，Queues，Input pipeline2.1 建立图(Building Graphs)本节主要介绍建立tensorflow图的相关类或函数 核心图的数据结构（Core graph data structures）tf.Graph 操作 描述 class tf.Graph tensorflow中的计算以图数据流的方式表示一个图包含一系列表示计算单元的操作对象以及在图中流动的数据单元以tensor对象表现 tf.Graph.init() 建立一个空图 tf.Graph.as_default() 一个将某图设置为默认图，并返回一个上下文管理器如果不显式添加一个默认图，系统会自动设置一个全局的默认图。所设置的默认图，在模块范围内所定义的节点都将默认加入默认图中 tf.Graph.as_graph_def(from_version=None, add_shapes=False) 返回一个图的序列化的GraphDef表示序列化的GraphDef可以导入至另一个图中(使用 import_graph_def())或者使用C++ Session API tf.Graph.finalize() 完成图的构建，即将其设置为只读模式 tf.Graph.finalized 返回True，如果图被完成 tf.Graph.control_dependencies(control_inputs) 定义一个控制依赖，并返回一个上下文管理器with g.control_dependencies([a, b, c]):# d 和 e 将在 a, b, 和c执行完之后运行.d = … e = … tf.Graph.device(device_name_or_function) 定义运行图所使用的设备，并返回一个上下文管理器with g.device(‘/gpu:0’): …with g.device(‘/cpu:0’): … tf.Graph.name_scope(name) 为节点创建层次化的名称，并返回一个上下文管理器 tf.Graph.add_to_collection(name, value) 将value以name的名称存储在收集器(collection)中 tf.Graph.get_collection(name, scope=None) 根据name返回一个收集器中所收集的值的列表 tf.Graph.as_graph_element(obj, allow_tensor=True, allow_operation=True) 返回一个图中与obj相关联的对象，为一个操作节点或者tensor数据 tf.Graph.get_operation_by_name(name) 根据名称返回操作节点 tf.Graph.get_tensor_by_name(name) 根据名称返回tensor数据 tf.Graph.get_operations() 返回图中的操作节点列表 tf.Graph.gradient_override_map(op_type_map) 用于覆盖梯度函数的上下文管理器#class tf.Graph#tensorflow运行时需要设置默认的图g = tf.Graph()with g.as_default(): # Define operations and tensors in g. c = tf.constant(30.0) assert c.graph is g##也可以使用tf.get_default_graph()获得默认图，也可在基础上加入节点或子图c = tf.constant(4.0)assert c.graph is tf.get_default_graph()#tf.Graph.as_default#以下两段代码功能相同#1、使用Graph.as_default():g = tf.Graph()with g.as_default(): c = tf.constant(5.0) assert c.graph is g#2、构造和设置为默认with tf.Graph().as_default() as g: c = tf.constant(5.0) assert c.graph is g#tf.Graph.control_dependencies(control_inputs)# 错误代码def my_func(pred, tensor): t = tf.matmul(tensor, tensor) with tf.control_dependencies([pred]): # 乘法操作(op)没有创建在该上下文，所以没有被加入依赖控制 return t# 正确代码def my_func(pred, tensor): with tf.control_dependencies([pred]): # 乘法操作(op)创建在该上下文，所以被加入依赖控制中 #执行完pred之后再执行matmul return tf.matmul(tensor, tensor)# tf.Graph.name_scope(name)# 一个图中包含有一个名称范围的堆栈，在使用name_scope(…)之后，将压(push)新名称进栈中，#并在下文中使用该名称with tf.Graph().as_default() as g: c = tf.constant(5.0, name=“c”) assert c.op.name == “c” c_1 = tf.constant(6.0, name=“c”) assert c_1.op.name == “c_1” # Creates a scope called “nested” with g.name_scope(“nested”) as scope: nested_c = tf.constant(10.0, name=“c”) assert nested_c.op.name == “nested/c” # Creates a nested scope called “inner”. with g.name_scope(“inner”): nested_inner_c = tf.constant(20.0, name=“c”) assert nested_inner_c.op.name == “nested/inner/c” # Create a nested scope called “inner_1”. with g.name_scope(“inner”): nested_inner_1_c = tf.constant(30.0, name=“c”) assert nested_inner_1_c.op.name == “nested/inner_1/c” # Treats scope as an absolute name scope, and # switches to the “nested/“ scope. with g.name_scope(scope): nested_d = tf.constant(40.0, name=“d”) assert nested_d.op.name == “nested/d” with g.name_scope(“”): e = tf.constant(50.0, name=“e”) assert e.op.name == “e”tf.Operation 操作 描述 class tf.Operation 代表图中的一个节点，用于计算tensors数据该类型将由python节点构造器产生(比如tf.matmul())或者Graph.create_op()例如c = tf.matmul(a, b)创建一个Operation类为类型为”MatMul”,输入为’a’,’b’，输出为’c’的操作类 tf.Operation.name 操作节点(op)的名称 tf.Operation.type 操作节点(op)的类型，比如”MatMul” tf.Operation.inputstf.Operation.outputs 操作节点的输入与输出 tf.Operation.control_inputs 操作节点的依赖 tf.Operation.run(feed_dict=None, session=None) 在会话(Session)中运行该操作 tf.Operation.get_attr(name) 获取op的属性值tf.Tensor 操作 描述 class tf.Tensor 表示一个由操作节点op产生的值，TensorFlow程序使用tensor数据结构来代表所有的数据, 计算图中, 操作间传递的数据都是 tensor，一个tensor是一个符号handle,里面并没有表示实际数据，而相当于数据流的载体 tf.Tensor.dtype tensor中数据类型 tf.Tensor.name 该tensor名称 tf.Tensor.value_index 该tensor输出外op的index tf.Tensor.graph 该tensor所处在的图 tf.Tensor.op 产生该tensor的op tf.Tensor.consumers() 返回使用该tensor的op列表 tf.Tensor.eval(feed_dict=None, session=None) 在会话中求tensor的值需要使用with sess.as_default()或者 eval(session=sess) tf.Tensor.get_shape() 返回用于表示tensor的shape的类TensorShape tf.Tensor.set_shape(shape) 更新tensor的shape tf.Tensor.device 设置计算该tensor的设备#tf.Tensor.get_shape()c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])print(c.get_shape())==&gt; TensorShape([Dimension(2), Dimension(3)])#现在有个用于图像处理的tensor-&gt;imageprint(image.get_shape())==&gt; TensorShape([Dimension(None), Dimension(None), Dimension(3)])# 假如我们知道数据集中图像尺寸为28 x 28，那么可以设置image.set_shape([28, 28, 3])print(image.get_shape())==&gt; TensorShape([Dimension(28), Dimension(28), Dimension(3)]) tensor类型(Tensor types)tf.DType 操作 描述 class tf.DType 数据类型主要包含tf.float16，tf.float16,tf.float32,tf.float64,tf.bfloat16,tf.complex64,tf.complex128,tf.int8,tf.uint8,tf.uint16,tf.int16,tf.int32,tf.int64,tf.bool,tf.string tf.DType.is_compatible_with(other) 判断other的数据类型是否将转变为该DType tf.DType.name 数据类型名称 tf.DType.base_dtype 返回该DType的基础DType，而非参考的数据类型(non-reference) tf.DType.as_ref 返回一个基于DType的参考数据类型 tf.DType.is_floating 判断是否为浮点类型 tf.DType.is_complex 判断是否为复数 tf.DType.is_integer 判断是否为整数 tf.DType.is_unsigned 判断是否为无符号型数据 tf.DType.as_numpy_dtype 返回一个基于DType的numpy.dtype类型 tf.DType.maxtf.DType.min 返回这种数据类型能表示的最大值及其最小值 tf.as_dtype(type_value) 返回由type_value转变得的相应tf数据类型 通用函数（Utility functions） 操作 描述 tf.device(device_name_or_function) 基于默认的图，其功能便为Graph.device() tf.container(container_name) 基于默认的图，其功能便为Graph.container() tf.name_scope(name) 基于默认的图，其功能便为 Graph.name_scope() tf.control_dependencies(control_inputs) 基于默认的图，其功能便为Graph.control_dependencies() tf.convert_to_tensor(value, dtype=None, name=None, as_ref=False) 将value转变为tensor数据类型 tf.get_default_graph() 返回返回当前线程的默认图 tf.reset_default_graph() 清除默认图的堆栈，并设置全局图为默认图 tf.import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None) 将graph_def的图导入到python中 图收集（Graph collections） 操作 描述 tf.add_to_collection(name, value) 基于默认的图，其功能便为Graph.add_to_collection() tf.get_collection(key, scope=None) 基于默认的图，其功能便为Graph.get_collection() 定义新操作节点（Defining new operations）tf.RegisterGradient 操作 描述 class tf.RegisterGradient 返回一个用于寄存op类型的梯度函数的装饰器 tf.NoGradient(op_type) 设置操作节点类型op_type的节点没有指定的梯度 class tf.RegisterShape 返回一个用于寄存op类型的shape函数的装饰器 class tf.TensorShape 表示tensor的shape tf.TensorShape.merge_with(other) 与other合并shape信息，返回一个TensorShape类 tf.TensorShape.concatenate(other) 与other的维度相连结 tf.TensorShape.ndims 返回tensor的rank tf.TensorShape.dims 返回tensor的维度 tf.TensorShape.as_list() 以list的形式返回tensor的shape tf.TensorShape.is_compatible_with(other) 判断shape是否为兼容TensorShape(None)与其他任何shape值兼容 class tf.Dimension tf.Dimension.is_compatible_with(other) 判断dims是否为兼容 tf.Dimension.merge_with(other) 与other合并dims信息 tf.op_scope(values, name, default_name=None) 在python定义op时，返回一个上下文管理器#tf.RegisterGradient#该装饰器只使用于定义一个新的op类型时候，如果一个op有m个输入，n个输出。那么该梯度函数应该设置原始的#操作类型，以及n个Tensor对象（表示每一个op输出的梯度），以及m个对象(表示每一个op输入的偏梯度)#以操作节点类型为’Sub’为例，两输入为x,y。为一个输出x-y@tf.RegisterGradient(“Sub”)def _sub_grad(unused_op, grad): return grad, tf.neg(grad)#tf.op_scope#定义一个名称为my_op的python操作节点opdef my_op(a, b, c, name=None): with tf.op_scope([a, b, c], name, “MyOp”) as scope: a = tf.convert_to_tensor(a, name=“a”) b = tf.convert_to_tensor(b, name=“b”) c = tf.convert_to_tensor(c, name=“c”) # Define some computation that uses a, b, and c. return foo_op(…, name=scope)2.2 输入和读取器(Inputs and Readers)本节主要介绍tensorflow中数据的读入相关类或函数 占位符（Placeholders）tf提供一种占位符操作，在执行时需要为其提供数据data。 操作 描述 tf.placeholder(dtype, shape=None, name=None) 为一个tensor插入一个占位符eg:x = tf.placeholder(tf.float32, shape=(1024, 1024)) tf.placeholder_with_default(input, shape, name=None) 当输出没有fed时，input通过一个占位符op tf.sparse_placeholder(dtype, shape=None, name=None) 为一个稀疏tensor插入一个占位符 读取器（Readers）tf提供一系列读取各种数据格式的类。对于多文件输入，可以使用函数tf.train.string_input_producer，该函数将创建一个保持文件的FIFO队列，以供reader使用。或者如果输入的这些文件名有相雷同的字符串，也可以使用函数tf.train.match_filenames_once。 操作 描述 class tf.ReaderBase 不同的读取器类型的基本类 tf.ReaderBase.read(queue, name=None) 返回下一个记录对(key, value),queue为tf文件队列FIFOQueue tf.ReaderBase.read_up_to(queue, num_records, name=None) 返回reader产生的num_records对(key, value) tf.ReaderBase.reader_ref 返回应用在该reader上的Op tf.ReaderBase.reset(name=None) 恢复reader为初始状态 tf.ReaderBase.restore_state(state, name=None) 恢复reader为之前的保存状态state tf.ReaderBase.serialize_state(name=None) 返回一个reader解码后产生的字符串tansor class tf.TextLineReader tf.TextLineReader.num_records_produced(name=None) 返回reader已经产生的记录(records )数目 tf.TextLineReader.num_work_units_completed(name=None) 返回该reader已经完成的处理的work数目 tf.TextLineReader.read(queue, name=None) 返回reader所产生的下一个记录对 (key, value)，该reader可以限定新产生输出的行数 tf.TextLineReader.reader_ref 返回应用在该reader上的Op tf.TextLineReader.reset(name=None) 恢复reader为初始状态 tf.TextLineReader.restore_state(state, name=None) 恢复reader为之前的保存状态state tf.TextLineReader.serialize_state(name=None) 返回一个reader解码后产生的字符串tansor class tf.WholeFileReader 一个阅读器，读取整个文件，返回文件名称key,以及文件中所有的内容value,该类的方法同上，不赘述 class tf.IdentityReader 一个reader，以key和value的形式，输出一个work队列。该类其他方法基本同上 class tf.TFRecordReader 读取TFRecord格式文件的reader。该类其他方法基本同上 class tf.FixedLengthRecordReader 输出 数据转换（Converting）tf提供一系列方法将各种格式数据转换为tensor表示。 操作 描述 tf.decode_csv(records, record_defaults, field_delim=None, name=None) 将csv转换为tensor，与tf.TextLineReader搭配使用 tf.decode_raw(bytes, out_type, little_endian=None, name=None) 将bytes转换为一个数字向量表示，bytes为一个字符串类型的tensor与函数 tf.FixedLengthRecordReader搭配使用，详见tf的CIFAR-10例子选取与要输入的文件格式相匹配的reader，并将文件队列提供给reader的读方法( read method)。读方法将返回文件唯一标识的key，以及一个记录(record)（有助于对出现一些另类的records时debug），以及一个标量的字符串值。再使用一个（或多个）解码器(decoder) 或转换操作(conversion ops)将字符串转换为tensor类型。#读取文件队列，使用reader中read的方法，返回key与valuefilename_queue = tf.train.string_input_producer([“file0.csv”, “file1.csv”])reader = tf.TextLineReader()key, value = reader.read(filename_queue)record_defaults = [[1], [1], [1], [1], [1]]col1, col2, col3, col4, col5 = tf.decode_csv( value, record_defaults=record_defaults)features = tf.pack([col1, col2, col3, col4])with tf.Session() as sess: # Start populating the filename queue. coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(coord=coord) for i in range(1200): # Retrieve a single instance: example, label = sess.run([features, col5]) coord.request_stop() coord.join(threads) Example protocol buffer提供了一些Example protocol buffers，tf所推荐的用于训练样本的数据格式，它们包含特征信息，详情可见。 这是一种与前述将手上现有的各种数据类型转换为支持的格式的方法，这种方法更容易将网络结构与数据集融合或匹配。这种tensorflow所推荐的数据格式是一个包含tf.train.Example protocol buffers (包含特征Features域)的TFRecords文件。 1、获取这种格式的文件方式为，首先将一般的数据格式填入Example protocol buffer中，再将 protocol buffer序列化为一个字符串，然后使用tf.python_io.TFRecordWriter类的相关方法将字符串写入一个TFRecords文件中，参见MNIST例子，将MNIST 数据转换为该类型数据。 2、读取TFRecords格式文件的方法为，使用tf.TFRecordReader读取器和tf.parse_single_example解码器。parse_single_example操作将 example protocol buffers解码为tensor形式。参见MNIST例子 操作 描述 class tf.VarLenFeature 解析变长的输入特征feature相关配置 class tf.FixedLenFeature 解析定长的输入特征feature相关配置 class tf.FixedLenSequenceFeature 序列项目中的稠密(dense )输入特征的相关配置 tf.parse_example(serialized, features, name=None, example_names=None) 将一组Example protos解析为tensor的字典形式解析serialized所给予的序列化的一些Example protos返回一个由特征keys映射Tensor和SparseTensor值的字典 tf.parse_single_example(serialized, features, name=None, example_names=None) 解析一个单独的Example proto，与tf.parse_example方法雷同 tf.decode_json_example(json_examples, name=None) 将JSON编码的样本记录转换为二进制protocol buffer字符串#tf.parse_example的使用举例#输入序列化数据如下： serialized = [ features { feature { key: “ft” value { float_list { value: [1.0, 2.0] } } } }, features { feature []}, features { feature { key: “ft” value { float_list { value: [3.0] } } }]#那么输出为一个字典(dict),如下：{“ft”: SparseTensor(indices=[[0, 0], [0, 1], [2, 0]], values=[1.0, 2.0, 3.0], shape=(3, 2)) }##########再来看一个例子，给定两个序列化的原始输入样本：[ features { feature { key: “kw” value { bytes_list { value: [ “knit”, “big” ] } } } feature { key: “gps” value { float_list { value: [] } } } }, features { feature { key: “kw” value { bytes_list { value: [ “emmy” ] } } } feature { key: “dank” value { int64_list { value: [ 42 ] } } } feature { key: “gps” value { } } }]#相关参数如下：example_names: [“input0”, “input1”],features: { “kw”: VarLenFeature(tf.string), “dank”: VarLenFeature(tf.int64), “gps”: VarLenFeature(tf.float32),}#那么有如下输出：{ “kw”: SparseTensor( indices=[[0, 0], [0, 1], [1, 0]], values=[“knit”, “big”, “emmy”] shape=[2, 2]), “dank”: SparseTensor( indices=[[1, 0]], values=[42], shape=[2, 1]), “gps”: SparseTensor( indices=[], values=[], shape=[2, 0]),}##########对于两个样本的输出稠密结果情况[ features { feature { key: “age” value { int64_list { value: [ 0 ] } } } feature { key: “gender” value { bytes_list { value: [ “f” ] } } } }, features { feature { key: “age” value { int64_list { value: [] } } } feature { key: “gender” value { bytes_list { value: [ “f” ] } } } }]#我们可以使用以下参数example_names: [“input0”, “input1”],features: { “age”: FixedLenFeature([], dtype=tf.int64, default_value=-1), “gender”: FixedLenFeature([], dtype=tf.string),}#期望的结果如下{ “age”: [[0], [-1]], “gender”: [[“f”], [“f”]],}##Example protocol buffer相关使用的例子#将mnist的数据转换为TFRecords文件格式import osimport tensorflow as tffrom tensorflow.contrib.learn.python.learn.datasets import mnistSOURCE_URL = ‘http://yann.lecun.com/exdb/mnist/‘TRAIN_IMAGES = ‘train-images-idx3-ubyte.gz’ # MNIST filenamesTRAIN_LABELS = ‘train-labels-idx1-ubyte.gz’TEST_IMAGES = ‘t10k-images-idx3-ubyte.gz’TEST_LABELS = ‘t10k-labels-idx1-ubyte.gz’tf.app.flags.DEFINE_string(‘directory’, ‘/tmp/data’, ‘Directory to download data files and write the ‘ ‘converted result’)tf.app.flags.DEFINE_integer(‘validation_size’, 5000, ‘Number of examples to separate from the training ‘ ‘data for the validation set.’)FLAGS = tf.app.flags.FLAGSdef _int64_feature(value): return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))def _bytes_feature(value): return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))def convert_to(data_set, name): images = data_set.images labels = data_set.labels num_examples = data_set.num_examples if images.shape[0] != num_examples: raise ValueError(‘Images size %d does not match label size %d.’ % (images.shape[0], num_examples)) rows = images.shape[1] cols = images.shape[2] depth = images.shape[3] filename = os.path.join(FLAGS.directory, name + ‘.tfrecords’) print(‘Writing’, filename) writer = tf.python_io.TFRecordWriter(filename) for index in range(num_examples): image_raw = images[index].tostring() example = tf.train.Example(features=tf.train.Features(feature={ ‘height’: _int64_feature(rows), ‘width’: _int64_feature(cols), ‘depth’: _int64_feature(depth), ‘label’: _int64_feature(int(labels[index])), ‘image_raw’: _bytes_feature(image_raw)})) writer.write(example.SerializeToString()) writer.close()def main(argv): # Get the data. data_sets = mnist.read_data_sets(FLAGS.directory, dtype=tf.uint8, reshape=False) # Convert to Examples and write the result to TFRecords. convert_to(data_sets.train, ‘train’) convert_to(data_sets.validation, ‘validation’) convert_to(data_sets.test, ‘test’)if name == ‘main‘: tf.app.run() 队列(Queues)tensorflow提供了几个队列应用，用来将tf计算图与tensors的阶段流水组织到一起。队列是使用tensorflow计算的一个强大的机制，正如其他Tensorflow的元素一样，一个队列也是tf图中的一个节点(node),它是一个有状态的node，就像一个变量：其他节点可以改变其内容。 我们来看一个简单的例子，如下gif图，我们将创建一个先入先出队列(FIFOQueue)并且将值全设为0，然后我们构建一个图以获取队列出来的元素，对该元素加1操作，并将结果再放入队列末尾。渐渐地，队列中的数字便增加。 操作 描述 class tf.QueueBase 基本的队列应用类.队列(queue)是一种数据结构，该结构通过多个步骤存储tensors,并且对tensors进行入列(enqueue)与出列(dequeue)操作 tf.QueueBase.enqueue(vals, name=None) 将一个元素编入该队列中。如果在执行该操作时队列已满，那么将会阻塞直到元素编入队列之中 tf.QueueBase.enqueue_many(vals, name=None) 将零个或多个元素编入该队列中 tf.QueueBase.dequeue(name=None) 将元素从队列中移出。如果在执行该操作时队列已空，那么将会阻塞直到元素出列，返回出列的tensors的tuple tf.QueueBase.dequeue_many(n, name=None) 将一个或多个元素从队列中移出 tf.QueueBase.size(name=None) 计算队列中的元素个数 tf.QueueBase.close(cancel_pending_enqueues=False, name=None) 关闭该队列 f.QueueBase.dequeue_up_to(n, name=None) 从该队列中移出n个元素并将之连接 tf.QueueBase.dtypes 列出组成元素的数据类型 tf.QueueBase.from_list(index, queues) 根据queues[index]的参考队列创建一个队列 tf.QueueBase.name 返回最队列下面元素的名称 tf.QueueBase.names 返回队列每一个组成部分的名称 class tf.FIFOQueue 在出列时依照先入先出顺序，其他方法与tf.QueueBase雷同 class tf.PaddingFIFOQueue 一个FIFOQueue ，同时根据padding支持batching变长的tensor class tf.RandomShuffleQueue 该队列将随机元素出列，其他方法与tf.QueueBase雷同 文件系统的处理(Dealing with the filesystem) 操作 描述 tf.matching_files(pattern, name=None) 返回与pattern匹配模式的文件名称 tf.read_file(filename, name=None) 读取并输出输入文件的整个内容 输入管道(Input pipeline)用于设置输入预取数的管道TF函数，函数 “producer”添加一个队列至图中，同时一个相应用于运行队列中子图(subgraph)的QueueRunner 操作 描述 tf.train.match_filenames_once(pattern, name=None) 保存与pattern的文件列表 tf.train.limit_epochs(tensor, num_epochs=None, name=None) 返回一个num_epochs次数，然后报告OutOfRange错误 tf.train.input_producer(input_tensor, element_shape=None, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, summary_name=None, name=None) 为一个输入管道输出input_tensor中的多行至一个队列中 tf.train.range_input_producer(limit, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None) 产生一个从1至limit-1的整数至队列中 tf.train.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None) 对tensor_list中的每一个tensor切片 tf.train.string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None) 为一个输入管道输出一组字符串(比如文件名)至队列中 在输入管道末端批量打包(Batching at the end of an input pipeline)该相关函数增添一个队列至图中以将数据一样本打包为batch。它们也会添加 一个QueueRunner，以便执行的已经被填满队列的子图 操作 描述 tf.train.batch(tensors, batch_size, num_threads=1, capacity=32, enqueue_many=False, shapes=None, dynamic_pad=False, allow_smaller_final_batch=False, shared_name=None, name=None) 在输入的tensors中创建一些tensor数据格式的batch，若输入为shape[, x, y, z]，那么输出则为[batch_size, x, y, z]返回一个列表或者一个具有与输入tensors相同类型tensors的字典 tf.train.batch_join(tensors_list, batch_size, capacity=32, enqueue_many=False, shapes=None, dynamic_pad=False, allow_smaller_final_batch=False, shared_name=None, name=None) 将一个tensors的列表添加至一个队列中以创建样本的batcheslen(tensors_list)个线程将启动，线程i将tensors_list[i]的tensors入列tensors_list[i1][j]与tensors_list[i2][j]有相同的类型和shape tf.train.shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, allow_smaller_final_batch=False, shared_name=None, name=None) 使用随机乱序的方法创建batchestensors:用于入列的一个list或者dictcapacity:一个整数，表示队列中元素最大数目 tf.train.shuffle_batch_join(tensors_list, batch_size, capacity, min_after_dequeue, seed=None, enqueue_many=False, shapes=None, allow_smaller_final_batch=False, shared_name=None, name=None) 随机乱序的tensors创建batches，其中tensors_list参数为tensors元组或tensors字典的列表len(tensors_list)个线程将启动，线程i将tensors_list[i]的tensors入列tensors_list[i1][j]与tensors_list[i2][j]有相同的类型和shape# 一个简单例子，使用tf.train.shuffle_batch创建一个具有32张图像和32个标签的batches.image_batch, label_batch = tf.train.shuffle_batch( [single_image, single_label], batch_size=32, num_threads=4, capacity=50000, min_after_dequeue=10000)#Batching函数相关例子，以函数tf.train.shuffle_batch为例#为training, evaluation等操作将样本batching，以下代码使用随机顺序打包样本def read_my_file_format(filename_queue): reader = tf.SomeReader() key, record_string = reader.read(filename_queue) example, label = tf.some_decoder(record_string) processed_example = some_processing(example) return processed_example, labeldef input_pipeline(filenames, batch_size, num_epochs=None): filename_queue = tf.train.string_input_producer( filenames, num_epochs=num_epochs, shuffle=True) example, label = read_my_file_format(filename_queue) # min_after_dequeue defines how big a buffer we will randomly sample # from – bigger means better shuffling but slower start up and more # memory used. # capacity must be larger than min_after_dequeue and the amount larger # determines the maximum we will prefetch. Recommendation: # min_after_dequeue + (num_threads + a small safety margin) batch_size min_after_dequeue = 10000 capacity = min_after_dequeue + 3 batch_size example_batch, label_batch = tf.train.shuffle_batch( [example, label], batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue) return example_batch, label_batch#如果需要跟多的并行或文件之间的样本乱序操作，可以使用函数tf.train.shuffle_batch_join多实例化readerdef read_my_file_format(filename_queue): # 与上例子相同def input_pipeline(filenames, batch_size, read_threads, num_epochs=None): filename_queue = tf.train.string_input_producer( filenames, num_epochs=num_epochs, shuffle=True) example_list = [read_my_file_format(filenamequeue) for in range(read_threads)] min_after_dequeue = 10000 capacity = min_after_dequeue + 3 * batch_size example_batch, label_batch = tf.train.shuffle_batch_join( example_list, batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue) return example_batch, label_batch相关链接：[1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 [7] Tensorflow一些常用基本概念与函数（1） http://blog.csdn.net/lenbow/article/details/52152766 摘要：本系列主要对tf的一些常用概念与方法进行描述。本文主要针对tensorflow的数据IO、图的运行等相关函数进行讲解。为‘Tensorflow一些常用基本概念与函数’系列之三。1、序言本文所讲的内容主要为以下相关函数： 操作组 操作 Data IO (Python functions) TFRecordWrite，rtf_record_iterator Running Graphs Session management，Error classes2、tf函数2.1 数据IO {Data IO (Python functions)}一个TFRecords 文件为一个字符串序列。这种格式并非随机获取，它比较适合大规模的数据流，而不太适合需要快速分区或其他非序列获取方式。数据IO {Data IO (Python functions)} 操作 描述 class tf.python_io.TFRecordWriter 一个用于将记录(records)写入TFRecords文件的类 tf.python_io.TFRecordWriter.init(path, options=None) 打开文件路径，并创建一个TFRecordWriter以供写入 tf.python_io.TFRecordWriter.write(record) 将一个字符串records写入文件中 tf.python_io.TFRecordWriter.close() 关闭文件 tf.python_io.tf_record_iterator(path, options=None) 从TFRecords文件中读取记录的迭代器2.2 运行图(Running Graphs)会话管理 (Session management) 操作 描述 class tf.Session 运行TF操作的类,一个Session对象将操作节点op封装在一定的环境内运行，同时tensor对象将被计算求值 tf.Session.init(target=”, graph=None, config=None) 创建一个新的会话 tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None) 运行fetches中的操作节点并求其值 tf.Session.close() 关闭会话 tf.Session.graph 返回加载值该会话的图(graph) tf.Session.as_default() 设置该对象为默认会话，并返回一个上下文管理器 tf.Session.reset(target, containers=None, config=None) 重设target的资源容器，并关闭所有连接的会话在0.10版本该功能仅应用在分布会话中target:为执行引擎所连接的目标，其包含有资源容器，该资源容器分布在同一个集群的所有works上 class tf.InteractiveSession 使用在交互式上下文环境的tf会话，比如shell，ipython tf.InteractiveSession.close() 关闭一个InteractiveSession tf.get_default_session() 返回当前线程的默认会话tf.Session#一个简单的tf.Session例子# 建立一个graph.a = tf.constant(5.0)b = tf.constant(6.0)c = a b# 将graph载入到一个会话session中sess = tf.Session()# 计算tensor c.print(sess.run(c))#一个会话可能会占用一些资源，比如变量、队列和读取器(reader)。释放这些不再使用的资源非常重要。#使用close()方法关闭会话，或者使用上下文管理器，释放资源。# 使用close()方法.sess = tf.Session()sess.run(…)sess.close()# 使用上下文管理器with tf.Session() as sess: sess.run(…)tf.Session()的变量设置， ConfigProto protocol buffer为会话提供了不同的配置选项。比如，创建一个会话，对设备布局使用软约束条件，以及对分布# Launch the graph in a session that allows soft device placement and# logs the placement decisions.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))tf.Session.run a = tf.constant([10, 20]) b = tf.constant([1.0, 2.0]) # ‘fetches’ 可以为单个数 v = session.run(a) # v is the numpy array [10, 20] # ‘fetches’ 可以为一个list. v = session.run([a, b]) # v a Python list with 2 numpy arrays: the numpy array [10, 20] and the # 1-D array [1.0, 2.0] # ‘fetches’ 可以是 lists, tuples, namedtuple, dicts中的任意: MyData = collections.namedtuple(‘MyData’, [‘a’, ‘b’]) v = session.run({‘k1’: MyData(a, b), ‘k2’: [b, a]}) # v 为一个dict，并有 # v[‘k1’] is a MyData namedtuple with ‘a’ the numpy array [10, 20] and # ‘b’ the numpy array [1.0, 2.0] # v[‘k2’] is a list with the numpy array [1.0, 2.0] and the numpy array # [10, 20].tf.Session.as_default() 使用关键字with指定会话， 可以在会话中执行Operation.run()或Tensor.eval()，以得到运行的tensor结果c = tf.constant(..)sess = tf.Session()with sess.as_default(): assert tf.get_default_session() is sess print(c.eval())使用函数tf.get_default_session()来得到当前默认的会话 需要注意的是，退出该as_default上下文管理器时，并没有关闭该会话(session )，必须明确的关闭会话c = tf.constant(…)sess = tf.Session()with sess.as_default(): print(c.eval())# …with sess.as_default(): print(c.eval())#关闭会话sess.close()#使用 with tf.Session()方式可以创建并自动关闭会话tf.InteractiveSessionsess = tf.InteractiveSession()a = tf.constant(5.0)b = tf.constant(6.0)c = a b# 我们直接使用’c.eval()’ 而没有通过’sess’print(c.eval())sess.close()以上的例子，在非交互会话的版本中为，a = tf.constant(5.0)b = tf.constant(6.0)c = a * bwith tf.Session(): # We can also use ‘c.eval()’ here. print(c.eval())ABC错误类 (Error classes) 操作 描述 class tf.OpError 一个基本的错误类型，在当TF执行失败时候报错 tf.OpError.op 返回执行失败的操作节点，有的操作如Send或Recv可能不会返回，那就要用用到node_def方法 tf.OpError.node_def 以NodeDef proto形式表示失败的op tf.OpError.error_code 描述该错误的整数错误代码 tf.OpError.message 返回错误信息 class tf.errors.CancelledError 当操作或者阶段呗取消时候报错 class tf.errors.UnknownError 未知错误类型 class tf.errors.InvalidArgumentError 在接收到非法参数时候报错 class tf.errors.NotFoundError 当发现不存在所请求的一个实体时候，比如文件或目录 class tf.errors.AlreadyExistsError 当创建的实体已经存在的时候报错 class tf.errors.PermissionDeniedError 没有执行权限做某操作的时候报错 class tf.errors.ResourceExhaustedError 资源耗尽时报错 class tf.errors.FailedPreconditionError 系统没有条件执行某个行为时候报错 class tf.errors.AbortedError 操作中止时报错，常常发生在并发情形 class tf.errors.OutOfRangeError 超出范围报错 class tf.errors.UnimplementedError 某个操作没有执行时报错 class tf.errors.InternalError 当系统经历了一个内部错误时报出 class tf.errors.DataLossError 当出现不可恢复的错误例如在运行 tf.WholeFileReader.read()读取整个文件的同时文件被删减 tf.errors.XXXXX.init(node_def, op, message) 使用该形式方法创建以上各种错误类相关链接：[1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 [7] Tensorflow一些常用基本概念与函数（1） http://blog.csdn.net/lenbow/article/details/52152766 [8] Tensorflow一些常用基本概念与函数（2） http://blog.csdn.net/lenbow/article/details/52181159 摘要：本系列主要对tf的一些常用概念与方法进行描述。本文主要针对tensorflow的模型训练Training与测试Testing等相关函数进行讲解。为‘Tensorflow一些常用基本概念与函数’系列之四。1、序言本文所讲的内容主要为以下列表中相关函数。函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作，在训练过程中，先实例化一个优化函数，比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：optimizer = tf.train.GradientDescentOptimizer(learning_rate)然后，可以设置 一个用于记录全局训练步骤的单值。以及使用minimize()操作，该操作不仅可以优化更新训练的模型参数，也可以为全局步骤(global step)计数。与其他tensorflow操作类似，这些训练操作都需要在tf.session会话中进行global_step = tf.Variable(0, name=’global_step’, trainable=False)train_op = optimizer.minimize(loss, global_step=global_step) 操作组 操作 Training Optimizers，Gradient Computation，Gradient Clipping，Distributed execution Testing Unit tests，Utilities，Gradient checking2、Tensorflow函数2.1 训练 (Training)一个TFRecords 文件为一个字符串序列。这种格式并非随机获取，它比较适合大规模的数据流，而不太适合需要快速分区或其他非序列获取方式。█ 优化 (Optimizers)tf中各种优化类提供了为损失函数计算梯度的方法，其中包含比较经典的优化算法，比如GradientDescent 和Adagrad。▶▶class tf.train.Optimizer 操作 描述 class tf.train.Optimizer 基本的优化类，该类不常常被直接调用，而较多使用其子类，比如GradientDescentOptimizer, AdagradOptimizer或者MomentumOptimizer tf.train.Optimizer.init(use_locking, name) 创建一个新的优化器，该优化器必须被其子类(subclasses)的构造函数调用 tf.train.Optimizer.minimize(loss, global_step=None, var_list=None, gate_gradients=1, aggregation_method=None, colocate_gradients_with_ops=False, name=None, grad_loss=None) 添加操作节点，用于最小化loss，并更新var_list该函数是简单的合并了compute_gradients()与apply_gradients()函数返回为一个优化更新后的var_list，如果global_step非None，该操作还会为global_step做自增操作 tf.train.Optimizer.compute_gradients(loss,var_list=None, gate_gradients=1, aggregation_method=None, colocate_gradients_with_ops=False, grad_loss=None) 对var_list中的变量计算loss的梯度该函数为函数minimize()的第一部分，返回一个以元组(gradient, variable)组成的列表 tf.train.Optimizer.apply_gradients(grads_and_vars, global_step=None, name=None) 将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global_step做自增操作 tf.train.Optimizer.get_name() 获取名称▷ class tf.train.Optimizer 用法# Create an optimizer with the desired parameters.opt = GradientDescentOptimizer(learning_rate=0.1)# Add Ops to the graph to minimize a cost by updating a list of variables.# “cost” is a Tensor, and the list of variables contains tf.Variable objects.opt_op = opt.minimize(cost, var_list=&lt;list of variables&gt;)# Execute opt_op to do one step of training:opt_op.run()▶▶在使用它们之前处理梯度 使用minimize()操作，该操作不仅可以计算出梯度，而且还可以将梯度作用在变量上。如果想在使用它们之前处理梯度，可以按照以下三步骤使用optimizer ：1、使用函数compute_gradients()计算梯度2、按照自己的愿望处理梯度3、使用函数apply_gradients()应用处理过后的梯度例如：# 创建一个optimizer.opt = GradientDescentOptimizer(learning_rate=0.1)# 计算&lt;list of variables&gt;相关的梯度grads_and_vars = opt.compute_gradients(loss, &lt;list of variables&gt;)# grads_and_vars为tuples (gradient, variable)组成的列表。#对梯度进行想要的处理，比如cap处理capped_grads_and_vars = [(MyCapper(gv[0]), gv[1]) for gv in grads_and_vars]# 令optimizer运用capped的梯度(gradients)opt.apply_gradients(capped_grads_and_vars)▶▶选通梯度(Gating Gradients) 函数minimize() 与compute_gradients()都含有一个参数gate_gradient，用于控制在应用这些梯度时并行化的程度。其值可以取：GATE_NONE, GATE_OP 或 GATE_GRAPH GATE_NONE : 并行地计算和应用梯度。提供最大化的并行执行，但是会导致有的数据结果没有再现性。比如两个matmul操作的梯度依赖输入值，使用GATE_NONE可能会出现有一个梯度在其他梯度之前便应用到某个输入中，导致出现不可再现的(non-reproducible)结果 GATE_OP: 对于每个操作Op，确保每一个梯度在使用之前都已经计算完成。这种做法防止了那些具有多个输入，并且梯度计算依赖输入情形中，多输入Ops之间的竞争情况出现。 GATE_GRAPH: 确保所有的变量对应的所有梯度在他们任何一个被使用前计算完成。该方式具有最低级别的并行化程度，但是对于想要在应用它们任何一个之前处理完所有的梯度计算时很有帮助的。█ Slots一些optimizer的之类，比如 MomentumOptimizer 和 AdagradOptimizer 分配和管理着额外的用于训练的变量。这些变量称之为’Slots’，Slots有相应的名称，可以向optimizer访问的slots名称。有助于在log debug一个训练算法以及报告slots状态 操作 描述 tf.train.Optimizer.get_slot_names() 返回一个由Optimizer所创建的slots的名称列表 tf.train.Optimizer.get_slot(var, name) 返回一个name所对应的slot，name是由Optimizer为var所创建var为用于传入 minimize() 或 apply_gradients()的变量 class tf.train.GradientDescentOptimizer 使用梯度下降算法的Optimizer tf.train.GradientDescentOptimizer.init(learning_rate, use_locking=False, name=’GradientDescent’) 构建一个新的梯度下降优化器(Optimizer) class tf.train.AdadeltaOptimizer 使用Adadelta算法的Optimizer tf.train.AdadeltaOptimizer.init(learning_rate=0.001, rho=0.95, epsilon=1e-08, use_locking=False, name=’Adadelta’) 创建Adadelta优化器 class tf.train.AdagradOptimizer 使用Adagrad算法的Optimizer tf.train.AdagradOptimizer.init(learning_rate, initial_accumulator_value=0.1, use_locking=False, name=’Adagrad’) 创建Adagrad优化器 class tf.train.MomentumOptimizer 使用Momentum算法的Optimizer tf.train.MomentumOptimizer.init(learning_rate, momentum, use_locking=False, name=’Momentum’, use_nesterov=False) 创建momentum优化器momentum：动量，一个tensor或者浮点值 class tf.train.AdamOptimizer 使用Adam 算法的Optimizer tf.train.AdamOptimizer.init(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name=’Adam’) 创建Adam优化器 class tf.train.FtrlOptimizer 使用FTRL 算法的Optimizer tf.train.FtrlOptimizer.init(learning_rate, learning_rate_power=-0.5, initial_accumulator_value=0.1, l1_regularization_strength=0.0, l2_regularization_strength=0.0, use_locking=False, name=’Ftrl’) 创建FTRL算法优化器 class tf.train.RMSPropOptimizer 使用RMSProp算法的Optimizer tf.train.RMSPropOptimizer.init(learning_rate, decay=0.9, momentum=0.0, epsilon=1e-10, use_locking=False, name=’RMSProp’) 创建RMSProp算法优化器▷ tf.train.AdamOptimizer Adam 的基本运行方式，首先初始化：m_0 &lt;- 0 (Initialize initial 1st moment vector)v_0 &lt;- 0 (Initialize initial 2nd moment vector)t &lt;- 0 (Initialize timestep)在论文中的 section2 的末尾所描述了更新规则，该规则使用梯度g来更新变量：t &lt;- t + 1lr_t &lt;- learning_rate sqrt(1 - beta2^t) / (1 - beta1^t)m_t &lt;- beta1 m_{t-1} + (1 - beta1) gv_t &lt;- beta2 v_{t-1} + (1 - beta2) g gvariable &lt;- variable - lr_t m_t / (sqrt(v_t) + epsilon)其中epsilon 的默认值1e-8可能对于大多数情况都不是一个合适的值。例如，当在ImageNet上训练一个 Inception network时比较好的选择为1.0或者0.1。 需要注意的是，在稠密数据中即便g为0时， m_t, v_t 以及variable都将会更新。而在稀疏数据中，m_t, v_t 以及variable不被更新且值为零。█ 梯度计算与截断(Gradient Computation and Clipping)TensorFlow 提供了计算给定tf计算图的求导函数，并在图的基础上增加节点。优化器(optimizer )类可以自动的计算网络图的导数，但是优化器中的创建器(creators )或者专业的人员可以通过本节所述的函数调用更底层的方法。 操作 描述 tf.gradients(ys, xs, grad_ys=None, name=’gradients’, colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None) 构建一个符号函数，计算ys关于xs中x的偏导的和，返回xs中每个x对应的sum(dy/dx) tf.stop_gradient(input, name=None) 停止计算梯度，在EM算法、Boltzmann机等可能会使用到 tf.clip_by_value(t, clip_value_min, clip_value_max, name=None) 基于定义的min与max对tesor数据进行截断操作，目的是为了应对梯度爆发或者梯度消失的情况 tf.clip_by_norm(t, clip_norm, axes=None, name=None) 使用L2范式标准化tensor最大值为clip_norm返回 t clip_norm / l2norm(t) tf.clip_by_average_norm(t, clip_norm, name=None) 使用平均L2范式规范tensor数据t，并以clip_norm为最大值返回 t clip_norm / l2norm_avg(t) tf.clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None) 返回t_list[i] clip_norm / max(global_norm, clip_norm)其中global_norm = sqrt(sum([l2norm(t)2 for t in t_list])) tf.global_norm(t_list, name=None) 返回global_norm = sqrt(sum([l2norm(t)2 for t in t_list]))█ 退化学习率(Decaying the learning rate) 操作 描述 tf.train.exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None) 对学习率进行指数衰退▷ tf.train.exponential_decay#该函数返回以下结果decayed_learning_rate = learning_rate decay_rate ^ (global_step / decay_steps)##例： 以0.96为基数，每100000 步进行一次学习率的衰退global_step = tf.Variable(0, trainable=False)starter_learning_rate = 0.1learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 100000, 0.96, staircase=True)# Passing global_step to minimize() will increment it at each step.learning_step = ( tf.train.GradientDescentOptimizer(learning_rate) .minimize(…my loss…, global_step=global_step))█ 移动平均(Moving Averages)一些训练优化算法，比如GradientDescent 和Momentum 在优化过程中便可以使用到移动平均方法。使用移动平均常常可以较明显地改善结果。 操作 描述 class tf.train.ExponentialMovingAverage 将指数衰退加入到移动平均中 tf.train.ExponentialMovingAverage.apply(var_list=None) 对var_list变量保持移动平均 tf.train.ExponentialMovingAverage.average_name(var) 返回var均值的变量名称 tf.train.ExponentialMovingAverage.average(var) 返回var均值变量 tf.train.ExponentialMovingAverage.variables_to_restore(moving_avg_variables=None) 返回用于保存的变量名称的映射▷ tf.train.ExponentialMovingAverage# Example usage when creating a training model:# Create variables.var0 = tf.Variable(…)var1 = tf.Variable(…)# … use the variables to build a training model……# Create an op that applies the optimizer. This is what we usually# would use as a training op.opt_op = opt.minimize(my_loss, [var0, var1])# Create an ExponentialMovingAverage objectema = tf.train.ExponentialMovingAverage(decay=0.9999)# Create the shadow variables, and add ops to maintain moving averages# of var0 and var1.maintain_averages_op = ema.apply([var0, var1])# Create an op that will update the moving averages after each training# step. This is what we will use in place of the usual training op.with tf.control_dependencies([opt_op]): training_op = tf.group(maintain_averages_op)…train the model by running training_op…#Example of restoring the shadow variable values:# Create a Saver that loads variables from their saved shadow values.shadow_var0_name = ema.average_name(var0)shadow_var1_name = ema.average_name(var1)saver = tf.train.Saver({shadow_var0_name: var0, shadow_var1_name: var1})saver.restore(…checkpoint filename…)# var0 and var1 now hold the moving average values▷ tf.train.ExponentialMovingAverage.variables_to_restore variables_to_restore = ema.variables_to_restore() saver = tf.train.Saver(variables_to_restore)█ 协调器和队列运行器(Coordinator and QueueRunner)查看queue中，queue相关的内容，了解tensorflow中队列的运行方式。 操作 描述 class tf.train.Coordinator 线程的协调器 tf.train.Coordinator.clear_stop() 清除停止标记 tf.train.Coordinator.join(threads=None, stop_grace_period_secs=120) 等待线程终止threads:一个threading.Threads的列表，启动的线程，将额外加入到registered的线程中 tf.train.Coordinator.register_thread(thread) Register一个用于join的线程 tf.train.Coordinator.request_stop(ex=None) 请求线程结束 tf.train.Coordinator.should_stop() 检查是否被请求停止 tf.train.Coordinator.stop_on_exception() 上下文管理器，当一个例外出现时请求停止 tf.train.Coordinator.wait_for_stop(timeout=None) 等待Coordinator提示停止进程 class tf.train.QueueRunner 持有一个队列的入列操作列表，用于线程中运行queue:一个队列enqueue_ops: 用于线程中运行的入列操作列表 tf.train.QueueRunner.create_threads(sess, coord=None, daemon=False, start=False) 创建运行入列操作的线程，返回一个线程列表 tf.train.QueueRunner.from_proto(queue_runner_def) 返回由queue_runner_def创建的QueueRunner对象 tf.train.add_queue_runner(qr, collection=’queue_runners’) 增加一个QueueRunner到graph的收集器(collection )中 tf.train.start_queue_runners(sess=None, coord=None, daemon=True, start=True, collection=’queue_runners’) 启动所有graph收集到的队列运行器(queue runners)▷ class tf.train.Coordinator#Coordinator的使用，用于多线程的协调try: … coord = Coordinator() # Start a number of threads, passing the coordinator to each of them. …start thread 1...(coord, …) …start thread N…(coord, …) # Wait for all the threads to terminate, give them 10s grace period coord.join(threads, stop_grace_period_secs=10)except RuntimeException: …one of the threads took more than 10s to stop after request_stop() …was called.except Exception: …exception that was passed to coord.request_stop()▷ tf.train.Coordinator.stop_on_exception()with coord.stop_on_exception(): # Any exception raised in the body of the with # clause is reported to the coordinator before terminating # the execution of the body. …body…#等价于try: …body…exception Exception as ex: coord.request_stop(ex)█ 布执行(Distributed execution)可以阅读TensorFlow的分布式学习框架简介 查看更多tensorflow分布式细节。 操作 描述 class tf.train.Server 一个进程内的tensorflow服务，用于分布式训练 tf.train.Server.init(server_or_cluster_def, job_name=None, task_index=None, protocol=None, config=None, start=True) 创建一个新的服务，其中job_name, task_index, 和protocol为可选参数，优先级高于server_or_cluster_def中相关信息server_or_cluster_def : 为一个tf.train.ServerDef 或 tf.train.ClusterDef 协议(protocol)的buffer，或者一个tf.train.ClusterSpec对象 tf.train.Server.create_local_server(config=None, start=True) 创建一个新的运行在本地主机的单进程集群 tf.train.Server.target 返回tf.Session所连接的目标服务器 tf.train.Server.server_def 返回该服务的tf.train.ServerDef tf.train.Server.start() 开启服务 tf.train.Server.join() 阻塞直到服务已经关闭 # class tf.train.Supervisor 一个训练辅助器，用于checkpoints模型以及计算的summaries。该监视器只是一个小的外壳(wrapper),用于Coordinator, a Saver, 和a SessionManager周围 tf.train.Supervisor.init(graph=None, ready_op=0, is_chief=True, init_op=0, init_feed_dict=None, local_init_op=0, logdir=None, summary_op=0, saver=0, global_step=0, save_summaries_secs=120, save_model_secs=600, recovery_wait_secs=30, stop_grace_secs=120, checkpoint_basename=’model.ckpt’, session_manager=None, summary_writer=0, init_fn=None) 创建一个监视器Supervisor tf.train.Supervisor.managed_session(master=”, config=None, start_standard_services=True, close_summary_writer=True) 返回一个管路session的上下文管理器 tf.train.Supervisor.prepare_or_wait_for_session(master=”, config=None, wait_for_checkpoint=False, max_wait_secs=7200, start_standard_services=True) 确保model已经准备好 tf.train.Supervisor.start_standard_services(sess) 为sess启动一个标准的服务 tf.train.Supervisor.start_queue_runners(sess, queue_runners=None) 为QueueRunners启动一个线程，queue_runners为一个QueueRunners列表 tf.train.Supervisor.summary_computed(sess, summary, global_step=None) 指示计算的summary tf.train.Supervisor.stop(threads=None, close_summary_writer=True) 停止服务以及协调器(coordinator),并没有关闭session tf.train.Supervisor.request_stop(ex=None) 参考Coordinator.request_stop() tf.train.Supervisor.should_stop() 参考Coordinator.should_stop() tf.train.Supervisor.stop_on_exception() 参考 Coordinator.stop_on_exception() tf.train.Supervisor.Loop(timer_interval_secs, target, args=None, kwargs=None) 开启一个循环器线程用于调用一个函数每经过timer_interval_secs秒执行，target(args, *kwargs) tf.train.Supervisor.coord 返回监督器(Supervisor)使用的协调器(Coordinator ) # class tf.train.SessionManager 训练的辅助器，用于从checkpoint恢复数据以及创建一个session tf.train.SessionManager.init(local_init_op=None, ready_op=None, graph=None, recovery_wait_secs=30) 创建一个SessionManager tf.train.SessionManager.prepare_session(master, init_op=None, saver=None, checkpoint_dir=None, wait_for_checkpoint=False, max_wait_secs=7200, config=None, init_feed_dict=None, init_fn=None) 创建一个session，并确保model可以被使用 tf.train.SessionManager.recover_session(master, saver=None, checkpoint_dir=None, wait_for_checkpoint=False, max_wait_secs=7200, config=None) 创建一个session，如果可以的话，使用恢复方法创建 tf.train.SessionManager.wait_for_session(master, config=None, max_wait_secs=inf) 创建一个session，并等待model准备完成 # class tf.train.ClusterSpec 将一个集群表示为一系列“tasks”，并整合至“jobs”中 tf.train.ClusterSpec.as_cluster_def() 返回该cluster中一个tf.train.ClusterDef协议的buffer tf.train.ClusterSpec.as_dict() 返回一个字典，由job名称对应于网络地址 tf.train.ClusterSpec.job_tasks(job_name) 返回一个给定的job对应的task列表 tf.train.ClusterSpec.jobs 返回该cluster的job名称列表 tf.train.replica_device_setter(ps_tasks=0, ps_device=’/job:ps’, worker_device=’/job:worker’, merge_devices=True, cluster=None, ps_ops=None) 返回一个设备函数(device function)，以在建立一个副本graph的时候使用，设备函数(device function)用在with tf.device(device_function)中▷ tf.train.Serverserver = tf.train.Server(…)with tf.Session(server.target): # …▷ tf.train.Supervisor 相关参数： ready_op : 一维 字符串 tensor。该tensor是用过监视器在prepare_or_wait_for_session()计算，检查model是否准备好可以使用。如果准备好，将返回一个空阵列，如果为None，该model没有被检查。 is_chief : 如果为True，创建一个主监视器用于负责初始化与模型的恢复，若为False，则依赖主监视器。 init_op : 一个操作，用于模型不能恢复时的初始化操作。默认初始化所有操作 local_init_op : 可被所有监视器运行的初始化操作。 logdir : 设置log目录 summary_op : 一个操作(Operation )，返回Summary 和事件logs，需要设置 logdir saver : 一个Saver对象 save_summaries_secs : 保存summaries的间隔秒数 save_model_secs : 保存model的间隔秒数 checkpoint_basename : checkpoint保存的基本名称使用在单进程中with tf.Graph().as_default(): …add operations to the graph… # Create a Supervisor that will checkpoint the model in ‘/tmp/mydir’. sv = Supervisor(logdir=‘/tmp/mydir’) # Get a TensorFlow session managed by the supervisor. with sv.managed_session(FLAGS.master) as sess: # Use the session to train the graph. while not sv.should_stop(): sess.run(&lt;my_train_op&gt;)# 在上下文管理器with sv.managed_session()内，所有在graph的变量都被初始化。# 或者说，一些服务器checkpoint相应模型并增加summaries至事件log中。# 如果有例外发生，should_stop()将返回True使用在多副本运行情况中 要使用副本训练已经部署在集群上的相同程序，必须指定其中一个task为主要，该task处理 initialization, checkpoints, summaries, 和recovery相关事物。其他task依赖该task。# Choose a task as the chief. This could be based on server_def.task_index,# or job_def.name, or job_def.tasks. It’s entirely up to the end user.# But there can be only one chief*.is_chief = (server_def.task_index == 0)server = tf.train.Server(server_def)with tf.Graph().as_default(): …add operations to the graph… # Create a Supervisor that uses log directory on a shared file system. # Indicate if you are the ‘chief’ sv = Supervisor(logdir=‘/shared_directory/…’, is_chief=is_chief) # Get a Session in a TensorFlow server on the cluster. with sv.managed_session(server.target) as sess: # Use the session to train the graph. while not sv.should_stop(): sess.run(&lt;my_train_op&gt;)如果有task崩溃或重启，managed_session() 将检查是否Model被初始化。如果已经初始化，它只需要创建一个session并将其返回至正在训练的正常代码中。如果model需要被初始化，主task将对它进行重新初始化，而其他task将等待模型初始化完成。 注意：该程序方法一样适用于单进程的work，该单进程标注自己为主要的便行▷ supervisor中master的字符串形式 无论运行在本机或者集群上，都可以使用以下值设定master flag：定义为 ” ，要求一个进程内且没有使用RPC的session定义为 ‘local’，要求一个使用基于RPC的主服务接口(“Master interface” )的session来运行tensorflow程序。更多细节可以查看 tf.train.Server.create_local_server()相关内容。定义为 ‘grpc://hostname:port’，要求一个指定的RPC接口的session，同时运行内部进程的master接入远程的tensorflow workers。可用server.target返回该形式▷ supervisor高级用法启动额外的服务 managed_session()启动了 Checkpoint 和Summary服务。如果需要运行更多的服务，可以在managed_session()控制的模块中启动他们。#例如： 开启一个线程用于打印loss. 设置每60秒该线程运行一次，我们使用sv.loop() … sv = Supervisor(logdir=‘/tmp/mydir’) with sv.managed_session(FLAGS.master) as sess: sv.loop(60, print_loss, (sess)) while not sv.should_stop(): sess.run(my_train_op)启动更少的的服务 managed_session() 启动了 “summary” 和 “checkpoint” 线程，这些线程通过构建器或者监督器默认自动创建了summary_op 和saver操作。如果想运行自己的 summary 和checkpointing方法，关闭这些服务，通过传递None值给summary_op 和saver参数。在chief中每100个step，创建summaries # Create a Supervisor with no automatic summaries. sv = Supervisor(logdir=‘/tmp/mydir’, is_chief=is_chief, summary_op=None) # As summary_op was None, managed_session() does not start the # summary thread. with sv.managed_session(FLAGS.master) as sess: for step in xrange(1000000): if sv.should_stop(): break if is_chief and step % 100 == 0: # Create the summary every 100 chief steps. sv.summary_computed(sess, sess.run(my_summary_op)) else: # Train normally sess.run(my_train_op)▷ tf.train.Supervisor.managed_sessiondef train(): sv = tf.train.Supervisor(…) with sv.managed_session(&lt;master&gt;) as sess: for step in xrange(..): if sv.should_stop(): break sess.run(&lt;my training op&gt;) …do other things needed at each training step…▷ tf.train.SessionManagerwith tf.Graph().as_default(): …add operations to the graph… # Create a SessionManager that will checkpoint the model in ‘/tmp/mydir’. sm = SessionManager() sess = sm.prepare_session(master, init_op, saver, checkpoint_dir) # Use the session to train the graph. while True: sess.run(&lt;my_train_op&gt;)#其中prepare_session()初始化和恢复一个模型参数。 #另一个进程将等待model准备完成，代码如下with tf.Graph().as_default(): …add operations to the graph… # Create a SessionManager that will wait for the model to become ready. sm = SessionManager() sess = sm.wait_for_session(master) # Use the session to train the graph. while True: sess.run(&lt;my_train_op&gt;)#wait_for_session()等待一个model被其他进程初始化▷ tf.train.ClusterSpec 一个tf.train.ClusterSpec表示一系列的进程，这些进程都参与分布式tensorflow的计算。每一个 tf.train.Server都在一个独有的集群中构建。 创建一个具有两个jobs及其5个tasks的集群们需要定义从job名称列表到网络地址列表之间的映射。cluster = tf.train.ClusterSpec({“worker”: [“worker0.example.com:2222”, “worker1.example.com:2222”, “worker2.example.com:2222”], “ps”: [“ps0.example.com:2222”, “ps1.example.com:2222”]})▷ tf.train.replica_device_setter# To build a cluster with two ps jobs on hosts ps0 and ps1, and 3 worker# jobs on hosts worker0, worker1 and worker2.cluster_spec = { “ps”: [“ps0:2222”, “ps1:2222”], “worker”: [“worker0:2222”, “worker1:2222”, “worker2:2222”]}with tf.device(tf.replica_device_setter(cluster=cluster_spec)): # Build your graph v1 = tf.Variable(…) # assigned to /job:ps/task:0 v2 = tf.Variable(…) # assigned to /job:ps/task:1 v3 = tf.Variable(…) # assigned to /job:ps/task:0# Run compute█ 汇总操作(Summary Operations)我们可以在一个session中获取summary操作的输出，并将其传输到SummaryWriter以添加至一个事件记录文件中。 操作 描述 tf.scalar_summary(tags, values, collections=None, name=None) 输出一个标量值的summary协议buffertag的shape需要与values的相同，用来做summaries的tags，为字符串 tf.image_summary(tag, tensor, max_images=3, collections=None, name=None) 输出一个图像tensor的summary协议buffer tf.audio_summary(tag, tensor, sample_rate, max_outputs=3, collections=None, name=None) 输出一个音频tensor的summary协议buffer tf.histogram_summary(tag, values, collections=None, name=None) 输出一个直方图的summary协议buffer tf.nn.zero_fraction(value, name=None) 返回0在value中的小数比例 tf.merge_summary(inputs, collections=None, name=None) 合并summary tf.merge_all_summaries(key=’summaries’) 合并在默认graph中手机的summaries▶▶将记录汇总写入文件中(Adding Summaries to Event Files) 操作 描述 class tf.train.SummaryWriter 将summary协议buffer写入事件文件中 tf.train.SummaryWriter.init(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None) 创建一个SummaryWriter实例以及新建一个事件文件 tf.train.SummaryWriter.add_summary(summary, global_step=None) 将一个summary添加到事件文件中 tf.train.SummaryWriter.add_session_log(session_log, global_step=None) 添加SessionLog到一个事件文件中 tf.train.SummaryWriter.add_event(event) 添加一个事件到事件文件中 tf.train.SummaryWriter.add_graph(graph, global_step=None, graph_def=None) 添加一个Graph到时间文件中 tf.train.SummaryWriter.add_run_metadata(run_metadata, tag, global_step=None) 为一个单一的session.run()调用添加一个元数据信息 tf.train.SummaryWriter.flush() 刷新时间文件到硬盘中 tf.train.SummaryWriter.close() 将事件问价写入硬盘中并关闭该文件 tf.train.summary_iterator(path) 一个用于从时间文件中读取时间协议buffer的迭代器▷ tf.train.SummaryWriter 创建一个SummaryWriter 和事件文件。如果我们传递一个Graph进入该构建器中，它将被添加到事件文件当中，这一点与使用add_graph()具有相同功能。 TensorBoard 将从事件文件中提取该graph，并将其显示。所以我们能直观地看到我们建立的graph。我们通常从我们启动的session中传递graph：…create a graph…# Launch the graph in a session.sess = tf.Session()# Create a summary writer, add the ‘graph’ to the event file.writer = tf.train.SummaryWriter(&lt;some-directory&gt;, sess.graph)▷ tf.train.summary_iterator#打印时间文件中的内容for e in tf.train.summary_iterator(path to events file): print(e)#打印指定的summary值# This example supposes that the events file contains summaries with a# summary value tag ‘loss’. These could have been added by calling# add_summary(), passing the output of a scalar summary op created with# with: tf.scalar_summary([&#39;loss&#39;], loss_tensor).for e in tf.train.summary_iterator(path to events file): for v in e.summary.value: if v.tag == ‘loss’: print(v.simple_value)█ 训练的通用函数及其他(Training utilities) 操作 描述 tf.train.global_step(sess, global_step_tensor) 一个用于获取全局step的小辅助器 tf.train.write_graph(graph_def, logdir, name, as_text=True) 将一个graph proto写入一个文件中 # :— class tf.train.LooperThread 可重复地执行代码的线程 tf.train.LooperThread.init(coord, timer_interval_secs, target=None, args=None, kwargs=None) 创建一个LooperThread tf.train.LooperThread.is_alive() 返回是否该线程是活跃的 tf.train.LooperThread.join(timeout=None) 等待线程结束 tf.train.LooperThread.loop(coord, timer_interval_secs, target, args=None, kwargs=None) 启动一个LooperThread，用于周期地调用某个函数调用函数target(args) tf.py_func(func, inp, Tout, stateful=True, name=None) 将python函数包装成tf中操作节点▷ tf.train.global_step# Creates a variable to hold the global_step.global_step_tensor = tf.Variable(10, trainable=False, name=‘global_step’)# Creates a session.sess = tf.Session()# Initializes the variable.sess.run(global_step_tensor.initializer)print(‘global_step: %s’ % tf.train.global_step(sess, global_step_tensor))global_step: 10▷ tf.train.write_graphv = tf.Variable(0, name=‘my_variable’)sess = tf.Session()tf.train.write_graph(sess.graph_def, ‘/tmp/my-model’, ‘train.pbtxt’)▷ tf.py_func#tf.py_func(func, inp, Tout, stateful=True, name=None)#func：为一个python函数#inp：为输入函数的参数，Tensor列表#Tout： 指定func返回的输出的数据类型，是一个列表def my_func(x): # x will be a numpy array with the contents of the placeholder below return np.sinh(x)inp = tf.placeholder(tf.float32, […])y = py_func(my_func, [inp], [tf.float32])2.2 测试 (Testing)TensorFlow 提供了一个方便的继承unittest.TestCase类的方法，该类增加有关TensorFlow 测试的方法。如下例子：import tensorflow as tfclass SquareTest(tf.test.TestCase): def testSquare(self): with self.test_session(): x = tf.square([2, 3]) self.assertAllEqual(x.eval(), [4, 9])if name == ‘main‘: tf.test.main()█ 共用(Utilities) 操作 描述 tf.test.main() 运行所有的单元测试 tf.test.assert_equal_graph_def(actual, expected) 断言 两个GraphDefs 是否几乎一样 tf.test.get_temp_dir() 返回测试期间使用的临时目录 tf.test.is_built_with_cuda() 返回是否Tensorflow支持CUDA(GPU)的build█ 梯度检查(Gradient checking)可对比compute_gradient 和compute_gradient_error函数的用法 操作 描述 tf.test.compute_gradient(x, x_shape, y, y_shape, x_init_value=None, delta=0.001, init_targets=None) 计算并返回理论的和数值的Jacobian矩阵 tf.test.compute_gradient_error(x, x_shape, y, y_shape, x_init_value=None, delta=0.001, init_targets=None) 计算梯度的error。在计算所得的与数值估计的Jacobian中 为dy/dx计算最大的error相关链接：[1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 [7] Tensorflow一些常用基本概念与函数（1） http://blog.csdn.net/lenbow/article/details/52152766 [8] Tensorflow一些常用基本概念与函数（2） http://blog.csdn.net/lenbow/article/details/52181159 [9] Tensorflow一些常用基本概念与函数（3） http://blog.csdn.net/lenbow/article/details/52213105","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"这一年来，数据科学家都用了哪些算法玩转人工智能？","date":"2017-02-13T00:40:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/Resources/benchmark-of-machine-learning/","text":"新智元mp论文作者：Shaohuai Shi, Qiang Wang, Pengfei Xu, Xiaowen Chu译者：吴博, Elaine, Melody 【新智元导读】新年伊始，新智元向你推荐香港浸会大学计算机学院褚晓文团队最新论文《基准评测当前最先进的深度学习软件工具》，评测了 Caffe、CNTK、MXNet、TensorFlow、Torch 这五个最受欢迎的DL框架在 FCN、CNN、RNN 上的表现。这是伯克利RISE实验室大牛、RISC之父 David Patterson 也在关注的深度学习库评测。论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。【进入新智元公众号，在对话框输入“0128”下载论文】 在2016年推出深度学习工具评测的褚晓文团队，赶在猴年最后一天，在arXiv.org上发布了最新的评测版本。这份评测的初版，通过国内AI自媒体的传播，在国内业界影响很大。在学术界，其反响更是非同一般。褚晓文教授在1月5日的朋友圈说David Patterson发邮件咨询他文章细节，感慨老人家论文看得仔细。 David Patterson在体系结构领域的名声如雷贯耳，RISC之父。不熟悉的吃瓜群众可能留意到1月25日蚂蚁金服宣布跟伯克利大学前身为AmpLab，更名为RISE实验室合作的新闻。David Patterson就是RISE实验室的顶梁大佬之一。 褚晓文教授最新版本的论文对Caffe、CNTK、MXNet、TensorFlow、Torch进行比较评测。在两个CPU平台、三个GPU平台下，比较这五个深度学习库在三类流行深度神经网络(FCN、CNN、RNN)上的性能表现。并对它们在单机多GPU卡环境下分布式版本进行了比较。相比以前的评测，最新的评测添加了对多GPU卡的测试，把MXNet纳入评比范围，还测试了MNIST和Cifar10这两个真实数据集。 《基准评测当前最先进的深度学习软件工具》 ## 1. 简介 在过去十年中，深度学习已成功应用到不同领域，包括计算机视觉、语音识别和自然语言处理等。深度学习的成功，归因于许多层人工神经元对输入数据的高表征能力。而GPU通过显著缩短训练时间，在深度学习的成功中扮演着重要的角色。为了提高开发深度学习方法的效率，有很多开源的深度学习工具包，包括伯克利大学的Caffe，微软的CNTK，谷歌的TensorFlow，还有Torch，MXNet，Theano，百度的 PaddlePaddle等。这些工具都支持多核CPU和超多核GPU。 深度学习的主要任务之一，是学习网络的每一层的权重，这可以通过向量或矩阵运算来实现。TensorFlow使用 Eigen作为矩阵加速库，而 Caffe、CNTK、MXNet和Torch采用OpenBLAS、Intel MKL 或 cuBLAS 来加快相关矩阵运算。所有这些工具包都引入了cuDNN，这是一个为神经网络计算进行GPU加速的深度学习库。但是，由于优化方法的差异，加上不同类型的网络或使用不同类型的硬件，上述工具包的性能差异很大。 鉴于深度学习软件工具及其底层硬件平台的多样化，终端用户难以选择合适的平台来执行深度学习任务。在此论文中，作者用三种最主要的深度神经网络（全连接神经网络FCN，卷积神经网络CNN，以及循环神经网络RNN）来基准评测当下最先进的基于GPU加速的深度学习工具（包括Caffe，CNTK， MXNet， TensorFlow 和Torch），比较它们在CPU和GPU上的运行时间性能。 几个工具的性能评估既针对合成数据，也针对真实数据。评测的硬件平台包括两种CPU（台式机级别的英特尔i7-3820 CPU，服务器级别的英特尔Xeon E5-2630 CPU）和三种Nvidia GPU (GTX 980、GTX 1080、Telsa K80，分别是Maxwell、Pascal和Kepler 架构)。作者也用两个Telsa K80卡（总共4个GK210 GPU）来评估多GPU卡并行的性能。每种神经网络类型均选择了一个小型网络和大型网络。 该评测的主要发现可概括如下： 总体上，多核CPU的性能并无很好的可扩展性。在很多实验结果中，使用16核CPU的性能仅比使用4核或8核稍好。TensorFlow在CPU环境有相对较好的可扩展性。 仅用一块GPU卡的话，FCN上Caffe、CNTK和Torch比MXNet和TensorFlow表现更好；CNN上MXNet表现出色，尤其是在大型网络时；而Caffe和CNTK在小型CNN上同样表现不俗；对于带LSTM的RNN，CNTK速度最快，比其他工具好上5到10倍。 通过将训练数据并行化，这些支持多GPU卡的深度学习工具，都有可观的吞吐量提升，同时收敛速度也提高了。多GPU卡环境下，CNTK平台在FCN和AlexNet上的可扩展性更好，而MXNet和Torch在CNN上相当出色。 比起多核CPU，GPU平台效率更高。所有的工具都能通过使用GPU达到显著的加速。 在三个GPU平台中，GTX1080由于其计算能力最高，在大多数实验结果中性能最出色。 某种程度上而言，性能也受配置文件的影响。例如，CNTK允许用户调整系统配置文件，在运算效率和GPU内存间取舍，而MXNet则能让用户对cuDNN库的自动设置进行调整。 ## 2. 背景及相关知识 随着深度学习技术的快速发展，人们针对不同的应用场合开发出各类深度神经网络，包括全连接神经网络(FCN)、卷积神经网络(CNN)、循环神经网络(RNN)、局限型波兹曼机(RBM)。此论文着重分析三种神经网络（FCN、CNN和RNN）的运行性能（或时间速度）及收敛速度。 FCN的历史可追溯到上世纪80年代，反向传播算法（backpropagation）发明之时。而CNN和RNN，一直以来分别在图像识别和自然语言处理应用上展现出优异的效果。 FCN是一个前向神经网络，由Yann LeCun等人在1989年成功应用于邮编识别。为了减少每一层的参数数量，CNN通过使用一组核(kernel)，建立了一个卷积层，每个核的参数在整个域（例如：一个彩色图像的通道）共享。CNN能减轻全连接层容易导致需要学习大量参数的问题。从LeNet架构开始，CNN已经实现很多成果，包括ImageNet分类、人脸识别和目标检测。 RNN允许网络单元的循环连接。RNN可以将整个历史输入序列跟每个输出相连，找到输入的上下文特性和输出之间的关系。有了这个特性，RNN可以保留之前输入的信息，类似于样本训练时的记忆功能。此外，长短时记忆（LSTM）通过适当地记录和丢弃信息，能解决RNN训练时梯度消失和爆炸的难题。含LSTM单元的RNN被证实是处理语音辨识和自然语言处理任务最有效的方法之一。 随着深度学习日益成功，诞生了许多受欢迎的开源GPU加速工具包。其中，Caffe、CNTK、MXNet、TensorFlow和Torch是最活跃、最受欢迎的例子。 Caffe由伯克利视觉和学习中心（BVLC）开发，自2014成为开源项目。作者声称Caffe可以借助NVIDIA K40或Titan GP卡，每天用GPU加速版本处理4000万图像。结合cuDNN之后，还可以加速约1.3倍。 CNTK是一个由微软研究院开发的工具包，支持大部分流行的神经网络。在2015年2月，官方报道了一个基准性能测试结果，针对一个4层全连接神经网络，CNTK与Caffe、TensorFlow、Theano和Torch对比，速度要快上1.5倍。 MXNet是一个支持多种语言的深度学习框架，旨在提供更灵活有效的编程接口，以提升生产效率。 TensorFlow由谷歌开发，它使用数据流图集成了深度学习框架中最常见的单元。它支持许多最新的网络如CNN，以及带不同设置的RNN。TensorFlow是为超凡的灵活性、轻便性和高效率而设计的。 Torch是一个科学计算框架，它为机器学习里最为有用的元件——如多维张量——提供数据结构。 (a) 全连接神经网络 (b) 卷积神经网络(AlexNet) (c) 循环神经网络 图1：深度学习模型的例子 为了加快深度神经网络的训练速度，有的使用CPU SSE技术和浮点SIMD模型来实现深度学习算法，相比浮点优化的版本能实现3倍加速。Andre Viebke等人利用多线程及SIMD并行化在英特尔Xeon Phi处理器上加速CNN。针对多GPU卡的并行化，Jeffrey Dean等人提出了一种大规模分布式深度网络，开发了两种算法（Downpour SGD和Sandblaster L-BFGS），可以在混有GPU机器的集群上运行。 加快训练方法的另一种方式是减少要学习的参数数量，Song Han等人使用修剪冗余连接的方法，在不失去网络表征能力下减少参数，这可以减少670万到6100万的AlexNet参数。Bahrampour等人也做了类似的性能评测工作，但他们仅用了一个GPU架构（NVIDIA Maxwell Titan X）和旧版的软件（cuDNN v2, v3）。 本文作者早前工作也探讨了单个GPU上跑旧版软件的基准测试结果。此文针对三版主要的GPU架构和一些最新的网络（如：ResNet-50）和软件（如：cuDNN v5）进行基准评测，并深入到工具包代码分析性能。此外，本文也比较了单台机器里多个GPU卡的性能。 因为单个GPU卡内存相对较少，限制了神经网络规模，训练的可伸缩性对于深度学习框架至关重要。在如今的深度学习工具中，支持多GPU卡成为了一个标准功能。为了利用多个GPU卡，分布式同步随机梯度下降法（SDG）使用很广泛，实现了很好的扩展性能。 在可扩展性方面，本文作者着重评估处理时间，以及数据同步方法的收敛速度。在数据并行模型里，针对N个worker，把有M个样本的一个mini-batch分成N份，每份M/N个样本，每个worker用相同的模型独立向前向后处理所分配的样本。当所有worker完成后，把梯度聚合，更新模型。 实际上，不同工具实现同步SGD算法的方式各有不同。 Caffe：采用删减树策略减少GPU间的数据通信。例如，假设有4个标记为0,1,2,3的GPU。首先，GPU 0和GPU 1交换梯度，GPU 2和GPU 3交换梯度，然后GPU 0和GPU 2交换梯度。之后，GPU 0会计算更新的模型，再将更新的模型传输到GPU 2中；接着GPU 0把模型传输到GPU 1，同时GPU 2把模型传输到GPU 3。 CNTK：使用MPI作为GPU之间的数据通信方法。CNTK支持4种类型的并行SGD算法（即：DataParallelSGD，BlockMomentumSGD，ModelAveragingSGD，DataParallelASGD）。对于本文关心的 data parallel SGD，CNTK把每个minibatch分摊到N个worker上。每次mini-batch后将梯度进行交换和聚合。 MXNet：同样将mini-batch样本分配到所有GPU中，每个GPU向前后执行一批规模为M/N的任务，然后在更新模型之前，将梯度汇总。 TensorFlow：在每个GPU上放置一份复制模型。也将mini-batch分到所有GPU。 Torch：其数据并行机制类似于MXNet，把梯度聚合的操作放在GPU端，减少了PCI-e卡槽的数据传输。 ## 3. 评测方法 处理时间(Processing time)及收敛速度(Convergence rate) 是用户训练深度学习模型时最看重的两个因素。因此该实验主要通过测量这两个指标以评估这几种深度学习工具。 一方面，评估处理时长有一种高效且主流的方法，就是测出对一个mini-batch所输入数据一次迭代的时长。在实际操作中，经历多轮迭代或收敛以后，深度学习的训练过程会终止。因此，对于每种神经网络，该实验使用不同大小的mini-batch来评测各个深度学习软件工具。作者针对每种大小的mini-batch都多次迭代，最后评估其平均运行速度。另一方面，由于数据并行化可能影响收敛速度，该评测还在多GPU卡的情况下比较了收敛速度。 评测使用合成数据集和真实数据集。合成数据集主要用于评估运行时间，真实数据集用于测量收敛速度。每种工具的时间测量方法如下： Caffe：使用“caffe train”命令训练所指定网络，随之计算两次连续迭代过程间的平均时间差。 CNTK：与Caffe类似，但排除包含磁盘I / O时间的首个epoch。 MXNet：使用内部定时功能，输出每个epoch和迭代的具体时间。 TensorFlow：在源脚本里使用计时功能，计算平均迭代时间。 Torch：和TensorFlow一样。 这几种工具均提供非常灵活的编程API或用于性能优化的配置选项。例如CNTK中可以在配置文件中指定“maxTempMemSizeIn-SamplesForCNN”选项，以控制CNN使用的临时内存的大小，虽然可能导致效率略微降低，但是内存需求更小了。 MXNet、TensorFlow和Torch也有丰富的API，在用于计算任务时供用户选择。换句话说，可能存在不同API以执行相同的操作。因此本评测结果仅仅是基于作者对这些工具用法的理解，不保证是最佳配置下的结果。 评测中的深度学习软件版本和相关库如表1所示。 表1：用于评测的深度学习软件 神经网络和数据集：对于合成数据的测试，实验采用具有约5500万个参数的大型神经网络（FCN-S）来评估FCN的性能。同时选择ImageNet所选的AlexNet和ResNet-50作为CNN的代表。 对于真实数据的测试，为MNIST数据集构建的FCN（FCN-R）较小；针对Cifar10数据集则使用名为AlexNet-R和ResNet-56的AlexNet架构。对于RNN，考虑到主要计算复杂度与输入序列长度有关，作者选择2个LSTM层进行测试，输入长度为32。每个网络的详细配置信息如表2和表3所示。 表2：合成数据的神经网络设置。注意：FCN-S有4层隐藏层，每层2048个节点；并且AlexNet-S中排除了batch normalization操作和dropout操作；为了测试CNN，输入数据是来自ImageNet数据库的彩色图像（维度224×224×3），输出维度是ImageNet数据的类别数量。 表3：真实数据的神经网络设置。注：FCN-R有3个隐藏层，节点数分别为2048、4096和1024。AlexNet-R的架构与原始出处里Cifar10所用的AlexNet相同，但不包括本地响应规范化（LRN）操作（CNTK不支持）。对于ResNet-56，作者沿用了最原始文件里的架构。 硬件平台：评测使用两种类型的多核CPU，其中包括一个4核台式机级CPU（Intel i7-3820 CPU @ 3.60GHz）和两个8核服务器级CPU（Intel XeonCPU E5-2630 v3 @ 2.40GHz），测试不同线程数下各个工具的性能。另外还用三代不同的GPU卡，分别是采用Maxwell架构的NVIDIA GTX 980 @ 1127MHz，采用Pascal架构的GTX 1080 @1607MHz，以及采用Kepler架构的Telsa K80 @ 562MHz。 评测只使用K80 GPU两个GK210芯片中的一个进行单GPU比较，同时，为了使得结果可重复，已禁用GPU自动超频功能。为了避免神经网络大小对主机内存的依赖，两台测试机分别配备64GB内存和128GB内存。硬件配置的详细信息如表4所示。 表4：本评测的硬件设置。注：K80卡上有2个GK210 GPU，但为了比较测试单GPU性能仅使用一个GPU。 数据并行化评测则在两个Tesla K80卡上进行，这样共有4个GK210 GPU。对于多GPU卡实验，系统配置如表5所示。 表5：数据并行性的评测硬件设置。注：K80卡上有两个GK210 GPU，因此进行双GPU并行评测时使用一个K80卡，进行四GPU并行评测时使用两个K80卡。 各神经网络，软件工具和硬件的组合结果如表6所示。 表6：各神经网络、软件工具和硬件的组合结果 4. 评测结果 评测结果分别在三个子部分呈现：CPU结果，单GPU结果和多GPU结果。对于CPU结果和单GPU结果，主要关注运行时长；对于多GPU还提出了关于收敛速度的比较。不同平台上的主要评测结果参见表7及表8。 表7：评测对比结果（每个mini-batch的运算时间，单位：秒）。注：FCN-S，AlexNet-S，ResNet-50，FCN-R，AlexNet-R，ResNet-56和LSTM的mini-batch大小分别为64，16，16，1024，1024，128，128。 表8：单GPU与多GPU间的比对结果（每个mini-batch的运算时间，单位：秒）。注：FCN-R，AlexNet-R和ResNet-56的mini-batch大小分别为4096，1024和128。 4.1. CPU评测结果 具体参见表7及原文。 4.2. 单GPU卡评测结果 在单GPU的比较上，该评测还展示了不同mini-batch大小的结果，以展示mini-batch大小对性能的影响。（译者注：原论文结论中详细描述了不同mini-batch大小下各学习工具的性能，具体见图表） 4.2.1. 合成数据（Synthetic Data） FCN-S：Caffe最佳，其次是CNTK和Torch，最后是TensorFlow及MXNet。 AlexNet-S：MXNet性能最佳，其次是Torch。 ResNet-50：MXNet性能远远高于其他工具，尤其是mini-batch大小比较大的时候。其次是CNTK和TensorFlow，Caffe相对较差。 4.2.2. 真实数据（Real Data） FCN-R：Torch最佳，Caffe、CNTK及MXNet三个工具次之，TensorFlow最差。 AlexNet-R：K80 平台上CNTK表现最佳，Caffe和Torch次之，然后是MXNet。TensorFlow处理时间最长。 ResNet-56：MXNet最优，其次是Caffe、CNTK 和Torch，这三个接近。最后是TensorFlow。 LSTM：CNTK全面超越其他工具。 4.3.多GPU卡评测结果 FCN-R：单GPU的情况下，Caffe、CNTK及MXNet接近，TensorFlow和Torch稍差。GPU数量翻番时，CNTK和MXNet的可扩展性最佳，均实现了约35%的提速，caffe实现了大约28%的提速，而Torch和TensorFlow只有约10%。GPU数量变为4个时，TensorFlow和Torch没有实现进一步的提速。 而收敛速度往往随着GPU数量的增加而增快。单个GPU时，Torch的训练融合速度最快，其次是Caffe、CNTK和MXNet，TensorFlow最慢。当GPU的数量增加到4时，CNTK和MXNet的收敛速度率接近Torch，而Caffe和TensorFlow收敛相对较慢。 AlexNet-R：单个GPU时，CNTK，MXNet和Torch性能接近，且比Caffe和TensorFlow快得多。随着GPU数量的增长，全部工具均实现高达40%的提速，而TensorFlow只有30%。 至于收敛速度，MXNet和Torch最快，CNTK稍慢，但也比Caffe和TensorFlow快得多。 ResNet-56：单GPU时，Torch用时最少。多个GPU时，MXNet往往更高效。 至于收敛速度，整体来说MXNet和Torch比其他三个工具更好，而Caffe最慢。 ## 5. 讨论 对于CPU并行，建议线程数不大于物理CPU内核数。因为在计算过程中需要额外的CPU资源来进行线程调度，如果CPU资源全部用于计算则难以实现高性能。然而，借助于Eigen的BLAS库（BLAS library），因其为了SIMD指令优化过，因此随着CPU内核数的增长，TensorFlow的性能能更好。 在FCN神经网络上，如果只用一个GPU卡，那么Caffe、CNTK和Torch的性能要比MXNet和TensorFlow略好。 通常来说，训练一个网络包含两阶计算（即前馈和后向传播）。在前馈阶段，矩阵乘法是最耗时的操作，评测的四个工具全部采用cuBLAS API：cublasSgemm。如果想要把矩阵A乘以矩阵B的转置，可以将cublasSgemm API的第二个参数设置为CUBLAS_OP_T，即应用in-place矩阵转置。但这就导致与没有转置的矩阵乘法相比，性能减慢3倍（例如，C = A×B^T，其中 A∈R^1024×26752 ，B∈R^2048×26752）。这是因为in-place矩阵转置非常耗时。CNTK和TensorFlow构造自己的数据结构，从而用的是cublasSgemm的CUBLAS_OP_N，而Caffe和Torch使用CUBLAS_OP_T。 在后向传播的阶段，则需要使用矩阵乘法来计算梯度，并使用element-wise矩阵运算来计算参数。如果通过调用cuBLAS来将A乘以B的转置，效率低时，可先转置B（如果GPU具有足够的内存，则采用out-place）再应用矩阵乘法可能会效果更好。 此外，cublasSgemm API完全支持后向传播，因为它在矩阵乘法后添加了一个缩放的矩阵。因此，如果将梯度计算和更新操作合并到单个GPU核中，则可以提高计算效率。为了优化FCN的效率，还可以在不转置的情况下使用cublasSgemm API，并同时使用cublasSgemm来计算梯度及执行更新操作。 在CNN上，所有工具包均使用cuDNN库进行卷积运算。尽管API调用相同，但是参数可能导致GPU内核不同。相关研究发现，在许多情况下，与直接执行卷积运算相比，FFT是更合适的解决方案。在矩阵的FFT之后，卷积计算可以被转换为更快速的内积运算（inner product operation）。 对于使用多个GPU卡的数据并行性，运算的扩展性受到梯度聚合处理的极大影响，因为其需要通过PCI-e传输数据。在本评测的测试平台中，Telsa K80的PCIe 3.0的最高吞吐量约为8GB/秒，这意味着在FCN-R情况下需要0.0256秒的时间将GPU的梯度转移到CPU。但是一个mini-batch的计算时间只有大约100毫秒。因此，减少GPU和CPU之间传输数据的成本将变得极为关键。 不同软件工具的性能表现各异，且与并行设计的策略相关。在Caffe中，梯度更新在GPU端执行，但它使用了树减少策略（tree reduction strategy）。如果说有4个GPU用于训练，则两对GPU将首先各自交换梯度（即GPU 0与GPU 1交换，GPU 2与GPU 3交换），然后GPU 0与GPU 2交换。之后，GPU 0负责计算更新的模型，再将模型传送到GPU 1，然后0将模型传送到1，2传送模型到3，这是一个并行过程。 因此，Caffe的可扩展性（scalability）的性能在很大程度上取决于系统的PCI-e拓扑。CNTK的作者在框架中添加了1比特的随机梯度下降（1-bit stochastic gradient descent），这意味着PCI-e交换梯度的时间可大大缩短。因此，即使使用大型网络，CNTK的可伸缩性也依旧表现良好。 在这类网络上，MXNet也表现出良好的可扩展性，因为它是在GPU上进行梯度聚合，这不仅减少了经常传输梯度数据的PCI-e时间，并能利用GPU资源来进行并行计算。 然而，TensorFlow在CPU端进行梯度聚合和模型更新，这不仅需要很多时间通过PCI-e传输梯度，而且还使用单个CPU更新串行算法中的模型。因此TensorFlow的伸缩性不如其他工具。 对于多个GPU，Torch在扩展性上与TensorFlow类似。其梯度聚合和更新都在CPU端执行，但Torch使用了并行算法来利用所有空闲的CPU资源。因此，其伸缩性要略好于TensorFlow，但仍然比不上Caffe、CNTK和MXNet。 总的来说，因为有了GPU计算资源，上述所有深度学习工具的速度与CPU的版本相比，都有了极大提高。这并不出奇，因为在GPU上的矩阵乘法以及FFT的性能要明显优于CPU。 未来作者还将评测更多的深度学习工具（比如百度的Paddle），也会把 AMD的GPU等也加入评测。并在高性能GPU集群上进行评测。 论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Caffe","slug":"Caffe","permalink":"http://ipcreator.me/tags/Caffe/"},{"name":"CNTK","slug":"CNTK","permalink":"http://ipcreator.me/tags/CNTK/"},{"name":"MXNet","slug":"MXNet","permalink":"http://ipcreator.me/tags/MXNet/"},{"name":"Torch","slug":"Torch","permalink":"http://ipcreator.me/tags/Torch/"}]},{"title":"人工智能和机器学习的进步 需要一个更加开源的世界","date":"2017-02-13T00:33:06.000Z","path":"2017/02/13/SmartAI/ProgramAI/OpenSources/ai-and-machine-learning-need-more-open-sources/","text":"作者：网易AI研究院 国外媒体TechCrunch撰文指出，当前的人工智能（AI）开源模式封闭，存在不足，且不合时宜。 人工智能正变得越来越重要。拥有机器学习（ML）技术经验的企业在寻求取得基于人工智能的技术。 还没有打造出机器学习技术的企业正竭力理解和设计机器学习和AI战略。正当AI受到大肆追捧，人们对该技术既感到困惑，又对它的风险感到恐慌，来自谷歌、Facebook、百度、微软等公司的一连串开源贡献公告（通过 Tensorflow、BigSur、Torch、SciKit、Caffe、CNTK、DMTK、Deeplearning4j、H2O、Mahout、MLLib、NuPIC、OpenNN等项目） 带来了一种明显的上手AI以及ML的方式，科技行业以外的企业尤其受益。 发现项目，下载，安装……应该是件轻而易举的事情。但事实上它并没有表面上那么的简单。 对于在AI使能或者AI影响的系统主导的时代软件的共享来说，当前的开源模式并不足够，且已经不合时宜；用户一天里使用过的AI引擎可能多达数千个。 对于AI和ML先驱们来说，共享他们的代码并不足够。整个行业和世界需要新的开源模式： 经过AI和ML训练的引擎本身开源的同时，数据、功能特性和现实世界表现细节也要开源。 当前的开源模式不足够且过时 AI和ML使能和影响的系统不同于其它用开源部件打造的软件。用开源部件打造的软件本质上还是具有确定性的，也就是说所设计和编写的软件每一次执行时的表现都是一样的。而 AI和ML系统，尤其是人工智能系统，并不能保证能够表现出确定性的行为。 随着对新情境、新环境和新用户的学习和适应，这些系统将会改变它们的行为。本质上，一旦这些AI系统被部署到现实世界，它们的创造者就会失去对AI的控制。当然，创造者们可以在学习框架中加入制衡机制。然而，即便是在AI系统被制约的范围内，仍需要进行大量的解读工作。与此同时，被AI包围的世界面临的更大挑战在于，制定制约条件的人造成的冲突。 想想看，最近有报道援引梅赛德斯董事长克里斯托弗·冯·雨果(Christoph Von Hugo)的话说，梅赛德斯无人驾驶汽车会选择优先保护乘客的生命，而非路人的生命。尽管该公司后来澄清说雨果的话被错误引述，但这揭示了资本主义将如何影响AI系统所嵌入的约束条件的根本性问题。 资本主义与AI伦理道德 如果企业的经营目的是创造利润，那将基于AI的体验描述为带附加价值的差异化体验，要求消费者溢价购买该技术的产品服务会在多久后进入市场呢？ 在这种情况下，愿意且有能力购买那种差异化体验的用户相比其他用户将会获得不正当的好处。因为企业将尝试从其对AI的投入中获得回报，这种技术将会局限于那些买得起的人。这将会导致AI内置的限制和行为对那些掏腰包购买的人有利，给他们提供保护，或者偏爱他们。 另一个担忧是，谁来为AI和M使能的产品的故障或者行为表现不佳负责的法律和政策问题。这个责任由谁来担负？用户，服务提供商，数据科学家，还是AI引擎？该如何问责，如何界定责任？回答这些问题的前提是，清晰地描述和遵守引发AI和ML的创造和使用的一系列事件。 AI与AI的互动 机器人玩木制魔术方块的3D渲染图 AI之间的冲突 考虑到AI使能产品在行为表现上可能存在不确定性，在原来没观察到的交互中可能会有意想不到的表现，在AI使能的产品代表两个或者更多的不同用户相互互动的场景中，这一问题会进一步放大。例如。当两辆由两个独立的AI引擎（由不同的公司用不同的训练数据和功能，以及独立配置的偏好和情境信息打造而成）驱动和运作的汽车遇到停车标志，或者将要发生碰撞时，会发生什么事情呢？这些系统在响应类似的情境时，即便有很细小的差异和变化，都可能会产生意想不到的不良影响。 偏好问题蔓延 互相影响的AI的另一个潜在副作用会放大训练的偏好风险。例如，如果无人驾驶汽车观察到另一辆无人驾驶汽车在以路人受伤为代价来保护乘客，观察到这一选择确保另一辆车能够避免发生事故，这种“学习”会使得它在遇到类似的情况时作出类似的行为。这会造成偏好问题蔓延：被独立训练的AI引擎受到另一个AI引擎的行为的影响（不管是正面的影响，还是负面的影响）。 学习的灵活性 即便类似的AI引擎获得的学习数据是一样的，训练环境和用来执行训练的基础设施方面的差异，也会导致训练和学习速度变得不一样，因而它们会得出不一样的结论。随着时间的推移，这些细微的变化会导致AI引擎的行为出现巨大的变化，带来不可预知的影响。 新的AI开源模式 我们需要新的AI开源模式来提供框架解决上述的部分问题。考虑到AI的本质，开源用于打造AI和ML引擎，将它们嵌入产品当中，并不足够。此外，类似于科学研究，行业将需要贡献回能够形成新改良的系统、引擎和产品基础的AI和ML引擎。 基线、基准与标准 对于无人驾驶汽车、图像识别、语音文本转换等所有重要的场景，尤其是有多家服务提供商涉足的场景， 行业需要能够定义统一的基线和标准，让所有其它的新AI引擎或者现存AI引擎有评估和堆栈排序的标准（例如，美国国家公路安全局针对无人驾驶汽车制定五星安全评级）。 为重要场景定义为行业所接受和批准的基准，可确保服务提供商和消费者能够在挑选AI与ML使能的产品服务时做出精明的决策。此外，现有的AI引擎可不断地根据基准与标准进行评估，进而确保这些系统的质量不断改进。 开发AI和ML模型的公司应当考虑对完整的AI和ML模型进行开源贡献（不仅仅是贡献打造这种模型的技术和框架）。 例如，即便是谷歌已有5年历史的图像识别模型，或者来自微软的Speech to Text语音文本转化模型，都能够在其它的领域或者行业激发AI和ML的快速创新和同化作用，进而形成自维持的创新回路。科技以外的行业也能够利用这些模式来启动自有的项目，以及将它们的学习成果贡献回开源社区。 偏好判定 行业需要偏好判定能力来使得嵌入AI和ML引擎的偏好能够被尽快发现和移除。没有这种能力的话，行业会难以形成在各种各样的场景中有着一致和确定性表现的统一AI引擎。偏好判定和偏好移除在AI开源模型中将需要以下的支持。 数据假定和偏好 AI使能的产品设计师需要确保它们理解其所做的和嵌入AI与ML引擎的数据假定和偏好。与其它AI使能产品进行交互的产品需要确保它们理解且准备好处理AI引擎行为带来的影响。为了确保消费者或者这类AI和ML模型的整合商做好准备，各个AI和ML模型应当揭示和共享以下的标准。 数据收集标准 数据是如何被收集的呢？数据生成器有哪些呢？数据收集的频率、地方、时间、方式和原因呢？数据是如何被收集、分层和传输的呢？ 数据选择标准 数据是如何被选来训练的呢？数据不被选择的标准是什么呢？什么数据子集被选择，什么不被选择呢？定义高质量数据的标准是什么呢？可接受但非高质量的数据标准是什么呢？ 数据处理标准 数据经过怎样的处理后才被拿来训练？数据经过怎样的转变、浓缩和概述呢？数据处理的频率如何？有什么会导致预订的数据处理推迟或者停止呢？ 功能假定与偏好 AI和ML模型通过对被模式化的系统的功能或者特点的观察来训练。这些功能提取自数据，被应用于AI和ML引擎，可预测该系统的行为，或者将新信号归类成想要的类别来触发系统特定的动作或者行为。消费者和AI模型的整合商需要清楚有哪些功能被选来开发AI模型，以及有哪些功能被考虑，哪些没被选择及没被选择的原因。此外，用来判定训练功能的洞见将需要记录下来和共享。 盲点移除 由于模型内置的偏好和假定，AI和ML引擎会形成令其在特定的情境、环境和语境中的有用性和效能受到限制的盲点。 盲点回报和反馈回路 AI和ML开源模型的另一重要功能，应当是既能够判定特定模型是否有盲点，还能够给AI模型贡献回可用于移除这些盲点的数据（现实生活的例子）。大体上，这种机制类似于垃圾邮件的汇报机制：垃圾邮件检测引擎可利用用户新提供的垃圾邮件案例来更新其对垃圾邮件的定义和检测垃圾邮件所需的过滤工具。 协作性盲点移除 理想的开源协议的另一个特性会是，不同服务提供商之间相互共享数据，共同协作移除模型中的盲点。想想谷歌的无人驾驶汽车和特斯拉的Autopilot自动驾驶模式。谷歌的汽车在自动驾驶模式下行驶了大约200万英里，而特斯拉汽车在Autopilot下行驶了大约5000万英里的高速公路。抛开这两家公司是竞争对手的事实，它们的数据集包含大量避免碰撞和确保司机、乘客或者路人的安全相关的数据。它们 可相互利用各自的数据集来改进各自的安全协议和程序。 也许，这种数据应当成为开源模型的一部分，毕竟它们可最大化行业和用户的利益。 总结 要真正变革和颠覆我们的生活，带来更好、更简单、更安全且更令人愉快的体验，AI和ML需要被纳入尽可能多的场景当中，需要被纳入各个行业领域的用户案例当中。 要真正启动和加速这种普及，开源用以打造AI和ML引擎的框架其实并不足够。我们需要新的开源模式来使得企业能够贡献和利用的不只是AI和ML开发技术，而是整个受训模型。而且，这些受训模型能够得到改进或者调整，或者在特定的场景中适应新环境以及AI和ML基准与标准，进而让新的AI和ML有参照标准。此外，揭示AI和ML模型的假定和偏好（数据或者功能层面）的信息，以及让AI和ML模型消费者能够给特定场景中的所有AI和ML产品贡献回重要数据和反馈的反馈回路，也非常重要。 没有这种开源模式，科技行业以外的世界将会继续难以实现AI和ML技术的普及。（皓慧）","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"Google 开源项目风格指南 (中文版)","date":"2017-02-12T04:10:06.000Z","path":"2017/02/12/SmartAI/ProgramAI/Tools/google-styleguide/","text":"作者：Jinhai ZHOU/JinhaiZ 每个较大的开源项目都有自己的风格指南: 关于如何为该项目编写代码的一系列约定 (有时候会比较武断). 当所有代码均保持一致的风格, 在理解大型代码库时更为轻松. “风格” 的含义涵盖范围广, 从 “变量使用驼峰格式 (camelCase)” 到 “决不使用全局变量” 再到 “决不使用异常”. 英文版项目维护的是在 Google 使用的编程风格指南. 如果你正在修改的项目源自 Google, 你可能会被引导至 英文版项目页面, 以了解项目所使用的风格. 我们已经发布了五份 中文版 的风格指南: Google C++ 风格指南Google Objective-C 风格指南Google Python 风格指南Google JSON 风格指南Google Shell 风格指南中文版项目采用 reStructuredText 纯文本标记语法, 并使用 Sphinx 生成 HTML / CHM / PDF 等文档格式. 英文版项目还包含 cpplint - 一个用来帮助适应风格准则的工具, 以及 google-c-style.el, Google 风格的 Emacs 配置文件.另外, 招募志愿者翻译 JavaScript Style Guide 以及 XML Document Format Style Guide, 有意者请联系 Yang.Y. Software Release Practice HOWTOEric Steven Raymond This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it. This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards. Table of Contents Introduction1.1. Why this document?1.2. New versions of this document Good patching practice2.1. Do send patches, don’t send whole archives or files2.2. Send patches against the current version of the code.2.3. Don’t include patches for generated files.2.4. Don’t send patch bands that just tweak version-control $-symbols.2.5. Do use -c or -u format, don’t use the default (-e) format2.6. Do include documentation with your patch2.7. Do include an explanation with your patch2.8. Do include useful comments in your code2.9. Just one bugfix or new feature per patch. Good project- and archive- naming practice3.1. Use GNU-style names with a stem and major.minor.patch numbering.3.2. But respect local conventions where appropriate3.3. Try hard to choose a name prefix that is unique and easy to type Good licensing and copyright practice: the theory4.1. Open source and copyrights4.2. What qualifies as open source Good licensing and copyright practice: the practice5.1. Make yourself or the FSF the copyright holder5.2. Use a license conformant to the Open Source Definition5.3. Don’t write your own license if you can possibly avoid it.5.4. Make your license visible in a standard place. Good development practice6.1. Choose the most portable language you can6.2. Don’t rely on proprietary code6.3. Build systems6.4. Test your code before release6.5. Sanity-check your code before release6.6. Sanity-check your documentation and READMEs before release6.7. Recommended C/C++ portability practices Good distribution-making practice7.1. Make sure tarballs always unpack into a single new directory7.2. Have a README7.3. Respect and follow standard file naming practices7.4. Design for Upgradability7.5. Provide checksums Good documentation practice8.1. Documentation formats8.2. Good practice recommendations Good communication practice9.1. Announce to Freecode9.2. Have a website9.3. Host project mailing lists9.4. Release to major archives Good project-management practice","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"如何成为一名黑客","date":"2017-01-20T12:31:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/how-to-become-a-hacker/","text":"如何成为一名黑客——Eric S. Raymond &#x65;&#115;&#114;&#64;&#116;&#104;&#121;&#114;&#115;&#117;&#115;&#46;&#99;&#111;&#x6d;Wang Dingwei &#119;&#x61;&#110;&#103;&#100;&#x69;&#110;&#x67;&#119;&#101;&#x69;&#x38;&#x32;&#x40;&#103;&#109;&#97;&#105;&#108;&#x2e;&#99;&#111;&#109; 基于 Barret 的翻译更正而成。转载请注明出处。 目录 为什么会有这份文档？ 什么是黑客？ 黑客的态度 黑客的基本技能 提高自己在黑客圈中的地位 黑客和书呆子(Nerd)的联系 向黑客的格调靠拢 关于黑客、开源、以及自由软件的历史 其它资源 FAQ（常见问题解答） 为什么会有这份文档？作为 Jargon File（译注：黑客行话大全）的编辑和几份其他类似性质知名文章的作者，我经常收到充满热情的网络新手的电子邮件询问：“我如何才能成为一名出色的 Hacker？”早在 1996 年，我注意到网上似乎没有任何的 FAQ 或者 Web 形式的文档提到及这个至关重要的问题，因此我写了这份文档。现在，很多 Hacker 都认为这是一篇权威性文档，那我也姑且这么认为吧。不过，我不认为我是这个话题的绝对权威；如果你不喜欢这篇文档，你也可以自己写一份。 如果你读到的是这份文档的离线拷贝，你可以在 http://catb.org/~esr/faqs/hacker-howto.html 读到最新版本。 注意：文档的结尾有一份 FAQ（常见问题解答）。如果你想通过邮件询问我关于这份文档的问题，请先读这份 FAQ 看看能否找到答案——一遍不行就读两遍。 目前这份文档有很多翻译版本：阿拉伯语、白俄罗斯语、丹麦语、 荷兰语 、爱沙尼亚语、德语 、希腊语、意大利语 、希伯来语、 挪威语 、葡萄牙语（巴西）、 罗马尼亚语 、西班牙语 、土耳其语、瑞典语 。注意由于这份文档时有修正，所以以上翻译版本可能有不同程度的过时。 装饰本文的“五点九宫格”图像被称作“glider”，在一种叫做 Life 的数学模型中，这个简单的样本有一些异乎寻常的属性，多年以来 Hacker 们都为此着迷。我认为这个图像是一个很好的黑客徽标：它显得抽象而且神秘，而且像是一扇大门，通向一个截然不同的有其内在逻辑的世界。你可以阅读更多关于 Glider 徽标 的内容。 什么是黑客？Jargon File 讲了一堆关于“hacker”这个词的定义，大部分是关于“技术高超”、“热衷解决问题”、以及“超越极限”的内容。但如果你只想知道如何成为一名黑客的话，真正重要的只有两条。 这可以追溯到几十年前，那时候第一代分时微型计算机才刚刚诞生, 而 ARPAnet 的实验也才刚展开。那时的编程专家和组网高手建立了一个具有共享性质的文化社群， “hacker” 这个名词就是其中的成员创造的。黑客们建立了互联网，黑客们让 Unix 操作系统演化到现在的模样，黑客们经营着 Usenet，黑客们让万维网运转起来。如果你是这个文化的一部分，如果你对这种文化有所贡献，而且这个社群的其它成员也认识你并称你为 hacker，那么你就是一名黑客。 黑客的思维方式并不仅仅局限在软件黑客的文化圈内。也有人用黑客态度对待其它事情，如电子和音乐方面——其实你可以在任何最高级别的科学和艺术活动中发现它的身影。软件黑客对这些领域的践行者尊重有加，并把他们也称作黑客——有人宣称黑客天性是绝对独立于他们工作的特定领域的。但在这份文档中，我们将集中书写在软件黑客的技术和态度，以及发明了“黑客”一词的、以共享为特征的文化传统。 有另外一群人大声嚷嚷着自己是黑客，但他们根本不是。他们主要由青少年男性构成，是一些蓄意破坏计算机和电话系统的人。真正的黑客把这些人叫做 “骇客”(cracker)，并不屑与之为伍。黑客们通常认为他们是一群懒散、没有责任心、而且不是很聪明的人。会通过热接线发动汽车并不意味着你是一个汽车工程师。一样的道理，会破坏安全也不意味着你是一名黑客，不幸的是，很多记者和作家往往错把“骇客”当成黑客；这种做法一直使真正的黑客感到恼火。 根本的区别是：黑客搞建设，骇客搞破坏。 如果你想成为一名黑客，请接着读下去。如果你想做一个骇客，就去读 alt.2600 新闻组吧，顺便准备好去蹲个五到十年的监狱，而且最终你会意识到你并不像自己想象的那么聪明。 关于骇客，我能说的只有这些。 黑客的态度 这个世界充满了令人着迷的问题等着我们解决。 一个问题不应该被解决两次。 无聊和乏味的工作是罪恶。 崇尚自由。 态度不能替代能力。 黑客们解决问题，建设事物，同时他们信仰自由和无私的双向帮助。 要想作为一名黑客被社群认同，你需要体现出自己已经具备了这种态度。而要体现出这种态度，你就得真正相信和赞同这种态度。 但是，如果你认为培养黑客态度只是进入黑客文化圈的敲门砖，那就大错特错了。这种态度将有助于有助于你的学习，并且能为你提供源源不断的动力，所以它对你而言是至关重要的。和所有创造性的艺术一样，成为大师的最有效方法，就是模仿大师的精神——智力上的模仿还不够，还要从感情上进行模仿。 或者正如下面这首现代的禅诗讲的： 修行之道： 关注大师的言行， 跟随大师的举动， 和大师一并修行， 领会大师的意境， 成为真正的大师。 所以，如果你想成为一名黑客，反复读下面的事情直至你相信它们为止： 1. 这个世界充满了令人着迷的问题等着我们解决。做一名黑客会有很多乐趣，但是这些乐趣需要付出很多努力才能获得。这些努力需要动力。成功的运动员在表演和超越自我极限的时候获得身体上的愉悦，并把这种愉悦作为自己的动力。同样，为了成为一名黑客，你要从 解决问题、磨练技术，以及锻炼智力中得到基本的享受。 如果你不是天性如此，而你又想成为一名黑客，你就要设法成为这样的人。否则你会发现，你的黑客热情会被其他分心的事物吞噬掉——如金钱、性、以及社交圈的认同。 （你必须建立对于 自己学习能力的信念——就算你掌握的知识不足以解决当前的问题，如果你从问题的一小部分下手并从中学习，你将学到足够的知识用来解决下一部分——以此类推，直到整个问题都被你解决为止。） 2. 一个问题不应该被解决两次。有创新能力的大脑是一种宝贵的有限资源。当世界还充满非常多有待解决的有趣的新问题时，它们不应该被浪费在重新发明轮子的事情上。 作为一名黑客，你必须相信其他黑客的思考时间是宝贵的——因此共享信息、解决问题、并发布结果给其他黑客几乎是一种道义，这样其他人就可以去解决新问题，而不用在旧问题上面浪费精力了。 （这并不是在说你有义务把自己所有的作品都免费发布出来，但这样做的黑客能获得大家最大的尊敬。使用黑客技能养家糊口甚至发财致富都没关系，只要你别忘记自己作为一个黑客的责任，不背离黑客群体即可。） 3. 无聊和乏味的工作是罪恶。黑客（以及所有创造力的人们）都不应该被愚蠢的重复性劳动所困扰。重复性劳动浪费了他们解决新问题的时间，而 解决新问题正是黑客最大的价值所在。 这种浪费会伤害到每一个人。无聊和乏味的工作不仅仅是令人不舒服而已，而且本身就是一种罪恶。 作为一个黑客，你必须坚信这点并 尽可能多地将乏味的工作自动化，这不仅是为了你自己，也是为了其他人（尤其是其他黑客们）。 (对此有一个明显的例外。黑客有时为了休息大脑、学习技能、或者别的特别的原因，也会做一些在他人看来是重复性或枯燥的事情。但这是自愿的——只要是有思维能力的人，就不应该被迫做无聊的活儿。） 4. 崇尚自由。黑客们是天生的反权威主义者。任何能向你发号施令的人都可以让你停止解决令你着迷的问题，同时，按照权威主义者的一般思路，他通常会给出一些极端愚昧的理由。因此，不论何处，任何权威主义的做法，只要它影响到了你和其他的黑客，你就要和它斗到底。 （这并非向所有权威挑战。儿童需要监护，罪犯要被看管起来。如果服从命令得到某种东西比起用其他方式得到它更节约时间，黑客可以同意接受某种形式的权威。但这是一个有限度的，斟酌过的的交易；那种权威主义者想要的个人服从是不在考虑范围内的。） 权威主义者喜欢审查和保密。他们不信任自愿的合作和信息的共享——他们只喜欢由他们控制的所谓“合作”。因此，作为一个黑客，你应该对审查、保密，以及使用武力或欺骗去压迫有行为能力的人们的做法有一种本能的敌意。同时你要有为此信念付出的意愿。 5. 态度不能替代能力。作为一名黑客，你必须培养起这些态度。但只具备这些态度并不能使你成为一名黑客，也不能使你成为一个运动健将和摇滚明星。成为一名黑客需要智力、实践、奉献精神、以及辛苦的工作。 因此，你 必须学着忽略态度问题，并尊重各种各样的能力。 黑客们不会为那些装模做样的人浪费时间，但他们却非常尊重能力——尤其是从事黑客工作的能力（虽然有能力总归是好事）。如果能具备少有人能掌握的技能就更好了，当然如果你具备一些急需的技能，而这些技能又需要敏锐的思维、高超的技巧、和专注的精神，那就是再好不过了。 如果你尊重能力，你就会享受到提高自己能力的乐趣——辛苦的工作和奉献将不会是一件苦差事，而是一种紧张的娱乐，这是成为黑客至关重要重要的一点。 黑客的基本技能 学习如何编程。 学习使用开源 Unix 系统。 学会使用万维网以及编写 HTML。 学习英语，如果你的水平不够用的话。 黑客态度重要，但技术更加重要。态度无法替代技术，在你被别的黑客称为黑客之前，你必须掌握一些基本的技术作为你随身携带的工具。 随着新技术的出现和老技术的过时，这个工具包的内容也在不断改变。比如以前机器语言编程也被列在里边，而 HTML 是直到最近才包括进去的。不过现在可以清楚地告诉你包含以下内容： 1. 学习如何编程。这一条无须多说，当然是最基本的黑客技能。如果你还不会任何编程语言，我建议你 从 Python 开始学起。它设计清晰，文档齐全，而且对初学者比较友好。虽然它很适合作为一种入门语言，但它不仅仅只是个玩具；它非常强大、灵活，也适合做大型项目。我在一篇更详细的 Evaluation of Python（译注：Python 试用体验）中有更详细的论述。 Python 网站有很好的入门教程。 我曾经推荐过将 Java 作为初学的语言，但这则批评改变了我的想法（在里边搜索”The Pitfalls of Java as a First Programming Language” 就知道我的意思了）。作为一名黑客，你不能像人们挖苦的一样，“像水管工人一样装电脑”，你必须知道各个部件的工作原理。现在我觉得可能还是学过 C 和 Lisp 后再学 Java 比较好。 有一个大体的规律，就是如果你过于偏重使用一种语言，这种语言一方面会成为你得心应手的工具，另一方面也会阻碍你的学习。有这个问题的不只是编程语言，类似 RubyOnRails、CakePHP、以及 Django 的 web 应用框架也有这个问题，它们只会让你肤浅地懂得一些东西，当你碰到难以解决的问题或者需要调试时，你就可能不知所措了。 如果你想进入正式的编程领域，你将不得不学习 C 语言，它是 Unix 的核心语言。C++ 与 C 非常其他类似；如果你了解其中一种，学习另一种应该不难。但这两种都不适合编程入门者学习。而且事实上，你越避免用C编程，你的工作效率会越高。 C 语言效率极高，而且占用很少的系统资源。不幸的是，C 的高效是通过你手动做很多底层的管理（如内存管理）来达到的。底层代码都很复杂，而且极易出现 bug，你要花很多的时间调试。而现今的计算机速度如此之快，花时间调试程序通常是得不偿失——比较明智的做法是使用一种运行较慢、效率较低，但能大幅节省你的开发时间的语言。因此，还是选择 Python 吧。 其他对黑客而言比较重要的语言包括 Perl 和 LISP。从实用的角度来说，Perl 是值得一学的；它被广泛用于动态网页和系统管理中，因此，即便你从不用Perl 写程序，至少也应该学会读懂 Perl。 许多人使用 Perl 的理由和 我建议你使用 Python 的理由一样，都是为了避免用 C 完成那些不需要 C 高效率的工作。你会需要理解那些工作的代码的。 LISP 值得学习的理由不同——最终掌握了它时你会得到丰富的启迪和经验。 虽然你实际上很少会用到 LISP，但这些经验会使你在以后的日子里成为一个更好的程序员。 当然，实际上你 最好五种都会（Python，Java，C/C++，Perl 和 LISP）。除了是最重要的黑客语言外，它们还代表了截然不同的编程思路和方法，每种都会让你受益非浅。（你可以通过修改 Emacs 编辑器的模式） 单单学习编程语言并不会让你达到黑客的程度，甚至连程序员的程度都难企及——你需要脱离某种编程语言的素服，学习通过编程解决问题的思路。要成为一个真正的黑客，你需要达到几天就能学会一门编程语言的水平，你可以将文档里的信息和你已经掌握的知识结合起来，很快就学会一门编程语言。这意味着你需要先学会机种思路截然不同的语言才行。 编程是一个复杂的技能，我无法给你完整的指南来教会你如何编程，不过我可以告诉你，书本和课程也无法教会你如何编程——很多黑客，或者也许几乎所有的黑客，都是靠自学的。你从书本上学到语言的特点——只是一些皮毛，但要使书面知识成为自身技能，你只能通过实践和虚心向他人学习。因此你 要做的就是 (a) 读代码，(b) 写代码。 Peter Novig 是 Google 公司的顶尖黑客之一，而且是最受欢迎的 AI 课本的一名作者。他写了一篇好文章名叫 Teach Yourself Programming in Ten Years（译注：十年教会自己编程） ，其中的“recipe for programming success”（译注：编程的成功之道）尤其值得一读。 学习编程就象学习自然语言写作一样。最好的做法是读一些大师的名著，试着自己写点东西，再读些，再写点，再读些，再写点……如此往复，直到你的文章具备范文的力量和感觉为止。 以前要找适合阅读的好代码并不容易，因为几乎没有大型程序的源代码能让新手练手。这种状况已经戏剧性地发生变化；开源软件、编程工具、和操作系统（全都由黑客写成）现在已经随处可见。让我们在下一个话题中继续讨论…… 2. 学习使用开源的 Unix 系统。我将假设你已经有一台个人计算机供自己使用了（你可以体会一下这意味着多少东西。早些时候，计算机是如此的昂贵，没有人能买得起。而黑客文化就是在那样的环境下演化来的）。新手们能够朝学习黑客技能迈出的最基本的一步，就是找一版 Linux 或 BSD-Unix，安装在个人电脑上，并且把它跑起来。 没错，这世界上除了Unix还有其他操作系统。但它们都是以二进制形式发布的——你无法读到它的源代码，也不可能修改它。尝试在运行 DOS、Windows、或 MacOS 的机器上学习黑客技术，就象是穿着骑士铠甲学跳舞。 除此之外，Unix 还是 Internet 的操作系统。你可以学会上网却不知道 Unix，但你不了解 Unix 就无法成为一名 Internet 黑客。因此，今天的黑客文化在很大程度上是以 Unix 为核心的。（这点并不总是真的，一些很早的黑客对此一直很不满，但 Unix 和 Internet 之间的联系已是如此之强，就连 Microsoft 这样强力的公司也对此也无可奈何。） 所以, 安装一套 Unix 吧——我个人偏爱 Linux，但还有其他种类共你选择（是的，你可以在同一电脑上同时安装 Linux 和 DOS/Windows)。学习它，运行它，鼓捣它。用它上 Internet。阅读它的源代码。修改它的源代码。你会用到很多优秀的编程工具（包括 C， LISP，Python 及 Perl），这些工具在 Windows 下是做梦都没法得到的。你会觉得乐趣无穷。当你有一天成为大师再回顾初学的日子，你会觉得那时学到的东西可真多。 如果你想了解更多关于学习 Unix 的信息，读一下 The Loginataka（译注：ESR 的另一著作，可以称为黑客大藏经）吧。也许你还想看看 The Art of Unix Programming （译注：Unix 编程艺术，经典著作）。 你可以访问 Linux Online! 网站，这个网站可以帮你起步。你可以从那里下载到Linux，或者更好的办法是找一个本地的 Linux 用户组，让他们帮你安装 Linux。 在这份 HOWTO 文档发布后的前十年里，关于 Linux 我写的是，从新人的观点来看，所有的Linux 发行版都差不多，但在 2006-2007 之间，我们终于有了一个最佳选择： Ubuntu。我们可以说各种Linux 发行版各有千秋，但 Ubuntu 是新人最容易上手的一个发行版。 你可以在 www.bsd.org 找到 BSD Unix 的求助及其他资源。 Linux 有一种被称为 Live CD 的发行方式，这种发行版会从CD 运行起来，而且不会动到你硬盘里的东西，Live CD 是尝试 Linux 的一个不错的方法。由于光驱读写本来就比较慢，Live CD 的速度一般也会比较慢，不过 Live CD 总归是一个能尝试各种可能性而又不过激的方法。 我有写一篇]关于 Unix 和 Internet 基础的入门文章。 对于新手，我以前不鼓励你自己独立安装Linux 或者 BSD，现在这些系统的安装工具已经足够好了，就算对新手来说，独立安装操作系统也不是不可能的事。无论如何，我还是推荐你联系本地的 Linux 用户组，向他们寻求帮助，这会进程更加顺利。 3. 学会使用万维网以及编写 HTML。黑客文化建造的大多东西都在你看不见的地方发挥着作用。这些东西可以帮助工厂、办公室、以及大学正常运转起来，但从表面上很难看到它们对非黑客的普通人的生活的影响。而 Web 是一个大大的例外。就连政客也同意，这个庞大耀眼的黑客玩具正在改变整个世界。就算只是因为这个（还有许多其它的原因），Web 也值得你一学。 这并不是仅仅意味着如何使用浏览器（谁都会），而是要学会如何写 HTML，也就是 Web 的标记语言。如果你不会编程，写HTML会教你一些有助于学习的思考习惯。因此，先完成一个主页。 但仅仅拥有一个主页不能使你成为一名黑客。 Web里充满了各种网页。大多数是毫无意义的、毫无信息量的垃圾——界面时髦的垃圾，不过还是垃圾（更多相关信息访问 The HTML Hell Page）。 要想有价值，你的网页必须有内容——它必须有趣或对其它黑客有帮助。这是下一个话题所涉及的…… 4. 学习英语，如果你的水平不够用的话。作为一个以英语为母语的美国人，我以前很不情愿提到这点，免得被当做一种文化上的帝国主义。但相当多以其他语言为母语的人一直劝我指出这一点，那就是：英语是黑客文化和 Internet 的工作语言，只有懂英语，你才能在黑客社区顺利做事。 大概1991年的时候，我就了解到许多黑客在技术讨论中使用英语，甚至有时他们来自同一种母语也在用英文讨论。在现阶段，英语有着比其他语言丰富得多的技术词汇，因此是一个对于工作来说相当好的工具。基于类似的原因，英文技术书籍的翻译通常都不怎么令人满意。（如果有翻译的话）。 Linus Torvalds 是芬兰人，但他的代码注解是用英语写的（很明显他从没想过其他的可能性）。他流利的英语。是他能够管理全球范围的 Linux 开发人员社区的重要因素。 这是一个值得学习的例子。 就算你的母语是英语，这也无法保证你的语言技能足够达到黑客的标准。如果你的写作文字不通、语法混乱、错字连篇，包括我在内的大部分的黑客都会忽略你的存在。虽然写作马虎不一定意味着思考也马虎，但我们发现两者的关联性还是挺强的——马虎的头脑对我们来说毫无价值，如果你写作能力不够，就好好学习写作吧。 提高自己在黑客圈中的地位 撰写开源软件 帮助测试并调试开源软件 发布有用的信息 帮助维护基础设施的运转 为黑客文化本身服务 和大部分不涉及金钱的文化一样，黑客王国靠声誉运转。你设法解决有趣的问题，但它们到底多有趣，你的解法有多好，是要由那些和你具有同样技术水平，或比你更厉害的人去评判的。 相应地你需要认识到，当你在玩黑客游戏时，你的分数主要是靠其他黑客对你的技术的评价得到的（这就是为什么只有在其它黑客称你为黑客时，你才算得上是一名黑客）。常人的印象里，黑客是一项独来独往的工作，所以上述评价方式并不为众人所知。另一个黑客文化误区是拒绝承认自我或外部评价是一个人的动力，这种想法在 1990 年代末以后就逐渐衰退了，但现在还有人这么认为。这也是让上述评价方式鲜为人知的原因之一。 明确地讲，黑客行为就是人类学家所称的“奉献文化”。在这里你不是凭借你对别人的统治来建立地位和名望，也不是靠美貌，或拥有其他人想要的东西，而是靠你的贡献。尤其是贡献你的时间、你的创造、以及你的技术成果。 要获得其他黑客的尊敬，你可以从下面五种事情着手： 1. 撰写开源软件第一个方法（也是最重要，最传统的方法）是写些被其他黑客认为有趣或有用的程序，并把程序源代码提供给整个黑客文化圈使用。 （过去我们称之为“free software （自由软件）”， 但这却使很多不知 free 的精确含义的人感到困惑。现在我们很多人，根据搜索引擎网页内容分析，至少三分之二的人在使用”open-source software，即“开源软件”这个词）。 黑客领域里最受尊敬的偶像，是那些写了大型的、好用的、用途广泛的软件，并把它们发布出来，使得每人都在使用他软件的人。 但是从历史方面来讲有一点值得一提。虽然黑客们一直认为开源软件的开发者是真正的黑客，但在 1990 年代中期以前，大部分黑客会把自己的主要时间用来撰写闭源软件，直到我 1996 年开始写这篇 HOWTO 时也是如此。但从 1997 年后开源软件进入了主流，而且改变了这一切。以现在的观点来看，“黑客社群”和“开源开发者”是对这一个社群的两种称呼，但值得记住的是，以前这两者的概念并不完全一样。(要了解更多信息，你可以看看 关于黑客、开源、以及自由软件的历史这一节的内容。) 2. 帮助测试并调试开源软件黑客也尊敬那些使用和测试开源软件的人。这个世界并不完美，我们不可避免地要把大多数的开发时间放在调试阶段。这就是为什么任何有头脑的开源代码的作者都会告诉你好的 beta 测试员象红宝石一样珍贵。好的测试者知道如何清楚描述出错症状，很好地定位错误，能忍受快速发布中的 bug，并且乐意配合做一些例行的诊断性工作。一个优秀的测试者可以让一场旷日持久辛苦不堪的调试大战变成一场有益身心的小打小闹。 如果你是个新手，试着找一个你感兴趣的正在开发中的程序，做一个好的 beta 测试员。你会自然地从帮着测试，进步到帮着抓 bug，到最后帮着改程序。你会从中学到很多，而且善因种善果，以后别人也会很乐意帮助你。 3. 发布有用的信息另一件好事是收集整理有用有趣的信息，做成网页或类似 FAQ 的文档，并且让大家都能看到。 技术性 FAQ 的维护者会受到和开源代码的作者一样多的尊敬。 4. 帮助维护基础设施的运转黑客文化（还有互联网工程方面的发展）是靠志愿者推动的。要使Internet能正常工作，就要有大量枯燥的工作不得不去完成——管理邮件列表和新闻组，维护大型软件库，开发 RFC 和其它技术标准等等。 做这类事情的人会得到很多尊敬，因为每人都知道这些事情费时颇多，而又不象编程那样有趣。做这些事情需要奉献精神。 5. 为黑客文化本身服务最后，你可以为这个文化本身做宣传（例如像我这样，写一个“如何成为黑客”的教程 :-) ）这并不要求在你已经在这个圈子呆了很久，因以上四点中的某点而出名，有一定声誉后才能去做。 黑客文化没有领袖，这点是确认无疑的。但黑客圈里确实有些文化英雄、部落长者、史学家、还有发言人。如果你在这圈里呆足够长时间，你也许也能成为其中之一。 记住：黑客们不相信他们的部落长者的自夸，因此过分追求这种名誉是危险的。与其奋力追求，不如先摆正自己的位置，等它自己落到你的手中——那时则要做到谦虚和优雅。 ##黑客和书呆子(Nerd)的联系 和大家普遍认为的相反，并不是只有书呆子才能成为一名黑客。但它确实有帮助，而且许多黑客事实上是书呆子。做一个深居简出的人有助于你集中精力进行十分重要的事情，如思考和编程。 因此，很多黑客都接受了“geek（奇客）”这个标签，并把它作为骄傲的奖章——这是宣布他们独立于主流社会期望的一种方式（这个标签也是他们喜欢科幻小说和策略型游戏的标记，而这些也是很多黑客喜欢的东西）。1990 年代更多用的称呼是“nerd（书呆子）”，那时“nerd”只带点轻微的贬义，而“geek”则是地地道道的蔑称，而在 2000 年以后，这两者逐渐调转过来了，至少再美国的大众文化中是这样。而到了现在，甚至在非技术人群里，也有不少以 geek 精神为傲的文化团体。 如果你能集中足够的精力做好黑客工作同时还能有正常的生活，这是件好事。现在要做到这一点比我在 1970 年代还是新手的时候要容易的多；如今主流文化对技术怪人要友善得多。甚至有越来越多的人意识到黑客通常是很好的恋人和配偶的材料。 如果你因为生活上不如意而迷上做黑客，那也没什么——至少你不会分神了。也许你以后还能找到自己的生活。 向黑客的格调靠拢重申一下，要做一名黑客，你必须深入体验黑客精神。就算你不在计算机边上，你仍然有很多对黑客工作有帮助的事情可做。它们并不能替代真正的编程（没有什么能替代编程），但很多黑客都那么做，并感到它们与黑客的本质存在某些基本的连系。 学会用母语流畅地写作。尽管很多人认为程序员写不出好文章，但是有相当数量的黑客（包括所有我知道的最棒的黑客）都是很有能力的写手。 阅读科幻小说。参加科幻小说讨论会。（这是一个认识黑客和准黑客的好方法） 学习一种武术。武术中需要的精神自律能力和黑客在这方面的需求非常相似。黑中最受欢迎的武术是来自亚洲的空手格斗类武术，例如跆拳道、空手道、武术、合气道、柔术等。西式击剑和亚洲剑术也有不少的跟随者。1990 年后期以来，在可以合法使用枪支的地方，射击受欢迎的程度也越来越高了。大部分黑客喜欢的武术类型都是那些强调精神的自律，放松的意识，以及意念的控制，而不仅仅是单纯的力量、运动精神、以及身体的强健。 实实在在学习一种冥想修炼。多年以来黑客中最受欢迎的形式是参禅。（很重要的一点是，参禅和宗教可以说是独立的，你不需要接受一种新宗教，或者放弃现有的宗教信仰，就能做参禅的修炼。其他的形式也许也管用，但注意一定要挑那些靠谱的，不需要你相信不着边际的事物的冥想方式来演练。 提高自己对双关语和文字游戏的鉴赏能力。如果这些事情有很多你已经在做了，那你可能是天生做黑客的材料。至于为什么偏偏是这些事情，原因并不完全清楚，但它们都涉及用到左－右脑能力的综合，这似乎是关键所在（黑客们既需要清晰的逻辑思维，有时又需要偏离逻辑跳出问题的表象）。 最后，还有一些不要去做的事情。 不要使用愚蠢的，哗众取宠的ID或昵称。 不要卷入 Usenet（或任何其他地方）的骂战。 不要自称为“cyberpunk（网络朋克）”，也不要浪费时间和那些人打交道。 不要让你的 email 或者帖子中充满错误的拼写和语法。以上的事情只会为你招来嘲笑。黑客们个个记忆超群——你将需要数年的时间让他们忘记你犯下的错误。 网名的问题值得深思。将身份隐藏在虚假的名字后是骇客、软件破解者、及其他低等生物幼稚愚蠢的行为。黑客不会做这些事；他们对他们所作的感到骄傲，而且乐于人们将作品与他们的真名相联系。因此, 如果你现在还在使用假名，那就放弃它吧。在黑客文化里假名是失败者的标记。 关于黑客、开源、以及自由软件的历史1996 年我开始写这篇 HOWTO，那时候的大环境和现在很不一样。这里会给你简单介绍一下相关的历史变迁，这样大致可以澄清一下开源软件、自由软件、以及 Linux 和黑客圈的关系。如果你对这些不感兴趣，你可以直接跳过这一节，继续读下面的 FAQ。 我在这里所描述黑客精神和社会远远早于1990 Linux 出现的时候，我第一次涉足黑客圈是 1976 年，而究其根源则可追溯到20世纪60年代初。但在 Linux 出现之前，大多数黑客使用的操作系统要么是私有的商业版本，要么是自己开发的未得到广泛使用的系统（例如麻省理工学院的 ITS 系统）。虽然那时也有人想要改变这种状况，但他们的努力影响范围相当有限，充其量仅在某个黑客社区有少数忠实用户而已。 现在所谓“开源”历史和黑客社区的历史几乎一样长，但直到 1985 年前，它只是一种没有固定称谓的习惯做法，而不是一套有理论做后盾，有宣言做前锋的自觉运动。这种状态在 1985年结束了，长老级黑客 Richard Stallman（也被称为“RMS”）将其命名为“自由软件 (Free Software)”。这种命名也是一种宣言的方式，不过大多数黑客社区都不接收这种包含明显思想烙印的标签。因此而大多数现有的黑客社区从来没有接受。结果，“自由软件”这一标签被黑客社群中声音较大的少数人（尤其是 BSD Unix 的相关人士）拒绝掉了，而剩下的大部分人（包括我）虽然也有保留意见，可也还是沿用了这一称谓。 尽管很多人存在保留意见，RMS 的“自由软件”的大旗也一直举到了 1990 年代中期。直到 Liunx 崛起时它才受到了重大挑战。Linux 给了的开源开发者一个新的自然归宿，很多项目都已我们现称的开源的方式由 Unix 移植到了 Linux 系统中。Linux 的社区也得到了爆炸性增长，成为了一个比以前黑客文化更为庞大，并且异质化的新的群体。RMS 曾今尝试将这一社群也归并到他的“自由软件运动”大旗下，但终究没有成功，原因可以归于 Linux 社区的样性，以及 Linus Torvalds 本人的质疑。Torvalds 公开拒绝了 RMS 的自由软件思想，但还是沿用了“自由软件”这一术语，这也引来了很多年轻黑客的效仿。 1996年，当我第一次发表这篇 HOWTO 的时候，黑客社团正在围绕着 Linux 和其它几个开源操作系统（尤其是 BSD Unix 的衍生系统）进行着快速的重组。几十年来围绕着闭源系统进行闭源开发的方式还没有开始淡出集体记忆，但在大家看来，这似乎已经是死去的历史了。越来越多的黑客都已经开始注重自己在开源项目（例如 Linux、Apache 等）上的贡献，并将这些贡献当做自己的成就。 然而在那个时候“开源”这一名词还没有出现。这个名词是 1998 年初才开始出现的，而在出现的半年内，大部分的黑客社区就接受了这一名词，只有少数不接受这一概念的人还在坚持使用“自由软件”这一名词。1998 年以后，或者更准确地说是 2003 年以后，所谓的“hacking” 和 “开源（自由）软件开发”的含义已经非常接近了。从今天的眼光来看，这种区分已经没有意义了，看趋势，这个现状将来也不大可能有多大的改变。 不管怎样，这段变更的历史还是值得记住的。 其它资源Paul Graham 写了一篇 Great Hackers，还有 Undergraduation 一篇，里边有充满智慧的言论。 Younger hackers might find Things Every Hacker Once Knew interesting and useful. 我还写过一篇 A Brief History Of Hackerdom （译注：黑客文化简史）。 我写了一本 The Cathedral and the Bazaar（译注：大教堂与市集），对于 Linux 及开放源代码文化现象有详细的解释。这种现象在我的另一篇 Homesteading the Noosphere （译注：开拓智域）中还有更直接的阐述。 Rick Moen 写了一份很好的关于 how to run a Linux user group（译注：如何运营Linux 用户组）的文档。 我和Rick Moen合作完成了另一份关于 How To Ask Smart Questions（译注：提问的智慧）的文章，可以让在寻求帮助时得到事半功倍的效果。 如果你想知道 PC、UNIX 及 Internet 基本概念和工作原理，参考 The Unix and Internet Fundamentals HOWTO。 当你发布软件或者补丁的时候，请遵照 Software Release Practice HOWTO 去做。 如果你对禅诗感兴趣，也许你还喜欢看这篇 Rootless Root: The Unix Koans of Master Foo FAQ（常见问题解答）怎样才能知道自己已经是一名够格的黑客？你能教我做黑客吗？那么，我要如何开始？我得什么时候开始学？现在会不会太迟了？要学多久才能学会黑客技能？Visual Basic 是好的入门语言吗？你能帮我“黑”掉一个站点吗？或者教我怎么黑它？我怎么样才能得到别人帐号的密码？我如何入侵/查看/监视别人的 Email？我如何才能在IRC聊天室里偷到频道 op 的特权？我被黑了。你能帮我避免以后再被攻击吗？我的 Windows 软件出现问题了。你能帮我吗？我在哪里能找到可以与之交流的真正的黑客？你能推荐一些有关黑客的好书吗？成为一名黑客我需要擅长数学吗？我该从那种语言学起？我需要什么样的机器配置？我想贡献社区。你可以帮我选一个问题让我下手吗？我得因此憎恨和反对 Microsoft 吗？开放源代码软件不会使程序员丢饭碗吗？我要如何开始？哪里有免费的Unix？ 怎样才能知道自己已经是一名够格的黑客？你可以问自己下面三个问题： 你能流利地读写代码吗？ 你认同黑客社群的目的和价值吗？ 黑客社群里有没有资深成员称呼你为黑客呢？ 如果你对这三个问题的答案都是“是”的话，你已经是一名黑客了。如果你只满足其中两项，那就说明你还不够格。 第一个问题是关于技能的。如果你已经符合本文前面提到的最低需求的话，你也算过关，不过如果你发布过为数不少的开源代码并被社群接受，那你就算满分过关了。 第二个问题是关于态度的。如果黑客精神的五项基本原则对你来说能有共鸣，而且已经是你处事的方式，你就算过关一半了。这算靠里的一半，靠外的一半和你在黑客社区长期项目上的投入和关联程度有关。 这里列出了一些项目的不完全列表供你参考：Linux 的改进和用户群扩大对你来说是否重要？你对于自由软件精神是否充满激情？你对于垄断是否有敌意？你是否相信计算机这种工具会让增加世界财富，让这个世界更富有人道主义？ 不过值得注意的一点是，黑客社群有一些特有的政治倾向，其中两条，一条是保卫言论自由权，一种是抵御所谓“知识产权”对于开源社区的侵害。实践这两条的是一些民间组织，例如电子前沿基金会（Electronic Frontier Foundation）就是其中之一。不过虽然如此，黑客们对于有任何明确政治目的的团体都是心怀戒备的，因为我们已经从各种经验教训中学到一点：这些活动只会分裂黑客社团，并让黑客们分心。如果有人以黑客精神为名组织一场首都大游行，那他就完全没有弄明白这点。真正的应对方式也许应该是“闭上嘴巴，给他们看代码”。 第三个问题有点循环递归的味道。在“什么是黑客”一节我已经讲过，作为一名黑客的意义在于参与某个黑客社群，也就是社交网络的一个亚文化团体，作为内部的贡献成员以及外部的宣传者积极活动。和很久以前相比，黑客群体现在的团结意识和自我意识已经增强了很多。过去三十年来，随着互联网的发展，社交网络逐渐开始发挥举足轻重的作用，而黑客的亚文化团体也更加容易发展和维护了。这种变革的明显一个有代表性的现象是：有的黑客社群现在都有自己专门的文化衫了。 研究社交网络的社会学家把黑客文化归为“看不见的大学”，而且注意到这些网络社交圈还有所谓的“看门人”——其中的一些核心成员，他们有一定的权威，可以准新成员的进入。所谓的“看不见的大学”本来就是一个松散的非正式组织，所以这些“看门人”也只是这门称呼而已。但不是每个黑客都是“看门人”，这是每个黑客都深刻明白的一点。“看门人”需要有一定的资历和成就，究竟要到什么程度很难讲，但一旦有这样的人出现，每一个黑客都能辨识出来。 你能教我做黑客吗？自从第一次发布这份文档，我每周都会收到一些请求，（频繁的话一天几封）要我“教会他们做黑客”。遗憾的是，我 没有时间和精力来做这个；我自己的黑客项目，及我作为一个开放源代码倡导者 的四处奔波已经占用了我110%的时间。 即便我想教你，黑客也依然基本上是一项自行修炼的的态度和技术。 当真正的黑客想帮助你的时候，如果你乞求他们一汤匙一汤匙“喂”你的话，你会发现他们不会尊重你。 先去学一些东西。显示你在尝试，你能靠自己去学习。然后再去向你遇到的黑客请教特殊的问题。 如果你发E-mail给一位黑客寻求他的帮助，这是两件首要记住的事情。 第一，写出来的文字显得懒且粗心的人通常非常懒于思考且非常马大哈，不能成为好黑客——因此注意拼写正确，使用正确的语法及发音，否则你可能会无人理睬。 第二，不要试图要求回复到一个ISP帐号，而那个帐号与你 的发信地址不同。这样做的人一般是使用盗用帐号，我们对于回报或者帮助窃贼不感兴趣。 那么，我要如何开始？对你而言最佳的入门方式也许是去参加 LUG（Linux用户组）的聚会。 你可以找到在 LDP 的综合 Linux 信息页面上找到类似的组织；也许有一个在你家附近的，而且非常有可能与一所大学或学校挂钩。如果你提出要求，LUG 成员兴许会给你一套 Linux，当然此后会帮你安装并带你入门。 我得什么时候开始学？现在会不会太迟了？你有动力学习的时候就是好时候。大多数人看来都是在15－20岁之间开始感兴趣的，但据我所知，在此年龄段之外的例外也是有的。 要学多久才能学会黑客技能？这取决于你的聪明程度和努力程度。对于大多数人，只要足够专注，就能在 18 个月到 2 年之间学会一套令人尊敬的技能。 但是，不要以为这样就够了；如果你是一个真正的黑客，你要用你的余生来学习和完善你的技术。 Visual Basic 是好的入门语言吗？既然你问了这个问题，那你肯定是想在 Microsoft Windows 操作系统下学习黑客技能。这本身就不是一个好主意。我前面讲过在 Windows 下 hack 就跟穿着骑士铠甲跳舞一样，我不是在开玩笑。别走这条路，Windows 是一个很低劣的 hack 环境，而且一直如此。 Visual Basic 有一个特征性问题，就是它不可以被移植到其他平台。虽然也有些 Visual Basic 开源实现的雏形，但实现的只是 ECMA 标准的一个很小的子集。在 Windows 下大部分类库的知识产权都是 Microsoft 独家所有，如果你不是及其小心的话，你的代码将只能在 Microsoft 支持的平台上使用。 如果你不打算从 Unix 起步，那你也有更好的语言可选，而且类库质量还更高，例如 Python 就是其中之一 和其他的 Basic 类语言一样，Visual Basic 这门编程语言的设计也很糟糕，它会教你一些坏的变成习惯。你就别问我细节了，这可是罄竹难书。还是去学一门设计优良的语言吧。其中一个坏习惯是让你依赖于单一厂商的函数库、控件及开发工具。 一般而言，任何不能够支持至少 Linux 或者某一种 BSD，或其不能支持至少三种以上操作系统的语言，都是一种不适合应付黑客工作的语言。 你能帮我“黑”掉一个站点吗？或者教我怎么黑它？No。任何读完这份 FAQ 后还问这个问题的人，都是无可救药的蠢材，即使有时间指教我也不会理睬。任何发给我的此类电子邮件都会被忽略或被痛骂一顿。 我怎么样才能得到别人帐号的密码？这是骇客行为。滚得远远的，白痴。 我如何入侵/查看/监视别人的 Email？这是骇客行为。在我面前消失，智障。 我如何才能在IRC聊天室里偷到频道 op 的特权？这是骇客行为。滚开，笨蛋。 我被黑了。你能帮我避免以后再被攻击吗？不行。目前为止，每次问我这个问题的，都是一些运行 Microsoft Windows 的菜鸟。不可能有效的保护 Windows 系统免受骇客攻击；太多代码和架构的缺陷使保护 Windows 的努力有如隔靴搔痒。唯一可靠的预防来自转移到 Linux 或其他设计得至少足够安全的系统。 我的 Windows 软件出现问题了。你能帮我吗？当然。打开 DOS 命令行输入“format c:”。你遇到的任何问题将会在几分钟之内消失。 我在哪里能找到可以与之交流的真正的黑客？最佳办法是在你附近找一个Unix或Linux的用户组，参加他们的聚会。（你可以在 ibiblio 的 LDP 站点找到一些用户组的链接。） （我过去曾说过不能在IRC上找到真正的黑客，但我发觉现在情况有所改变。显然一些真正的黑客的社区像 GIMP 及 Perl，也有IRC频道了。） 你能推荐一些有关黑客的好书吗？我维护着一份 Linux Reading List HOWTO，也许你会觉得有用。The Loginataka 也大致值得一读。 关于Python的介绍，请访问在Python站点上的入门教程。 成为一名黑客我需要擅长数学吗？不用。黑客道很少使用常规的数学或算术，不过你绝对 需要能逻辑性地思考和进行精密的推理。 尤其是你不会用到微积分或电路分析（我们把这些留给电子工程师们 :-)）。有限数学中的一些grounding （包括布尔代数，集合论，组合数学，图论）的背景知识会对你有所帮助。 更重要的一点：你要有逻辑思维能力，能够以数学家的方式追溯因果。虽然大部分的数学知识对你可能没什么用处，但数学思维的能力对你来说是极其重要的。如果你缺乏这方面的智慧，要做一名黑客恐怕是无望了。如果你缺乏这方面的训练，还是尽早开始吧。 我该从那种语言学起？如果你还没学过XHTML（HTML最新的表现形式）的话，就从它开始吧。市面上有一大堆的封面精美，宣传得天花乱坠的HTML 书籍，不幸的是质量优秀的几近于无。我最喜欢的是 HTML: The Definitive Guide。 但HTML 不是一种完整的编程语言。当你准备开始编程时，我推荐从 Python 起步。 你会听到一大群人推荐 Perl，但是 Perl 要难学得多，而且（以我之见）设计得不是很好。 C 确实重要，但它也比 Python 或 Perl 难多了。不要尝试先学 C。 Windows用户注意：不要满足于 Visual Basic。它会教给你坏习惯，而且它不可以跨平台移植，只能在Windows下运行。因此还是敬而远之为好。 我需要什么样的机器配置？过去个人电脑能力相当不足并且内存很小，这给黑客的学习过程设置了人为的障碍。不过 1990 中期以后就不是这样了；任何一台 Intel 486DX50 以上配置的机器都有足够的能力进行开发工作、运行 X 系统、以及进行 Internet 通讯。而且你买到的市面上最小的硬盘都大得足够你使用了。 选择用来学习的机器时重要的一点是注意配件是否是Linux兼容的（或BSD兼容，如果你选择 BSD 的话）。和刚才提到的一样，大多数现在的机器都是符合的；唯一值得注意的区域在于 modem 和打印机；有些具备为Windows设计的配件的机器不会在Linux下工作。 你可以查看这份 Linux Hardware Compatibility FAQ。 我想贡献社区。你可以帮我选一个问题让我下手吗？不行，因为我不知道你的兴趣和擅长领域在哪里。如果你没有内在动力，你就很难坚持下去，所以说，别人只给你的路是行不通的。 试试这么做吧。在 Freshmeat 网站观察几天，看看里边的项目更新，如果你看到一个看上去很酷而且你也很感兴趣的项目，就加入吧。 我得因此憎恨和反对 Microsoft 吗？不，你不必如此。不是因为Microsoft不令人讨厌，而是因为黑客文化早在 Microsoft 出现之前就存在了，且将在 Microsoft 成为历史后依然存在。 你耗费在憎恨 Microsoft 的任何力气不如花在爱你的技术上。写好的代码——那会相当有效地打击 Microsoft 又不会让你得到恶报应。 开放源代码软件不会使程序员丢饭碗吗？目前看起来不太可能，开放源代码软件产业似乎创造了更多的就业机会而不是减少就业机会。如果写一个程序比起不写来是纯经济收益的话，那么在写完后，程序员应该得到报酬不管程序是否是开放源代码。并且，无论写出多么“免费自由”的软件，都存在更多对新的，定制的软件的需求。我有这方面更多的论述，放在放源代码]网站资料中。 我要如何开始？哪里有免费的Unix？在本份文档的某个地方我已经提到过何处可以得到最常用的免费 Unix。要做一名黑客，你需要自己找到激励和动力，还要有自学的能力。现在就开始努力吧…… How To Become A HackerEric Steven Raymond Thyrsus Enterprises &lt;esr@thyrsus.com&gt; Copyright © 2001 Eric S. Raymond Revision HistoryRevision 1.50 19 July 2015 esrAdded link to “Let’s Go Larval”.Revision 1.49 21 November 2014 esrAdded link to “How To Learn Hacking”.Revision 1.48 19 June 2014 esrfreshmeat/freecode is dead, alas.Revision 1.47 20 May 2014 esrFix up various stale links. Join a hackerspace!Revision 1.46 25 Sep 2013 esrAdd micropatronage explanation and gittip link. Why you should not ask me for advice on how to get started.Revision 1.45 12 May 2013 esrOpen Solaris isn’t, and Unity screwed the pooch.Revision 1.44 20 May 2012 esrUpdated the critique of Java.Revision 1.43 07 Feb 2011 esrPython passed Perl in popularity in 2010.Revision 1.42 22 Oct 2010 esrAdded “Historical note”.Revision 1.40 3 Nov 2008 esrLink fixes.Revision 1.39 14 Aug 2008 esrLink fixes.Revision 1.38 8 Jan 2008 esrDeprecate Java as a language to learn early.Revision 1.37 4 Oct 2007 esrRecommend Ubuntu as a Unix distro for newbies.Table of Contents Why This Document?What Is a Hacker?The Hacker Attitude The world is full of fascinating problems waiting to be solved. No problem should ever have to be solved twice. Boredom and drudgery are evil. Freedom is good. Attitude is no substitute for competence.Basic Hacking Skills Learn how to program. Get one of the open-source Unixes and learn to use and run it. Learn how to use the World Wide Web and write HTML. If you don’t have functional English, learn it.Status in the Hacker Culture Write open-source software Help test and debug open-source software Publish useful information Help keep the infrastructure working Serve the hacker culture itselfThe Hacker/Nerd ConnectionPoints For StyleHistorical Note: Hacking, Open Source, and Free SoftwareOther ResourcesFrequently Asked Questions Why This Document? As editor of the Jargon File and author of a few other well-known documents of similar nature, I often get email requests from enthusiastic network newbies asking (in effect) “how can I learn to be a wizardly hacker?”. Back in 1996 I noticed that there didn’t seem to be any other FAQs or web documents that addressed this vital question, so I started this one. A lot of hackers now consider it definitive, and I suppose that means it is. Still, I don’t claim to be the exclusive authority on this topic; if you don’t like what you read here, write your own. If you are reading a snapshot of this document offline, the current version lives at http://catb.org/~esr/faqs/hacker-howto.html. Note: there is a list of Frequently Asked Questions at the end of this document. Please read these—twice—before mailing me any questions about this document. Numerous translations of this document are available: Arabic Belorussian Bulgarian Chinese, Danish Dutch Estonian French German, Greek Italian Hebrew, Japanese Lithuanian Norwegian, Persian Polish Portuguese (Brazilian), Romanian Spanish, Turkish, and Swedish. Note that since this document changes occasionally, they may be out of date to varying degrees. The five-dots-in-nine-squares diagram that decorates this document is called a glider. It is a simple pattern with some surprising properties in a mathematical simulation called Life that has fascinated hackers for many years. I think it makes a good visual emblem for what hackers are like — abstract, at first a bit mysterious-seeming, but a gateway to a whole world with an intricate logic of its own. Read more about the glider emblem here. If you find this document valuable, please support me on Patreon. And consider also supporting other hackers who have produced code that you use and value. Lots of small but continuing donations add up quickly, and can free the people who have given you gifts of their labor to create more value. What Is a Hacker? The Jargon File contains a bunch of definitions of the term ‘hacker’, most having to do with technical adeptness and a delight in solving problems and overcoming limits. If you want to know how to become a hacker, though, only two are really relevant. There is a community, a shared culture, of expert programmers and networking wizards that traces its history back through decades to the first time-sharing minicomputers and the earliest ARPAnet experiments. The members of this culture originated the term ‘hacker’. Hackers built the Internet. Hackers made the Unix operating system what it is today. Hackers make the World Wide Web work. If you are part of this culture, if you have contributed to it and other people in it know who you are and call you a hacker, you’re a hacker. The hacker mind-set is not confined to this software-hacker culture. There are people who apply the hacker attitude to other things, like electronics or music — actually, you can find it at the highest levels of any science or art. Software hackers recognize these kindred spirits elsewhere and may call them ‘hackers’ too — and some claim that the hacker nature is really independent of the particular medium the hacker works in. But in the rest of this document we will focus on the skills and attitudes of software hackers, and the traditions of the shared culture that originated the term ‘hacker’. There is another group of people who loudly call themselves hackers, but aren’t. These are people (mainly adolescent males) who get a kick out of breaking into computers and phreaking the phone system. Real hackers call these people ‘crackers’ and want nothing to do with them. Real hackers mostly think crackers are lazy, irresponsible, and not very bright, and object that being able to break security doesn’t make you a hacker any more than being able to hotwire cars makes you an automotive engineer. Unfortunately, many journalists and writers have been fooled into using the word ‘hacker’ to describe crackers; this irritates real hackers no end. The basic difference is this: hackers build things, crackers break them. If you want to be a hacker, keep reading. If you want to be a cracker, go read the alt.2600 newsgroup and get ready to do five to ten in the slammer after finding out you aren’t as smart as you think you are. And that’s all I’m going to say about crackers. The Hacker Attitude The world is full of fascinating problems waiting to be solved. No problem should ever have to be solved twice. Boredom and drudgery are evil. Freedom is good. Attitude is no substitute for competence.Hackers solve problems and build things, and they believe in freedom and voluntary mutual help. To be accepted as a hacker, you have to behave as though you have this kind of attitude yourself. And to behave as though you have the attitude, you have to really believe the attitude. But if you think of cultivating hacker attitudes as just a way to gain acceptance in the culture, you’ll miss the point. Becoming the kind of person who believes these things is important for you — for helping you learn and keeping you motivated. As with all creative arts, the most effective way to become a master is to imitate the mind-set of masters — not just intellectually but emotionally as well. Or, as the following modern Zen poem has it: To follow the path: look to the master, follow the master, walk with the master, see through the master, become the master. So, if you want to be a hacker, repeat the following things until you believe them: The world is full of fascinating problems waiting to be solved. Being a hacker is lots of fun, but it’s a kind of fun that takes lots of effort. The effort takes motivation. Successful athletes get their motivation from a kind of physical delight in making their bodies perform, in pushing themselves past their own physical limits. Similarly, to be a hacker you have to get a basic thrill from solving problems, sharpening your skills, and exercising your intelligence. If you aren’t the kind of person that feels this way naturally, you’ll need to become one in order to make it as a hacker. Otherwise you’ll find your hacking energy is sapped by distractions like sex, money, and social approval. (You also have to develop a kind of faith in your own learning capacity — a belief that even though you may not know all of what you need to solve a problem, if you tackle just a piece of it and learn from that, you’ll learn enough to solve the next piece — and so on, until you’re done.) No problem should ever have to be solved twice. Creative brains are a valuable, limited resource. They shouldn’t be wasted on re-inventing the wheel when there are so many fascinating new problems waiting out there. To behave like a hacker, you have to believe that the thinking time of other hackers is precious — so much so that it’s almost a moral duty for you to share information, solve problems and then give the solutions away just so other hackers can solve new problems instead of having to perpetually re-address old ones. Note, however, that “No problem should ever have to be solved twice.” does not imply that you have to consider all existing solutions sacred, or that there is only one right solution to any given problem. Often, we learn a lot about the problem that we didn’t know before by studying the first cut at a solution. It’s OK, and often necessary, to decide that we can do better. What’s not OK is artificial technical, legal, or institutional barriers (like closed-source code) that prevent a good solution from being re-used and force people to re-invent wheels. (You don’t have to believe that you’re obligated to give all your creative product away, though the hackers that do are the ones that get most respect from other hackers. It’s consistent with hacker values to sell enough of it to keep you in food and rent and computers. It’s fine to use your hacking skills to support a family or even get rich, as long as you don’t forget your loyalty to your art and your fellow hackers while doing it.) Boredom and drudgery are evil. Hackers (and creative people in general) should never be bored or have to drudge at stupid repetitive work, because when this happens it means they aren’t doing what only they can do — solve new problems. This wastefulness hurts everybody. Therefore boredom and drudgery are not just unpleasant but actually evil. To behave like a hacker, you have to believe this enough to want to automate away the boring bits as much as possible, not just for yourself but for everybody else (especially other hackers). (There is one apparent exception to this. Hackers will sometimes do things that may seem repetitive or boring to an observer as a mind-clearing exercise, or in order to acquire a skill or have some particular kind of experience you can’t have otherwise. But this is by choice — nobody who can think should ever be forced into a situation that bores them.) Freedom is good. Hackers are naturally anti-authoritarian. Anyone who can give you orders can stop you from solving whatever problem you’re being fascinated by — and, given the way authoritarian minds work, will generally find some appallingly stupid reason to do so. So the authoritarian attitude has to be fought wherever you find it, lest it smother you and other hackers. (This isn’t the same as fighting all authority. Children need to be guided and criminals restrained. A hacker may agree to accept some kinds of authority in order to get something he wants more than the time he spends following orders. But that’s a limited, conscious bargain; the kind of personal surrender authoritarians want is not on offer.) Authoritarians thrive on censorship and secrecy. And they distrust voluntary cooperation and information-sharing — they only like ‘cooperation’ that they control. So to behave like a hacker, you have to develop an instinctive hostility to censorship, secrecy, and the use of force or deception to compel responsible adults. And you have to be willing to act on that belief. Attitude is no substitute for competence. To be a hacker, you have to develop some of these attitudes. But copping an attitude alone won’t make you a hacker, any more than it will make you a champion athlete or a rock star. Becoming a hacker will take intelligence, practice, dedication, and hard work. Therefore, you have to learn to distrust attitude and respect competence of every kind. Hackers won’t let posers waste their time, but they worship competence — especially competence at hacking, but competence at anything is valued. Competence at demanding skills that few can master is especially good, and competence at demanding skills that involve mental acuteness, craft, and concentration is best. If you revere competence, you’ll enjoy developing it in yourself — the hard work and dedication will become a kind of intense play rather than drudgery. That attitude is vital to becoming a hacker. Basic Hacking Skills Learn how to program. Get one of the open-source Unixes and learn to use and run it. Learn how to use the World Wide Web and write HTML. If you don’t have functional English, learn it.The hacker attitude is vital, but skills are even more vital. Attitude is no substitute for competence, and there’s a certain basic toolkit of skills which you have to have before any hacker will dream of calling you one. This toolkit changes slowly over time as technology creates new skills and makes old ones obsolete. For example, it used to include programming in machine language, and didn’t until recently involve HTML. But right now it pretty clearly includes the following: Learn how to program. This, of course, is the fundamental hacking skill. If you don’t know any computer languages, I recommend starting with Python. It is cleanly designed, well documented, and relatively kind to beginners. Despite being a good first language, it is not just a toy; it is very powerful and flexible and well suited for large projects. I have written a more detailed evaluation of Python. Good tutorials are available at the Python web site; there’s an excellent third-party one at Computer Science Circles. I used to recommend Java as a good language to learn early, but this critique has changed my mind (search for “The Pitfalls of Java as a First Programming Language” within it). A hacker cannot, as they devastatingly put it “approach problem-solving like a plumber in a hardware store”; you have to know what the components actually do. Now I think it is probably best to learn C and Lisp first, then Java. There is perhaps a more general point here. If a language does too much for you, it may be simultaneously a good tool for production and a bad one for learning. It’s not only languages that have this problem; web application frameworks like RubyOnRails, CakePHP, Django may make it too easy to reach a superficial sort of understanding that will leave you without resources when you have to tackle a hard problem, or even just debug the solution to an easy one. If you get into serious programming, you will have to learn C, the core language of Unix. C++ is very closely related to C; if you know one, learning the other will not be difficult. Neither language is a good one to try learning as your first, however. And, actually, the more you can avoid programming in C the more productive you will be. C is very efficient, and very sparing of your machine’s resources. Unfortunately, C gets that efficiency by requiring you to do a lot of low-level management of resources (like memory) by hand. All that low-level code is complex and bug-prone, and will soak up huge amounts of your time on debugging. With today’s machines as powerful as they are, this is usually a bad tradeoff — it’s smarter to use a language that uses the machine’s time less efficiently, but your time much more efficiently. Thus, Python. Other languages of particular importance to hackers include Perl and LISP. Perl is worth learning for practical reasons; it’s very widely used for active web pages and system administration, so that even if you never write Perl you should learn to read it. Many people use Perl in the way I suggest you should use Python, to avoid C programming on jobs that don’t require C’s machine efficiency. You will need to be able to understand their code. LISP is worth learning for a different reason — the profound enlightenment experience you will have when you finally get it. That experience will make you a better programmer for the rest of your days, even if you never actually use LISP itself a lot. (You can get some beginning experience with LISP fairly easily by writing and modifying editing modes for the Emacs text editor, or Script-Fu plugins for the GIMP.) It’s best, actually, to learn all five of Python, C/C++, Java, Perl, and LISP. Besides being the most important hacking languages, they represent very different approaches to programming, and each will educate you in valuable ways. But be aware that you won’t reach the skill level of a hacker or even merely a programmer simply by accumulating languages — you need to learn how to think about programming problems in a general way, independent of any one language. To be a real hacker, you need to get to the point where you can learn a new language in days by relating what’s in the manual to what you already know. This means you should learn several very different languages. I can’t give complete instructions on how to learn to program here — it’s a complex skill. But I can tell you that books and courses won’t do it — many, maybe most of the best hackers are self-taught. You can learn language features — bits of knowledge — from books, but the mind-set that makes that knowledge into living skill can be learned only by practice and apprenticeship. What will do it is (a) reading code and (b) writing code. Peter Norvig, who is one of Google’s top hackers and the co-author of the most widely used textbook on AI, has written an excellent essay called Teach Yourself Programming in Ten Years. His “recipe for programming success” is worth careful attention. Learning to program is like learning to write good natural language. The best way to do it is to read some stuff written by masters of the form, write some things yourself, read a lot more, write a little more, read a lot more, write some more … and repeat until your writing begins to develop the kind of strength and economy you see in your models. I have had more to say about this learning process in How To Learn Hacking. It’s a simple set of instructions, but not an easy one. Finding good code to read used to be hard, because there were few large programs available in source for fledgeling hackers to read and tinker with. This has changed dramatically; open-source software, programming tools, and operating systems (all built by hackers) are now widely available. Which brings me neatly to our next topic… Get one of the open-source Unixes and learn to use and run it. I’ll assume you have a personal computer or can get access to one. (Take a moment to appreciate how much that means. The hacker culture originally evolved back when computers were so expensive that individuals could not own them.) The single most important step any newbie can take toward acquiring hacker skills is to get a copy of Linux or one of the BSD-Unixes, install it on a personal machine, and run it. Yes, there are other operating systems in the world besides Unix. But they’re distributed in binary — you can’t read the code, and you can’t modify it. Trying to learn to hack on a Microsoft Windows machine or under any other closed-source system is like trying to learn to dance while wearing a body cast. Under Mac OS X it’s possible, but only part of the system is open source — you’re likely to hit a lot of walls, and you have to be careful not to develop the bad habit of depending on Apple’s proprietary code. If you concentrate on the Unix under the hood you can learn some useful things. Unix is the operating system of the Internet. While you can learn to use the Internet without knowing Unix, you can’t be an Internet hacker without understanding Unix. For this reason, the hacker culture today is pretty strongly Unix-centered. (This wasn’t always true, and some old-time hackers still aren’t happy about it, but the symbiosis between Unix and the Internet has become strong enough that even Microsoft’s muscle doesn’t seem able to seriously dent it.) So, bring up a Unix — I like Linux myself but there are other ways (and yes, you can run both Linux and Microsoft Windows on the same machine). Learn it. Run it. Tinker with it. Talk to the Internet with it. Read the code. Modify the code. You’ll get better programming tools (including C, LISP, Python, and Perl) than any Microsoft operating system can dream of hosting, you’ll have fun, and you’ll soak up more knowledge than you realize you’re learning until you look back on it as a master hacker. For more about learning Unix, see The Loginataka. You might also want to have a look at The Art Of Unix Programming. The blog Let’s Go Larval! is a window on the learning process of a a new Linux user that I think is unusually lucid and helpful. The post How I Learned Linux makes a good starting point. To get your hands on a Linux, see the Linux Online! site; you can download from there or (better idea) find a local Linux user group to help you with installation. During the first ten years of this HOWTO’s life, I reported that from a new user’s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable “Unity” desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better. You can find BSD Unix help and resources at www.bsd.org. A good way to dip your toes in the water is to boot up what Linux fans call a live CD, a distribution that runs entirely off a CD or USB stick without having to modify your hard disk. This may be slow, because CDs are slow, but it’s a way to get a look at the possibilities without having to do anything drastic. I have written a primer on the basics of Unix and the Internet. I used to recommend against installing either Linux or BSD as a solo project if you’re a newbie. Nowadays the installers have gotten good enough that doing it entirely on your own is possible, even for a newbie. Nevertheless, I still recommend making contact with your local Linux user’s group and asking for help. It can’t hurt, and may smooth the process. Learn how to use the World Wide Web and write HTML. Most of the things the hacker culture has built do their work out of sight, helping run factories and offices and universities without any obvious impact on how non-hackers live. The Web is the one big exception, the huge shiny hacker toy that even politicians admit has changed the world. For this reason alone (and a lot of other good ones as well) you need to learn how to work the Web. This doesn’t just mean learning how to drive a browser (anyone can do that), but learning how to write HTML, the Web’s markup language. If you don’t know how to program, writing HTML will teach you some mental habits that will help you learn. So build a home page. But just having a home page isn’t anywhere near good enough to make you a hacker. The Web is full of home pages. Most of them are pointless, zero-content sludge — very snazzy-looking sludge, mind you, but sludge all the same (for more on this see The HTML Hell Page). To be worthwhile, your page must have content — it must be interesting and/or useful to other hackers. And that brings us to the next topic… If you don’t have functional English, learn it. As an American and native English-speaker myself, I have previously been reluctant to suggest this, lest it be taken as a sort of cultural imperialism. But several native speakers of other languages have urged me to point out that English is the working language of the hacker culture and the Internet, and that you will need to know it to function in the hacker community. Back around 1991 I learned that many hackers who have English as a second language use it in technical discussions even when they share a birth tongue; it was reported to me at the time that English has a richer technical vocabulary than any other language and is therefore simply a better tool for the job. For similar reasons, translations of technical books written in English are often unsatisfactory (when they get done at all). Linus Torvalds, a Finn, comments his code in English (it apparently never occurred to him to do otherwise). His fluency in English has been an important factor in his ability to recruit a worldwide community of developers for Linux. It’s an example worth following. Being a native English-speaker does not guarantee that you have language skills good enough to function as a hacker. If your writing is semi-literate, ungrammatical, and riddled with misspellings, many hackers (including myself) will tend to ignore you. While sloppy writing does not invariably mean sloppy thinking, we’ve generally found the correlation to be strong — and we have no use for sloppy thinkers. If you can’t yet write competently, learn to. Status in the Hacker Culture Write open-source software Help test and debug open-source software Publish useful information Help keep the infrastructure working Serve the hacker culture itselfLike most cultures without a money economy, hackerdom runs on reputation. You’re trying to solve interesting problems, but how interesting they are, and whether your solutions are really good, is something that only your technical peers or superiors are normally equipped to judge. Accordingly, when you play the hacker game, you learn to keep score primarily by what other hackers think of your skill (this is why you aren’t really a hacker until other hackers consistently call you one). This fact is obscured by the image of hacking as solitary work; also by a hacker-cultural taboo (gradually decaying since the late 1990s but still potent) against admitting that ego or external validation are involved in one’s motivation at all. Specifically, hackerdom is what anthropologists call a gift culture. You gain status and reputation in it not by dominating other people, nor by being beautiful, nor by having things other people want, but rather by giving things away. Specifically, by giving away your time, your creativity, and the results of your skill. There are basically five kinds of things you can do to be respected by hackers: Write open-source software The first (the most central and most traditional) is to write programs that other hackers think are fun or useful, and give the program sources away to the whole hacker culture to use. (We used to call these works “free software”, but this confused too many people who weren’t sure exactly what “free” was supposed to mean. Most of us now prefer the term “open-source” software). Hackerdom’s most revered demigods are people who have written large, capable programs that met a widespread need and given them away, so that now everyone uses them. But there’s a bit of a fine historical point here. While hackers have always looked up to the open-source developers among them as our community’s hardest core, before the mid-1990s most hackers most of the time worked on closed source. This was still true when I wrote the first version of this HOWTO in 1996; it took the mainstreaming of open-source software after 1997 to change things. Today, “the hacker community” and “open-source developers” are two descriptions for what is essentially the same culture and population — but it is worth remembering that this was not always so. (For more on this, see the section called “Historical Note: Hacking, Open Source, and Free Software”.) Help test and debug open-source software They also serve who stand and debug open-source software. In this imperfect world, we will inevitably spend most of our software development time in the debugging phase. That’s why any open-source author who’s thinking will tell you that good beta-testers (who know how to describe symptoms clearly, localize problems well, can tolerate bugs in a quickie release, and are willing to apply a few simple diagnostic routines) are worth their weight in rubies. Even one of these can make the difference between a debugging phase that’s a protracted, exhausting nightmare and one that’s merely a salutary nuisance. If you’re a newbie, try to find a program under development that you’re interested in and be a good beta-tester. There’s a natural progression from helping test programs to helping debug them to helping modify them. You’ll learn a lot this way, and generate good karma with people who will help you later on. Publish useful information Another good thing is to collect and filter useful and interesting information into web pages or documents like Frequently Asked Questions (FAQ) lists, and make those generally available. Maintainers of major technical FAQs get almost as much respect as open-source authors. Help keep the infrastructure working The hacker culture (and the engineering development of the Internet, for that matter) is run by volunteers. There’s a lot of necessary but unglamorous work that needs done to keep it going — administering mailing lists, moderating newsgroups, maintaining large software archive sites, developing RFCs and other technical standards. People who do this sort of thing well get a lot of respect, because everybody knows these jobs are huge time sinks and not as much fun as playing with code. Doing them shows dedication. Serve the hacker culture itself Finally, you can serve and propagate the culture itself (by, for example, writing an accurate primer on how to become a hacker :-)). This is not something you’ll be positioned to do until you’ve been around for while and become well-known for one of the first four things. The hacker culture doesn’t have leaders, exactly, but it does have culture heroes and tribal elders and historians and spokespeople. When you’ve been in the trenches long enough, you may grow into one of these. Beware: hackers distrust blatant ego in their tribal elders, so visibly reaching for this kind of fame is dangerous. Rather than striving for it, you have to sort of position yourself so it drops in your lap, and then be modest and gracious about your status. The Hacker/Nerd Connection Contrary to popular myth, you don’t have to be a nerd to be a hacker. It does help, however, and many hackers are in fact nerds. Being something of a social outcast helps you stay concentrated on the really important things, like thinking and hacking. For this reason, many hackers have adopted the label ‘geek’ as a badge of pride — it’s a way of declaring their independence from normal social expectations (as well as a fondness for other things like science fiction and strategy games that often go with being a hacker). The term ‘nerd’ used to be used this way back in the 1990s, back when ‘nerd’ was a mild pejorative and ‘geek’ a rather harsher one; sometime after 2000 they switched places, at least in U.S. popular culture, and there is now even a significant geek-pride culture among people who aren’t techies. If you can manage to concentrate enough on hacking to be good at it and still have a life, that’s fine. This is a lot easier today than it was when I was a newbie in the 1970s; mainstream culture is much friendlier to techno-nerds now. There are even growing numbers of people who realize that hackers are often high-quality lover and spouse material. If you’re attracted to hacking because you don’t have a life, that’s OK too — at least you won’t have trouble concentrating. Maybe you’ll get a life later on. Points For Style Again, to be a hacker, you have to enter the hacker mindset. There are some things you can do when you’re not at a computer that seem to help. They’re not substitutes for hacking (nothing is) but many hackers do them, and feel that they connect in some basic way with the essence of hacking. Learn to write your native language well. Though it’s a common stereotype that programmers can’t write, a surprising number of hackers (including all the most accomplished ones I know of) are very able writers. Read science fiction. Go to science fiction conventions (a good way to meet hackers and proto-hackers). Join a hackerspace and make things (another good way to meet hackers and proto-hackers). Train in a martial-arts form. The kind of mental discipline required for martial arts seems to be similar in important ways to what hackers do. The most popular forms among hackers are definitely Asian empty-hand arts such as Tae Kwon Do, various forms of Karate, Kung Fu, Aikido, or Ju Jitsu. Western fencing and Asian sword arts also have visible followings. In places where it’s legal, pistol shooting has been rising in popularity since the late 1990s. The most hackerly martial arts are those which emphasize mental discipline, relaxed awareness, and precise control, rather than raw strength, athleticism, or physical toughness. Study an actual meditation discipline. The perennial favorite among hackers is Zen (importantly, it is possible to benefit from Zen without acquiring a religion or discarding one you already have). Other styles may work as well, but be careful to choose one that doesn’t require you to believe crazy things. Develop an analytical ear for music. Learn to appreciate peculiar kinds of music. Learn to play some musical instrument well, or how to sing. Develop your appreciation of puns and wordplay. The more of these things you already do, the more likely it is that you are natural hacker material. Why these things in particular is not completely clear, but they’re connected with a mix of left- and right-brain skills that seems to be important; hackers need to be able to both reason logically and step outside the apparent logic of a problem at a moment’s notice. Work as intensely as you play and play as intensely as you work. For true hackers, the boundaries between “play”, “work”, “science” and “art” all tend to disappear, or to merge into a high-level creative playfulness. Also, don’t be content with a narrow range of skills. Though most hackers self-describe as programmers, they are very likely to be more than competent in several related skills — system administration, web design, and PC hardware troubleshooting are common ones. A hacker who’s a system administrator, on the other hand, is likely to be quite skilled at script programming and web design. Hackers don’t do things by halves; if they invest in a skill at all, they tend to get very good at it. Finally, a few things not to do. Don’t use a silly, grandiose user ID or screen name. Don’t get in flame wars on Usenet (or anywhere else). Don’t call yourself a ‘cyberpunk’, and don’t waste your time on anybody who does. Don’t post or email writing that’s full of spelling errors and bad grammar. The only reputation you’ll make doing any of these things is as a twit. Hackers have long memories — it could take you years to live your early blunders down enough to be accepted. The problem with screen names or handles deserves some amplification. Concealing your identity behind a handle is a juvenile and silly behavior characteristic of crackers, warez d00dz, and other lower life forms. Hackers don’t do this; they’re proud of what they do and want it associated with their real names. So if you have a handle, drop it. In the hacker culture it will only mark you as a loser. Historical Note: Hacking, Open Source, and Free Software When I originally wrote this how-to in late 1996, some of the conditions around it were very different from the way they look today. A few words about these changes may help clarify matters for people who are confused about the relationship of open source, free software, and Linux to the hacker community. If you are not curious about this, you can skip straight to the FAQ and bibliography from here. The hacker ethos and community as I have described it here long predates the emergence of Linux after 1990; I first became involved with it around 1976, and, its roots are readily traceable back to the early 1960s. But before Linux, most hacking was done on either proprietary operating systems or a handful of quasi-experimental homegrown systems like MIT’s ITS that were never deployed outside of their original academic niches. While there had been some earlier (pre-Linux) attempts to change this situation, their impact was at best very marginal and confined to communities of dedicated true believers which were tiny minorities even within the hacker community, let alone with respect to the larger world of software in general. What is now called “open source” goes back as far as the hacker community does, but until 1985 it was an unnamed folk practice rather than a conscious movement with theories and manifestos attached to it. This prehistory ended when, in 1985, arch-hacker Richard Stallman (“RMS”) tried to give it a name — “free software”. But his act of naming was also an act of claiming; he attached ideological baggage to the “free software” label which much of the existing hacker community never accepted. As a result, the “free software” label was loudly rejected by a substantial minority of the hacker community (especially among those associated with BSD Unix), and used with serious but silent reservations by a majority of the remainder (including myself). Despite these reservations, RMS’s claim to define and lead the hacker community under the “free software” banner broadly held until the mid-1990s. It was seriously challenged only by the rise of Linux. Linux gave open-source development a natural home. Many projects issued under terms we would now call open-source migrated from proprietary Unixes to Linux. The community around Linux grew explosively, becoming far larger and more heterogenous than the pre-Linux hacker culture. RMS determinedly attempted to co-opt all this activity into his “free software” movement, but was thwarted by both the exploding diversity of the Linux community and the public skepticism of its founder, Linus Torvalds. Torvalds continued to use the term “free software” for lack of any alternative, but publicly rejected RMS’s ideological baggage. Many younger hackers followed suit. In 1996, when I first published this Hacker HOWTO, the hacker community was rapidly reorganizing around Linux and a handful of other open-source operating systems (notably those descended from BSD Unix). Community memory of the fact that most of us had spent decades developing closed-source software on closed-source operating systems had not yet begun to fade, but that fact was already beginning to seem like part of a dead past; hackers were, increasingly, defining themselves as hackers by their attachments to open-source projects such as Linux or Apache. The term “open source”, however, had not yet emerged; it would not do so until early 1998. When it did, most of the hacker community adopted it within the following six months; the exceptions were a minority ideologically attached to the term “free software”. Since 1998, and especially after about 2003, the identification of ‘hacking’ with ‘open-source (and free software) development’ has become extremely close. Today there is little point in attempting to distinguish between these categories, and it seems unlikely that will change in the future. It is worth remembering, however, that this was not always so. Other Resources Paul Graham has written an essay called Great Hackers, and another on Undergraduation, in which he speaks much wisdom. Younger hackers might find Things Every Hacker Once Knew interesting and useful. I have also written A Brief History Of Hackerdom. I have written a paper, The Cathedral and the Bazaar, which explains a lot about how the Linux and open-source cultures work. I have addressed this topic even more directly in its sequel Homesteading the Noosphere. Rick Moen has written an excellent document on how to run a Linux user group. Rick Moen and I have collaborated on another document on How To Ask Smart Questions. This will help you seek assistance in a way that makes it more likely that you will actually get it. If you need instruction in the basics of how personal computers, Unix, and the Internet work, see The Unix and Internet Fundamentals HOWTO. When you release software or write patches for software, try to follow the guidelines in the Software Release Practice HOWTO. If you enjoyed the Zen poem, you might also like Rootless Root: The Unix Koans of Master Foo. Frequently Asked Questions Q: How do I tell if I am already a hacker?Q: Will you teach me how to hack?Q: How can I get started, then?Q: When do you have to start? Is it too late for me to learn?Q: How long will it take me to learn to hack?Q: Is Visual Basic a good language to start with?Q: Would you help me to crack a system, or teach me how to crack?Q: How can I get the password for someone else’s account?Q: How can I break into/read/monitor someone else’s email?Q: How can I steal channel op privileges on IRC?Q: I’ve been cracked. Will you help me fend off further attacks?Q: I’m having problems with my Windows software. Will you help me?Q: Where can I find some real hackers to talk with?Q: Can you recommend useful books about hacking-related subjects?Q: Do I need to be good at math to become a hacker?Q: What language should I learn first?Q: What kind of hardware do I need?Q: I want to contribute. Can you help me pick a problem to work on?Q: Do I need to hate and bash Microsoft?Q: But won’t open-source software leave programmers unable to make a living?Q: Where can I get a free Unix?Q: How do I tell if I am already a hacker? A: Ask yourself the following three questions: Do you speak code, fluently? Do you identify with the goals and values of the hacker community? Has a well-established member of the hacker community ever called you a hacker? If you can answer yes to all three of these questions, you are already a hacker. No two alone are sufficient. The first test is about skills. You probably pass it if you have the minimum technical skills described earlier in this document. You blow right through it if you have had a substantial amount of code accepted by an open-source development project. The second test is about attitude. If the five principles of the hacker mindset seemed obvious to you, more like a description of the way you already live than anything novel, you are already halfway to passing it. That’s the inward half; the other, outward half is the degree to which you identify with the hacker community’s long-term projects. Here is an incomplete but indicative list of some of those projects: Does it matter to you that Linux improve and spread? Are you passionate about software freedom? Hostile to monopolies? Do you act on the belief that computers can be instruments of empowerment that make the world a richer and more humane place? But a note of caution is in order here. The hacker community has some specific, primarily defensive political interests — two of them are defending free-speech rights and fending off “intellectual-property” power grabs that would make open source illegal. Some of those long-term projects are civil-liberties organizations like the Electronic Frontier Foundation, and the outward attitude properly includes support of them. But beyond that, most hackers view attempts to systematize the hacker attitude into an explicit political program with suspicion; we’ve learned, the hard way, that these attempts are divisive and distracting. If someone tries to recruit you to march on your capitol in the name of the hacker attitude, they’ve missed the point. The right response is probably “Shut up and show them the code.” The third test has a tricky element of recursiveness about it. I observed in the section called “What Is a Hacker?” that being a hacker is partly a matter of belonging to a particular subculture or social network with a shared history, an inside and an outside. In the far past, hackers were a much less cohesive and self-aware group than they are today. But the importance of the social-network aspect has increased over the last thirty years as the Internet has made connections with the core of the hacker subculture easier to develop and maintain. One easy behavioral index of the change is that, in this century, we have our own T-shirts. Sociologists, who study networks like those of the hacker culture under the general rubric of “invisible colleges”, have noted that one characteristic of such networks is that they have gatekeepers — core members with the social authority to endorse new members into the network. Because the “invisible college” that is hacker culture is a loose and informal one, the role of gatekeeper is informal too. But one thing that all hackers understand in their bones is that not every hacker is a gatekeeper. Gatekeepers have to have a certain degree of seniority and accomplishment before they can bestow the title. How much is hard to quantify, but every hacker knows it when they see it. Q: Will you teach me how to hack? A: Since first publishing this page, I’ve gotten several requests a week (often several a day) from people to “teach me all about hacking”. Unfortunately, I don’t have the time or energy to do this; my own hacking projects, and working as an open-source advocate, take up 110% of my time. Even if I did, hacking is an attitude and skill you basically have to teach yourself. You’ll find that while real hackers want to help you, they won’t respect you if you beg to be spoon-fed everything they know. Learn a few things first. Show that you’re trying, that you’re capable of learning on your own. Then go to the hackers you meet with specific questions. If you do email a hacker asking for advice, here are two things to know up front. First, we’ve found that people who are lazy or careless in their writing are usually too lazy and careless in their thinking to make good hackers — so take care to spell correctly, and use good grammar and punctuation, otherwise you’ll probably be ignored. Secondly, don’t dare ask for a reply to an ISP account that’s different from the account you’re sending from; we find people who do that are usually thieves using stolen accounts, and we have no interest in rewarding or assisting thievery. Q: How can I get started, then? A: The best way for you to get started would probably be to go to a LUG (Linux user group) meeting. You can find such groups on the LDP General Linux Information Page; there is probably one near you, possibly associated with a college or university. LUG members will probably give you a Linux if you ask, and will certainly help you install one and get started. Your next step (and your first step if you can’t find a LUG nearby) should be to find an open-source project that interests you. Start reading code and reviewing bugs. Learn to contribute, and work your way in. The only way in is by working to improve your skills. If you ask me personally for advice on how to get started, I will tell you these exact same things, because I don’t have any magic shortcuts for you. I will also mentally write you off as a probable loser - because if you lacked the stamina to read this FAQ and the intelligence to understand from it that the only way in is by working to improve your skills, you’re hopeless. Another interesting possibility is to go visit a hackerspace. There is a burgeoning movement of people creating physical locations - maker’s clubs - where they can hang out to work on hardware and software projects together, or work solo in a cogenial atmosphere. Hackerspaces often collect tools and specialized equipment that would be too expensive or logistically inconvenient for individuals to own. Hackerspaces are easy to find on the Internet; one may be located near you. Q: When do you have to start? Is it too late for me to learn? A: Any age at which you are motivated to start is a good age. Most people seem to get interested between ages 15 and 20, but I know of exceptions in both directions. Q: How long will it take me to learn to hack? A: That depends on how talented you are and how hard you work at it. Most people who try can acquire a respectable skill set in eighteen months to two years, if they concentrate. Don’t think it ends there, though; in hacking (as in many other fields) it takes about ten years to achieve mastery. And if you are a real hacker, you will spend the rest of your life learning and perfecting your craft. Q: Is Visual Basic a good language to start with? A: If you’re asking this question, it almost certainly means you’re thinking about trying to hack under Microsoft Windows. This is a bad idea in itself. When I compared trying to learn to hack under Windows to trying to learn to dance while wearing a body cast, I wasn’t kidding. Don’t go there. It’s ugly, and it never stops being ugly. There is a specific problem with Visual Basic; mainly that it’s not portable. Though there is a prototype open-source implementations of Visual Basic, the applicable ECMA standards don’t cover more than a small set of its programming interfaces. On Windows most of its library support is proprietary to a single vendor (Microsoft); if you aren’t extremely careful about which features you use — more careful than any newbie is really capable of being — you’ll end up locked into only those platforms Microsoft chooses to support. If you’re starting on a Unix, much better languages with better libraries are available. Python, for example. Also, like other Basics, Visual Basic is a poorly-designed language that will teach you bad programming habits. No, don’t ask me to describe them in detail; that explanation would fill a book. Learn a well-designed language instead. One of those bad habits is becoming dependent on a single vendor’s libraries, widgets, and development tools. In general, any language that isn’t fully supported under at least Linux or one of the BSDs, and/or at least three different vendors’ operating systems, is a poor one to learn to hack in. Q: Would you help me to crack a system, or teach me how to crack? A: No. Anyone who can still ask such a question after reading this FAQ is too stupid to be educable even if I had the time for tutoring. Any emailed requests of this kind that I get will be ignored or answered with extreme rudeness. Q: How can I get the password for someone else’s account? A: This is cracking. Go away, idiot. Q: How can I break into/read/monitor someone else’s email? A: This is cracking. Get lost, moron. Q: How can I steal channel op privileges on IRC? A: This is cracking. Begone, cretin. Q: I’ve been cracked. Will you help me fend off further attacks? A: No. Every time I’ve been asked this question so far, it’s been from some poor sap running Microsoft Windows. It is not possible to effectively secure Windows systems against crack attacks; the code and architecture simply have too many flaws, which makes securing Windows like trying to bail out a boat with a sieve. The only reliable prevention starts with switching to Linux or some other operating system that is designed to at least be capable of security. Q: I’m having problems with my Windows software. Will you help me? A: Yes. Go to a DOS prompt and type “format c:”. Any problems you are experiencing will cease within a few minutes. Q: Where can I find some real hackers to talk with? A: The best way is to find a Unix or Linux user’s group local to you and go to their meetings (you can find links to several lists of user groups on the LDP site at ibiblio). (I used to say here that you wouldn’t find any real hackers on IRC, but I’m given to understand this is changing. Apparently some real hacker communities, attached to things like GIMP and Perl, have IRC channels now.) Q: Can you recommend useful books about hacking-related subjects? A: I maintain a Linux Reading List HOWTO that you may find helpful. The Loginataka may also be interesting. For an introduction to Python, see the tutorial on the Python site. Q: Do I need to be good at math to become a hacker? A: No. Hacking uses very little formal mathematics or arithmetic. In particular, you won’t usually need trigonometry, calculus or analysis (there are exceptions to this in a handful of specific application areas like 3-D computer graphics). Knowing some formal logic and Boolean algebra is good. Some grounding in finite mathematics (including finite-set theory, combinatorics, and graph theory) can be helpful. Much more importantly: you need to be able to think logically and follow chains of exact reasoning, the way mathematicians do. While the content of most mathematics won’t help you, you will need the discipline and intelligence to handle mathematics. If you lack the intelligence, there is little hope for you as a hacker; if you lack the discipline, you’d better grow it. I think a good way to find out if you have what it takes is to pick up a copy of Raymond Smullyan’s book What Is The Name Of This Book?. Smullyan’s playful logical conundrums are very much in the hacker spirit. Being able to solve them is a good sign; enjoying solving them is an even better one. Q: What language should I learn first? A: HTML if you don’t already know it. There are a lot of glossy, hype-intensive bad HTML books out there, and distressingly few good ones. The one I like best is HTML: The Definitive Guide. But HTML is not a full programming language. When you’re ready to start programming, I would recommend starting with Python. You will hear a lot of people recommending Perl, but it’s harder to learn and (in my opinion) less well designed. C is really important, but it’s also much more difficult than either Python or Perl. Don’t try to learn it first. Windows users, do not settle for Visual Basic. It will teach you bad habits, and it’s not portable off Windows. Avoid. Q: What kind of hardware do I need? A: It used to be that personal computers were rather underpowered and memory-poor, enough so that they placed artificial limits on a hacker’s learning process. This stopped being true in the mid-1990s; any machine from an Intel 486DX50 up is more than powerful enough for development work, X, and Internet communications, and the smallest disks you can buy today are plenty big enough. The important thing in choosing a machine on which to learn is whether its hardware is Linux-compatible (or BSD-compatible, should you choose to go that route). Again, this will be true for almost all modern machines. The only really sticky areas are modems and wireless cards; some machines have Windows-specific hardware that won’t work with Linux. There’s a FAQ on hardware compatibility; the latest version is here. Q: I want to contribute. Can you help me pick a problem to work on? A: No, because I don’t know your talents or interests. You have to be self-motivated or you won’t stick, which is why having other people choose your direction almost never works. Q: Do I need to hate and bash Microsoft? A: No, you don’t. Not that Microsoft isn’t loathsome, but there was a hacker culture long before Microsoft and there will still be one long after Microsoft is history. Any energy you spend hating Microsoft would be better spent on loving your craft. Write good code — that will bash Microsoft quite sufficiently without polluting your karma. Q: But won’t open-source software leave programmers unable to make a living? A: This seems unlikely — so far, the open-source software industry seems to be creating jobs rather than taking them away. If having a program written is a net economic gain over not having it written, a programmer will get paid whether or not the program is going to be open-source after it’s done. And, no matter how much “free” software gets written, there always seems to be more demand for new and customized applications. I’ve written more about this at the Open Source pages. Q: Where can I get a free Unix? A: If you don’t have a Unix installed on your machine yet, elsewhere on this page I include pointers to where to get the most commonly used free Unix. To be a hacker you need motivation and initiative and the ability to educate yourself. Start now…","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[]},{"title":"The Unix and Internet Fundamentals HOWTO","date":"2017-01-20T12:31:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/the-unix-and-internet-fundamentals-howto/","text":"Eric Raymond This document describes the working basics of PC-class computers, Unix-like operating systems, and the Internet in non-technical language. Table of Contents Introduction1.1. Purpose of this document1.2. New versions of this document1.3. Feedback and corrections1.4. Related resources Basic anatomy of your computer What happens when you switch on a computer? What happens when you log in? What happens when you run programs from the shell? How do input devices and interrupts work? How does my computer do several things at once? How does my computer keep processes from stepping on each other?8.1. Virtual memory: the simple version8.2. Virtual memory: the detailed version8.3. The Memory Management Unit How does my computer store things in memory?9.1. Numbers9.2. Characters How does my computer store things on disk?10.1. Low-level disk and file system structure10.2. File names and directories10.3. Mount points10.4. How a file gets looked up10.5. File ownership, permissions and security10.6. How things can go wrong How do computer languages work?11.1. Compiled languages11.2. Interpreted languages11.3. P-code languages How does the Internet work?12.1. Names and locations12.2. The Domain Name System12.3. Packets and routers12.4. TCP and IP12.5. HTTP, an application protocol To Learn More 1. Introduction1.1. Purpose of this document This document is intended to help Linux and Internet users who are learning by doing. While this is a great way to acquire specific skills, sometimes it leaves peculiar gaps in one’s knowledge of the basics – gaps which can make it hard to think creatively or troubleshoot effectively, from lack of a good mental model of what is really going on. I’ll try to describe in clear, simple language how it all works. The presentation will be tuned for people using Unix or Linux on PC-class hardware. Nevertheless, I’ll usually refer simply to `Unix’ here, as most of what I will describe is constant across platforms and across Unix variants. I’m going to assume you’re using an Intel PC. The details differ slightly if you’re running an Alpha or PowerPC or some other Unix box, but the basic concepts are the same. I won’t repeat things, so you’ll have to pay attention, but that also means you’ll learn from every word you read. It’s a good idea to just skim when you first read this; you should come back and reread it a few times after you’ve digested what you have learned. This is an evolving document. I intend to keep adding sections in response to user feedback, so you should come back and review it periodically. 1.2. New versions of this document New versions of the Unix and Internet Fundamentals HOWTO will be periodically posted to comp.os.linux.help and comp.os.linux.announce and news.answers. They will also be uploaded to various Linux WWW and FTP sites, including the LDP home page. You can view the latest version of this on the World Wide Web via the URL http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html. This document has been translated into Polish. 1.3. Feedback and corrections If you have questions or comments about this document, please feel free to mail Eric S. Raymond, at esr@thyrsus.com. I welcome any suggestions or criticisms. I especially welcome hyperlinks to more detailed explanations of individual concepts. If you find a mistake with this document, please let me know so I can correct it in the next version. Thanks. 1.4. Related resources If you’re reading this in order to learn how to hack, you should also read the How To Become A Hacker FAQ. It has links to some other useful resources. 2. Basic anatomy of your computerYour computer has a processor chip inside it that does the actual computing. It has internal memory (what DOS/Windows people call RAM&#39;&#39; and Unix people often callcore’’; the Unix term is a folk memory from when RAM consisted of ferrite-core donuts). The processor and memory live on the motherboard, which is the heart of your computer. Your computer has a screen and keyboard. It has hard drives and floppy disks. Some of these devices are run by controller cards that plug into the motherboard and help the computer drive them; others are run by specialized chipsets directly on the motherboard that fulfill the same function as a controller card. Your keyboard is too simple to need a separate card; the controller is built into the keyboard chassis itself. We’ll go into some of the details of how these devices work later. For now, here are a few basic things to keep in mind about how they work together: All the parts of your computer inside the case are connected by a bus. Physically, the bus is what you plug your controller cards into (the video card, the disk controller, a sound card if you have one). The bus is the data highway between your processor, your screen, your disk, and everything else. (If you’ve seen references to ISA&#39;,PCI’, and `PCMCIA’ in connection with PCs and have not understood them, these are bus types. ISA is, except in minor details, the same bus that was used on IBM’s original PCs in 1980; it is passing out of use now. PCI, for Peripheral Component Interconnection, is the bus used on most modern PCs, and on modern Macintoshes as well. PCMCIA is a variant of ISA with smaller physical connectors used on laptop computers.) The processor, which makes everything else go, can’t actually see any of the other pieces directly; it has to talk to them over the bus. The only other subsystem that it has really fast, immediate access to is memory (the core). In order for programs to run, then, they have to be in core (in memory). When your computer reads a program or data off the disk, what actually happens is that the processor uses the bus to send a disk read request to your disk controller. Some time later the disk controller uses the bus to signal the processor that it has read the data and put it in a certain location in memory. The processor can then use the bus to look at that data. Your keyboard and screen also communicate with the processor via the bus, but in simpler ways. We’ll discuss those later on. For now, you know enough to understand what happens when you turn on your computer. 3. What happens when you switch on a computer? A computer without a program running is just an inert hunk of electronics. The first thing a computer has to do when it is turned on is start up a special program called an operating system. The operating system’s job is to help other computer programs to work by handling the messy details of controlling the computer’s hardware. The process of bringing up the operating system is called booting (originally this was bootstrapping and alluded to the process of pulling yourself up ``by your bootstraps’’). Your computer knows how to boot because instructions for booting are built into one of its chips, the BIOS (or Basic Input/Output System) chip. The BIOS chip tells it to look in a fixed place, usually on the lowest-numbered hard disk (the boot disk) for a special program called a boot loader (under Linux the boot loader is called LILO). The boot loader is pulled into memory and started. The boot loader’s job is to start the real operating system. The loader does this by looking for a kernel, loading it into memory, and starting it. When you boot Linux and see “LILO” on the screen followed by a bunch of dots, it is loading the kernel. (Each dot means it has loaded another disk block of kernel code.) ( You may wonder why the BIOS doesn’t load the kernel directly – why the two-step process with the boot loader? Well, the BIOS isn’t very smart. In fact it’s very stupid, and Linux doesn’t use it at all after boot time. It was originally written for primitive 8-bit PCs with tiny disks, and literally can’t access enough of the disk to load the kernel directly. The boot loader step also lets you start one of several operating systems off different places on your disk, in the unlikely event that Unix isn’t good enough for you.) Once the kernel starts, it has to look around, find the rest of the hardware, and get ready to run programs. It does this by poking not at ordinary memory locations but rather at I/O ports – special bus addresses that are likely to have device controller cards listening at them for commands. The kernel doesn’t poke at random; it has a lot of built-in knowledge about what it’s likely to find where, and how controllers will respond if they’re present. This process is called autoprobing. Most of the messages you see at boot time are the kernel autoprobing your hardware through the I/O ports, figuring out what it has available to it and adapting itself to your machine. The Linux kernel is extremely good at this, better than most other Unixes and much better than DOS or Windows. In fact, many Linux old-timers think the cleverness of Linux’s boot-time probes (which made it relatively easy to install) was a major reason it broke out of the pack of free-Unix experiments to attract a critical mass of users. But getting the kernel fully loaded and running isn’t the end of the boot process; it’s just the first stage (sometimes called run level 1). After this first stage, the kernel hands control to a special process called `init’ which spawns several housekeeping processes. The init process’s first job is usually to check to make sure your disks are OK. Disk file systems are fragile things; if they’ve been damaged by a hardware failure or a sudden power outage, there are good reasons to take recovery steps before your Unix is all the way up. We’ll go into some of this later on when we talk about how file systems can go wrong. Init’s next step is to start several daemons. A daemon is a program like a print spooler, a mail listener or a WWW server that lurks in the background, waiting for things to do. These special programs often have to coordinate several requests that could conflict. They are daemons because it’s often easier to write one program that runs constantly and knows about all requests than it would be to try to make sure that a flock of copies (each processing one request and all running at the same time) don’t step on each other. The particular collection of daemons your system starts may vary, but will almost always include a print spooler (a gatekeeper daemon for your printer). The next step is to prepare for users. Init starts a copy of a program called getty to watch your console (and maybe more copies to watch dial-in serial ports). This program is what issues the login prompt to your console. Once all daemons and getty processes for each terminal are started, we’re at run level 2. At this level, you can log in and run programs. But we’re not done yet. The next step is to start up various daemons that support networking and other services. Once that’s done, we’re at run level 3 and the system is fully ready for use. 4. What happens when you log in?When you log in (give a name to getty) you identify yourself to the computer. It then runs a program called (naturally enough) login, which takes your password and checks to see if you are authorized to be using the machine. If you aren’t, your login attempt will be rejected. If you are, login does a few housekeeping things and then starts up a command interpreter, the shell. (Yes, getty and login could be one program. They’re separate for historical reasons not worth going into here.) Here’s a bit more about what the system does before giving you a shell (you’ll need to know this later when we talk about file permissions). You identify yourself with a login name and password. That login name is looked up in a file called /etc/passwd, which is a sequence of lines each describing a user account. One of these fields is an encrypted version of the account password (sometimes the encrypted fields are actually kept in a second /etc/shadow file with tighter permissions; this makes password cracking harder). What you enter as an account password is encrypted in exactly the same way, and the login program checks to see if they match. The security of this method depends on the fact that, while it’s easy to go from your clear password to the encrypted version, the reverse is very hard. Thus, even if someone can see the encrypted version of your password, they can’t use your account. (It also means that if you forget your password, there’s no way to recover it, only to change it to something else you choose.) Once you have successfully logged in, you get all the privileges associated with the individual account you are using. You may also be recognized as part of a group. A group is a named collection of users set up by the system administrator. Groups can have privileges independently of their members’ privileges. A user can be a member of multiple groups. (For details about how Unix privileges work, see the section below on permissions.) (Note that although you will normally refer to users and groups by name, they are actually stored internally as numeric IDs. The password file maps your account name to a user ID; the /etc/group file maps group names to numeric group IDs. Commands that deal with accounts and groups do the translation automatically.) Your account entry also contains your home directory, the place in the Unix file system where your personal files will live. Finally, your account entry also sets your shell, the command interpreter that login will start up to accept your commmands. 5. What happens when you run programs from the shell?The shell is Unix’s interpreter for the commands you type in; ## it’s called a shell because it wraps around and hides the operating system kernel.## It’s an important feature of Unix that the shell and kernel are separate programs communicating through a small set of system calls. This makes it possible for there to be multiple shells, suiting different tastes in interfaces. The normal shell gives you the ‘$’ prompt that you see after logging in (unless you’ve customized it to be something else). We won’t talk about shell syntax and the easy things you can see on the screen here; instead we’ll take a look behind the scenes at what’s happening from the computer’s point of view. After boot time and before you run a program, you can think of your computer as containing a zoo of processes that are all waiting for something to do. They’re all waiting on events. An event can be you pressing a key or moving a mouse. Or, if your machine is hooked to a network, an event can be a data packet coming in over that network. The kernel is one of these processes. It’s a special one, because it controls when the other user processes can run, and it is normally the only process with direct access to the machine’s hardware. In fact, user processes have to make requests to the kernel when they want to get keyboard input, write to your screen, read from or write to disk, or do just about anything other than crunching bits in memory. These requests are known as system calls. Normally all I/O goes through the kernel so it can schedule the operations and prevent processes from stepping on each other. A few special user processes are allowed to slide around the kernel, usually by being given direct access to I/O ports. X servers (the programs that handle other programs’ requests to do screen graphics on most Unix boxes) are the most common example of this. But we haven’t gotten to an X server yet; you’re looking at a shell prompt on a character console. The shell is just a user process, and not a particularly special one. It waits on your keystrokes, listening (through the kernel) to the keyboard I/O port. As the kernel sees them, it echoes them to your screen. When the kernel sees an `Enter’ it passes your line of text to the shell. The shell tries to interpret those keystrokes as commands. **Let’s say you type ls&#39; and Enter to invoke the Unix directory lister. The shell applies its built-in rules to figure out that you want to run the executable command in the file/bin/ls’. It makes a system call asking the kernel to start /bin/ls as a new child process and give it access to the screen and keyboard through the kernel. Then the shell goes to sleep, waiting for ls to finish. When /bin/ls is done, it tells the kernel it’s finished by issuing an exit system call. The kernel then wakes up the shell and tells it it can continue running. The shell issues another prompt and waits for another line of input.** Other things may be going on while your `ls’ is executing, however (we’ll have to suppose that you’re listing a very long directory). You might switch to another virtual console, log in there, and start a game of Quake, for example. Or, suppose you’re hooked up to the Internet. Your machine might be sending or receiving mail while /bin/ls runs. 6. How do input devices and interrupts work?Your keyboard is a very simple input device; simple because it generates small amounts of data very slowly (by a computer’s standards). When you press or release a key, that event is signalled up the keyboard cable to raise a hardware interrupt. It’s the operating system’s job to watch for such interrupts. For each possible kind of interrupt, there will be an interrupt handler, a part of the operating system that stashes away any data associated with them (like your keypress/keyrelease value) until it can be processed. What the interrupt handler for your keyboard actually does is post the key value into a system area near the bottom of memory. There, it will be available for inspection when the operating system passes control to whichever program is currently supposed to be reading from the keyboard. More complex input devices like disk or network cards work in a similar way. Earlier, I referred to a disk controller using the bus to signal that a disk request has been fulfilled. What actually happens is that the disk raises an interrupt. The disk interrupt handler then copies the retrieved data into memory, for later use by the program that made the request. Every kind of interrupt has an associated priority level. Lower-priority interrupts (like keyboard events) have to wait on higher-priority interrupts (like clock ticks or disk events). Unix is designed to give high priority to the kinds of events that need to be processed rapidly in order to keep the machine’s response smooth. In your operating system’s boot-time messages, you may see references to IRQ numbers. You may be aware that one of the common ways to misconfigure hardware is to have two different devices try to use the same IRQ, without understanding exactly why. Here’s the answer. IRQ is short for “Interrupt Request”. The operating system needs to know at startup time which numbered interrupts each hardware device will use, so it can associate the proper handlers with each one. If two different devices try use the same IRQ, interrupts will sometimes get dispatched to the wrong handler. This will usually at least lock up the device, and can sometimes confuse the OS badly enough that it will flake out or crash. 7. How does my computer do several things at once?It doesn’t, actually. Computers can only do one task (or process) at a time. But a computer can change tasks very rapidly, and fool slow human beings into thinking it’s doing several things at once. This is called timesharing. One of the kernel’s jobs is to manage timesharing. It has a part called the scheduler which keeps information inside itself about all the other (non-kernel) processes in your zoo. Every 1/60th of a second, a timer goes off in the kernel, generating a clock interrupt. The scheduler stops whatever process is currently running, suspends it in place, and hands control to another process. 1/60th of a second may not sound like a lot of time. But on today’s microprocessors it’s enough to run tens of thousands of machine instructions, which can do a great deal of work. So even if you have many processes, each one can accomplish quite a bit in each of its timeslices. In practice, a program may not get its entire timeslice. If an interrupt comes in from an I/O device, the kernel effectively stops the current task, runs the interrupt handler, and then returns to the current task. A storm of high-priority interrupts can squeeze out normal processing; this misbehavior is called thrashing and is fortunately very hard to induce under modern Unixes. In fact, the speed of programs is only very seldom limited by the amount of machine time they can get (there are a few exceptions to this rule, such as sound or 3-D graphics generation). Much more often, delays are caused when the program has to wait on data from a disk drive or network connection. An operating system that can routinely support many simultaneous processes is called “multitasking”. The Unix family of operating systems was designed from the ground up for multitasking and is very good at it – much more effective than Windows or the Mac OS, which have had multitasking bolted into it as an afterthought and do it rather poorly. Efficient, reliable multitasking is a large part of what makes Linux superior for networking, communications, and Web service. 8. How does my computer keep processes from stepping on each other?The kernel’s scheduler takes care of dividing processes in time. Your operating system also has to divide them in space, so that processes can’t step on each others’ working memory. Even if you assume that all programs are trying to be cooperative, you don’t want a bug in one of them to be able to corrupt others. The things your operating system does to solve this problem are called memory management. Each process in your zoo needs its own area of memory, as a place to run its code from and keep variables and results in. You can think of this set as consisting of a read-only code segment (containing the process’s instructions) and a writeable data segment (containing all the process’s variable storage). The data segment is truly unique to each process, but if two processes are running the same code Unix automatically arranges for them to share a single code segment as an efficiency measure. 8.1. Virtual memory: the simple version Efficiency is important, because memory is expensive. Sometimes you don’t have enough to hold the entirety of all the programs the machine is running, especially if you are using a large program like an X server. To get around this, Unix uses a technique called virtual memory. It doesn’t try to hold all the code and data for a process in memory. Instead, it keeps around only a relatively small working set; the rest of the process’s state is left in a special swap space area on your hard disk. Note that in the past, that “Sometimes” last paragraph ago was “Almost always” – the size of memory was typically small relative to the size of running programs, so swapping was frequent. Memory is far less expensive nowadays and even low-end machines have quite a lot of it. On modern single-user machines with 64MB of memory and up, it’s possible to run X and a typical mix of jobs without ever swapping after they’re initially loded into core. 8.2. Virtual memory: the detailed version Actually, the last section oversimplified things a bit. Yes, programs see most of your memory as one big flat bank of addresses bigger than physical memory, and disk swapping is used to maintain that illusion. But your hardware actually has no fewer than five different kinds of memory in it, and the differences between them can matter a good deal when programs have to be tuned for maximum speed. To really understand what goes on in your machine, you should learn how all of them work. The five kinds of memory are these: processor registers, internal (or on-chip) cache, external (or off-chip) cache, main memory, and disk. And the reason there are so many kinds is simple: speed costs money. I have listed these kinds of memory in decreasing order of access time and increasing order of cost. Register memory is the fastest and most expensive and can be random-accessed about a billion times a second, while disk is the slowest and cheapest and can do about 100 random accesses a second. Here’s a full list reflecting early-2000 speeds for a typical desktop machine. While speed and capacity will go up and prices will drop, you can expect these ratios to remain fairly constant – and it’s those ratios that shape the memory hierarchy. DiskSize: 13000MB Accesses: 100KB/sec Main memorySize: 256MB Accesses: 100M/sec External cacheSize: 512KB Accesses: 250M/sec Internal CacheSize: 32KB Accesses: 500M/sec ProcessorSize: 28 bytes Accesses: 1000M/sec We can’t build everything out of the fastest kinds of memory. It would be way too expensive – and even if it weren’t, fast memory is volatile. That is, it loses its marbles when the power goes off. Thus, computers have to have hard disks or other kinds of non-volatile storage that retains data when the power goes off. And there’s a huge mismatch between the speed of processors and the speed of disks. The middle three levels of the memory hierarchy (internal cache, external cache, and main memory) basically exist to bridge that gap. Linux and other Unixes have a feature called virtual memory. What this means is that the operating system behaves as though it has much more main memory than it actually does. Your actual physical main memory behaves like a set of windows or caches on a much larger “virtual” memory space, most of which at any given time is actually stored on disk in a special zone called the swap area. Out of sight of user programs, the OS is moving blocks of data (called “pages”) between memory and disk to maintain this illusion. The end result is that your virtual memory is much larger but not too much slower than real memory. How much slower virtual memory is than physical depends on how well the operating system’s swapping algorithms match the way your programs use virtual memory. Fortunately, memory reads and writes that are close together in time also tend to cluster in memory space. This tendency is called locality, or more formally locality of reference – and it’s a good thing. If memory references jumped around virtual space at random, you’d typically have to do a disk read and write for each new reference and virtual memory would be as slow as a disk. But because programs do actually exhibit strong locality, your operating system can do relatively few swaps per reference. It’s been found by experience that the most effective method for a broad class of memory-usage patterns is very simple; it’s called LRU or the “least recently used” algorithm. The virtual-memory system grabs disk blocks into its working set as it needs them. When it runs out of physical memory for the working set, it dumps the least-recently-used block. All Unixes, and most other virtual-memory operating systems, use minor variations on LRU. Virtual memory is the first link in the bridge between disk and processor speeds. It’s explicitly managed by the OS. But there is still a major gap between the speed of physical main memory and the speed at which a processor can access its register memory. The external and internal caches address this, using a technique similar to virtual memory as I’ve described it. Just as the physical main memory behaves like a set of windows or caches on the disk’s swap area, the external cache acts as windows on main memory. External cache is faster (250M accesses per sec, rather than 100M) and smaller. The hardware (specifically, your computer’s memory controller) does the LRU thing in the external cache on blocks of data fetched from the main memory. For historical reasons, the unit of cache swapping is called a “line” rather than a page. But we’re not done. The internal cache gives us the final step-up in effective speed by caching portions of the external cache. It is faster and smaller yet – in fact, it lives right on the processor chip. If you want to make your programs really fast, it’s useful to know these details. Your programs get faster when they have stronger locality, because that makes the caching work better. The easiest way to make programs fast is therefore to make them small. If a program isn’t slowed down by lots of disk I/O or waits on network events, it will usually run at the speed of the smallest cache that it will fit inside. If you can’t make your whole program small, some effort to tune the speed-critical portions so they have stronger locality can pay off. Details on techniques for doing such tuning are beyond the scope of this tutorial; by the time you need them, you’ll be intimate enough with some compiler to figure out many of them yourself. 8.3. The Memory Management Unit Even when you have enough physical core to avoid swapping, the part of the operating system called the memory manager still has important work to do. It has to make sure that programs can only alter their own data segments – that is, prevent erroneous or malicious code in one program from garbaging the data in another. To do this, it keeps a table of data and code segments. The table is updated whenever a process either requests more memory or releases memory (the latter usually when it exits). This table is used to pass commands to a specialized part of the underlying hardware called an MMU or memory management unit. Modern processor chips have MMUs built right onto them. The MMU has the special ability to put fences around areas of memory, so an out-of-bound reference will be refused and cause a special interrupt to be raised. If you ever see a Unix message that says “Segmentation fault”, “core dumped” or something similar, this is exactly what has happened; an attempt by the running program to access memory (core) outside its segment has raised a fatal interrupt. This indicates a bug in the program code; the core dump it leaves behind is diagnostic information intended to help a programmer track it down. There is another aspect to protecting processes from each other besides segregating the memory they access. You also want to be able to control their file accesses so a buggy or malicious program can’t corrupt critical pieces of the system. This is why Unix has file permissions which we’ll discuss later. 9. How does my computer store things in memory?You probably know that everything on a computer is stored as strings of bits (binary digits; you can think of them as lots of little on-off switches). Here we’ll explain how those bits are used to represent the letters and numbers that your computer is crunching. Before we can go into this, you need to understand about the word size of your computer. The word size is the computer’s preferred size for moving units of information around; technically it’s the width of your processor’s registers, which are the holding areas your processor uses to do arithmetic and logical calculations. When people write about computers having bit sizes (calling them, say, 32-bit&#39;&#39; or64-bit’’ computers), this is what they mean. Most computers (including 386, 486, and Pentium PCs) have a word size of 32 bits. The old 286 machines had a word size of 16. Old-style mainframes often had 36-bit words. A few processors (like the Alpha from what used to be DEC and is now Compaq) have 64-bit words. The 64-bit word will become more common over the next five years; Intel is planning to replace the Pentium series with a 64-bit chip called the `Itanium’. The computer views your memory as a sequence of words numbered from zero up to some large value dependent on your memory size. That value is limited by your word size, which is why programs on older machines like 286s had to go through painful contortions to address large amounts of memory. I won’t describe them here; they still give older programmers nightmares. 9.1. Numbers Integer numbers are represented as either words or pairs of words, depending on your processor’s word size. One 32-bit machine word is the most common integer representation. Integer arithmetic is close to but not actually mathematical base-two. The low-order bit is 1, next 2, then 4 and so forth as in pure binary. But signed numbers are represented in twos-complement notation. The highest-order bit is a sign bit which makes the quantity negative, and every negative number can be obtained from the corresponding positive value by inverting all the bits and adding one. This is why integers on a 32-bit machine have the range -2^31 to 2^31 - 1 1 (where ^ is the `power’ operation, 2^3 = 8). That 32nd bit is being used for sign. Some computer languages give you access to unsigned arithmetic which is straight base 2 with zero and positive numbers only. Most processors and some languages can do operations in floating-point numbers (this capability is built into all recent processor chips). Floating-point numbers give you a much wider range of values than integers and let you express fractions. The ways in which this is done vary and are rather too complicated to discuss in detail here, but the general idea is much like so-called `scientific notation’, where one might write (say) 1.234 * 10^23; the encoding of the number is split into a mantissa (1.234) and the exponent part (23) for the power-of-ten multiplier (which means the number multiplied out would have 20 zeros on it, 23 minus the three decimal places). 9.2. Characters Characters are normally represented as strings of seven bits each in an encoding called ASCII (American Standard Code for Information Interchange). On modern machines, each of the 128 ASCII characters is the low seven bits of an octet or 8-bit byte; octets are packed into memory words so that (for example) a six-character string only takes up two memory words. For an ASCII code chart, type `man 7 ascii’ at your Unix prompt. The preceding paragraph was misleading in two ways. The minor one is that the term octet&#39; is formally correct but seldom actually used; most people refer to an octet as byte and expect bytes to be eight bits long. Strictly speaking, the termbyte’ is more general; there used to be, for example, 36-bit machines with 9-bit bytes (though there probably never will be again). The major one is that not all the world uses ASCII. In fact, much of the world can’t – ASCII, while fine for American English, lacks many accented and other special characters needed by users of other languages. Even British English has trouble with the lack of a pound-currency sign. There have been several attempts to fix this problem. All use the extra high bit that ASCII doesn’t, making it the low half of a 256-character set. The most widely-used of these is the so-called `Latin-1’ character set (more formally called ISO 8859-1). This is the default character set for Linux, HTML, and X. Microsoft Windows uses a mutant version of Latin-1 that adds a bunch of characters such as right and left double quotes in places proper Latin-1 leaves unassigned for historical reasons (for a scathing account of the trouble this causes, see the demoroniser page). Latin-1 handles western European languages, including English, French, German, Spanish, Italian, Dutch, Norwegian, Swedish, Danish. However, this isn’t good enough either, and as a result there is a whole series of Latin-2 through -9 character sets to handle things like Greek, Arabic, Hebrew, Esperanto, and Serbo-Croatian. For details, see the ISO alphabet soup page. The ultimate solution is a huge standard called Unicode (and its identical twin ISO/IEC 10646-1:1993). Unicode is identical to Latin-1 in its lowest 256 slots. Above these in 16-bit space it includes Greek, Cyrillic, Armenian, Hebrew, Arabic, Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada, Malayalam, Thai, Lao, Georgian, Tibetan, Japanese Kana, the complete set of modern Korean Hangul, and a unified set of Chinese/Japanese/Korean (CJK) ideographs. For details, see the Unicode Home Page. 10. How does my computer store things on disk?When you look at a hard disk under Unix, you see a tree of named directories and files. Normally you won’t need to look any deeper than that, but it does become useful to know what’s going on underneath if you have a disk crash and need to try to salvage files. Unfortunately, there’s no good way to describe disk organization from the file level downwards, so I’ll have to describe it from the hardware up. 10.1. Low-level disk and file system structure The surface area of your disk, where it stores data, is divided up something like a dartboard – into circular tracks which are then pie-sliced into sectors. Because tracks near the outer edge have more area than those close to the spindle at the center of the disk, the outer tracks have more sector slices in them than the inner ones. Each sector (or disk block) has the same size, which under modern Unixes is generally 1 binary K (1024 8-bit words). Each disk block has a unique address or disk block number. Unix divides the disk into disk partitions. Each partition is a continuous span of blocks that’s used separately from any other partition, either as a file system or as swap space. The original reasons for partitions had to do with crash recovery in a world of much slower and more error-prone disks; the boundaries between them reduce the fraction of your disk likely to become inaccessible or corrupted by a random bad spot on the disk. Nowadays, it’s more important that partitions can be declared read-only (preventing an intruder from modifying critical system files) or shared over a network through various means we won’t discuss here. The lowest-numbered partition on a disk is often treated specially, as a boot partition where you can put a kernel to be booted. Each partition is either swap space (used to implement virtual memory) or a file system used to hold files. Swap-space partitions are just treated as a linear sequence of blocks. File systems, on the other hand, need a way to map file names to sequences of disk blocks. Because files grow, shrink, and change over time, a file’s data blocks will not be a linear sequence but may be scattered all over its partition (from wherever the operating system can find a free block when it needs one). This scattering effect is called fragmentation. 10.2. File names and directories Within each file system, the mapping from names to blocks is handled through a structure called an i-node. There’s a pool of these things near the ``bottom’’ (lowest-numbered blocks) of each file system (the very lowest ones are used for housekeeping and labeling purposes we won’t describe here). Each i-node describes one file. File data blocks (including directories) live above the i-nodes (in higher-numbered blocks). Every i-node contains a list of the disk block numbers in the file it describes. (Actually this is a half-truth, only correct for small files, but the rest of the details aren’t important here.) Note that the i-node does not contain the name of the file. Names of files live in directory structures. A directory structure just maps names to i-node numbers. This is why, in Unix, a file can have multiple true names (or hard links); they’re just multiple directory entries that happen to point to the same i-node. 10.3. Mount points In the simplest case, your entire Unix file system lives in just one disk partition. While you’ll see this arrangement on some small personal Unix systems, it’s unusual. More typical is for it to be spread across several disk partitions, possibly on different physical disks. So, for example, your system may have one small partition where the kernel lives, a slightly larger one where OS utilities live, and a much bigger one where user home directories live. The only partition you’ll have access to immediately after system boot is your root partition, which is (almost always) the one you booted from. It holds the root directory of the file system, the top node from which everything else hangs. The other partitions in the system have to be attached to this root in order for your entire, multiple-partition file system to be accessible. About midway through the boot process, your Unix will make these non-root partitions accessible. It will mount each one onto a directory on the root partition. For example, if you have a Unix directory called `/usr’, it is probably a mount point to a partition that contains many programs installed with your Unix but not required during initial boot. 10.4. How a file gets looked up Now we can look at the file system from the top down. When you open a file (such as, say, /home/esr/WWW/ldp/fundamentals.sgml) here is what happens:Your kernel starts at the root of your Unix file system (in the root partition). It looks for a directory there called home&#39;. Usuallyhome’ is a mount point to a large user partition elsewhere, so it will go there. In the top-level directory structure of that user partition, it will look for a entry called esr&#39; and extract an i-node number. It will go to that i-node, notice that its associated file data blocks are a directory structure, and look upWWW’. Extracting that i-node, it will go to the corresponding subdirectory and look up ldp&#39;. That will take it to yet another directory i-node. Opening that one, it will find an i-node number forfundamentals.sgml’. That i-node is not a directory, but instead holds the list of disk blocks associated with the file.## 10.5. File ownership, permissions and security To keep programs from accidentally or maliciously stepping on data they shouldn’t, Unix has permission features. These were originally designed to support timesharing by protecting multiple users on the same machine from each other, back in the days when Unix ran mainly on expensive shared minicomputers. In order to understand file permissions, you need to recall the description of users and groups in the section What happens when you log in?. Each file has an owning user and an owning group. These are initially those of the file’s creator; they can be changed with the programs chown(1) and chgrp(1). The basic permissions that can be associated with a file are read&#39; (permission to read data from it),write’ (permission to modify it) and execute&#39; (permission to run it as a program). Each file has three sets of permissions; one for its owning user, one for any user in its owning group, and one for everyone else. Theprivileges’ you get when you log in are just the ability to do read, write, and execute on those files for which the permission bits match your user ID or one of the groups you are in, or files that have been made accessible to the world. To see how these may interact and how Unix displays them, let’s look at some file listings on a hypothetical Unix system. Here’s one: snark:~$ ls -l notes-rw-r–r– 1 esr users 2993 Jun 17 11:00 notesThis is an ordinary data file. The listing tells us that it’s owned by the user esr&#39; and was created with the owning groupusers’. Probably the machine we’re on puts every ordinary user in this group by default; other groups you commonly see on timesharing machines are staff&#39;,admin’, or `wheel’ (for obvious reasons, groups are not very important on single-user workstations or PCs). Your Unix may use a different default group, perhaps one named after your user ID. The string -rw-r--r--&#39; represents the permission bits for the file. The very first dash is the position for the directory bit; it would showd’ if the file were a directory. After that, the first three places are user permissions, the second three group permissions, and the third are permissions for others (often called world&#39; permissions). On this file, the owning useresr’ may read or write the file, other people in the `users’ group may read it, and everybody else in the world may read it. This is a pretty typical set of permissions for an ordinary data file. Now let’s look at a file with very different permissions. This file is GCC, the GNU C compiler. snark:~$ ls -l /usr/bin/gcc-rwxr-xr-x 3 root bin 64796 Mar 21 16:41 /usr/bin/gccThis file belongs to a user called root&#39; and a group calledbin’; it can be written (modified) only by root, but read or executed by anyone. This is a typical ownership and set of permissions for a pre-installed system command. The bin&#39; group exists on some Unixes to group together system commands (the name is a historical relic, short forbinary’). Your Unix might use a root&#39; group instead (not quite the same as theroot’ user!). The `root’ user is the conventional name for numeric user ID 0, a special, privileged account that can override all privileges. Root access is useful but dangerous; a typing mistake while you’re logged in as root can clobber critical system files that the same command executed from an ordinary user account could not touch. Because the root account is so powerful, access to it should be guarded very carefully. Your root password is the single most critical piece of security information on your system, and it is what any crackers and intruders who ever come after you will be trying to get. About passwords: Don’t write them down – and don’t pick a passwords that can easily be guessed, like the first name of your girlfriend/boyfriend/spouse. This is an astonishingly common bad practice that helps crackers no end. In general, don’t pick any word in the dictionary; there are programs called dictionary crackers that look for likely passwords by running through word lists of common choices. A good technique is to pick a combination consisting of a word, a digit, and another word, such as shark6cider&#39; orjump3joy’; that will make the search space too large for a dictionary cracker. Don’t use these examples, though – crackers might expect that after reading this document and put them in their dictionaries. Now let’s look at a third case: snark:~$ ls -ld ~drwxr-xr-x 89 esr users 9216 Jun 27 11:29 /home2/esrsnark:~$This file is a directory (note the `d’ in the first permissions slot). We see that it can be written only by esr, but read and executed by anybody else. Read permission gives you the ability to list the directory – that is, to see the names of files and directories it contains. Write permission gives you the ability to create and delete files in the directory. If you remember that the directory includes a list of the names of the files and subdirectories it contains, these rules will make sense. Execute permission on a directory means you can get through the directory to open the files and directories below it. In effect, it gives you permission to access the i-nodes in the directory. A directory with execute completely turned off would be useless. Occasionally you’ll see a directory that is world-executable but not world-readable; this means a random user can get to files and directories beneath it, but only by knowing their exact names (the directory cannot be listed). It’s important to remember that read, write, or execute permission on a directory is independent of the permissions on the files and directories beneath. In particular, write access on a directory means you can create new files or delete existing files there, but does not automatically give you write access to existing files. Finally, let’s look at the permissions of the login program itself. snark:~$ ls -l /bin/login-rwsr-xr-x 1 root bin 20164 Apr 17 12:57 /bin/loginThis has the permissions we’d expect for a system command – except for that ‘s’ where the owner-execute bit ought to be. This is the visible manifestation of a special permission called the `set-user-id’ or setuid bit. The setuid bit is normally attached to programs that need to give ordinary users the privileges of root, but in a controlled way. When it is set on an executable program, you get the privileges of the owner of that program file while the program is running on your behalf, whether or not they match your own. Like the root account itself, setuid programs are useful but dangerous. Anyone who can subvert or modify a setuid program owned by root can use it to spawn a shell with root privileges. For this reason, opening a file to write it automatically turns off its setuid bit on most Unixes. Many attacks on Unix security try to exploit bugs in setuid programs in order to subvert them. Security-conscious system administrators are therefore extra-careful about these programs and reluctant to install new ones. There are a couple of important details we glossed over when discussing permissions above; namely, how the owning group and permissions are assigned when a file or directory is first created. The group is an issue because users can be members of multiple groups, but one of them (specified in the user’s /etc/passwd entry) is the user’s default group and will normally own files created by the user. The story with initial permission bits is a little more complicated. A program that creates a file will normally specify the permissions it is to start with. But these will be modified by a variable in the user’s environment called the umask. The umask specifies which permission bits to turn off when creating a file; the most common value, and the default on most systems, is ——-w- or 002, which turns off the world-write bit. See the documentation of the umask command on your shell’s manual page for details. Initial directory group is also a bit complicated. On some Unixes a new directory gets the default group of the creating user (this in the System V convention); on others, it gets the owning group of the parent directory in which it’s created (this is the BSD convention). On some modern Unixes, including Linux, the latter behavior can be selected by setting the set-group-ID on the directory (chmod g+s). 10.6. How things can go wrong Earlier it was hinted that file systems can be fragile things. Now we know that to get to a file you have to hopscotch through what may be an arbitrarily long chain of directory and i-node references. Now suppose your hard disk develops a bad spot? If you’re lucky, it will only trash some file data. If you’re unlucky, it could corrupt a directory structure or i-node number and leave an entire subtree of your system hanging in limbo – or, worse, result in a corrupted structure that points multiple ways at the same disk block or i-node. Such corruption can be spread by normal file operations, trashing data that was not in the original bad spot. Fortunately, this kind of contingency has become quite uncommon as disk hardware has become more reliable. Still, it means that your Unix will want to integrity-check the file system periodically to make sure nothing is amiss. Modern Unixes do a fast integrity check on each partition at boot time, just before mounting it. Every few reboots they’ll do a much more thorough check that takes a few minutes longer. If all of this sounds like Unix is terribly complex and failure-prone, it may be reassuring to know that these boot-time checks typically catch and correct normal problems before they become really disastrous. Other operating systems don’t have these facilities, which speeds up booting a bit but can leave you much more seriously screwed when attempting to recover by hand (and that’s assuming you have a copy of Norton Utilities or whatever in the first place…). One of the trends in current Unix designs is journalling file systems. These arrange traffic to the disk so that it’s guaranteed to be in a consistent state that can be recovered when the system comes back up. This will speed up the boot-time integrity check a lot. 11. How do computer languages work?We’ve already discussed how programs are run. Every program ultimately has to execute as a stream of bytes that are instructions in your computer’s machine language. But human beings don’t deal with machine language very well; doing so has become a rare, black art even among hackers. Almost all Unix code except a small amount of direct hardware-interface support in the kernel itself is nowadays written in a high-level language. (The high-level&#39; in this term is a historical relic meant to distinguish these fromlow-level’ assembler languages, which are basically thin wrappers around machine code.) There are several different kinds of high-level languages. In order to talk about these, you’ll find it useful to bear in mind that the source code of a program (the human-created, editable version) has to go through some kind of translation into machine code that the machine can actually run. 11.1. Compiled languages The most conventional kind of language is a compiled language. Compiled languages get translated into runnable files of binary machine code by a special program called (logically enough) a compiler. Once the binary has been generated, you can run it directly without looking at the source code again. (Most software is delivered as compiled binaries made from code you don’t see.) Compiled languages tend to give excellent performance and have the most complete access to the OS, but also to be difficult to program in. C, the language in which Unix itself is written, is by far the most important of these (with its variant C++). FORTRAN is another compiled language still used among engineers and scientists but years older and much more primitive. In the Unix world no other compiled languages are in mainstream use. Outside it, COBOL is very widely used for financial and business software. There used to be many other compiler languages, but most of them have either gone extinct or are strictly research tools. If you are a new Unix developer using a compiled language, it is overwhelmingly likely to be C or C++. 11.2. Interpreted languages An interpreted language depends on an interpreter program that reads the source code and translates it on the fly into computations and system calls. The source has to be re-interpreted (and the interpreter present) each time the code is executed. Interpreted languages tend to be slower than compiled languages, and often have limited access to the underlying operating system and hardware. On the other hand, they tend to be easier to program and more forgiving of coding errors than compiled languages. Many Unix utilities, including the shell and bc(1) and sed(1) and awk(1), are effectively small interpreted languages. BASICs are usually interpreted. So is Tcl. Historically, the most important interpretive language has been LISP (a major improvement over most of its successors). Today, Unix shells and the Lisp that lives inside the Emacs editor are probably the most important pure interpreted languages. 11.3. P-code languages Since 1990 a kind of hybrid language that uses both compilation and interpretation has become increasingly important. P-code languages are like compiled languages in that the source is translated to a compact binary form which is what you actually execute, but that form is not machine code. Instead it’s pseudocode (or p-code), which is usually a lot simpler but more powerful than a real machine language. When you run the program, you interpret the p-code. P-code can run nearly as fast as a compiled binary (p-code interpreters can be made quite simple, small and speedy). But p-code languages can keep the flexibility and power of a good interpreter. Important p-code languages include Python, Perl, and Java. 12. How does the Internet work?To help you understand how the Internet works, we’ll look at the things that happen when you do a typical Internet operation – pointing a browser at the front page of this document at its home on the Web at the Linux Documentation Project. This document is http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.htmlwhich means it lives in the file LDP/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html under the World Wide Web export directory of the host www.linuxdoc.org. 12.1. Names and locations The first thing your browser has to do is to establish a network connection to the machine where the document lives. To do that, it first has to find the network location of the host www.linuxdoc.org (host&#39; is short forhost machine’ or network host&#39;; www.linuxdoc.org is a typical hostname). The corresponding location is actually a number called an IP address (we&#39;ll explain theIP’ part of this term later). To do this, your browser queries a program called a name server. The name server may live on your machine, but it’s more likely to run on a service machine that yours talks to. When you sign up with an ISP, part of your setup procedure will almost certainly involve telling your Internet software the IP address of a nameserver on the ISP’s network. The name servers on different machines talk to each other, exchanging and keeping up to date all the information needed to resolve hostnames (map them to IP addresses). Your nameserver may query three or four different sites across the network in the process of resolving www.linuxdoc.org, but this usually happens very quickly (as in less than a second). We’ll look at how nameservers detail in the next section. The nameserver will tell your browser that www.linuxdoc.org’s IP address is 152.19.254.81; knowing this, your machine will be able to exchange bits with www.linuxdoc.org directly. 12.2. The Domain Name System The whole network of programs and databases that cooperates to translate hostnames to IP addresses is called DNS&#39; (Domain Name System). When you see references to aDNS server’, that means what we just called a nameserver. Now I’ll explain how the overall system works. Internet hostnames are composed of parts separated by dots. A domain is a collection of machines that share a common name suffix. Domains can live inside other domains. For example, the machine www.linuxdoc.org lives in the .linuxdoc.org subdomain of the .org domain. Each domain is defined by an authoritative name server that knows the IP addresses of the other machines in the domain. The authoritative (or primary&#39;) name server may have backups in case it goes down; if you see references to a secondary name server or (secondary DNS’) it’s talking about one of those. These secondaries typically refresh their information from their primaries every few hours, so a change made to the hostname-to-IP mapping on the primary will automatically be propagated. Now here’s the important part. The nameservers for a domain do not have to know the locations of all the machines in other domains (including their own subdomains); they only have to know the location of the nameservers. In our example, the authoritative name server for the .org domain knows the IP address of the nameserver for .linuxdoc.org, but not the address of all the other machines in linuxdoc.org. The domains in the DNS system are arranged like a big inverted tree. At the top are the root servers. Everybody knows the IP addresses of the root servers; they’re wired into your DNS software. The root servers know the IP addresses of the nameservers for the top-level domains like .com and .org, but not the addresses of machines inside those domains. Each top-level domain server knows where the nameservers for the domains directly beneath it are, and so forth. DNS is carefully designed so that each machine can get away with the minimum amount of knowledge it needs to have about the shape of the tree, and local changes to subtrees can be made simply by changing one authoritative server’s database of name-to-IP-address mappings. When you query for the IP address of www.linuxdoc.org, what actually happens is this: First, your nameserver asks a root server to tell it where it can find a nameserver for .org. Once it knows that, it then asks the .org server to tell it the IP address of a .linuxdoc.org nameserver. Once it has that, it asks the .linuxdoc.org nameserver to tell it the address of the host www.linuxdoc.org. Most of the time, your nameserver doesn’t actually have to work that hard. Nameservers do a lot of cacheing; when yours resolves a hostname, it keeps the association with the resulting IP address around in memory for a while. This is why, when you surf to a new website, you’ll usually only see a message from your browser about “Looking up” the host for the first page you fetch. Eventually the name-to-address mapping expires and your DNS has to re-query — this is important so you don’t have invalid information hanging around forever when a hostname changes addresses. Your cached IP address for a site is also thrown out if the host is unreachable. 12.3. Packets and routers What the browser wants to do is send a command to the Web server on www.linuxdoc.org that looks like this: GET /LDP/HOWTO/Fundamentals.html HTTP/1.0Here’s how that happens. The command is made into a packet, a block of bits like a telegram that is wrapped with three important things; the source address (the IP address of your machine), the destination address (152.19.254.81), and a service number or port number (80, in this case) that indicates that it’s a World Wide Web request. Your machine then ships the packet down the wire (your connection to your ISP, or local network) until it gets to a specialized machine called a router. The router has a map of the Internet in its memory – not always a complete one, but one that completely describes your network neighborhood and knows how to get to the routers for other neighborhoods on the Internet. Your packet may pass through several routers on the way to its destination. Routers are smart. They watch how long it takes for other routers to acknowledge having received a packet. They also use that information to direct traffic over fast links. They use it to notice when another routers (or a cable) have dropped off the network, and compensate if possible by finding another route. There’s an urban legend that the Internet was designed to survive nuclear war. This is not true, but the Internet’s design is extremely good at getting reliable performance out of flaky hardware in an uncertain world. This is directly due to the fact that its intelligence is distributed through thousands of routers rather than concentrated in a few massive and vulnerable switches (like the phone network). This means that failures tend to be well localized and the network can route around them. Once your packet gets to its destination machine, that machine uses the service number to feed the packet to the web server. The web server can tell where to reply to by looking at the command packet’s source IP address. When the web server returns this document, it will be broken up into a number of packets. The size of the packets will vary according to the transmission media in the network and the type of service. 12.4. TCP and IP To understand how multiple-packet transmissions are handled, you need to know that the Internet actually uses two protocols, stacked one on top of the other. The lower level, IP (Internet Protocol), is responsible for labeling individual packets with the source address and destination address of two computers exchanging information over a network. For example, when you access http://www.linuxdoc.org, the packets you send will have your computer’s IP address, such as 192.168.1.101, and the IP address of the www.linuxdoc.org computer, 152.2.210.81. These addresses work in much the same way that your home address works when someone sends you a letter. The post office can read the address and determine where you are and how best to route the letter to you, much like a router does for Internet traffic. The upper level, TCP (Transmission Control Protocol), gives you reliability. When two machines negotiate a TCP connection (which they do using IP), the receiver knows to send acknowledgements of the packets it sees back to the sender. If the sender doesn’t see an acknowledgement for a packet within some timeout period, it resends that packet. Furthermore, the sender gives each TCP packet a sequence number, which the receiver can use you reassemble packets in case they show up out of order. (This can easily happen if network links go up or down during a connection.) TCP/IP packets also contain a checksum to enable detection of data corrupted by bad links. (The checksum is computed from the rest of the packet in such a way that if the either the rest of the packet or the checksum is corrupted, redoing the computation and comparing is very likely to indicate an error.) So, from the point of view of anyone using TCP/IP and nameservers, it looks like a reliable way to pass streams of bytes between hostname/service-number pairs. People who write network protocols almost never have to think about all the packetizing, packet reassembly, error checking, checksumming, and retransmission that goes on below that level. 12.5. HTTP, an application protocol Now let’s get back to our example. Web browsers and servers speak an application protocol that runs on top of TCP/IP, using it simply as a way to pass strings of bytes back and forth. This protocol is called HTTP (Hyper-Text Transfer Protocol) and we’ve already seen one command in it – the GET shown above. When the GET command goes to www.linuxdoc.org’s webserver with service number 80, it will be dispatched to a server daemon listening on port 80. Most Internet services are implemented by server daemons that do nothing but wait on ports, watching for and executing incoming commands. If the design of the Internet has one overall rule, it’s that all the parts should be as simple and human-accessible as possible. HTTP, and its relatives (like the Simple Mail Transfer Protocol, SMTP, that is used to move electronic mail between hosts) tend to use simple printable-text commands that end with a carriage-return/line feed. This is marginally inefficient; in some circumstances you could get more speed by using a tightly-coded binary protocol. But experience has shown that the benefits of having commands be easy for human beings to describe and understand outweigh any marginal gain in efficiency that you might get at the cost of making things tricky and opaque. Therefore, what the server daemon ships back to you via TCP/IP is also text. The beginning of the response will look something like this (a few headers have been suppressed): HTTP/1.1 200 OKDate: Sat, 10 Oct 1998 18:43:35 GMTServer: Apache/1.2.6 Red HatLast-Modified: Thu, 27 Aug 1998 17:55:15 GMTContent-Length: 2982Content-Type: text/htmlThese headers will be followed by a blank line and the text of the web page (after which the connection is dropped). Your browser just displays that page. The headers tell it how (in particular, the Content-Type header tells it the returned data is really HTML). To Learn More There is a Reading List HOWTO that lists books you can read to learn more about the topics we have touched on here. You might also want to read the How To Become A Hacker document.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Unix","slug":"Unix","permalink":"http://ipcreator.me/tags/Unix/"},{"name":"Internet","slug":"Internet","permalink":"http://ipcreator.me/tags/Internet/"}]},{"title":"提问的智慧","date":"2017-01-20T12:28:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/how-to-ask-questions-the-smart-way/","text":"How To Ask Questions The Smart WayEric S. Raymond, Rick Moen 翻译者：2010 by Gasolin, 2015 by Ryan Wu 在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。 目录声明简介在提问之前当你提问时慎选提问的论坛Stack Overflow网站和 IRC 论坛 第二步，使用项目邮件列表使用有意义且描述明确的标题使问题容易回复用清晰、正确、精准并合法语法的语句使用易于读取且标准的文件格式发送问题精确的描述问题并言之有物话不在多而在精别动辄声称找到 Bug可以低声下气，但还是要先做功课描述问题症状而非猜测按发生时间先后列出问题症状描述目标而不是过程别要求使用私人电邮回复清楚明确的表达你的问题以及需求询问有关代码的问题时别把自己家庭作业的问题贴上来去掉无意义的提问句即使你很急也不要在标题写紧急礼多人不怪，而且有时还很有帮助问题解决后，加个简短的补充说明 如何解读答案RTFM 和 STFW：如何知道你已完全搞砸了如果还是搞不懂处理无礼的回应如何避免扮演失败者不该问的问题好问题与蠢问题如果得不到回答如何更好地回答问题相关资源鸣谢 声明许多项目在他们的使用协助/说明网页中链接了本指南，这么做很好，我们也鼓励大家都这么做。但如果你是负责管理这个项目网页的人，请在超链接附近的显著位置上注明： 本指南不提供此项目的实际支持服务！ 我们已经深刻领教到少了上述声明所带来的痛苦。因为少了这点声明，我们不停地被一些白痴纠缠。这些白痴认为既然我们发布了这本指南，那么我们就有责任解决世上所有的技术问题。 如果你是因为需要某些协助而正在阅读这本指南，并且最后离开是因为发现从本指南作者们身上得不到直接的协助，那么你就是我们所说的那些白痴之一。别问我们问题，我们只会忽略你。我们在这本指南中是教你如何从那些真正懂得你所遇到软件或硬件问题的人取得协助，而 99% 的情况下那不会是我们。除非你确定本指南的作者之一刚好是你所遇到的问题领域的专家，否则请不要打扰我们，这样大家都会开心一点。 简介在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。 本指南将教你如何正确的提问以获得你满意的答案。 不只是黑客，现在开放源代码（Open Source）软件已经相当盛行，你常常也可以由其他有经验的使用者身上得到好答案，这是件好事；使用者比起黑客来，往往对那些新手常遇到的问题更宽容一些。然而，将有经验的使用者视为黑客，并采用本指南所提的方法与他们沟通，同样也是能从他们身上得到满意回答的最有效方式。 首先你应该明白，黑客们喜爱有挑战性的问题，或者能激发我们思维的好问题。如果我们并非如此，那我们也不会成为你想询问的对象。如果你给了我们一个值得反复咀嚼玩味的好问题，我们自会对你感激不尽。好问题是激励，是厚礼。好问题可以提高我们的理解力，而且通常会暴露我们以前从没意识到或者思考过的问题。对黑客而言，”好问题！”是诚挚的大力称赞。 尽管如此，黑客们有着蔑视或傲慢面对简单问题的坏名声，这有时让我们看起来对新手、无知者似乎较有敌意，但其实不是那样的。 我们不讳言我们对那些不愿思考、或者在发问前不做他们该做的事的人的蔑视。那些人是时间杀手 -– 他们只想索取，从不付出，消耗我们可用在更有趣的问题或更值得回答的人身上的时间。我们称这样的人为 失败者（撸瑟） （由于历史原因，我们有时把它拼作 lusers）。 我们意识到许多人只是想使用我们写的软件，他们对学习技术细节没有兴趣。对大多数人而言，电脑只是种工具，是种达到目的的手段而已。他们有自己的生活并且有更要紧的事要做。我们了解这点，也从不指望每个人都对这些让我们着迷的技术问题感兴趣。尽管如此，我们回答问题的风格是指向那些真正对此有兴趣并愿意主动参与解决问题的人，这一点不会变，也不该变。如果连这都变了，我们就是在降低做自己最擅长的事情上的效率。 我们（在很大程度上）是自愿的，从繁忙的生活中抽出时间来解答疑惑，而且时常被提问淹没。所以我们无情的滤掉一些话题，特别是拋弃那些看起来像失败者的家伙，以便更高效的利用时间来回答赢家（winner）的问题。 如果你厌恶我们的态度，高高在上，或过于傲慢，不妨也设身处地想想。我们并没有要求你向我们屈服 – 事实上，我们大多数人非常乐意与你平等地交流，只要你付出小小努力来满足基本要求，我们就会欢迎你加入我们的文化。但让我们帮助那些不愿意帮助自己的人是没有效率的。无知没有关系，但装白痴就是不行。 所以，你不必在技术上很在行才能吸引我们的注意，但你必须表现出能引导你变得在行的特质 – 机敏、有想法、善于观察、乐于主动参与解决问题。如果你做不到这些使你与众不同的事情，我们建议你花点钱找家商业公司签个技术支持服务合同，而不是要求黑客个人无偿地帮助你。 如果你决定向我们求助，当然你也不希望被视为失败者，更不愿成为失败者中的一员。能立刻得到快速并有效答案的最好方法，就是像赢家那样提问 – 聪明、自信、有解决问题的思路，只是偶尔在特定的问题上需要获得一点帮助。 （欢迎对本指南提出改进意见。你可以 email 你的建议至 esr@thyrsus.com 或 respond-auto@linuxmafia.com。然而请注意，本文并非网络礼节的通用指南，而我们通常会拒绝无助于在技术论坛得到有用答案的建议。） 在提问之前在你准备要通过电子邮件、新闻群组或者聊天室提出技术问题前，请先做到以下事情： 尝试在你准备提问的论坛的旧文章中搜索答案。 尝试上网搜索以找到答案。 尝试阅读手册以找到答案。 尝试阅读常见问题文件（FAQ）以找到答案。 尝试自己检查或试验以找到答案 向你身边的强者朋友打听以找到答案。 如果你是程序开发者，请尝试阅读源代码以找到答案。 当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并 不是一个不劳而获且浪费别人的时间的提问者。 如果你能一并表达在做了上述努力的过程中所学到的东西会更好，因为我们更乐于回答那些表现出能从答案中学习的人的问题。 运用某些策略，比如先用 Google 搜索你所遇到的各种错误信息（既搜索 Google 论坛，也搜索网页），这样很可能直接就找到了能解决问题的文件或邮件列表线索。即使没有结果，在邮件列表或新闻组寻求帮助时加上一句 我在 Google 中搜过下列句子但没有找到什么有用的东西 也是件好事，即使它只是表明了搜索引擎不能提供哪些帮助。这么做（加上搜索过的字串）也让遇到相似问题的其他人能被搜索引擎引导到你的提问来。 别着急，不要指望几秒钟的 Google 搜索就能解决一个复杂的问题。在向专家求助之前，再阅读一下常见问题文件（FAQ）、放轻松、坐舒服一些，再花点时间思考一下这个问题。相信我们，他们 能从你的提问看出你做了多少阅读与思考，如果你是有备而来，将更有可能得到解答。不要将所有问题一股脑拋出，只因你的第一次搜索没有找到答案（或者找到太多答案）。 准备好你的问题，再将问题仔细的思考过一遍，因为 草率的发问只能得到草率的回答，或者根本得不到任何答案。越是能表现出在寻求帮助前你为解决问题所付出的努力，你越有可能得到实质性的帮助。 小心别问错了问题。如果你的问题基于错误的假设，某个普通黑客（J. Random Hacker）多半会一边在心里想着蠢问题…， 一边用无意义的字面解释来答复你，希望着你会从问题的回答（而非你想得到的答案）中汲取教训。 绝不要自以为够格得到答案，你没有；你并没有。毕竟你没有为这种服务支付任何报酬。你将会是 自己去挣到一个答案，靠提出有内涵的、有趣的、有思维激励作用的问题 –一个有潜力能贡献社区经验的问题，而不仅仅是被动的从他人处索取知识。 另一方面，表明你愿意在找答案的过程中做点什么是一个非常好的开端。谁能给点提示？、我的这个例子里缺了什么？以及我应该检查什么地方比请把我需要的确切的过程贴出来更容易得到答复。因为你表现出只要有人能指个正确方向，你就有完成它的能力和决心。 当你提问时慎选提问的论坛 小心选择你要提问的场合。如果你做了下述的事情，你很可能被忽略掉或者被看作失败者： 在与主题不合的论坛上贴出你的问题 在探讨进阶技术问题的论坛张贴非常初级的问题；反之亦然 在太多的不同新闻群组上重复转贴同样的问题（cross-post） 向既非熟人也没有义务解决你问题的人发送私人电邮 黑客会剔除掉那些搞错场合的问题，以保护他们沟通的渠道不被无关的东西淹没。你不会想让这种事发生在自己身上的。 因此，第一步是找到对的论坛。再说一次，Google 和其它搜索引擎还是你的朋友，用它们来找到与你遭遇到困难的软硬件问题最相关的网站。通常那儿都有常见问题（FAQ）、邮件列表及相关说明文件的链接。如果你的努力（包括阅读 FAQ）都没有结果，网站上也许还有报告 Bug（Bug-reporting）的流程或链接，如果是这样，连过去看看。 向陌生的人或论坛发送邮件最可能是风险最大的事情。举例来说，别假设一个提供丰富内容的网页的作者会想充当你的免费顾问。不要对你的问题是否会受到欢迎做太乐观的估计 – 如果你不确定，那就向别处发送，或者压根别发。 在选择论坛、新闻群组或邮件列表时，别太相信名字，先看看 FAQ 或者许可书以弄清楚你的问题是否切题。发文前先翻翻已有的话题，这样可以让你感受一下那里的文化。事实上，事先在新闻组或邮件列表的历史记录中搜索与你问题相关的关键词是个极好的主意，也许这样就找到答案了。即使没有，也能帮助你归纳出更好的问题。 别像机关枪似的一次”扫射”所有的帮助渠道，这就像大喊大叫一样会使人不快。要一个一个地来。 搞清楚你的主题！最典型的错误之一是在某种致力于跨平台可移植的语言、套件或工具的论坛中提关于 Unix 或 Windows 操作系统程序界面的问题。如果你不明白为什么这是大错，最好在搞清楚这之间差异之前什么也别问。 一般来说，在仔细挑选的公共论坛中提问，会比在私有论坛中提同样的问题更容易得到有用的回答。有几个理由可以支持这点，一是看潜在的回复者有多少，二是看观众有多少。黑客较愿意回答那些能帮助到许多人的问题。 可以理解的是，老练的黑客和一些热门软件的作者正在接受过多的错发信息。就像那根最后压垮骆驼背的稻草一样，你的加入也有可能使情况走向极端 – 已经好几次了，一些热门软件的作者从自己软件的支持中抽身出来，因为伴随而来涌入其私人邮箱的无用邮件变得无法忍受。 Stack Overflow搜索，然后 在 Stack Exchange 问。 近年来，Stack Exchange community 社区已经成为回答技术及其他问题的主要渠道，尤其是那些开放源码的项目。 因为 Google 索引是即时的，在看 Stack Exchange 之前先在 Google 搜索。有很高的机率某人已经问了一个类似的问题，而且 Stack Exchange 网站们往往会是搜索结果中最前面几个。如果你在 Google 上没有找到任何答案，你再到特定相关主题的网站去找。用标签（Tag）搜索能让你更缩小你的搜索结果。 Stack Exchange 已经成长到超过一百个网站，以下是最常用的几个站： Super User 是问一些通用的电脑问题，如果你的问题跟代码或是写程序无关，只是一些网络连线之类的，请到这里。Stack Overflow 是问写程序有关的问题。Server Fault 是问服务器和网管相关的问题。 网站和 IRC 论坛 本地的使用者群组（user group），或者你所用的 Linux 发行版本也许正在宣传他们的网页论坛或 IRC 频道，并提供新手帮助（在一些非英语国家，新手论坛很可能还是邮件列表）， 这些地方是开始提问的好首选，特别是当你觉得遇到的也许只是相对简单或者很普通的问题时。有广告赞助的 IRC 频道是公开欢迎提问的地方，通常可以即时得到回应。 事实上，如果程序出的问题只发生在特定 Linux 发行版提供的版本（这很常见），最好先去该发行版的论坛或邮件列表中提问，再到程序本身的论坛或邮件列表提问。（否则）该项目的黑客可能仅仅回复 “用我们的版本”。 在任何论坛发文以前，先确认一下有没有搜索功能。如果有，就试着搜索一下问题的几个关键词，也许这会有帮助。如果在此之前你已做过通用的网页搜索（你也该这样做），还是再搜索一下论坛，搜索引擎有可能没来得及索引此论坛的全部内容。 通过论坛或 IRC 频道来提供使用者支持服务有增长的趋势，电子邮件则大多为项目开发者间的交流而保留。所以最好先在论坛或 IRC 中寻求与该项目相关的协助。 在使用 IRC 的时候，首先最好不要发布很长的问题描述，有些人称之为频道洪水。最好通过一句话的问题描述来开始聊天。 第二步，使用项目邮件列表当某个项目提供开发者邮件列表时，要向列表而不是其中的个别成员提问，即使你确信他能最好地回答你的问题。查一查项目的文件和首页，找到项目的邮件列表并使用它。有几个很好的理由支持我们采用这种办法： 任何好到需要向个别开发者提出的问题，也将对整个项目群组有益。反之，如果你认为自己的问题对整个项目群组来说太愚蠢，也不能成为骚扰个别开发者的理由。 向列表提问可以分散开发者的负担，个别开发者（尤其是项目领导人）也许太忙以至于没法回答你的问题。 大多数邮件列表都会被存档，那些被存档的内容将被搜索引擎索引。如果你向列表提问并得到解答，将来其它人可以通过网页搜索找到你的问题和答案，也就不用再次发问了。 如果某些问题经常被问到，开发者可以利用此信息来改进说明文件或软件本身，以使其更清楚。如果只是私下提问，就没有人能看到最常见问题的完整场景。 如果一个项目既有”使用者” 也有”开发者”（或”黑客”）邮件列表或论坛，而你又不会动到那些源代码，那么就向”使用者”列表或论坛提问。不要假设自己会在开发者列表中受到欢迎，那些人多半会将你的提问视为干扰他们开发的噪音。 然而，如果你确信你的问题很特别，而且在”使用者” 列表或论坛中几天都没有回复，可以试试前往”开发者”列表或论坛发问。建议你在张贴前最好先暗地里观察几天以了解那里的行事方式（事实上这是参与任何私有或半私有列表的好主意） 如果你找不到一个项目的邮件列表，而只能查到项目维护者的电子邮件地址，尽管向他发信。即使是在这种情况下，也别假设（项目）邮件列表不存在。在你的电子邮件中，请陈述你已经试过但没有找到合适的邮件列表，也提及你不反对将自己的邮件转发给他人（许多人认为，即使没什么秘密，私人电子邮件也不应该被公开。通过允许将你的电子邮件转发他人，你给了相应人员处置你邮件的选择）。 使用有意义且描述明确的标题在邮件列表、新闻群组或论坛中，大约 50 字以内的标题是抓住资深专家注意力的好机会。别用喋喋不休的帮帮忙、跪求、急（更别说救命啊！！！！这样让人反感的话，用这种标题会被条件反射式地忽略）来浪费这个机会。不要妄想用你的痛苦程度来打动我们，而是在这点空间中使用极简单扼要的描述方式来提出问题。 一个好标题范例是目标 – 差异式的描述，许多技术支持组织就是这样做的。在目标部分指出是哪一个或哪一组东西有问题，在差异部分则描述与期望的行为不一致的地方。 蠢问题：救命啊！我的笔电不能正常显示了！ 聪明问题：X.org 6.8.1 的鼠标游标会变形，某牌显卡 MV1005 芯片组。 更聪明问题：X.org 6.8.1 的鼠标游标，在某牌显卡 MV1005 芯片组环境下 - 会变形。 编写目标 – 差异 式描述的过程有助于你组织对问题的细致思考。 是什么被影响了？ 仅仅是鼠标游标或者还有其它图形？只在 X.org 的 X 版中出现？或只是出现在 6.8.1 版中？ 是针对某牌显卡芯片组？或者只是其中的 MV1005 型号？ 一个黑客只需瞄一眼就能够立即明白你的环境和你遇到的问题。 总而言之，请想像一下你正在一个只显示标题的存档讨论串（Thread）索引中查寻。让你的标题更好地反映问题，可使下一个搜索类似问题的人能够关注这个讨论串，而不用再次提问相同的问题。 如果你想在回复中提出问题，记得要修改内容标题，以表明你是在问一个问题， 一个看起来像 Re: 测试 或者 Re: 新 bug 的标题很难引起足够重视。另外，在不影响连贯性之下，适当引用并删减前文的内容，能给新来的读者留下线索。 对于讨论串，不要直接点击回复来开始一个全新的讨论串，这将限制你的观众。因为有些邮件阅读程序，比如 mutt ，允许使用者按讨论串排序并通过折叠讨论串来隐藏消息，这样做的人永远看不到你发的消息。 仅仅改变标题还不够。mutt 和其它一些邮件阅读程序还会检查邮件标题以外的其它信息，以便为其指定讨论串。所以宁可发一个全新的邮件。 在网页论坛上，好的提问方式稍有不同，因为讨论串与特定的信息紧密结合，并且通常在讨论串外就看不到里面的内容，故通过回复提问，而非改变标题是可接受的。不是所有论坛都允许在回复中出现分离的标题，而且这样做了基本上没有人会去看。不过，通过回复提问，这本身就是暧昧的做法，因为它们只会被正在查看该标题的人读到。所以，除非你只想在该讨论串当前活跃的人群中提问，不然还是另起炉灶比较好。 使问题容易回复 以请将你的回复寄到……来结束你的问题多半会使你得不到回答。如果你觉得花几秒钟在邮件客户端设置一下回复地址都麻烦，我们也觉得花几秒钟思考你的问题更麻烦。如果你的邮件程序不支持这样做，换个好点的；如果是操作系统不支持这种邮件程序，也换个好点的。 在论坛，要求通过电子邮件回复是非常无礼的，除非你相信回复的信息可能比较敏感（而且有人会为了某些未知的原因，只让你而不是整个论坛知道答案）。如果你只是想在有人回复讨论串时得到电子邮件提醒，可以要求网页论坛发送给你。几乎所有论坛都支持诸如追踪此讨论串、有回复时发送邮件提醒等功能。 用清晰、正确、精准并语法正确的语句我们从经验中发现，粗心的提问者通常也会粗心的写程序与思考（我敢打包票）。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。 正确的拼字、标点符号和大小写是很重要的。一般来说，如果你觉得这样做很麻烦，不想在乎这些，那我们也觉得麻烦，不想在乎你的提问。花点额外的精力斟酌一下字句，用不着太僵硬与正式 – 事实上，黑客文化很看重能准确地使用非正式、俚语和幽默的语句。但它必须很准确，而且有迹象表明你是在思考和关注问题。 正确地拼写、使用标点和大小写，不要将its混淆为it’s，loose搞成lose或者将discrete弄成discreet。不要全部用大写，这会被视为无礼的大声嚷嚷（全部小写也好不到哪去，因为不易阅读。Alan Cox 也许可以这样做，但你不行。） 更白话的说，如果你写得像是个半文盲[译注：小白]，那多半得不到理睬。也不要使用即时通讯中的简写或火星文，如将的简化为ㄉ会使你看起来像一个为了少打几个键而省字的小白。更糟的是，如果像个小孩似地鬼画符那绝对是在找死，可以肯定没人会理你（或者最多是给你一大堆指责与挖苦）。 如果在使用非母语的论坛提问，你可以犯点拼写和语法上的小错，但决不能在思考上马虎（没错，我们通常能弄清两者的分别）。同时，除非你知道回复者使用的语言，否则请使用英语书写。繁忙的黑客一般会直接删除用他们看不懂语言写的消息。在网络上英语是通用语言，用英语书写可以将你的问题在尚未被阅读就被直接删除的可能性降到最低。 如果英文是你的外语（Second language），提示潜在回复者你有潜在的语言困难是很好的： [译注：以下附上原文以供使用] English is not my native language; please excuse typing errors.英文不是我的母语，请原谅我的错字或语法 If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question.如果你说某语言，请寄信/私讯给我；我需要有人协助我翻译我的问题 I am familiar with the technical terms, but some slang expressions and idioms are difficult for me.我对技术名词很熟悉，但对于俗语或是特别用法比较不甚了解。 I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other.我把我的问题用某语言和英文写出来，如果你只用一种语言回答，我会乐意将其翻译成另一种。 使用易于读取且标准的文件格式发送问题如果你人为地将问题搞得难以阅读，它多半会被忽略，人们更愿读易懂的问题，所以： 使用纯文字而不是 HTML (关闭 HTML 并不难）。 使用 MIME 附件通常是可以的，前提是真正有内容（譬如附带的源代码或 patch），而不仅仅是邮件程序生成的模板（譬如只是信件内容的拷贝）。 不要发送一段文字只是一行句子但自动换行后会变成多行的邮件（这使得回复部分内容非常困难）。设想你的读者是在 80 个字符宽的终端机上阅读邮件，最好设置你的换行分割点小于 80 字。但是，对一些特殊的文件不要设置固定宽度（譬如日志档案拷贝或会话记录）。数据应该原样包含，让回复者有信心他们看到的是和你看到的一样的东西。 在英语论坛中，不要使用Quoted-Printable MIME 编码发送消息。这种编码对于张贴非 ASCII 语言可能是必须的，但很多邮件程序并不支持这种编码。当它们处理换行时，那些文本中四处散布的=20符号既难看也分散注意力，甚至有可能破坏内容的语意。绝对，永远不要指望黑客们阅读使用封闭格式编写的文档，像微软公司的 Word 或 Excel 文件等。大多数黑客对此的反应就像有人将还在冒热气的猪粪倒在你家门口时你的反应一样。即便他们能够处理，他们也很厌恶这么做。 如果你从使用 Windows 的电脑发送电子邮件，关闭微软愚蠢的智能引号功能 （从[选项] &gt; [校订] &gt; [自动校正选项]，勾选掉智能引号单选框），以免在你的邮件中到处散布垃圾字符。 在论坛，勿滥用表情符号和HTML功能（当它们提供时）。一两个表情符号通常没有问题，但花哨的彩色文本倾向于使人认为你是个无能之辈。过滥地使用表情符号、色彩和字体会使你看来像个傻笑的小姑娘。这通常不是个好主意，除非你只是对性而不是对答案感兴趣。 如果你使用图形用户界面的邮件程序（如微软公司的 Outlook 或者其它类似的），注意它们的默认设置不一定满足这些要求。大多数这类程序有基于选单的查看源代码命令，用它来检查发送文件夹中的邮件，以确保发送的是纯文本文件同时没有一些奇怪的字符。 精确的描述问题并言之有物 仔细、清楚地描述你的问题或 Bug 的症状。 描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：Fedora Core 4、Slackware 9.1等）。 描述在提问前你是怎样去研究和理解这个问题的。 描述在提问前为确定问题而采取的诊断步骤。 描述最近做过什么可能相关的硬件或软件变更。 尽可能的提供一个可以重现这个问题的可控环境的方法。 尽量去揣测一个黑客会怎样反问你，在你提问之前预先将黑客们可能遇到的问题回答一遍。 以上几点中，当你报告的是你认为可能在代码中的问题时，给黑客一个可以重现你的问题的环境尤其重要。当你这么做时，你得到有效的回答的机会和速度都会大大的提升。 Simon Tatham 写过一篇名为《如何有效的报告 Bug》的出色文章。强力推荐你也读一读。 话不在多而在精 你需要提供精确有内容的信息。这并不是要求你简单的把成堆的出错代码或者资料完全转录到你的提问中。如果你有庞大而复杂的测试样例能重现程序挂掉的情境，尽量将它剪裁得越小越好。 这样做的用处至少有三点。第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加；第二，简化问题使你更有可能得到有用的答案；第三，在精炼你的 bug 报告的过程中，你很可能就自己找到了解决方法或权宜之计。 别动辄声称找到 Bug 当你在使用软件中遇到问题，除非你非常、非常的有根据，不要动辄声称找到了 Bug。提示：除非你能提供解决问题的源代码补丁，或者提供回归测试来表明前一版本中行为不正确，否则你都多半不够完全确信。这同样适用在网页和文件，如果你（声称）发现了文件的Bug，你应该能提供相应位置的修正或替代文件。 请记得，还有许多其它使用者没遇到你发现的问题，否则你在阅读文件或搜索网页时就应该发现了（你在抱怨前已经做了这些，是吧？）。这也意味着很有可能是你弄错了而不是软件本身有问题。 编写软件的人总是非常辛苦地使它尽可能完美。如果你声称找到了 Bug，也就是在质疑他们的能力，即使你是对的，也有可能会冒犯到其中某部分人。当你在标题中嚷嚷着有Bug时，这尤其严重。 提问时，即使你私下非常确信已经发现一个真正的 Bug，最好写得像是你做错了什么。如果真的有 Bug，你会在回复中看到这点。这样做的话，如果真有 Bug，维护者就会向你道歉，这总比你惹恼别人然后欠别人一个道歉要好一点。 低声下气不能代替你的功课 有些人明白他们不该粗鲁或傲慢的提问并要求得到答复，但他们选择另一个极端 – 低声下气：我知道我只是个可悲的新手，一个撸瑟，但…。这既使人困扰，也没有用，尤其是伴随着与实际问题含糊不清的描述时更令人反感。 别用原始灵长类动物的把戏来浪费你我的时间。取而代之的是，尽可能清楚地描述背景条件和你的问题情况。这比低声下气更好地定位了你的位置。 有时网页论坛会设有专为新手提问的版面，如果你真的认为遇到了初学者的问题，到那去就是了，但一样别那么低声下气。 描述问题症状而非你的猜测 告诉黑客们你认为问题是怎样造成的并没什么帮助。（如果你的推断如此有效，还用向别人求助吗？），因此要确信你原原本本告诉了他们问题的症状，而不是你的解释和理论；让黑客们来推测和诊断。如果你认为陈述自己的猜测很重要，清楚地说明这只是你的猜测，并描述为什么它们不起作用。 蠢问题 我在编译内核时接连遇到 SIG11 错误， 我怀疑某条飞线搭在主板的走线上了，这种情况应该怎样检查最好？ 聪明问题 我的组装电脑是 FIC-PA2007 主机板搭载 AMD K6/233 CPU（威盛 Apollo VP2 芯片组）， 256MB Corsair PC133 SDRAM 内存，在编译内核时，从开机 20 分钟以后就频频产生 SIG11 错误， 但是在头 20 分钟内从没发生过相同的问题。重新启动也没有用，但是关机一晚上就又能工作 20 分钟。 所有内存都换过了，没有效果。相关部分的标准编译记录如下…。 由于以上这点似乎让许多人觉得难以配合，这里有句话可以提醒你：所有的诊断专家都来自密苏里州。 美国国务院的官方座右铭则是：让我看看（出自国会议员 Willard D. Vandiver 在 1899 年时的讲话：我来自一个出产玉米，棉花，牛蒡和民主党人的国家，滔滔雄辩既不能说服我，也不会让我满意。我来自密苏里州，你必须让我看看。） 针对诊断者而言，这并不是一种怀疑，而只是一种真实而有用的需求，以便让他们看到的是与你看到的原始证据尽可能一致的东西，而不是你的猜测与归纳的结论。所以，大方的展示给我们看吧！ 按发生时间先后列出问题症状 问题发生前的一系列操作，往往就是对找出问题最有帮助的线索。因此，你的说明里应该包含你的操作步骤，以及机器和软件的反应，直到问题发生。在命令行处理的情况下，提供一段操作记录（例如运行脚本工具所生成的），并引用相关的若干行（如 20 行）记录会非常有帮助。 如果挂掉的程序有诊断选项（如 -v 的详述开关），试着选择这些能在记录中增加调试信息的选项。记住，多不等于好。试着选取适当的调试级别以便提供有用的信息而不是让读者淹没在垃圾中。 如果你的说明很长（如超过四个段落），在开头简述问题，接下来再按时间顺序详述会有所帮助。这样黑客们在读你的记录时就知道该注意哪些内容了。 描述目标而不是过程 如果你想弄清楚如何做某事（而不是报告一个 Bug），在开头就描述你的目标，然后才陈述重现你所卡住的特定步骤。 经常寻求技术帮助的人在心中有个更高层次的目标，而他们在自以为能达到目标的特定道路上被卡住了，然后跑来问该怎么走，但没有意识到这条路本身就有问题。结果要费很大的劲才能搞定。 蠢问题 我怎样才能从某绘图程序的颜色选择器中取得十六进制的的 RGB 值？ 聪明问题 我正试着用替换一幅图片的色码（color table）成自己选定的色码，我现在知道的唯一方法是编辑每个色码区块（table slot）， 但却无法从某绘图程序的颜色选择器取得十六进制的的 RGB 值。 第二种提问法比较聪明，你可能得到像是建议采用另一个更合适的工具的回复。 别要求使用私人电邮回复 黑客们认为问题的解决过程应该公开、透明，此过程中如果更有经验的人注意到不完整或者不当之处，最初的回复才能够、也应该被纠正。同时，作为提供帮助者可以得到一些奖励，奖励就是他的能力和学识被其他同行看到。 当你要求私下回复时，这个过程和奖励都被中止。别这样做，让回复者来决定是否私下回答 – 如果他真这么做了，通常是因为他认为问题编写太差或者太肤浅，以至于对其它人没有兴趣。 这条规则存在一条有限的例外，如果你确信提问可能会引来大量雷同的回复时，那么这个神奇的提问句会是向我发电邮，我将为论坛归纳这些回复。试着将邮件列表或新闻群组从洪水般的雷同回复中解救出来是非常有礼貌的 – 但你必须信守诺言。 清楚明确的表达你的问题以及需求 漫无边际的提问是近乎无休无止的时间黑洞。最有可能给你有用答案的人通常也正是最忙的人（他们忙是因为要亲自完成大部分工作）。这样的人对无节制的时间黑洞相当厌恶，所以他们也倾向于厌恶那些漫无边际的提问。 如果你明确表述需要回答者做什么（如提供指点、发送一段代码、检查你的补丁、或是其他等等），就最有可能得到有用的答案。因为这会定出一个时间和精力的上限，便于回答者能集中精力来帮你。这么做很棒。 要理解专家们所处的世界，请把 专业技能想像为充裕的资源，而回复的时间则是稀缺的资源。 你要求他们奉献的时间越少，你越有可能从真正专业而且很忙的专家那里得到解答。 所以，界定一下你的问题，使专家花在辨识你的问题和回答所需要付出的时间减到最少，这技巧对你有用答案相当有帮助 – 但这技巧通常和简化问题有所区别。因此，问我想更好的理解 X，可否指点一下哪有好一点说明？通常比问你能解释一下 X 吗？更好。如果你的代码不能运作，通常请别人看看哪里有问题，比要求别人替你改正要明智得多。 询问有关代码的问题时别要求他人帮你调试有问题的代码，不提示一下应该从何入手。张贴几百行的代码，然后说一声：它不能工作会让你完全被忽略。只贴几十行代码，然后说一句：在第七行以后，我期待它显示 ，但实际出现的是 比较有可能让你得到回应。 最有效描述程序问题的方法是提供最精简的 Bug 展示测试示例（bug-demonstrating test case）。什么是最精简的测试示例？那是问题的缩影；一小个程序片段能刚好展示出程序的异常行为，而不包含其他令人分散注意力的内容。怎么制作最精简的测试示例？如果你知道哪一行或哪一段代码会造成异常的行为，复制下来并加入足够重现这个状况的代码（例如，足以让这段代码能被编译/直译/被应用程序处理）。如果你无法将问题缩减到一个特定区块，就复制一份代码并移除不影响产生问题行为的部分。总之，测试示例越小越好（查看话不在多而在精一节）。 一般而言，要得到一段相当精简的测试示例并不太容易，但永远先尝试这样做的是种好习惯。这种方式可以帮助你了解如何自行解决这个问题 —- 而且即使你的尝试不成功，黑客们也会看到你在尝试取得答案的过程中付出了努力，这可以让他们更愿意与你合作。 如果你只是想让别人帮忙审查（Review）一下代码，在信的开头就要说出来，并且一定要提到你认为哪一部分特别需要关注以及为什么。 别把自己家庭作业的问题贴上来 黑客们很擅长分辨哪些问题是家庭作业式的问题；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由你来搞定，你会从中学到东西。你可以要求给点提示，但别要求得到完整的解决方案。 如果你怀疑自己碰到了一个家庭作业式的问题，但仍然无法解决，试试在使用者群组，论坛或（最后一招）在项目的使用者邮件列表或论坛中提问。尽管黑客们会看出来，但一些有经验的使用者也许仍会给你一些提示。 去掉无意义的提问句 避免用无意义的话结束提问，例如有人能帮我吗？或者这有答案吗？。 首先：如果你对问题的描述不是很好，这样问更是画蛇添足。 其次：由于这样问是画蛇添足，黑客们会很厌烦你 – 而且通常会用逻辑上正确，但毫无意义的回答来表示他们的蔑视， 例如：没错，有人能帮你或者不，没答案。 一般来说，避免用 是或否、对或错、有或没有类型的问句，除非你想得到是或否类型的回答。 即使你很急也不要在标题写紧急 这是你的问题，不是我们的。宣称紧急极有可能事与愿违：大多数黑客会直接删除无礼和自私地企图即时引起关注的问题。更严重的是，紧急这个字（或是其他企图引起关注的标题）通常会被垃圾信过滤器过滤掉 – 你希望能看到你问题的人可能永远也看不到。 有半个例外的情况是，如果你是在一些很高调，会使黑客们兴奋的地方，也许值得这样去做。在这种情况下，如果你有时间压力，也很有礼貌地提到这点，人们也许会有兴趣回答快一点。 当然，这风险很大，因为黑客们兴奋的点多半与你的不同。譬如从 NASA 国际空间站（International Space Station）发这样的标题没有问题，但用自我感觉良好的慈善行为或政治原因发肯定不行。事实上，张贴诸如紧急：帮我救救这个毛绒绒的小海豹！肯定让你被黑客忽略或惹恼他们，即使他们认为毛绒绒的小海豹很重要。 如果你觉得这点很不可思议，最好再把这份指南剩下的内容多读几遍，直到你弄懂了再发文。 礼多人不怪，而且有时还很有帮助 彬彬有礼，多用请和谢谢您的关注，或谢谢你的关照。让大家都知道你对他们花时间免费提供帮助心存感激。 坦白说，这一点并没有比清晰、正确、精准并合法语法和避免使用专用格式重要（也不能取而代之）。黑客们一般宁可读有点唐突但技术上鲜明的 Bug 报告，而不是那种有礼但含糊的报告。（如果这点让你不解，记住我们是按问题能教给我们什么来评价问题的价值的） 然而，如果你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。 （我们注意到，自从本指南发布后，从资深黑客那里得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些黑客觉得先谢了意味着事后就不用再感谢任何人的暗示。我们的建议是要么先说先谢了，然后事后再对回复者表示感谢，或者换种方式表达感激，譬如用谢谢你的关注或谢谢你的关照。） 问题解决后，加个简短的补充说明 问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个说明比较恰当。 最理想的方式是向最初提问的话题回复此消息，并在标题中包含已修正，已解决或其它同等含义的明显标记。在人来人往的邮件列表里，一个看见讨论串问题 X和问题 X - 已解决的潜在回复者就明白不用再浪费时间了（除非他个人觉得问题 X的有趣），因此可以利用此时间去解决其它问题。 补充说明不必很长或是很深入；简单的一句你好，原来是网线出了问题！谢谢大家 – Bill比什么也不说要来的好。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇大论更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。 对于有深度的问题，张贴调试记录的摘要是有帮助的。描述问题的最终状态，说明是什么解决了问题，在此之后才指明可以避免的盲点。避免盲点的部分应放在正确的解决方案和其它总结材料之后，而不要将此信息搞成侦探推理小说。列出那些帮助过你的名字，会让你交到更多朋友。 除了有礼貌和有内涵以外，这种类型的补充也有助于他人在邮件列表/新闻群组/论坛中搜索到真正解决你问题的方案，让他们也从中受益。 至少，这种补充有助于让每位参与协助的人因问题的解决而从中得到满足感。如果你自己不是技术专家或者黑客，那就相信我们，这种感觉对于那些你向他们求助的大师或者专家而言，是非常重要的。问题悬而未决会让人灰心；黑客们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次提问时尝到甜头。 思考一下怎样才能避免他人将来也遇到类似的问题，自问写一份文件或加个常见问题（FAQ）会不会有帮助。如果是的话就将它们发给维护者。 在黑客中，这种良好的后继行动实际上比传统的礼节更为重要，也是你如何透过善待他人而赢得声誉的方式，这是非常有价值的资产。 如何解读答案RTFM 和 STFW：如何知道你已完全搞砸了 有一个古老而神圣的传统：如果你收到 RTFM （Read The Fucking Manual） 的回应，回答者认为你应该去读他妈的手册。当然，基本上他是对的，你应该去读一读。 RTFM 有一个年轻的亲戚。如果你收到 STFW（Search The Fucking Web） 的回应，回答者认为你应该到他妈的网上搜索过了。那人多半也是对的，去搜索一下吧。（更温和一点的说法是 Google 是你的朋友！） 在论坛，你也可能被要求去爬爬论坛的旧文。事实上，有人甚至可能热心地为你提供以前解决此问题的讨论串。但不要依赖这种关照，提问前应该先搜索一下旧文。 通常，用这两句之一回答你的人会给你一份包含你需要内容的手册或者一个网址，而且他们打这些字的时候也正在读着。这些答复意味着回答者认为 你需要的信息非常容易获得； 你自己去搜索这些信息比灌给你，能让你学到更多。 你不应该因此不爽；依照黑客的标准，他已经表示了对你一定程度的关注，而没有对你的要求视而不见。你应该对他祖母般的慈祥表示感谢。 如果还是搞不懂 如果你看不懂回应，别立刻要求对方解释。像你以前试着自己解决问题时那样（利用手册，FAQ，网络，身边的高手），先试着去搞懂他的回应。如果你真的需要对方解释，记得表现出你已经从中学到了点什么。 比方说，如果我回答你：看来似乎是 zentry 卡住了；你应该先清除它。，然后，这是一个很糟的后续问题回应：zentry 是什么？ 好的问法应该是这样：哦~~~我看过说明了但是只有 -z 和 -p 两个参数中提到了 zentries，而且还都没有清楚的解释如何清除它。你是指这两个中的哪一个吗？还是我看漏了什么？ 处理无礼的回应 很多黑客圈子中看似无礼的行为并不是存心冒犯。相反，它是直接了当，一针见血式的交流风格，这种风格更注重解决问题，而不是使人感觉舒服而却模模糊糊。 如果你觉得被冒犯了，试着平静地反应。如果有人真的做了出格的事，邮件列表、新闻群组或论坛中的前辈多半会招呼他。如果这没有发生而你却发火了，那么你发火对象的言语可能在黑客社区中看起来是正常的，而你将被视为有错的一方，这将伤害到你获取信息或帮助的机会。 另一方面，你偶而真的会碰到无礼和无聊的言行。与上述相反，对真正的冒犯者狠狠地打击，用犀利的语言将其驳得体无完肤都是可以接受的。然而，在行事之前一定要非常非常的有根据。纠正无礼的言论与开始一场毫无意义的口水战仅一线之隔，黑客们自己莽撞地越线的情况并不鲜见。如果你是新手或外人，避开这种莽撞的机会并不高。如果你想得到的是信息而不是消磨时光，这时最好不要把手放在键盘上以免冒险。 （有些人断言很多黑客都有轻度的自闭症或亚斯伯格综合症，缺少用于润滑人类社会正常交往所需的神经。这既可能是真也可能是假的。如果你自己不是黑客，兴许你认为我们脑袋有问题还能帮助你应付我们的古怪行为。只管这么干好了，我们不在乎。我们喜欢我们现在这个样子，并且通常对病患标记都有站得住脚的怀疑。） Jeff Bigler 的观察总结和这个相关也值得一读 (tact filters)。 在下一节，我们会谈到另一个问题，当你行为不当时所会受到的冒犯。 如何避免扮演失败者在黑客社区的论坛中有那么几次你可能会搞砸 – 以本指南所描述到的或类似的方式。而你会在公开场合中被告知你是如何搞砸的，也许攻击的言语中还会带点夹七夹八的颜色。 这种事发生以后，你能做的最糟糕的事莫过于哀嚎你的遭遇、宣称被口头攻击、要求道歉、高声尖叫、憋闷气、威胁诉诸法律、向其雇主报怨、忘了关马桶盖等等。相反地，你该这么做： 熬过去，这很正常。事实上，它是有益健康且合理的。 社区的标准不会自行维持，它们是通过参与者积极而公开地执行来维持的。不要哭嚎所有的批评都应该通过私下的邮件传送，它不是这样运作的。当有人评论你的一个说法有误或者提出不同看法时，坚持声称受到个人攻击也毫无益处，这些都是失败者的态度。 也有其它的黑客论坛，受过高礼节要求的误导，禁止参与者张贴任何对别人帖子挑毛病的消息，并声称如果你不想帮助用户就闭嘴。 结果造成有想法的参与者纷纷离开，这么做只会使它们沦为毫无意义的唠叨与无用的技术论坛。 夸张的讲法是：你要的是友善（以上述方式）还是有用？两个里面挑一个。 记着：当黑客说你搞砸了，并且（无论多么刺耳）告诉你别再这样做时，他正在为关心你和他的社区而行动。对他而言，不理你并将你从他的生活中滤掉更简单。如果你无法做到感谢，至少要表现得有点尊严，别大声哀嚎，也别因为自己是个有戏剧性超级敏感的灵魂和自以为有资格的新来者，就指望别人像对待脆弱的洋娃娃那样对你。 有时候，即使你没有搞砸（或者只是在他的想像中你搞砸了），有些人也会无缘无故地攻击你本人。在这种情况下，抱怨倒是真的会把问题搞砸。 这些来找麻烦的人要么是毫无办法但自以为是专家的不中用家伙，要么就是测试你是否真会搞砸的心理专家。其它读者要么不理睬，要么用自己的方式对付他们。这些来找麻烦的人在给他们自己找麻烦，这点你不用操心。 也别让自己卷入口水战，最好不要理睬大多数的口水战 – 当然，这是在你检验它们只是口水战，并且未指出你有搞砸的地方，同时也没有巧妙地将问题真正的答案藏于其后（这也是有可能的）。 不该问的问题 以下是几个经典蠢问题，以及黑客没回答时心中所想的： 问题：我能在哪找到 X 程序或 X 资源？ 问题：我怎样用 X 做 Y？ 问题：如何设定我的 shell 提示？ 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？ 问题：我的程序/设定/SQL 语句没有用 问题：我的 Windows 电脑有问题，你能帮我吗？ 问题：我的程序不会动了，我认为系统工具 X 有问题 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？ 问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？ 问题：我能在哪找到 X 程序或 X 资源？回答：就在我找到它的地方啊，白痴 – 搜索引擎的那一头。天哪！难道还有人不会用 Google 吗？ 问题：我怎样用 X 做 Y？回答：如果你想解决的是 Y ，提问时别给出可能并不恰当的方法。这种问题说明提问者不但对 X 完全无知，也对 Y 要解决的问题糊涂，还被特定形势禁锢了思维。最好忽略这种人，等他们把问题搞清楚了再说。 问题：如何设定我的 shell 提示？？回答：如果你有足够的智慧提这个问题，你也该有足够的智慧去 RTFM，然后自己去找出来。 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？回答：试试看就知道了。如果你试过，你既知道了答案，就不用浪费我的时间了。 问题：我的{程序/设定/SQL 语句}不工作回答：这不算是问题吧，我对要我问你二十个问题才找得出你真正问题的问题没兴趣 – 我有更有意思的事要做呢。在看到这类问题的时候，我的反应通常不外如下三种 你还有什么要补充的吗？真糟糕，希望你能搞定。这关我有什么屁事？ 问题：我的 Windows 电脑有问题，你能帮我吗？回答：能啊，扔掉微软的垃圾，换个像 Linux 或 BSD 的开放源代码操作系统吧。 注意：如果程序有官方版 Windows 或者与 Windows 有互动（如 Samba），你可以问与 Windows 相关的问题， 只是别对问题是由 Windows 操作系统而不是程序本身造成的回复感到惊讶， 因为 Windows 一般来说实在太烂，这种说法通常都是对的。 问题：我的程序不会动了，我认为系统工具 X 有问题回答：你完全有可能是第一个注意到被成千上万用户反复使用的系统调用与函数库档案有明显缺陷的人，更有可能的是你完全没有根据。不同凡响的说法需要不同凡响的证据，当你这样声称时，你必须有清楚而详尽的缺陷说明文件作后盾。 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的 Linux 使用群组者寻求实际的指导吧（你能在这儿找到使用者群组的清单）。 注意：如果安装问题与某 Linux 的发行版有关，在它的邮件列表、论坛或本地使用者群组中提问也许是恰当的。此时，应描述问题的准确细节。在此之前，先用 Linux 和所有被怀疑的硬件作关键词仔细搜索。 问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？回答：想要这样做，说明了你是个卑鄙小人；想找个黑客帮你，说明你是个白痴！ 好问题与蠢问题最后，我将透过举一些例子，来说明怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。 蠢问题： 我可以在哪儿找到关于 Foonly Flurbamatic 的资料？这种问法无非想得到 STFW 这样的回答。 聪明问题： 我用 Google 搜索过 “Foonly Flurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？这个问题已经 STFW 过了，看起来他真的遇到了麻烦。 蠢问题 我从 foo 项目找来的源码没法编译。它怎么这么烂？他觉得都是别人的错，这个傲慢自大的提问者。 聪明问题 foo 项目代码在 Nulix 6.2 版下无法编译通过。我读过了 FAQ，但里面没有提到跟 Nulix 有关的问题。这是我编译过程的记录，我有什么做的不对的地方吗？提问者已经指明了环境，也读过了 FAQ，还列出了错误，并且他没有把问题的责任推到别人头上，他的问题值得被关注。 蠢问题 我的主机板有问题了，谁来帮我？某黑客对这类问题的回答通常是：好的，还要帮你拍拍背和换尿布吗？，然后按下删除键。 聪明问题 我在 S2464 主机板上试过了 X 、 Y 和 Z ，但没什么作用，我又试了 A 、 B 和 C 。请注意当我尝试 C 时的奇怪现象。显然 florbish 正在 grommicking，但结果出人意料。通常在 Athlon MP 主机板上引起 grommicking 的原因是什么？有谁知道接下来我该做些什么测试才能找出问题？这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。 在最后一个问题中，注意告诉我答案和给我启示，指出我还应该做什么诊断工作之间微妙而又重要的区别。 事实上，后一个问题源自于 2001 年 8 月在 Linux 内核邮件列表（lkml）上的一个真实的提问。我（Eric）就是那个提出问题的人。我在 Tyan S2464 主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决这一问题的重要信息。 通过我的提问方法，我给了别人可以咀嚼玩味的东西；我设法让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，并邀请他们与我共同探讨。通过告诉他们我所走过的弯路，以避免他们再浪费时间，我也表明了对他们宝贵时间的尊重。 事后，当我向每个人表示感谢，并且赞赏这次良好的讨论经历的时候， 一个 Linux 内核邮件列表的成员表示，他觉得我的问题得到解决并非由于我是这个列表中的名人，而是因为我用了正确的方式来提问。 黑客从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我像个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，这直接导致了本指南的出现。 如果得不到回答如果仍得不到回答，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。 总的来说，简单的重复张贴问题是个很糟的点子。这将被视为无意义的喧闹。有点耐心，知道你问题答案的人可能生活在不同的时区，可能正在睡觉，也有可能你的问题一开始就没有组织好。 你可以通过其他渠道获得帮助，这些渠道通常更适合初学者的需要。 有许多网上的以及本地的使用者群组，由热情的软件爱好者（即使他们可能从没亲自写过任何软件）组成。通常人们组建这样的团体来互相帮助并帮助新手。 另外，你可以向很多商业公司寻求帮助，不论公司大还是小。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了– 完全可能如此 –你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。 对像是 Linux 这种大众化的软件，每个开发者至少会对应到上万名使用者。根本不可能由一个人来处理来自上万名使用者的求助电话。要知道，即使你要为这些协助付费，和你所购买的同类软件相比，你所付出的也是微不足道的（通常封闭源代码软件的技术支持费用比开放源代码软件的要高得多，且内容也没那么丰富）。 如何更好地回答问题态度和善一点。问题带来的压力常使人显得无礼或愚蠢，其实并不是这样。 对初犯者私下回复。对那些坦诚犯错之人没有必要当众羞辱，一个真正的新手也许连怎么搜索或在哪找常见问题都不知道。 如果你不确定，一定要说出来！一个听起来权威的错误回复比没有还要糟，别因为听起来像个专家很好玩，就给别人乱指路。要谦虚和诚实，给提问者与同行都树个好榜样。 如果帮不了忙，也别妨碍他。不要在实际步骤上开玩笑，那样也许会毁了使用者的设置 –有些可怜的呆瓜会把它当成真的指令。 试探性的反问以引出更多的细节。如果你做得好，提问者可以学到点东西 –你也可以。试试将蠢问题转变成好问题，别忘了我们都曾是新手。 尽管对那些懒虫抱怨一声 RTFM 是正当的，能指出文件的位置（即使只是建议个 Google 搜索关键词）会更好。 如果你决定回答，就请给出好的答案。当别人正在用错误的工具或方法时别建议笨拙的权宜之计（wordaround），应推荐更好的工具，重新界定问题。 正面的回答问题！如果这个提问者已经很深入的研究而且也表明已经试过 X 、 Y 、 Z 、 A 、 B 、 C 但没得到结果，回答 试试看 A 或是 B 或者 试试 X 、 Y 、 Z 、 A 、 B 、 C 并附上一个链接一点用都没有。 帮助你的社区从问题中学习。当回复一个好问题时，问问自己如何修改相关文件或常见问题文件以免再次解答同样的问题？，接着再向文件维护者发一份补丁。 如果你是在研究一番后才做出的回答，展现你的技巧而不是直接端出结果。毕竟 授人以鱼不如授人以渔。 相关资源 如果你需要个人电脑、Unix 系统和网络如何运作的基础知识，参阅 Unix 系统和网络基本原理。 当你发布软件或补丁时，试着按软件发布实践操作。 鸣谢 Evelyn Mitchel 贡献了一些愚蠢问题例子并启发了编写如何更好地回答问题这一节， Mikhail Ramendik 贡献了一些特别有价值的建议和改进。 How To Ask Questions The Smart WayEric Steven Raymond Thyrsus Enterprises &lt;esr@thyrsus.com&gt; Rick Moen &lt;respond-auto@linuxmafia.com&gt; Copyright © 2001,2006,2014 Eric S. Raymond, Rick Moen Revision HistoryRevision 3.10 21 May 2014 esrNew section on Stack Overflow.Revision 3.9 23 Apr 2013 esrURL fixes.Revision 3.8 19 Jun 2012 esrURL fix.Revision 3.7 06 Dec 2010 esrHelpful hints for ESL speakers.Revision 3.7 02 Nov 2010 esrSeveral translations have disappeared.Revision 3.6 19 Mar 2008 esrMinor update and new links.Revision 3.5 2 Jan 2008 esrTypo fix and some translation links.Revision 3.4 24 Mar 2007 esrNew section, “When asking about code”.Revision 3.3 29 Sep 2006 esrFolded in a good suggestion from Kai Niggemann.Revision 3.2 10 Jan 2006 esrFolded in edits from Rick Moen.Revision 3.1 28 Oct 2004 esrDocument ‘Google is your friend!’Revision 3.0 2 Feb 2004 esrMajor addition of stuff about proper etiquette on Web forums.Table of Contents TranslationsDisclaimerIntroductionBefore You AskWhen You AskChoose your forum carefullyStack OverflowWeb and IRC forumsAs a second step, use project mailing listsUse meaningful, specific subject headersMake it easy to replyWrite in clear, grammatical, correctly-spelled languageSend questions in accessible, standard formatsBe precise and informative about your problemVolume is not precisionDon’t rush to claim that you have found a bugGrovelling is not a substitute for doing your homeworkDescribe the problem’s symptoms, not your guessesDescribe your problem’s symptoms in chronological orderDescribe the goal, not the stepDon’t ask people to reply by private e-mailBe explicit about your questionWhen asking about codeDon’t post homework questionsPrune pointless queriesDon’t flag your question as “Urgent”, even if it is for youCourtesy never hurts, and sometimes helpsFollow up with a brief note on the solutionHow To Interpret AnswersRTFM and STFW: How To Tell You’ve Seriously Screwed UpIf you don’t understand…Dealing with rudenessOn Not Reacting Like A LoserQuestions Not To AskGood and Bad QuestionsIf You Can’t Get An AnswerHow To Answer Questions in a Helpful WayRelated ResourcesAcknowledgementsTranslations Translations: Bahasa Indonesian Belorussian Brazilo-Portuguese Bulgarian Chinese (Traditional) Croatian Dutch French Georgian German Greek Hindi Irish Gaelic Japanese Lithuanian Polish Portuguese Romanian Russian Serbian Spanish Uzbek If you want to copy, mirror, translate, or excerpt this document, please see my copying policy. Disclaimer Many project websites link to this document in their sections on how to get help. That’s fine, it’s the use we intended — but if you are a webmaster creating such a link for your project page, please display prominently near the link notice that we are not a help desk for your project! We have learned the hard way that without such a notice, we will repeatedly be pestered by idiots who think having published this document makes it our job to solve all the world’s technical problems. If you’re reading this document because you need help, and you walk away with the impression you can get it directly from the authors of this document, you are one of the idiots we are talking about. Don’t ask us questions. We’ll just ignore you. We are here to show you how to get help from people who actually know about the software or hardware you’re dealing with, but 99.9% of the time that will not be us. Unless you know for certain that one of the authors is an expert on what you’re dealing with, leave us alone and everybody will be happier. Introduction In the world of hackers, the kind of answers you get to your technical questions depends as much on the way you ask the questions as on the difficulty of developing the answer. This guide will teach you how to ask questions in a way more likely to get you a satisfactory answer. Now that use of open source has become widespread, you can often get as good answers from other, more experienced users as from hackers. This is a Good Thing; users tend to be just a little bit more tolerant of the kind of failures newbies often have. Still, treating experienced users like hackers in the ways we recommend here will generally be the most effective way to get useful answers out of them, too. The first thing to understand is that hackers actually like hard problems and good, thought-provoking questions about them. If we didn’t, we wouldn’t be here. If you give us an interesting question to chew on we’ll be grateful to you; good questions are a stimulus and a gift. Good questions help us develop our understanding, and often reveal problems we might not have noticed or thought about otherwise. Among hackers, “Good question!” is a strong and sincere compliment. Despite this, hackers have a reputation for meeting simple questions with what looks like hostility or arrogance. It sometimes looks like we’re reflexively rude to newbies and the ignorant. But this isn’t really true. What we are, unapologetically, is hostile to people who seem to be unwilling to think or to do their own homework before asking questions. People like that are time sinks — they take without giving back, and they waste time we could have spent on another question more interesting and another person more worthy of an answer. We call people like this “losers” (and for historical reasons we sometimes spell it “lusers”). We realize that there are many people who just want to use the software we write, and who have no interest in learning technical details. For most people, a computer is merely a tool, a means to an end; they have more important things to do and lives to live. We acknowledge that, and don’t expect everyone to take an interest in the technical matters that fascinate us. Nevertheless, our style of answering questions is tuned for people who do take such an interest and are willing to be active participants in problem-solving. That’s not going to change. Nor should it; if it did, we would become less effective at the things we do best. We’re (largely) volunteers. We take time out of busy lives to answer questions, and at times we’re overwhelmed with them. So we filter ruthlessly. In particular, we throw away questions from people who appear to be losers in order to spend our question-answering time more efficiently, on winners. If you find this attitude obnoxious, condescending, or arrogant, check your assumptions. We’re not asking you to genuflect to us — in fact, most of us would love nothing more than to deal with you as an equal and welcome you into our culture, if you put in the effort required to make that possible. But it’s simply not efficient for us to try to help people who are not willing to help themselves. It’s OK to be ignorant; it’s not OK to play stupid. So, while it isn’t necessary to already be technically competent to get attention from us, it is necessary to demonstrate the kind of attitude that leads to competence — alert, thoughtful, observant, willing to be an active partner in developing a solution. If you can’t live with this sort of discrimination, we suggest you pay somebody for a commercial support contract instead of asking hackers to personally donate help to you. If you decide to come to us for help, you don’t want to be one of the losers. You don’t want to seem like one, either. The best way to get a rapid and responsive answer is to ask it like a person with smarts, confidence, and clues who just happens to need help on one particular problem. (Improvements to this guide are welcome. You can mail suggestions to esr@thyrsus.com or respond-auto@linuxmafia.com. Note however that this document is not intended to be a general guide to netiquette, and we will generally reject suggestions that are not specifically related to eliciting useful answers in a technical forum.) Before You Ask Before asking a technical question by e-mail, or in a newsgroup, or on a website chat board, do the following: Try to find an answer by searching the archives of the forum or mailing list you plan to post to. Try to find an answer by searching the Web. Try to find an answer by reading the manual. Try to find an answer by reading a FAQ. Try to find an answer by inspection or experimentation. Try to find an answer by asking a skilled friend. If you’re a programmer, try to find an answer by reading the source code. When you ask your question, display the fact that you have done these things first; this will help establish that you’re not being a lazy sponge and wasting people’s time. Better yet, display what you have learned from doing these things. We like answering questions for people who have demonstrated they can learn from the answers. Use tactics like doing a Google search on the text of whatever error message you get (searching Google groups as well as Web pages). This might well take you straight to fix documentation or a mailing list thread answering your question. Even if it doesn’t, saying “I googled on the following phrase but didn’t get anything that looked promising” is a good thing to do in e-mail or news postings requesting help, if only because it records what searches won’t help. It will also help to direct other people with similar problems to your thread by linking the search terms to what will hopefully be your problem and resolution thread. Take your time. Do not expect to be able to solve a complicated problem with a few seconds of Googling. Read and understand the FAQs, sit back, relax and give the problem some thought before approaching experts. Trust us, they will be able to tell from your questions how much reading and thinking you did, and will be more willing to help if you come prepared. Don’t instantly fire your whole arsenal of questions just because your first search turned up no answers (or too many). Prepare your question. Think it through. Hasty-sounding questions get hasty answers, or none at all. The more you do to demonstrate that having put thought and effort into solving your problem before seeking help, the more likely you are to actually get help. Beware of asking the wrong question. If you ask one that is based on faulty assumptions, J. Random Hacker is quite likely to reply with a uselessly literal answer while thinking “Stupid question…”, and hoping the experience of getting what you asked for rather than what you needed will teach you a lesson. Never assume you are entitled to an answer. You are not; you aren’t, after all, paying for the service. You will earn an answer, if you earn it, by asking a substantial, interesting, and thought-provoking question — one that implicitly contributes to the experience of the community rather than merely passively demanding knowledge from others. On the other hand, making it clear that you are able and willing to help in the process of developing the solution is a very good start. “Would someone provide a pointer?”, “What is my example missing?”, and “What site should I have checked?” are more likely to get answered than “Please post the exact procedure I should use.” because you’re making it clear that you’re truly willing to complete the process if someone can just point you in the right direction. When You Ask Choose your forum carefully Be sensitive in choosing where you ask your question. You are likely to be ignored, or written off as a loser, if you: post your question to a forum where it’s off topic post a very elementary question to a forum where advanced technical questions are expected, or vice-versa cross-post to too many different newsgroups post a personal e-mail to somebody who is neither an acquaintance of yours nor personally responsible for solving your problem Hackers blow off questions that are inappropriately targeted in order to try to protect their communications channels from being drowned in irrelevance. You don’t want this to happen to you. The first step, therefore, is to find the right forum. Again, Google and other Web-searching methods are your friend. Use them to find the project webpage most closely associated with the hardware or software giving you difficulties. Usually it will have links to a FAQ (Frequently Asked Questions) list, and to project mailing lists and their archives. These mailing lists are the final places to go for help, if your own efforts (including reading those FAQs you found) do not find you a solution. The project page may also describe a bug-reporting procedure, or have a link to one; if so, follow it. Shooting off an e-mail to a person or forum which you are not familiar with is risky at best. For example, do not assume that the author of an informative webpage wants to be your free consultant. Do not make optimistic guesses about whether your question will be welcome — if you’re unsure, send it elsewhere, or refrain from sending it at all. When selecting a Web forum, newsgroup or mailing list, don’t trust the name by itself too far; look for a FAQ or charter to verify your question is on-topic. Read some of the back traffic before posting so you’ll get a feel for how things are done there. In fact, it’s a very good idea to do a keyword search for words relating to your problem on the newsgroup or mailing list archives before you post. It may find you an answer, and if not it will help you formulate a better question. Don’t shotgun-blast all the available help channels at once, that’s like yelling and irritates people. Step through them softly. Know what your topic is! One of the classic mistakes is asking questions about the Unix or Windows programming interface in a forum devoted to a language or library or tool portable across both. If you don’t understand why this is a blunder, you’d be best off not asking any questions at all until you get it. In general, questions to a well-selected public forum are more likely to get useful answers than equivalent questions to a private one. There are multiple reasons for this. One is simply the size of the pool of potential respondents. Another is the size of the audience; hackers would rather answer questions that educate many people than questions serving only a few. Understandably, skilled hackers and authors of popular software are already receiving more than their fair share of mis-targeted messages. By adding to the flood, you could in extreme cases even be the straw that breaks the camel’s back — quite a few times, contributors to popular projects have withdrawn their support because collateral damage in the form of useless e-mail traffic to their personal accounts became unbearable. Stack Overflow Search, then ask on Stack Exchange In recent years, the Stack Exchange community of sites has emerged as a major resource for answering technical and other questions and is even the preferred forum for many open-source projects. Start with a Google search before looking at Stack Exchange; Google indexes it in real time. There’s a very good chance someone has already asked a similar question, and the Stack Exchange sites are often near the top of the search results. If you didn’t find anything through Google, search again on the specific site most relevant to your question (see below). Searching with tags can help narrow down the results. If you still didn’t find anything, post your question on the one site where it’s most on-topic. Use the formatting tools, especially for code, and add tags that are related to the substance of your question (particularly the name of the programming language, operating system, or library you’re having trouble with). If a commenter asks you for more information, edit your main post to include it. If any answer is helpful, click the up arrow to upvote it; if an answer gives a solution to your problem, click the check under the voting arrows to accept it as correct. Stack Exchange has grown to over 100 sites, but here are the most likely candidates: Super User is for questions about general-purpose computing. If your question isn’t about code or programs that you talk to only over a network connection, it probably goes here. Stack Overflow is for questions about programming. Server Fault is for questions about server and network administration. Several projects have their own specific sites, including Android, Ubuntu, TeX/LaTeX, and SharePoint. Check the Stack Exchange site for an up-to-date list. Web and IRC forums Your local user group, or your Linux distribution, may advertise a Web forum or IRC channel where newbies can get help. (In non-English-speaking countries newbie forums are still more likely to be mailing lists.) These are good first places to ask, especially if you think you may have tripped over a relatively simple or common problem. An advertised IRC channel is an open invitation to ask questions there and often get answers in real time. In fact, if you got the program that is giving you problems from a Linux distribution (as is common today), it may be better to ask in the distro’s forum/list before trying the program’s project forum/list. The project’s hackers may just say, “use our build”. Before posting to any Web forum, check if it has a Search feature. If it does, try a couple of keyword searches for something like your problem; it just might help. If you did a general Web search before (as you should have), search the forum anyway; your Web-wide search engine might not have all of this forum indexed recently. There is an increasing tendency for projects to do user support over a Web forum or IRC channel, with e-mail reserved more for development traffic. So look for those channels first when seeking project-specific help. In IRC, it’s probably best not to dump a long problem description on the channel first thing; some people interpret this as channel-flooding. Best to utter a one-line problem description in a way pitched to start a conversation on the channel. As a second step, use project mailing lists When a project has a development mailing list, write to the mailing list, not to individual developers, even if you believe you know who can best answer your question. Check the documentation of the project and its homepage for the address of a project mailing list, and use it. There are several good reasons for this policy: Any question good enough to be asked of one developer will also be of value to the whole group. Contrariwise, if you suspect your question is too dumb for a mailing list, it’s not an excuse to harass individual developers. Asking questions on the list distributes load among developers. The individual developer (especially if he’s the project leader) may be too busy to answer your questions. Most mailing lists are archived and the archives are indexed by search engines. If you ask your question on-list and it is answered, a future querent could find your question and the answer on the Web instead of asking it again. If certain questions are seen to be asked often, developers can use that information to improve the documentation or the software itself to be less confusing. But if those questions are asked in private, nobody has the complete picture of what questions are asked most often. If a project has both a “user” and a “developer” (or “hacker”) mailing list or Web forum, and you are not hacking on the code, ask in the “user” list/forum. Do not assume that you will be welcome on the developer list, where they’re likely to experience your question as noise disrupting their developer traffic. However, if you are sure your question is non-trivial, and you get no answer in the “user” list/forum for several days, try the “developer” one. You would be well advised to lurk there for a few daysor at least review the last few days of archived messages, to learn the local folkways before posting (actually this is good advice on any private or semi-private list). If you cannot find a project’s mailing list address, but only see the address of the maintainer of the project, go ahead and write to the maintainer. But even in that case, don’t assume that the mailing list doesn’t exist. Mention in your e-mail that you tried and could not find the appropriate mailing list. Also mention that you don’t object to having your message forwarded to other people. (Many people believe that private e-mail should remain private, even if there is nothing secret in it. By allowing your message to be forwarded you give your correspondent a choice about how to handle your e-mail.) Use meaningful, specific subject headers On mailing lists, newsgroups or Web forums, the subject header is your golden opportunity to attract qualified experts’ attention in around 50 characters or fewer. Don’t waste it on babble like “Please help me” (let alone “PLEASE HELP ME!!!!”; messages with subjects like that get discarded by reflex). Don’t try to impress us with the depth of your anguish; use the space for a super-concise problem description instead. One good convention for subject headers, used by many tech support organizations, is “object - deviation”. The “object” part specifies what thing or group of things is having a problem, and the “deviation” part describes the deviation from expected behavior. Stupid:HELP! Video doesn’t work properly on my laptop! Smart:X.org 6.8.1 misshapen mouse cursor, Fooware MV1005 vid. chipset Smarter:X.org 6.8.1 mouse cursor on Fooware MV1005 vid. chipset - is misshapen The process of writing an “object-deviation” description will help you organize your thinking about the problem in more detail. What is affected? Just the mouse cursor or other graphics too? Is this specific to the X.org version of X? To version 6.8.1? Is this specific to Fooware video chipsets? To model MV1005? A hacker who sees the result can immediately understand what it is that you are having a problem with and the problem you are having, at a glance. More generally, imagine looking at the index of an archive of questions, with just the subject lines showing. Make your subject line reflect your question well enough that the next person searching the archive with a question similar to yours will be able to follow the thread to an answer rather than posting the question again. If you ask a question in a reply, be sure to change the subject line to indicate that you’re asking a question. A Subject line that looks like “Re: test” or “Re: new bug” is less likely to attract useful amounts of attention. Also, pare quotation of previous messages to the minimum consistent with cluing in new readers. Do not simply hit reply to a list message in order to start an entirely new thread. This will limit your audience. Some mail readers, like mutt, allow the user to sort by thread and then hide messages in a thread by folding the thread. Folks who do that will never see your message. Changing the subject is not sufficient. Mutt, and probably other mail readers, looks at other information in the e-mail’s headers to assign it to a thread, not the subject line. Instead start an entirely new e-mail. On Web forums the rules of good practice are slightly different, because messages are usually much more tightly bound to specific discussion threads and often invisible outside those threads. Changing the subject when asking a question in reply is not essential. Not all forums even allow separate subject lines on replies, and nearly nobody reads them when they do. However, asking a question in a reply is a dubious practice in itself, because it will only be seen by those who are watching this thread. So, unless you are sure you want to ask only the people currently active in the thread, start a new one. Make it easy to reply Finishing your query with “Please send your reply to… ” makes it quite unlikely you will get an answer. If you can’t be bothered to take even the few seconds required to set up a correct Reply-To header in your mail agent, we can’t be bothered to take even a few seconds to think about your problem. If your mail program doesn’t permit this, get a better mail program. If your operating system doesn’t support any e-mail programs that permit this, get a better operating system. In Web forums, asking for a reply by e-mail is outright rude, unless you believe the information may be sensitive (and somebody will, for some unknown reason, let you but not the whole forum know it). If you want an e-mail copy when somebody replies in the thread, request that the Web forum send it; this feature is supported almost everywhere under options like “watch this thread”, “send e-mail on answers”, etc. Write in clear, grammatical, correctly-spelled language We’ve found by experience that people who are careless and sloppy writers are usually also careless and sloppy at thinking and coding (often enough to bet on, anyway). Answering questions for careless and sloppy thinkers is not rewarding; we’d rather spend our time elsewhere. So expressing your question clearly and well is important. If you can’t be bothered to do that, we can’t be bothered to pay attention. Spend the extra effort to polish your language. It doesn’t have to be stiff or formal — in fact, hacker culture values informal, slangy and humorous language used with precision. But it has to be precise; there has to be some indication that you’re thinking and paying attention. Spell, punctuate, and capitalize correctly. Don’t confuse “its” with “it’s”, “loose” with “lose”, or “discrete” with “discreet”. Don’t TYPE IN ALL CAPS; this is read as shouting and considered rude. (All-smalls is only slightly less annoying, as it’s difficult to read. Alan Cox can get away with it, but you can’t.) More generally, if you write like a semi-literate boob you will very likely be ignored. So don’t use instant-messaging shortcuts. Spelling “you” as “u” makes you look like a semi-literate boob to save two entire keystrokes. Worse: writing like a l33t script kiddie hax0r is the absolute kiss of death and guarantees you will receive nothing but stony silence (or, at best, a heaping helping of scorn and sarcasm) in return. If you are asking questions in a forum that does not use your native language, you will get a limited amount of slack for spelling and grammar errors — but no extra slack at all for laziness (and yes, we can usually spot that difference). Also, unless you know what your respondent’s languages are, write in English. Busy hackers tend to simply flush questions in languages they don’t understand, and English is the working language of the Internet. By writing in English you minimize your chances that your question will be discarded unread. If you are writing in English but it is a second language for you, it is good form to alert potential respondents to potential language difficulties and options for getting around them. Examples: English is not my native language; please excuse typing errors. If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question. I am familiar with the technical terms, but some slang expressions and idioms are difficult for me. I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other. Send questions in accessible, standard formats If you make your question artificially hard to read, it is more likely to be passed over in favor of one that isn’t. So: Send plain text mail, not HTML. (It’s not hard to turn off HTML.) MIME attachments are usually OK, but only if they are real content (such as an attached source file or patch), and not merely boilerplate generated by your mail client (such as another copy of your message). Don’t send e-mail in which entire paragraphs are single multiply-wrapped lines. (This makes it too difficult to reply to just part of the message.) Assume that your respondents will be reading mail on 80-character-wide text displays and set your line wrap accordingly, to something less than 80. However, do not wrap data (such as log file dumps or session transcripts) at any fixed column width. Data should be included as-is, so respondents can have confidence that they are seeing what you saw. Don’t send MIME Quoted-Printable encoding to an English-language forum. This encoding can be necessary when you’re posting in a language ASCII doesn’t cover, but many e-mail agents don’t support it. When they break, all those =20 glyphs scattered through the text are ugly and distracting — or may actively sabotage the semantics of your text. Never, ever expect hackers to be able to read closed proprietary document formats like Microsoft Word or Excel. Most hackers react to these about as well as you would to having a pile of steaming pig manure dumped on your doorstep. Even when they can cope, they resent having to do so. If you’re sending e-mail from a Windows machine, turn off Microsoft’s problematic “Smart Quotes” feature (From Tools &gt; AutoCorrect Options, clear the smart quotes checkbox under AutoFormat As You Type.). This is so you’ll avoid sprinkling garbage characters through your mail. In Web forums, do not abuse “smiley” and “HTML” features (when they are present). A smiley or two is usually OK, but colored fancy text tends to make people think you are lame. Seriously overusing smileys and color and fonts will make you come off like a giggly teenage girl, which is not generally a good idea unless you are more interested in sex than answers. If you’re using a graphical-user-interface mail client such as Netscape Messenger, MS Outlook, or their ilk, beware that it may violate these rules when used with its default settings. Most such clients have a menu-based “View Source” command. Use this on something in your sent-mail folder, verifying sending of plain text without unnecessary attached crud. Be precise and informative about your problem Describe the symptoms of your problem or bug carefully and clearly. Describe the environment in which it occurs (machine, OS, application, whatever). Provide your vendor’s distribution and release level (e.g.: “Fedora Core 7”, “Slackware 9.1”, etc.). Describe the research you did to try and understand the problem before you asked the question. Describe the diagnostic steps you took to try and pin down the problem yourself before you asked the question. Describe any possibly relevant recent changes in your computer or software configuration. If at all possible, provide a way to reproduce the problem in a controlled environment. Do the best you can to anticipate the questions a hacker will ask, and answer them in advance in your request for help. Giving hackers the ability to reproduce the problem in a controlled environment is especially important if you are reporting something you think is a bug in code. When you do this, your odds of getting a useful answer and the speed with which you are likely to get that answer both improve tremendously. Simon Tatham has written an excellent essay entitled How to Report Bugs Effectively. I strongly recommend that you read it. Volume is not precision You need to be precise and informative. This end is not served by simply dumping huge volumes of code or data into a help request. If you have a large, complicated test case that is breaking a program, try to trim it and make it as small as possible. This is useful for at least three reasons. One: being seen to invest effort in simplifying the question makes it more likely you’ll get an answer, Two: simplifying the question makes it more likely you’ll get a useful answer. Three: In the process of refining your bug report, you may develop a fix or workaround yourself. Don’t rush to claim that you have found a bug When you are having problems with a piece of software, don’t claim you have found a bug unless you are very, very sure of your ground. Hint: unless you can provide a source-code patch that fixes the problem, or a regression test against a previous version that demonstrates incorrect behavior, you are probably not sure enough. This applies to webpages and documentation, too; if you have found a documentation “bug”, you should supply replacement text and which pages it should go on. Remember, there are many other users that are not experiencing your problem. Otherwise you would have learned about it while reading the documentation and searching the Web (you did do that before complaining, didn’t you?). This means that very probably it is you who are doing something wrong, not the software. The people who wrote the software work very hard to make it work as well as possible. If you claim you have found a bug, you’ll be impugning their competence, which may offend some of them even if you are correct. It’s especially undiplomatic to yell “bug” in the Subject line. When asking your question, it is best to write as though you assume you are doing something wrong, even if you are privately pretty sure you have found an actual bug. If there really is a bug, you will hear about it in the answer. Play it so the maintainers will want to apologize to you if the bug is real, rather than so that you will owe them an apology if you have messed up. Grovelling is not a substitute for doing your homework Some people who get that they shouldn’t behave rudely or arrogantly, demanding an answer, retreat to the opposite extreme of grovelling. “I know I’m just a pathetic newbie loser, but…”. This is distracting and unhelpful. It’s especially annoying when it’s coupled with vagueness about the actual problem. Don’t waste your time, or ours, on crude primate politics. Instead, present the background facts and your question as clearly as you can. That is a better way to position yourself than by grovelling. Sometimes Web forums have separate places for newbie questions. If you feel you do have a newbie question, just go there. But don’t grovel there either. Describe the problem’s symptoms, not your guesses It’s not useful to tell hackers what you think is causing your problem. (If your diagnostic theories were such hot stuff, would you be consulting others for help?) So, make sure you’re telling them the raw symptoms of what goes wrong, rather than your interpretations and theories. Let them do the interpretation and diagnosis. If you feel it’s important to state your guess, clearly label it as such and describe why that answer isn’t working for you. Stupid:I’m getting back-to-back SIG11 errors on kernel compiles, and suspect a hairline crack on one of the motherboard traces. What’s the best way to check for those? Smart:My home-built K6/233 on an FIC-PA2007 motherboard (VIA Apollo VP2 chipset) with 256MB Corsair PC133 SDRAM starts getting frequent SIG11 errors about 20 minutes after power-on during the course of kernel compiles, but never in the first 20 minutes. Rebooting doesn’t restart the clock, but powering down overnight does. Swapping out all RAM didn’t help. The relevant part of a typical compile session log follows. Since the preceding point seems to be a tough one for many people to grasp, here’s a phrase to remind you: “All diagnosticians are from Missouri.” That US state’s official motto is “Show me” (earned in 1899, when Congressman Willard D. Vandiver said “I come from a country that raises corn and cotton and cockleburs and Democrats, and frothy eloquence neither convinces nor satisfies me. I’m from Missouri. You’ve got to show me.”) In diagnosticians’ case, it’s not a matter of skepticism, but rather a literal, functional need to see whatever is as close as possible to the same raw evidence that you see, rather than your surmises and summaries. Show us. Describe your problem’s symptoms in chronological order The clues most useful in figuring out something that went wrong often lie in the events immediately prior. So, your account should describe precisely what you did, and what the machine and software did, leading up to the blowup. In the case of command-line processes, having a session log (e.g., using the script utility) and quoting the relevant twenty or so lines is very useful. If the program that blew up on you has diagnostic options (such as -v for verbose), try to select options that will add useful debugging information to the transcript. Remember that more is not necessarily better; try to choose a debug level that will inform rather than drowning the reader in junk. If your account ends up being long (more than about four paragraphs), it might be useful to succinctly state the problem up top, then follow with the chronological tale. That way, hackers will know what to watch for in reading your account. Describe the goal, not the step If you are trying to find out how to do something (as opposed to reporting a bug), begin by describing the goal. Only then describe the particular step towards it that you are blocked on. Often, people who need technical help have a high-level goal in mind and get stuck on what they think is one particular path towards the goal. They come for help with the step, but don’t realize that the path is wrong. It can take substantial effort to get past this. Stupid:How do I get the color-picker on the FooDraw program to take a hexadecimal RGB value? Smart:I’m trying to replace the color table on an image with values of my choosing. Right now the only way I can see to do this is by editing each table slot, but I can’t get FooDraw’s color picker to take a hexadecimal RGB value. The second version of the question is smart. It allows an answer that suggests a tool better suited to the task. Don’t ask people to reply by private e-mail Hackers believe solving problems should be a public, transparent process during which a first try at an answer can and should be corrected if someone more knowledgeable notices that it is incomplete or incorrect. Also, helpers get some of their reward for being respondents from being seen to be competent and knowledgeable by their peers. When you ask for a private reply, you are disrupting both the process and the reward. Don’t do this. It’s the respondent’s choice whether to reply privately — and if he or she does, it’s usually because he or she thinks the question is too ill-formed or obvious to be interesting to others. There is one limited exception to this rule. If you think the question is such that you are likely to get many answers that are all closely similar, then the magic words are “e-mail me and I’ll summarize the answers for the group”. It is courteous to try and save the mailing list or newsgroup a flood of substantially identical postings — but you have to keep the promise to summarize. Be explicit about your question Open-ended questions tend to be perceived as open-ended time sinks. Those people most likely to be able to give you a useful answer are also the busiest people (if only because they take on the most work themselves). People like that are allergic to open-ended time sinks, thus they tend to be allergic to open-ended questions. You are more likely to get a useful response if you are explicit about what you want respondents to do (provide pointers, send code, check your patch, whatever). This will focus their effort and implicitly put an upper bound on the time and energy a respondent must allocate to helping you. This is good. To understand the world the experts live in, think of expertise as an abundant resource and time to respond as a scarce one. The less of a time commitment you implicitly ask for, the more likely you are to get an answer from someone really good and really busy. So it is useful to frame your question to minimize the time commitment required for an expert to field it — but this is often not the same thing as simplifying the question. Thus, for example, “Would you give me a pointer to a good explanation of X?” is usually a smarter question than “Would you explain X, please?”. If you have some malfunctioning code, it is usually smarter to ask for someone to explain what’s wrong with it than it is to ask someone to fix it. When asking about code Don’t ask others to debug your broken code without giving a hint what sort of problem they should be searching for. Posting a few hundred lines of code, saying “it doesn’t work”, will get you ignored. Posting a dozen lines of code, saying “after line 7 I was expecting to see , but occurred instead” is much more likely to get you a response. The most effective way to be precise about a code problem is to provide a minimal bug-demonstrating test case. What’s a minimal test case? It’s an illustration of the problem; just enough code to exhibit the undesirable behavior and no more. How do you make a minimal test case? If you know what line or section of code is producing the problematic behavior, make a copy of it and add just enough supporting code to produce a complete example (i.e. enough that the source is acceptable to the compiler/interpreter/whatever application processes it). If you can’t narrow it down to a particular section, make a copy of the source and start removing chunks that don’t affect the problematic behavior. The smaller your minimal test case is, the better (see the section called “Volume is not precision”). Generating a really small minimal test case will not always be possible, but trying to is good discipline. It may help you learn what you need to solve the problem on your own — and even when it doesn’t, hackers like to see that you have tried. It will make them more cooperative. If you simply want a code review, say as much up front, and be sure to mention what areas you think might particularly need review and why. Don’t post homework questions Hackers are good at spotting homework questions; most of us have done them ourselves. Those questions are for you to work out, so that you will learn from the experience. It is OK to ask for hints, but not for entire solutions. If you suspect you have been passed a homework question, but can’t solve it anyway, try asking in a user group forum or (as a last resort) in a “user” list/forum of a project. While the hackers will spot it, some of the advanced users may at least give you a hint. Prune pointless queries Resist the temptation to close your request for help with semantically-null questions like “Can anyone help me?” or “Is there an answer?” First: if you’ve written your problem description halfway competently, such tacked-on questions are at best superfluous. Second: because they are superfluous, hackers find them annoying — and are likely to return logically impeccable but dismissive answers like “Yes, you can be helped” and “No, there is no help for you.” In general, asking yes-or-no questions is a good thing to avoid unless you want a yes-or-no answer. Don’t flag your question as “Urgent”, even if it is for you That’s your problem, not ours. Claiming urgency is very likely to be counter-productive: most hackers will simply delete such messages as rude and selfish attempts to elicit immediate and special attention. Furthermore, the word ‘Urgent’ (and other similar attempts to grab attention in the subject line) often triggers spam filters - your intended recipients might never see it at all! There is one semi-exception. It can be worth mentioning if you’re using the program in some high-profile place, one that the hackers will get excited about; in such a case, if you’re under time pressure, and you say so politely, people may get interested enough to answer faster. This is a very risky thing to do, however, because the hackers’ metric for what is exciting probably differs from yours. Posting from the International Space Station would qualify, for example, but posting on behalf of a feel-good charitable or political cause would almost certainly not. In fact, posting “Urgent: Help me save the fuzzy baby seals!” will reliably get you shunned or flamed even by hackers who think fuzzy baby seals are important. If you find this mysterious, re-read the rest of this how-to repeatedly until you understand it before posting anything at all. Courtesy never hurts, and sometimes helps Be courteous. Use “Please” and “Thanks for your attention” or “Thanks for your consideration”. Make it clear you appreciate the time people spend helping you for free. To be honest, this isn’t as important as (and cannot substitute for) being grammatical, clear, precise and descriptive, avoiding proprietary formats etc.; hackers in general would rather get somewhat brusque but technically sharp bug reports than polite vagueness. (If this puzzles you, remember that we value a question by what it teaches us.) However, if you’ve got your technical ducks in a row, politeness does increase your chances of getting a useful answer. (We must note that the only serious objection we’ve received from veteran hackers to this HOWTO is with respect to our previous recommendation to use “Thanks in advance”. Some hackers feel this connotes an intention not to thank anybody afterwards. Our recommendation is to either say “Thanks in advance” first and thank respondents afterwards, or express courtesy in a different way, such as by saying “Thanks for your attention” or “Thanks for your consideration”.) Follow up with a brief note on the solution Send a note after the problem has been solved to all who helped you; let them know how it came out and thank them again for their help. If the problem attracted general interest in a mailing list or newsgroup, it’s appropriate to post the followup there. Optimally, the reply should be to the thread started by the original question posting, and should have ‘FIXED’, ‘RESOLVED’ or an equally obvious tag in the subject line. On mailing lists with fast turnaround, a potential respondent who sees a thread about “Problem X” ending with “Problem X - FIXED” knows not to waste his/her time even reading the thread (unless (s)he personally finds Problem X interesting) and can therefore use that time solving a different problem. Your followup doesn’t have to be long and involved; a simple “Howdy — it was a failed network cable! Thanks, everyone. - Bill” would be better than nothing. In fact, a short and sweet summary is better than a long dissertation unless the solution has real technical depth. Say what action solved the problem, but you need not replay the whole troubleshooting sequence. For problems with some depth, it is appropriate to post a summary of the troubleshooting history. Describe your final problem statement. Describe what worked as a solution, and indicate avoidable blind alleys after that. The blind alleys should come after the correct solution and other summary material, rather than turning the follow-up into a detective story. Name the names of people who helped you; you’ll make friends that way. Besides being courteous and informative, this sort of followup will help others searching the archive of the mailing-list/newsgroup/forum to know exactly which solution helped you and thus may also help them. Last, and not least, this sort of followup helps everybody who assisted feel a satisfying sense of closure about the problem. If you are not a techie or hacker yourself, trust us that this feeling is very important to the gurus and experts you tapped for help. Problem narratives that trail off into unresolved nothingness are frustrating things; hackers itch to see them resolved. The goodwill that scratching that itch earns you will be very, very helpful to you next time you need to pose a question. Consider how you might be able to prevent others from having the same problem in the future. Ask yourself if a documentation or FAQ patch would help, and if the answer is yes send that patch to the maintainer. Among hackers, this sort of good followup behavior is actually more important than conventional politeness. It’s how you get a reputation for playing well with others, which can be a very valuable asset. How To Interpret Answers RTFM and STFW: How To Tell You’ve Seriously Screwed Up There is an ancient and hallowed tradition: if you get a reply that reads “RTFM”, the person who sent it thinks you should have Read The Fucking Manual. He or she is almost certainly right. Go read it. RTFM has a younger relative. If you get a reply that reads “STFW”, the person who sent it thinks you should have Searched The Fucking Web. He or she is almost certainly right. Go search it. (The milder version of this is when you are told “Google is your friend!”) In Web forums, you may also be told to search the forum archives. In fact, someone may even be so kind as to provide a pointer to the previous thread where this problem was solved. But do not rely on this consideration; do your archive-searching before asking. Often, the person telling you to do a search has the manual or the web page with the information you need open, and is looking at it as he or she types. These replies mean that the responder thinks (a) the information you need is easy to find, and (b) you will learn more if you seek out the information than if you have it spoon-fed to you. You shouldn’t be offended by this; by hacker standards, your respondent is showing you a rough kind of respect simply by not ignoring you. You should instead be thankful for this grandmotherly kindness. If you don’t understand… If you don’t understand the answer, do not immediately bounce back a demand for clarification. Use the same tools that you used to try and answer your original question (manuals, FAQs, the Web, skilled friends) to understand the answer. Then, if you still need to ask for clarification, exhibit what you have learned. For example, suppose I tell you: “It sounds like you’ve got a stuck zentry; you’ll need to clear it.” Then: here’s a bad followup question: “What’s a zentry?” Here’s a good followup question: “OK, I read the man page and zentries are only mentioned under the -z and -p switches. Neither of them says anything about clearing zentries. Is it one of these or am I missing something here?” Dealing with rudeness Much of what looks like rudeness in hacker circles is not intended to give offense. Rather, it’s the product of the direct, cut-through-the-bullshit communications style that is natural to people who are more concerned about solving problems than making others feel warm and fuzzy. When you perceive rudeness, try to react calmly. If someone is really acting out, it is very likely a senior person on the list or newsgroup or forum will call him or her on it. If that doesn’t happen and you lose your temper, it is likely that the person you lose it at was behaving within the hacker community’s norms and you will be considered at fault. This will hurt your chances of getting the information or help you want. On the other hand, you will occasionally run across rudeness and posturing that is quite gratuitous. The flip-side of the above is that it is acceptable form to slam real offenders quite hard, dissecting their misbehavior with a sharp verbal scalpel. Be very, very sure of your ground before you try this, however. The line between correcting an incivility and starting a pointless flamewar is thin enough that hackers themselves not infrequently blunder across it; if you are a newbie or an outsider, your chances of avoiding such a blunder are low. If you’re after information rather than entertainment, it’s better to keep your fingers off the keyboard than to risk this. (Some people assert that many hackers have a mild form of autism or Asperger’s Syndrome, and are actually missing some of the brain circuitry that lubricates “normal” human social interaction. This may or may not be true. If you are not a hacker yourself, it may help you cope with our eccentricities if you think of us as being brain-damaged. Go right ahead. We won’t care; we like being whatever it is we are, and generally have a healthy skepticism about clinical labels.) Jeff Bigler’s observations about tact filters are also relevant and worth reading. In the next section, we’ll talk about a different issue; the kind of “rudeness” you’ll see when you misbehave. On Not Reacting Like A Loser Odds are you’ll screw up a few times on hacker community forums — in ways detailed in this article, or similar. And you’ll be told exactly how you screwed up, possibly with colourful asides. In public. When this happens, the worst thing you can do is whine about the experience, claim to have been verbally assaulted, demand apologies, scream, hold your breath, threaten lawsuits, complain to people’s employers, leave the toilet seat up, etc. Instead, here’s what you do: Get over it. It’s normal. In fact, it’s healthy and appropriate. Community standards do not maintain themselves: They’re maintained by people actively applying them, visibly, in public. Don’t whine that all criticism should have been conveyed via private e-mail: That’s not how it works. Nor is it useful to insist you’ve been personally insulted when someone comments that one of your claims was wrong, or that his views differ. Those are loser attitudes. There have been hacker forums where, out of some misguided sense of hyper-courtesy, participants are banned from posting any fault-finding with another’s posts, and told “Don’t say anything if you’re unwilling to help the user.” The resulting departure of clueful participants to elsewhere causes them to descend into meaningless babble and become useless as technical forums. Exaggeratedly “friendly” (in that fashion) or useful: Pick one. Remember: When that hacker tells you that you’ve screwed up, and (no matter how gruffly) tells you not to do it again, he’s acting out of concern for (1) you and (2) his community. It would be much easier for him to ignore you and filter you out of his life. If you can’t manage to be grateful, at least have a little dignity, don’t whine, and don’t expect to be treated like a fragile doll just because you’re a newcomer with a theatrically hypersensitive soul and delusions of entitlement. Sometimes people will attack you personally, flame without an apparent reason, etc., even if you don’t screw up (or have only screwed up in their imagination). In this case, complaining is the way to really screw up. These flamers are either lamers who don’t have a clue but believe themselves to be experts, or would-be psychologists testing whether you’ll screw up. The other readers either ignore them, or find ways to deal with them on their own. The flamers’ behavior creates problems for themselves, which don’t have to concern you. Don’t let yourself be drawn into a flamewar, either. Most flames are best ignored — after you’ve checked whether they are really flames, not pointers to the ways in which you have screwed up, and not cleverly ciphered answers to your real question (this happens as well). Questions Not To Ask Here are some classic stupid questions, and what hackers are thinking when they don’t answer them. Q: Where can I find program or resource X?Q: How can I use X to do Y?Q: How can I configure my shell prompt?Q: Can I convert an AcmeCorp document into a TeX file using the Bass-o-matic file converter?Q: My {program, configuration, SQL statement} doesn’t workQ: I’m having problems with my Windows machine. Can you help?Q: My program doesn’t work. I think system facility X is broken.Q: I’m having problems installing Linux or X. Can you help?Q: How can I crack root/steal channel-ops privileges/read someone’s e-mail?Q: Where can I find program or resource X? A: The same place I’d find it, fool — at the other end of a web search. Ghod, doesn’t everybody know how to use Google yet? Q: How can I use X to do Y? A: If what you want is to do Y, you should ask that question without pre-supposing the use of a method that may not be appropriate. Questions of this form often indicate a person who is not merely ignorant about X, but confused about what problem Y they are solving and too fixated on the details of their particular situation. It is generally best to ignore such people until they define their problem better. Q: How can I configure my shell prompt? A: If you’re smart enough to ask this question, you’re smart enough to RTFM and find out yourself. Q: Can I convert an AcmeCorp document into a TeX file using the Bass-o-matic file converter? A: Try it and see. If you did that, you’d (a) learn the answer, and (b) stop wasting my time. Q: My {program, configuration, SQL statement} doesn’t work A: This is not a question, and I’m not interested in playing Twenty Questions to pry your actual question out of you — I have better things to do. On seeing something like this, my reaction is normally of one of the following: do you have anything else to add to that? oh, that’s too bad, I hope you get it fixed. and this has exactly what to do with me? Q: I’m having problems with my Windows machine. Can you help? A: Yes. Throw out that Microsoft trash and install an open-source operating system like Linux or BSD. Note: you can ask questions related to Windows machines if they are about a program that does have an official Windows build, or interacts with Windows machines (i.e., Samba). Just don’t be surprised by the reply that the problem is with Windows and not the program, because Windows is so broken in general that this is very often the case. Q: My program doesn’t work. I think system facility X is broken. A: While it is possible that you are the first person to notice an obvious deficiency in system calls and libraries heavily used by hundreds or thousands of people, it is rather more likely that you are utterly clueless. Extraordinary claims require extraordinary evidence; when you make a claim like this one, you must back it up with clear and exhaustive documentation of the failure case. Q: I’m having problems installing Linux or X. Can you help? A: No. I’d need hands-on access to your machine to troubleshoot this. Go ask your local Linux user group for hands-on help. (You can find a list of user groups here.) Note: questions about installing Linux may be appropriate if you’re on a forum or mailing list about a particular distribution, and the problem is with that distro; or on local user groups forums. In this case, be sure to describe the exact details of the failure. But do careful searching first, with “linux” and all suspicious pieces of hardware. Q: How can I crack root/steal channel-ops privileges/read someone’s e-mail? A: You’re a lowlife for wanting to do such things and a moron for asking a hacker to help you. Good and Bad Questions Finally, I’m going to illustrate how to ask questions in a smart way by example; pairs of questions about the same problem, one asked in a stupid way and one in a smart way. Stupid: Where can I find out stuff about the Foonly Flurbamatic?This question just begs for “STFW” as a reply. Smart: I used Google to try to find “Foonly Flurbamatic 2600” on the Web, but I got no useful hits. Can I get a pointer to programming information on this device?This one has already STFWed, and sounds like there might be a real problem. Stupid: I can’t get the code from project foo to compile. Why is it broken?The querent assumes that somebody else screwed up. Arrogant git… Smart: The code from project foo doesn’t compile under Nulix version 6.2. I’ve read the FAQ, but it doesn’t have anything in it about Nulix-related problems. Here’s a transcript of my compilation attempt; is it something I did?The querent has specified the environment, read the FAQ, is showing the error, and is not assuming his problems are someone else’s fault. This one might be worth some attention. Stupid: I’m having problems with my motherboard. Can anybody help?J. Random Hacker’s response to this is likely to be “Right. Do you need burping and diapering, too?” followed by a punch of the delete key. Smart: I tried X, Y, and Z on the S2464 motherboard. When that didn’t work, I tried A, B, and C. Note the curious symptom when I tried C. Obviously the florbish is grommicking, but the results aren’t what one might expect. What are the usual causes of grommicking on Athlon MP motherboards? Anybody got ideas for more tests I can run to pin down the problem?This person, on the other hand, seems worthy of an answer. He/she has exhibited problem-solving intelligence rather than passively waiting for an answer to drop from on high. In the last question, notice the subtle but important difference between demanding “Give me an answer” and “Please help me figure out what additional diagnostics I can run to achieve enlightenment.” In fact, the form of that last question is closely based on a real incident that happened in August 2001 on the linux-kernel mailing list (lkml). I (Eric) was the one asking the question that time. I was seeing mysterious lockups on a Tyan S2462 motherboard. The list members supplied the critical information I needed to solve them. By asking the question in the way I did, I gave people something to chew on; I made it easy and attractive for them to get involved. I demonstrated respect for my peers’ ability and invited them to consult with me as a peer. I also demonstrated respect for the value of their time by telling them the blind alleys I had already run down. Afterwards, when I thanked everyone and remarked how well the process had worked, an lkml member observed that he thought it had worked not because I’m a “name” on that list, but because I asked the question in the proper form. Hackers are in some ways a very ruthless meritocracy; I’m certain he was right, and that if I had behaved like a sponge I would have been flamed or ignored no matter who I was. His suggestion that I write up the whole incident as instruction to others led directly to the composition of this guide. If You Can’t Get An Answer If you can’t get an answer, please don’t take it personally that we don’t feel we can help you. Sometimes the members of the asked group may simply not know the answer. No response is not the same as being ignored, though admittedly it’s hard to spot the difference from outside. In general, simply re-posting your question is a bad idea. This will be seen as pointlessly annoying. Have patience: the person with your answer may be in a different time-zone and asleep. Or it may be that your question wasn’t well-formed to begin with. There are other sources of help you can go to, often sources better adapted to a novice’s needs. There are many online and local user groups who are enthusiasts about the software, even though they may never have written any software themselves. These groups often form so that people can help each other and help new users. There are also plenty of commercial companies you can contract with for help, both large and small. Don’t be dismayed at the idea of having to pay for a bit of help! After all, if your car engine blows a head gasket, chances are you would take it to a repair shop and pay to get it fixed. Even if the software didn’t cost you anything, you can’t expect that support to always come for free. For popular software like Linux, there are at least 10,000 users per developer. It’s just not possible for one person to handle the support calls from over 10,000 users. Remember that even if you have to pay for support, you are still paying much less than if you had to buy the software as well (and support for closed-source software is usually more expensive and less competent than support for open-source software). How To Answer Questions in a Helpful Way Be gentle. Problem-related stress can make people seem rude or stupid even when they’re not. Reply to a first offender off-line. There is no need of public humiliation for someone who may have made an honest mistake. A real newbie may not know how to search archives or where the FAQ is stored or posted. If you don’t know for sure, say so! A wrong but authoritative-sounding answer is worse than none at all. Don’t point anyone down a wrong path simply because it’s fun to sound like an expert. Be humble and honest; set a good example for both the querent and your peers. If you can’t help, don’t hinder. Don’t make jokes about procedures that could trash the user’s setup — the poor sap might interpret these as instructions. Ask probing questions to elicit more details. If you’re good at this, the querent will learn something — and so might you. Try to turn the bad question into a good one; remember we were all newbies once. While muttering RTFM is sometimes justified when replying to someone who is just a lazy slob, a pointer to documentation (even if it’s just a suggestion to google for a key phrase) is better. If you’re going to answer the question at all, give good value. Don’t suggest kludgy workarounds when somebody is using the wrong tool or approach. Suggest good tools. Reframe the question. Answer the actual question! If the querent has been so thorough as to do his or her research and has included in the query that X, Y, Z, A, B, and C have already been tried without good result, it is supremely unhelpful to respond with “Try A or B,” or with a link to something that only says, “Try X, Y, Z, A, B, or C.”. Help your community learn from the question. When you field a good question, ask yourself “How would the relevant documentation or FAQ have to change so that nobody has to answer this again?” Then send a patch to the document maintainer. If you did research to answer the question, demonstrate your skills rather than writing as though you pulled the answer out of your butt. Answering one good question is like feeding a hungry person one meal, but teaching them research skills by example is showing them how to grow food for a lifetime. Related Resources If you need instruction in the basics of how personal computers, Unix, and the Internet work, see The Unix and Internet Fundamentals HOWTO. When you release software or write patches for software, try to follow the guidelines in the Software Release Practice HOWTO. Acknowledgements Evelyn Mitchell contributed some example stupid questions and inspired the “How To Give A Good Answer” section. Mikhail Ramendik contributed some particularly valuable suggestions for improvements.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[]},{"title":"如何有效地报告 Bug","date":"2017-01-20T12:23:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/how-to-report-bugs-effectively/","text":"作者：Simon Tatham 专业的自由软件程序员翻译：Dasn 引言为公众写过软件的人，大概都收到过很拙劣的bug（计算机程序代码中的错误或程序运行时的瑕疵——译者注）报告，例如： 在报告中说“不好用”； 所报告内容毫无意义； 在报告中用户没有提供足够的信息； 在报告中提供了错误信息； 所报告的问题是由于用户的过失而产生的； 所报告的问题是由于其他程序的错误而产生的； 所报告的问题是由于网络错误而产生的； 这便是为什么“技术支持”被认为是一件可怕的工作，因为有拙劣的bug报告需要处理。然而并不是所有的bug报告都令人生厌：我在业余时间维护自由软件，有时我会收到非常清晰、有帮助并且“有内容”的bug报告。在这里我会尽力阐明如何写一个好的bug报告。我非常希望每一个人在报告bug之前都读一下这篇短文，当然我也希望用户在给我报告bug之前已经读过这篇文章。 简单地说，报告bug的目的是为了让程序员看到程序的错误。您可以亲自示范，也可以给出能导致程序出错的、详尽的操作步骤。如果程序出错了，程序员会收集额外的信息直到找到错误的原因；如果程序没有出错，那么他们会请您继续关注这个问题，收集相关的信息。 在bug报告里，要设法搞清什么是事实（例如：“我在电脑旁”和“XX出现了”）什么是推测（例如：“我想问题可能是出在……”）。如果愿意的话，您可以省去推测，但是千万别省略事实。 当您报告bug的时候（既然您已经这么做了），一定是希望bug得到及时修正。所以此时针对程序员的任何过激或亵渎的言语（甚至谩骂）都是与事无补的——因为这可能是程序员的错误，也有可能是您的错误，也许您有权对他们发火，但是如果您能多提供一些有用的信息（而不是激愤之词）或许bug会被更快的修正。除此以外，请记住：如果是免费软件，作者提供给我们已经是出于好心，所以要是太多的人对他们无礼，他们可能就要“收起”这份好心了。 ##“程序不好用” 程序员不是弱智：如果程序一点都不好用，他们不可能不知道。他们不知道一定是因为程序在他们看来工作得很正常。所以，或者是您作过一些与他们不同的操作，或者是您的环境与他们不同。他们需要信息，报告bug也是为了提供信息。信息总是越多越好。 许多程序，特别是自由软件，会公布一个“已知bug列表”。如果您找到的bug在列表里已经有了，那就不必再报告了，但是如果您认为自己掌握的信息比列表中的丰富，那无论如何也要与程序员联系。您提供的信息可能会使他们更简单地修复bug。 本文中提到的都是一些指导方针，没有哪一条是必须恪守的准则。不同的程序员会喜欢不同形式的bug报告。如果程序附带了一套报告bug的准则，一定要读。如果它与本文中提到的规则相抵触，那么请以它为准。 如果您不是报告bug，而是寻求帮助，您应该说明您曾经到哪里找过答案，（例如：我看了第四章和第五章的第二节，但我找不到解决的办法。）这会使程序员了解用户喜欢到哪里去找答案，从而使程序员把帮助文档做得更容易使用。 ##“演示给我看” 报告bug的最好的方法之一是“演示”给程序员看。让程序员站在电脑前，运行他们的程序，指出程序的错误。让他们看着您启动电脑、运行程序、如何进行操作以及程序对您的输入有何反应。 他们对自己写的软件了如指掌，他们知道哪些地方不会出问题，而哪些地方最可能出问题。他们本能地知道应该注意什么。在程序真的出错之前，他们可能已经注意到某些地方不对劲，这些都会给他们一些线索。他们会观察程序测试中的每一个细节，并且选出他们认为有用的信息。 这些可能还不够。也许他们觉得还需要更多的信息，会请您重复刚才的操作。他们可能在这期间需要与您交流一下，以便在他们需要的时候让bug重新出现。他们可能会改变一些操作，看看这个错误的产生是个别问题还是相关的一类问题。如果您不走运，他们可能需要坐下来，拿出一堆开发工具，花上几个小时来好好地研究一下。但是最重要的是在程序出错的时候让程序员在电脑旁。一旦他们看到了问题，他们通常会找到原因并开始试着修改。 ##“告诉我该怎么做” 如今是网络时代，是信息交流的时代。我可以点一下鼠标把自己的程序送到俄罗斯的某个朋友那里，当然他也可以用同样简单的方法给我一些建议。但是如果我的程序出了什么问题，我不可能在他旁边。“演示”是很好的办法，但是常常做不到。 如果您必须报告bug，而此时程序员又不在您身边，那么您就要想办法让bug重现在他们面前。当他们亲眼看到错误时，就能够进行处理了。 确切地告诉程序员您做了些什么。如果是一个图形界面程序，告诉他们您按了哪个按钮，依照什么顺序按的。如果是一个命令行程序，精确的告诉他们您键入了什么命令。您应该尽可能详细地提供您所键入的命令和程序的反应。 把您能想到的所有的输入方式都告诉程序员，如果程序要读取一个文件，您可能需要发一个文件的拷贝给他们。如果程序需要通过网络与另一台电脑通讯，您或许不能把那台电脑复制过去，但至少可以说一下电脑的类型和安装了哪些软件（如果可以的话）。 ##“哪儿出错了？在我看来一切正常哦！” 如果您给了程序员一长串输入和指令，他们执行以后没有出现错误，那是因为您没有给他们足够的信息，可能错误不是在每台计算机上都出现，您的系统可能和他们的在某些地方不一样。有时候程序的行为可能和您预想的不一样，这也许是误会，但是您会认为程序出错了，程序员却认为这是对的。 同样也要描述发生了什么。精确的描述您看到了什么。告诉他们为什么您觉得自己所看到的是错误的，最好再告诉他们，您认为自己应该看到什么。如果您只是说：“程序出错了”，那您很可能漏掉了非常重要的信息。 如果您看到了错误消息，一定要仔细、准确的告诉程序员，这确实很重要。在这种情况下，程序员只要修正错误，而不用去找错误。他们需要知道是什么出问题了，系统所报的错误消息正好帮助了他们。如果您没有更好的方法记住这些消息，就把它们写下来。只报告“程序出了一个错”是毫无意义的，除非您把错误消息一块报上来。 特殊情况下，如果有错误消息号，一定要把这些号码告诉程序员。不要以为您看不出任何意义，它就没有意义。错误消息号包含了能被程序员读懂的各种信息，并且很有可能包含重要的线索。给错误消息编号是因为用语言描述计算机错误常常令人费解。用这种方式告诉您错误的所在是一个最好的办法。 在这种情形下，程序员的排错工作会十分高效。他们不知道发生了什么，也不可能到现场去观察，所以他们一直在搜寻有价值的线索。错误消息、错误消息号以及一些莫名其妙的延迟，都是很重要的线索，就像办案时的指纹一样重要，保存好。 如果您使用UNIX系统，程序可能会产生一个内核输出（coredump）。内核输出是特别有用的线索来源，别扔了它们。另一方面，大多数程序员不喜欢收到含有大量内核输出文件的EMAIL，所以在发邮件之前最好先问一下。还有一点要注意：内核输出文件记录了完整的程序状态，也就是说任何秘密（可能当时程序正在处理一些私人信息或秘密数据）都可能包含在内核输出文件里。 ##“出了问题之后，我做了……” 当一个错误或bug发生的时候，您可能会做许多事情。但是大多数人会使事情变的更糟。我的一个朋友在学校里误删了她所有的Word文件，在找人帮忙之前她重装了Word，又运行了一遍碎片整理程序，这些操作对于恢复文件是毫无益处的，因为这些操作搞乱了磁盘的文件区块。恐怕在这个世界上没有一种反删除软件能恢复她的文件了。如果她不做任何操作，或许还有一线希望。 这种用户仿佛一只被逼到墙角的鼬（黄鼠狼、紫貂一类的动物——译者注）：背靠墙壁，面对死亡的降临奋起反扑，疯狂攻击。他们认为做点什么总比什么都不做强。然而这些在处理计算机软件问题时并不适用。 不要做鼬，做一只羚羊。当一只羚羊面对料想不到的情况或受到惊吓时，它会一动不动，是为了不吸引任何注意，与此同时也在思考解决问题的最好办法（如果羚羊有一条技术支持热线，此时占线。）。然后，一旦它找到了最安全的行动方案，它便去做。 当程序出毛病的时候，立刻停止正在做的任何操作。不要按任何健。仔细地看一下屏幕，注意那些不正常的地方，记住它或者写下来。然后慎重地点击“确定” 或“取消”，选择一个最安全的。学着养成一种条件反射——一旦电脑出了问题，先不要动。要想摆脱这个问题，关掉受影响的程序或者重新启动计算机都不好，一个解决问题的好办法是让问题再次产生。程序员们喜欢可以被重现的问题，快乐的程序员可以更快而且更有效率的修复bug。 ##“我想粒子的跃迁与错误的极化有关” 并不只是非专业的用户才会写出拙劣的bug报告，我见过一些非常差的bug报告出自程序员之手，有些还是非常优秀的程序员。 有一次我与另一个程序员一起工作，他一直在找代码中的bug，他常常遇到一个bug，但是不会解决，于是就叫我帮忙。“出什么毛病了？”我问。而他的回答却总是一些关于bug的意见。如果他的观点正确，那的确是一件好事。这意味着他已经完成了工作的一半，并且我们可以一起完成另一半工作。这是有效率并有用的。 但事实上他常常是错的。这就会使我们花上半个小时在原本正确的代码里来回寻找错误，而实际上问题出在别的地方。我敢肯定他不会对医生这么做。“大夫，我得了Hydroyoyodyne（真是怪病——译者），给我开个方子”，人们知道不该对一位医生说这些。您描述一下症状，哪个地方不舒服，哪里疼、起皮疹、发烧……让医生诊断您得了什么病，应该怎样治疗。否则医生会把您当做疑心病或精神病患者打发了，这似乎没什么不对。 做程序员也是一样。即便您自己的“诊断”有时真的有帮助，也要只说“症状”。“诊断”是可说可不说的，但是“症状”一定要说。同样，在bug报告里面附上一份针对bug而做出修改的源代码是有用处的，但它并不能替代bug报告本身。 如果程序员向您询问额外的信息，千万别应付。曾经有一个人向我报告bug，我让他试一个命令，我知道这个命令不好用，但我是要看看程序会返回一个什么错误（这是很重要的线索）。但是这位老兄根本就没试，他在回复中说“那肯定不好用”，于是我又花了好些时间才说服他试了一下那个命令。 用户多动动脑筋对程序员的工作是有帮助的。即使您的推断是错误的，程序员也应该感谢您，至少您想去帮助他们，使他们的工作变的更简单。不过千万别忘了报告“症状”，否则只会使事情变得更糟。 ##“真是奇怪，刚才还不好用，怎么现在又好了？” “间歇性错误”着实让程序员发愁。相比之下，进行一系列简单的操作便能导致错误发生的问题是简单的。程序员可以在一个便于观察的条件下重复那些操作，观察每一个细节。太多的问题在这种情况下不能解决，例如：程序每星期出一次错，或者偶然出一次错，或者在程序员面前从不出错（程序员一离开就出错。——译者）。当然还有就是程序的截止日期到了，那肯定要出错。 大多数“间歇性错误”并不是真正的“间歇”。其中的大多数错误与某些地方是有联系的。有一些错误可能是内存泄漏产生的，有一些可能是别的程序在不恰当的时候修改某个重要文件造成的，还有一些可能发生在每一个小时的前半个小时中（我确实遇到过这种事情）。 同样，如果您能使bug重现，而程序员不能，那很有可能是他们的计算机和您的计算机在某些地方是不同的，这种不同引起了问题。我曾写过一个程序，它的窗口可以蜷缩成一个小球呆在屏幕的左上角，它在别的计算机上只能在 800x600 的解析度工作，但是在我的机器上却可以在 1024x768 下工作。 程序员想要了解任何与您发现的问题相关的事情。有可能的话您到另一台机器上试试，多试几次，两次，三次，看看问题是不是经常发生。如果问题出现在您进行了一系列操作之后，不是您想让它出现它就会出现，这就有可能是长时间的运行或处理大文件所导致的错误。程序崩溃的时候，您要尽可能的记住您都做了些什么，并且如果您看到任何图形,也别忘了提一下。您提供的任何事情都是有帮助的。即使只是概括性的描述（例如：当后台有EMACS运行时，程序常常出错），这虽然不能提供导致问题的直接线索，但是可能帮助程序员重现问题。 最重要的是：程序员想要确定他们正在处理的是一个真正的“间歇性错误”呢，还是一个在另一类特定的计算机上才出现的错误。他们想知道有关您计算机的许多细节，以便了解您的机器与他们的有什么不同。有许多细节都依仗特定的程序，但是有一件东西您一定要提供——版本号。程序的版本、操作系统的版本以及与问题有关的程序的版本。 ##“我把磁盘装进了 Windows……” 表意清楚在一份bug报告里是最基本的要求。如果程序员不知道您说的是什么意思，那您就跟没说一样。我收到的bug报告来自世界各地，有许多是来自非英语国家，他们通常为自己的英文不好而表示歉意。总的来说，这些用户发来的bug报告通常是清晰而且有用的。几乎所有不清晰的bug报告都是来自母语是英语的人，他们总是以为只要自己随便说说，程序员就能明白。 精确。如果做相同的事情有两种方法，请说明您用的是哪一种。例如：“我选择了‘载入’”，可能意味着“我用鼠标点击‘载入’”或“我按下了‘ALT+L’”，说清楚您用了哪种方法，有时候这也有关系。详细。信息宁多毋少！如果您说了很多，程序员可以略去一部分，可是如果您说的太少，他们就不得不回过头再去问您一些问题。有一次我收到了一份bug报告只有一句话，每一次我问他更多事情时，他每次的回复都是一句话，于是我花了几个星期的时间才得到了有用的信息。慎用代词。诸如“它”，“窗体”这些词，当它们指代不清晰的时候不要用。来看看这句话：“我运行了FooApp，它弹出一个警告窗口，我试着关掉它，它就崩溃了。”这种表述并不清晰，用户究竟关掉了哪个窗口？是警告窗口还是整个FooApp程序？您可以这样说，“我运行FooApp程序时弹出一个警告窗口，我试着关闭警告窗口，FooApp崩溃了。”这样虽然罗嗦点，但是很清晰不容易产生误解。 检查。重新读一遍您写的bug报告，您觉得它是否清晰？如果您列出了一系列能导致程序出错的操作，那么照着做一遍，看看您是不是漏写了一步。 小结 bug报告的首要目的是让程序员亲眼看到错误。如果您不能亲自做给他们看，给他们能使程序出错的详细的操作步骤。 如果首要目的不能达成，程序员不能看到程序出错。这就需要bug报告的第二个目的来描述程序的什么地方出毛病了。详细的描述每一件事情：您看到了什么，您想看到什么，把错误消息记下来，尤其是“错误消息号”。 当您的计算机做了什么您料想不到的事，不要动！在您平静下来之前什么都别做。不要做您认为不安全的事。 尽量试着自己“诊断”程序出错的原因（如果您认为自己可以的话）。即使做出了“诊断”，您仍然应该报告“症状”。 如果程序员需要，请准备好额外的信息。如果他们不需要，就不会问您要。他们不会故意为难自己。您手头上一定要有程序的版本号，它很可能是必需品。 表述清楚，确保您的意思不能被曲解。 总的来说，最重要的是要做到精确。程序员喜欢精确。 声明：我从没有真的看见过鼬和羚羊，我的比喻可能不恰当。 版权所有 Simon Tatham 1999 本文属于OPL（OpenContent License），请在复制和使用本文时自觉遵守OPL。 对本文的任何意见和批评请发送至： 英文版：anakin@pobox.com 中文版：dasn@users.sf.net How to Report Bugs Effectivelyby Simon Tatham, professional and free-software programmer [ English | Português | 简体中文 | Česky | Dansk | Deutsch | Español | Français | Magyar | Italiano | 日本語 | Nederlands | Polski | Русский | 繁體中文 ] Introduction Anybody who has written software for public use will probably have received at least one bad bug report. Reports that say nothing (“It doesn’t work!”); reports that make no sense; reports that don’t give enough information; reports that give wrong information. Reports of problems that turn out to be user error; reports of problems that turn out to be the fault of somebody else’s program; reports of problems that turn out to be network failures. There’s a reason why technical support is seen as a horrible job to be in, and that reason is bad bug reports. However, not all bug reports are unpleasant: I maintain free software, when I’m not earning my living, and sometimes I receive wonderfully clear, helpful, informative bug reports. In this essay I’ll try to state clearly what makes a good bug report. Ideally I would like everybody in the world to read this essay before reporting any bugs to anybody. Certainly I would like everybody who reports bugs to me to have read it. In a nutshell, the aim of a bug report is to enable the programmer to see the program failing in front of them. You can either show them in person, or give them careful and detailed instructions on how to make it fail. If they can make it fail, they will try to gather extra information until they know the cause. If they can’t make it fail, they will have to ask you to gather that information for them. In bug reports, try to make very clear what are actual facts (“I was at the computer and this happened”) and what are speculations (“I think the problem might be this”). Leave out speculations if you want to, but don’t leave out facts. When you report a bug, you are doing so because you want the bug fixed. There is no point in swearing at the programmer or being deliberately unhelpful: it may be their fault and your problem, and you might be right to be angry with them, but the bug will get fixed faster if you help them by supplying all the information they need. Remember also that if the program is free, then the author is providing it out of kindness, so if too many people are rude to them then they may stop feeling kind. “It doesn’t work.” Give the programmer some credit for basic intelligence: if the program really didn’t work at all, they would probably have noticed. Since they haven’t noticed, it must be working for them. Therefore, either you are doing something differently from them, or your environment is different from theirs. They need information; providing this information is the purpose of a bug report. More information is almost always better than less. Many programs, particularly free ones, publish their list of known bugs. If you can find a list of known bugs, it’s worth reading it to see if the bug you’ve just found is already known or not. If it’s already known, it probably isn’t worth reporting again, but if you think you have more information than the report in the bug list, you might want to contact the programmer anyway. They might be able to fix the bug more easily if you can give them information they didn’t already have. This essay is full of guidelines. None of them is an absolute rule. Particular programmers have particular ways they like bugs to be reported. If the program comes with its own set of bug-reporting guidelines, read them. If the guidelines that come with the program contradict the guidelines in this essay, follow the ones that come with the program! If you are not reporting a bug but just asking for help using the program, you should state where you have already looked for the answer to your question. (“I looked in chapter 4 and section 5.2 but couldn’t find anything that told me if this is possible.”) This will let the programmer know where people will expect to find the answer, so they can make the documentation easier to use. “Show me.” One of the very best ways you can report a bug is by showing it to the programmer. Stand them in front of your computer, fire up their software, and demonstrate the thing that goes wrong. Let them watch you start the machine, watch you run the software, watch how you interact with the software, and watch what the software does in response to your inputs. They know that software like the back of their hand. They know which parts they trust, and they know which parts are likely to have faults. They know intuitively what to watch for. By the time the software does something obviously wrong, they may well have already noticed something subtly wrong earlier which might give them a clue. They can observe everything the computer does during the test run, and they can pick out the important bits for themselves. This may not be enough. They may decide they need more information, and ask you to show them the same thing again. They may ask you to talk them through the procedure, so that they can reproduce the bug for themselves as many times as they want. They might try varying the procedure a few times, to see whether the problem occurs in only one case or in a family of related cases. If you’re unlucky, they may need to sit down for a couple of hours with a set of development tools and really start investigating. But the most important thing is to have the programmer looking at the computer when it goes wrong. Once they can see the problem happening, they can usually take it from there and start trying to fix it. “Show me how to show myself.” This is the era of the Internet. This is the era of worldwide communication. This is the era in which I can send my software to somebody in Russia at the touch of a button, and he can send me comments about it just as easily. But if he has a problem with my program, he can’t have me standing in front of it while it fails. “Show me” is good when you can, but often you can’t. If you have to report a bug to a programmer who can’t be present in person, the aim of the exercise is to enable them to reproduce the problem. You want the programmer to run their own copy of the program, do the same things to it, and make it fail in the same way. When they can see the problem happening in front of their eyes, then they can deal with it. So tell them exactly what you did. If it’s a graphical program, tell them which buttons you pressed and what order you pressed them in. If it’s a program you run by typing a command, show them precisely what command you typed. Wherever possible, you should provide a verbatim transcript of the session, showing what commands you typed and what the computer output in response. Give the programmer all the input you can think of. If the program reads from a file, you will probably need to send a copy of the file. If the program talks to another computer over a network, you probably can’t send a copy of that computer, but you can at least say what kind of computer it is, and (if you can) what software is running on it. “Works for me. So what goes wrong?” If you give the programmer a long list of inputs and actions, and they fire up their own copy of the program and nothing goes wrong, then you haven’t given them enough information. Possibly the fault doesn’t show up on every computer; your system and theirs may differ in some way. Possibly you have misunderstood what the program is supposed to do, and you are both looking at exactly the same display but you think it’s wrong and they know it’s right. So also describe what happened. Tell them exactly what you saw. Tell them why you think what you saw is wrong; better still, tell them exactly what you expected to see. If you say “and then it went wrong”, you have left out some very important information. If you saw error messages then tell the programmer, carefully and precisely, what they were. They are important! At this stage, the programmer is not trying to fix the problem: they’re just trying to find it. They need to know what has gone wrong, and those error messages are the computer’s best effort to tell you that. Write the errors down if you have no other easy way to remember them, but it’s not worth reporting that the program generated an error unless you can also report what the error message was. In particular, if the error message has numbers in it, do let the programmer have those numbers. Just because you can’t see any meaning in them doesn’t mean there isn’t any. Numbers contain all kinds of information that can be read by programmers, and they are likely to contain vital clues. Numbers in error messages are there because the computer is too confused to report the error in words, but is doing the best it can to get the important information to you somehow. At this stage, the programmer is effectively doing detective work. They don’t know what’s happened, and they can’t get close enough to watch it happening for themselves, so they are searching for clues that might give it away. Error messages, incomprehensible strings of numbers, and even unexplained delays are all just as important as fingerprints at the scene of a crime. Keep them! If you are using Unix, the program may have produced a core dump. Core dumps are a particularly good source of clues, so don’t throw them away. On the other hand, most programmers don’t like to receive huge core files by e-mail without warning, so ask before mailing one to anybody. Also, be aware that the core file contains a record of the complete state of the program: any “secrets” involved (maybe the program was handling a personal message, or dealing with confidential data) may be contained in the core file. “So then I tried . . .” There are a lot of things you might do when an error or bug comes up. Many of them make the problem worse. A friend of mine at school deleted all her Word documents by mistake, and before calling in any expert help, she tried reinstalling Word, and then she tried running Defrag. Neither of these helped recover her files, and between them they scrambled her disk to the extent that no Undelete program in the world would have been able to recover anything. If she’d only left it alone, she might have had a chance. Users like this are like a mongoose backed into a corner: with its back to the wall and seeing certain death staring it in the face, it attacks frantically, because doing something has to be better than doing nothing. This is not well adapted to the type of problems computers produce. Instead of being a mongoose, be an antelope. When an antelope is confronted with something unexpected or frightening, it freezes. It stays absolutely still and tries not to attract any attention, while it stops and thinks and works out the best thing to do. (If antelopes had a technical support line, it would be telephoning it at this point.) Then, once it has decided what the safest thing to do is, it does it. When something goes wrong, immediately stop doing anything. Don’t touch any buttons at all. Look at the screen and notice everything out of the ordinary, and remember it or write it down. Then perhaps start cautiously pressing “OK” or “Cancel”, whichever seems safest. Try to develop a reflex reaction - if a computer does anything unexpected, freeze. If you manage to get out of the problem, whether by closing down the affected program or by rebooting the computer, a good thing to do is to try to make it happen again. Programmers like problems that they can reproduce more than once. Happy programmers fix bugs faster and more efficiently. “I think the tachyon modulation must be wrongly polarised.” It isn’t only non-programmers who produce bad bug reports. Some of the worst bug reports I’ve ever seen come from programmers, and even from good programmers. I worked with another programmer once, who kept finding bugs in his own code and trying to fix them. Every so often he’d hit a bug he couldn’t solve, and he’d call me over to help. “What’s gone wrong?” I’d ask. He would reply by telling me his current opinion of what needed to be fixed. This worked fine when his current opinion was right. It meant he’d already done half the work and we were able to finish the job together. It was efficient and useful. But quite often he was wrong. We would work for some time trying to figure out why some particular part of the program was producing incorrect data, and eventually we would discover that it wasn’t, that we’d been investigating a perfectly good piece of code for half an hour, and that the actual problem was somewhere else. I’m sure he wouldn’t do that to a doctor. “Doctor, I need a prescription for Hydroyoyodyne.” People know not to say that to a doctor: you describe the symptoms, the actual discomforts and aches and pains and rashes and fevers, and you let the doctor do the diagnosis of what the problem is and what to do about it. Otherwise the doctor dismisses you as a hypochondriac or crackpot, and quite rightly so. It’s the same with programmers. Providing your own diagnosis might be helpful sometimes, but always state the symptoms. The diagnosis is an optional extra, and not an alternative to giving the symptoms. Equally, sending a modification to the code to fix the problem is a useful addition to a bug report but not an adequate substitute for one. If a programmer asks you for extra information, don’t make it up! Somebody reported a bug to me once, and I asked him to try a command that I knew wouldn’t work. The reason I asked him to try it was that I wanted to know which of two different error messages it would give. Knowing which error message came back would give a vital clue. But he didn’t actually try it - he just mailed me back and said “No, that won’t work”. It took me some time to persuade him to try it for real. Using your intelligence to help the programmer is fine. Even if your deductions are wrong, the programmer should be grateful that you at least tried to make their life easier. But report the symptoms as well, or you may well make their life much more difficult instead. “That’s funny, it did it a moment ago.” Say “intermittent fault” to any programmer and watch their face fall. The easy problems are the ones where performing a simple sequence of actions will cause the failure to occur. The programmer can then repeat those actions under closely observed test conditions and watch what happens in great detail. Too many problems simply don’t work that way: there will be programs that fail once a week, or fail once in a blue moon, or never fail when you try them in front of the programmer but always fail when you have a deadline coming up. Most intermittent faults are not truly intermittent. Most of them have some logic somewhere. Some might occur when the machine is running out of memory, some might occur when another program tries to modify a critical file at the wrong moment, and some might occur only in the first half of every hour! (I’ve actually seen one of these.) Also, if you can reproduce the bug but the programmer can’t, it could very well be that their computer and your computer are different in some way and this difference is causing the problem. I had a program once whose window curled up into a little ball in the top left corner of the screen, and sat there and sulked. But it only did it on 800x600 screens; it was fine on my 1024x768 monitor. The programmer will want to know anything you can find out about the problem. Try it on another machine, perhaps. Try it twice or three times and see how often it fails. If it goes wrong when you’re doing serious work but not when you’re trying to demonstrate it, it might be long running times or large files that make it fall over. Try to remember as much detail as you can about what you were doing to it when it did fall over, and if you see any patterns, mention them. Anything you can provide has to be some help. Even if it’s only probabilistic (such as “it tends to crash more often when Emacs is running”), it might not provide direct clues to the cause of the problem, but it might help the programmer reproduce it. Most importantly, the programmer will want to be sure of whether they’re dealing with a true intermittent fault or a machine-specific fault. They will want to know lots of details about your computer, so they can work out how it differs from theirs. A lot of these details will depend on the particular program, but one thing you should definitely be ready to provide is version numbers. The version number of the program itself, and the version number of the operating system, and probably the version numbers of any other programs that are involved in the problem. “So I loaded the disk on to my Windows . . .” Writing clearly is essential in a bug report. If the programmer can’t tell what you meant, you might as well not have said anything. I get bug reports from all around the world. Many of them are from non-native English speakers, and a lot of those apologise for their poor English. In general, the bug reports with apologies for their poor English are actually very clear and useful. All the most unclear reports come from native English speakers who assume that I will understand them even if they don’t make any effort to be clear or precise. Be specific. If you can do the same thing two different ways, state which one you used. “I selected Load” might mean “I clicked on Load” or “I pressed Alt-L”. Say which you did. Sometimes it matters.Be verbose. Give more information rather than less. If you say too much, the programmer can ignore some of it. If you say too little, they have to come back and ask more questions. One bug report I received was a single sentence; every time I asked for more information, the reporter would reply with another single sentence. It took me several weeks to get a useful amount of information, because it turned up one short sentence at a time.Be careful of pronouns. Don’t use words like “it”, or references like “the window”, when it’s unclear what they mean. Consider this: “I started FooApp. It put up a warning window. I tried to close it and it crashed.” It isn’t clear what the user tried to close. Did they try to close the warning window, or the whole of FooApp? It makes a difference. Instead, you could say “I started FooApp, which put up a warning window. I tried to close the warning window, and FooApp crashed.” This is longer and more repetitive, but also clearer and less easy to misunderstand.Read what you wrote. Read the report back to yourself, and see if you think it’s clear. If you have listed a sequence of actions which should produce the failure, try following them yourself, to see if you missed a step.Summary The first aim of a bug report is to let the programmer see the failure with their own eyes. If you can’t be with them to make it fail in front of them, give them detailed instructions so that they can make it fail for themselves.In case the first aim doesn’t succeed, and the programmer can’t see it failing themselves, the second aim of a bug report is to describe what went wrong. Describe everything in detail. State what you saw, and also state what you expected to see. Write down the error messages, especially if they have numbers in.When your computer does something unexpected, freeze. Do nothing until you’re calm, and don’t do anything that you think might be dangerous.By all means try to diagnose the fault yourself if you think you can, but if you do, you should still report the symptoms as well.Be ready to provide extra information if the programmer needs it. If they didn’t need it, they wouldn’t be asking for it. They aren’t being deliberately awkward. Have version numbers at your fingertips, because they will probably be needed.Write clearly. Say what you mean, and make sure it can’t be misinterpreted.Above all, be precise. Programmers like precision.Disclaimer: I’ve never actually seen a mongoose or an antelope. My zoology may be inaccurate. $Id$ Copyright © 1999 Simon Tatham.This document is OpenContent.You may copy and use the text under the terms of the OpenContent Licence. This article is not specific to any particular program. If you have reached this page by following a link from the website for a particular program, DO NOT send bug reports for that program to me. Instead, return to the page you came from to find out where to report bugs in the program. If you have comments or criticism about this article itself, please send them to anakin@pobox.com.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[]},{"title":"Software Release Practice HOWTO","date":"2017-01-20T11:53:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/software-release-practice-howto/","text":"Software Release Practice HOWTO Eric Steven Raymond This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it. This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards. Table of Contents Introduction1.1. Why this document?1.2. New versions of this document Good patching practice2.1. Do send patches, don’t send whole archives or files2.2. Send patches against the current version of the code.2.3. Don’t include patches for generated files.2.4. Don’t send patch bands that just tweak version-control $-symbols.2.5. Do use -c or -u format, don’t use the default (-e) format2.6. Do include documentation with your patch2.7. Do include an explanation with your patch2.8. Do include useful comments in your code2.9. Just one bugfix or new feature per patch. Good project- and archive- naming practice3.1. Use GNU-style names with a stem and major.minor.patch numbering.3.2. But respect local conventions where appropriate3.3. Try hard to choose a name prefix that is unique and easy to type Good licensing and copyright practice: the theory4.1. Open source and copyrights4.2. What qualifies as open source Good licensing and copyright practice: the practice5.1. Make yourself or the FSF the copyright holder5.2. Use a license conformant to the Open Source Definition5.3. Don’t write your own license if you can possibly avoid it.5.4. Make your license visible in a standard place. Good development practice6.1. Choose the most portable language you can6.2. Don’t rely on proprietary code6.3. Build systems6.4. Test your code before release6.5. Sanity-check your code before release6.6. Sanity-check your documentation and READMEs before release6.7. Recommended C/C++ portability practices Good distribution-making practice7.1. Make sure tarballs always unpack into a single new directory7.2. Have a README7.3. Respect and follow standard file naming practices7.4. Design for Upgradability7.5. Provide checksums Good documentation practice8.1. Documentation formats8.2. Good practice recommendations Good communication practice9.1. Announce to Freecode9.2. Have a website9.3. Host project mailing lists9.4. Release to major archives Good project-management practice","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"Advice for Computer Science College Students","date":"2017-01-20T11:44:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/advice-for-computer-science-college-students/","text":"Joel Spolsky co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow. Despite the fact that it was only a year or two ago that I was blubbering about how rich Windows GUI clients were the wave of the future, college students nonetheless do occasionally email me asking for career advice, and since it’s recruiting season, I thought I’d write up my standard advice which they can read, laugh at, and ignore. Most college students, fortunately, are brash enough never to bother asking their elders for advice, which, in the field of computer science, is a good thing, because their elders are apt to say goofy, antediluvian things like “the demand for keypunch operators will exceed 100,000,000 by the year 2010” and “lisp careers are really very hot right now.” I, too, have no idea what I’m talking about when I give advice to college students. I’m so hopelessly out of date that I can’t really figure out AIM and still use (horrors!) this quaint old thing called “email” which was popular in the days when music came on flat round plates called “CDs.” So you’d be better off ignoring what I’m saying here and instead building some kind of online software thing that lets other students find people to go out on dates with. Nevertheless. If you enjoy programming computers, count your blessings: you are in a very fortunate minority of people who can make a great living doing work they enjoy. Most people aren’t so lucky. The very idea that you can “love your job” is a modern concept. Work is supposed to be something unpleasant you do to get money to do the things you actually like doing, when you’re 65 and can finally retire, if you can afford it, and if you’re not too old and infirm to do those things, and if those things don’t require reliable knees, good eyes, and the ability to walk twenty feet without being out of breath, etc. What was I talking about? Oh yeah. Advice. Without further ado, then, here are Joel’s Seven Pieces of Free Advice for Computer Science College Students (worth what you paid for them): Learn how to write before graduating. Learn C before graduating. Learn microeconomics before graduating. Don’t blow off non-CS classes just because they’re boring. Take programming-intensive courses. Stop worrying about all the jobs going to India. No matter what you do, get a good summer internship. Now for the explanations, unless you’re gullible enough to do all that stuff just because I tell you to, in which case add: 8. Seek professional help for that self-esteem thing. Learn how to write before graduating.Would Linux have succeeded if Linus Torvalds hadn’t evangelized it? As brilliant a hacker as he is, it was Linus’s ability to convey his ideas in written English via email and mailing lists that made Linux attract a worldwide brigade of volunteers. Have you heard of the latest fad, Extreme Programming? Well, without getting into what I think about XP, the reason you’ve heard of it is because it is being promoted by people who are very gifted writers and speakers. Even on the small scale, when you look at any programming organization, the programmers with the most power and influence are the ones who can write and speak in English clearly, convincingly, and comfortably. Also it helps to be tall, but you can’t do anything about that. The difference between a tolerable programmer and a great programmer is not how many programming languages they know, and it’s not whether they prefer Python or Java. It’s whether they can communicate their ideas. By persuading other people, they get leverage. By writing clear comments and technical specs, they let other programmers understand their code, which means other programmers can use and work with their code instead of rewriting it. Absent this, their code is worthless. By writing clear technical documentation for end users, they allow people to figure out what their code is supposed to do, which is the only way those users can see the value in their code. There’s a lot of wonderful, useful code buried on sourceforge somewhere that nobody uses because it was created by programmers who don’t write very well (or don’t write at all), and so nobody knows what they’ve done and their brilliant code languishes. I won’t hire a programmer unless they can write, and write well, in English. If you can write, wherever you get hired, you’ll soon find that you’re getting asked to write the specifications and that means you’re already leveraging your influence and getting noticed by management. Most colleges designate certain classes as “writing intensive,” meaning, you have to write an awful lot to pass them. Look for those classes and take them! Seek out classes in any field that have weekly or daily written assignments. Start a journal or weblog. The more you write, the easier it will be, and the easier it is to write, the more you’ll write, in a virtuous circle. Learn C before graduatingPart two: C. Notice I didn’t say C++. Although C is becoming increasingly rare, it is still the lingua franca of working programmers. It is the language they use to communicate with one another, and, more importantly, it is much closer to the machine than “modern” languages that you’ll be taught in college like ML, Java, Python, whatever trendy junk they teach these days. You need to spend at least a semester getting close to the machine or you’ll never be able to create efficient code in higher level languages. You’ll never be able to work on compilers and operating systems, which are some of the best programming jobs around. You’ll never be trusted to create architectures for large scale projects. I don’t care how much you know about continuations and closures and exception handling: if you can’t explain why while (s++ = t++); copies a string, or if that isn’t the most natural thing in the world to you, well, you’re programming based on superstition, as far as I’m concerned: a medical doctor who doesn’t know basic anatomy, passing out prescriptions based on what the pharma sales babe said would work. Learn microeconomics before graduatingSuper quick review if you haven’t taken any economics courses: econ is one of those fields that starts off with a bang, with many useful theories and facts that make sense, can be proven in the field, etc., and then it’s all downhill from there. The useful bang at the beginning is microeconomics, which is the foundation for literally every theory in business that matters. After that things start to deteriorate: you get into Macroeconomics (feel free to skip this if you want) with its interesting theories about things like the relationship of interest rates to unemployment which, er, seem to be disproven more often than they are proven, and after that it just gets worse and worse and a lot of econ majors switch out to Physics, which gets them better Wall Street jobs, anyway. But make sure you take Microeconomics, because you have to know about supply and demand, you have to know about competitive advantage, and you have to understand NPVs and discounting and marginal utility before you’ll have any idea why business works the way it does. Why should CS majors learn econ? Because a programmer who understands the fundamentals of business is going to be a more valuable programmer, to a business, than a programmer who doesn’t. That’s all there is to it. I can’t tell you how many times I’ve been frustrated by programmers with crazy ideas that make sense in code but don’t make sense in capitalism. If you understand this stuff, you’re a more valuable programmer, and you’ll get rewarded for it, for reasons which you’ll also learn in micro. Don’t blow off non-CS classes just because they’re boring.Blowing off your non-CS courses is a great way to get a lower GPA. Never underestimate how big a deal your GPA is. Lots and lots of recruiters and hiring managers, myself included, go straight to the GPA when they scan a resume, and we’re not going to apologize for it. Why? Because the GPA, more than any other one number, reflects the sum of what dozens of professors over a long period of time in many different situations think about your work. SAT scores? Ha! That’s one test over a few hours. The GPA reflects hundreds of papers and midterms and classroom participations over four years. Yeah, it’s got its problems. There has been grade inflation over the years. Nothing about your GPA says whether you got that GPA taking easy classes in home economics at Podunk Community College or taking graduate level Quantum Mechanics at Caltech. Eventually, after I screen out all the 2.5 GPAs from Podunk Community, I’m going to ask for transcripts and recommendations. And then I’m going to look for consistently high grades, not just high grades in computer science. Why should I, as an employer looking for software developers, care about what grade you got in European History? After all, history is boring. Oh, so, you’re saying I should hire you because you don’t work very hard when the work is boring? Well, there’s boring stuff in programming, too. Every job has its boring moments. And I don’t want to hire people that only want to do the fun stuff. I took this course in college called Cultural Anthropology because I figured, what the heck, I need to learn something about anthropology, and this looked like an interesting survey course. Interesting? Not even close! I had to read these incredibly monotonous books about Indians in the Brazilian rain forest and Trobriand Islanders, who, with all due respect, are not very interesting to me. At some point, the class was so incredibly wearisome that I longed for something more exciting, like watching grass grow. I had completely lost interest in the subject matter. Completely, and thoroughly. My eyes teared I was so tired of the endless discussions of piling up yams. I don’t know why the Trobriand Islanders spend so much time piling up yams, I can’t remember any more, it’s incredibly boring, but It Was Going To Be On The Midterm, so I plowed through it. I eventually decided that Cultural Anthropology was going to be my Boredom Gauntlet: my personal obstacle course of tedium. If I could get an A in a class where the tests required me to learn all about potlatch blankets, I could handle anything, no matter how boring. The next time I accidentally get stuck in Lincoln Center sitting through all 18 hours of Wagner’s Ring Cycle, I could thank my studies of the Kwakiutl for making it seem pleasant by comparison. I got an A. And if I could do it, you can do it. Take programming-intensive courses.I remember the exact moment I vowed never to go to graduate school. It was in a course on Dynamic Logic, taught by the dynamic Lenore Zuck at Yale, one of the brightest of an array of very bright CS faculty. Now, my murky recollections are not going to do proper credit to this field, but let me muddle through anyway. The idea of Formal Logic is that you prove things are true because other things are true. For example thanks to Formal Logic, “Everyone who gets good grades will get hired” plus “Johnny got good grades” allows you to discover the new true fact, “Johnny will get hired.” It’s all very quaint and it only takes ten seconds for a deconstructionist to totally tear apart everything useful in Formal Logic so you’re left with something fun, but useless. Now, dynamic logic is the same thing, with the addition of time. For example, “after you turn the light on, you can see your shoes” plus “The light went on in the past” implies “you can see your shoes.” Dynamic Logic is appealing to brilliant theoreticians like Professor Zuck because it holds up the hope that you might be able to formally prove things about computer programs, which could be very useful, if, for example, you could formally prove that the Mars Rover’s flash card wouldn’t overflow and cause itself to be rebooted again and again all day long when it’s supposed to be driving around the red planet looking for Marvin the Martian. So in the first day of that class, Dr. Zuck filled up two entire whiteboards and quite a lot of the wall next to the whiteboards proving that if you have a light switch, and the light was off, and you flip the switch, the light will then be on. The proof was insanely complicated, and very error-prone. It was harder to prove that the proof was correct than to convince yourself of the fact that switching a light switch turns on the light. Indeed the multiple whiteboards of proof included many skipped steps, skipped because they were too tedious to go into formally. Many steps were reached using the long-cherished method of Proof by Induction, others by Proof by Reductio ad Absurdum, and still others using Proof by Graduate Student. For our homework, we had to prove the converse: if the light was off, and it’s on now, prove that you flipped it. I tried, I really did. I spent hours in the library trying. After a couple of hours I found a mistake in Dr. Zuck’s original proof which I was trying to emulate. Probably I copied it down wrong, but it made me realize something: if it takes three hours of filling up blackboards to prove something trivial, allowing hundreds of opportunities for mistakes to slip in, this mechanism would never be able to prove things that are interesting. Not that that matters to dynamic logicians: they’re not in it for useful, they’re in it for tenure. I dropped the class and vowed never to go to graduate school in Computer Science. The moral of the story is that computer science is not the same as software development. If you’re really really lucky, your school might have a decent software development curriculum, although, they might not, because elite schools think that teaching practical skills is better left to the technical-vocational institutes and the prison rehabilitation programs. You can learn mere programming anywhere. We are Yale University, and we Mold Future World Leaders. You think your $160,000 tuition entititles you to learn about while loops? What do you think this is, some fly-by-night Java seminar at the Airport Marriott? Pshaw. The trouble is, we don’t really have professional schools in software development, so if you want to be a programmer, you probably majored in Computer Science. Which is a fine subject to major in, but it’s a different subject than software development. If you’re lucky, though, you can find lots of programming-intensive courses in the CS department, just like you can find lots of courses in the History department where you’ll write enough to learn how to write. And those are the best classes to take. If you love programming, don’t feel bad if you don’t understand the point of those courses in lambda calculus or linear algebra where you never touch a computer. Look for the 400-level courses with Practicum in the name. This is an attempt to hide a useful (shudder) course from the Liberal Artsy Fartsy Administration by dolling it up with a Latin name. Stop worrying about all the jobs going to India.Well, OK, first of all, if you’re already in India, you never really had to worry about this, so don’t even start worrying about all the jobs going to India. They’re wonderful jobs, enjoy them in good health. But I keep hearing that enrollment in CS departments is dropping perilously, and one reason I hear for it is “students are afraid to go into a field where all the jobs are going to India.” That’s so wrong for so many reasons. First, trying to choose a career based on a current business fad is foolish. Second, programming is incredibly good training for all kinds of fabulously interesting jobs, such as business process engineering, even if every single programming job does go to India and China. Third, and trust me on this, there’s still an incredible shortage of the really good programmers, here and in India. Yes, there are a bunch of out of work IT people making a lot of noise about how long they’ve been out of work, but you know what? At the risk of pissing them off, really good programmers do have jobs. Fourth, you got any better ideas? What are you going to do, major in History? Then you’ll have no choice but to go to law school. And there’s one thing I do know: 99% of working lawyers hate their jobs, hate every waking minute of it, and they’re working 90 hour weeks, too. Like I said: if you love to program computers, count your blessings: you are in a very fortunate minority of people who can make a great living doing work they love. Anyway, I don’t think students really think about this. The drop in CS enrollment is merely a resumption of historically normal levels after a big bubble in enrollment caused by dotcom mania. That bubble consisted of people who didn’t really like programming but thought the sexy high paid jobs and the chances to IPO at age 24 were to be found in the CS department. Those people, thankfully, are long gone. No matter what you do, get a good summer internship.Smart recruiters know that the people who love programming wrote a database for their dentist in 8th grade, and taught at computer camp for three summers before college, and built the content management system for the campus newspaper, and had summer internships at software companies. That’s what they’re looking for on your resume. If you enjoy programming, the biggest mistake you can make is to take any kind of job–summer, part time, or otherwise–that is not a programming job. I know, every other 19-year-old wants to work in the mall folding shirts, but you have a skill that is incredibly valuable even when you’re 19, and it’s foolish to waste it folding shirts. By the time you graduate, you really should have a resume that lists a whole bunch of programming jobs. The A&amp;F graduates are going to be working at Enterprise Rent-a-Car “helping people with their rental needs.” (Except for Tom Welling. He plays Superman on TV.) To make your life really easy, and to underscore just how completely self-serving this whole essay is, my company, Fog Creek Software, has summer internships in software development that look great on resumes. “You will most likely learn more about software coding, development, and business with Fog Creek Software than any other internship out there,” says Ben, one of the interns from last summer, and not entirely because I sent a goon out to his dorm room to get him to say that. The application deadline is February 1st. Get on it. If you follow my advice, you, too, may end up selling stock in Microsoft way too soon, turning down jobs at Google because you want your own office with a door, and other stupid life decisions, but they won’t be my fault. I told you not to listen to me. WANT TO KNOW MORE? You’re reading Joel on Software, stuffed with years and years of completely raving mad articles about software development, managing software teams, designing user interfaces, running successful software companies, and rubber duckies. ABOUT THE AUTHOR. I’m Joel Spolsky, co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow. More about me.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Education","slug":"Education","permalink":"http://ipcreator.me/tags/Education/"}]},{"title":"Great hacker, Want to start a startup?","date":"2017-01-20T11:37:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/want-to-start-a-startup-great-hacker/","text":"Paul Graham July 2004 (This essay is derived from a talk at Oscon 2004.) A few months ago I finished a new book, and in reviews I keep noticing words like “provocative’’ and “controversial.’’ To say nothing of “idiotic.’’ I didn’t mean to make the book controversial. I was trying to make it efficient. I didn’t want to waste people’s time telling them things they already knew. It’s more efficient just to give them the diffs. But I suppose that’s bound to yield an alarming book. Edisons There’s no controversy about which idea is most controversial: the suggestion that variation in wealth might not be as big a problem as we think. I didn’t say in the book that variation in wealth was in itself a good thing. I said in some situations it might be a sign of good things. A throbbing headache is not a good thing, but it can be a sign of a good thing– for example, that you’re recovering consciousness after being hit on the head. Variation in wealth can be a sign of variation in productivity. (In a society of one, they’re identical.) And that is almost certainly a good thing: if your society has no variation in productivity, it’s probably not because everyone is Thomas Edison. It’s probably because you have no Thomas Edisons. In a low-tech society you don’t see much variation in productivity. If you have a tribe of nomads collecting sticks for a fire, how much more productive is the best stick gatherer going to be than the worst? A factor of two? Whereas when you hand people a complex tool like a computer, the variation in what they can do with it is enormous. That’s not a new idea. Fred Brooks wrote about it in 1974, and the study he quoted was published in 1968. But I think he underestimated the variation between programmers. He wrote about productivity in lines of code: the best programmers can solve a given problem in a tenth the time. But what if the problem isn’t given? In programming, as in many fields, the hard part isn’t solving problems, but deciding what problems to solve. Imagination is hard to measure, but in practice it dominates the kind of productivity that’s measured in lines of code. Productivity varies in any field, but there are few in which it varies so much. The variation between programmers is so great that it becomes a difference in kind. I don’t think this is something intrinsic to programming, though. In every field, technology magnifies differences in productivity. I think what’s happening in programming is just that we have a lot of technological leverage. But in every field the lever is getting longer, so the variation we see is something that more and more fields will see as time goes on. And the success of companies, and countries, will depend increasingly on how they deal with it. If variation in productivity increases with technology, then the contribution of the most productive individuals will not only be disproportionately large, but will actually grow with time. When you reach the point where 90% of a group’s output is created by 1% of its members, you lose big if something (whether Viking raids, or central planning) drags their productivity down to the average. If we want to get the most out of them, we need to understand these especially productive people. What motivates them? What do they need to do their jobs? How do you recognize them? How do you get them to come and work for you? And then of course there’s the question, how do you become one? More than Money I know a handful of super-hackers, so I sat down and thought about what they have in common. Their defining quality is probably that they really love to program. Ordinary programmers write code to pay the bills. Great hackers think of it as something they do for fun, and which they’re delighted to find people will pay them for. Great programmers are sometimes said to be indifferent to money. This isn’t quite true. It is true that all they really care about is doing interesting work. But if you make enough money, you get to work on whatever you want, and for that reason hackers are attracted by the idea of making really large amounts of money. But as long as they still have to show up for work every day, they care more about what they do there than how much they get paid for it. Economically, this is a fact of the greatest importance, because it means you don’t have to pay great hackers anything like what they’re worth. A great programmer might be ten or a hundred times as productive as an ordinary one, but he’ll consider himself lucky to get paid three times as much. As I’ll explain later, this is partly because great hackers don’t know how good they are. But it’s also because money is not the main thing they want. What do hackers want? Like all craftsmen, hackers like good tools. In fact, that’s an understatement. Good hackers find it unbearable to use bad tools. They’ll simply refuse to work on projects with the wrong infrastructure. At a startup I once worked for, one of the things pinned up on our bulletin board was an ad from IBM. It was a picture of an AS400, and the headline read, I think, “hackers despise it.’’ [1] When you decide what infrastructure to use for a project, you’re not just making a technical decision. You’re also making a social decision, and this may be the more important of the two. For example, if your company wants to write some software, it might seem a prudent choice to write it in Java. But when you choose a language, you’re also choosing a community. The programmers you’ll be able to hire to work on a Java project won’t be as smart as the ones you could get to work on a project written in Python. And the quality of your hackers probably matters more than the language you choose. Though, frankly, the fact that good hackers prefer Python to Java should tell you something about the relative merits of those languages. Business types prefer the most popular languages because they view languages as standards. They don’t want to bet the company on Betamax. The thing about languages, though, is that they’re not just standards. If you have to move bits over a network, by all means use TCP/IP. But a programming language isn’t just a format. A programming language is a medium of expression. I’ve read that Java has just overtaken Cobol as the most popular language. As a standard, you couldn’t wish for more. But as a medium of expression, you could do a lot better. Of all the great programmers I can think of, I know of only one who would voluntarily program in Java. And of all the great programmers I can think of who don’t work for Sun, on Java, I know of zero. Great hackers also generally insist on using open source software. Not just because it’s better, but because it gives them more control. Good hackers insist on control. This is part of what makes them good hackers: when something’s broken, they need to fix it. You want them to feel this way about the software they’re writing for you. You shouldn’t be surprised when they feel the same way about the operating system. A couple years ago a venture capitalist friend told me about a new startup he was involved with. It sounded promising. But the next time I talked to him, he said they’d decided to build their software on Windows NT, and had just hired a very experienced NT developer to be their chief technical officer. When I heard this, I thought, these guys are doomed. One, the CTO couldn’t be a first rate hacker, because to become an eminent NT developer he would have had to use NT voluntarily, multiple times, and I couldn’t imagine a great hacker doing that; and two, even if he was good, he’d have a hard time hiring anyone good to work for him if the project had to be built on NT. [2] The Final Frontier After software, the most important tool to a hacker is probably his office. Big companies think the function of office space is to express rank. But hackers use their offices for more than that: they use their office as a place to think in. And if you’re a technology company, their thoughts are your product. So making hackers work in a noisy, distracting environment is like having a paint factory where the air is full of soot. The cartoon strip Dilbert has a lot to say about cubicles, and with good reason. All the hackers I know despise them. The mere prospect of being interrupted is enough to prevent hackers from working on hard problems. If you want to get real work done in an office with cubicles, you have two options: work at home, or come in early or late or on a weekend, when no one else is there. Don’t companies realize this is a sign that something is broken? An office environment is supposed to be something that helps you work, not something you work despite. Companies like Cisco are proud that everyone there has a cubicle, even the CEO. But they’re not so advanced as they think; obviously they still view office space as a badge of rank. Note too that Cisco is famous for doing very little product development in house. They get new technology by buying the startups that created it– where presumably the hackers did have somewhere quiet to work. One big company that understands what hackers need is Microsoft. I once saw a recruiting ad for Microsoft with a big picture of a door. Work for us, the premise was, and we’ll give you a place to work where you can actually get work done. And you know, Microsoft is remarkable among big companies in that they are able to develop software in house. Not well, perhaps, but well enough. If companies want hackers to be productive, they should look at what they do at home. At home, hackers can arrange things themselves so they can get the most done. And when they work at home, hackers don’t work in noisy, open spaces; they work in rooms with doors. They work in cosy, neighborhoody places with people around and somewhere to walk when they need to mull something over, instead of in glass boxes set in acres of parking lots. They have a sofa they can take a nap on when they feel tired, instead of sitting in a coma at their desk, pretending to work. There’s no crew of people with vacuum cleaners that roars through every evening during the prime hacking hours. There are no meetings or, God forbid, corporate retreats or team-building exercises. And when you look at what they’re doing on that computer, you’ll find it reinforces what I said earlier about tools. They may have to use Java and Windows at work, but at home, where they can choose for themselves, you’re more likely to find them using Perl and Linux. Indeed, these statistics about Cobol or Java being the most popular language can be misleading. What we ought to look at, if we want to know what tools are best, is what hackers choose when they can choose freely– that is, in projects of their own. When you ask that question, you find that open source operating systems already have a dominant market share, and the number one language is probably Perl. Interesting Along with good tools, hackers want interesting projects. What makes a project interesting? Well, obviously overtly sexy applications like stealth planes or special effects software would be interesting to work on. But any application can be interesting if it poses novel technical challenges. So it’s hard to predict which problems hackers will like, because some become interesting only when the people working on them discover a new kind of solution. Before ITA (who wrote the software inside Orbitz), the people working on airline fare searches probably thought it was one of the most boring applications imaginable. But ITA made it interesting by redefining the problem in a more ambitious way. I think the same thing happened at Google. When Google was founded, the conventional wisdom among the so-called portals was that search was boring and unimportant. But the guys at Google didn’t think search was boring, and that’s why they do it so well. This is an area where managers can make a difference. Like a parent saying to a child, I bet you can’t clean up your whole room in ten minutes, a good manager can sometimes redefine a problem as a more interesting one. Steve Jobs seems to be particularly good at this, in part simply by having high standards. There were a lot of small, inexpensive computers before the Mac. He redefined the problem as: make one that’s beautiful. And that probably drove the developers harder than any carrot or stick could. They certainly delivered. When the Mac first appeared, you didn’t even have to turn it on to know it would be good; you could tell from the case. A few weeks ago I was walking along the street in Cambridge, and in someone’s trash I saw what appeared to be a Mac carrying case. I looked inside, and there was a Mac SE. I carried it home and plugged it in, and it booted. The happy Macintosh face, and then the finder. My God, it was so simple. It was just like … Google. Hackers like to work for people with high standards. But it’s not enough just to be exacting. You have to insist on the right things. Which usually means that you have to be a hacker yourself. I’ve seen occasional articles about how to manage programmers. Really there should be two articles: one about what to do if you are yourself a programmer, and one about what to do if you’re not. And the second could probably be condensed into two words: give up. The problem is not so much the day to day management. Really good hackers are practically self-managing. The problem is, if you’re not a hacker, you can’t tell who the good hackers are. A similar problem explains why American cars are so ugly. I call it the design paradox. You might think that you could make your products beautiful just by hiring a great designer to design them. But if you yourself don’t have good taste, how are you going to recognize a good designer? By definition you can’t tell from his portfolio. And you can’t go by the awards he’s won or the jobs he’s had, because in design, as in most fields, those tend to be driven by fashion and schmoozing, with actual ability a distant third. There’s no way around it: you can’t manage a process intended to produce beautiful things without knowing what beautiful is. American cars are ugly because American car companies are run by people with bad taste. Many people in this country think of taste as something elusive, or even frivolous. It is neither. To drive design, a manager must be the most demanding user of a company’s products. And if you have really good taste, you can, as Steve Jobs does, make satisfying you the kind of problem that good people like to work on. Nasty Little Problems It’s pretty easy to say what kinds of problems are not interesting: those where instead of solving a few big, clear, problems, you have to solve a lot of nasty little ones. One of the worst kinds of projects is writing an interface to a piece of software that’s full of bugs. Another is when you have to customize something for an individual client’s complex and ill-defined needs. To hackers these kinds of projects are the death of a thousand cuts. The distinguishing feature of nasty little problems is that you don’t learn anything from them. Writing a compiler is interesting because it teaches you what a compiler is. But writing an interface to a buggy piece of software doesn’t teach you anything, because the bugs are random. [3] So it’s not just fastidiousness that makes good hackers avoid nasty little problems. It’s more a question of self-preservation. Working on nasty little problems makes you stupid. Good hackers avoid it for the same reason models avoid cheeseburgers. Of course some problems inherently have this character. And because of supply and demand, they pay especially well. So a company that found a way to get great hackers to work on tedious problems would be very successful. How would you do it? One place this happens is in startups. At our startup we had Robert Morris working as a system administrator. That’s like having the Rolling Stones play at a bar mitzvah. You can’t hire that kind of talent. But people will do any amount of drudgery for companies of which they’re the founders. [4] Bigger companies solve the problem by partitioning the company. They get smart people to work for them by establishing a separate R&amp;D department where employees don’t have to work directly on customers’ nasty little problems. [5] In this model, the research department functions like a mine. They produce new ideas; maybe the rest of the company will be able to use them. You may not have to go to this extreme. Bottom-up programming suggests another way to partition the company: have the smart people work as toolmakers. If your company makes software to do x, have one group that builds tools for writing software of that type, and another that uses these tools to write the applications. This way you might be able to get smart people to write 99% of your code, but still keep them almost as insulated from users as they would be in a traditional research department. The toolmakers would have users, but they’d only be the company’s own developers. [6] If Microsoft used this approach, their software wouldn’t be so full of security holes, because the less smart people writing the actual applications wouldn’t be doing low-level stuff like allocating memory. Instead of writing Word directly in C, they’d be plugging together big Lego blocks of Word-language. (Duplo, I believe, is the technical term.) Clumping Along with interesting problems, what good hackers like is other good hackers. Great hackers tend to clump together– sometimes spectacularly so, as at Xerox Parc. So you won’t attract good hackers in linear proportion to how good an environment you create for them. The tendency to clump means it’s more like the square of the environment. So it’s winner take all. At any given time, there are only about ten or twenty places where hackers most want to work, and if you aren’t one of them, you won’t just have fewer great hackers, you’ll have zero. Having great hackers is not, by itself, enough to make a company successful. It works well for Google and ITA, which are two of the hot spots right now, but it didn’t help Thinking Machines or Xerox. Sun had a good run for a while, but their business model is a down elevator. In that situation, even the best hackers can’t save you. I think, though, that all other things being equal, a company that can attract great hackers will have a huge advantage. There are people who would disagree with this. When we were making the rounds of venture capital firms in the 1990s, several told us that software companies didn’t win by writing great software, but through brand, and dominating channels, and doing the right deals. They really seemed to believe this, and I think I know why. I think what a lot of VCs are looking for, at least unconsciously, is the next Microsoft. And of course if Microsoft is your model, you shouldn’t be looking for companies that hope to win by writing great software. But VCs are mistaken to look for the next Microsoft, because no startup can be the next Microsoft unless some other company is prepared to bend over at just the right moment and be the next IBM. It’s a mistake to use Microsoft as a model, because their whole culture derives from that one lucky break. Microsoft is a bad data point. If you throw them out, you find that good products do tend to win in the market. What VCs should be looking for is the next Apple, or the next Google. I think Bill Gates knows this. What worries him about Google is not the power of their brand, but the fact that they have better hackers. [7] Recognition So who are the great hackers? How do you know when you meet one? That turns out to be very hard. Even hackers can’t tell. I’m pretty sure now that my friend Trevor Blackwell is a great hacker. You may have read on Slashdot how he made his own Segway. The remarkable thing about this project was that he wrote all the software in one day (in Python, incidentally). For Trevor, that’s par for the course. But when I first met him, I thought he was a complete idiot. He was standing in Robert Morris’s office babbling at him about something or other, and I remember standing behind him making frantic gestures at Robert to shoo this nut out of his office so we could go to lunch. Robert says he misjudged Trevor at first too. Apparently when Robert first met him, Trevor had just begun a new scheme that involved writing down everything about every aspect of his life on a stack of index cards, which he carried with him everywhere. He’d also just arrived from Canada, and had a strong Canadian accent and a mullet. The problem is compounded by the fact that hackers, despite their reputation for social obliviousness, sometimes put a good deal of effort into seeming smart. When I was in grad school I used to hang around the MIT AI Lab occasionally. It was kind of intimidating at first. Everyone there spoke so fast. But after a while I learned the trick of speaking fast. You don’t have to think any faster; just use twice as many words to say everything. With this amount of noise in the signal, it’s hard to tell good hackers when you meet them. I can’t tell, even now. You also can’t tell from their resumes. It seems like the only way to judge a hacker is to work with him on something. And this is the reason that high-tech areas only happen around universities. The active ingredient here is not so much the professors as the students. Startups grow up around universities because universities bring together promising young people and make them work on the same projects. The smart ones learn who the other smart ones are, and together they cook up new projects of their own. Because you can’t tell a great hacker except by working with him, hackers themselves can’t tell how good they are. This is true to a degree in most fields. I’ve found that people who are great at something are not so much convinced of their own greatness as mystified at why everyone else seems so incompetent. But it’s particularly hard for hackers to know how good they are, because it’s hard to compare their work. This is easier in most other fields. In the hundred meters, you know in 10 seconds who’s fastest. Even in math there seems to be a general consensus about which problems are hard to solve, and what constitutes a good solution. But hacking is like writing. Who can say which of two novels is better? Certainly not the authors. With hackers, at least, other hackers can tell. That’s because, unlike novelists, hackers collaborate on projects. When you get to hit a few difficult problems over the net at someone, you learn pretty quickly how hard they hit them back. But hackers can’t watch themselves at work. So if you ask a great hacker how good he is, he’s almost certain to reply, I don’t know. He’s not just being modest. He really doesn’t know. And none of us know, except about people we’ve actually worked with. Which puts us in a weird situation: we don’t know who our heroes should be. The hackers who become famous tend to become famous by random accidents of PR. Occasionally I need to give an example of a great hacker, and I never know who to use. The first names that come to mind always tend to be people I know personally, but it seems lame to use them. So, I think, maybe I should say Richard Stallman, or Linus Torvalds, or Alan Kay, or someone famous like that. But I have no idea if these guys are great hackers. I’ve never worked with them on anything. If there is a Michael Jordan of hacking, no one knows, including him. Cultivation Finally, the question the hackers have all been wondering about: how do you become a great hacker? I don’t know if it’s possible to make yourself into one. But it’s certainly possible to do things that make you stupid, and if you can make yourself stupid, you can probably make yourself smart too. The key to being a good hacker may be to work on what you like. When I think about the great hackers I know, one thing they have in common is the extreme difficulty of making them work on anything they don’t want to. I don’t know if this is cause or effect; it may be both. To do something well you have to love it. So to the extent you can preserve hacking as something you love, you’re likely to do it well. Try to keep the sense of wonder you had about programming at age 14. If you’re worried that your current job is rotting your brain, it probably is. The best hackers tend to be smart, of course, but that’s true in a lot of fields. Is there some quality that’s unique to hackers? I asked some friends, and the number one thing they mentioned was curiosity. I’d always supposed that all smart people were curious– that curiosity was simply the first derivative of knowledge. But apparently hackers are particularly curious, especially about how things work. That makes sense, because programs are in effect giant descriptions of how things work. Several friends mentioned hackers’ ability to concentrate– their ability, as one put it, to “tune out everything outside their own heads.’’ I’ve certainly noticed this. And I’ve heard several hackers say that after drinking even half a beer they can’t program at all. So maybe hacking does require some special ability to focus. Perhaps great hackers can load a large amount of context into their head, so that when they look at a line of code, they see not just that line but the whole program around it. John McPhee wrote that Bill Bradley’s success as a basketball player was due partly to his extraordinary peripheral vision. “Perfect’’ eyesight means about 47 degrees of vertical peripheral vision. Bill Bradley had 70; he could see the basket when he was looking at the floor. Maybe great hackers have some similar inborn ability. (I cheat by using a very dense language, which shrinks the court.) This could explain the disconnect over cubicles. Maybe the people in charge of facilities, not having any concentration to shatter, have no idea that working in a cubicle feels to a hacker like having one’s brain in a blender. (Whereas Bill, if the rumors of autism are true, knows all too well.) One difference I’ve noticed between great hackers and smart people in general is that hackers are more politically incorrect. To the extent there is a secret handshake among good hackers, it’s when they know one another well enough to express opinions that would get them stoned to death by the general public. And I can see why political incorrectness would be a useful quality in programming. Programs are very complex and, at least in the hands of good programmers, very fluid. In such situations it’s helpful to have a habit of questioning assumptions. Can you cultivate these qualities? I don’t know. But you can at least not repress them. So here is my best shot at a recipe. If it is possible to make yourself into a great hacker, the way to do it may be to make the following deal with yourself: you never have to work on boring projects (unless your family will starve otherwise), and in return, you’ll never allow yourself to do a half-assed job. All the great hackers I know seem to have made that deal, though perhaps none of them had any choice in the matter. Notes [1] In fairness, I have to say that IBM makes decent hardware. I wrote this on an IBM laptop. [2] They did turn out to be doomed. They shut down a few months later. [3] I think this is what people mean when they talk about the “meaning of life.” On the face of it, this seems an odd idea. Life isn’t an expression; how could it have meaning? But it can have a quality that feels a lot like meaning. In a project like a compiler, you have to solve a lot of problems, but the problems all fall into a pattern, as in a signal. Whereas when the problems you have to solve are random, they seem like noise. [4] Einstein at one point worked designing refrigerators. (He had equity.) [5] It’s hard to say exactly what constitutes research in the computer world, but as a first approximation, it’s software that doesn’t have users. I don’t think it’s publication that makes the best hackers want to work in research departments. I think it’s mainly not having to have a three hour meeting with a product manager about problems integrating the Korean version of Word 13.27 with the talking paperclip. [6] Something similar has been happening for a long time in the construction industry. When you had a house built a couple hundred years ago, the local builders built everything in it. But increasingly what builders do is assemble components designed and manufactured by someone else. This has, like the arrival of desktop publishing, given people the freedom to experiment in disastrous ways, but it is certainly more efficient. [7] Google is much more dangerous to Microsoft than Netscape was. Probably more dangerous than any other company has ever been. Not least because they’re determined to fight. On their job listing page, they say that one of their “core values’’ is “Don’t be evil.’’ From a company selling soybean oil or mining equipment, such a statement would merely be eccentric. But I think all of us in the computer world recognize who that is a declaration of war on. Thanks to Jessica Livingston, Robert Morris, and Sarah Harlin for reading earlier versions of this talk.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"Undergraduation, Want to start a startup?","date":"2017-01-20T11:37:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/want-to-start-a-startup-undergraduate/","text":"Paul Graham July 2004 March 2005 (Parts of this essay began as replies to students who wrote to me with questions.) Recently I’ve had several emails from computer science undergrads asking what to do in college. I might not be the best source of advice, because I was a philosophy major in college. But I took so many CS classes that most CS majors thought I was one. I was certainly a hacker, at least. Hacking What should you do in college to become a good hacker? There are two main things you can do: become very good at programming, and learn a lot about specific, cool problems. These turn out to be equivalent, because each drives you to do the other. The way to be good at programming is to work (a) a lot (b) on hard problems. And the way to make yourself work on hard problems is to work on some very engaging project. Odds are this project won’t be a class assignment. My friend Robert learned a lot by writing network software when he was an undergrad. One of his projects was to connect Harvard to the Arpanet; it had been one of the original nodes, but by 1984 the connection had died. [1] Not only was this work not for a class, but because he spent all his time on it and neglected his studies, he was kicked out of school for a year. [2] It all evened out in the end, and now he’s a professor at MIT. But you’ll probably be happier if you don’t go to that extreme; it caused him a lot of worry at the time. Another way to be good at programming is to find other people who are good at it, and learn what they know. Programmers tend to sort themselves into tribes according to the type of work they do and the tools they use, and some tribes are smarter than others. Look around you and see what the smart people seem to be working on; there’s usually a reason. Some of the smartest people around you are professors. So one way to find interesting work is to volunteer as a research assistant. Professors are especially interested in people who can solve tedious system-administration type problems for them, so that is a way to get a foot in the door. What they fear are flakes and resume padders. It’s all too common for an assistant to result in a net increase in work. So you have to make it clear you’ll mean a net decrease. Don’t be put off if they say no. Rejection is almost always less personal than the rejectee imagines. Just move on to the next. (This applies to dating too.) Beware, because although most professors are smart, not all of them work on interesting stuff. Professors have to publish novel results to advance their careers, but there is more competition in more interesting areas of research. So what less ambitious professors do is turn out a series of papers whose conclusions are novel because no one else cares about them. You’re better off avoiding these. I never worked as a research assistant, so I feel a bit dishonest recommending that route. I learned to program by writing stuff of my own, particularly by trying to reverse-engineer Winograd’s SHRDLU. I was as obsessed with that program as a mother with a new baby. Whatever the disadvantages of working by yourself, the advantage is that the project is all your own. You never have to compromise or ask anyone’s permission, and if you have a new idea you can just sit down and start implementing it. In your own projects you don’t have to worry about novelty (as professors do) or profitability (as businesses do). All that matters is how hard the project is technically, and that has no correlation to the nature of the application. “Serious” applications like databases are often trivial and dull technically (if you ever suffer from insomnia, try reading the technical literature about databases) while “frivolous” applications like games are often very sophisticated. I’m sure there are game companies out there working on products with more intellectual content than the research at the bottom nine tenths of university CS departments. If I were in college now I’d probably work on graphics: a network game, for example, or a tool for 3D animation. When I was an undergrad there weren’t enough cycles around to make graphics interesting, but it’s hard to imagine anything more fun to work on now. Math When I was in college, a lot of the professors believed (or at least wished) that computer science was a branch of math. This idea was strongest at Harvard, where there wasn’t even a CS major till the 1980s; till then one had to major in applied math. But it was nearly as bad at Cornell. When I told the fearsome Professor Conway that I was interested in AI (a hot topic then), he told me I should major in math. I’m still not sure whether he thought AI required math, or whether he thought AI was nonsense and that majoring in something rigorous would cure me of such stupid ambitions. In fact, the amount of math you need as a hacker is a lot less than most university departments like to admit. I don’t think you need much more than high school math plus a few concepts from the theory of computation. (You have to know what an n^2 algorithm is if you want to avoid writing them.) Unless you’re planning to write math applications, of course. Robotics, for example, is all math. But while you don’t literally need math for most kinds of hacking, in the sense of knowing 1001 tricks for differentiating formulas, math is very much worth studying for its own sake. It’s a valuable source of metaphors for almost any kind of work.[3] I wish I’d studied more math in college for that reason. Like a lot of people, I was mathematically abused as a child. I learned to think of math as a collection of formulas that were neither beautiful nor had any relation to my life (despite attempts to translate them into “word problems”), but had to be memorized in order to do well on tests. One of the most valuable things you could do in college would be to learn what math is really about. This may not be easy, because a lot of good mathematicians are bad teachers. And while there are many popular books on math, few seem good. The best I can think of are W. W. Sawyer’s. And of course Euclid. [4] Everything Thomas Huxley said “Try to learn something about everything and everything about something.” Most universities aim at this ideal. But what’s everything? To me it means, all that people learn in the course of working honestly on hard problems. All such work tends to be related, in that ideas and techniques from one field can often be transplanted successfully to others. Even others that seem quite distant. For example, I write essays the same way I write software: I sit down and blow out a lame version 1 as fast as I can type, then spend several weeks rewriting it. Working on hard problems is not, by itself, enough. Medieval alchemists were working on a hard problem, but their approach was so bogus that there was little to learn from studying it, except possibly about people’s ability to delude themselves. Unfortunately the sort of AI I was trying to learn in college had the same flaw: a very hard problem, blithely approached with hopelessly inadequate techniques. Bold? Closer to fraudulent. The social sciences are also fairly bogus, because they’re so much influenced by intellectual fashions. If a physicist met a colleague from 100 years ago, he could teach him some new things; if a psychologist met a colleague from 100 years ago, they’d just get into an ideological argument. Yes, of course, you’ll learn something by taking a psychology class. The point is, you’ll learn more by taking a class in another department. The worthwhile departments, in my opinion, are math, the hard sciences, engineering, history (especially economic and social history, and the history of science), architecture, and the classics. A survey course in art history may be worthwhile. Modern literature is important, but the way to learn about it is just to read. I don’t know enough about music to say. You can skip the social sciences, philosophy, and the various departments created recently in response to political pressures. Many of these fields talk about important problems, certainly. But the way they talk about them is useless. For example, philosophy talks, among other things, about our obligations to one another; but you can learn more about this from a wise grandmother or E. B. White than from an academic philosopher. I speak here from experience. I should probably have been offended when people laughed at Clinton for saying “It depends on what the meaning of the word ‘is’ is.” I took about five classes in college on what the meaning of “is” is. Another way to figure out which fields are worth studying is to create the dropout graph. For example, I know many people who switched from math to computer science because they found math too hard, and no one who did the opposite. People don’t do hard things gratuitously; no one will work on a harder problem unless it is proportionately (or at least log(n)) more rewarding. So probably math is more worth studying than computer science. By similar comparisons you can make a graph of all the departments in a university. At the bottom you’ll find the subjects with least intellectual content. If you use this method, you’ll get roughly the same answer I just gave. Language courses are an anomaly. I think they’re better considered as extracurricular activities, like pottery classes. They’d be far more useful when combined with some time living in a country where the language is spoken. On a whim I studied Arabic as a freshman. It was a lot of work, and the only lasting benefits were a weird ability to identify semitic roots and some insights into how people recognize words. Studio art and creative writing courses are wildcards. Usually you don’t get taught much: you just work (or don’t work) on whatever you want, and then sit around offering “crits” of one another’s creations under the vague supervision of the teacher. But writing and art are both very hard problems that (some) people work honestly at, so they’re worth doing, especially if you can find a good teacher. Jobs Of course college students have to think about more than just learning. There are also two practical problems to consider: jobs, and graduate school. In theory a liberal education is not supposed to supply job training. But everyone knows this is a bit of a fib. Hackers at every college learn practical skills, and not by accident. What you should learn to get a job depends on the kind you want. If you want to work in a big company, learn how to hack Blub on Windows. If you want to work at a cool little company or research lab, you’ll do better to learn Ruby on Linux. And if you want to start your own company, which I think will be more and more common, master the most powerful tools you can find, because you’re going to be in a race against your competitors, and they’ll be your horse. There is not a direct correlation between the skills you should learn in college and those you’ll use in a job. You should aim slightly high in college. In workouts a football player may bench press 300 pounds, even though he may never have to exert anything like that much force in the course of a game. Likewise, if your professors try to make you learn stuff that’s more advanced than you’ll need in a job, it may not just be because they’re academics, detached from the real world. They may be trying to make you lift weights with your brain. The programs you write in classes differ in three critical ways from the ones you’ll write in the real world: they’re small; you get to start from scratch; and the problem is usually artificial and predetermined. In the real world, programs are bigger, tend to involve existing code, and often require you to figure out what the problem is before you can solve it. You don’t have to wait to leave (or even enter) college to learn these skills. If you want to learn how to deal with existing code, for example, you can contribute to open-source projects. The sort of employer you want to work for will be as impressed by that as good grades on class assignments. In existing open-source projects you don’t get much practice at the third skill, deciding what problems to solve. But there’s nothing to stop you starting new projects of your own. And good employers will be even more impressed with that. What sort of problem should you try to solve? One way to answer that is to ask what you need as a user. For example, I stumbled on a good algorithm for spam filtering because I wanted to stop getting spam. Now what I wish I had was a mail reader that somehow prevented my inbox from filling up. I tend to use my inbox as a todo list. But that’s like using a screwdriver to open bottles; what one really wants is a bottle opener. Grad School What about grad school? Should you go? And how do you get into a good one? In principle, grad school is professional training in research, and you shouldn’t go unless you want to do research as a career. And yet half the people who get PhDs in CS don’t go into research. I didn’t go to grad school to become a professor. I went because I wanted to learn more. So if you’re mainly interested in hacking and you go to grad school, you’ll find a lot of other people who are similarly out of their element. And if half the people around you are out of their element in the same way you are, are you really out of your element? There’s a fundamental problem in “computer science,” and it surfaces in situations like this. No one is sure what “research” is supposed to be. A lot of research is hacking that had to be crammed into the form of an academic paper to yield one more quantum of publication. So it’s kind of misleading to ask whether you’ll be at home in grad school, because very few people are quite at home in computer science. The whole field is uncomfortable in its own skin. So the fact that you’re mainly interested in hacking shouldn’t deter you from going to grad school. Just be warned you’ll have to do a lot of stuff you don’t like. Number one will be your dissertation. Almost everyone hates their dissertation by the time they’re done with it. The process inherently tends to produce an unpleasant result, like a cake made out of whole wheat flour and baked for twelve hours. Few dissertations are read with pleasure, especially by their authors. But thousands before you have suffered through writing a dissertation. And aside from that, grad school is close to paradise. Many people remember it as the happiest time of their lives. And nearly all the rest, including me, remember it as a period that would have been, if they hadn’t had to write a dissertation. [5] The danger with grad school is that you don’t see the scary part upfront. PhD programs start out as college part 2, with several years of classes. So by the time you face the horror of writing a dissertation, you’re already several years in. If you quit now, you’ll be a grad-school dropout, and you probably won’t like that idea. When Robert got kicked out of grad school for writing the Internet worm of 1988, I envied him enormously for finding a way out without the stigma of failure. On the whole, grad school is probably better than most alternatives. You meet a lot of smart people, and your glum procrastination will at least be a powerful common bond. And of course you have a PhD at the end. I forgot about that. I suppose that’s worth something. The greatest advantage of a PhD (besides being the union card of academia, of course) may be that it gives you some baseline confidence. For example, the Honeywell thermostats in my house have the most atrocious UI. My mother, who has the same model, diligently spent a day reading the user’s manual to learn how to operate hers. She assumed the problem was with her. But I can think to myself “If someone with a PhD in computer science can’t understand this thermostat, it must be badly designed.” If you still want to go to grad school after this equivocal recommendation, I can give you solid advice about how to get in. A lot of my friends are CS professors now, so I have the inside story about admissions. It’s quite different from college. At most colleges, admissions officers decide who gets in. For PhD programs, the professors do. And they try to do it well, because the people they admit are going to be working for them. Apparently only recommendations really matter at the best schools. Standardized tests count for nothing, and grades for little. The essay is mostly an opportunity to disqualify yourself by saying something stupid. The only thing professors trust is recommendations, preferably from people they know. [6] So if you want to get into a PhD program, the key is to impress your professors. And from my friends who are professors I know what impresses them: not merely trying to impress them. They’re not impressed by students who get good grades or want to be their research assistants so they can get into grad school. They’re impressed by students who get good grades and want to be their research assistants because they’re genuinely interested in the topic. So the best thing you can do in college, whether you want to get into grad school or just be good at hacking, is figure out what you truly like. It’s hard to trick professors into letting you into grad school, and impossible to trick problems into letting you solve them. College is where faking stops working. From this point, unless you want to go work for a big company, which is like reverting to high school, the only way forward is through doing what you love. Notes [1] No one seems to have minded, which shows how unimportant the Arpanet (which became the Internet) was as late as 1984. [2] This is why, when I became an employer, I didn’t care about GPAs. In fact, we actively sought out people who’d failed out of school. We once put up posters around Harvard saying “Did you just get kicked out for doing badly in your classes because you spent all your time working on some project of your own? Come work for us!” We managed to find a kid who had been, and he was a great hacker. When Harvard kicks undergrads out for a year, they have to get jobs. The idea is to show them how awful the real world is, so they’ll understand how lucky they are to be in college. This plan backfired with the guy who came to work for us, because he had more fun than he’d had in school, and made more that year from stock options than any of his professors did in salary. So instead of crawling back repentant at the end of the year, he took another year off and went to Europe. He did eventually graduate at about 26. [3] Eric Raymond says the best metaphors for hackers are in set theory, combinatorics, and graph theory. Trevor Blackwell reminds you to take math classes intended for math majors. “‘Math for engineers’ classes sucked mightily. In fact any ‘x for engineers’ sucks, where x includes math, law, writing and visual design.” [4] Other highly recommended books: What is Mathematics?, by Courant and Robbins; Geometry and the Imagination by Hilbert and Cohn-Vossen. And for those interested in graphic design, Byrne’s Euclid. [5] If you wanted to have the perfect life, the thing to do would be to go to grad school, secretly write your dissertation in the first year or two, and then just enjoy yourself for the next three years, dribbling out a chapter at a time. This prospect will make grad students’ mouths water, but I know of no one who’s had the discipline to pull it off. [6] One professor friend says that 15-20% of the grad students they admit each year are “long shots.” But what he means by long shots are people whose applications are perfect in every way, except that no one on the admissions committee knows the professors who wrote the recommendations. So if you want to get into grad school in the sciences, you need to go to college somewhere with real research professors. Otherwise you’ll seem a risky bet to admissions committees, no matter how good you are. Which implies a surprising but apparently inevitable consequence: little liberal arts colleges are doomed. Most smart high school kids at least consider going into the sciences, even if they ultimately choose not to. Why go to a college that limits their options? Thanks to Trevor Blackwell, Alex Lewin, Jessica Livingston, Robert Morris, Eric Raymond, and several anonymous CS professors for reading drafts of this, and to the students whose questions began it. Joel Spolsky: [Advice for Computer Science College Students](http://www.joelonsoftware.com/articles/CollegeAdvice.html) Eric Raymond: [How to Become a Hacker](http://www.catb.org/~esr/faqs/hacker-howto.html) More Advice for UndergradsI asked several friends who were professors and/or eminent hackers what they thought of Undergraduation. Their comments were so good that I thought I&apos;d just give them directly to you. I&apos;ve given them all codenames for now, since some may want to remain anonymous. NT: The one thing that I felt was missing from your essay was a statement supporting or dispelling the notion that CS is for loners. I disagree with this notion. I love hacking, but I love it even more when it&apos;s a shared experience. The hard problems seem just a bit more surmountable when there&apos;s two of you. Of course, Fred Brooks&apos;s law about adding manpower comes into play eventually. The rule: work in small groups with good people. Stay away from large bureaucratic organizations where status reports are more important than thinking outside the box. There are many individual aspects to CS, just like art. But, being an individual doesn&apos;t mean that the machine takes the place of good friends, colleagues, and mentors. TO: I think you should say &quot;College is where faking starts to stop working.&quot; FS: Math is more difficult than CS, no question. However, it is not at all clear to me that math has as much intellectual content as CS. The math hills are individually harder to climb, but CS is a bigger piece of landscape. (Formally, CS has to encompass reasoning about stateful objects with histories. There are important ways in which this is more difficult and general than pure axiomatic systems.) Empirically, I don&apos;t think the difference between math and CS is very useful for predicting how interesting and effective a thinker will come out the other end. So, while I agree with the spirit of your &quot;dropout graph&quot; heuristic, I think math and CS are an unhelpful choice to explain it with. Much better to note that both are hard subjects with real content, and contrast them with some sort of blatant basket-weaving like political science or (urgh) &quot;ethnic studies.&quot; &quot;They may be trying to make you lift weights with your brain.&quot; Indeed; I think pure mathematics makes excellent weightlifting. SA: The problem with graphics as an application is that doing a decent 3D game has a large component of movie making in it. You need motion capture and an art department for all the textures and backgrounds. Nobody will be impressed with pink cubes and green spheres bouncing around on the screen. I think the technology has pretty much surpassed anyone&apos;s ability to do anything simple and cool with it. DF: I found, when I was studying mathematics, that 2 things were true: (1) the teacher was not too good and (2) the book was not too good. So I would always buy a half-dozen books on the topic and try to get the full picture by reading the same sections in each book. The combination helped me understand much more than the sum of the content. Also, I was never opposed to reading something as much as 10 times until I squeezed everything out of it. I have found mathematics and especially formal logic to be an indispensible tool for structuring ideas. It was like Latin for me. Latin was this very clean natural language and logic was this very clean formal language. I had to teach it to myself because the logic course I had was the first 30 pages of Mendelsohn. When you want to say something unequivocally, describing formally is a good first start. When you want to understand, for example, the excitement of monads, understanding logic and some category theory helps. Category theory is also quite pretty. It simply says that everything has to be described in terms of function composition and this operator has to satisfy certain properties. If you think of logic as something alive, which allows you to prove theorems, it is fascinating. Just think about it: prove theorems by computer. It is mind-boggling. It will not likely lead to a start-up being successful, but what a moment when you prove a theorem without heuristics, etc. I have insisted that all my graduate students minor in logic, so that should say something. ML: The real reason to study math is not that it&apos;s useful but that it&apos;s cool. This should be all the reason a would-be hacker needs. Also, with its emphasis on rigor and abstraction, it&apos;s cool in a lot of the same ways as programming at its best. The fact that it&apos;s occasionally useful as well is just lagniappe. I also disagree that good mathematicians tend to be bad teachers. Having enjoyed the privilege of an expensive education, I am of the opinion that the very best mathematicians are usually (certainly not always) rather good teachers and are sometimes extraordinarily good. The real reason it is hard to learn what math is about is that mathematical understanding requires new and difficult (at least at first) ways of thinking. Cookbook calculus courses sidestep these difficulties and therefore teach little of value. Really understanding calculus was hard for Newton and is hard today.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Education","slug":"Education","permalink":"http://ipcreator.me/tags/Education/"}]},{"title":"The Loginataka","date":"2017-01-20T11:31:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/the-loginataka/","text":"The Loginataka by Eric S. Raymond &#x65;&#115;&#x72;&#64;&#x74;&#x68;&#x79;&#114;&#x73;&#117;&#115;&#x2e;&#x63;&#111;&#109; Speak, O Guru: How can I become a Unix Wizard? O, Nobly Born: know that the Way to Wizardhood is long, and winding, and Fraught with Risks. Thou must Attune thyself with the Source, attaining the arcane Knowledge and Conversation of the System Libraries and Internals. Yea; and such an all-consuming Time and Energy Sink is this as to greatly Imperil thy Grade Point Average (if one thou hast), not to mention thy Sex Life (if one thou hast). But persevere, oh Larval One; rewards beyond the Dreams of Lusers await thee! Speak, O Guru: What books should I study? Are the O’Reilly “Nutshell” guides a good place to start? O, Nobly Born: know that the Nutshell Guides are but the outermost Portal of the True Enlightenment. Worthy are they (and praise to the Name of O’Reilly, whose books show forth the Hacker Spirit in numerous pleasing ways), but the Nutshell Guides are only the Beginning of the Road. If thou desirest with True Desire to tread the Path of Wizardly Wisdom, first learn the elementary Postures of Kernighan &amp; Pike’s The Unix Programming Environment; then, absorb the mantic puissance of March Rochkind’s Advanced Unix Programming and W. Richard Stevens’s Advanced Programming In The Unix Environment. Immerse thyself, then, in the Pure Light of Maurice J. Bach’s The Design Of The Unix Operating System. Neglect not the Berkelian Way; study also The Design and Implementation Of The 4.4BSD Operating System by Kirk McKusick, Keith Bostic et. al. For useful hints, tips, and tricks, see Unix Power Tools, Tim O’Reilly, ed. Consider also the dark Wisdom to be gained from contemplation of the dread Portable C And Unix Systems Programming, e’en though it hath flowed from the keyboard of the mad and doomed Malvernite whom the world of unknowing Man misnames “J. E. Lapin”. These tomes shall instruct thy Left Brain in the Nature of the Unix System; to Feed the other half of thy Head, O Nobly Born, embrace also the Lore of its Nurture. Don Libes’s and Sandy Ressler’s Life With Unix will set thy Feet unerringly upon that Path; take as thy Travelling Companion the erratic but illuminating compendium called The New Hacker’s Dictionary (Eric S. Raymond, ed., with Guy L. Steele Jr.). (In this wise shalt thou travel the Way of the Camel.) Speak, O Guru: To attain Mastery, how many Kernels do I need to take apart and reassemble? O Nobly Born: this question reveals that indeed thou hast touched upon an Ineffable Truth about Unix — that thou canst not Plumb its Mysteries by mere Study but must become One with it through Practice. The true Way to the Knowledge of the Source is not the timid and footling way of the Student, but the Divine Foolery of the Hacker. Hack, then; strive against Mighty Problems, have joy in thy Striving, and let the Crashes fall where they may (maintaining the while, for the Good of thy Karma, a Rigorous Backup Policy). In this day of Boot-Time Autoconfiguration and Dynamically Loadable Device Drivers, reassembling a Kernel is no longer the daunting Test and Seal of Mastery that once it was. However, writing and verifying thine own Device Driver for some piece of Exotic Hardware is still a worthy challenge to thy Budding Guruhood. Indeed, such Challenge may be found the Crafting of any Program sufficiently Powerful to Extend or Compete with the Tools now available in Open Source. Therefore: seek thee out the Open Source Unixes: OpenBSD, FreeBSD, NetBSD, and most Especially Linux in many of its Incarnations. Join the Wizards and Aspirants to Wizardhood who Labor Unceasingly to Improve these. Commune with them in their Great Work, their unceasing Extension and Reinvention of Unix. In this wise may thou become one among the Mighty. Speak, O Guru: Some there are who claim that the sole Path to Wizardry and the proper Way of every Right-Thinking Hacker is to rewrite the Unix Kernel from Scratch. Is this not Sacrilege? Sacrilege, O Nobly Born? Nay! Certainly the Kernel Source is the Inmost Mystery of Unix — but there is a Mystery beyond that Mystery. The Nature of Unix inhereth not in any one Version but in the Design Tradition of which all Unixes are Evolving Parts. The Rite of the Rewrite is not the only Path to Mastery, but it is perhaps the highest and most Sacred of all Paths. Few indeed are those who, travelling it, have crossed the dark and yawning Abyss of Implementation to Delivery. Many, yea, many in truth stagnate yet in the Desert of Delay, or linger ever in the ghastly limbo called Perpetual Beta. (In this wise shalt thou travel the Way of the Lion.) Speak, O Guru: What, then, is the True Path to Wizardhood? O Nobly Born: learn, and seek within thyself. Cultivate the cunning of the Serpent and the courage of the Tiger; sup deeply from the Wisdom of those who came before thee. Hack, and hack again; grow, by trial and by error. Post thy best hacks to the Net and gain in Repute thereby. Also, O Nobly Born, be thou grave and courteous in thy speech; be helpful to those less than thee, quick to succour and slow to flame. If thou dost these things faithfully, if thou travellest with high heart and pure intention, soon shall thy callow Newbiehood be shed. By degrees imperceptible to thyself shalt thou gain Power and Wisdom, Striving and Doing all the while. Gradually shall thy Puissance unfold and deepen. O Nobly Born, if thou dost all these things, thy Wizardhood shall surely come upon thee; but not of a sudden, and not until after thy arrogant Mind hath more than half Forgotten that such was its Aim. For know this — you may not by thyself in Pride claim the Mantle of Wizardry; that way lies only Bogosity without End. Rather must you Become, and Become, and Become, until Hackers respect thy Power, and other Wizards hail thee as a Brother or Sister in Wisdom, and you wake up and realize that the Mantle hath lain unknown upon thy Shoulders since you knew not when. (In this wise shalt thou travel the Way of the Child.) Hear, O nobly born: Techniques can be taught, but the Way of the Hacker cannot be taught. Skills can be acquired, but the Way of the Hacker is not a checklist of skills. Programming can be accomplished, but the Way of the Hacker is not a place at which you can stop and say “I have arrived!” Hear, O nobly born: The Way of the Hacker is a posture of mind; he who seeks a teacher of the Way knows it not, but he is only looking for a mirror. All those competent to teach the Way know that it cannot be taught, only pursued with joyous labor and by emulation of the great hackers of the past. Hear, O nobly born: Great were the hackers of the past! Subtle and deep in their thinking, shaggy-bearded and with thunder on their brows! You may seek to become as them, but it will not suffice you to grow a beard. Hear, O Nobly Born: The center of the mystery is the act of coding. You have a keyboard before you; pursue the Way through work. SHANTIH! SHANTIH! SHANTIH! Annotations: Most of this (up to “(In this wise shalt thou travel the Way of the Child.)”) was originally a Usenet response to some eager newbie questions; it appears that I wrote it on 21 November 1992 in response to a post by one Ade Barkah. After ten years, I guess it’s time to draw aside the veil of those mysteries. The remainder I wrote in 2010 after I was actually asked to give an answer in the style of the Loginataka. For those of you who are not native English speakers, the entirety is written in imitation of the Early Modern English of the late 1500s and early 1600s, the language of the King James Bible. The influence of the King James Bible is such that its dialect has retained connotations of majesty, solemnity, and religious authority. Holy scriptures from other languages are, therefore, often translated into a KJB-like pseudo-archaic English rather than following modern usage. Parts of this border on obsolescence now. Portable C And Unix Systems Programming has been out of print for a long time, but the Lovecraft joke was too funny to lose. Life With Unix is history, too, but the other references are still good. In 1998 I changed references to “freeware” and “free software” to “open source”. Otherwise changes have been pretty minor. “Loginataka” The title of the document is a play on the name of the Tripitaka, an early compilation of Buddhist scriptures. **&quot;Oh Nobly Born:&quot; ** The formulaic use of the salutation is intended to be reminiscent of the Bardo Thödöl — the Tibetan Book Of The Dead. **&quot;the Name of O&apos;Reilly&quot; ** A phrase rich with meaning in the clan system of old Scotland and Ireland. It might refer to the reputation of the clan O’Reilly, or to the person of the clan chief. The implied image is of Tim O’Reilly, be-tartaned, surrounded by louring Celts bristling with weapons. It’s worth noting that O’Reilly and Associates was pretty new at the game when I wrote this; it was over the following five years that they built up their remarkable reputation as friends of the hacker community. **&quot;attaining the arcane Knowledge and Conversation&quot; ** This is a reference to the occultism of Alesteir Crowley. He wrote of attaining the “Knowledge and Conversation of the Holy Guardian Angel” as the central aim of Thelemic mysticism, and added that he had chosen that term for it because it was the most absurd locution he could think of. **&quot;the Pure Light&quot; ** In Buddhist mysticism, the Pure Light of the Void (“void” being the usual English translation of Sanskrit sunyata) is a frequent metaphor for the wisdom that comes from realizing the emptiness of all things. **&quot;the Berkelian Way&quot; ** If you caught the previous reference to sunyata, you might also recall that Bishop Berkeley famously denied the existence of objective reality. **&quot;the mad and doomed Malvernite&quot; ** This is a play on H.P. Lovecraft’s “mad and doomed Arab”, Abdul al-Hazred, the author of the Necronomicon. And the actual doomed Malvernite was…er…me, in 1987. The “world of unknowing man misnames” because I wrote the book, but was pressured into allowing it to be published under a corporate pseudonym. **&quot;feed the other half of thy head&quot; ** Cue Grace Slick, in the last lines of Jefferson Airplane’s White Rabbit, a song about a hallucinogenic drug experience: “Remember…what the dormouse said! FEED YOUR HEAD! FEED YOUR HEAD!” **&quot;the Way of the Camel&quot; ** The references to the Ways of the Camel, Lion, and Child are to a mystical rant in Nietzsche’s Thus Spoke Zarathustra. **&quot;Divine Foolery of the Hacker&quot; ** The image of the Fool of God is a pervasive one in world mysticism. I was thinking here especially of the Fool card in the Rider-Waite Tarot, showing a clown walking or capering at the edge of a precipice. **&quot;Great Work&quot; ** In alchemy, the production of the Philosopher’s Stone that could transmute lead to gold, confer immortality. In some mystical interpretations of alchemy, the transmutation of the adept’s own soul. Modern Hermetic occultism generalizes the second meaning. **&quot;Desert of Delay&quot; ** This part is intended to recall the landscapes in Bunyan’s moral allegory Pilgrim’s Progress. **&quot;cunning of the Serpent and the courage of the Tiger&quot; ** In the New Testament of the Christian Bible, Matthew 10:16 exhorts Christians to be as cunning as serpents and as harmless as doves. This in turn refers to the “cunning of the serpent” in the Old Testament Book of Genesis. **&quot;if thou travellest with high heart and pure intention&quot; ** In the Egyptian Book Of The Dead, “I have travelled here with high heart and pure intention” is part of the ritual one must speak to pass the Weigher of Souls. **&quot;Shantih!&quot; ** “Shanti!” is Sanskrit and means “Peace!” I deliberately used the older transliteration “Shantih!” because it’s found at the end of T.S. Eliot’s poem The Wasteland. The threefold repetition is a form of invocatory magic closely equivalent to the Catholic ritual blessing “Peace be with you!” If you found this entertaining, you would probably also enjoy Rootless Root: The Unix Koans of Master Foo.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"The Art of Unix Programming","date":"2017-01-20T11:16:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/the-art-of-unix-programming/","text":"The Art of Unix Programming Eric Steven Raymond This book and its on-line version are distributed under the terms of the Creative Commons Attribution-NoDerivs 1.0 license, with the additional proviso that the right to publish it on paper for sale or other for-profit use is reserved to Pearson Education, Inc. A reference copy of this license may be found at http://creativecommons.org/licenses/by-nd/1.0/legalcode. AIX, AS/400, DB/2, OS/2, System/360, MVS, VM/CMS, and IBM PC are trademarks of IBM. Alpha, DEC, VAX, HP-UX, PDP, TOPS-10, TOPS-20, VMS, and VT-100 are trademarks of Compaq. Amiga and AmigaOS are trademarks of Amiga, Inc. Apple, Macintosh, MacOS, Newton, OpenDoc, and OpenStep are trademarks of Apple Computers, Inc. ClearCase is a trademark of Rational Software, Inc. Ethernet is a trademark of 3COM, Inc. Excel, MS-DOS, Microsoft Windows and PowerPoint are trademarks of Microsoft, Inc. Java. J2EE, JavaScript, NeWS, and Solaris are trademarks of Sun Microsystems. SPARC is a trademark of SPARC international. Informix is a trademark of Informix software. Itanium is a trademark of Intel. Linux is a trademark of Linus Torvalds. Netscape is a trademark of AOL. PDF and PostScript are trademarks of Adobe, Inc. UNIX is a trademark of The Open Group. The photograph of Ken and Dennis in Chapter 2 appears courtesy of Bell Labs/Lucent Technologies. The epigraph on the Portability chapter is from the Bell System Technical Journal, v57 #6 part 2 (July-Aug. 1978) pp. 2021-2048 and is reproduced with the permission of Bell Labs/Lucent Technologies. Revision HistoryRevision 1.0 19 September 2003 esrThis is the content that went to Addison-Wesley’s printers.Revision 0.4 5 February 2003 esrRelease for public review.Revision 0.3 22 January 2003 esrFirst eighteen-chapter draft. Manuscript walkthrough at Chapter 12. Limited release for early reviewers.Revision 0.2 2 January 2003 esrFirst manuscript walkthrough at Chapter 7. Released to Dmitry Kirsanov at AW production.Revision 0.1 16 November 2002 esrFirst DocBook draft, fifteen chapters. Languages rewritten to incorporate lots of feedback. Transparency, Modularity, Multiprogramming, Configuration, Interfaces, Documentation, and Open Source chapters released. Shipped to Mark Taub at AW.Revision 0.0 1999 esrPublic HTML draft, first four chapters only.Dedication To Ken Thompson and Dennis Ritchie, because you inspired me. Table of Contents PrefaceWho Should Read This BookHow to Use This BookRelated ReferencesConventions Used in This BookOur Case StudiesAuthor’s AcknowledgementsI. Context PhilosophyCulture? What Culture?The Durability of UnixThe Case against Learning Unix CultureWhat Unix Gets WrongWhat Unix Gets RightOpen-Source SoftwareCross-Platform Portability and Open StandardsThe Internet and the World Wide WebThe Open-Source CommunityFlexibility All the Way DownUnix Is Fun to HackThe Lessons of Unix Can Be Applied ElsewhereBasics of the Unix PhilosophyRule of Modularity: Write simple parts connected by clean interfaces.Rule of Clarity: Clarity is better than cleverness.Rule of Composition: Design programs to be connected with other programs.Rule of Separation: Separate policy from mechanism; separate interfaces from engines.Rule of Simplicity: Design for simplicity; add complexity only where you must.Rule of Parsimony: Write a big program only when it is clear by demonstration that nothing else will do.Rule of Transparency: Design for visibility to make inspection and debugging easier.Rule of Robustness: Robustness is the child of transparency and simplicity.Rule of Representation: Fold knowledge into data, so program logic can be stupid and robust.Rule of Least Surprise: In interface design, always do the least surprising thing.Rule of Silence: When a program has nothing surprising to say, it should say nothing.Rule of Repair: Repair what you can — but when you must fail, fail noisily and as soon as possible.Rule of Economy: Programmer time is expensive; conserve it in preference to machine time.Rule of Generation: Avoid hand-hacking; write programs to write programs when you can.Rule of Optimization: Prototype before polishing. Get it working before you optimize it.Rule of Diversity: Distrust all claims for one true way.Rule of Extensibility: Design for the future, because it will be here sooner than you think.The Unix Philosophy in One LessonApplying the Unix PhilosophyAttitude Matters Too HistoryOrigins and History of Unix, 1969-1995Genesis: 1969–1971Exodus: 1971–1980TCP/IP and the Unix Wars: 1980-1990Blows against the Empire: 1991-1995Origins and History of the Hackers, 1961-1995At Play in the Groves of Academe: 1961-1980Internet Fusion and the Free Software Movement: 1981-1991Linux and the Pragmatist Reaction: 1991-1998The Open-Source Movement: 1998 and OnwardThe Lessons of Unix History ContrastsThe Elements of Operating-System StyleWhat Is the Operating System’s Unifying Idea?Multitasking CapabilityCooperating ProcessesInternal BoundariesFile Attributes and Record StructuresBinary File FormatsPreferred User Interface StyleIntended AudienceEntry Barriers to DevelopmentOperating-System ComparisonsVMSMacOSOS/2Windows NTBeOSMVSVM/CMSLinuxWhat Goes Around, Comes AroundII. Design ModularityEncapsulation and Optimal Module SizeCompactness and OrthogonalityCompactnessOrthogonalityThe SPOT RuleCompactness and the Strong Single CenterThe Value of DetachmentSoftware Is a Many-Layered ThingTop-Down versus Bottom-UpGlue LayersCase Study: C Considered as Thin GlueLibrariesCase Study: GIMP PluginsUnix and Object-Oriented LanguagesCoding for Modularity TextualityThe Importance of Being TextualCase Study: Unix Password File FormatCase Study: .newsrc FormatCase Study: The PNG Graphics File FormatData File MetaformatsDSV StyleRFC 822 FormatCookie-Jar FormatRecord-Jar FormatXMLWindows INI FormatUnix Textual File Format ConventionsThe Pros and Cons of File CompressionApplication Protocol DesignCase Study: SMTP, the Simple Mail Transfer ProtocolCase Study: POP3, the Post Office ProtocolCase Study: IMAP, the Internet Message Access ProtocolApplication Protocol MetaformatsThe Classical Internet Application MetaprotocolHTTP as a Universal Application ProtocolBEEP: Blocks Extensible Exchange ProtocolXML-RPC, SOAP, and Jabber TransparencyStudying CasesCase Study: audacityCase Study: fetchmail’s -v optionCase Study: GCCCase Study: kmailCase Study: SNGCase Study: The Terminfo DatabaseCase Study: Freeciv Data FilesDesigning for Transparency and DiscoverabilityThe Zen of TransparencyCoding for Transparency and DiscoverabilityTransparency and Avoiding OverprotectivenessTransparency and Editable RepresentationsTransparency, Fault Diagnosis, and Fault RecoveryDesigning for Maintainability MultiprogrammingSeparating Complexity Control from Performance TuningTaxonomy of Unix IPC MethodsHanding off Tasks to Specialist ProgramsPipes, Redirection, and FiltersWrappersSecurity Wrappers and Bernstein ChainingSlave ProcessesPeer-to-Peer Inter-Process CommunicationProblems and Methods to AvoidObsolescent Unix IPC MethodsRemote Procedure CallsThreads — Threat or Menace?Process Partitioning at the Design Level MinilanguagesUnderstanding the Taxonomy of LanguagesApplying MinilanguagesCase Study: sngCase Study: Regular ExpressionsCase Study: GladeCase Study: m4Case Study: XSLTCase Study: The Documenter’s Workbench ToolsCase Study: fetchmail Run-Control SyntaxCase Study: awkCase Study: PostScriptCase Study: bc and dcCase Study: Emacs LispCase Study: JavaScriptDesigning MinilanguagesChoosing the Right Complexity LevelExtending and Embedding LanguagesWriting a Custom GrammarMacros — Beware!Language or Application Protocol? GenerationData-Driven ProgrammingCase Study: asciiCase Study: Statistical Spam FilteringCase Study: Metaclass Hacking in fetchmailconfAd-hoc Code GenerationCase Study: Generating Code for the ascii DisplaysCase Study: Generating HTML Code for a Tabular List ConfigurationWhat Should Be Configurable?Where Configurations LiveRun-Control FilesCase Study: The .netrc FilePortability to Other Operating SystemsEnvironment VariablesSystem Environment VariablesUser Environment VariablesWhen to Use Environment VariablesPortability to Other Operating SystemsCommand-Line OptionsThe -a to -z of Command-Line OptionsPortability to Other Operating SystemsHow to Choose among the MethodsCase Study: fetchmailCase Study: The XFree86 ServerOn Breaking These Rules InterfacesApplying the Rule of Least SurpriseHistory of Interface Design on UnixEvaluating Interface DesignsTradeoffs between CLI and Visual InterfacesCase Study: Two Ways to Write a Calculator ProgramTransparency, Expressiveness, and ConfigurabilityUnix Interface Design PatternsThe Filter PatternThe Cantrip PatternThe Source PatternThe Sink PatternThe Compiler PatternThe ed patternThe Roguelike PatternThe ‘Separated Engine and Interface’ PatternThe CLI Server PatternLanguage-Based Interface PatternsApplying Unix Interface-Design PatternsThe Polyvalent-Program PatternThe Web Browser as a Universal Front EndSilence Is Golden OptimizationDon’t Just Do Something, Stand There!Measure before OptimizingNonlocality Considered HarmfulThroughput vs. LatencyBatching OperationsOverlapping OperationsCaching Operation Results ComplexitySpeaking of ComplexityThe Three Sources of ComplexityTradeoffs between Interface and Implementation ComplexityEssential, Optional, and Accidental ComplexityMapping ComplexityWhen Simplicity Is Not EnoughA Tale of Five EditorsedviSamEmacsWilyThe Right Size for an EditorIdentifying the Complexity ProblemsCompromise Doesn’t WorkIs Emacs an Argument against the Unix Tradition?The Right Size of SoftwareIII. Implementation LanguagesUnix’s Cornucopia of LanguagesWhy Not C?Interpreted Languages and Mixed StrategiesLanguage EvaluationsCC++ShellPerlTclPythonJavaEmacs LispTrends for the FutureChoosing an X Toolkit ToolsA Developer-Friendly Operating SystemChoosing an EditorUseful Things to Know about viUseful Things to Know about EmacsThe Antireligious Choice: Using BothSpecial-Purpose Code Generatorsyacc and lexCase Study: Glademake: Automating Your RecipesBasic Theory of makemake in Non-C/C++ DevelopmentUtility ProductionsGenerating MakefilesVersion-Control SystemsWhy Version Control?Version Control by HandAutomated Version ControlUnix Tools for Version ControlRuntime DebuggingProfilingCombining Tools with EmacsEmacs and makeEmacs and Runtime DebuggingEmacs and Version ControlEmacs and ProfilingLike an IDE, Only Better ReuseThe Tale of J. Random NewbieTransparency as the Key to ReuseFrom Reuse to Open SourceThe Best Things in Life Are OpenWhere to Look?Issues in Using Open-Source SoftwareLicensing IssuesWhat Qualifies as Open SourceStandard Open-Source LicensesWhen You Need a LawyerIV. Community PortabilityEvolution of CEarly History of CC StandardsUnix StandardsStandards and the Unix WarsThe Ghost at the Victory BanquetUnix Standards in the Open-Source WorldIETF and the RFC Standards ProcessSpecifications as DNA, Code as RNAProgramming for PortabilityPortability and Choice of LanguageAvoiding System DependenciesTools for PortabilityInternationalizationPortability, Open Standards, and Open Source DocumentationDocumentation ConceptsThe Unix StyleThe Large-Document BiasCultural StyleThe Zoo of Unix Documentation Formatstroff and the Documenter’s Workbench ToolsTeXTexinfoPODHTMLDocBookThe Present Chaos and a Possible Way OutDocBookDocument Type DefinitionsOther DTDsThe DocBook ToolchainMigration ToolsEditing ToolsRelated Standards and PracticesSGMLXML-DocBook ReferencesBest Practices for Writing Unix Documentation Open SourceUnix and Open SourceBest Practices for Working with Open-Source DevelopersGood Patching PracticeGood Project- and Archive-Naming PracticeGood Development PracticeGood Distribution-Making PracticeGood Communication PracticeThe Logic of Licenses: How to Pick OneWhy You Should Use a Standard LicenseVarieties of Open-Source LicensingMIT or X Consortium LicenseBSD Classic LicenseArtistic LicenseGeneral Public LicenseMozilla Public License FuturesEssence and Accident in Unix TraditionPlan 9: The Way the Future WasProblems in the Design of UnixA Unix File Is Just a Big Bag of BytesUnix Support for GUIs Is WeakFile Deletion Is ForeverUnix Assumes a Static File SystemThe Design of Job Control Was Badly BotchedThe Unix API Doesn’t Use Exceptionsioctl2 and fcntl2 Are an EmbarrassmentThe Unix Security Model May Be Too PrimitiveUnix Has Too Many Different Kinds of NamesFile Systems Might Be Considered HarmfulTowards a Global Internet Address SpaceProblems in the Environment of UnixProblems in the Culture of UnixReasons to BelieveA. Glossary of AbbreviationsB. ReferencesC. ContributorsD. Rootless RootEditor’s IntroductionMaster Foo and the Ten Thousand LinesMaster Foo and the Script KiddieMaster Foo Discourses on the Two PathsMaster Foo and the MethodologistMaster Foo Discourses on the Graphical User InterfaceMaster Foo and the Unix ZealotMaster Foo Discourses on the Unix-NatureMaster Foo and the End UserList of Figures 2.1. The PDP-7.3.1. Schematic history of timesharing.4.1. Qualitative plot of defect count and density vs. module size.4.2. Caller/callee relationships in GIMP with a plugin loaded.6.1. Screen shot of audacity.6.2. Screen shot of kmail.6.3. Main window of a Freeciv game.8.1. Taxonomy of languages.11.1. The xcalc GUI.11.2. Screen shot of the original Rogue game.11.3. The Xcdroast GUI.11.4. Caller/callee relationships in a polyvalent program.13.1. Sources and kinds of complexity.18.1. Processing structural documents.18.2. Present-day XML-DocBook toolchain.18.3. Future XML-DocBook toolchain with FOP.List of Tables 8.1. Regular-expression examples.8.2. Introduction to regular-expression operations.14.1. Language choices.14.2. Summary of X Toolkits.List of Examples 5.1. Password file example.5.2. A .newsrc example.5.3. A fortune file example.5.4. Basic data for three planets in a record-jar format.5.5. An XML example.5.6. A .INI file example.5.7. An SMTP session example.5.8. A POP3 example session.5.9. An IMAP session example.6.1. An example fetchmail -v transcript.6.2. An SNG Example.7.1. The pic2graph pipeline.8.1. Glade Hello, World.8.2. A sample m4 macro.8.3. A sample XSLT program.8.4. Taxonomy of languages — the pic source.8.5. Synthetic example of a fetchmailrc.8.6. RSA implementation using dc.9.1. Example of fetchmailrc syntax.9.2. Python structure dump of a fetchmail configuration.9.3. copy_instance metaclass code.9.4. Calling context for copy_instance.9.5. ascii usage screen.9.6. Desired output format for the star table.9.7. Master form of the star table.10.1. A .netrc example.10.2. X configuration example.18.1. groff1 markup example.18.2. man markup example.19.1. tar archive maker production.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Unix","slug":"Unix","permalink":"http://ipcreator.me/tags/Unix/"}]},{"title":"Things Every Hacker Once Knew","date":"2017-01-20T11:16:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/things-every-hacker-once-knew/","text":"Things Every Hacker Once Knew by Eric S. Raymond &#x65;&#x73;&#x72;&#64;&#x74;&#x68;&#x79;&#114;&#115;&#117;&#x73;&#46;&#x63;&#111;&#109; One fine day in January 2017 I was reminded of something I had half-noticed a few times over the previous decade. That is, younger hackers don’t know the bit structure of ASCII and the meaning of the odder control characters in it. This is knowledge every fledgling hacker used to absorb through their pores. It’s nobody’s fault this changed; the obsolescence of hardware terminals and the near-obsolescence of the RS-232 protocol is what did it. Tools generate culture; sometimes, when a tool becomes obsolete, a bit of cultural commonality quietly evaporates. It can be difficult to notice that this has happened. This document is a collection of facts about ASCII and related technologies, notably hardware serial terminals and RS-232 and modems. This is lore that was at one time near-universal and is no longer. It’s not likely to be directly useful today - until you trip over some piece of still-functioning technology where it’s relevant (like a GPS puck), or it makes sense of some old-fart war story. Even so, it’s good to know anyway, for cultural-literacy reasons. One thing this collection has that tends to be indefinite in the minds of older hackers is calendar dates. Those of us who lived through all this tend to have remembered order and dependencies but not exact timing; here, I did the research to pin a lot of that down. I’ve noticed that people have a tendency to retrospectively back-date the technologies that interest them, so even if you did live through the era it describes you might get a few surprises from reading this. There are lots of references to Unix in here because I am mainly attempting to educate younger open-source hackers working on Unix-derived systems such as Linux and the BSDs. If those terms mean nothing to you, the rest of this document probably won’t either. Hardware contextNowadays, when two computers talk to each other, it’s usually via TCP/IP over some physical layer you seldom need to care much about. And a “terminal” is actually a “terminal emulator”, a piece of software that manages part of your display and itself speaks TCP/IP. Before ubiquitous TCP/IP and bit-mapped displays things were very different. For most hackers that transition took place within a few years of 1992 - perhaps somewhat earlier if you had access to then-expensive workstation hardware. Before then there were video display terminals - VDTs for short. In the mid-1970s these had displaced an earlier generation of printing terminals derived from really old technology called a “teletype”, which had evolved around 1900 from Victorian telegraph networks. The very earliest versions of Unix in the late 1960s were written for these printing terminals, in particular for the Teletype Model 33 (aka ASR-33); the “tty” that shows up in Unix device names was a then-common abbreviation for “teletype”. In those pre-Internet days computers didn’t talk to each other much, and the way teletypes and terminals talked to computers was a hardware protocol called “RS-232” (or, if you’re being pedantic, “EIA RS-232C”) [1]. Before USB, when people spoke of a “serial” link, they meant RS-232, and sometimes referred to the equipment that spoke it as “serial terminals”. RS-232 had a very long service life; it was developed in the early 1960s, not originally for computer use but as a way for teletypewriters to talk to modems. Though it has passed out of general use and is no longer common knowledge, it’s not quite dead even today.I’ve been simplifying a bit here. There were other things besides RS-232 and serial terminals going on, notably on IBM mainframes. But they’ve left many fewer traces in current technology and its folklore. This is because the lineage of modern Unix passes back through a now-forgotten hardware category called a “minicomputer”, especially minicomputers made by the Digital Equipment Corporation. ASCII, RS-232 and serial terminals were part of the technology cluster around minicomputers - as was, for that matter, Unix itself. Minicomputers were wiped out by workstations and workstations by descendants of the IBM PC, but hackers old enough to remember the minicomputer era (mid-1960s to mid-1980s) tend still to get a bit misty-eyed about the DEC hardware they cut their teeth on. Often, however, nostalgia obscures how very underpowered those machines were. For example: a DEC VAX 11-780 minicomputer in the mid-1980s, used for timesharing and often supporting a dozen simultaneous users, had less than 1/1000 the processing power and less than 1/5000 times as much storage available as a low-end smartphone does in 2017. In fact, until well into the 1980s microcomputers ran slowly enough (and had poor enough RF shielding) that this was common knowledge: you could put an AM radio next to one and get a clue when it was doing something unusual, because either fundamentals or major subharmonics of the clock frequencies were in the range of human audibility. Nothing has run that slowly since the turn of the 21st century. The strange afterlife of the Hayes smartmodemAbout those modems: the word is a portmanteau for “modulator/demodulator”. Modems allowed digital signals to pass over copper phone wires - ridiculously slowly by today’s standards, but that’s how we did our primitive wide-area networking in pre-Internet times. It was not generally known back then that modems had first been invented in the late 1950s for use in military communications, notably the SAGE air-defense network; we just took them for granted. Today modems that speak over copper or optical fiber are embedded invisibly in the Internet access point in your basement; other varieties perform over-the-air signal handling for smartphones and tablets. A variety every hacker used to know about (and most of us owned) was the “outboard” modem, a separate box wired to your computer and your telephone line. Inboard modems (expansion cards for your computer) were also known, but never sold as well because being located inside the case made them vulnerable to RF noise, and the blinkenlights on an outboard were useful for diagnosing problems. Also, most hackers learned to interpret (at least to some extent) modem song - the beeping and whooshing noises the outboards made while attempting to establish a connection. The happy song of a successful connect was identifiably different from various sad songs of synchronization failure. These old-fashioned modems were, by today’s standards, unbelievably slow. Modem speeds increased from 110 bits per second back at the beginning of interactive computing to 56 kilobits per second just before the technology was effectively wiped out by wide-area Internet around the end of the 1990s, which brought in speeds of a megabit per second and more (20 times faster). For the longest stable period of modem technology after 1970, about 1984 to 1991, typical speed was 9600bps. This has left some traces; it’s why surviving serial-protocol equipment tends to default to a speed of 9600bps. There was a line of modems called “Hayes Smartmodems” that could be told to dial a number, or set parameters such as line speed, with command codes sent to the modem over its serial link from the machine. Every hacker used to know the “AT” prefix used for commands and that, for example, ATDT followed by a phone number would dial the number. Other modem manufacturers copied the Hayes command set and variants of it became near universal after 1981. What was not commonly known then is that the “AT” prefix had a helpful special property. That bit sequence (1+0 1000 0010 1+0 0010 1010 1+, where the plus suffix indicates one or more repetitions of the preceding bit) has a shape that makes it as easy as possible for a receiver to recognize it even if the receiver doesn’t know the transmit-line speed; this, in turn, makes it possible to automatically synchronize to that speed [2]. That property is still useful, and thus in 2017 the AT convention has survived in some interesting places. AT commands have been found to perform control functions on 3G and 4G cellular modems used in smartphones. On one widely deployed variety, “AT+QLINUXCMD=” is a prefix that passes commands to an instance of Linux running in firmware on the chip itself (separately from whatever OS might be running visibly on the phone). Preserving core valuesFrom about 1955 to 1975 - before semiconductors - the dominant technology in computer memory used tiny magnetic doughnuts strung on copper wires. The doughnuts were known as “ferrite cores” and main memory thus known as “core memory” or “core”. Unix terminology was formed in the early 1970s, and compounds like “in core” and “core dump” survived into the semiconductor era. Until as late as around 1990 it could still be assumed that every hacker knew from where these terms derived; even microcomputer hackers for which memory had always been semiconductor RAM tended to pick up this folklore rapidly on contact with Unix. After 2000, however, as multiprocessor systems became increasingly common even on desktops, “core” increasingly took on a conflicting meaning as shorthand for “processor core”. In 2017 “core” can still mean either thing, but the reason for the older usage is no longer generally understood and idioms like “in core” may be fading. 36-bit machines and the persistence of octalThere’a a power-of-two size hierarchy in memory units that we now think of as normal - 8 bit bytes, 16 or 32 or 64-bit words. But this did not become effectively universal until after 1983. There was an earlier tradition of designing computer architectures with 36-bit words.There was a time when 36-bit machines loomed large in hacker folklore and some of the basics about them were ubiquitous common knowledge, though cultural memory of this era began to fade in the early 1990s. Two of the best-known 36-bitters were the DEC PDP-10 and the Symbolics 3600 Lisp machine. The cancellation of the PDP-10 in ‘83 proved to be the death knell for this class of machine, though the 3600 fought a rear-guard action for a decade afterwards. Hexadecimal is a natural way to represent raw memory contents on machines with the power-of-two size hierarchy. But octal (base-8) representations of machine words were common on 36-bit machines, related to the fact that a 36-bit word naturally divides into 12 3-bit fields naturally represented as octal. In fact, back then we generally assumed you could tell which of the 32- or 36-bit phyla a machine belonged in by whether you could see digits greater than 7 in a memory dump. Here are a few things every hacker used to know that related to these machines: 36 bits was long enough to represent positive and negative integers to an accuracy of ten decimal digits, as was expected on mechanical calculators of the era. Standardization on 32 bits was unsuccessfully resisted by numerical analysts and people in scientific computing, who really missed that last 4 bits of accuracy. A “character” might be 9 bits on these machines, with 4 packed to a word. Consequently, keyboards designed for them might have both a meta key to assert bit 8 and a now-extinct extra modifier key (usually but not always called “Super”) that asserted bit 9. Sometimes this selected a tier of non-ASCII characters including Greek letters and mathematical symbols. It used also to be generally known that 36-bit architectures explained some unfortunate features of the C language. The original Unix machine, the PDP-7, featured 18-bit words corresponding to half-words on larger 36-bit computers. These were more naturally represented as six octal (3-bit) digits. The immediate ancestor of C was an interpreted language written on the PDP-7 and named B. In it, a numeric literal beginning with 0 was interpreted as octal. The PDP-7’s successor, and the first workhorse Unix machine was the PDP-11 (first shipped in 1970). It had 16-bit words - but, due to some unusual peculiarities of the instruction set, octal made more sense for its machine code as well. C, first implemented on the PDP-11, thus inherited the B octal syntax. And extended it: when an in-string backslash has a following digit, that was expected to lead an octal literal. The Interdata 32, VAX, and other later Unix platforms didn’t have those peculiarities; their opcodes expessed more naturally in hex. But C was never adjusted to prefer hex, and the surprising interpretation of leading 0 wasn’t removed. Because many later languages (Java, Python, etc) copied C’s low-level lexical rules for compatibility reasons, the relatively useless and sometimes dangerous octal syntax besets computing platforms for which three-bit opcode fields are wildly inappropriate, and may never be entirely eradicated [3]. The PDP-11 was so successful that architectures strongly influenced by it (notably, including Intel [4] and ARM microprocessors) eventually took over the world, killing off 36-bit machines. RS232 and its discontentsA TCP/IP link generally behaves like a clean stream of 8-bit bytes (formally, octets). You get your data as fast as the network can run, and error detection/correction is done somewhere down below the layer you can see. RS-232 was not like that. Two devices speaking it had to agree on a common line speed - also on how the byte framing works (the latter is why you’ll see references to “stop bits” in related documentation). Finally, error detection and correction was done in-stream, sort of. RS232 devices almost always spoke ASCII, and used the fact that ASCII only filled 7 bits. The top bit might be, but was not always, used as a parity bit for error detection. If not used, the top bit could carry data. You had to set your equipment at both ends for a specific combination of all of these. After about 1984 anything other than “8N1” - eight bits, no parity, one stop bit - became increasingly rare. Before that, all kinds of weird combinations were in use. Even parity (“E”) was more common than odd (“O”) and 1 stop bit more common than 2, but you could see anything come down a wire. And if you weren’t properly set up for it, all you got was “baud barf” - random 8-bit garbage rather than the character data you were expecting. This, in particular, is one reason the API for the POSIX/Unix terminal interface, termios(3), has a lot of complicated options with no obvious modern-day function. It had to be able to manipulate all these settings, and more. Another consequence was that passing binary data over an RS-232 link wouldn’t work if parity was enabled - the high bits would get clobbered. Other now-forgotten wide-area network protocols reacted even worse, treating in-band characters with 0x80 on as control codes with results ranging from amusing to dire. We had a term, “8-bit clean”, for networks and software that didn’t clobber the 0x80 bit. And we needed that term… Even the RS-232 physical connector varied. Standard RS-232 as defined in 1962 used a roughly D-shaped shell with 25 physical pins (DB-25), way more than the physical protocol actually required (you can support a minimal version with just three wires, and this was actually common). Twenty years later, after the IBM PC-AT introduced it in 1984, most manufacturers switched to using a smaller DB-9 connector (which is technically a DE-9 but almost nobody ever called it that). If you look at a PC with a serial port it is most likely to be a DB-9; confusingly, DB-25 came to be used for printer parallel ports (which originally had a very different connector) before those too were obsolesced by USB and Ethernet. Anybody who worked with this stuff had to keep around a bunch of specialized hardware - gender changers, DB-25-to-DB-9 adapters (and the reverse), breakout boxes, null modems, and other stuff I won’t describe in detail because it’s left no traces in today’s tech. Hackers of a certain age still tend to have these things cluttering their toolboxes or gathering dust in a closet somewhere. The main reason to still care about any of this (other than understanding greybeard war stories) is that some kinds of sensor and control equipment, routers, and IoT devices still speak RS-232, often wrapped inside a USB emulation. The most common devices that do this are probably GPS sensors designed to talk to computers (as opposed to handheld GPSes or car-navigation systems). Because of devices like GPSes, you may still occasionally need to know what an RS-232 “handshake line” is. These were originally used to communicate with modems; a terminal, for example, could change the state of the DTR (Data Terminal Ready) line to indicate that it was ready to receive, initiate, or continue a modem session. Later, handshake lines were used for other equipment-specific kinds of out-of-band signals. The most commonly re-used lines were DCD (data carrier detect) and RI (Ring Indicator). Three-wire versions of RS-232 omitted these handshake lines entirely. A chronic source of frustration was equipment at one end of your link that failed to supply an out-of-band signal that the equipment at the other end needed. The modern version of this is GPSes that fail to supply their 1PPS (a high-precision top-of-second pulse) over one of the handshake lines. Another significant problem was that an RS-232 device not actually sending data was undetectable without analog-level monitoring equipment. You couldn’t tell a working but silent device from one that had come unplugged or suffered a connection fault in its wiring. This caused no end of complications when troubleshooting and is a major reason USB was able to displace RS-232 after 1994.A trap for the unwary that opened up after about the year 2000 is that peripheral connectors labeled RS232 could have one of two different sets of voltage levels. If they’re pins or sockets in a DB9 or DB25 shell, the voltage swing between 1 and 0 bits can be as much as 50 volts, and is usually about 26. Bare connectors on a circuit board, or chip pins, increasingly came to use what’s called “TTL serial” - same signalling with a swing of 3.3 or (less often) 5 volts. You can’t wire standard RS232 to TTL serial directly; the link needs a device called a “level shifter”. If you connect without one, components on the TTL side will get fried. RS-232 passed out of common knowledge in the mid- to late 1990s, but didn’t finally disappear from general-purpose computers until around 2010. Standard RS-232 is still widely used on industrial controllers and in some niche applications, including point-of-sale systems and diagnostic consoles on commercial-grade routers. The TTL serial variant is often used on maker devices. UUCP and BBSes, the forgotten pre-InternetsEvery hacker over a certain age remembers either UUCP or the BBS scene. Many participated in both. In those days access to to the “real” net (ARPANET, which became Internet) was difficult if you weren’t affiliated with one of a select group of federal agencies, military contractors, or university research labs. So we made do with what we had, which was modems and the telephone network. UUCP stands for Unix to Unix Copy Program. Between its escape from Bell Labs in 1979 and the mass-market Internet explosion of the mid-1990s, it provided slow but very low-cost networking among Unix sites using modems and the phone network. UUCP was a store-and-forward system originally intended for propagating software updates, but its major uses rapidly became email and a thing called USENET (launched 1981) that was the ur-ancestor of Stack Overflow and other modern web fora. It supported topic groups for messages which, propagated from their point of origin through UUCP, would eventually flood to the whole network. In part, UUCP and USENET were a hack around the two-tier rate structure that then existed for phone calls, with “local” being flat-rate monthly and “long-distance” being expensively metered by the minute. UUCP traffic could be relayed across long distances by local hops.A direct descendant of USENET still exists, as Google Groups [5], but was much more central to the hacker culture before cheap Internet. Open source as we now know it germinated in USENET groups dedicated to sharing source code. Several conventions still in use today, like having project metadata files named README and NEWS and INSTALL, originated there in the early 1980s. Two key dates in USENET history were universally known. One was the Great Renaming in 1987, when the name hierarchy of USENET topic groups was reorganized. The other was the “September that never ended” in 1993, when the AOL commercial timesharing services gave its users access to USENET. The resulting vast flood of newbies proved difficult to acculturate. UUCP explains a quirk you may run across in old mailing-list archives: the bang-path address. UUCP links were point-to-point and you had to actually specify the route of your mail through the UUCP network; this led to people publishing addresses of the form “…!bigsite!foovax!barbox!user”, presuming that people who wanted to reach them would know how to reach bigsite. UUCP was notoriously difficult to configure, enough so that people who knew how often put that skill on their CVs in the justified expectation that it could land them a job. Meanwhile, in the microcomputer world, a different kind of store-and-forward evolved - the BBS (Bulletin-Board System). This was software running on a computer (after 1991 usually an MS-DOS machine) with one (or, rarely, more) attached modems that could accept incoming phone calls. Users (typically, just one user at a time!) would access the BBS using a their own modem and a terminal program; the BBS software would allow them to leave messages for each other, upload and download files, and sometimes play games. The first BBS, patterned after the community notice-board in a supermarket, was fielded in Chicago in 1978. Over the next eighteen years over a hundred thousand BBSes flashed in and out of existence, typically operated out of the sysop’s bedroom or garage with a spare computer. From 1984 the BBS culture evolved a primitive form of internetworking called “FidoNet” that supported cross-site email and a forum system broadly resembling USENET. During a very brief period after 1990, just before mass-market Internet, software with BBS-like capabilities but supporting multiple simultaneous modem users (and often offeing USENET access) got written for low-cost Unix systems. The end-stage BBSes, when they survived, moved to the Web and dropped modem access. The history of cellar.org chronicles this period. A handful of BBSes are still run by nostalgicists, and some artifacts from the culture are still preserved. But, like the UUCP network, the BBS culture as a whole collapsed when inexpensive Internet became widely available. Almost the only cultural memory of BBSes is around a family of file-transfer protocols - XMODEM, YMODEM, and ZMODEM - developed and used on BBSes. For hackers of that day who did not cut their teeth on minicomputers with native TCP/IP, these were a first introduction to concepts like packetization, error detection, and retransmission. To this day, hardware from at least one commercial router vendor accepts software patches by XMODEM upload through a serial port. Also roughly contemporaneous with USENET and the BBS culture, and also destroyed or absorbed by cheap Internet, were some commercial timesharing services supporting dialup access by modem, of which the best known were AOL (America Online) CompuServe, and GEnie. These provided BBS-like facilities. Every hacker knew of these, though few used them. They have left no traces at all in today’s hacker culture.Terminal confusion The software terminal emulators on modern Unix systems are the near-end - and probably final - manifestations of a long and rather confused history. It began with early displays sometimes called “glass TTYs” because they emulated teletypes - but less expensively, because they didn’t require consumables like paper. The phrase “dumb terminal” is equivalent. The first of these was shipped in 1969. The best-remembered of them is probably still the ADM-3 from 1975. The very earliest VDTs, like the ASR-33, could form only upper-case letters. An interesting hangover from that these devices was that, even though most VDTs made after 1975 could form lower-case letters, for many years afterwards Unix and Linux responded to an all-upper-case login by switching to an mode which upcased all input. If you created an account with an all-upper-case login name and a mixed-case password, hilarity ensued. If the password was also upper-case the hilarity was less desparate but still confusing for the user.The classic “smart terminal” VDT designs that have left a mark on later computing appeared during a relatively short period beginning in 1975. Devices like the Lear-Siegler ADM-3A (1976) and the DEC VT-100 (1978) inherited the 80-character line width of punched cards (longer than the 72-character line length of teletypes) and supported as many lines as could fit on an approximately 4:3 screen; they are the reason your software terminal emulator has a 24x80 or 25x80 default size. These terminals were called “smart” because they could interpret control codes to do things like addressing the cursor to any point on the screen in order to produce truly 2-dimensional displays [6]. The ability to do bold, underline or reverse-video highlighting also rapidly became common. Colored text and backgrounds, however, only became available a few years before VDTs were obsolesced; before that displays were monochromatic. Some had crude, low-resolution dot graphics; a few types supported black-and-white vector graphics.Early VDTs used a crazy variety of control codes. One of the principal relics of this era is the Unix terminfo database, which tracked these codes so terminal-using applications could do abstracted operations like “move the cursor” without being restricted to working with just one terminal type. The curses(3) library still used with software terminal emulators was originally intended to make this sort of thing easier. After 1979 there was an ANSI standard for terminal control codes, based on the DEC VT-100 (being supported in the IBM PC’s original screen driver gave it a boost) [7]. By the early 1990s ANSI conformance was close to universal in VDTs, which is why that’s what your software terminal emulator does. This whole technology category was rapidly wiped out in general-purpose computing, like dinosaurs after the Alvarez strike, when bit-mapped color displays on personal computers that could match the dot pitch of a monochrome VDT became relatively inexpensive, around 1992. The legacy VDT hardware lingered longest in dedicated point-of-sale systems, remaining not uncommon until as late as 2010 or so.It’s not true, as is sometime suggested, that heritage from the VDT era explains the Unix command line - that actually predated VDTs, going back to the last generation of printing terminals in the late 1960s and early 1970s. Every hacker once knew that this is why we often speak of of “printing” output when we mean sending it to standard output that is normally connected to a terminal emulator.What the VDT era does explain is some of our heritage games (see next section) and a few surviving utility programs like vi(1), top(1) and mutt(1). These are what advanced visual interfaces looked like in the VDT era, before bitmapped displays. Games before GUIsBefore bit-mapped color displays became common and made graphics-intensive games the norm, there was a vigorous tradition of games that required only textual interfaces or the character-cell graphics on a VDT. Every hacker once knew what the phrase “You are in a maze of twisty little passages, all alike” meant, and often used variants about confusing situations in real life (For example, “You are in a maze of twisty little technical standards, all different”). It was from the very first dungeon-crawling adventure game, Colossal Cave Adventure (1976). People who knew this game from its beginnings often thought of it as ADVENT, after its 6-character filename on the PDP-10 where it first ran. ADVENT had a direct successor that was even more popular - Zork, first released in 1979 by hackers at MIT and later successfully commercialized. This game is why every hacker once knew that a zorkmid was the currency of the Great Underground Empire, and that if you wander around in dark places without your lantern lit you might be eaten by a grue. There was a another family of games that took a different, more visual approach to dungeon-crawling. They are generally called “roguelikes”, after one of the earliest widely-distributed games in this group, Rogue from 1980. They featured top-down, maplike views of dungeon levels through which the player would wander battling monsters and seeking treasure. The most widely played games in this group were Hack (1982) and Nethack (1987). Nethack is a notable for having been one of the earliest programs in which the development group was consciously organized as a distributed collaboration over the Internet; at the time, this was a sufficiently novel idea to be advertised in the project’s name. These games gradually passed out of universal common knowledge after the mid-1990s, but they retain devoted minority followings today. Their fans accurately point out that the primitive state of interface design encouraged concentration on plot and story values, leading to a surprisingly rich imaginative experience. ASCIIASCII, the American Standard Code for Information Interchange, evolved in the early 1960s out of a family of character codes used on teletypes.ASCII, unlike a lot of other early character encodings, is likely to live forever - because by design the low 127 code points of Unicode are ASCII. If you know what UTF-8 is (and you should) every ASCII file is correct UTF-8 as well.The following table describes ASCII-1967, the version in use today.Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex 0 00 NUL 16 10 DLE 32 20 48 30 0 64 40 @ 80 50 P 96 60 ` 112 70 p 1 01 SOH 17 11 DC1 33 21 ! 49 31 1 65 41 A 81 51 Q 97 61 a 113 71 q 2 02 STX 18 12 DC2 34 22 “ 50 32 2 66 42 B 82 52 R 98 62 b 114 72 r 3 03 ETX 19 13 DC3 35 23 # 51 33 3 67 43 C 83 53 S 99 63 c 115 73 s 4 04 EOT 20 14 DC4 36 24 $ 52 34 4 68 44 D 84 54 T 100 64 d 116 74 t 5 05 ENQ 21 15 NAK 37 25 % 53 35 5 69 45 E 85 55 U 101 65 e 117 75 u 6 06 ACK 22 16 SYN 38 26 &amp; 54 36 6 70 46 F 86 56 V 102 66 f 118 76 v 7 07 BEL 23 17 ETB 39 27 ‘ 55 37 7 71 47 G 87 57 W 103 67 g 119 77 w 8 08 BS 24 18 CAN 40 28 ( 56 38 8 72 48 H 88 58 X 104 68 h 120 78 x 9 09 HT 25 19 EM 41 29 ) 57 39 9 73 49 I 89 59 Y 105 69 i 121 79 y 10 0A LF 26 1A SUB 42 2A * 58 3A : 74 4A J 90 5A Z 106 6A j 122 7A z 11 0B VT 27 1B ESC 43 2B + 59 3B ; 75 4B K 91 5B [ 107 6B k 123 7B { 12 0C FF 28 1C FS 44 2C , 60 3C &lt; 76 4C L 92 5C \\ 108 6C l 124 7C | 13 0D CR 29 1D GS 45 2D - 61 3D = 77 4D M 93 5D ] 109 6D m 125 7D } 14 0E SO 30 1E RS 46 2E . 62 3E &gt; 78 4E N 94 5E ^ 110 6E n 126 7E ~ 15 0F SI 31 1F US 47 2F / 63 3F ? 79 4F O 95 5F _ 111 6F o 127 7F DEL It used to be common knowledge that the original 1963 ASCII had been sightly different. It lacked tilde and vertical bar; 5E was an up-arrow rather than a caret, and 5F was a left arrow rather than underscore. Some early adopters (notably DEC) held to the 1963 version.If you learned your chops after 1990 or so, the mysterious part of this is likely the control characters, code points 0-31. You probably know that C uses NUL as a string terminator. Others, notably LF = Line Feed and HT = Horizontal Tab, show up in plain text. But what about the rest? Many of these are remnants from teletype protocols that have either been dead for a very long time or, if still live, are completely unknown in computing circles. A few had conventional meanings that were half-forgotten even before Internet times. A very few are still used in binary data protocols today. Here’s a tour of the meanings these had in older computing, or retain today. If you feel an urge to send me more, remember that the emphasis here is on what was common knowledge back in the day. If I don’t know it now, we probably didn’t generally know it then. NUL (Null)Survives as the string terminator in C. SOH (Start of Heading)Rarely used (as Ctrl-A) as a section divider in otherwise textual formats. Some versions of Unix mailbox format used it as a message divider. One very old version-control system (SCCS) did something similar. STX (Start of Text), ETX (End of Text)Very rarely used as packet or control-sequence delimiters. You will probably never see this, and the only place I’ve ever seen it was on a non-Unix OS in the early 1980s. ETX is Ctrl-C, which is a SIGINT interrupt character on Unix systems, but that has nothing to do with its ASCII meaning per se and probably derives from abbreviating the word “Cancel”. EOT (End of Transmission)As Ctrl-D, the way you type “End of file” to a Unix terminal. ENQ (Enquiry)In the days of hardware serial terminals, there was a convention that if a computer sent ENQ to a terminal, it should reply with terminal type identification. While this was not universal, it at least gave computers a fighting chance of autoconfiguring what capabilities it could assume the terminal to have. ACK (Acknowledge)It used to be common for wire protocols written in ASCII to use ENQ/ACK as a handshake, sometimes with NAK as a failure indication. Hackers used to use ACK in speech as “I hear you” and were a bit put out when this convention was disrupted in the 1980s by Bill The Cat’s “Ack! Thppt!” BEL (Bell)Make the bell ring on the teletype - an attention signal. This often worked on VDTs as well, but is no longer reliably the default on software terminal emulators. Some map it to a visual indication like flashing the title bar. BS (Backspace)Still does what it says on the tin, though there has been some historical confusion over whether the backspace key on a keyboard should behave like BS (nondestructive cursor move) or DEL (backspace and delete). Never used in textual data protocols. HT (Horizontal tab)Still does what it says on the tin. Sometimes used as a field separator in Unix textual file formats, but this is now old-fashioned and declining in usage. LF (Line Feed)The Unix textual end-of-line. Printing terminals interpreted it as “scroll down one line”; the Unix tty driver would normally wedge in a CR right after it on output. VT (Vertical Tab)In the days of printing terminals this often caused them to scroll down a configurable number of lines. VDTs had any number of possible behaviors; at least some pre-ANSI ones interpreted VT as “scroll up one line”. The only reason anybody remembers this one at all is that it persisted in Unix definitions of what a whitespace character is, even though it’s now extinct in the wild. FF (Form Feed)Eject the current page from your printing terminal. Many VDTs interpreted this as a “clear screen” instruction. Software terminal emulators sometimes still do. CR (Carriage Return)It is now possible that the reader has never seen a typewriter, so this needs explanation: “carriage return” is the operation of moving your print head or cursor to the left margin. Windows, other non-Unix operating systems, and some Internet protocols (such as SMTP) tend to use CR-LF as a line terminator, rather than bare LF. Pre-Unix MacOS used a bare CR. SO (Shift Out), SI (Shift In)Escapes to and from an alternate character set. Unix software used to emit them to drive pre-ANSI VDTs that interpreted them that way, but native Unix usage is rare to nonexistent. DLE (Data Link Escape)Sometimes used as a packet-framing character in binary protocols. That is, a packet starts with a DLE, ends with a DLE, and if one of the interior data bytes matches DLE it is doubled. DC[1234] (Device Control [1234])Never to my knowledge used specially after teletypes. However: there was a common software flow-control protocol, used over ASCII but separate from it, in which XOFF (DC3) was used as a request to pause transmission and XON (DC1) was used as a request to resume transmission. As Ctrl-S and Ctrl-Q these were implemented in the Unix terminal driver and long outlived their origin in the Model 33 Teletype. And not just Unix; this was implemented in CP/M and DOS, too. NAK (Negative Acknowledge)Never to my knowledge used specially after teletypes, but it would have been unsurprising to anybody if a device-control protocol used it as a negative response to ENQ. SYN (Synchronous Idle)Never to my knowledge used specially after teletypes. Be careful not to confuse this with the SYN (synchronization) packet used in TCP/IP’s SYN SYN-ACK initialization sequence. ETB (End of Transmission Block)Never to my knowledge used specially after teletypes. CAN (Cancel), EM (End of Medium)Never to my knowledge used specially after teletypes. SUB (Substitute)DOS and Windows use Ctrl-Z (SUB) as an end-of-file character; this is unrelated to its ASCII meaning. It was common knowledge then that this use of ^Z had been inherited from a now largely forgotten earlier OS called CP/M (1974), and into CP/M from earlier DEC minicomputer OSes such as RSX-11 (1972). ESC (Escape)Still commonly used as a control-sequence introducer. This usage is especially associated with the control sequences recognized by VT100 and ANSI-standard VDTs, and today by essentially all software terminal emulators[FGRU]S ({Field|Group|Record|Unit} Separator)Never to my knowledge used specially after teletypes. FS, as Ctrl-\\, sends SIGQUIT under some Unixes, but this has nothing to do with ASCII. Ctrl-] (GS) is the exit character from telnet, but this also has nothing to do with its ASCII meaning. DEL (Delete)Usually an input character meaning “backspace and delete”. Under older Unix variants, sometimes a SIGINT interrupt character.Not all of these were so well known that any hacker could instantly map from mnemonic to binary, or vice-versa. The well-known set was roughly NUL, BEL, BS, HT, LF, FF, CR, ESC, and DEL.There are a few other bits of ASCII lore worth keeping in mind…The Control modifier on your keyboard basically clears the top three bits of whatever character you type, leaving the bottom five and mapping it to the 0..31 range. So, for example, Ctrl-SPACE, Ctrl-@, and Ctrl-` all mean the same thing: NUL.A Meta or Alt key on a VDT added 128 to the ASCII keycode for whatever it’s modifying (probably - on a few machines with peculiar word lengths they did different things). Software terminal emulators have more variable behavior; many of them now simply insert an ESC before the modified key, which Emacs treats as equivalent to adding 128.Very old keyboards used to do Shift just by toggling the 32 or 16 bit, depending on the key; this is why the relationship between small and capital letters in ASCII is so regular, and the relationship between numbers and symbols, and some pairs of symbols, is sort of regular if you squint at it. The ASR-33, which was an all-uppercase terminal, even let you generate some punctuation characters it didn’t have keys for by shifting the 16 bit; thus, for example, Shift-K (0x4B) became a [ (0x5B) Key datesThese are dates that every hacker knew were important at the time, or shortly afterwards. I’ve tried to concentrate on milestones for which the date - or the milestone itself - seems to have later passed out of folk memory.1961MIT takes delivery of a PDP-1. The first recognizable ancestor of the hacker culture of today rapidly coalesces around it.1969Ken Thompson begins work on what will become Unix. First commercial VDT ships; it’s a glass TTY. First packets exchanged on the ARPANET, the direct ancestor of today’s Internet.1970DEC PDP-11 first ships; architectural descendants of this machine, including later Intel microprocessors, will come to dominate computing.1973Interdata 32 ships; the long 32-bit era begins [8]. Unix Edition 5 (not yet on the Interdata) escapes Bell Labs to take root at a number of educational institutions. The XEROX Alto pioneers the “workstation” - a networked personal computer with a high-resolution display and a mouse.1975First Altair 8800 ships. Beginning of heroic age of microcomputers. First 24x80 and 25x80 “smart” (addressable-cursor) VDTs. ARPANET declared “operational”, begins to spread to major universities.1976“Lions’ Commentary on UNIX 6th Edition, with Source Code” released. First look into the Unix kernel source for most hackers, and was a huge deal in those pre-open-source days.1977Unix ported to the Interdata. First version with a kernel written largely in C rather than machine-dependent assembler.1978First BBS launched - CBBS, in Chicago.1981First IBM PC ships. End of the heroic age of micros. TCP/IP is implemented on a VAX-11/780 under 4.1BSD Unix; ARPANET and Unix cultures begin to merge.1982Sun Microsystems founded. Era of commercial Unix workstations begins.1983PDP-10 canceled. This is effectively the end of 36-bit architectures anywhere outside of deep mainframe country, though Symbolics Lisp machines hold out a while longer. ARPANET, undergoing some significant technical changes, becomes Internet.1984AT&amp;T begins a largely botched attempt to commercialize Unix, clamping down on access to source code. In the BBS world, FidoNet is invented.1985RMS published GNU Manifesto. This is also roughly the year the C language became the dominant lingua franca of both systems and applications programming, eventually displacing earlier compiled language so completely that they are almost forgotten.1986Intel 386 ships; end of the line for 8- and 16-bit PCs. Consumer-grade hardware in this class wouldn’t be generally available until around 1989, but after that would rapidly surpass earlier 32-bit minicomputers in and workstations capability.1991Linux and the World Wide Web are (separately) launched.1992Bit-mapped color displays with a dot pitch matching that of a monochrome VDT (and a matching ability to display crisp text at 80x25) ship on consumer-grade PCs. Bottom falls out of the VDT market.1993Linux gets TCP/IP capability, moves from hobbyist’s toy to serious OS. America OnLine offers USENET access to its uses; “September That Never Ended” begins.1994Mass-market Internet takes off in the U.S. USB promulgated.1995-1996Peak years of UUCP/USENET and the BBS culture, then collapse under pressure from mass-market Internet.1997I first give the “Cathedral and Bazaar” talk.1999Peak year of the dot-com bubble. End of workstation era: Market for Suns and other proprietary Unix workstations collapses under pressure from Linux running on PCs.2005Major manufacturers cease production of cathode-ray tubes in favor of flat-panel displays. Flat-panels have been ubiquitous on new hardware since about 2003. There is a brief window until about 2007 during which high-end CRTs no longer in production still exceed the resolution of flat-panel displays and are still sought after. Also in 2005, AOL drops USENET support and Endless September ends.2007-200864-bit transition in mass market PCs. The 32-bit era ends. The first smartphones ship. Request to contributorsA lot of people reading this have been seized by the urge to send me some bit of lore or trivia for inclusion. Thank you, but bear in mind that the most important choice is what to leave out. Here are some guidelines: I’m trying to describe common knowledge at the time. That means not every bit of fascinating but obscure trivia belongs here.Anything from a tech generation before early minis - in particular the era of mainframes, punched cards, and paper tape - is out of scope. I gotta draw the line somewhere, and it’s there. Stories about isolated survivals of old tech today are not interesting if the tech wasn’t once common knowledge.Please do not send me timeline entries for dates which you think are important unless you think the date has been generally been forgotten, or is in serious danger of same. Supporting this workIf you enjoyed this, please contribute at my Patreon page so I won’t be forced to get a $DAYJOB and no longer have time to think up or write things like this document. I work on a lot of more serious projects too, including critical network infrastructure. So give generously; the civilization you save could be your own. Related ReadingHow To Become A HackerThe Lost Art of C Structure Packing Change history1.0: 2017-01-26Initial version.1.1: 2017-01-27Pin down the date DB-9 came in. Added a minor section on the persistence of octal. More on the afterlife of RS-232.1.2: 2017-01-29More about the persistence of octal. Mention current-loop ASR-33s. 36-bit machines and their lingering influence. Explain ASCII shift. A bit more about ASCII-1963. Some error correction.1.3: 2017-01-30Added “Key dates” and “Request to contributors”.1.4: 2017-02-03The curious survival of the Hayes AT command set.1.5: 2017-02-04TTL in serial and maker devices. The AT Hayes prefix explained. UUCP and long distance rates. Reference to space-cadet keyboard removed, as it turned out to ship a 32-bit word. Improved description of ASCII shift.1.6: 2017-02-08How VDTs explain some heritage programs, and how bitmapped displays eventually obsolesced them. Explain why the ADM-3 was called “dumb” even though it was smart.1.7: 2017-02-09The BBS subculture. XMODEM/YMODEM/ZMODEM. Commercial timesharing. Two dates in USENET history.1.8: 2017-02-14Heritage games. The legacy of all-uppercase terminals. Where README came from. What “core” is. The ARPANET. Monitoring your computer with a radio. Actually, there was an even older style of tty interface called “current loop” that the ASR-33 originally used; in the 1970s dual-mode ASR-33s that could also speak RS-232 began to ship, and RS-232 eventually replaced current loop entirely. A full explanation of the magic of the AT prefix can be found at http://esr.ibiblio.org/?p=7333&amp;cpage=1#comment-1802568 Python 3 and Perl 6 have at least gotten rid of the dangerous leading-0-for-octal syntax, but Go kept it Early Intel microprocessors weren’t much like the 11, but the 80286 and later converged with it in important ways. The old free-floating USENET still exists too, but Google Groups is where you can find what has been preserved of the historical USENET archives. Confusingly, the ADM-3A (which could address any screen cell) was described in marketing copy as a “dumb” terminal, not a “smart” one. This is because there was a rival definition of “smart” as capable of doing local editing of the screen without involving the remote computer, like an IBM 3270. But since minicomputers never used that capability this definition was never live in the Unix world, and has mostly faded out of use. It was not commonly known that the VT100 was designed to fit a 1976 stanfard called ECMA-48; ANSI simply adopted it. There were a few 32-bit minis before the Interdata, but they seem to have been designed for real-time or other non-timesharing uses.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"Teach Yourself Programming in Ten Years","date":"2017-01-20T09:22:06.000Z","path":"2017/01/20/SmartAI/ProgramAI/Master/teach-yourself-programming-in-ten-years/","text":"Teach Yourself Programming in Ten YearsPeter Norvig Why is everyone in such a rush?Walk into any bookstore, and you’ll see how to Teach Yourself Java in 24 Hours alongside endless variations offering to teach C, SQL, Ruby, Algorithms, and so on in a few days or hours. The Amazon advanced search for [title: teach, yourself, hours, since: 2000 and found 512 such books. Of the top ten, nine are programming books (the other is about bookkeeping). Similar results come from replacing “teach yourself” with “learn” or “hours” with “days.” The conclusion is that either people are in a big rush to learn about programming, or that programming is somehow fabulously easier to learn than anything else. Felleisen et al. give a nod to this trend in their book How to Design Programs, when they say “Bad programming is easy. Idiots can learn it in 21 days, even if they are dummies.” The Abtruse Goose comic also had their take. Let’s analyze what a title like Teach Yourself C++ in 24 Hours could mean: Teach Yourself: In 24 hours you won’t have time to write several significant programs, and learn from your successes and failures with them. You won’t have time to work with an experienced programmer and understand what it is like to live in a C++ environment. In short, you won’t have time to learn much. So the book can only be talking about a superficial familiarity, not a deep understanding. As Alexander Pope said, a little learning is a dangerous thing. C++: In 24 hours you might be able to learn some of the syntax of C++ (if you already know another language), but you couldn’t learn much about how to use the language. In short, if you were, say, a Basic programmer, you could learn to write programs in the style of Basic using C++ syntax, but you couldn’t learn what C++ is actually good (and bad) for. So what’s the point? Alan Perlis once said: “A language that doesn’t affect the way you think about programming, is not worth knowing”. One possible point is that you have to learn a tiny bit of C++ (or more likely, something like JavaScript or Processing) because you need to interface with an existing tool to accomplish a specific task. But then you’re not learning how to program; you’re learning to accomplish that task. in 24 Hours: Unfortunately, this is not enough, as the next section shows. Teach Yourself Programming in Ten YearsResearchers (Bloom (1985), Bryan &amp; Harter (1899), Hayes (1989), Simmon &amp; Chase (1973)) have shown it takes about ten years to develop expertise in any of a wide variety of areas, including chess playing, music composition, telegraph operation, painting, piano playing, swimming, tennis, and research in neuropsychology and topology. The key is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes. Then repeat. And repeat again. There appear to be no real shortcuts: even Mozart, who was a musical prodigy at age 4, took 13 more years before he began to produce world-class music. In another genre, the Beatles seemed to burst onto the scene with a string of #1 hits and an appearance on the Ed Sullivan show in 1964. But they had been playing small clubs in Liverpool and Hamburg since 1957, and while they had mass appeal early on, their first great critical success, Sgt. Peppers, was released in 1967. Malcolm Gladwell has popularized the idea, although he concentrates on 10,000 hours, not 10 years. Henri Cartier-Bresson (1908-2004) had another metric: “Your first 10,000 photographs are your worst.” (He didn’t anticipate that with digital cameras, some people can reach that mark in a week.) True expertise may take a lifetime: Samuel Johnson (1709-1784) said “Excellence in any department can be attained only by the labor of a lifetime; it is not to be purchased at a lesser price.” And Chaucer (1340-1400) complained “the lyf so short, the craft so long to lerne.” Hippocrates (c. 400BC) is known for the excerpt “ars longa, vita brevis”, which is part of the longer quotation “Ars longa, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile”, which in English renders as “Life is short, [the] craft long, opportunity fleeting, experiment treacherous, judgment difficult.” Of course, no single number can be the final answer: it doesn’t seem reasonable to assume that all skills (e.g., programming, chess playing, checkers playing, and music playing) could all require exactly the same amount of time to master, nor that all people will take exactly the same amount of time. As Prof. K. Anders Ericsson puts it, “In most domains it’s remarkable how much time even the most talented individuals need in order to reach the highest levels of performance. The 10,000 hour number just gives you a sense that we’re talking years of 10 to 20 hours a week which those who some people would argue are the most innately talented individuals still need to get to the highest level.” So You Want to be a ProgrammerHere’s my recipe for programming success: Get interested in programming, and do some because it is fun. Make sure that it keeps being enough fun so that you will be willing to put in your ten years/10,000 hours. Program. The best kind of learning is learning by doing. To put it more technically, “the maximal level of performance for individuals in a given domain is not attained automatically as a function of extended experience, but the level of performance can be increased even by highly experienced individuals as a result of deliberate efforts to improve.” (p. 366) and “the most effective learning requires a well-defined task with an appropriate difficulty level for the particular individual, informative feedback, and opportunities for repetition and corrections of errors.” (p. 20-21) The book Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life is an interesting reference for this viewpoint. Talk with other programmers; read other programs. This is more important than any book or training course.If you want, put in four years at a college (or more at a graduate school). This will give you access to some jobs that require credentials, and it will give you a deeper understanding of the field, but if you don’t enjoy school, you can (with some dedication) get similar experience on your own or on the job. In any case, book learning alone won’t be enough. “Computer science education cannot make anybody an expert programmer any more than studying brushes and pigment can make somebody an expert painter” says Eric Raymond, author of The New Hacker’s Dictionary. One of the best programmers I ever hired had only a High School degree; he’s produced a lot of great software, has his own news group, and made enough in stock options to buy his own nightclub. Work on projects with other programmers. Be the best programmer on some projects; be the worst on some others. When you’re the best, you get to test your abilities to lead a project, and to inspire others with your vision. When you’re the worst, you learn what the masters do, and you learn what they don’t like to do (because they make you do it for them). Work on projects after other programmers. Understand a program written by someone else. See what it takes to understand and fix it when the original programmers are not around. Think about how to design your programs to make it easier for those who will maintain them after you. Learn at least a half dozen programming languages. Include one language that emphasizes class abstractions (like Java or C++), one that emphasizes functional abstraction (like Lisp or ML or Haskell), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), and one that emphasizes parallelism (like Clojure or Go). Remember that there is a “computer” in “computer science”. Know how long it takes your computer to execute an instruction, fetch a word from memory (with and without a cache miss), read consecutive words from disk, and seek to a new location on disk. (Answers here.) Get involved in a language standardization effort. It could be the ANSI C++ committee, or it could be deciding if your local coding style will have 2 or 4 space indentation levels. Either way, you learn about what other people like in a language, how deeply they feel so, and perhaps even a little about why they feel so. Have the good sense to get off the language standardization effort as quickly as possible.With all that in mind, its questionable how far you can get just by book learning. Before my first child was born, I read all the How To books, and still felt like a clueless novice. 30 Months later, when my second child was due, did I go back to the books for a refresher? No. Instead, I relied on my personal experience, which turned out to be far more useful and reassuring to me than the thousands of pages written by experts. Fred Brooks, in his essay No Silver Bullet identified a three-part plan for finding great software designers: Systematically identify top designers as early as possible. Assign a career mentor to be responsible for the development of the prospect and carefully keep a career file. Provide opportunities for growing designers to interact and stimulate each other. This assumes that some people already have the qualities necessary for being a great designer; the job is to properly coax them along. Alan Perlis put it more succinctly: “Everyone can be taught to sculpt: Michelangelo would have had to be taught how not to. So it is with the great programmers”. Perlis is saying that the greats have some internal quality that transcends their training. But where does the quality come from? Is it innate? Or do they develop it through diligence? As Auguste Gusteau (the fictional chef in Ratatouille) puts it, “anyone can cook, but only the fearless can be great.“ I think of it more as willingness to devote a large portion of one’s life to deliberative practice. But maybe fearless is a way to summarize that. Or, as Gusteau’s critic, Anton Ego, says: “Not everyone can become a great artist, but a great artist can come from anywhere.” So go ahead and buy that Java/Ruby/Javascript/PHP book; you’ll probably get some use out of it. But you won’t change your life, or your real overall expertise as a programmer in 24 hours or 21 days. How about working hard to continually improve over 24 months? Well, now you’re starting to get somewhere… References Bloom, Benjamin (ed.) Developing Talent in Young People, Ballantine, 1985. Brooks, Fred, No Silver Bullets, IEEE Computer, vol. 20, no. 4, 1987, p. 10-19. Bryan, W.L. &amp; Harter, N. “Studies on the telegraphic language: The acquisition of a hierarchy of habits. Psychology Review, 1899, 8, 345-375 Hayes, John R., Complete Problem Solver Lawrence Erlbaum, 1989. Chase, William G. &amp; Simon, Herbert A. “Perception in Chess” Cognitive Psychology, 1973, 4, 55-81. Lave, Jean, Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life, Cambridge University Press, 1988. Answers Approximate timing for various operations on a typical PC:execute typical instruction 1/1,000,000,000 sec = 1 nanosecfetch from L1 cache memory 0.5 nanosecbranch misprediction 5 nanosecfetch from L2 cache memory 7 nanosecMutex lock/unlock 25 nanosecfetch from main memory 100 nanosecsend 2K bytes over 1Gbps network 20,000 nanosecread 1MB sequentially from memory 250,000 nanosecfetch from new disk location (seek) 8,000,000 nanosecread 1MB sequentially from disk 20,000,000 nanosecsend packet US to Europe and back 150 milliseconds = 150,000,000 nanosecAppendix: Language Choice Several people have asked what programming language they should learn first. There is no one answer, but consider these points: Use your friends. When asked “what operating system should I use, Windows, Unix, or Mac?”, my answer is usually: “use whatever your friends use.” The advantage you get from learning from your friends will offset any intrinsic difference between OS, or between programming languages. Also consider your future friends: the community of programmers that you will be a part of if you continue. Does your chosen language have a large growing community or a small dying one? Are there books, web sites, and online forums to get answers from? Do you like the people in those forums? Keep it simple. Programming languages such as C++ and Java are designed for professional development by large teams of experienced programmers who are concerned about the run-time efficiency of their code. As a result, these languages have complicated parts designed for these circumstances. You’re concerned with learning to program. You don’t need that complication. You want a language that was designed to be easy to learn and remember by a single new programmer. Play. Which way would you rather learn to play the piano: the normal, interactive way, in which you hear each note as soon as you hit a key, or “batch” mode, in which you only hear the notes after you finish a whole song? Clearly, interactive mode makes learning easier for the piano, and also for programming. Insist on a language with an interactive mode and use it. Given these criteria, my recommendations for a first programming language would be Python or Scheme. Another choice is Javascript, not because it is perfectly well-designed for beginners, but because there are so many online tutorials for it, such as Khan Academy’s tutorial. But your circumstances may vary, and there are other good choices. If your age is a single-digit, you might prefer Alice or Squeak or Blockly (older learners might also enjoy these). The important thing is that you choose and get started. Appendix: Books and Other Resources Several people have asked what books and web pages they should learn from. I repeat that “book learning alone won’t be enough” but I can recommend the following:Scheme: Structure and Interpretation of Computer Programs (Abelson &amp; Sussman) is probably the best introduction to computer science, and it does teach programming as a way of understanding the computer science. You can see online videos of lectures on this book, as well as the complete text online. The book is challenging and will weed out some people who perhaps could be successful with another approach. Scheme: How to Design Programs (Felleisen et al.) is one of the best books on how to actually design programs in an elegant and functional way. Python: Python Programming: An Intro to CS (Zelle) is a good introduction using Python. Python: Several online tutorials are available at Python.org. Oz: Concepts, Techniques, and Models of Computer Programming (Van Roy &amp; Haridi) is seen by some as the modern-day successor to Abelson &amp; Sussman. It is a tour through the big ideas of programming, covering a wider range than Abelson &amp; Sussman while being perhaps easier to read and follow. It uses a language, Oz, that is not widely known but serves as a basis for learning other languages. &lt; Notes T. Capey points out that the Complete Problem Solver page on Amazon now has the “Teach Yourself Bengali in 21 days” and “Teach Yourself Grammar and Style” books under the “Customers who shopped for this item also shopped for these items” section. I guess that a large portion of the people who look at that book are coming from this page. Thanks to Ross Cohen for help with Hippocrates.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://ipcreator.me/tags/Algorithm/"}]},{"title":"十分钟后开始使用英语","date":"2017-01-19T18:13:06.000Z","path":"2017/01/20/MyShare/how-to-use-english/","text":"原文作者：李笑来，十分钟后开始使用英语…… 阅读这一篇文章，最多需要十分钟而已，之后你就可以开始使用英语了。学习英语的最少必要知识是什么呢？ 学会音标 学会查词典 学会查语法书 学会正确地提问 养成最基本语言学习习惯 学会音标音标只是一个符号系统。首先，任何人花上一下午就都可以学会。其次，千万别信那种胡说八道：“外国人都不用音标的”。先说说我们自己的母语，你什么时候见过一个受过教育的人不会用拼音的？遇到生词生字的时候，连拼音都不会的话，就算查到了，也不知道那字或词如何读。英语世界更是如此，要知道英语是目前地球上词汇量最多的语言，也就是说，在英语世界里，任何人遇到生词的概率都要大出许多许多倍 —— 只要是个正常受过教育的人，怎么可能不去查词典？怎么可能甘心于查了词典之后竟然不懂如何发音？ 学习音标真的很简单。 从任何一本有文本的有声书中截取一段大约三五分钟的录音，然后把电子书的文本拷贝出来，粘贴复制到这个网站提供的工具里：http://upodn.com/phon.php ，然后你就会得到一个英语与音标对应的文本。（我是如何知道这个网站的？Google 呗 —— ‘Phonetic Transcription’……）三五分钟的语音中（大约三五百个词）一定包含了所有的音素（辅音、元音）……一边看音标文本文件，一边反复跟读这段文本……一个下午，任何一个正常成年人都能搞定。 学会查词典查词典，是学习语言的必需习惯 —— 正如学习是生活的必需习惯一样，也正如翻阅文档是开发者必需习惯一样，其实，哪个领域都是一样的。 遇到生词就查。对，每一个。查着查着就越查越少了 —— 这是一定的。那些告诉你，“遇到生词（先）不（用）查，先猜”的人，让他们去屎。望文生义的笨蛋说的就是他们。 一句话里感觉没有生词，可就是看不懂，原因可能是某个单词有另外的词义，而你却只知道最常用的词义。比如，“down”这个单词，竟然还可以做名词使用，意思是“小鸟小鸡身上的软毛”…… 那可能是有“你全都认识的词构成的你完全猜不到的词义”造成的，比如“purple passage”，“purple”你认识，“紫色的”，“passage”你也认识，“文章”，但“purple passage”是“辞藻过分华丽，金玉其外败絮其中的文章” —— 你可能就不知道了。 还有一种情况是，语法结构弄不明白…… 比如，“as” 有很多用法，到底是哪一个呢？那就走下一步：查语法书。 学会查语法书语法书是用来查的，不是用来背的 —— 你啥时候见过人们背地图？ 一张地图拿过来，知道“上北下南左西右东”，以及“少量标记符号”（比如，公交线长什么样，地铁线长什么样）这两个最少必要知识之后，就可以开始查地图了，不是吗？ 语法书也一样，除了你在初中的时候已经学过的一些基础语法概念，比如“名词”、“动词”、“形容词”、“副词”什么的之外，你还需要知道另外一个概念：“功能词”。什么叫功能词呢？就是那些在语法书的附录里，带着页码编号的词…… 你应该找个时间，比如一下午，大概翻翻那些功能词都有哪些，有个印象就好。 然后，在遇到“没有生词、没有不了解的词义、没有不认识的词组，但就是读不懂的句子”的时候，仔细看看那句子里有没有功能词存在？有的话，去查查语法书，在附录里找到对应的页码（可能不止一个），按图索骥地查下去，一定能找到答案…… 你以为你遇到过的英语老师啥都懂吗？不是的！他们就是比学生多一个技能：遇到问题的时候，他们懂得如何查词典，如何查语法书…… 哪个领域都是一样的 —— 你以为“高级程序员”什么都懂吗？某种意义上，他们只比那些“低级程序员”多一个技能：遇到问题的时候，他们懂得如何检索文档，如何问 Google…… 学会正确提问能问 Google 的，都不要去问别人，这是礼貌。 别问人家这个单词什么意思，别问人家这句话什么意思 —— 自己动手去查！一个词典查不到，再换一个，换一个还查不到，还有 Gooogle 呢！ 实在查不明白，还有个办法，去 Google 那句原文，然后加上一个汉字“的”或者“了”（这两个字是中文中使用频率最高的词），这个搜索组合很可能让你找到已经有人在网上提问过…… 自己折腾过了，还搞不明白，再去问可能帮你的人 —— 他们也搞不定，也有可能，那就记在本子里。很神奇的事情是，大量的问题，都会在某一天自动出现解决方案的 —— 前提是，你还记得那个问题! 不会正确提问，其实只不过是懒惰的表现，懒人是没救的，所以千万不能做懒人。 养成最基本语言学习习惯朗读。天天朗读。每天朗读半小时，坚持两百天，才 100 小时…… 每天朗读一小时，坚持 100 天，也就是三个月多一点点 —— 你已经把 90% 的人甩在身后了，真的！ 阅读先行是很自然的口语难练，这是很正常的，因为在大多数情况下，我们读书、看电影的时候，由于面对的并不是真实的人，所以我们大脑中的“镜像神经元”很难被激发，于是学习能力处于“冬眠状态”。其实每个人都很有语言天赋的，顶多是一点点的好坏差异而已。你看，几乎任何一个人在一个新的城市里住上一周以上，口音就会发生一些微妙的变化，并且根本不是故意的（都没有刻意练习） —— 只是因为镜像神经元被激发了。 可是阅读这东西，用不着镜像神经元过分活跃 —— 只是在小时候启动的时候可能需要（家长喜欢看书，孩子通常更容易喜欢看书）。所以，你要相信你的阅读能力可以很快提高的，事实上，确实如此 —— 只需要啃上一本原版书，基本上就过关了。 选择原版书的时候，一定要选择自己感兴趣的领域 —— 英语教科书在这方面几乎是最差的。现在对你来说，这是个很好的机会，你不是对编程感兴趣吗？不是对成为计算机工程师感兴趣吗？那就读这个领域的原版书好了。这样的时候，你的焦点并不在于英语本，而是在于那语言文字背后的思想，这样的时候，你的大脑会很厉害，它自己会想办法穿透那层“毛玻璃”（英语），看到那玻璃背后的意义…… 不知不觉之间，那“毛玻璃”就会变成“透明玻璃” —— 就这么简单。 刻意练习永远是必须的每天都要挤出一点时间，把今天遇到过的生词复习几遍 —— 上学的时候不懂如何复习的人学习都不好，现在在成年阶段重新学习的时候，可别再吃这个亏了！而且，这个习惯是会“遗传”的：你的孩子若是看到你总是通过重复获得进步，他们也会自然而然地习惯于重复获得进步，这是真理。 没！有！别！的！了！ 任何正常人都可以上路了。如果还想让自己更心安一点，那就去读一本书《人人都能用英语》，其实只有一个字和一个感叹号：“用！” 用吧用吧，不是罪。 大多数人的平庸和愚蠢，其实都是当初自己选的 —— 这真是一个残酷的事实。 任务 今天就彻底学会音标。 从明天早上就开始坚持朗读。 配置好自己的计算机以便随时查词典，请 Google Mac Dictionary 添加词典。 请 Google 新编英语阅读手册。 请 Google 人人都能用英语。 请 Google how to ask questions，第一个就是 Eric Steven Raymond 写的 How to ask questions the smart way，必须精读。 另外，还有一篇 HBR 的文章，也要细看。","comments":true,"categories":[{"name":"英语","slug":"英语","permalink":"http://ipcreator.me/categories/英语/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"正确高效使用 Google","date":"2017-01-19T18:12:06.000Z","path":"2017/01/20/MyShare/how-to-use-google/","text":"原文作者：李笑来，摘自《新生 —— 七年就是一辈子》 研究这个词，在英文中是research，我把它理解为re-search，实际上各种语言是相通的，所谓re-search其实就是“反复搜索”，就是“上下求索”（路漫漫其修远兮，吾将上下而求索）。所以，如果你想学点什么，就要善于搜索。而在这个时代里，最好的搜索工具就是 Google。 搜索引擎之所以迷人，就是因为它就好像望远镜一样： 能让你看到你原本完全看不到的东西……互联网就好像那浩瀚的宇宙，里面几乎什么都有，只要你肯用“望远镜”去看、用搜索引擎去搜…… 搜索引擎是公开的，人人都可以用的，可偏偏大多数人不用、不会用，甚至错误地用…… 于是人与人之间的差异多了另外一个不断延展的维度。在这个维度上你不如人家你能怪谁？ 最烂的提问是：“我连不上 Google 怎么办呀？” 答案是“自己想办法” —— 如果你在乎，你就肯花时间自己解决这个问题，如果你不在乎，就不用在乎了。 1 使用“本尊” 最好使用 http://www.google.com/ncr NCR: No Country Redirection，而不是http://www.google.com.hk；有时，直接输入http://www.google.com也会被自动转到“本地Google”，比如，我用日本的 VPN，浏览器就会把我转到http://www.google.co.jp…… 2 优先使用英文关键字搜索 这是个好习惯。别说不会英文，不会就学，没那么难。 3 基本技巧 Google 搜索引擎也许是世界上最简单的应用界面，只有一个输入框和一个按钮。然而，用好它还是需要花点时间去学习的。Google 有帮助文档，还专门设计了个学习网站 A Google A Day 3.a 加号 在 Google 的输入框里，所有的空格都被 Google 理解为加号+。如果你输入的是 purpose of education那么 Google 返回的文章里既有“purpose”存在，也有“education”存在，但不一定有“purpose of education”存在。另外，过分常用的、单独存在没有意义的词汇往往被忽略掉，比如冠词“a”、“the”；介词“of”、“in”、“on”、“at”、“to”；连词“and”、“or”、“but”；从属连词“that”、“which”、“when”；代词“my”、“his”、“them”等等。 3.b 引号 如果你想要找含有“purpose of education”这个词组的文章，那么你必须输入”purpose of education”。现在的 Google 已经可以处理 utf-8 大字符集了，所以，即便你在输入的时候使用的是全角字符（不是半角字符的”而是“或者”）Google也照样能够正确处理。比较一下两种输入返回的结果：purpose of education vs.“purpose of education”。再试试 the most important benefit of education 和 “the most important benefit of education”。这就是引号（“……”）的作用——返回“完整匹配”的结果。 3.c 减号 为了进一步筛选搜索结果，还需要学会另外一个符号——减号-。比如，“the most important benefit of education” – “united states”要求Google返回含有“the most important benefit of education”但不存在“united states”的文章。 3.d 星号 另外一个威力无穷的符号是星号。Google 支持通配符搜索，即搜索字符串中可以包含星号，用来替代任意字符串。比如，“the most * examples of censorship”将会返回含有类似“the most outrageous examples of censorship”、“the most brazen examples of censorship”、“the most heinous examples of censorship”、“the most stupidest examples of censorship”、“the most dangerous examples of censorship”、“the most egregious examples of censorship”、“the most prolific examples of censorship”、“the most absurd examples of censorship”…… 3.e 波浪号 还有一个运用相当灵活、经常带来意外收获的符号是波浪号~。把波浪号~加在某个单词前面，是在告诉 Google：除了给出的关键字之外，还要搜索与波浪号~后面的那个单词相关的词汇。比如，搜索the importance of ~censorship的结果中包含着“the importance of censorship”，也包含着与censorship相关的另外一个词汇“propaganda”——“the importance of propaganda”。 4 高级技巧 4.a 站内搜索 再学一个在指定网站中搜索的语法“site:”。比如，“the purpose of education” site:http://www.time.com/就是要求 Google 只返回 http://www.time.com 这个网站里的含有“the purpose of education”的文章。 4.b 定制搜索 2006年，Google 推出了“co-op”服务（自定义搜索引擎）。其中最常用的功能之一就是可以指定 Google 搜索一个或者若干个指定的网站——相当于前面提到的 Google 语法“site:”的扩展。比如，我就曾经为我的学生定制了一个 Google cse（Custom Search Engine）——Search News Media。不妨看看在这个自定义搜索引擎上搜索censorship返回的结果（GRE/SAT 的作文考试中，都有很多关于“censorship”的作文题）。这个 cse 只搜索以下10个网站： http://www.economist.com/http://www.cnn.com/http://www.time.com/http://nytimes.com/http://www.washingtonpost.com/http://www.usnews.com/http://usatoday.com/http://www.reuters.com/http://www.bbc.co.uk/http://en.wikinews.org/","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"}]},{"title":"理财理念","date":"2017-01-19T18:11:06.000Z","path":"2017/01/20/MyShare/financial-philosophy./","text":"原文作者：李笑来 摘自《新生————七年一辈子》 越早越好 从今天开始存钱 躺着赚钱 自由意志 生活目标 注重学识 节省与否 被动支出 认识周期 性格养成 别做“险盲” 越早开始越好的事情没几个，理财排在第一位对大多数人来说，理财的困难与矛盾来自这样一个窘境：很难很早开始，等开始的时候已经太晚。 所谓理财，这个定义比较合理、准确：如何有效管理现金流—— 这其实与钱多钱少关系不大。 研究者发现，贫穷与自制力差有很大的正相关。这也很容易解释：贫穷意味着诱惑显得更多、更大、更明显。也就是说，即便在自制力实际上差不多的情况下，贫穷的个体与富有的个体相比，贫穷的个体也会表现得更差。年轻人相对是穷的，于是，相对来看需要更多的自制力才能抵制诱惑。这其中的重要因素是：不同年龄段的人对时间的感受不同。 为什么今天的人更应该重视理财呢？人们的平均寿命变得更长了。人们可获得收入的工作时间也随之变长了。 有更多的钱需要管理，有更长的时间去管理钱，而最为重要的是 —— 哪怕起点稍微低一点也无所谓了。 理财最难的地方有两个：对自我的把控对风险的把控这两个都是可习得的，且习得之后不可逆的技能。更为重要的是，这两个都是必须通过反复实践才能习得的技能。 转移注意力是抵御诱惑的一种常用的有效手段，这其实也是后来理财成功的人常用的手段。他们会尝试着骗自己，把那些定期存款或者股票投资当作“已经丢了”，尽量不去想它，不去看它。这跟聪明与否其实没有什么关系。有时候，骗骗自己也挺好的，不是吗？ 理财上的风险意识，跟遗传没什么关系，跟智商关系也不大，它是必须通过自己的实践、通过自己的失败、通过自己的教训、通过自己的总结才能获得的东西—哪怕在书上看过、听别人说过也没用。理财这件事肯定是越早开始越好。年轻的时候理财虽然难，但即便发生风险，损失也不会太多—因为本来就没有太多。等可管理的财富多了才开始学习，一旦损失，就肯定惨重得多。在这种情况下，尤其可怕的是—剩下的时间不多了！ 自控与自制是可以习得的，并且，一旦习得就不会失去，这才是关键。而反过来，开始学习理财，可能也是改善自制力、自控力的方法，不是吗？ 理财越早开始越好，这已经说过了。那如何开始呢？从今天开始存钱。“我得存钱，我才不想跟那些笨蛋一样呢……”因为没有引发负面情绪而更容易被大脑采纳的建议 一个人的自控能力是总量一定的，某些方面的高度自控，会导致在其他方面的失控。该花就要花，有的时候就要活在当下人的年纪越大，赚到的钱对生活质量的改善越小，这是事实。年轻的时候，确实应该适当地享受人生，甚至应该有意培养一些高质量的生活习惯。 爱面子其实是绝大多数人存不下钱的根本原因。年轻人更爱面子，为什么呢？说穿了，就是不成熟呗 —— 过分地、没必要地在意他人的看法。从商业模式上，校园分期是很成功的；从风险投资的角度，那几个做校园分期的创始人也是非常优秀的，优秀到令人眼红。但从另外一个角度看，那些肯支付年化 30% 甚至 50% 的利息购买 iPhone 的人，也挺吓人的…… 真的合适吗？分期没还完的时候，新一代 iPhone 又出来了…… 如何摆脱呢？我有经验 —— 海量阅读心理学书籍。尼采认为“一切都是主观的”，其实也有一点点道理，因为现代心理学告诉我们，我们都是受自己的主观意识所影响的，或轻或重，只不过有些人可以通过对心理学常识的理解去调整自己。 还有一个办法非常有效：给自己培养一个不那么费钱的兴趣爱好。大多数人出去花钱，根本上来看就是“闲的” —— 女性读者该笑出声了，因为她们自己最清楚。在我看来，读书就是一个超级省钱的兴趣爱好，可竟然有很多人认为“书太贵了”！这也是没办法的事，因为“连希望对一些人而言都是极其危险的”。再如，弹琴也是一个花钱比较少的兴趣爱好，吉他比钢琴花钱更少。有个兴趣爱好的好处是，闲暇时间有所寄托 —— 没工夫乱花钱，这不挺好的吗？ 从另外一个角度，理财无非就是“开源节流”。相对来看，“节流”固然重要，“开源”才是正途。对年轻人来说，努力提高自己未来的营收能力才是当务之急。微博、微信朋友圈固然得看，但更为重要的是要花更多时间去系统地研读正式书籍，多花时间去打磨自己的劳动技能。不要只顾着升级手机系统，也要常常升级自己的大脑，选择更好、更强的思维模式，进而有能力作出不同的选择。 最后，死活存不下钱的人，某种意义上都有共同的特征 —— 常常“一厢情愿”。他们一开始是“心里希望”，后来是“认定”一切都会自动变好，甚至进一步成功地欺骗自己：“这才是正能量”……骨子里，这是拒绝成长，拒绝承担责任，乃至心理学上还有个专门的词 —— 彼得潘综合症1。 现实是这样的：这个世界和这个社会整体上来看是会越来越好的，可每个个体的状况却不一定。很多人越来越糟，没有人会自动变好，只有行动才会带来变化，期望本身在没有行动支持的情况下只能变成自我欺骗。 成年之后，生活的一切几乎都是选择的结果。然后，给自己设置一个机制，使自己就是不能动用存起来的钱。这时，欺骗自己其实是有用的 —— 还记得那些 4 岁的孩子是怎么学会通过骗自己忍住不吃棉花糖的吗？就当那些钱丢了。丢了的钱，不是用来“应急”的，丢了就是丢了！“丢了”的意思是，没了，那些钱彻底没了！ 如何制造这种效果呢？这个灵感来自《本能：为什么我们管不住自己？》的作者。你可以这么干：到外地办一张储蓄卡，记下卡号之后把卡扔掉；以后每个月转一定金额的钱到那张卡上。其实金额大小并不重要，是收入的 20% 还是 5% 也不是很重要，真正重要的是 —— 给自己一个机会，在 5 年之后体会一下突然可以动用一笔闲钱的机会。如果你今年 25 岁，等待相当于自己已有生命的 1/5 的时段是很惊人的成就，这段经历在未来很可能会“折现”成惊人的毅力（Grit） —— 另外一个提高收入的重要能力。而且，来自经验的毅力更可靠 —— 5 年后你可就赚大了。 给自己存出一个机会，这就试试吧。 作为这个时代的年轻人，要坚定地理解两个事实： 普遍来看，普通人的赚钱能力在越来越快地提高； 普遍来看，普通人在生活必需上的开销所占比例正在缩小。这两条都笃信且实践，才能做到“别把自己的青春过得太穷”。 收入其实分为两种： 主动收入 被动收入 所谓主动收入，就是你必须干点什么才能获得点什么的那种收入；而被动收入则相反，就是那种你不必干什么但竟然可以获得的收入。被动收入的最常见例子是利息。利息是需要本金才能获得的，没有本金怎么办？更多的人，不仅没有“睡后收入”，还有很多“睡后支出” —— 分期消费的负担其实挺重的。 不管你处在什么年龄，从现在开始刻意寻找那种可以一次性付出却能够长期获得收入的事情去做。这种事情不像看上去那么难，甚至有越来越简单的趋势。比如，过去只有靠写书被正式出版才能拿到版税，现在很多人写写微信公众号文章就可能获得读者“打赏”，收入甚至比写书高一点，这就是趋势。 拼命锻炼自己的创作技能。可以是任何领域的创作，但必须是可以获得收入的创作。慨叹一句：所谓的创作，从某个角度上来看简直就是“无中生有” —— 一种成本长期趋近于零，收入长期趋近于无限的活动。 “未来是不可知的（unknown）”和“未来是不确定的（uncertain/random）”之间有着看起来细微但实际上意义重大的差异。 未来是不可知的（The Future is unkownable），意味着我们对未来毫无办法，正如我们对过去无可奈何一样。2未来是不确定的（The Future is uncertain/random），意味着我们对未来有一定的概率可以成功预测。 换句话讲，当我们抛出一个硬币，在它落稳之前，我们确实不知道它究竟是哪一面朝上，但我们确实知道任何一面朝上的概率都是 1/2 —— 这是巨大的差异。 科学的敌人并不一定是宗教，科学的敌人一定是那些不愿意改变自己既定人生观、价值观的人。 概率论就是风险控制的基础工具。因为绝大多数人真的不认为科学与自己的生活有太大的关系。学识使人坚毅。金融专业毕业的人通常会想办法全款买房买车，这不仅仅是因为他们可能赚的比较多，更因为他们对利率和理财的理解使他们无法作出分期消费的决定。在今天这个时代，求知就是求富。因为知识变现不仅越来越容易，也越来越快，越来越多。重复的、枯燥的工作应该自动化完成。 这世界发生了很多变化。其中之一就是，越来越多的人靠着一点点的小发明的商业化赚到了越来越多的钱。这就是时代的不同。所谓“屌丝逆袭”的故事只有到了现代才开始批量出现，就是因为智力变现、知识变现可能了、容易了。 在今天这个时代，我们可能并不需要打败谁才能过得更好，起码可以过得足够好。细想想，很多人其实是被自己打败的。他们普遍的特点是一样的：在虽然很难但明明可以选择的情况下，误以为自己完全没有选择，于是只能走进死胡同。放弃了选择，就是被打败了。 在一个普遍认为人们其实没有选择的世界里： 用以学识支持的坚毅认定其实选择是存在的，并且是可追求的，是有很大相对优势的—— 就是这样。 什么叫高品质生活？高品质生活与金钱肯定有着一定的联系自欺欺人不仅无补，甚至有害，尤其是对自己的大脑 —— 人要珍爱自己的大脑。被动收入略高于支付足够高品质的生活必需支出所需要的金额。 对成年人来说，高品质生活从停止自欺欺人开始。比如， “金钱不一定带来高品质生活”，以及它的各种变体：有钱不一定幸福。（但没钱更不容易幸福。）那么拼有什么用？不还是得了乳腺癌？（不拼的人也有很多得了乳腺癌。）我很穷，但我有骨气！（说得好像富人没有骨气似的。） 即便是今天，求知的成本依然相当高。全球范围内连年上涨的大学学费就是明证 —— 真的不是所有人都有钱完成高等教育的，不是吗？正因为富有，他们的勤奋才更容易达成目标，或者反过来，当他们的勤奋没有直接、快速的回报之时，他们也更不容易着急，而是显得更有耐心 —— 时间久了，耐心就真的有了。 事实上，致富失败的人更容易放弃勤奋，而持续勤奋的人最终不可能太穷。很努力依然很穷的人，其实是选择出了问题，而不应该怪罪勤奋本身。 是否能拥有高品质生活与一个人的审美能力有着至关重要的联系。所谓审美，真的不只是在选美大赛中判断哪个姑娘最漂亮而已。审美实际上是一切生活选择的基础。什么是美？审美教育不够普及，就算有也常常失败的重要原因在于 —— 人们误以为“美”与“不美”是一种主观判断，可事实上，美是一种客观存在。所谓的“主观”，实际上指的是对美的感受有多准确。达·芬奇遇到帕西奥利之后，因为帕西奥利教给了他足够的数学知识，他专门为帕西奥利的书《神圣比例论》画了插图。在此之前，达·芬奇其实一直是凭直觉创造美，但被教育之后，美的创作就有了理论依据和指导，这就是黄金分割率的应用。 对美的认知是可以培养的。对美的认知，最基础的来自“五感”，即视觉、听觉、嗅觉、味觉和触觉。即便是小孩子，也有一些天然的审美意识：有些人的相貌是美的，有些风景是美的，有些音乐是美的，有些食物是美的，有些材料是美的有审美意识，有审美能力，有为自己创造美的意愿和动手能力 —— 这是长期培养之后习得的结果。审美认知、审美能力，大多数情况下真的与金钱无关，因为更多更重要的审美体系，需要的不只是某一个器官的感受，而是系统思考的能力。 比如，除了美食、美景、美人之外，还有很多事物都是美的。 有些语言文字很美有些科学证明很美 进而还有更多抽象的美。 简洁很美效率很美创新很美 教育的意义就是让我们拥有更高级、知觉更丰富的器官。科学教育可以让一个人“打开眼睛”，看到不一样的却更真实的世界；音乐训练可以使我们分辨、创造更美的曲调……于是，长期的教育和自我教育会形成个体之间审美能力的巨大差异。最终，审美意识会触及且影响一个人价值观的方方面面。 审美意识的开化和审美能力的积累，自始至终都在影响人们的理财过程。金钱这个东西对于审美来说是“后相关”。什么叫“后相关”呢？这是我自己杜撰的一个词。金钱本身通常对开启审美意识、提高审美能力没什么作用，不过，在有了良好的审美意识、良好的审美能力之后，金钱可以发挥的作用很大，这就是金钱对审美的“后相关”作用。 高品质生活不一定要等到未来，也不一定要有钱才可以拥有。但未来因为现在开始理财成功的你，一定会有更高品质的生活。千万不要胡乱从小刻意灌输理财观念，尤其是大多数父母的观念还是错的。要从更本质的地方开始：开启孩子的审美意识，刻意培养他们的审美能力。 理财也好、投资也罢，要抛弃勇气，注重学识。 人们对勇气、勇敢的理解常常过于肤浅，从未认真审视，甚至干脆忽视。勇气、勇敢背后的支撑究竟是什么？比如，小孩子打架，双方对峙，更多是靠先天条件 —— 身强力壮的更容易“勇敢”，体质弱小的更容易“怯懦”。细想想，这跟勇气的关联并非100% —— 甚至没有勇气什么事，只与体质的强弱有关。 俗话说，“狭路相逢，勇者胜”。这也确实是一种实际存在的情况。在双方势均力敌的情况下，竟然有一方是更有勇气的，最终勇者胜出了。可问题在于，胜出的一方为什么更有勇气呢？更可能的解释是：其中一方想明白了 —— 大家都害怕，你们害怕，我们也害怕，只不过，我不让你们看出来我在害怕，那你们就更害怕了，于是我就有相对优势了。这样的时候，所谓的勇气，已经不再是抽象的特质，而是一种相对精巧的计算（或算计）了。 苏轼在《留侯论》里就说过：“古之所谓豪杰之士，必有过人之节。人情有所不能忍者，匹夫见辱，拔剑而起，挺身而斗，此不足为勇也。天下有大勇者，卒然临之而不惊，无故加之而不怒。此其所挟持者甚大，而其志甚远也。”意思是说，“蛮勇”其实并不算“勇”，只不过是个“然并卵”的东西。苏轼所说的“大勇”是什么呢？换句话讲，其实是脑壮，而不是肉粗。 所谓的勇敢、勇气，尤其是脱离先天条件支撑的勇敢、勇气，其实也是、更是学识与思考的表现。在理财与投资的起点就要明白：成功与所谓的勇气无关，靠的是足够的衡量风险与收益的能力 —— 这才是成功的智慧。智慧的特征是，可习得，可积累。 风险永远无所不在，真正的问题在于你如何识别它们，如何衡量它们，当有收益可能的时候如何计算风险是否可以接受，以及自己是否有足够的实力承受。这些都是可以通过学习获得并进一步提高的思考能力。应对风险的能力是必须花时间学习的，只因为它确实可以习得，但不容易习得。大多数人在生活的方方面面都缺乏风险意识。比如，刚学会开车的人，上路之后就常常后怕 —— 看着不怕车辆的行人才反应过来，原来过去那么多年里，自己其实很多次都是在“九死一生”的状态下过马路的。再如，我个人也是在自己开车之后才明白晚上穿着深色的衣服沿着马路走其实是非常危险的。对没有开过车的人来说，有一些风险“不存在” —— 他们未曾意识到那些很大的风险竟然存在。同样的道理，未曾做过理财和投资的人，往往不知道很多风险的存在，原因仅仅是他们从来没见过、从来没想过。 仅仅能够感知风险的存在，清楚地知道风险有多大，大到什么程度，都是需要大量观察、大量思考才能真正习得的能力。我问过很多专家，他们其实都一样，除了反复说“注意风险”之外拿不出更好的建议。不仅仅是理财，生活中的任何方面其实都一样：安全，要靠避险，而不是冒险；要靠小心，而不是勇气。 从本质上来看，大多数人想着去赚钱，最终却“被赚”了的本质原因在于他们根本就没学习过、没研究过他们所参与的游戏究竟是怎么回事。他们甚至连赌徒都算不上，因为赌徒起码知道应该怎样结合胜率计算收益、怎样决定下注的筹码数量、怎样计算多次下注后的概率变化……所以，实际观察一下就能知道，很多人进了股市，连赌都没有赌，钱就没了。他们只不过是人肉印钞机，为股市“定向增发”。钱没了，他们都不知道是怎么没的，甚至都不知道应该怪谁、该怪什么，只能怨自己运气不好。他们有的其实不是勇气，也不是勇敢，只不过是天然的贪婪而已。 “股市有风险，投资需谨慎”这种建议天天在耳边飘荡，怎么那么多人就是听不进去呢？ 第一个解释就是：无知无畏。 第二个解释是：安全保护会使人放松警惕。正如驾驶员系上安全带之后会不由自主地、下意识放心地提高车速一样，安全保护常常刺激人们放松安全意识。所以，对安全带的争议在于：安全带也许保护了驾车的司机，却可能给路上的其他人、其他车带来更大的危险。 风险与收益一直共存，并且，风险的大小是可以通过对它的了解和学习而被控制的 —— 这是人类进步的基础，也是人类进步的表现。但显然，它不会自动消失，或者自动配合人们的行动。只有通过学习，才能与它共舞。 科技的进步正在某个层面抹平贫富差异所造成的生活质量差异。有了 Uber 之后，人们几乎可以随时轮换着坐各种品牌的豪车，还不需要支付过高的费用 —— 弄不好补贴完发现比搭乘普通的出租车还便宜。 【买书的钱不能省】：在追求学识的过程中，免费常常是陷阱。因为，我们的时间并不是免费的，同时会随着我们自己的学识变得越来越贵。舍不得花钱买好书是最“屌丝”的行为，也是最高效地制造“屌丝”的方式。不仅不能在好书上省钱，还要为了淘到真正的好书，付出“总是得前后买过很多烂书才能提高甄别能力”的代价。再往大里说，一切有助于帮助自己成长的开销都不能省，尤其对年轻人来说更是如此 —— 你的前途取决于此。 【买工具的钱不能省】一切工具，其发明与使用的目的都是一样的 —— 提高效率。花一点钱提高效率，赚大了；为了省一点钱，却要忍受长期的低效率甚至无效率 —— 只有“屌丝”才会觉得没问题。 【事关安全的钱不能省】家里的电源插座之类的东西，绝对不能图便宜，因为这涉及安全。在这样的事情上，没有“万一”，因为天天都在用，所以最终结果是“一定会出事”。买车的时候也一样，要不要加后视影像，要不要配置全景雷达 —— 这些其实完全不是应该省钱的地方，因为它涉及安全。在这样的地方省钱，将来一定会付出更高的代价。 【事关终极体验的钱不能省】终极体验的特点是，当前的享受不可能用未来的享受替代。 【知识产权的钱不能省】我总觉得程序员用盗版软件是个特别“屌丝”的行为 —— 你自己指望用技能、产品赚钱，却坚决不让别人用技能、产品赚钱，这种逻辑让人无语。对知识产权的尊重，对知识产权的保护，是让那些有能力创作的人获得“被动收入”、获得财务自由的基础。没有知识产权保护，有能力创作的人就只能“无产”了 —— 还有什么是比这更阴暗的未来展望呢？ 节省肯定没错，但节省肯定不是创造未来的主要方式。铺张浪费肯定不对，但在一些地方对自己好一点，对今天的年轻人来说，也肯定没错。 被动支出 【通货膨胀是最可怕的被动支出】2015 年 10 月，央行释放 7 万亿元，导致人民币瞬间贬值 2%，也就是说，你兜里揣着的 100 元钱，现在只相当于之前的 98 元了，有 2 元钱已经“不翼而飞”，只不过那张纸币上印着的数字不会自动改变，所以，看起来还是 100 元。越有钱的人，“恢复能力”越强，就好像受了同样的伤，身体强壮的人相对更容易复原一样。假设货币贬值了 2%，即购买力大约下降了 2%。一个月收入 5,000 元的人，如果他的月花销本来就是 5,000 元（也就是说，本来每月刚刚好），那么他现在收入依然是 5,000 元，可每个月的花销却需要大约 5,102 元（5,000 ÷ 0.98） —— 还得去借点钱才够用。而一个月收入 15,000 元的人，假定他的月花销也是 5,000 元，那么，虽然他现在需要用 5,102 元才能满足生活需求，但他依然有 9,898 元可以去储蓄，如果是定存的话，有可能获得 3% 甚至更高的利息，于是没多久，那损失的 2% 就补回来了。如果一个人有几百万元的存款，那么他通常可以在银行买到利率更高的理财产品，比如信托之类，利率可能高达 12% ~ 15% —— 虽然也有一定的风险 —— 于是，他们的恢复能力更强。 【利息对借款者来说也是很可怕的被动支出】借来的钱，之所以要支付利息，是因为在很多情况下钱本身就是一种生产资料，它也可以用来购买其他生产资料，而生产出来的商品是可以以更高的价格卖掉的 —— 能赚到钱。所以，利息这东西，本来就是天经地义的。只是古今中外，在很多文化里，很多人总是下意识地觉得赚取利息的人是不劳而获的，但到了不得已的时候又不惜去借很高利息的贷款 —— 错上加错。 【生活必需品开支其实是一种被动支出】尽量只为生产借钱，尽量不要为消费借钱。也就是说，如果你借来钱，用它可以赚到钱，赚到的钱比利息多，你就是有利润的，这本质上就是生产。如果借钱仅仅是为了消费，钱花出去了，获得的只是享受（即便有些确实是“终极体验”），那就有点亏了，甚至亏大了 —— 别人赚了 1 分钱，你花掉 1 分钱，这加起来就差了 2 分钱呢。 用借来的钱去支付教育费用，这也是生产，因为这相当于提高了自己将来获得更高收入的可能，算是一种投资，其实是很划算的投资。用借来的钱去买房子，虽然复杂一点，也算是投资，但还要看整个经济周期的状况。可用借来的钱去买部 iPhone，然后支付 30% 以上的利息，就不太划算了，因为有更便宜的替代方案存在，比如用坚果手机之类，代价就是 —— 没那么酷呗。但是，如果买来 iPhone，不仅用了，还把它作为开发机、测试机，那就不一样了！ 最后看第三项生活必需品支出。对于生活必需品的支出，对策如果是不吃不喝，显然不怎么明智。在今天这个世界里，竟然要连上网费都省下，那跟原始人有什么区别？过分约束自己，其实并不是一个优势策略，尤其是考虑到终极体验的不可替代性的时候。 一般规律倒也简单：收益越高，风险越大（反过来不一定成立） —— 虽然同时也有很多收益并不高的风险也很大。 别指望从别人那里找到答案，只能靠自己去判断。 人一辈子基本上要靠3种力量： 体力智力财力 即便是在远古时代，体力超群或者智力超群，直接的结果通常就是财力的增加，而财力的增加常常会进一步导致体力和智力的改善。 有两个自然规律在人类史上从来都没有变过： 只有第一被重赏财力积累无上限 自然规律就是“老大通吃”，发展到今天，这个趋势越来越夸张。创投圈里流行一个朴素的认知，其是古老的自然规律：这个世界，只有老大，没有老二。一个人的体力是有上限的，再强壮也有衰老的必然；一个人的智力是有上限的，再好学、再勤奋，时间总是有限的。但是，财力却有着优于体力和智力的属性。 可无限积累可直接继承 后天获得的体力可能遗传，也可能不遗传，也就是说，有可能，但不一定。后天提高的智力，很难遗传，更多的是通过对下一代的教育引导大致达到“遗传”的效果。可财力却不一样，除了可积累、无上限之外，还可以直接让子女继承，若是他们拥有足够的体力和智力，就可以继续积累，且站在更高的起点上继续积累。 从历史上看，只有一种靠谱的途径 —— 长期积累。“一夜暴富”其实很常见，但由于不是通过积累获得的，所谓“暴发户”在财富方面的智力（所谓“财商”）跟不上，于是无论有多少财富都可能很快败光。这种例子非常多，学者们曾经跟踪观察那些中了彩票的人，几乎有一个算一个都最终回到穷困潦倒的状态。 长期积累本来就是很少有人能做到的事情。积累就是难得的习惯，且要长期，这就难上加难。即便有人做到，历史上也有观察 —— 富不过三代，穷不过五服。为什么呢？只因为积累教育实在太难了！但这确实是唯一靠谱的途径。 所以，细想想就会发现，只有养成积累的习惯 —— 无论是在哪方面 —— 才是抵消被动支出的最有效手段。 认识周期周期是理财投资活动中最为关键的考量因素，是开始实践之前必须学习、研究、掌握、遵循的理念和现实，可惜总是被忽略。周期也是市场上大多数理财书籍中干脆不提，或者放在最后一笔带过，实际上却是最为基础、最为关键的知识点。不深入了解周期，就无法进行有效的判断，整个理财投资活动基本上就等于是没有判断的行为，甚至比不过两个人抛硬币赌博。而在这样的时候，墨菲定律一定会显灵：如果一件事可能变坏，那么它一定会变坏。 真正的趋势常常需要在多个周期（至少2个）之后才能真实展现。如果我们探究的是真正的趋势，就会发现，上升与下降只不过是一个真理的表象 —— 现实的经济里没有直线，只有波（动）。 在一个很长的波段中，从任何一个点前后望，看起来都像自己身处在一条直线而不是曲线上，就好像我们站在地球上却很难感知我们自己其实是站在球面上而不是平面上一样。 一个上升与一个下降构成一个周期。2 个或多个周期之后，如果我们发现曲线就好像是数学课本里的 sin 曲线的话，那么所谓的“趋势”实际上就是一条水平线而已，而我们常常说的且在寻找的所谓“趋势”应该是个要么上升、要么下降的线条才对，因为“水平”等于“无变化”，无变化就无趋势。 这就解释了为什么有些人认定的所谓的趋势在另外一些人眼里根本谈不上是趋势，因为后者重视的是1个以上的周期之后所显现的真正的趋势。这也解释了为什么“跟涨杀跌”的人必然吃亏，因为他们所看到的并不是实际的趋势，他们看到的和把握的只不过是幻象而已。 关注周期，以及多个周期背后显现出来的真正趋势，会给你一个全新且更为可靠的世界和视界。 进而，几乎一切事物，无论是抽象的还是具体的，都有它自己的周期。而他们的周期不大可能一致。于是，几乎一切的机会和陷阱都隐藏在周期与周期之间的差异上。据说GDP和股市的周期轮换如下图所示。 还有个“库伯勒 —— 罗丝改变曲线”（Kübler-Ross change curve）特别好玩，它看起来是这样的。 更进一步，人们发现，任何新生事物的发展过程（Transition Curve）也是差不多的。 反思这样的现象了：每次巨大技术变革出现的时候，都有一批投资者死在路上。为什么呢？因为他们看到了所谓的“趋势”，却忘记了或者不知道真正的趋势需要 1 个以上的周期才会真正显现。回顾一下历史吧，互联网、NetPC（后来所谓的“云”）等都是如此。再如，我相对比较了解的比特币，现在在这样一个阶段：比特币正在引发很多人的愤怒。 对周期的深入理解，甚至可能影响一个人的性格。在我看来，所谓的不屈不挠，所谓的坚持不懈，更多的时候，只不过是因为对自己身处某个周期的某个位置非常了解，所以才更容易作出的决定。 事实上，如果你需要理财顾问或者保险顾问1，你会发现，真正专业的理财师、保险师最终都是从你的情况出发，即从你身处的生命周期与经济周期的具体节点出发，制定你的理财计划。 繁殖能力强是王道。拿到理财与投资里说，就是存的越多越好。 太简单了吧？简单到好像没必要教育或学习似的。其实这也是传递重要知识时所面临的困惑与困难 —— 越是重要的东西越是看起来并不相关。比如，品质生活其实与审美能力更正相关，与钱的关系并不大，但是钱却看起来是最重要的、也被认为是最重要的因素。再如，当年我教英语的时候也发现，背单词的方法、找外教之类的学习环境其实都没有另外一个简单的字重要 —— 用。可越是重要的东西，说出来之后越是简单到令人不由自主地轻视。还有，性高潮其实与大脑关系最大。 性格养成一个人的性格是由他的价值观决定的。而所谓的价值观，其实就是一个人分辨好坏主次的思维体系。审美能力让我们分辨美丑，价值观让我们分辨好坏。于是，正如审美能力能够影响生活品质一样，价值观决定了一个人的性格。每个人都有自己的价值观，于是，每个人都有自己的一套体系去判别好坏，进而，好坏的判别，影响每一次的选择。于是，价值观影响选择，选择影响行动，行动构成命运。所以，“一个人的命运是由他的性格决定的”，这话我没办法不同意。 虽然环境对于性格养成的影响很大，但实际上一个人的性格可以脱离环境的影响，或者至少部分脱离。不做没用的事，这也是一种价值观导致的选择 我常常自我审视。现在回头看，对我性格影响最大的一个时期，是我从 2007 年开始写《把时间当作朋友》的两年时间。从我的个人体验来说，那个长达两年的写作过程 ——期间还有一次书稿尽失，只好凭记忆重新来过 —— 是我对自己的价值观的一次细心梳理。虽然很多价值观在那之前就定型了，但那一次的梳理却将更多的细节确定下来 —— 直接的结果就是，对自己可能做出的选择毫无疑问、毫不犹豫。 有什么值得生气的呢？都是想不开造成的。平时人们所说的“想不开”，其实无非就是“价值观混乱”。是什么影响价值观呢？我觉得与影响审美能力的因素是一样的：还是学识。 这个时代的好处是，学识相对容易获得，而且越来越容易获得。读书其实越来越便宜，早已不像过去，只有贵族才有资格读书；正规教育体系固然有很多问题，但毕竟义务教育真的普及了；人们讨论的问题越来越开放，而拥有健康好奇心的人刨根问底也越来越方便 ——若是能读懂英文，再加上 Google，那简直没有边界。 一个人的性格是长期自我选择积累的结果。 “险盲”是我借用“文盲”这个词的结构杜撰出来的一个词汇，是指那些不了解风险，不知道如何回避风险，更不懂如何控制风险的人。文盲的一生其实很吃亏，险盲的一生更是如此。文盲可以通过（自我）教育得到解放，险盲也一样。 风险教育应该是理财教育，甚至应该是整个教育中最重要的组成部分，也不知道为什么它竟然一直被忽略，顶多在学校里搞个防火模拟演习。火灾其实只是风险的一种，有一个术语是“不可抗力造成的系统风险”。这也是为什么我们必须不断自我教育的原因。仅靠别人教永远是不够的，要靠自己学才行。至于“活到老，学到老”，其实只不过是一种生活方式。 首先，要平静地接受第一个事实：风险是一种客观存在。第二，一旦未知存在，就有风险存在。有一个普遍的误解就是认为“风险的概率决定风险的大小”，可实际上，衡量风险的首要因素并不是风险的概率第三，衡量风险大小的决定性因素是赌注的大小。 假设有两个人玩公平的抛硬币赌输赢的游戏，规则是： 赌注大小恒定直至一方输光游戏才能结束请问，最终决定输赢的是什么（单选）？ A.手气 B.谁先抛硬币 C.抛硬币次数 D.总游戏时长 E.以上皆是 F.以上皆不是 关于之前的那道选择题，最终决定输赢的是谁的赌本更多。 由于赌注是大小恒定的，又由于抛硬币是概率为¹⁄₂的游戏，所以，如果双方赌本一样多，那么最终双方输赢的概率就都是¹⁄₂。可是，如果一方的赌本更多，那么他最终获胜的概率就会更大。由于玩的是概率为¹⁄₂的游戏，所以，如果其中一方的赌本是另外一方的2倍以上，那么前者几乎必胜。也就是说，在这个游戏里，赌本相对越多，输的概率越趋近于零。 如果你参与这个游戏，一上来发现那个“恒定大小的赌注”比你的总赌本还多，那么你就不应该参与。如果你的赌本只够下 1 注，虽然赢的概率依然是¹⁄₂，但从长期来看，你没有任何胜算。 很多人看起来一辈子倒霉，可实际上，那所谓的“倒霉”是有来历的。他们对风险的认识是错误的。他们倒霉的原因只有一个： 动不动就把自己的全部赌进去。赌注太大，则意味着结果无法承受。为什么赌本少的人更倾向于下大赌注呢？据说是越差的人梦想越大。高速公路上开得很快还不愿意系安全带的 —— 险盲，因为这些人不知不觉就把自己的性命当成了赌注。经常做铤而走险之事的人 —— 险盲。股市里怕自己赚得少，拿出全部身家（甚至借钱，更甚至借钱做杠杆）的人 —— 险盲。 第四，抗风险能力的高低本质上就是总赌本的大小，尤其是在面临同样概率的风险的时候。赌注相对大的时候，智力会急剧下降。为什么高考的时候总有一些人考砸？就是因为赌注（未来一辈子）太大，以致压力太大，进而无法正常发挥。那些天天刻苦训练的选手，每一个在训练的时候都能经常打出“满贯”，但在整个赛季都没有几个选手能在赛场上做到。为什么呢？就是因为赌注太大了。平时训练的时候没什么赌注，也就没什么压力。这也可以反过来解释一个常见的现象：历史上所有成功的庞氏骗局都有一个普遍的重要特征，那就是“加入费用惊人地高”，因为只有这样，进来的人才能普遍不冷静。所以，人真的不能穷，不能没有积蓄，否则真的会在某一瞬间突然变傻。另外，永远不要“All In”。这在很多时候并不是空话，真的需要放在心上。 第五，冒险没问题，但尽量不要被抽水。“抽水”是赌场里的术语，是指赢家要支付盈利中的一定比例给庄家。不要以为赌场太阴险，实际上，开赌场、保证公平就是需要开销的，所以，玩家支付抽水是合理的。也不要以为股票交易所太贪婪，它们收手续费也是合理的，这就是无所不在、不可消灭的“成本”。公平是有成本的。有抽水机制的赌局本质是倾斜的。因为即便是抛硬币的游戏，加上抽水机制之后，长期来看所有的玩家也都会输光，所有的赌注最终都会转化成抽水者的利润 —— 就好像一个正弦函数被改造成阻尼正弦函数一样。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"坐享其成","date":"2017-01-19T18:10:06.000Z","path":"2017/01/20/MyShare/sit-idle-and-enjoy-the-fruits/","text":"作者：李笑来 坐享，也许是最简单的大脑锻炼方式，这也是人类莫名其妙地已经运用了两千五百年以上的大脑锻炼方式。已经有足够多的科学研究证明，它能使你的大脑皮层表面积加大，能使你的灰质变厚，它也能增强人们的免疫系统，它还能让人们摆脱抑郁症……尽管简单，但也相当神奇。虽然神奇，却又非常简单。 所谓知识（或者知识的基石，即，概念）的三个基本要素，分别是： “是什么”（what） “为什么”（why） “怎么做/用”（how） 从这个角度望过去，不管三七二十一，用起来再说，从来就是人类的智慧。你现在知道为什么我主张不要闲着没事儿就学外语，而是一上来就要用了罢？（详见《人人都能用英语》） “坐享”这个词是我刻意造的中文词汇。在英文中，它叫 Meditation，翻译过来是“冥想”；在东方，它叫打坐、坐禅、禅修、内视、静观…… 其实“静坐”倒是个不错的词，可惜在中国它有另外的含义，不敢乱用。于是，只好生生编造了一个词：坐享。 也许释迦牟尼是地球上第一个知道如何坐享的人，并由此构建了一个系统的、庞杂的、却也足够完整的解释理论：佛教。如此算来，人类练习坐享，因为坐享获得益处迄今为止至少有两千五百多年了，真是神奇得很…… 什么是元认知能力？所谓的元认知，指的就是“认知的认知”。也就是说，你能认知到你的认知，虽然有点拗口，但其实也不是那么难以理解。当你在思考的时候，你能意识到自己在思考，进一步还能意识到自己在思考什么，又进一步还能判断自己的思考方式、思考结果是否正确，更进一步还能纠正自己错误的思考方式或者结果，这就是元认知能力。坐享无非就是通过一种简单合理的方式锻炼自己的“元认知能力”。 元认知能力几乎是一切学习与进步的最底层的、最根本的能力。一个人的潜力有多大，几乎完全取决于他的元认知能力有多强。 很多所谓个性强、脾气大的人，从最底层上来看，其实就是元认知能力困乏而已。因为这样的人其实没有分清楚谁是主人，谁是仆人，他们不明白这个很重要的道理：你的大脑并不是你，你的大脑是属于你的一个器官…… 而不是反过来，你竟然隶属于你的大脑。 元认知能力的强弱，与一个人大脑皮层的面积和灰质的厚度有着正相关的联系。决定一个人聪明与否的并不是脑壳大小，而是大脑皮层的面积。大脑皮层表面有很多沟回，沟回的多少，决定了最终大脑皮层表面积的大小，人和人之间的大脑皮层表面积大小甚至可能相差一倍以上。 通过不断有效地学习，我们的大脑获得更多的锻炼，最终的结果是大脑皮层表面积加大，灰质变厚；而反过来，大脑皮层表面积加大，灰质变厚，也会使学习能力有更大的扩展空间……元认知能力的获得，一方面与知识的习得有关系，因为任何学习过程本质上来看都是“制造更多的沟回”；而另外一方面，我们也可以像锻炼胳膊上的二头肌一样通过一定的方式进行锻炼大脑 —— 坐享就是这种锻炼。 通过放松大脑，长时间只专注于身体的某一部分，坐享可以让一个人逐步通过运用不断加强自己的注意力。注意力，是认知的最重要方式之一。而在不断把被分散的注意力重新集中起来的过程中，练习者可以渐渐感受到、并越来越熟练地应用自己的元认知能力 —— 当他认知到自己的认知并没有按照应该的方式操作的时候，他会运用自己的元认知能力纠正自己的认知及其操作方式。走路够简单吧？每天多走一小时，对身体的帮助可以说是无限大 —— 即便这么简单的事情，也很少有人愿意做，只不过是因为他们并没有深刻意识到那么做的种种好处，更无法想象不这么做的巨大害处。 每天坐享一刻钟或者一小时，已经是足够的大脑锻炼强度。已经有足够的科学研究证明这样做带来的巨大好处，除了大脑皮层面积增大、灰质变厚之外，它还能加强人体的免疫系统。更为重要的是，当一个人的元认知能力加强的时候，他更容易转变为进取型人格，更难被情绪所左右，相对更容易冷静，更容易清楚地思考…… 无论从哪方面看，都是能够极大提高生活品质的活动。 如何开始坐享？由于在坐享过程中，注意力足够集中的时候，全身放松的状态与人体在睡觉的状态几乎相同，所以，要注意保暖，注意风向。 可以找个毯子盖上膝盖； 不能有风持续吹到耳朵周围……(三叉神经汇聚于耳部周围，不小心的话，可能会引起面部偏瘫。) 至于姿势，其实并不重要，只要舒服就好。不一定非要盘腿…… 其实以下任何姿势都可以： 但脊背坐直倒是挺重要，因为最终，长时间弓着背可能更累。 从以下简单的步骤开始： 找个安静的地方 设定一个计时器（从五分钟或者十五分钟开始，渐渐延长到四十五分钟到一小时） 用你自己感觉舒服的方式坐好（最好脊背挺直） 闭上眼睛 开始深呼吸 将自己所有的注意力全部集中到呼吸上 一旦发现注意力转移到其它地方，就要刻意地将注意力集中到呼吸上 持续深呼吸…… 直至计时器将你“唤醒”。 坐享几次之后，可以开始尝试在坐享过程中用你的注意力扫描你的整个身体。 从左脚的脚尖开始…… 左脚掌…… 左脚跟…… 左小腿 ……左膝盖 …… 左大腿…… 左臀…… 顺着脊柱一直到后脖跟…… 划到左肩…… 左上臂…… 左肘…… 左小臂…… 左手腕…… 左手心…… 左指尖…… 再回来…… 左手心…… 左手腕…… 左小臂…… 左肘…… 左上臂…… 左肩……沿着你的肩一直划到右肩…… 右上臂…… 右肘…… 右小臂…… 右手腕…… 右手心…… 右指尖…… 再回来…… 右手心…… 右手腕…… 右小臂…… 右肘…… 右上臂…… 右肩…… 回到后脖根…… 顺着脊柱一直到右臀…… 右大腿…… 右膝盖…… 右小腿…… 右脚后跟…… 右脚心…… 右脚尖…… 在这个过程中，你会感觉到某个地方不舒服。这样的时候，把注意力全部集中到那个不舒服的地方，仔细观察自己的感受，尝试着接受…… 这是个机会，也是个挑战…… 一旦能做到接受那个原本不舒服的感觉，接下来的感觉竟然是解脱…… 尝试着在任何地方坐享。出租车上、火车上、飞机上、甚至颠簸的船上，或者干脆是在某个其实非常嘈杂的地方…… 总而言之，要集中注意力、并且最终可以做到自如地控制注意力才算是坐享 —— 最终的目标是可以做到在越来越长的时间里自如地注意力集中，并且还能控制集中的注意力。而胡思乱想、放空，甚至睡着了，都算不上是坐享，对增大大脑皮层面积，增厚灰质没有什么具体的帮助。 参考文献 Alterations in Brain and Immune Function Produced by Mindfulness MeditationEffect of compassion meditation on neuroendocrine, innate immune and behavioral responses to psychosocial stressBrain Mechanisms Supporting Modulation of Pain by Mindfulness MeditationA comparison of mindfulness-based stress reduction and an active control in modulation of neurogenic inflammationWorkplace based mindfulness practice and inflammation: A randomized trialOpen hearts build lives: Positive emotions, induced through loving-kindness meditation, build consequential personal resources.The Effects of Mindfulness Meditation on Cognitive Processes and Affect in Patients with Past DepressionSystematic Review of the Efficacy of Meditation Techniques as Treatments for Medical IllnessEffectiveness of a meditation-based stress reduction program in the treatment of anxiety disordersThree-year follow-up and clinical implications of a mindfulness meditation-based stress reduction intervention in the treatment of anxiety disordersMindfulness-Based Stress Reduction for Health Care Professionals: Results From a Randomized Trial. A Randomized, Wait-List Controlled Clinical Trial: The Effect of a Mindfulness Meditation-Based Stress Reduction Program on Mood and Symptoms of Stress in Cancer OutpatientsLoving-kindness meditation increases socialx connectedness.Enhancing Compassion: A Randomized Controlled Trial of a Compassion Cultivation Training ProgramCompassion Training Alters Altruism and Neural Responses to SufferingMindfulness-Based Stress Reduction training reduces loneliness and pro-inflammatory gene expression in older adults: A small randomized controlled trialA randomized controlled trial of compassion cultivation training: Effects on mindfulness, affect, and emotion regulationCoherence Between Emotional Experience and Physiology: Does Body Awareness Training Have an Impact?The Brain&apos;s Ability to Look Within: A Secret to Self-MasteryThe underlying anatomical correlates of long-term meditation: Larger hippocampal and frontal volumes of gray matterMeditation experience is associated with increased cortical thicknessMindfulness training modifies subsystems of attentionInitial results from a study of the effects of meditation on multitasking performanceMental Training Affects Distribution of Limited Brain ResourcesMindfulness meditation improves cognition: Evidence of brief mental training","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"Summary and Table of Principles","date":"2017-01-19T15:32:18.000Z","path":"2017/01/19/MyShare/summary-and-table-of-principles/","text":"Principles —-译者：刘念 张帆” Principles 记录了Bridgewater创始人Ray Dalio对自己人生成功过程的反思，试图提供一套能通用的理念，帮助人们在生活中作出正确的选择。Ray Dalio，来自纽约中产之家，中年创建Bridgewater，2011年六十岁时Bridgewater成为世界上第一大对冲基金。 原则汇总列表 To Get the Culture Right…塑造良好的公司文化 … 1) Trust in truth. … 1) 相信真相 … 2) Realize that you have nothing to fear from truth. … 2) 你要知道，真相没什么可怕的。 … 3) Create an environment in which everyone has the right to understand what makes sense and no one has the right to hold a critical opinion withoutspeaking up about it. … 3) 创造这样一种氛围，只要是合理的事情，人人都能相互理解，没有人有权妄加批评，除非他能开诚布公地讲他的理由。 … 4) Be extremely open. … 4) 要极为开放。 … 5) Have integrity and demand it from others. … 5) 保持正直，要求别人也必须保持正直。 a) Never say anything about a person you wouldn’t say to them directly, and don’t try people without accusing them to their face. a) 若当面不对别人进行评论，背地里也不要说。若未曾当面控诉过别人，也不要背地里试探。 b) Don’t let “loyalty” stand in the way of truth and openness. b) 所谓的“忠诚”不能成为真相与开放的拦路虎。 … 6) Be radically transparent. … 6) 要极为透明。 a) Record almost all meetings and share them with all relevant people. a) 记录每一次会议，并分享给与之有关系的人。 … 7) Don’t tolerate dishonesty. … 7) 绝不容忍失信。 a) Don’t believe it when someone caught being dishonest says they have seen the light and will never do that sort of thing again. a) 不要相信失信之人说他已痛改前非，绝不再犯。 … 8) Create a Culture in which it is oK to make mistakes but unacceptable Not to identify, Analyze, and Learn From Them … 8) 创造这样一种文化：容许犯错，并从错误中进行识别、分析、吸取教训。 … 9) Recognize that effective, innovative thinkers are going to make mistakes … 9）要意识到处事高效创新的思考者都会犯错。 … 10) Do not feel bad about your mistakes or those of others. Love them! … 10）不要为自己或别人犯的错而郁郁寡欢，要热爱这些错！ … 11) Observe the patterns of mistakes to see if they are a product of weaknesses. … 11）仔细观察所犯错误的模式，看看它们是不是自身缺点所导致。 … 12) Do not feel bad about your weaknesses or those of others. … 12）不要因为自己或别人的缺点而感到糟糕。 … 13) Don’t worry about looking good - worry about achieving your goals. … 13）别老担心面子上过不过得去，而要担心是否会影响目的的实现。 … 14) Get over “blame” and “credit” and get on with “accurate” and “inaccurate.” … 14）别去管“责备”或“赞扬”，要习惯关注错误的归因是“精准”还是“不精准”。 … 15) Don’t depersonalize mistakes. … 15）错误归因要具体到个人。 … 16) Write down your weaknesses and the weaknesses of others to help remember and acknowledge them. … 16）写下你和别人的缺点，帮助自己牢记并承认这些缺点。 … 17) When you experience pain, remember to reflect. … 17）若因犯了错而感到痛苦，记得要反省。 … 18) Be self-reflective and make sure your people are self-reflective. … 18）要自我反思，也确保你身边的朋友们也都是懂得自我反思的。 … 19) Teach and reinforce the merits of mistake-based learning. … 19）教导和强化基于错误学习的优点。 a) The most valuable tool we have for this is the issues log (explained fully later) , which is aimed at identifying and learning from mistakes. a) 最有效的工具是建立“问题日志”（下文中将详述），旨在鉴别问题，并从中吸取教训。 …20) Constantly Get in Synch. …20）不断争取意见统一。 … 21) Constantly get in synch about what is true and what to do about it. … 21）要去伪存真，争取在解决方案上的意见统一。 … 22) Talk about “Is it true?” and “Does it make sense?” … 22）讨论“这是对的么？”和“这事有意义么？” … 23) Fight for right. … 23）认为对的事情，要据理力争。 … 24) Be assertive and open-minded at the same time. … 24）既要立场坚定，也要保持兼容并蓄。 a) Ask yourself whether you have earned the right to have an opinion. a) 问问自己，是否拥有发表观点的权利。 b) Recognize that you always have the right to have and ask questions. b) 要知道自己始终拥有提问的权利。 c) Distinguish open-minded people from closed-minded people. c) 区分思维开放的人和思想保守的人。 d) Don’t have anything to do with closed-minded, inexperienced people. d) 思想保守、缺乏经验之人，还是敬而远之吧。 e) Be wary of the arrogant intellectual who comments from the stands without having played on the field. e) 谨防纸上谈兵、夸夸其谈的人。 f) Watch out for people who think it’s embarrassing not to know. f) 谨防那些不知为耻的人。 … 25) Make sure responsible parties are open-minded about the questions and comments of others. … 25）确保主要责任方对于他人提出的问题与评论都是持开放态度的。 … 26) Recognize that conflicts are essential for great relationships because they are the means by which people determine whether their principles are alignedand resolve their differences. … 26）要意识到，冲突对于建立重要关系是大有裨益的，因为通过冲突人们才能确定对方的原则是否与自己的一致，便于化解分歧。 a) Expect more open-minded disagreements at Bridgewater than at most other firms. a) 在桥水联合基金公司里，要期待比其他公司更多的不拘于成见的分歧。 b) There is giant untapped potential in disagreement, especially if the disagreement is between two or more thoughtful people b) 分歧中蕴含巨大潜力，尤其对于两个有想法的人之间的分歧而言，更是如此。 … 27) Know when to stop debating and move on to agreeing about what should be done. … 27）知道什么时候终止辩论，进而讨论一致的解决方案。 a) However, when people disagree on the importance of debating something, it should be debated. a) 当有人质疑就某事展开辩论的重要性时，辩论是有必要的。 b) Recognize that “there are many good ways to skin a cat.” b) “办法总比问题多”。 c) For disagreements to have a positive effect, people evaluating an individual decision ordecision-maker must view the issue within a broader context. c) 要想通过分歧获得积极的结果，评估个人抉择或决策者的观点时需要树立大局观。 d) Distinguish between 1) idle complaints and 2) complaints that are meant to lead to improvement. d) 要区分两个概念：1）无用的抱怨 2）旨在实现改善的合理诉求。 … 28) Appreciate that open debate is not meant to create rule by referendum. … 28）赞赏开放式辩论的讨论方式并不意味着要通过全体投票来制定规则。 … 29) Evaluate whether an issue calls for debate, discussion, or teaching. … 29）要评估事项是否需要辩论、讨论或传授。 a) To avoid confusion, make clear which kind of conversation (debate, discussion, or teaching) you are having a) 为了避免产生误解，需要确定使用何种沟通方式（辩论、讨论或传授）。 b) Communication aimed at getting the best answer should involve the most relevant people. b) 旨在获得最佳方案的沟通，应该邀请最相关的人参与其中。 c) Communication aimed at educating or boosting cohesion should involve a broader set of people than would be needed if the aim were just getting the best answer. c) 旨在教育，增强凝聚力的沟通，如果目标是获取最优解决方案，那么就应该听取更多人的意见。 d) Leverage your communication. d) 充分利用各种沟通手段。 … 30) Don’t treat all opinions as equally valuable. … 30) 不要对所有的观点一视同仁。 a) A hierarchy of merit is not only consistent with a meritocracy of ideas but essential forit. a) 能力层级不仅需要与观点优先原则相一致，更是后者的必然要求。 … 31) Consider your own and others’ “believabilities.” … 31）思考自己和别人的可信度。 a) Ask yourself whether you have earned the right to have an opinion. a) 问问自己，是否拥有发表观点的权利。 b) People who have repeatedly and successfully accomplished the thing in question andhave great explanations when probed are most believable. b) 若有人多次成功解决悬而未决的问题，面对质疑也能讲得头头是道，这种人的观点最可信。 c) If someone asks you a question, think first whether you’re the responsible party/rightperson to be answering the question. c) 如果有人问你一个问题，首先要考虑自己是不是能够解答这个问题的人。 … 32) Spend lavishly on the time and energy you devote to “getting in synch”because it’s the best investment you can make. … 32）为了“意见统一”，花再多的时间与精力都不为过，因为这是最有价值的投资。 … 33) If it is your meeting to run, manage the conversation. … 33）如果是你主持会议，请协调好会议中各方的讨论。 a) Make it clear who the meeting is meant to serve and who is directing the meeting. a) 弄清会议的服务方和主持方。 b) Make clear what type of communication you are going to have in light of the objectivesand priorities. b) 根据会议目标与重点议题，确定会议的交流方式。 c) Lead the discussion by being assertive and open-minded. c) 主持讨论要坚定自信，开诚布公。 d) A small group (3 to 5) of smart, conceptual people seeking the right answers in anopen-minded way will generally lead to the best answer. d) 组织三至五人的小组讨论，邀请思维灵活、概念清晰的成员开放地寻求最佳方案，这种情况一般能取得最好的效果。 e) 1+1=3. f) Navigate the levels of the conversation clearly. f) 要明确讨论的层次的方向。 g) Watch out for “topic slip.” g) 注意不要让讨论偏题。 h) Enforce the logic of conversations. h) 增强沟通的逻辑性。 i) Worry about substance more than style. i) 实质内容比形式更重要。 j) Achieve completion in conversations. j) 在讨论中要得出一定结论。 k) Have someone assigned to maintain notes in meetings and make sure follow-throughhappens. k) 安排人做会议纪要，保证会议讨论的事项后续落实。 l) Be careful not to lose personal responsibility via group decision-making. l) 需要注意的是，集体决策时不要忘记了个人的职责。 … 34) Make sure people don’t confuse their right to complain, give advice, anddebate with the right to make decisions. … 34）不要将控诉、献言献策、辩论的权利同抉择权混为一谈。 … 35) Recognize that getting in synch is a two-way responsibility. … 35）要认识到，达成意见统一是双向责任。 … 36) Escalate if you can’t get in synch. … 36）如果意见无法统一，提交上级进行讨论。 To Get the People Right… 选对人，用对人 … 37) Recognize the Most Important Decisions You Make Are Who You Choose toBe Your Responsible Party … 37）要知道，最重要的选择是选谁做负责人。 … 38) Remember that almost everything good comes from having great peopleoperating in a great culture. …38）要记住，几乎所有的成功都是来自优秀的文化以及在其中工作的优秀的人才。 … 39) First, match the person to the design. … 39）首先，要选择合适的人参与规划。 a) Most importantly, find people who share your values. a) 最为重要的是要找同你价值观一致的人。 b) Look for people who are willing to look at themselves objectively and have character. b) 要找愿意客观评价自己且有自身性格特点的人。 c) Conceptual thinking and common sense are required in order to assign someone theresponsibility for achieving goals (as distinct from tasks) . c) 根据需要完成任务和实现目标，选择具备相关概念性思维和常识的人履职尽责。 … 40) Recognize that the inevitable responsible party is the person who bears theconsequences of what is done. … 40）必然责任人是需要承担一切后果的。 … 41) By and large, you will get what you deserve over time. … 41）总的来说，日积月累，你会得到你应得的。 … 42) The most important responsible parties are those who are most responsible forthe goals, outcomes, and machines (they are those higher in the pyramid) . … 42）最重要的责任人要为目标、结果和组织机构负主要责任（即位于组织里的上层的人）。 … 43) Choose those who understand the difference between goals and tasks to runthings. … 43）选择那些明白“目标”与“任务”之间差异的人来做事。 …44) Recognize that People Are Built Very Differently …44) 要知道每个人生来和后天塑造都是不同的。 … 45) Think about their very different values, abilities, and skills. … 45）考虑他们在价值观、能力和技能上的差异。 … 46） Understand what each person who works for you is like so that you know whatto expect from them. … 46）要了解你每个员工的情况，才能知道你能在他们身上有何种期待。 … 47) Recognize that the type of person you fit in the job must match therequirements for that job. … 47）岗位用人要与职位要求相匹配。 … 48) Use personality assessment tests and quality reflections on experiences tohelp you identify these differences. … 48）通过性格测试以及员工工作经历中反映的性格特点来帮助自己了解他们之间的差异。 … 49) Understand that different ways of seeing and thinking make people suitable fordifferent jobs. … 49）要知道，每个人的观察与思考方式不同，因此适合的职位也不同。 a) People are best at the jobs that require what they do well. a) 人们在所擅长的领域工作表现最佳。 b) If you’re not naturally good at one type of thinking, it doesn’t mean you’re precludedfrom paths that require that type of thinking b) 若你天生不擅长某种思维方式，并不意味着就做不好需要这种思维方式的工作。 … 50) Don’t hide these differences. Explore them openly with the goal of figuring outhow you and your people are built so you can put the right people in the rightjobs and clearly assign responsibilities. … 50）不要隐藏这些差异，坦诚沟通，以深入了解自己和员工，把合适的人用在合适的岗位上，并明确任务分工。 … 51) Remember that people who see things and think one way often have difficultycommunicating and relating to people who see things and think another way. … 51）要记住，看待事物与思维方式不同的人，在交流和相处上是存在困难的。 … 52) Hire Right, Because the Penalties of Hiring Wrong Are Huge … 52）雇佣对的人，用错了人，代价会极为惨重。 … 53) Think through what values, abilities, and skills you are looking for. … 53) 仔细审度自己想要的员工应具备什么样的价值观、能力和技能。 … 54) Weigh values and abilities more heavily than skills in deciding whom to hire. … 54）招聘员工时，要多考虑员工的价值观与能力，这比技能更重要。 … 55) Write the profile of the person you are looking for into the job description. … 55）招聘员工时，在岗位说明里描述希望招到一个什么样的员工。 … 56) Select the appropriate people and tests for assessing each of these qualitiesand compare the results of those assessments to what you’ve decided isneeded for the job. … 56）挑选合适人选，根据相应工作岗位应具备的素质要求对他们进行考核评估，比对评估结果与素质要求。 a) Remember that people tend to pick people like themselves, so pick interviewers whocan identify what you are looking for. a) 要记住，人们往往倾向于选择和自己相似的人，因此应挑选那些了解自己想雇佣何种员工的人担任面试考官。 b) Understand how to use and interpret personality assessments. b) 要知道如何使用和解读性格测试。 c) Pay attention to people’s track records. c) 注意受聘者的过往业绩。 d) Dig deeply to discover why people did what they did. d) 深入挖掘，探寻他们过往行为的动机。 e) Recognize that performance in school, while of some value in making assessments,doesn’t tell you much about whether the person has the values and abilities you arelooking for. e) 要认识到，尽管学校表现在进行评估时有一定价值，但却不能体现应聘者是否具备你想要的价值观或能力。 f) Ask for past reviews. f) 要求提供过往业绩的评估。 g) Check references. g) 参考推荐信。 … 57) Look for people who have lots of great questions. … 57）寻找可提出好问题的员工。 … 58) Make sure candidates interview you and Bridgewater. … 58）确保应聘者对你和桥水联合基金也进行了面试。 … 59) Don’t hire people just to fit the first job they will do at Bridgewater; hire peopleyou want to share your life with. … 59）不要聘用那些只把桥水联合基金当做第一份工作的人，要用那些你愿意与之分享人生的人。 … 60) Look for people who sparkle, not just “another one of those.” … 60）要选熠熠生辉之人，而不是又一个平庸之辈。 … 61) Hear the click: Find the right fit between the role and the person. … 61）听到咔哒声：所需职位和聘用之人一定要匹配合适。 … 62) Pay for the person, not for the job. … 62）以人论酬，而不是以岗论酬。 … 63) Recognize that no matter how good you are at hiring, there is a high probabilitythat the person you hire will not be the great person you need for the job. … 63）要知道无论你在招聘人才方面有多在行，你所聘用的人选都很有可能不是岗位的最佳人选。 … 64) Manage as Someone Who Is Designing and Operating a Machine to Achieve the Goal … 64）像设计和运行一台机器一样做好管理工作，才能实现预期目标。 … 65) Understand the differences between managing, micromanaging, and notmanaging. … 65）明白管理、微观管理和不管理之间的区别。 a) Managing the people who report to you should feel like “skiing together.” a) 管理下属应该感觉像是一同滑雪一样。 b) An excellent skier is probably going to be more critical and a better critic of anotherskier than a novice skier. b) 优秀的滑雪者更能挑出对方的毛病，这是初学者很难做到的。 … 66) Constantly compare your outcomes to your goals. … 66）不断比较完成情况和目标之间的差距。 … 67) Look down on your machine and yourself within it from the higher level. … 67）在所管理的机制内，从更高层次审视自己和机制。 … 68) Connect the case at hand to your principles for handling cases of that type. … 68）解决问题要参照同类别问题解决时所遵循的原则。 … 69) Conduct the discussion at two levels when a problem occurs: 1) the “machine”level discussion of why the machine produced that outcome and 2) the “caseat hand” discussion of what to do now about the problem. … 69）问题出现时，要展开两个层面的讨论：1）从机制层面来讨论，为什么会出现这个问题？2）单从问题本身层面来讨论，当下应如何解决。 … 70) Don’t try to be followed; try to be understood and to understand others. … 70）和员工的关系不是服从与被服从，而应是相互理解。 a) Don’t try to control people by giving them orders. a) 不要给员工下命令控制他们。 b) Communicate the logic and welcome feedback. b) 沟通要有逻辑，多听取反馈意见。 … 71) Clearly assign responsibilities. … 71）明确责任分工。 … 72) Hold people accountable and appreciate them holding you accountable. … 72）对员工进行工作问责制度，若他们问责你，要感谢他们。 a) Distinguish between failures where someone broke their “contract” from ones where there was no contract to begin with. a) 要分清楚，有些工作上的失败是因为员工没履行一开始的“约定”，而有些则是因为一开始就没有指定“约定”。 … 73) Avoid the “sucked down” phenomenon. … 73）避免“上级卷入下级工作职责”现象 a) Watch out for people who confuse goals and tasks, because you can’t trust people with responsibilities if they don’t understand the goals. a) 提防那些混淆目标与任务的员工，不能理解工作目标的员工是不值得信任的。 … 74) Think like an owner, and expect the people you work with to do the same. … 74）要有主人翁思维，并希望员工们也能具备这种思维方式。 … 75) Force yourself and the people who work for you to do difficult things. … 75）强迫自己和员工迎难而上。 a) Hold yourself and others accountable. a) 对自己和他人要采取问责制度。 … 76) Don’t worry if your people like you; worry about whether you are helping your people and Bridgewater to be great. … 76）别担忧员工喜不喜欢你，还是多想想自己所做的事情能不能帮员工和桥水联合基金获得成功吧。 … 77) Know what you want and stick to it if you believe it’s right, even if others want to take you in another direction. … 77）知道自己想要什么，坚信自己认为的是正确的事情，不要轻易被人牵着鼻子走。 … 78) Communicate the plan clearly. … 78）计划沟通要清晰明了。 a) Have agreed-upon goals and tasks that everyone knows (from the people in the departments to the people outside the departments who oversee them) . a) 已达成共识的目标任务要让所有相关人士都知道。（包括有关部门的员工及监管层的领导） b) Watch out for the unfocused and unproductive “we should … (do something) .” b) 要警惕交流中出现没有重点，低效无用的句式：我们应该如何。 … 79) Constantly get in synch with your people. … 79）保持与员工意见统一。 … 80) Get a “threshold level of understanding” … 80）充分了解工作相关情况。 … 81) Avoid staying too distant. … 81）避免和员工产生距离感。 a) Tool: Use daily updates as a tool for staying on top of what your people are doing and thinking. a) 工具：使用每日进度更新了解员工工作与思考的情况。 … 82) Learn confidence in your people—don’t presume it. … 82）对员工的信任度不能先入为主，要逐步去了解。 … 83) Vary your involvement based on your confidence. … 83）处理问题时，根据自己感觉有把握的情况来调整参与度。 … 84) Avoid the “theoretical should.” … 84）避免说“理论上应该”。 … 85) Care about the people who work for you. … 85）关爱员工。 … 86) Logic, reason, and common sense must trump everything else in decision-making. … 86）决策中最重要的是讲究逻辑、给明理由且符合常识。 … 87) While logic drives our decisions, feelings are very relevant. … 87）尽管做决策时主要依靠逻辑，但情感感觉也是很重要的。 … 88) Escalate when you can’t adequately handle your responsibilities, and make sure that the people who work for you do the same. … 88）如果发现自己无法有效解决问题时，应将问题提交给上级，确保为你工作的员工们也是这样操作的。 a) Make sure your people know to be proactive. a) 确保员工主动积极。 b) Tool: An escalation button. b) 工具：升级按钮。 … 89) Involve the person who is the point of the pyramid when encountering material cross-departmental or cross sub-departmental issues. … 89）跨部门间或跨子部门间出现问题时，需要上级部门，也就是这个组织的“金字塔尖”的那个人来参与定夺。 … 90) Probe Deep and Hard to Learn What to Expect from Your “Machine” … 90) 认真深入调查，了解机制能够创造什么。 … 91) Know what your people are like, and make sure they do their jobs excellently. … 91) 了解自己的员工，确保他们顺利完成工作。 … 92) Constantly probe the people who report to you, and encourage them to probe you. … 92) 不断调查直接向你汇报的下级，并鼓励他们调查你。 a) Remind the people you are probing that problems and mistakes are fuel for improvement. a) 提醒你调查的员工，问题和错误是改进的动力。 … 93) Probe to the level below the people who work for you. … 93) 调查你属下的下级。 … 94) Remember that few people see themselves objectively, so it’s important to welcome probing and to probe others. … 94) 记住，只要极少人能够客观地看待自己。因此，你应该欢迎调查，同时要去调查别人。 … 95) Probe so that you have a good enough understanding of whether problems are likely to occur before they actually do. … 95) 调查有助于你在问题出现之前充分了解其出现的可能性。 a) When a crisis appears to be brewing, contact should be so close that it’s extremely unlikely that there will be any surprises. a) 如果说有迹象显示危机正在酝酿，那么你就应该保持密切关注，就能在其发生之时没有任何惊讶。 b) Investigate and let people know you are going to investigate so there are no surprises and they don’t take it personally. b) 调查情况的时候要告诉被调查的人，不要让被调查的人措手不及，让他们知道你是对事不对人。 … 96) Don’t “pick your battles.” Fight them all. … 96) 不要挑肥拣瘦，要解决所有问题。 … 97) Don’t let people off the hook. … 97) 不要让人逃避责任。 … 98) Don’t assume that people’s answers are correct. … 98) 不要想当然地认为人们的答案都是正确的。 … 99) Make the probing transparent rather than private. … 99) 将调查透明化，不要私下进行。 … 100) Evaluate People Accurately, Not “Kindly” … 100) 准确地，而不是善意地评估员工。 … 101) Make accurate assessments. … 101) 进行准确评估。 a) Use evaluation tools such as performance surveys, metrics, and formal reviews to document all aspects of a person’s performance. These will help clarify assessments and communication surrounding them. a) 使用各种评估工具来记录员工全方位表现，包括工作表现调查问卷、计量图表、正式评估报告。这些工具能够帮助你将员工的相关评估和沟通整理清楚。 b) Maintain “baseball cards” and/or “believability matrixes” for your people. b) 为员工建立“棒球记录卡”以及“可信度图表”。 … 102) Evaluate employees with the same rigor as you evaluate job candidates. … 102) 以同等的严厉程度来评价员工、雇佣新人。 … 103) Know what makes your people tick, because people are your most important resource. … 103) 充分了解员工的特质，因为人才是最重要的资源。 … 104) Recognize that while most people prefer compliments over criticisms, there is nothing more valuable than accurate criticisms. … 104) 要认识到，尽管大多数人都喜欢被表扬，不喜欢被批评，但准确的批评却是最宝贵的。 … 105) Make this discovery process open, evolutionary, and iterative. … 105) 将这一发现过程公开，循环往复，促其演变。 … 106) Provide constant, clear, and honest feedback, and encourage discussion of this feedback. … 106) 提供频繁的、清楚的、诚实的反馈，并鼓励就这些反馈进行讨论。 a) Put your compliments and criticisms into perspective. a) 正确对待表扬与批评。 b) Remember that convincing people of their strengths is generally much easier than convincing them of their weaknesses. b) 记住，让别人看到自己的长处通常比让他们看到自己的短处要容易得多。 c) Encourage objective reflection c) 鼓励客观的反思。 d) Employee reviews: d) 员工评估报告: … 107) Understand that you and the people you manage will go through a process of personal evolution. … 107) 你以及你管理的人都会经历个人成长的过程。 … 108) Recognize that your evolution at Bridgewater should be relatively rapid and a natural consequence of discovering your strengths and weaknesses; as a result, your career path is not planned at the outset … 108) 要认识到，你在桥水基金的成长会相对较快，这是了解自己优缺点的必然结果。因此，你的职业规划不是在一开始就定下来的。 … 109) Remember that the only purpose of looking at what people did is to learn what they are like. … 109) 要记住，了解员工的过去是为了了解他们的特质。 a) Look at patterns of behaviors and don’t read too much into any one event. a) 关注行为模式，但不要过分解读任何单一事件。 b) Don’t believe that being good or bad at some things means that the person is good or bad at everything. b) 不要认为擅长（或不擅长）某件事的人就一定对所有的事都擅长（或不擅长）。 … 110) If someone is doing their job poorly, consider whether this is due to inadequate learning (i.e., training/experience) or inadequate ability … 110) 如果某人工作做得很差劲，要去想这是因为缺少学习（培训或相关经验）还是因为缺少能力。 … 111) Remember that when it comes to assessing people, the two biggest mistakes are being overconfident in your assessment and failing to get in synch on that assessment. Don’t make those mistakes. … 111) 记住，在评估员工时最常犯的两个错误是：对于评估结果过于自信；对于评估结果意见无法达成一致。不要犯这两个错误。 a) Get in synch in a non-hierarchical way regarding assessments. a) 针对评估争取意见一致时，要以非等级的方式来进行。 b) Learn about your people and have them learn about you with very frank conversations about mistakes and their root causes. b) 通过开展坦诚对话，讨论错误以及犯错的根源，来了解彼此。 … 112) Help people through the pain that comes with exploring their weaknesses. … 112) 帮助人们渡过发现缺点的阵痛期。 … 113) Recognize that when you are really in synch with people about weaknesses, whether yours or theirs, they are probably true. … 113) 要认识到，如果你就某人的弱点达成一致，不管是你的还是其他人的，这个弱点多半是事实。 … 114) Remember that you don’t need to get to the point of “beyond a shadow of a doubt” when judging people. … 114) 记住，在评价员工时，并不需要达到“不含一丝质疑”的程度。 … 115) Understand that you should be able to learn the most about what a person is like and whether they are a “click” for the job in their first year. … 115) 要知道，你是能够了解一个人的大部分特质的，也能够在他们第一年来时判断他们是否能够胜任工作。 … 116) Continue assessing people throughout their time at Bridgewater. … 116) 员工在桥水联合基金工作期间，持续对员工进行评估。 … 117) Train and Test People Through Experiences … 117) 通过实战经验来培训、测试员工。 … 118) Understand that training is really guiding the process of personal evolution. … 118) 要知道，培训对个人的成长过程起着指引作用。 … 119) Know that experience creates internalization … 119) 经验能够内化成为知识。 … 120) Provide constant feedback to put the learning in perspective … 120) 正确对待学习，频繁提供反馈。 … 121) Remember that everything is a case study. … 121) 要记住，每件事都是一个案例 … 122) Teach your people to fish rather than give them fish. … 122) 授人以鱼不如授人以渔。 … 123) Recognize that sometimes it is better to let people make mistakes so that they can learn from them rather than tell them the better decision. … 123) 要认识到，有时让人犯错并从中吸取教训要比直接告诉他们一个更好决定更明智。 a) When criticizing, try to make helpful suggestions. a) 在批评时，要提一些有建设性的意见。 b) Learn from success as well as from failure. b) 从成功中学习，也要从失败中学习。 … 124) Know what types of mistakes are acceptable and unacceptable, and don’t allow the people who work for you to make the unacceptable ones. … 124) 分清哪些错误是可以接受的，哪些是不能接受的。不要让员工犯不可接受的错误。 … 125) Recognize that behavior modification typically takes about 18 months of constant reinforcement. … 125) 要认识到，一般需要18个月持续不断的巩固才能实现行为矫正。 … 126) Train people; don’t rehabilitate them. … 126) 培训员工，而不是改造员工。 a) A common mistake: training and testing a poor performer to see if he or she can acquire the required skills without simultaneously trying to assess their abilities. a) 常见错误：在没有对一个工作表现差的员工进行能力评估之前，培训、测试该员工，试图让他获得所需技能。 … 127) After you decide “what’s true” (i.e., after you figure out what your people are like) , think carefully about “what to do about it.” … 127) 在找到真相之后（即了解到员工的真实情况），谨慎思考下一步该做什么。 … 128) Sort People into Other Jobs at Bridgewater, or Remove Them from Bridgewater … 128) 在桥水基金内部进行换岗，或将其解雇。 … 129) When you find that someone is not a good “click” for a job, get them out of it ASAP. … 129) 一旦发现某人不能胜任工作，尽快将其调离该职位。 … 130) Know that it is much worse to keep someone in a job who is not suited for it than it is to fire someone. … 130) 勉强将某人留在不合适的职位上要比将其开除更糟糕。 … 131) When people are “without a box,” consider whether there is an open box at Bridgewater that would be a better fit. If not, fire them. … 131) 当员工没有岗位时，思考桥水公司内部是否还有更适合的岗位。如果没有，应该将该员工开除。 … 132) Do not lower the bar. … 132) 不要降低标准。 To Perceive, Diagnose, and Solve Problems… 发现、诊断、解决问题 … 133) Know How to Perceive Problems Effectively … 133) 懂得如何有效地发现问题 … 134) Keep in mind the 5-Step Process explained in Part 2. … 134) 时刻牢记在第二部分阐释过的五步流程。 … 135) Recognize that perceiving problems is the first essential step toward great management. … 135) 要认识到，发现问题是优秀管理的第一步。 … 136) Understand that problems are the fuel for improvement. … 136) 要理解，问题是提升的动力。 … 137) You need to be able to perceive if things are above the bar (i.e., good enough) or below the bar (i.e., not good enough) , and you need to make sure your people can as well … 137) 你需要观察事情是在预期之上还是在预期之下，确保你的员工也有此观察力。 … 138) Don’t tolerate badness. … 138) 不要容忍问题。 … 139) “Taste the soup.” … 139) “品尝汤的味道”。 … 140) Have as many eyes looking for problems as possible. … 140) 找尽可能多的人手来一起发现问题。 a) “Pop the cork.” a) “拔出瓶塞。” b) Hold people accountable for raising their complaints. b) 将投诉作为员工义务来进行。 c) The leader must encourage disagreement and be either impartial or open-minded. c) 领导者必须鼓励提出不同的意见，不偏不倚，思想开放。 d) The people closest to certain jobs probably know them best, or at least have perspectives you need to understand, so those people are essential for creating improvement. d) 与某项工作接触最密切的人应该最了解该项工作，或者至少有值得你借鉴的观点。因此，这些人对于促进提升是很重要的。 … 141) To perceive problems, compare how the movie is unfolding relative to your script … 141) 参照你的剧本，比较电影情节的发展，通过这种方式来发现问题。 … 142) Don’t use the anonymous “we” and “they,” because that masks personal responsibility—use specific names. … 142) 不要使用模糊的人称，如“我们”或“他们”，这样做会掩盖个人责任。请使用具体人名。 … 143) Be very specific about problems; don’t start with generalizations. … 143) 具体问题要具体对待，不要一开始就过于宽泛。 … 144) Tool: Use the following tools to catch problems: issues logs, metrics, surveys, checklists, outside consultants, and internal auditors. … 144) 工具：使用以下工具来捕捉问题：问题日志、计量图表、调查问卷、清单、外部咨询，以及内部审计。 … 145) The most common reason problems aren’t perceived is what I call the “frog in the boiling water” problem. … 145) 最常见的无法观察到原因的问题是被称为“温水煮青蛙”的问题。 … 146) In some cases, people accept unacceptable problems because they are perceived as being too difficult to fix. Yet fixing unacceptable problems is actually a lot easier than not fixing them, because not fixing them will make you miserable. … 146) 在某些情况下，因为某些问题实在难以解决，人们不得不接受那些不可接受的问题。但是，解决那些不可接受的问题其实要比不解决它们更容易，因为不解决它们，将后患无穷。 a) Problems that have good, planned solutions are completely different from those that don’t. a) 已经拥有有效周密的解决方案的问题与那些没有解决方案的问题天差地别。 … 147) Diagnose to Understand What the Problems Are Symptomatic Of … 147) 通过诊断分析来理解问题症结所在 … 148) Recognize that all problems are just manifestations of their root causes, so diagnose to understand what the problems are symptomatic of. … 148) 要认识到所有问题只是其根本原因的表征，所以要通过诊断分析来理解问题症结所在。 … 149) Understand that diagnosis is foundational both to progress and quality relationships. … 149) 要明白诊断分析是发展公司和建立良好人际关系的基础。 … 150) Ask the following questions when diagnosing. … 150) 诊断分析时要问自己以下几个问题。 … 151) Remember that a root cause is not an action but a reason. … 151) 要谨记根本原因不是行为而是原因。 … 152) Identify at which step failure occurred in the 5-Step Process. … 152) 找出五步流程中哪一步失败了。 … 153) Remember that a proper diagnosis requires a quality, collaborative, and honest discussion to get at the truth. … 153) 要做好诊断分析，需要深入讨论，共同协作，态度诚恳，只有这样才能触及问题真相。 … 154) Keep in mind that diagnoses should produce outcomes. … 154) 要记得诊断分析应该出结果。 … 155) Don’t make too much out of one “dot”—synthesize a richer picture by squeezing lots of “dots” quickly and triangulating with others. … 155) 不要试图从一个“点”中获取大量信息，而应该快速压榨大量的“点”，并将它们相互联结，从而形成更丰富的图像。 … 156) Maintain an emerging synthesis by diagnosing continuously… 156) 要进行持续性的诊断分析，整合新思路。 … 157) To distinguish between a capacity issue and a capability issue, imagine how the person would perform at that particular function if they had ample capacity. … 157) 要区别才能问题和能力问题，就去想象如果一个人有足够的才能，那他在这个特定职能上的表现会是如何。 … 158) The most common reasons managers fail to produce excellent results or escalate are … 158) 管理者绩效不佳或未能升职最常见的原因有： … 159) Avoid “Monday morning quarterbacking.” … 159) 不要做事后诸葛。 … 160) Identify the principles that were violated. … 160) 找出违背了哪些原则。 … 161) Remember that if you have the same people doing the same things, you should expect the same results. … 161) 要记得如果你让同样的人做同样的事，那么得到的也应该是同样的结果。 … 162) Use the following “drilldown” technique to gain an 80/20 understanding of a department or sub-department that is having problems. … 162) 运用下述的“钻取”方法，重点理解部门或分部面临的问题。 … 163) Put Things in Perspective … 163）理清思维 … 164) Go back before going forward. … 164) 前进之前请先回顾。 a) Tool: Have all new employees listen to tapes of “the story” to bring them up to date. a) 方法：让所有新员工听“故事”磁带，帮助他们了解公司截止到目前的发展状况。 … 165) Understand “above the line” and “below the line” thinking and how to navigate between the two. … 165）理解“宏观”和“微观”的思维模式及其适用范围。 … 166) Design Your Machine to Achieve Your Goals … 166) 设定机制，达成目标 … 167) Remember: You are designing a “machine” or system that will produce outcomes. … 167）要记得：你是在设定一个能够有产出的“机制”或系统。 a) A short-term goal probably won’t require you to build a machine. a) 短期目标可能不需要你设立机制。 b) Beware of paying too much attention to what is coming at you and not enough attention to what your responsibilities are or how your machine should work to achieve your goals. b) 注意不要太过关注你眼前的问题，而忽视了你的职责，以及机制怎样运行并达成目标。 … 168) Don’t act before thinking. Take the time to come up with a game plan … 168）三思而后行。花点时间做计划。 … 169) The organizational design you draw up should minimize problems and maximize capitalization on opportunities. … 169）你拟出的组织设计应该能最小化问题，最大化机会。 … 170) Put yourself in the “position of pain” for a while so that you gain a richer understanding of what you’re designing for. … 170) 将自己体会一段时间的“痛点”，你就会更理解自己的设定针对的是什么样的对象。 … 171) Recognize that design is an iterative process; between a bad “now” and a good “then” is a “working through it” period. … 171) 要认识到，机构设置是一个循环往复的过程，在一个糟糕的“现在”和一个美好的“未来”之间，是“努力实现”的过程。 … 172) Visualize alternative machines and their outcomes, and then choose. … 172) 将可替代的其他机制及其成果形象化，以供选择。 … 173) Think about second- and third-order consequences as well as first-order consequences. … 173) 思考二、三级效应与一级效应。 … 174) Most importantly, build the organization around goals rather than tasks. … 174) 以目标为中心建立机构，而不是以任务为中心，这是重中之重。 a) First come up with the best workflow design, sketch it out in an organizational chart, visualize how the parts interact, specify what qualities are required for each job, and, only after that is done, choose the right people to fill the jobs. a) 首先，设计最佳工作流，在一个组织图中画出草图，将各部分互动情况形象化，标出每个职位所需的特质，最后，选择合适的员工来填充岗位 (根据他们的能力和意愿来进行需求匹配) 。 b) Organize departments and sub-departments around the most logical groupings. b) 按照最富逻辑的组团方式来组建部门和子部门。 c) Make departments as self-sufficient as possible so that they have control over the resources they need to achieve the goals. c) 让每个部门尽可能的自给自足，以此确保他们能够自主控制达成目标所需的资源。 d) The efficiency of an organization decreases and the bureaucracy of an organization increases in direct relation to the increase in the number of people and/or the complexity of the organization. d) 公司效率的下降与官僚作风的扩张程度与公司人数增长和复杂性提升直接相关。 … 175) Build your organization from the top down. … 175) 自上而下组建公司。 a) Everyone must be overseen by a believable person who has high standards. a) 应该给每名员工安排一位拥有高标准的靠谱的人，负责对其进行监管。 b) The people at the top of each pyramid should have the skills and focus to manage their direct reports and a deep understanding of their jobs. b) 位于金字塔尖的管理者应该具备管理直接下属的能力和精力，对下属的工作职责有深入的了解。 c) The ratio of senior managers to junior managers and to the number of people who work two levels below should be limited, to preserve quality communication and mutual understanding. c) 高级管理者与初级管理者、管理者与两级以下的被管理者之间的人数比例应该限定在一定范围内，以确保高质量的沟通与互相理解。 d) The number of layers from top to bottom and the ratio of managers to their direct reports will limit the size of an effective organization. d) 自上而下的层级数量以及管理者与直接下属的比例会制约高效公司的规模。 e) The larger the organization, the more important are 1) information technology expertise in management and 2) cross-department communication (more on these later) . e) 公司越大，越需要1）在管理中运用信息技术；2）跨部门沟通（后详）。 f) Do not build the organization to fit the people. f) 不要为了迁就人员而组建机构。岗位是基于所需完成的工作来设定的，而不是基于人们想要干什么事，能干什么事而设定。 … 176) Have the clearest possible delineation of responsibilities and reporting lines. … 176) 尽可能清楚地描述工作职责与级别关系。 a) Create an organizational chart to look like a pyramid, with straight lines down that don’t cross. a) 建立一个金字塔形的组织图，画出不相交的竖线 … 177) Constantly think about how to produce leverage. … 177) 经常思考该如何让事情发挥最大的效果。 a) You should be able to delegate the details away. a) 你应该将细节工作委派给他人。 b) It is far better to find a few smart people and give them the best technology than to have a greater number of ordinary and less well-equipped people. b) 与其让一众能力平庸之人获得不那么精良的装备，不如只给一小部分聪明人配备最好的技术。c) Use “leveragers.” c) 使用执行力强的人。 … 178) Understand the clover-leaf design.… 178) 理解四叶草形的机构设置。 … 179) Don’t do work for people in another department or grab people from another department to do work for you unless you speak to the boss. … 179) 不要为其他部门做事，也不要在没有和其他部门领导交涉的情况下从其他部门抓人来为你做事。 … 180) Watch out for “department slip.” … 180) 谨防“部门职能错位”。 … 181) Assign responsibilities based on workflow design and people’s abilities, not job titles. … 181) 在分配责任时，注意考虑工作流的设置和员工的能力，而不是岗位头衔。 … 182) Watch out for consultant addiction. … 182) 谨防过分依赖外部咨询。 … 183) Tool: Maintain a procedures manual. … 183) 工具：使用流程手册。 … 184) Tool: Use checklists. … 184) 工具：使用任务清单。 a) Don’t confuse checklists with personal responsibility. a) 不要将任务清单与个人责任混为一谈。 b) Remember that “systematic” doesn’t necessarily mean computerized. b) 记住，系统性并不意味着必须全部由电脑来控制。 c) Use “double-do” rather than “double-check” to make sure mission-critical tasks are done correctly. c) 要“重复工作”，不要“重复检查”，保证重要任务完成无误。 … 185) Watch out for “job slip.” … 185) 谨防“职责错位”。 … 186) Think clearly how things should go, and when they aren’t going that way, acknowledge it and investigate … 186) 考虑清楚工作应该如何开展，如果事情不是朝预期的方向发展，需要及时发现并展开调查。 … 187) Have good controls so that you are not exposed to the dishonesty of others and trust is never an issue. … 187) 加强监管，谨防他人的不诚实，使信任不再成为问题。 a) People doing auditing should report to people outside the department being audited, and auditing procedures should not be made known to those being audited. a) 审计人员应该向被审计部门之外的人汇报审计结果，同时审计程序不能向被审计对象透露。 b) Remember: There is no sense in having laws unless you have policemen (auditors) . b) 记住，如果没有警察（审计人员），法律则形同虚设。 … 188) Do What You Set Out to Do … 188) 按计划进行。 … 189) Push through! … 189) 坚持到底！ To Make Decisions Effectively… 有效决策 …190) Recognize the Power of Knowing How to Deal with Not Knowing …190) 认可处理无知的能力 … 191) Recognize that your goal is to come up with the best answer, that the probability of your having it is small, and that even if you have it, you can’t be confident that you do have it unless you have other believable people test you. … 191) 要认识到，你的目标是找到最佳答案，而找到最佳答案的可能性是很小的，就算你真的找到了，你也无法确信自己成功了，你必须让其他的靠谱的人来对你进行测试。 … 192) Understand that the ability to deal with not knowing is far more powerful than knowing … 192) 要知道，处理无知的能力要比知道某事的能力更强大。 a) Embrace the power of asking: “What don’t I know, and what should I do about it?” a) 鼓励提问：“有什么是我不知道的呢？那我该怎么办呢？” b) Finding the path to success is at least as dependent on coming up with the right questions as coming up with answers. b) 寻找成功的道路上，提出正确的问题与获得正确答案同等重要。 … 193) Remember that your goal is to find the best answer, not to give the best one you have. … 193) 记住，你的目标是寻找最佳答案，而不是在已有的答案中挑一个最好的。 … 194) While everyone has the right to have questions and theories, only believable people have the right to have opinions … 194) 每个人都有权拥有自己的问题和理论，但是只有靠谱的人才有权提出观点。 … 195) Constantly worry about what you are missing. … 195) 时刻警惕考虑不周的情况。 a) Successful people ask for the criticism of others and consider its merit. a) 成功人士会征求别人的批评意见，并看到批评的价值。 b) Triangulate your view. b) 吸收众人观点。 … 196) Make All Decisions Logically, as Expected Value Calculations … 196）做决定要讲逻辑，基于期望值测算 … 197) Considering both the probabilities and the payoffs of the consequences, make sure that the probability of the unacceptable (i.e., the risk of ruin) is nil. … 197）考虑结果的可能性与收益，确保不可接受结果（如搞砸的风险）的可能性为零。 a) The cost of a bad decision is equal to or greater than the reward of a good decision, so knowing what you don’t know is at least as valuable as knowing. a) 不良决策的代价等同于，甚至严重于正确决策带来的回报，因此，知道自己没掌握什么，至少和知道自己掌握什么一样有价值。 b) Recognize opportunities where there isn’t much to lose and a lot to gain, even if the probability of the gain happening is low. b) 鉴别出有亏少利多的机会，就算获利可能性低也要试试。 c) Understand how valuable it is to raise the probability that your decision will be right by accurately assessing the probability of your being right. c) 精准评估，提高决策的准确性十分有价值。 d) Don’t bet too much on anything. Make 15 or more good, uncorrelated bets. d) 任何事情都不能押过多赌注，要留15%或更多的余地给无关联的赌注。 … 198) Remember the 80/20 Rule, and Know What the Key 20% Is … 198）牢记80/20法则，并知道那关键的20%是什么。 … 199) Distinguish the important things from the unimportant things and deal with the important things first. … 199）区分重要事项和不重要事项，先处理重要事项。 a) Don’t be a perfectionist a) 不要做完美主义者。 b) Since 80% of the juice can be gotten with the first 20% of the squeezing, there are relatively few (typically less than five) important things to consider in making a decision. b) 压榨过程进行20%的时候就能得到80%的果汁，所以做决定时，最重要的事项是比较少的（一般少于五件）。 c) Watch out for “detail anxiety,” c) 警惕“细节焦虑”。 d) Don’t mistake small things for unimportant things, because some small things can be very important d) 不要混淆小事情和不重要事项，因为小事情也可能很重要。 … 200) Think about the appropriate time to make a decision in light of the marginal gains made by acquiring additional information versus the marginal costs of postponing the decision. … 200）要根据获取额外信息而取得的边际收益与延迟决定所造成的边际成本的比较与权衡，来思考合适的时间做出一个决定。 … 201) Make sure all the “must do’s” are above the bar before you do anything else. … 201）确保所有“必须完成的任务”在完成时优先于其他任何事情。 … 202) Remember that the best choices are the ones with more pros than cons, not those that don’t have any cons. Watch out for people who tend to argue against something because they can find something wrong with it without properly weighing all the pros against the cons. … 202）要记住，最佳选择是基于赞同意见多于反对意见的，当然不是说不允许任何反对意见。要警惕有人在不恰当权衡正反意见的基础上挑错，进而反对。 … 203) Watch out for unproductively identifying possibilities without assigning them probabilities, because it screws up prioritization. …203）要警惕在没有考虑所有可能性的情况下，就低效地确定其可能性，这样会打乱优先次序。 … 204) Understand the concept and use the phrase “by and large.” … 204）理解并运用“总体来说”的概念。 a) When you ask someone whether something is true and they tell you that “It’s not totally true,” it’s probably true enough. a) 当询问某事的真实性时，若对方告诉你“也不完全是事实”时，其实也八九不离十了。 … 205) Synthesize … 205）综合 … 206) Understand and connect the dots. … 206） 理解并串联关键点 … 207) Understand what an acceptable rate of improvement is, and that it is the level and not the rate of change that matters most. … 207）知道可接受的改善速度是多少，因为改变的程度比改变的速度更关键。 … 208) If your best solution isn’t good enough, think harder or escalate that you can’t produce a solution that is good enough. … 208）如果最佳方案不够令人满意，就得尽力想出更好的办法，实在想不到就提交给上级。 … 209) Avoid the temptation to compromise on that which is uncompromisable. … 209）经受住诱惑，避免让不可妥协的事情得到妥协。 … 210) Don’t try to please everyone … 210）不要试图让所有人都满意。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Management","slug":"Management","permalink":"http://ipcreator.me/tags/Management/"}]},{"title":"向死而生","date":"2017-01-19T11:02:06.000Z","path":"2017/01/19/MyShare/credits-of-death /","text":"李开复《向死而生：我修的死亡学分》 脱去虚名与成就，你的人生还剩下什么? 7 个学分 健康无价； 一切事物都是有它的理由； 珍惜缘分，学会感恩和爱； 学会如何生活，活在当下； 经得住诱惑； 人人平等，善待每一个人； 我们的人生究竟是为什么？ 李开复演讲实录： 谢谢各位，非常感谢今天各位嘉宾的到来。让我有这个机会跟大家分享一下我生病的心路路程。平时我工作的时候，非常热爱我的工作，包括今天，我从来没有想到，要面临死亡，面临癌症，我心中想过的每一个思念都和我的工作丝毫无关。有一个很著名的护士看护了很多临终病人，大部分的临终病人最大的遗憾就是没有和自己的家人在一起。 我们每个人都要临死才会想到这样的事情吗？我相信今天的纪录片和我出的书，能阐述我个人向死而生的过程。向死而生本身的意思，就是人在世俗里面很容易陷入今天的现实世界里面。而面对死亡，我们反而容易得到顿悟，了解生命的意义，让死亡成为生命旅程中无形的好友，温和提醒我们，好好珍惜我们的生命，不是只渡过每一天的日子，也不是只是追求一个现实的名利目标。 学分1：健康无价 在我平时的生活中，我热爱美食，不爱睡眠，认为睡眠是浪费时间，每天起来回E-mail，给我员工证明我工业多努力。生病以后，才深深体会到，其实健康失去了，就什么都没有了，生命最重要，健康和生命是一样重要的。 如果我们要维护自己的健康和生命，很多人会认为说，如果你养生，就没有事业了，什么都不要了，过退休的生活，过慢日子吧。我领悟以后，和几位朋友交流以后，其实真的不是这样的。每一个人的健康，其实不是要放弃一切。我们的健康如果简单来说，其实就是我们的睡眠、压力、运动、饮食。如果这 4 点达到即可，对年轻人来说。你是可以努力工作的，一个礼拜拿三四个小时维护你的健康，我非常希望在这里告诉大家要爱惜自己的健康，不要等到有一天，像我这样几乎后悔，几乎来不及才知道学会要爱惜自己的身体。 学分2：一切的事物都是有它的理由 我们往往把发生在自己身体的事情，一定做错了才惩罚我身上。其实不见得如此，世界的玄妙我们只了解里面的千分之一，万分之一，也许每一件事情的发生都有它的理由，我们应该多思考当一件事发生以后，是不是有什么正面的启示或者正面的力量。发生一个灾难，是不是不要把它当成一个果，而是把它当成因 ，如果把它当成因，任何的灾难都是学习的机会。如果我们生病了，是让我们学会生活更健康，也许我们无助的时候，让我们接受无法改变的事情。也许我们面临死亡才能教会我们分辨什么才是人生最重要的事情。 学分3：珍惜缘分，学会感恩和爱 一直面对死亡的时候，对于家人对我无私的爱，我当年是多么冷漠。虽然我告诉朋友说，我一放假就陪我们的母亲，但是我们只有 4 周的假。陪母亲 5 天以后，我就认为我的任务完成了。一直到我自己面临死亡的时候，我才知道，我是多么冷漠，我是以多么敷衍的方式表达了人们口中的孝顺。 我觉得真正改变应该有三个层次。最基本的是别人对你好，你感觉到了这是感恩，再稍微好一点的是别人对你好你要回报他。第三个层次就是主动不要求回报付出关怀，这才是最高的境界。这是我发现的，不知道过去做的什么好事，如果有上辈子，上辈子做了好事，有这样的家庭，我的父母、姐姐、妻子、女儿都是不要求回报的。无论我怎么对待他们，无论我是因为事业把家庭从美国搬来了中国又搬回美国，再搬回中国，又迁回台湾，整个过程对他们是多么煎熬，我只想做好我的事业。 有一句话，我觉得很有意义，每一次的相遇都是久别重逢，能和亲人在一起，他们能这样对我们，这不是猿猴演变出来的人类，就因为被教导，孔子说的亲情，我觉得这样的缘份，真的是久别之后的重逢，我们应该珍惜人生中的缘份和爱护。 所以我生病以后我就决定说，我要改变我的方式，每一周不但要陪我的妈妈，还要陪我的姐姐。我到了台湾，花更多的时间和我爱人在一起。我女儿要考大学，我帮她做各种准备。后来有一天她弄了一个刺青，刺了一个 try，这就是我没有付出足够教育方式的现象。然后她学业上升了也被大学录取了，然后又把 try 变成了 stay gold，我认为我自己是发光的黄金。也许我对父母的爱可能很难直接给他们回报，但是至少对妻子女儿，过去的 17 个月，我做的一些事情，也学会如何感恩，如何爱，如何直接表达。 父亲节的时候，我发了一条微博，是我女儿亲我的照片，我鼓励更多的孩子亲他们的父亲。我看他们的留言，很多女孩子说这么大了，怎么好意思，父亲很威严。爱不是藏在心里的，是应该表达出来的，如果没有表达，以后没有机会的话会很后悔。 学分4：学会如何生活，活在当下 我的癌症是淋巴癌四期，我认为我的生命并不长了。当时我也想到，如果我的生命真的只有 100 天了，我会怎么样渡过这个时间？我的结论和看护临终病人的护士是非常相似的。我的结论是说，我要让我的亲人知道我如何爱他们，我和他们在一起渡过特别难忘的时光，无论是和妻子去我们蜜月的地方，或者和孩子去一个我们过去特别快乐的地方，怀念回忆过去的美好，去吃我们爱吃的东西，做我们爱做的事情，这才是活。我希望活的时候，能全心全意每一刻活着，不只是脑子不停想我的公司，想我的事情。开始看世界其实是充满了美好的东西的。 如果稍微偶尔慢一下，能活在当下，才能体验到这些美好，才能感觉自己没有白活。我活了 50 多岁，一直没有分清什么是桂花，什么是茉莉花等等，我就知道他们都有香味。有一次我到朋友家这是什么味？我说桂花，什么时候种的？他说种了很长时间了。慢下来的时候，才会感受世界的美好。这是美食，这是我们最爱的酒，最漂亮的衣服，留到哪一天才会穿。我鼓励你们，不要把所有事情都推到以后，别说将来，找机会，还有一天等特殊的日子，我希望我们都活在当下。我们今天为什么不能成为那个特殊的日子呢，让每一天都成为最特殊的一天。我觉得人生如果这样活下去，不仅仅是最后的一百天，而是每一天都这样活下去，一定会非常圆满，丰富。 学分5：经得住诱惑 第五个学分经得住诱惑。我们小的时候，我父亲跟我们说，不要爱钱，对财富来讲，越多越好，但是不要贪婪的想得到更多。中国有一个通病，特别爱美。我们看到这么多古时候的皇帝，各方面的慈善家，做的各种事情都让别人知道自己有好。我父亲留给我 10 个字，有容则乃大，无求则更高。人死留名，我们希望做好的事情是对的，希望留名没有任何的必要，除了孔子以外，有哪个人被大家都记住了。我相信我们每一位 50 年以后都没有被别人记下来。 当你特别纠结自己“名”的时候，或许刻意，或者不刻意，都会让自己追求名成为一种方式。比如说之前我告诉年轻人追求自己的梦想，最大化自己的影响力，做最好的自己。这个话没有错，如果把最大化影响力这个词发挥到极致，每天机械化衡量影响力有没有提升，有没有人听我的演讲，成为我的粉丝。当我人生过去生病前的几年，5-10 年，慢慢越来越越顺，越来越有更多人喜欢把我当成他们的导师，一方面出于善心的帮助年轻人，但是不可避免的，每天的追随希望有更大的影响力。 听起来是很灰色的地带，影响力是好的吗？要一点名没有关系，我和清云大师讨论这个事情的时候，他告诉我，其实人是禁不住诱惑的。你要影响力的目的就是让世界更好，不断做好事情，不断衡量，我和别人都做好事就够了，为什么算我卖了多少本书，有多少粉丝呢？这样的过程，让我发现，虽然我认为我一直追求的方向和建议并没有错，但是如果特别机械化的追求效率，衡量每一天的结果，会让我们变得更冷漠无情。所以我发现，虽然我走的道路是正确的，但是过度追求名声，让我走偏了。 学分6：人人平等，善待每一个人 当你追求每一件事情影响力最大化的时候，你就想认识更多聪明的人。见创业者只见最顶尖的，一个青年人找你签字，如果是普通人，你就不考虑，你会见聪明人，成功人，把自己的一圈都变成社会的顶尖人士。但是我发现，如果真的再继续这么做的话，其实丧失了非常重要的一点就是人人是平等的。当我得了癌症，发的第一条微博，癌症面前人人平等。但是我慢慢觉醒的时候，我发现任何事上，人人都是平等的。世界的奥妙，不允许我们渺小对人类的评估。我们凭什么说这个人是普通人，这个人不怎么样，这个企业不会成功，这个创业者不行。 既然我们没有权利，也没有能力做评估的话，既然人人都是平等的，只要时间允许，我会秉承这样的理念，让我花更多的时间在网上和一些包括所谓的普通网友交流，每一周见一些想要见我的人，哪怕我们从来不认识，哪怕他们并没有特别光辉的履历。我建议大家，不要吝啬给别人爱的关怀。因为你对任何人，优秀的人，普通的人，都是一样的。你对任何人的微笑，一个行为，都可能帮助别人，帮助生命。 学分7：我们的人生究竟是为什么？ 我觉得如果我们太狂妄的说，我们来到人生就是为了改变世界，我们懂得这么小，这么渺小，凭什么狂妄，我们世界改变了，是更好，还是更不好，每天做的每一件事都能评估出来吗？我认为我们不必强求把改变世界作为我们的要求。如果每天拼命改变世界，那是充满压力的。 我认为来到人间，我们有缘认识周围的人，好好体验人生，结交善缘，做事问心无愧，凭良心，做人真诚平等，让自己的每一天都能有学习，成长，其实那就足够了。如果世界上每一个人都这么做，世界就会变得更好。如果过去我的哲学更多的是因为人生只有一次，所以要分秒必争，征求效率做最好的自己。现在我更觉得说，其实生命里很多东西，并没有办法用科学的方法解释，并没有办法每天衡量，比如说人与人之间的缘份。从现在开始，我不再看世界上很多的缺陷，批评他们，我相信每一个平等的生命都是来到这里不断学习，不断成长。人只有有缺陷才能学习成长，我们没有权利过分的批评别人，我们需要做的是怎么让自己成为一个更好更完善的人。 既然每个人都在持续成长，对于那些曾经伤害我，打击我，或者未来打击我的人，我不但宽恕他们，而且感谢他们，因为他们可能点醒我很多的不足。我相信人生的生命是与大宇宙连在一起的，我们有责任提升自己。我们的生命随着心跳停止也没关系，我们的人生只有一次，死去离开世界，如果这一生是体验学习提升，我相信也会让世界更美好，整个世界的群体意识也会变得更正向。 我经过这七个教训，我认为我们珍贵的生命旅程，应该保持着初学者的心态，对世界有儿童一般的好奇心，好好体验人生，让每天的自己都比以前有进步有成长，不要想着改变他人，做事问心无愧，多感恩和爱你周围的人。对人真诚、平等，这样就足够了。如果世界上每个人都能如此，世界就会更美好，谢谢。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"此生未完成","date":"2017-01-18T11:02:06.000Z","path":"2017/01/18/MyShare/unfinished-life/","text":"于娟《此生未完成：一个母亲、妻子、女儿的生命日记》 我们要用多大的代价，才能认清活着的意义。 在生命的最后日子里，于娟完全放下了生死，放下了名利权情，赤裸裸的去反思和写作。所有的浮躁沉淀了，所有的伪装剥离了，所有的喧嚣远去了，所有的执着放下了。只有一个普通的女子，普通的女儿、妻子、母亲对生命最单纯的感悟。在这个故事里，很多读者看到的不是于娟，而是自己。 在生死临界点的时候，你会发现，任何的加班，给自己太多的压力，买房买车的需求，这些都是浮云。如果有时间好好陪陪你的孩子，把买车的钱给父母买双鞋子，不要拼命去换什么大房子 ，和爱的人在一起蜗居也温暖…… 不要认为后面还有更好的，因为现在拥有的就是最好的；不要认为还年轻可以晚些结婚，爱情是不等年龄的；不要因为距离太远而放弃，爱情是可以和你一起坐火车的；不要因为对方不富裕而放弃，只要不是无能的人，彼此鼓励可以让你们富足的；不要因为外人反对而放弃，幸福是靠自己内心来感受的。 人有个好的心态，才能享受人生。不奢望太多的东西，只要这一生中有自己的居所，有自己的小家，甜蜜而温馨，每天过着快乐的生活就够了。随缘的爱是最幸福的爱，无须计划，无须设计，一切都顺理成章，轻松，自然，流淌着最本真的爱，相爱的人儿自是充满着感动，心喜，激动。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"选择的智慧","date":"2017-01-17T01:12:06.000Z","path":"2017/01/17/MyShare/wisdom-of-choose/","text":"李开复写《给中国学生的第六封信》——选择的智慧 有勇气来改变可以改变的事情，有胸怀来接受不可改变的事情，有智慧来分辨两者的不同。 “‘有勇气来改变可以改变的事情’代表了用西方式的积极进取的心态，以永不放弃、永不消沉的主动人生态度，鼓励我们靠自己的努力达到目的。“‘有胸怀来接受不可改变的事情’代表了用中国式的谦恭谨让的度量来培养自己的修养，学会承认和接受真实的、不完美甚至不公正的世界。有智慧来分辨两者的不同，可是，智慧从哪里来呢？”其实，“有智慧来分辨两者的不同”就是要求我们使用自己的智慧，主动发现并选择最完整、最均衡的状态，并通过这一选择获得成功。这里所说的“智 慧”，既是甄别、判断的智慧，也是权衡、折中的智慧，但从根本上讲，它更是在选择中孕育又在选择中升华的最高智慧——我也把它称作“选择成功”的智慧。 中国的青年学生虽然有幸出生在能够自由选择的时代，但时代并没有传授他们选择的智慧。我能帮你做的不是选择，因为你自身的问题只有自己最清楚，自己的未来也只有自己最在意。我能做的只是传授给你选择的智慧，帮你聆听自己心底里最真实的声音，帮助你做出智慧的选择 选择成功的智慧共有八种： 用中庸拒绝极端 用理智分析情景 用务实发挥影响 用冷静掌控抉择 用自觉端正态度 用学习积累经验 用勇气放弃包袱 用真心追随智慧 中庸告诉我们的最重要的一点，就是要避免并拒绝极端和片面。比如说，我认为最重要的积极主动，如果做到了极端，就变成了霸道，喜欢对别人颐指气使，横行跋扈。还有我提出与人相处最重要的同理心，如果做到了极端， 就变成了盲从，失去了自己的选择，什么事都没有主见。极端的自信就成了自傲，极端的勇气就成了愚勇，极端的胸怀就是懦弱，极端的 自省就会变成自卑。 自信、自省、勇气、胸怀，积极、同理心六种态度都是成功的必备要素，也都是成功者需要具备的优点。但是，一旦将其中某一种态度发展到极端，优点就会立刻演变为缺点。下面的图显示的就是这六种成功者必须的态度，和它们发展到极端的后果：内圈代表完整、均衡的状态，外圈代表极端、片面的行为。第一个智慧的真谛就是：我们必须用中庸的思想指导自己，把自己的态度限制在完整、均衡的范畴内，兼顾自信和自省、勇气和胸怀、积极和同理心等各方面因素，时刻防止自己在其中某一方面有过于偏激的表现。 沉默是金和口无遮拦都不可取，那么我们怎么达到“中庸式的智慧沟通”呢？记得我刚进入苹果公司开始我的第一份工 作时，公司里有一位经理叫西恩，大家都知道他是一个非常有才华的人，尤其在开会的时候， 他得体的言辞完美地展现出他过人的才学、情商与口才，足以让在场的 所有人钦佩不已。有一天，我鼓足勇气去向西恩讨教有效沟通的秘诀。 西恩说：“我的秘诀其实很简单：我并不总是抢着发言；当我不懂或不确定时，我的嘴闭得紧 紧的；但是，当我有好的意见时，我绝不错过良机——如果不让我发言，我就不让会议结束。” 我问他：“如果别人都抢着讲话，你怎么发言呢？”西恩说：“我会 先用肢体语言告诉别人：下一个该轮到我发言啦！例如，我会举起手，发出特殊的声响（如清嗓子声），或者用目光要求主持人让我发言。 但是，如果其他人的确霸 占了所有的发言机会，我就等发言人调整呼吸时，迅速接上话头。”我又问他：“如果你懂得不多，但是别人向你咨询呢？” 西恩说：“我会先看看有没有比我懂得 更多的人帮我回答。如果有，我会巧妙地把回答的机会‘让’给他；如果没有，我会说‘我不知道，但是我会去查’，等会开完后，我一定去把问题查清楚。” 跟他 的一席话让我学到了很多东西——只要把握好说话的度，选择好说话的时机，就可以得到周围人的尊敬，而且，别人也会从你的话语中了解到你是一个渊博而谦逊的 人。 “我不同意我的老板，我该站起来发言吗？” 我的回答是：“这要看情形而定。首先，你的老板是一个愿意接纳异议的人吗？如果不是，那么你千万不要乱发言，但是，你可以开始物色一个新 工作和新老板了！如果他能够接受异议，那么，在老板还没做出最后的决定时，不要怕提出异议；但同时也要考虑到，如果是当众发言，自己的话就必须有一定的技 巧，应当顾虑到老板的面子。老板一旦做出了决定，我们无论有无异议，都必须支持和贯彻，有不同意的地方只可以私下与老板沟通。” 在这样一个具体的例子里，我们必须学会用智慧甄别各种复杂的情况，并从不同候选方案中择善而从的方法，这样才能找到提出异议的最佳途径。这个例子中的选择过程也可以用计算机流程图直观地表示出来： 一个出色领导总是拥有上述的六种领导力，并且会理智地分析当前的情景，以便决定运用其中的哪一种。例如， 假设员工表现不佳或 员工是新手，在公司遇到重大危机时，对员工就应该采用指挥、命令的方式； 如果企业需要改变方向，或员工因为不理解方向而士气不高，而你又是一个值得信任的 领导者，那就应该采用宏观掌控的方法； 如果你发现员工对工作得心应手，部门协调没有问题，那就应该注重和谐合作； 当你发现员工知识渊博，或你对结果不确定 的时候，就应该选择民主自由的方式； 如果员工能力很高又是专家，或具备了积极自主的态度，就应该采用授权负责的方式； 如果员工很有动力，愿意把工作做好， 但是经验不足，同时企业并没有处于危机时刻，那应该尽量指导培养。 最好的领导是拥有这六种看起来相互矛盾的领导力，并且用智慧根据不同的情景正确选择的 人。 人生中的绝大多数选择都不是非黑即白、非此即彼的事情。大家要学会在最合适的时候对最合适的人用最合适的方法，要学会在做出决定前用理智全面衡 量各种因素的利弊以及自己的能力和倾向。这些东西并不能靠简单的公式来决定。读者应该凭借自己的智慧，选择最适合自己的成功之路。 史蒂芬·柯维在其所著的《高效能人士的七个习惯》一书中，把所有值得关注的事情称为“关注圈”，把能够发挥影响的事情称为“影响圈”。在整个关注圈中，根据自主程度的高低，人生面临的问题可分为三类： 可直接影响的问题：对于这种问题，解决之道在于用正确的态度执行。这是我们绝对做得到的，也是最核心的“影响圈”。 可间接影响的问题：有赖改进发挥影响力的方法来加以解决，如借助人际关系、团队合作和沟通能力来解决。这是最值得我们努力争取的“影响圈”。 无能为力的问题：需要以平和的态度和胸怀，接纳这些问题。纵使有再多不满，也要泰然处之，如此才不至于让问题征服了我们。 碰到问题时，你只要耐心地将它分解开，看看哪些部分是你可以影响的，哪些部分是你可以关注但却无法影响的。然后，去努力争取那些可以 “间接影响”的问题，让它们变成可“直接影响”的，同时把全部心力投入自己的影响圈——你可以在这样的过程中不断获得进步，这反过来又可以让你进一步扩大 自己的影响圈。解决问题的第一步都要从自己的影响圈开始：先影响自己，再影响别人，最后才有可能影响环境。虽然我们不能改变风，但我们可以调整船帆。人在挫折中学到的 东西会远远多于在成功中学到的。希望你在经过这一次不幸后能够成为一个更成熟、更成功的人。专注于你能够改变的事情，可能最后连当初不能改变的事情也改变了。 在抉择前“重重”思考，抉择后“轻轻”放下。 所谓“重重”思考，就是要培养客观的、精准的判断力。每一个重要的抉择可能都与你自己的前途密切相关，但你在抉择和判断时，一定要避免先入为主的思维定式，要避免自己的主观倾向影响判断的精准和客观。我们该如何做出客观、精准的抉择呢？我给大家提供三个建议： 第一、把影响你抉择的因素罗列成一张“利弊对照表”。 第二、学会用概率论的方法看问题。 第三、当自己不确定时，学会谋之于众。 在利弊对照表中写出每个因素的利益和弊端，然后借助该表客观地分析，哪些利益和弊端对你来说最为重要？这些因素是否符合你的价值观和理想？当你面前摆了这样一张客观而详尽的利弊对照表时，主观因素就不容易影响你的判断力了。借助这样一份利弊对照表，我很快就做出了客观而明智的决定——回中国工作。因为综合考虑各种利弊因素后，回中国工作最能发挥我自身的特长，也最符合我个人的价值观和理想。 我们应当学会分析一件事情“可改变的概率”或“可能发生的概 率”。对于发生概率小的事情，在做之前一定要有失败的心理准备。另一方面，也不要等到事情成功的概率达到100%时才去做，因为即便做成了这种事情，也没 有什么值得骄傲的。做概率分析时，可以列出“最好的可能”和“最坏的打算”，以帮助自己综合考量。例如，上面提到的“回中国建立研究院”的工作，我有100%的把 握，可以把研究院办得与其他任何公司在中国建立的研究院一样好——这是最坏的打算；我有40%的把握，可以做出世界一流的研究机构来——这是最好的可能。用这样的方法考虑到两个极端后，我马上就会明白，即便出现最坏的情况，我和公司也可以坦然接受。因此，我选择回中国工作就成了一件顺理成章的事。许多抉择并没有这么好的“后路”，在这种时候，我们既要谨慎地评估风险因素，也要在适当的时候有勇气挑战自己。美国前国务卿鲍威尔曾在阐 述“领导力”时指出：“当你自估的成功概率达到40~70%，你就该去做这件事了。也许你会失败，但拖延或等待的代价往往是更大的。” 多征求别人的意见总是好的。那些更有经验的人可以用他们多年的积累为我们指引方向，那些聪明绝顶的人可以用他们的智商启发我们的思路，那些懂得人际关系的人可以用他们的情商帮助我们有效沟通…… 最终的决定权在你自己，即便你采纳了别人的意见，你也不可以就此将责任推卸给他人。所谓“轻轻”放下，就是说我们在做出抉择后，应当坦然面对可能发生的任何结果，既不要因为抉择正确而欣喜若狂，也不要因为抉择失误而悔恨终生。 无论你的抉择正确与否，无论它的结果如何，已经做出的决定就无法收回了，你只有坦然接受它，或者在今后想办法补救。对于已经发生的事情， 或者自己已经无法控制的事情，任何担忧或悔恨都是多余的。与其把时间花在无谓的焦虑上，倒不如把这些东西“轻轻”放下，然后一身轻松地去做自己应该做的 事。 人贵有自知之明。这实际上是说，社会生活中的每个人都应当对自己的素质、潜能、特长、缺陷、 经验等各种基本能力有一个清醒的认识，对自己在社会工作生活中可能扮演的角色有一个明确的定位。心理学上把这种有自知之明的能力称为“自觉”，这通常包括 察觉自己的情绪对言行的影响，了解并正确评估自己的资质、能力与局限，相信自己的价值和能力等几个方面。 有自觉的人能够针对自己做出最具有智慧的选择，选择做自己能够胜任的工作，选择做能够得到满足感的工作等等。要做一个自觉的人，既不会对自己的 能力判断过高，也不会轻易低估自己的潜能。对自己判断过高的人往往容易浮躁、冒进，不善于和他人合作，在事业遭到挫折时心理落差较大，难以平静对待客观事 实；低估了自己潜能的人，则会在工作中畏首畏尾、踟蹰不前，没有承担责任和肩负重担的勇气，也没有主动请缨的积极性。无论是上述哪一种情况，个人的潜力都 不能得到充分的发挥，个人事业也不可能取得最大的成功。 有自觉的人在工作遇到挫折的时候不会轻言失败，在工作取得成绩时也不会沾沾自喜。认识自我，准确定位自我价值的能力不仅仅可以帮助个人找到自己合适的空间及发展方向，也可以帮助企业建立起各司其职、协同工作的优秀团队。有自觉的人的抉择让他人更愿意信任。 很多人只是从来没有考虑过要 了解自己。确定计划和原则时，必须完全基于对自己的了解。最关键的是，一定要清楚自己对什么事情最感兴趣。制定了一个计划以后，也许随着时间的推移，会有 某种程度上的修改，但始终要明确自己的大方向。所以我觉得更难的一点是，能经常以旁观者的目光审视自己，看一下自己哪方面做得好，需要保持，哪方面做得 差，需要更加努力，哪方面走入了歧途，需要改正。 西方有一则寓言，说的是一个年轻人向一个年长的智者请教智慧的秘诀。年轻人问：“智慧从哪里来？”智者说：“正确的选择。”年轻人又问：“正确的选择从哪里来？”智者说：“经验。”年轻人进一步追问：“经验从哪里来？”智者说：“错误的选择。”不要畏惧失败。每一个失 败不是惩罚，而是一个学习的经验。 学习经验不是一蹴而就的事情，有时候要经历漫长的过程。英文中有一句名言：“旅途本身就是收获（The journey is the reward）。”很多时候，你的收获并不一定是每件事的成功，而是你在走向成功的旅途中经历的一切。旅途中的每一次正确的或是错误的选择都会让你学到新 的知识、获取新的教训，并以此调整自己的自觉，掌握正确的选择方法。 创新固然重要，但有用的创新更重要。在整个学习的过程中，无论是错误的选择，还是失败的经历，它们都可以成为印刻在我们心底，能够随时拿出来比较、借鉴的“模板 （Template）”。当我们面临新的抉择时，我们就会使用过去积累的“模板”来比较、分析各种不同情况下成功的概率，以权衡利弊，做出正确的抉择。 当新的机会摆在面前的时候，敢于放弃已经获得的一切，这需要相当大的勇气。有时，你在还没有找到“新的机会”之前，就必须放弃你已经拥有的东西，那就需要更多的勇气了。这种眼前的利益往往是阻碍你获得更大成功的根源。当新的机会到来时，勇于放弃已经获得的东西并不是功亏一篑，更不是半途而 废，这是为了谋求新的发展空间。如果你在适当的时候勇敢地——当然也应该是有智慧地——放弃已经拥有但可能成为前进障碍的东西，你多半会惊讶地发现，自己 抛开的不过是一把虽能遮风挡雨，但又会阻碍视线的雨伞，自己因此而看到的却是无比广阔、无比壮丽的江山图景！ 当苹果电脑的一 位副总裁对我说“你要选择终身写些没有人读得懂的论文，还是要选择改变世界”时，我毫不犹豫地选择了改变世界。我的感觉就像是获得了自由。如果我只对我拥有的东西依依不舍，那么我将错过这个“once in a lifetime”的机会。于是，就像我在“追随我新的抉择”中所说的：“我有选择的权利——我选择了Google。我选择了中国。我要做有影响力的事 ——在中国，我能更多地帮助中国的青年，做最有影响力的事。我要成为最好的自己——在Google，我能经过学习新的创新模式，成为最好的自己。”同时， 我放弃了在微软的人脉，放弃了继续与比尔·盖茨工作的机会，放弃了那安稳的工作，放弃了那“世界第一大IT公司”的荣誉。 我人生中这几次勇于放弃的经历，都使我更加清楚自己的追求和兴趣所在，也使我更有激情去从事自己喜爱的事业。放弃意味着失去，但失去的是那些自己缺乏激情的东西，得到的却是自己主动追寻的事业。 最后一个可以帮助你做出正确抉择的“智囊”就是你内心深处的价值观、理想和兴趣了。价值观就是每个人判断是非、善恶的信念体系（What is right？），理想就是我们对自己人生目标的基本设计（What do I want my life to be?），而兴趣则是我们每个人最喜欢、最热爱的事情（What do I love doing?）。这三者共同构成了我们内心深处最为真实的声音。有关如何找到自己的价值观、理想和兴趣，读者可以参看《做最好的自己》一书中的相关章节。 你的价值观是你判断“是非”的准绳，你的理想和兴趣是你辨别“方向”的指南针——它们都是你心底里最真实、最“自我” 的东西，还有什么是比这些更重要，更精确的判断依据呢？ 我建议大家应该通过自己正确的价值观和理想来寻找最为完整、最为均衡的人生状态。任何一个高尚的人，一个有远大理想的人都必然会在积极追寻成功 的道路上运用自己最高的智慧：因为拥有了正确的价值观和远大的理想，他在面临困难和挑战时就必然会听从自己的真心、用冷静的心态权衡各种利弊，他也必然会 在一次又一次或是成功、或是失败的抉择中不断积累经验完善自我……这样的人最能理解完整与均衡的真谛，这样的人最懂得使用自己的“选择”的权利来赢得真正 的成功。 融会中西，均衡发展在今天这个信息化、全球化的时代里，只有融会中西才能成为真正有价值的国际化人才。中国人讲求纪律与服从、重视谦虚和毅力以及西方人强调创意与个性，鼓励积极与勇气的 特长 大部分中国青年和美国青年的优势可以用下表来概括。既需要西方的科技和理性，也需要东方的心胸与美德。 一个人甚至要同时具备多种看似相互矛盾的品质，才能在复杂的境遇中因具体情景不同而运用正确的一种。 用智慧在各种看似矛盾的因素之间主动选择“完整”和“均衡”，这是“选择成功”的最大秘诀。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"孙振耀退休感言","date":"2017-01-15T23:50:06.000Z","path":"2017/01/16/MyShare/retirement-speech-of-HP-president/","text":"HP大中华区总裁孙振耀退休感言 职业生涯首先要关注的是自己，自己想要什么？寻找真正能够使你获得快乐的东西，那才是你想要的东西。有很多的不快乐，其实是源自不满足，而不满足，很多时候是源自于心不定，而心不定则是因为不清楚究竟自己要什么，不清楚要什么的结果就是什么都想要，结果什么都没得到。 关于工作与生活 外企员工的成功很大程度上是公司的成功，并非个人的成功而进外企的人往往并不能很早理解这一点，把自己的成功90％归功于自己的能力看待工作，眼光要放远一点，一时的谁高谁低并不能说明什么。 马拉松比赛 正常人大概要工作35年，这好比是一场马拉松比赛，和真正的马拉松比赛不同的是，这次比赛没有职业选手，每个人都只有一次机会。要知道，有很多人甚至坚持不到终点，大多数人最后是走到终点的，只有少数人是跑过终点的，因此在刚开始的时候，去抢领先的位置并没有太大的意义。每个人的职业生涯中都会碰到几个瓶颈，你熬过去了而别人没有熬过去你就领先了。跑长跑的人会知道，开始的时候很轻松，但是很快会有第一次的难受，但过了这一段又能跑很长一段，接下来会碰到第二次的难受，坚持过了以后又能跑一段，如此往复，难受一次比一次厉害，直到坚持不下去了。大多数人第一次就坚持不了了，一些人能坚持到第二次，第三次，虽然大家都坚持不住了，可是跑到这里的人也没几个了，这点资本足够你安稳活这一辈子了。 初赛 职业生涯就像一场体育比赛，有初赛、复赛、决赛。初赛的时候大家都刚刚进社会，大多数都是实力一般的人，这时候努力一点认真一点很快就能让人脱颖而出，于是有的人二十多岁做了经理，有的人迟些也终于赢得了初赛，三十多岁成了经理。然后是复赛，能参加复赛的都是赢得初赛的，每个人都有些能耐，在聪明才智上都不成问题，这个时候再想要胜出就不那么容易了，单靠一点点努力和认真还不够，要有很强的坚忍精神，要懂得靠团队的力量，要懂得收服人心，要有长远的眼光…… 复赛 看上去赢得复赛并不容易，但，还不是那么难。因为这个世界的规律就是给人一点成功的同时让人骄傲自满，刚刚赢得初赛的人往往不知道自己赢得的仅仅是初赛，有了一点小小的成绩大多数人都会骄傲自满起来，认为自己已经懂得了全部，不需要再努力再学习了，他们会认为之所以不能再进一步已经不是自己的原因了。虽然他们仍然不好对付，但是他们没有耐性，没有容人的度量，更没有清晰长远的目光。就像一只愤怒的斗牛，虽然猛烈，最终是会败的，而赢得复赛的人则象斗牛士一样，不急不躁，跟随着自己的节拍，慢慢耗尽对手的耐心和体力。赢得了复赛以后，大约已经是一位很了不起的职业经理人了，当上了中小公司的总经理，大公司的副总经理，主管着每年几千万乃至几亿的生意。 决赛 最终的决赛来了，说实话我自己都还没有赢得决赛，因此对于决赛的决胜因素也只能凭自己的猜测而已，这个时候的输赢或许就像武侠小说里写得那样，大家都是高手，只能等待对方犯错了，要想轻易击败对手是不可能的，除了使上浑身解数，还需要一点运气和时间。世界的规律依然发挥着作用，赢得复赛的人已经不只是骄傲自满了，他们往往刚愎自用，听不进去别人的话，有些人的脾气变得暴躁，心情变得浮躁，身体变得糟糕，他们最大的敌人就是他们自己，在决赛中要做的只是不被自己击败，等着别人被自己击败。这和体育比赛是一样的，最后高手之间的比赛，就看谁失误少谁就赢得了决赛。 你工作快乐么？你的工作好么？ 你不快乐的根源，是因为你不知道要什么！你不知道要什么，所以你不知道去追求什么，你不知道追求什么，所以你什么也得不到。职业生涯首先要关注的是自己，自己想要什么？大多数人大概没想过这个问题，唯一的想法只是——我想要一份工作，我想要一份不错的薪水寻找自己想要的东西不是和别人比赛，比谁要得更多更高，比谁的目标更远大。你必须听听你内心的声音，寻找真正能够使你获得快乐的东西，那才是你想要的东西。先想好自己要过怎样的人生，再决定要找什么样的职业。有很多的不快乐，其实是源自不满足，而不满足，很多时候是源自于心不定，而心不定则是因为不清楚究竟自己要什么，不清楚要什么的结果就是什么都想要，结果什么都没得到。还是因为生活而工作，不是因为工作而生活，生活是最要紧的，工作只是生活中的一部分。我总是觉得生活的各个方面都是相互影响的，如果生活本身一团乱麻，工作也不会顺利。所以要有娱乐、要有社交、要锻炼身体，要有和睦的家庭……最要紧的，要开心首先的首先，人还是要让自己高兴起来，让自己心态好起来，这种发自内心的改变会让你更有耐心，更有信心，更有气质，更能包容…… 恶性循环你想每隔几年重来一次找工作的过程么？你想每年都在这种对于工作和薪水的焦急不安中度过么？不想的话，就好好想清楚。饮鸩止渴，不能因为口渴就拼命喝毒药。越是焦急，越是觉得自己需要一份工作，越饥不择食，越想不清楚，越容易失败，你的经历越来越差，下一份工作的人看着你的简历就皱眉头。于是你越喝越渴，越渴越喝，陷入恶性循环。 压力大多数人都有生存压力，我也是，有生存压力就会有很多焦虑，积极的人会从焦虑中得到动力，而消极的人则会因为焦虑而迷失方向。所有人都必须在压力下做出选择，这就是世道，你喜欢也罢不喜欢也罢。 重要 VS 紧急 一般我们处理的事情分为重要的事情和紧急的事情，如果不做重要的事情就会常常去做紧急的事情。比如锻炼身体保持健康是重要的事情，而看病则是紧急的事情。如果不锻炼身体保持健康，就会常常为了病痛烦恼。又比如防火是重要的事情，而救火是紧急的事情，如果不注意防火，就要常常救火。找工作也是如此，想好自己究竟要什么是重要的事情，找工作是紧急的事情，如果不想好，就会常常要找工作。往往紧急的事情给人的压力比较大，迫使人们去赶紧做，相对来说重要的事情反而没有那么大的压力，大多数人做事情都是以压力为导向的，压力之下，总觉得非要先做紧急的事情，结果就是永远到处救火，永远没有停歇的时候。（很多人的工作也像是救火队一样忙碌痛苦，也是因为工作中没有做好重要的事情。）那些说自己活在水深火热为了生存顾不上那么多的朋友，今天找工作困难是当初你们没有做重要的事情，是结果不是原因。如果今天你们还是因为急于要找一份工作而不去思考，那么或许将来要继续承受痛苦找工作的结果。 12天下没有轻松的成功，成功，要付代价。请先忘记一切的生存压力，想想这辈子你最想要的是什么？所以，最要紧的事情，先想好自己想要什么。人总想找到那个最好的，可是，什么是最好的？你觉得是最好的那个，是因为你的确了解，还是因为别人说他是最好的？即使他对于别人是最好的，对于你也一定是最好的么？ 什么是好工作 人都是要面子的，也是喜欢攀比的，即使在工作上也喜欢攀比，不管那是不是自己想要的。你想清楚了么？500强一定好么？找工作究竟是考虑你想要什么，还是考虑别人想看什么？“很多事情就像看A片，看的人觉得很爽，做的人未必。” 你究竟是要过谁的一生？人的一生不是父母一生的续集，也不是儿女一生的前传，更不是朋友一生的外篇，只有你自己对自己的一生负责，别人无法也负不起这个责任。自己做的决定，至少到最后，自己没什么可后悔。对于大多数正常智力的人来说，所做的决定没有大的对错，无论怎么样的选择，都是可以尝试的。 好工作，应该是适合你的工作，具体点说，应该是能给你带来你想要的东西的工作，你或许应该以此来衡量你的工作究竟好不好，而不是拿公司的大小，规模，外企还是国企，是不是有名，是不是上市公司来衡量。小公司，未必不是好公司，赚钱多的工作，也未必是好工作。你还是要先弄清楚你想要什么，如果你不清楚你想要什么，你就永远也不会找到好工作，因为你永远只看到你得不到的东西，你得到的，都是你不想要的。 万科的王石登珠穆朗玛峰的体验给我很多启发，虽然在出发时携带大量的物资，但是登顶的过程中，必须不断减轻负荷，最终只有一个氧气瓶和他登上峰顶。登山如此，漫长的人生又何尝不是。 可能，最好的，已经在你的身边，只是，你还没有学会珍惜。人们总是盯着得不到的东西，而忽视了那些已经得到的东西。 普通人 中国的励志比较鼓励人立下大志愿，卧薪尝胆，有朝一日成富成贵。需要用999个失败者来堆砌一个成功者的故事。国外的励志比较鼓励人勇敢面对现实生活，面对普通人的困境，虽然结果也是成富成贵，但起点不一样目标定得高些对于喜欢挑战的人来说有好处，但对于大多数普通人来说，反而比较容易灰心沮丧，很容易就放弃了。 目标其实并没有高低之分，你不需要因为自己的目标没有别人远大而不好意思，达到自己的目标其实就是成功，成功有大有小，快乐却是一样的。我们追逐成功，其实追逐的是成功带来的快乐，而非成功本身。职业生涯的道路上，我们常常会被攀比的心态蒙住眼睛，忘记了追求的究竟是什么，忘记了是什么能使我们更快乐。 这个世界上，有史以来直到我们能够预见得到的未来，成功的人总是少数，有钱的人总是少数，大多数人是一般的，普通的，不太成功的。因此，大多数人的做法和看法，往往都不是距离成功最近的做法和看法。因此大多数人说好的东西不见得好，大多数人说不好的东西不见得不好。大多数人都去炒股的时候说明跌只是时间问题，大家越是热情高涨的时候，跌的日子越近。大多数人买房子的时候，房价不会涨，而房价涨的差不多的时候，大多数人才开始买房子。不会有这样一件事情让大家都变成功，发了财，历史上不曾有过，将来也不会发生。有些东西即使一时运气好得到了，还是会在别的时候别的地方失去的。 只见贼吃肉，不见贼挨揍社会上一夜暴富的新闻很多，这些消息，总会在我们的心里面掀起很多涟漪，涟漪多了就变成惊涛骇浪，心里的惊涛骇浪除了打翻承载你目标的小船，并不会使得你也一夜暴富。“只见贼吃肉，不见贼挨揍。”我们这些普通人既没有当贼的勇气，又缺乏当贼的狠辣绝决，虽然羡慕吃肉，却更害怕挨揍，偶尔看到几个没挨揍的贼就按奈不住，或者心思活动，或者大感不公，真要叫去做贼，却也不敢。 跳槽与积累 不反对跳槽，但跳槽决不是解决问题的办法，而且频繁跳槽的后果是让人觉得没有忠诚度可言，而且不能安心工作。要跳槽肯定是有问题，一般来说问题发生了，躲是躲不开的，很多人跳槽是因为这样或者那样的不开心，如果这种不开心，在现在这个公司不能解决，那么在下一个公司多半也解决不掉。你必须相信，90%的情况下，你所在的公司并没有那么烂，你认为不错的公司也没有那么好。就像围城里说的，“城里的人拼命想冲出来，而城外的人拼命想冲进去。”每个公司都有每个公司的问题，没有问题的公司是不存在的。换个环境你都不知道会碰到什么问题，与其如此，不如就在当下把问题解决掉。很多问题当你真的想要去解决的时候，或许并没有那么难。有的时候你觉得问题无法解决，事实上，那只是“你觉得”。 基本上，35岁以前我们的生存资本靠打拼，35岁以生存的资本靠的就是积累，这种积累包括人际关系，经验，人脉，口碑……工作两三年的人，无论是客户关系，人脉，手下，和领导的关系，在业内的名气……还都是远远不够的，但稍有成绩的人总是会自我感觉良好的，每个人都觉得自己跟客户关系铁得要命，觉得自己在业界的口碑好得很。其实可以肯定地说，一定不是，这个时候，还是要拿出前两年的干劲来，稳扎稳打，积累才刚刚开始。你足够了解你的客户吗？你知道他最大的烦恼是什么吗？你足够了解你的老板么？你知道他最大的烦恼是什么吗？你足够了解你的手下么？你知道他最大的烦恼是什么吗？如果你不知道，你凭什么觉得自己已经积累够了？如果你都不了解，你怎么能让他们帮你的忙，做你想让他们做的事情？如果他们不做你想让他们做的事情，你又何来的成功？ 等待 并不是每次闯红灯都会被汽车撞，并不是每个罪犯都会被抓到， 并不是每个错误都会被惩罚，并不是每个贪官都会被枪毙， 并不是你的每一份努力都会得到回报，并不是你的每一次坚持都会有人看到， 并不是你每一点付出都能得到公正的回报，并不是你的每一个善意都能被理解…… 这个，就是世道。好吧，世道不够好，可是，你有推翻世道的勇气么？如果没有，你有更好的解决办法么？ 有很多时候，人需要一点耐心，一点信心。每个人总会轮到几次不公平的事情，而通常，安心等待是最好的办法。 有很多时候我们需要等待，需要耐得住寂寞，等待属于你的那一刻。 每一个成功者都有一段低沉苦闷的日子，我几乎能想象得出来他们借酒浇愁的样子，我也能想象得出他们为了生存而挣扎的窘迫。在他们一生最中灿烂美好的日子里，他们渴望成功，但却两手空空，一如现在的你。没有人保证他们将来一定会成功，而他们的选择是耐住寂寞。如果当时的他们总念叨着“成功只是属于特权阶级的”，你觉得他们今天会怎样？ 他们在社会上奋斗积累了十几二十年，我们新人来了，他们有的我都想要，我这不是在要公平，我这是在要抢劫。因为我要得太急，因为我忍不住寂寞。二十多岁的男人，没有钱，没有事业，却有蓬勃的欲望。 12345人总是会遇到挫折的，人总是会有低潮的，人总是会有不被人理解的时候的，人总是有要低声下气的时候，这些时候恰恰是人生最关键的时候，因为大家都会碰到挫折，而大多数人过不了这个门槛，你能过，你就成功了。在这样的时刻，我们需要耐心等待，满怀信心地去等待，相信，生活不会放弃你，机会总会来的。至少，你还年轻，你没有坐牢，没有生治不了的病，没有欠还不起的债。比你不幸的人远远多过比你幸运的人，你还怕什么？路要一步步走，虽然到达终点的那一步很激动人心，但大部分的脚步是平凡甚至枯燥的，但没有这些脚步，或者耐不住这些平凡枯燥，你终归是无法迎来最后的那些激动人心。无论什么时候，我们总还是有希望。当所有的人离开的时候，我不失去希望，我不放弃。每天下班坐在车里，我喜欢哼着《隐形的翅膀》看着窗外，我知道，我在静静等待，等待属于我的那一刻。 逆境，是上帝帮你淘汰竞争者的地方。要知道，你不好受，别人也不好受，你坚持不下去了，别人也一样，千万不要告诉别人你坚持不住了，那只能让别人获得坚持的信心，让竞争者看着你微笑的面孔，失去信心，退出比赛。胜利属于那些有耐心的人。 入对行跟对人 第一份工作对人最大的影响就是入行，现代的职业分工已经很细，我们基本上只能在一个行业里成为专家，不可能在多个行业里成为专家。很多案例也证明即使一个人在一个行业非常成功，到另外一个行业，往往完全不是那么回事情其实没有哪个行业特别好，也没有哪个行业特别差，或许有报道说哪个行业的平均薪资比较高，但是他们没说的是，那个行业的平均压力也比较大。看上去很美的行业一旦进入才发现很多地方其实并不那么完美，只是外人看不见。其实选什么行业真的不重要，关键是怎么做。事情都是人做出来的，关键是人。和那些比你强的人打交道，看他们是怎么想的，怎么做的，学习他们，然后跟更强的人打交道。 年轻人在职业生涯的刚开始，尤其要注意的是，要做对的事情，不要让自己今后几十年的人生总是提心吊胆，更不值得为了一份工作赔上自己的青春年华。人还是要看长远一点。很多时候，看起来最近的路，其实是最远的路，看起来最远的路，其实是最近的路。 跟对人是说，入行后要跟个好领导好老师，刚进社会的人做事情往往没有经验，需要有人言传身教。对于一个人的发展来说，一个好领导是非常重要的。所谓“好”的标准，不是他让你少干活多拿钱，而是以下三个。 首先，好领导要有宽广的心胸，如果一个领导每天都会发脾气，那几乎可以肯定他不是个心胸宽广的人，能发脾气的时候却不发脾气的领导，多半是非常厉害的领导。中国人当领导最大的毛病是容忍不了能力比自己强的人，所以常常可以看到的一个现象是，领导很有能力，手下一群庸才或者手下一群闲人。如果看到这样的环境，还是不要去的好。 其次，领导要愿意从下属的角度来思考问题，这一点其实是从面试的时候就能发现的，如果这位领导总是从自己的角度来考虑问题，几乎不听你说什么，这就危险了。从下属的角度来考虑问题并不代表同意下属的说法，但他必须了解下属的立场，下属为什么要这么想，然后他才有办法说服你，只关心自己怎么想的领导往往难以获得下属的信服。 第三，领导敢于承担责任，如果出了问题就把责任往下推，有了功劳就往自己身上揽，这样的领导不跟也罢。选择领导，要选择关键时刻能抗得住的领导，能够为下属的错误买单的领导，因为这是他作为领导的责任。 选择 从某种意义上来说我们的未来不是别人给的，是我们自己选择的每天你都可以选择是否为客户服务更周到一些，是否对同事更耐心一些，是否把工作做得更细致一些，是否把情况了解得更清楚一些，是否把不清楚的问题再弄清楚一些……你也可以选择在是否在痛苦中继续坚持，是否抛弃掉自己的那些负面的想法，是否原谅一个人的错误，是否相信我在这里写下的这些话，是否不要再犯同样的错误……生活每天都在给你选择的机会，每天都在给你改变自己人生的机会，你可以选择赖在地上撒泼打滚，也可以选择咬牙站起来。你永远都有选择。有些选择不是立杆见影的，需要累积，比如农民可以选择自己常常去浇地，也可以选择让老天去浇地，诚然你今天浇水下去苗不见得今天马上就长出来，但常常浇水，大部分苗终究会长出来的，如果你不浇，收成一定很糟糕。 你选择相信什么？你选择和谁交朋友？你选择做什么？你选择怎么做？……我们面临太多的选择，而这些选择当中，意识形态层面的选择又远比客观条件的选择来得重要得多，比如选择做什么产品其实并不那么重要，而选择怎么做才重要。选择用什么人并不重要，而选择怎么带这些人才重要。大多数时候选择客观条件并不要紧，大多数关于客观条件的选择并没有对错之分，要紧的是选择怎么做。一个大学生毕业了，他要去微软也好，他要卖猪肉也好，他要创业也好，他要做游戏代练也好，只要不犯法，不害人，都没有什么关系，要紧的是，选择了以后，怎么把事情做好。 你还可以选择时间和环境，比如，你可以选择把这辈子最大的困难放在最有体力最有精力的时候，也可以走一步看一步，等到了40岁再说，只是到了40多岁，那正是一辈子最脆弱的时候，上有老下有小，如果在那个时候碰上了职业危机，实在是一件很苦恼的事情。与其如此不如在20多岁30多岁的时候吃点苦，好让自己脆弱的时候活得从容一些。你可以选择在温室里成长，也可以选择到野外磨砺，你可以选择在办公室吹冷气的工作，也可以选择40度的酷热下，去见你的客户，只是，这一切最终会累积起来，引导你到你应得的未来。 选择职业销售就是一门跟人打交道的学问，而管理其实也是跟人打交道的学问，这两者之中有很多相通的东西，他们的共同目标就是“让别人去做某件特定的事情。”而财务则是从数字的层面了解生意的本质，从宏观上看待生意的本质，对于一个生意是否挣钱，是否可以正常运作有着最深刻的认识。 公司小的时候是销售主导公司，而公司大的时候是财务主导公司，销售的局限性在于只看人情不看数字，财务的局限性在于只看数字不看人情。公司初期，运营成本低，有订单就活得下去，跟客户也没有什么谈判的条件，别人肯给生意做已经谢天谢地了，这个时候订单压倒一切，客户的要求压倒一切，所以当然要顾人情。公司大了以后，一切都要规范化，免得因为不规范引起一些不必要的风险，同时运营成本也变高，必须提高利润率，把有限的资金放到最有产出的地方。对于上市公司来说，股东才不管你客户是不是最近出国，最近是不是那个省又在搞严打，到了时候就要把业绩拿出来，拿不出来就抛股票，这个时候就是数字压倒一切。 开始的时候我们想“能做什么？”，等到公司做大了有规模了，我们想“不能做什么。”很多人在工作中觉得为什么领导这么保守，这也不行那也不行，错过很多机会。很多时候是因为，你还年轻，你想的是“能做什么”，而作为公司领导要考虑的方面很多，他比较关心“不能做什么”。 践行有人会说，你说得容易，我每天加班，不加班老板就会把我炒掉，每天累得要死，哪有时间娱乐、社交、锻炼？那是人们把目标设定太高的缘故，如果你还在动不动就会被老板炒掉的边缘，那么你当然不能设立太高的目标，难道你还想每天去打高尔夫？你没时间去健身房锻炼身体，但是上下班的时候多走几步可以吧，有楼梯的时候走走楼梯不走电梯可以吧？办公的间隙扭扭脖子拉拉肩膀做做俯卧撑可以吧？谁规定锻炼就一定要拿出每天2个小时去健身房？你没时间社交，每月参加郊游一次可以吧，周末去参加个什么音乐班，绘画班之类的可以吧，去尝试认识一些同行，和他们找机会交流交流可以吧？开始的时候总是有些难的，但迈出这一步就会向良性循环的方向发展。而每天工作得很苦闷，剩下的时间用来咀嚼苦闷，只会陷入恶性循环，让生活更加糟糕。 墓志铭由于受我父亲早逝的影响，我很早就下定决心，要在有生之年实现自己的愿望，我不要像我父亲一样，为家庭生活忙碌一辈子，临终前感伤，懊恼自己有很多没有实现的理想。一本杂志的文章提到我们在生前就应该思考自己的墓志铭，因为那代表你自己对完美人生的定义，我们应该尽可能在有生之年去实现它。Carly Fiorina曾经对我说过“这个世界上有好想法的人很多，但有能力去实现的人很少”，2007年5月21日在北大演讲时，有人问起那些书对我影响较大，我想对我人生观有影响的其中一本书叫 “TriggerPoint”，它的主要观点是：人生最需要的不是规划，而是在适当的时机掌握机会，采取行动。 和任何人一样，要丢掉自己现在所拥有的，所熟悉的环境及稳定的收入，转到一条自己未曾经历过，存在未知风险的道路，需要绝大的勇气，家人的支持和好友的鼓励。有舍才有得，真是知易行难，我很高兴自己终于跨出了第一步。因为割舍及改变对人是多么的困难，我相信大部分的人都有自己人生的理想，但我也相信很多人最终只是把这些理想当成是幻想，然后不断的为自己寻找不能实现的藉口，南非前总统曼德拉曾经说过，“与改变世界相比，改变自己更困难”，真是一针见血。 LakeTahoe我去了多次，但这次的体验有所不同，我从心里欣赏到它的美丽。 我的人生观是“完美的演出来自充分的准备”，“勇于改变自己，适应不断变化的环境，机会将不断出现”，“快乐及有意义的人生来自于实现自己心中的愿望，而非外在的掌声”。 我总结人生有三个阶段，一个阶段是为现实找一份工作，一个阶段是为现实，但可以选择一份自己愿意投入的工作，一个阶段是为理想去做一些事情。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"新生 —— 七年就是一辈子","date":"2017-01-15T10:00:18.000Z","path":"2017/01/15/MyShare/reborn-every-7-years/","text":"“我们的一生其实可以活很多辈子的…… —-李笑来” 没有任何工具能够直接令人进步。真正使人进步的其实只有两个字：践行。切记：只有行动才能发生改变。想到了，就按照正确的想法做了 —— 不管别人是否理解 —— 这就是践行。我这哪里是对自己狠啊？这根本就是对自己的爱惜啊！想到了，学到了，就当真了；当真了，就当真做了，且真的做到了，这才是践行。践行才是真正的学习与创作。讲道理的人很多，践行的人很少很少。 我们就好像计算机一样，通过不断打磨、升级概念与方法论来升级我们自己的操作系统； 我们相信通过学习获得重生 —— 对我们来说，七年就是一辈子。每一辈子都要至少习得一个重要的技能，进而获得不可逆的重生。第一年可以像苍蝇一样左冲右突，一旦找到了突破口就要像蜜蜂一样，朝着既定的方向不断飞行。习得任何技能的过程中，我们都知道刻意训练并不依赖任何运气，只要付出就有收获。越是早期，越应该花更多时间精力去学习（磨练技能）。我们就是相信学识决定一切。 我们崇尚自学，认为没有自学能力的人尚不成熟。我们学习学习再学习。我们向往更好的生活，我们相信本质上一切都依赖学识。我们相信一切的努力都遵循复利效应，只要有耐心，通过积累，就可以达到之前无法想象的效果。财富、能力、魅力，以及抵御变故的能量…… 都是靠积累获得的，都有复利效应。我们相信惊喜（serendipity）其实是复利效应的终极体现。我们总是尝试着融会贯通…… 学习其实很简单，核心只不过是深入理解最重要的概念，不断总结与之相关的方法论。这样的朴素总结，使得我们很容易量化自己的进步 —— 看看自己过去一段时间里习得、打磨的概念与方法论数量就可以了。衡量学习效果的标准也很清楚：生活没有随之改变，就是没学会、没学好 —— 因为只有践行才是唯一有效的学习手段。我们不需要榜样，我们要成为他人的榜样。 要经常全无功利地学习 —— 只有这样才有更多的意外好运。我们向任何人学习，只要他们有长处，我们知道研究别人的失败比研究别人的成功更有价值。 我们珍爱家人，知道那是我们与这个世界最重要的关联。我们珍惜朋友，清楚他们的价值，也时时刻刻在寻找战友；我们寻找共同的价值取向，我们渴望改变自己，也渴望与战友共同参与到这个世界的逐步变好的过程中。我们通过努力把学习变成乐趣，不仅是为了自己，更是为了下一代 —— 聪明不能通过基因遗传，但绝对靠环境的潜移默化影响。 我们不花时间与他人争论，我们只为了弄清楚事实而讨论。我们不鄙视他人的能力 —— 我们自己曾经也能力不足，我们倒是不怕自黑，不过，我们更愿意与那些欣赏我们的人共同成长。我们懂得如何调整焦点，我们会主动尝试从多个角度去看待问题；我们不会把时间浪费在无谓的情绪之中，我们会用时间精力改变那些能够改变的事情。 我们不是圣人，肯定不小心会犯错。做错了事，我们不会逃避，我们不会只用嘴道歉，我们会想办法尽力用行动去弥补，只有这样做才能证明我们是负责任的人。犯了错，我们会认错；若是当初选择错误，我们会接受后果。我们量力而行，我们知道自己不断进步是为了即便出了更大的错误或者麻烦，也依然有能力承担、承受。生活中我们早晚会遇到各式各样的问题，它也总是反复无常，在不同的情况下，我们可能会调整模式，在极端的逆境中，我们也会想办法不被击败。 掌握任何一项新的重要技能，都相当于重生。学了却没有改变生活，那其实就是根本没学会。 重生的手段倒也简单：学习。学习新技能、走入新领域，循环往复。 学习学习再学习 我所说的“学习学习再学习”，不是由三个动词构成的句子；在这个句子中，第一个学习是动词，第二个学习是名词，第三个学习是动词。所以我的意思是说：要先学会学习这件事儿然后再去接着学习，这样才真的有意思。真的不是“学啊学啊学”的意思，更不是所谓的“重要的事情要说三遍”…… 《把时间当作朋友》 一本讲“如何正常、正确思考”的书籍，而不是一本“时间管理书籍” —— 因为时间其实不可管理，所以还是最好管管自己罢。而所谓的成功，其实只不过是用正确的方式去做正确的事情，耐心等待正确的结果出现。所以必须学会正常、正确思考，否则想错了的话，就做错了事情，做错事情的时候，效率越高越可怕，不是吗？选择了正确的事情之后，正确的方式是什么呢？是“一切都靠积累”。 史蒂夫·乔布斯 “You can’t connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in your future.”你无法连接未来的点，你只能连接过去的点。所以你只能也最好相信那些点终究会连起来。乔布斯就是把东西做到最好的人，这是他最可贵的地方。他是神一样的销售，他创造奇迹 —— 别人做不到他却做得到的事儿就是奇迹，这很朴素的道理。他把东西做到最好，好到什么程度呢？苹果也有很多不可理喻的地方，但不重要了，因为其它地方实在是太好了，好到用户无法舍弃的地步。就是这样。 李笑来当年我费尽周折应聘进入新东方，对我个人来说，是个突破。小时候学了点编程原理得过大奖却没能够被保送进清华但终究有点计算机常识；读了完全不喜欢的会计专业却因此收获了最重要的知识：概率和统计；因为本专业并不精湛所以毕业之后只能去做销售却因此锻炼了演讲能力 —— 就是这三点使得我在突破之后成为最受欢迎的老师。突破是突破了，这样的结果，其实并不是“设计”，却也不完全是“偶然”。 再后来的《把时间当作朋友》创作，对我个人来说也是一次突破。教写作不是我的计划与设计，只是教阅读的我听从领导安排去教大家不愿意教的课程 —— 没人愿意教写作课，都觉得费力不讨好。为了教好，自己就要学好，写好。前后写了大量的英文文章，反过来中文竟然写得比以前更清澈了，我自己也没想到。而最终提炼出“时间不可管理”，其实是在写作过程中闪现的“灵感” —— 这一点从我最初给那系列文章取的名字就看得出来：《管理我的时间》…… 在反复折腾中抵达了一个之前完全看不见、想不到的地方。 创建 Knewone，收割大量的比特币，创建比特基金，参与若干个创业项目，甚至像是玩票一样的 Telegram 第三方客户端 Dove…… 这些都是今天我正在做一个教育类社群的成因，但还是相同的类比：是破冰，而不是登山。哪怕在 2015 年的 10 月份，我还没有彻底明了我最终做出来的东西究竟是什么样的。整个破冰过程是 2015 年的 11 月才开始的，然后我就看到了另外一个之前完全无法想象的世界…… 很多道理上清楚正确的事情，却很少有人真的去做。 绝大多数人，差的其实只是一个机会和一点点的训练 —— 如若他真的有一颗不甘的心。恰当的机会、恰当的训练，就是可能让一个人脱胎换骨的 —— 就是我们反复提及的“重生”。 鸡汤 所谓的鸡汤，其实正确的概念名称应该是：进步方法论。 爱因斯坦 “Compound interest is the eighth wonder of the world. He who understands it, earns it … he who doesn’t … pays it.” 复利是世界第八大奇迹。知之者赚、不知之者被赚。 笨蛋 别笑，别以为自己不是笨蛋，我们每个人都有可能是，或者必然曾经是。 复利效应 万幸的、也是公平的是，每个人都一样，在智力上、知识上、经验上，复利效应依然存在的 —— 这是多么令人喜出望外的事实啊！只要能积累的东西，基本上最终都会产生复利效应。如果没有继承资产，那么就持续积累知识罢，我们运气真的很好。我们恰恰活在一个知识变现很容易、且越来越容易、且变现金额越来越大的时代。在没有继承资产的情况下。我选择了知识积累，并且笃信知识的效用 —— 我知道、我相信，在许多年后的某一天，知识会变现的，而且它一旦变现，很可能瞬间就能抵消过往所有的挫折。结果呢？所谓的“许多年之后”，在我 39 岁那年（2011）的时候来临了…… “逃逸速度”（Escape Velocity），又叫做第二宇宙速度（Second Cosmic Velocity） 第一宇宙速度是 7.9 km/s —— 用这个起始速度发射，航天器可以环绕地球飞行； 若是起始速度超过 11.2 km/s，即超过第二宇宙速度，那么航天器可以摆脱地球引力的束缚，飞离地球…… 第三宇宙速度，16.7 km/s，可以让航天器飞离太阳系， 第四宇宙速度，大约应该是 52.5 km/s，能飞离银河系…… 航天飞行器怎么飞起来的呢？科学家们要考虑的是这么几件事情，航天飞行器的重量、起始的速度、可携带的燃料数量 —— 要命的是燃料箱本身也有重量…… 所以，科学家们想出来的办法是，飞到一定高度之后，把一节燃料箱丢弃掉（jettison），降低飞行器的重量；再飞高一段距离之后，还要再丢掉另外一节燃料箱…… 知识是有能量的，且不受“重力加速度”的限制。 你的商业计划就是你的赚钱计划。 既然商业计划就是赚钱计划，这样朴素的描述，使得衡量商业计划的标准特别简单： 你可能赚到多少钱？你最快多久可能赚到那么多钱？注意措辞：是“可能”，不是必然，不是必须。另外，快不是一个单独的变量，数量和速度放在一起才有意义。获得经济自由的方法很简单：就是靠朴素的思考、朴素的方法论、朴素的践行 个人品牌 “个人品牌”的积累，从使用实名那一瞬间开始……认真给自己找乐子的人没办法不招别人喜欢。新鲜感其实完全是可以自己创造的麽！我今天的写作能力也是通过很长很长时间才磨炼出来的。你的苦没人知道。所以，从此坚决不抱怨。但凡有点办法的人，就忙着做事去了，抱怨、诉苦管啥用啊？这就是我的看法。没人害你，你也可能很倒霉。关键时刻，谁都帮不上忙，只能靠自己。 灵感灵感更多的时候是创作过程中获得的，而不是创作的起点。 评论 不删除评论是很重要的，先不说那些冠冕堂皇的话，比如， “你有表达的的自由，我有捍卫你表达的自由的权利”，只说说这对自己的用处：若是真能做到心平气和，那些反对你的和辱骂你的留言和评论，作用很多： 给你一些线索去理解那些人的思考方式； 偶尔你会发现自己的表达不清楚才招致误解； 还有些时候恰恰因为它们的存在而能确认自己确实是对的……绝对不删除任何评论，在那几年里给我带来了另外一个好处：性情真的淡定起来，开始变得很难生气或者难过。 情绪 许多年后，我一直觉得那段经历是我幸运的起点之一，因为我后来的淡定的性格，几乎真的是从那时候开始的，情绪的鸿沟，只要真正跨越一次，就真的不可逆了，因为你已经明白一个道理，情绪与目标无关，相对于“达成目标”只有行动才是相关事件。失败不可怕，可怕的是差一点成功了。关键时刻，不要掉链子，没人能帮你，只有靠自己。情绪这东西，百无一用，行动才是必须的。 主动、创造 我希望有一天我能够卖我自己创造的东西，而不是别人的东西。虽然我不知道我能创造什么，但我知道我要成为一个有创造产品能力的人。在那段时间里，我做出了我人生第一个重大的主动的选择。这次的选择，却是主动的。我在挣扎中看到了自己的未来，我必须成为一个有创造能力的人这次的选择，其实是含混的，我甚至不知道将来要创造的是什么，我只知道我必须成为能创造的人。从 28 岁那次的主动选择之后，做出主动选择的难度在不断降低，所以，这一次再做出一个主动选择就很自然了。所有的重生都是主动的选择。衡量一个人是否真正活着的根本方法，就是看他是否有意愿、有能力做出主动的选择。 自欺欺人 我在某次事件中义愤填膺地觉得“不公平！”，并且四处游说…… 可事后反思的时候，发现自己真正想要的只不过是“分一杯羹”。在自欺欺人的状态下，很多卑劣的行动好像一下子就“理直气壮”、“光明正大”了似的；等冷静下来开始反思的时候，觉得自己每个毛孔都是肮脏的……甚至连呼吸的声音都是猥琐的。高品质生活完全从停止自欺欺人开始……我逐渐开始意识到很多情况下，抢占道德制高点是特愚蠢的事情……人们抢占道德制高点，只不过是被“自欺欺人”的心理所左右。我开始不怕被人们用道德的理由指责我了，我甚至开始懒得争辩，他们说他们的，我做我的，他们舒服他们的，我舒服我的，其实可以互不干涉，只不过是他们以为他们的干涉有用而已，我要是像之前那样一不小心就真的被他们干涉了，那才不划算呢。 犯错 人总是会犯错的——本质上来看，对大多数人来说，这只是运气不好，因为故意犯错的人是坏人，不在考虑范围内。 犯了错之后，绝大多数人只用嘴道歉。 表现更为恶劣的是掩盖、撒谎、或想办法证明对方也不是个好人……这些人其实已经差不多是坏人了， 再下一步就是用嘴道歉之后得不到原谅就说你小心眼啊、没风度啊、不够意思啊什么的，这样的人比坏人还坏。 只有少数人在发现自己不小心犯了错之后，马上用嘴道歉，随后开始用行动道歉，弥补，直至一切恢复原状，甚至比原来更好——这其中可能需要付出很多代价，但他们知道这是自己必须做的，否则就不再是自己。 Live with it! —— 这是我在电影里听到的最震撼心灵的台词。是啊，很多事，最终就留在那里，好啊、坏啊，不重要，重要的是它们挥之不去，一辈子都与你相伴。我用了好几年的时间，才渐渐地感觉自己干净了一些，清爽了一些，也因此感觉自己真的重生了。那几年过后，我开始变得宽容起来 —— 真正的宽容 —— 因为我自己是“走出来的人”。那“自欺欺人”就像个牢笼，何止啊？干脆是个“Panopticon”，我自己走出来了，就好像成功越狱一样，当然明了走出来多难，当然知道在里面多苦，不是吗？ 严于律己、宽于律人，对我来说不再是一句“有道理的废话”，而是清楚的实践。而且，这其实是一种“自私的实践”。严于律己，其实等同于在提高自己的效率；严于律人，其实等同于降低自己的效率，或者用另外一个说法就是，允许他人拖累自己的效率。与此同时，严于律人的副产品常常只不过是“凭什么让他们占便宜？” 或者 “我也不必当个好人罢？” 之类的特别容易转换为行动的愚蠢想法。自我治疗成功的另外一个副作用是，从此不害怕追求进步了。从此不再容易自卑。 “年轻的时候做了蠢事是正常的” —— 何止“正常”啊，简直是“必然”。每个人在成长过程中都会做一些这样那样的蠢事，关键在于一个人是否能够成长到可以承担那些责任，修复那些错误的地步 —— 大多数人不能。没有人是完美的，没有人不曾做过蠢事，即便有一天在某方面成功，也要永远面对自己曾经做过的蠢事，也要 live with it，扛一辈子…… 自信 人要有自信，但，应该是对自己的未来有自信，而对现在的自己，对过去的自己，自信、自负、自卑其实都是无意义的，要现实才对 —— 错了就是错了，蠢了就是蠢了，把自己变得更好才能弥补那些错误，才能承担当初的愚蠢。我应该对自己的未来自信，而不是对自己的现状自信……我能够真心为了别人的进步和成功感到高兴，说明我终于有了真正的自信。衡量一个人是否真正自信，就看他是否能真心为他人的成功而毫无芥蒂地感到高兴。 自卑 该自卑的时候就得自卑。生活中遇到问题，就犹如遇到一个已经被锁上了的锁头，而那钥匙一定不在锁孔里，否则那锁头一拧钥匙就开了啊。遇到打不开的锁头，当然要到其他地方找钥匙，而不是盯着锁头发呆。找钥匙所耗费的时间可能很短，也可能很久。“彻底消灭自卑”的钥匙我找了三十多年…… 找到之后才觉得自己好笨啊！ 停止嘲弄他人 忘记自己的优点 适当地放纵一下自己 自省自省真的是个艰苦卓绝的事情，虽然说起来的时候总是可以做到显得云淡风轻…… 比较拿着现状与他人相互比较，必然总有这样那样的不足 —— 而比较带来的幸福感，通常也是虚妄的。即便是要比较，那被比较的对象也应该是“自己的现状”和“自己的未来”；而不是“自己的现状”与“别人的现状”。为了自己有更好的未来，所以今天必须足够努力，反过来，今天要更加努力，也正因此才对自己有更好的未来确信不疑。(又一次 X 值相对下降，Y 值相对提高……) 错过 错过的原因，无非是一个念头，一个当时想当然的念头而已。这是个活生生的“ 一念之差 ”的例子。想当然的念头，常常来自于周遭环境，一团乱糟糟的东西打成包，直接植入了自己的操作系统，最要命的是它们通常还处于底层，所以才想当然，所以它们的害处才不易察觉。比如，“学外语很难的！” 就是个这样的“想当然的念头”，被打包植入了我们的操作系统，乃至于我们不由自主地变傻了…… 观念 人与人的差异在哪里？在我看来主要是观念上的差异。上面让我错过一辈子的，就是个落后的观念：别人做不好的，我也别做了罢……很多影响我们一生的，竟然都是很小，却又不成比例地重要的环节。 想当然与认知读一本好书，基本上就是对操作系统的一次升级 ，或者起码一点的升级（叫“打补丁”也可以）。然后呢？有的人一年升级 50 次以上，有的人起码 12 次，也有的人好几年都不升级，后来干脆就那么对付着用了，却也不觉得自己落后且越来越心安……很多其实很重要的建议，常常只不过是因为陈述过于笼统而难以传递，难以接受，难以践行。找出那些想当然的念头，挨个审视一遍，看看它对不对？有没有道理？是否应该被升级，或者被替换？这事儿一定要仔细，因为那些不经审视就嵌入操作系统的“想当然”实在是太危险了…… 类比计算机 我们自己其实就是这样的计算机，“厂商”（我们的父母）并没有为我们提供详尽的说明书，也并不负责定期升级我们的操作系统 —— 即便他们并非故意……每个人的大脑里其实都有一个属于自己的操作系统，真的跟计算机一样！每个人都有一套属于自己的输入输出体系（IO 系统），有着一套属于自己的运行处理机制。人和人之间很不一样，就好像计算机和计算机之间也很不一样。有些人的中央处理器（头脑）更强大一些，有些人的内存容量（记忆力）更大一些，有些人的硬盘空间（笔记与藏书）更大一些，有些人的显示器（外表）更漂亮一点，有些人的打印机（写作能力）相对比较高效，有些人配置了网卡（沟通能力）所以可以连网，有些人则不连网，有些人的带宽（沟通有效性）很足，有些人的带宽很小，有点人在互联网上（开放），有的人在局域网里（封闭）…… 操作系统升级 绝大多数人的操作系统竟然从不更新！粗糙、原始的操作系统的主要特征是：它越差就越自洽，漏洞百出却又能持续运转，最关键的是：它没有任何自动升级的机制。我们的操作系统主要由概念及其相关方法论两个紧密相关的部分构成我们操作系统里 —— 描述正确的、理解完整的概念和方法论越多，我们理解新概念、新方法论的速度越快，融会贯通能力也越强……理解速度快了，阅读速度放慢一点，效率可能更高呢。只不过是不断清理自己的概念、扔掉该废弃的，不断吸收新的、有必要的概念，并且通过应用不断完善与那些概念相关的方法论。所谓的“成长”就是操作系统不断完善的过程；所谓的“重生”就是操作系统更新换代的节点；所谓的“不断再生”就是我们意识到这些操作系统更新换代的必要性，于是给自己设置提醒模式，给自己发展自动更新模式的持续动力。(比如给自己设定每七年要有一次大的更新换代……) 硬件升级 所有的体育运动本质上都是在升级“硬件”。熟练使用工具，也是“升级”硬件的一种方法。很多人长期不升级自己的“硬件”的根本原因只不过是“没想到”罢了。 教育就像一副眼镜。 戴上眼镜之前和之后，我们看到的其实是同样的世界；但带上眼镜之后，我们就能看得更清楚。教育也一样，受教育之前与之后，我们身处的其实是同样的世界；可受教育之后，我们就能看得更清楚，想得更明白，选择得更有效，行动起来更有收获…… 科学与信息 VS 房子与砖头 科学确实是由信息构成的，正如房子是用砖头盖的一样。可问题在于，正如仅仅一堆砖头放在那里的时候我们不能称其为房子一样，一堆信息放在一块儿就叫科学，有点不像话…… 创造类比 创造类比本身就是难度很高的活动，一般人做不来 首先要有足够的知识、信息储备，才能在理解新事物的时候找到真正合适的、最恰当的那个“参照物”； 之所以能找到最恰当的，不仅仅是找到最“像”的那个，还要仔细搞清楚“不像”的地方究竟有哪些，以免在传递信息的时候出现偏差……类比也常常是产生“融会贯通”的手段。学会任何一个概念、方法论之后，都要问自己：这个道理还能用在什么地方？ 幸福 VS 商业 … all happy families are alike and all unhappy families are unhappy in their own special way, is not true in business, where I think all happy companies are different because they’re doing something very unique. All unhappy companies are alike because they failed to escape the essential sameness in competition.（这是个反向类比——即，你别以为它们一样，其实它们刚好相反……） ……据说，幸福婚姻都是一样的，不幸的婚姻各有各自的不幸；在商业世界里不是这样的，我倒是认为所有的幸福公司都是不一样的，因为他们都在做不同的事情。而所有不行的公司倒是一样的，因为他们都没能脱离竞争的相同窘境。 编辑 VS 管理 So one of the most important things I learned at Square is the concept of editing. And this is the best metaphor I have ever seen in 14 years of running stuff, of how to think about your job. 所以我在 Square 学到的最重要事情之一就是“编辑”的概念 —— 这是过去我在管理员工的 14 年经历中所遇到的关于如何看待（管理者）工作的最好隐喻（类比）。 “像”与“是”不小心混淆了“像”与“是”的人，在用类比理解新事物的时候，接着下一步要犯的错误就是“以偏概全” —— 因为新事物已经等同于（是）旧事物了，那就没什么需要“理解”的了嘛！更没有了继续研究得必要……理解了那“像”的部分之后，还要继续探究那些“不像”的部分，新事物之所以新，就是因为那些“不像”旧事物的部分啊！在面对新事物的时候，我总是告诫自己，暂时先克制寻找类比的冲动，因为不恰当的类比还不如没有类比，甚至，不恰当的类比干脆相当于有毒，会麻醉我们的大脑，阻止我们有效地思考。我总觉得，在对新事物有了足够的了解之后再去找类比不迟；而对新事物有足够的了解，也是有能力找到精妙类比的前提，万一找到了，可以自己用来辅助面向他人的说明，或者作为帮助他人的辅助理解工具…… 找不到很好的类比，也很正常。好的、精妙的类比超级炫酷，可还是要小心为妙，因为类比真的影响思维。 成功类比 好像人们都喜欢用“登山”去比喻成功的路径，也许“攀登”这个词本身就给人“进取”的印象罢。 可是长期以来，我觉得我所遇到的所有成功与突破，都更像是破冰。我总觉得自己站在一个冰原之上，特别想要把脚下的冰砸开…… 可无论是我使劲跺脚也好，满地打滚也罢，我总是没办法一下子成功，一下子突破。若非换个视角，或者谁给我个透视镜，我真不知道那冰实在是太厚了…… 往往是就好像我在冰原上四处游荡，四处猛砸，猛凿，有时深，有时浅，有时候甚至可以从冰缝或者冰洞里看到冰下的水，可那冰就是那么坚实，我死活都没办法破冰而入…… 还记得美剧越狱里主角是怎样运用胡克定律凿开那堵厚厚的、“坚不可摧”的墙的吗？ 终于破冰的那一瞬间，我的感觉就是，过往我砸过的、凿过冰缝、冰洞，终于以某种方式（几乎肯定是我之前完全不知道的方式）形成了一个三角，力学原理瞬间爆发，那冰一下子大面积破开…… 于是，我终于“入水”了。把登山当作类比，与把破冰当作类比，有一点不一样的地方。把登山当作类比的时候，我们会不由自主地以为“突破”是看得到目标的事情 —— 因为山顶就在那里。把破冰当作类比的时候，我就很自然地不太在意那个可以看得见、想得到的目标，很理直气壮地明白：我要去的是一个现在完全看不到的地方，但肯定是不一样的世界。 概念 概念是一切知识的基石我们要持续升级概念及其相关方法论我们描述一个人能力不够，或者全无能力的时候，经常这么说：xxx 在 yyy 方面根本没概念。司机坐在车里，有完全看不到的盲区车这东西，真不是司机想停下来的时候就能瞬间停下来的……行人在晚上穿着暗色衣服在路边走非常危险……在任何一个领域，对该领域中重要的概念无知，那就真的与白痴无异学习就是让自己变聪明的过程，习得那个领域中最重要的概念，琢磨清楚相关的方法论，就马上“不那么白痴了”。“上火”就是一个早就应该抛弃了的概念，正确的概念是“炎症”，或者“维生素供应不足”。 独立思考 能够独立地、正确地使用正确的概念。 读书 这么厚厚一本书，其实就那么几个概念；讲一个概念就要花费一个章节的篇幅，从结构上来看，其实讲的都一样，无非是一个接一个的概念，要说清楚它是什么，它不是什么，它和别的概念有什么异同；然后就是与它相关的方法论，比如，使用的时候需要注意什么，怎样使用是正确的，怎样使用是错误的，容易发生错误的地方是什么…… 这些都弄明白了，一个概念就算是学透了，这些概念都弄明白了，这本书算是看懂了，就这么简单。 那些之前属于“死记硬背”的东西，其实相当于给自己的大脑安装了很多个“传感器”，一旦听到有人提到它们，因为熟悉，脑子里就会有反应。若是之前完全没有过死记硬背，那些概念在脑子里根本不存在，那么在走神的时候，即便有人在身边提到那个东西，大脑也全然不会有所反应。 教育 今天学了什么呀？那 xxx 是 yyy 吗？那 xxx 为什么不是 yyy 呀？那 yyy 有什么用处啊？那我这么用 yyy 可不可以啊？今天有谁把 yyy 用错了啊？…… 阅读速度真正有意义值得研究的概念是：理解速度。输入是为了处理啊，胡乱处理，甚至无法处理，输入了也没用啊！读书不是吃东西啊，读书就算有点像吃东西，那也是要消化了之后再排泄啊！不消化很难受的好不好？若是阅读速度快就可以了的话，那么谁都拼不过复印机了罢？开什么玩笑？！ 固守与进取人分为两种，一种是固守型的（Be Good Type），一种是进取型的（Be Better Type）。这两种人的主要区别在于，他们做事的时候，关注的焦点不一样：固守型的人（Be Good Type）更关注自己当时的表现，更在意外界对那表现的看法；进取型的人（Be Better Type）更关注自己当时有无进步，并不在意对外界的看法； 第一种人过分在意自己当时当刻的表现，直接带来的结果就是，如果“感觉有可能做不好”，就直接不做了 —— 省的丢人。第二种人常常并不在意外界的看法，他们知道自己有可能做得并不好，但这并不妨碍他们进步，只要下一次比这一次更好，就是他们想要的结果。他们更习惯于接受挑战，处理压力，更懂得积累的好处。 面对同样的压力，这两种人会做出截然相反的选择。固守型的人，在压力下表现会更差，表现差会进一步导致他全方位溃退。进取型的人，在压力下反倒可能更有动力，因为历史经验反复告诉他自己总会越来越好的…… X和Y评测 固守型、进取型这两个重要的概念来自于一本书，《成功，动机与目标》(Succeed: How Can We Reach Our Goals, by Heidi Grant Halvorson)。Halvorson 博士在书中给出了一个小调查文件，用来让读者自行判断自己究竟属于哪一种人：认真地问自己以下问题，如实地回答自己，给每一个问题打分。一点都不同意，是1分，非常正确是6分。 功课或者工作比同学、同事做的更好对我来说非常重要。 我喜欢能让我更了解自己的朋友，尽管有时候得到的不是正面信息。 我常常寻找开发新技能、汲取新知识的机会。 我很在乎是否给人留下好印象。 展示自己的聪明才智与能力对我来说很重要。 我努力和朋友及熟人保持开诚布公的关系。 我努力在学校或者工作中不断学习与进步。 当我和其他人在一起时，我很在意给别人留下的印象如何。 当我知道别人喜欢我时，自我感觉会很好。 我试图比同学或同事更出色。 我喜欢别人挑战我，从而使我成长。 在上学或上班时，我注重施展我的本领。 现在请把第1、4、5、8、9、10、12题的得分相加之后除以7，记为 X。再把第2、3、6、7、11题的得分想家之后除以5，记为 Y。最终，你的得分中，X 和 Y 哪个数值更大呢？X 数值更大的人倾向于“表现导向”（Be-Good Type）；而 Y 数值更大的人倾向于“进步导向”（Be-Better Type）。 有个简便的方法判断一个人的 X 值是否过高？“你只要看他是否害怕被他人嘲弄？”固守型这类人的主要特征是“死要面子活受罪”，但更为可怕的是，他们无法进步。 压力 致命的不是压力本身，而是压力与观念（认为压力有害健康甚至致命）的组合。“很多人其实是被自己慢慢吓死的……”人就是这样一种动物：”心理与生理相互影响。” 成长 学会了哪些原本不知道的概念和方法论？？哪些已有的概念和方法论被进一步打磨了？这样的描述使得“成长”多少可被量化 —— “可量化”很重要，因为量化的结果是最好的反馈。成长从来都是需要过程的（常常是漫长的过程），需要不断有足够的反馈机制去激励。成长可量化了，它就有了足够的动力。而这本身，也是“成长与重生的方法论”。一切都是学识决定的。很多的时候，所谓的耐心、所谓的沉得住气，其实是学识 —— 学识决定一切。 非议、争论，与鄙视链 所谓的“超常的应急反应”其实是可以提前通过各种假想和预演提前反复练习的……善恶其实是次要的。所谓“人人心里有杆秤”——那秤称的其实是强弱。面对非议的时候，真正要解决的问题不是去辩解，而是想办法让自己变得更强。弱者的逻辑都一样，奇葩而又自洽爷又不是人民币，怎么可能谁都喜欢？自己错了，就承认，并且想办法承担后果 —— 我觉得大丈夫就应该这样。而别人错了，承认与承担都是别人的事情，用不着我去操心；如果那错造成了我的损失，可也无法上升到法律保护高度，那我就懒得追究 —— 因为我自认自己的时间精力更为宝贵，不应该浪费在这样的地方，甚至连生气的必要都没有，大好的人生在等着自己，哪里有功夫理会那些？你所处在的那个位置，常常会决定你的视角“有些事情跟处女就不要说了罢” —— 这是一个很好的类比，因为有些人的立场，是不可能有另外一些体验、经历所支持的。这是一方面，于此同时，“有些话跟已经离婚的人就别说了罢” —— 这还是个很好的类比，因为有些人的立场，是不再可能有另外一些体验经历所支持的，因为他们已经确定不会有“百年好合”的结果了。 你手里攥着某个公司的股票（数量很多），那么你的立场就与那些光说不练的股评师不同；跟那些买一点见好就收的短线操作者不同；其实你的立场通常也与董事会那些大股东非常不同…… 在这种情况下，有些争论，其实并不是道理上的冲突，只不过是视角不同、层面不同而已。 最终的数据表明，无论是哪一方都得到了印证自己想法的结果…相信“压力影响健康”的人，健康就真的受到了影响；相信“压力不影响健康”的人，健康就真的没有受到影响 ——这种观念影响结局的现象，使得有些争论永无平息之日，因为从争论双方各自的视角来看，自己都是天经地义地正确的！ 讨论的目标是为了让自己更明白争论的目标是为了彻底说服对方 争论的冲动常常来于自己的弱小。人微易怒。弱小的个体更容易闹情绪，若是有情绪掺杂，那么言论就越发地不靠谱，不靠谱的言论又掺杂着更多的情绪，恶性循环生生不息。彻底逃离鄙视链。有些事情，尤其是倒霉事情，其实是自找的鄙视链也是一样的，那是个循环嵌套的局，一旦置身其中，必然会反过来被鄙视，早晚而已，私下或者公开，谁都逃不掉。不想被鄙视，就别在那个局里。事实上，即便你挣扎着脱离了那个局，一样会被莫名其妙的人鄙视，只不过，因为你自己不在那个局里，所以你清醒，所以你知道，那鄙视是那个人的幻觉，跟你完全没关系。时常反省，就会知道鄙视与争论一样，通常是自身弱小才更容易产生的冲动，常常是自欺欺人的表现。嗯，被鄙视，其实是自找的。 计算机 计算机是由我们人类中的极少数极少数人 —— 比例上来看可能连千万分之一都不到 —— 发明并持续研究完善出来的东西。所以，我们从计算机上可以学到的，其实是极少数极少数聪明人的思维方式和方法论。 通信协议 不同的操作系统之间的通讯，是需要共同的协议支撑的，不使用共同的协议的计算机之间没办法通讯。在互联网上，最常见的协议是 TCP/IP 协议。TCP/IP 协议的运行机理大致如下：网络上有很多台计算机（A ~ Z）相互联网，它们之间使用相同的协议传输数据……A 若是需要传输数据给 Z，那么之前需要 A 与 Z 握手三次，才能确定连接有效…… A 必须先把数据切分成若干个小的数据块，然后逐一传输出去…… A 送出的每个小数据块，到达 Z 的路径每次都可能并不相同：不一定是直接的 A-Z，可能是 A-B-X-Z，可能是 A-X-C-Z，也可能是 A-B-C-Z…… 反正是个各自相通的网络么，所以，无论选择什么路径，只要能够到达就可以…… Z 一旦收到了小数据块，会发出回执，A 收到上一条回执之后就会发出下一条，若是在设定的时间窗口中未获得回执，则判定传输失败，放弃继续传输…… 直至所有数据块全部发送完毕，A 收到所有收据之后，再发出一个“发送完毕”的消息（这个消息也会返回一个收据），Z 在另外一端再把所有数据块按照顺序拼起来，形成一个完整的数据…… 沟通借鉴 很多事儿，其实很复杂，想要一下子说明白，一下子让对方想通，是很难的，甚至是不可能的。那怎么办？必须把整个事情提前拆分好，分清楚主次，分清楚先后，然后一件一件地来，并且在这过程中，还要反复确认确实沟通成功才能进行下一步……沟通成功的关键在于：双方都是讲道理的人（就是肯遵守协议的人）。 我要做好至少尝试确认三次是否真的可以开始沟通； 沟通有很多种方式(至少有直接沟通和间接沟通两种)，不能局限在特定的某种方式上； 我要有个办法确认每次沟通确实成功； 如果事儿足够大，我就会切块，分步沟通； 总而言之每个环节上都一定要有清楚的确认机制…… 夫妻为什么吵架 在选择伴侣的时候，最好……寻找同级别的操作系统；要升级就大家一块儿升级……“门当户对”，其实就可能是为了找到“合适的、可兼容的操作系统”“三观不和最伤感情了……”，其实真的不是玩笑。的确如此，从某个角度望过去，所谓的三观，就是在说操作系统的一部分。保持对异性的魅力的方法其实很简单：持续学习，不断进步。为什么婚姻中普遍存在所谓的“七年之痒”？我的解释是很简单：七年就是一辈子，一辈子都过去了，下辈子还要过同样的生活，多腻歪啊。 底层概念差异 主次不分 价值观不同 立场不同 历史不同 无仲裁夫妻不吵架或者逐步减少吵架频率的方法论无非是：共同“创建”协议，共同”遵守”协议，共同”升级”协议…… 身边还有很多原本应该很亲近但实际上却不那么亲近的人 —— 亲戚。不知道为什么，我发现亲戚竟然是最难与之共同成长群体，也许是现代人的生活结构发生了变化罢。另外一个群体也是如此，老同学 —— 明明心里有那么多的亲近之感，但确实早就失去了共同成长的机会。那怎么办？在自己的大脑里也多创建几个虚拟机才对啊！这真是非常先进的方法论！—— 说多少遍都不过份：向计算机科学学习思考，等同于向地球上最聪明的人学习思考……教书的时候，之所以被学生“感觉教得好”，无非就是相当于我在脑子里开启了一个与他们一样操作系统的虚拟机，所以我知道他们跑出来的结果是什么样的，所以我才有清楚的解决方案啊…… 有规定没问题啊，拿出来给我看看呗……先说清楚啊，我一会儿哪怕嗓门大了，也不是针对你个人，是被你们公司气的…… 生气，是最浪费时间的行为。浪费的不仅仅是气头上的那一段时间，更为可怕的是在气头上做的决定常常连带一个很微妙且又复杂当期影响，最可怕的是，这个影响其实很容易产生“复利效应”，我的意思是说，“负面的复利效应”……首先，不能生气。其次，在不生气的情况下，偶尔可以假装生气，这是工具。再次，一定要先表明立场和态度。最后，只说道理上百分之百站得住脚的话。 多赚钱，快赚钱，有钱到吃得起亏的地步。吃不起亏，就很容易生气；很生气，就很容易失控，最终无法解决问题，既浪费了时间，又不得不接受不好的结果，于是恶性循环……哪里有什么好脾气啊，只有想的明白和想不明白…… 因为想不明白而抓耳挠腮的时候多的去了，实际上，我自己天天都有生气的时候，气自己为什么那么笨，连这点问题都解决不了…… 能解决问题就不用生气了罢。 什么是朋友？ 朋友就是那些与我们共度时光，让我们感觉温暖，让我们心甘情愿地付出的人。而这里所说的付出，常常是我愿意花时间、花精力主动联络，主动维系友谊的那些人。因为老朋友的稀缺性，自己开始为这个类别增加了一个原则：轻易不跟他们产生合作关系，生怕伤到这个稀缺的存在。不是不，而是轻易不，这其实是一种尊重。成熟的特征就是独立，独立的意思是说，生活上、经济上越来越不依赖朋友的存在，朋友更多是精神上的需求。 朋友就是那些愿意与我交往，并且我也钦佩的人。朋友就是那些我愿意花时间与精力，与之共同做成至少一件事儿的人。 对朋友、友情的定义，其实背后是一个很简单很清晰的过程： 依附 独立 共生 友谊中最有价值的部分来自于各自的成长或者共同成长。 维系任何一个关系，都需要有一个主动的人存在，否则，总会渐渐淡忘。这当然也是很多朋友这么长时间以来一直能跟我保持联系的重要原因。每个人的时间都有限，必须认真选择值得花时间的人，否则不划算。于是，我有了几个简单的标准，作为我甄别朋友的方法论： 一技之长追求进步真诚热情 所谓的大牛，就是那些有能力构建自己的世界的人。用嘴道歉的人不值得交往，用行动道歉的人遇到一个就要珍惜一个。 所谓的情商，指的是一个人有多大的能力去创造共赢局面。不要说多人，就是两个人交往，也最好尽量避免求人的状态，这样的关系没办法长久。最好是能够创造一个两人共赢的局面，各自都开心。这不太容易做到，但肯定值得为此多花时间做功课。 有些人别说战友了，连朋友都做不得，尤其是那种“死要面子活受罪”的人。他们总是毫无主张（就是其实没脑子），遇事总是各种纠结（还是没脑子），要么唉声叹气地抱怨，要么无能地暴跳如雷（反正就是没脑子）……遇到这种人，一定要当机立断地断舍离，顶多偶尔为他们打开一个虚拟机，应付一下，但有一扇大门一定要直接关掉，让他们绝对没办法进入属于你的那个领域。 朋友不会自动变为战友。要满足以下几个条件或者经过以下几个阶段，朋友才可能转变成战友：共同目标并肩战斗共享成果 找到共同的目标，并且经过沟通，确立共同的目标，这很重要 —— 否则没有战斗，就算有也是各自的战斗。有了共同的目标，才有并肩战斗，才有同甘共苦，才有荣辱与共，才有出生入死，才有共进退……没有共同目标的，不是战友，是狐朋狗友，不是团队，是团伙。所谓战斗力，长期来看，是脑力，而不是体力，核心是学习能力。要先把自己变成战士，然后才有资格寻找到其他的战士，找到共同目标之后，成为战友，然后共同浴血奋战，达成成就。看看历史书吧，有一个生死战友，就很厉害了，陈胜、吴广，各自只有一个真正的生死战友；有两个生死战友，就可以桃园三结义了……创个业什么的，根本不是什么事儿罢？所谓的领导力，其实就是带着战友战斗，然后自己成长，也帮助他们成长，帮助战友再找到战友……两三个层级下来，就形成了一个真正的团队。 真正有用的书，一本就可能完全改变生活 做出真正好的东西，销售就好像是不存在了一样，放在那里就行 —— 为什么呢？因为这是互联网时代。《把时间当作朋友》更是印证了这个看法，在免费版一直放在网上的情况下，印刷版销量一样也是多年逐步攀升。 把东西做到真好，直至最好，其实是最省心、最省时的方法论。它若是真的已经最好了，任何“推销”都是没必要的。不用费心给别人理论为什么我这个东西最好，也不用理论为什么你一定要买我的东西…… 完全不用。 不学习就要挨打，这肯定是真的。 做出最好的东西，不是不讲理，而是不用讲理了 —— 因为把东西做到最好，就是最大的理，这事儿都做完了，还有啥可讲的？你都把东西做到最好了，还有人说三道四，那就随他们去罢，忽略他们，过滤掉他们，没时间跟他们打交道，就是这样。 这是一个物资极为丰富的时代，这是个任何人都可以光明正大赚到足够多钱的时代。在这样的一个时代里，没必要偷偷摸摸地赚钱，没必要昧着良心做事，没必要靠着雕虫小计讨生活。我希望这不是技巧。这应该只是一个习惯：把客户真的当作好朋友。真的做到这点，你就会发现自己的整个想法都可能变了。别说不好意思，你就是不愿意把不好的东西卖给朋友的。甚至即便是好东西，也要三思而行，万一有什么闪失怎么办？别说卖了，哪怕推荐都要自然而然地三思而行。 那些酒肉朋友，那些平日里跟你热闹的人，绝大多数都是靠不住的。 把东西做到最好的人，往往能自然而然地享受这世上看起来最好的一种状态：头上有光环。光环效应同时可能是毁人的。光环效应之所以存在，并且能量巨大，本质上就是因为绝大多数人无能力判断，甚至不知道自己其实完全无能力判断。于是，光环效应是迷惑人的，但创造者要抵御这股力量，不能被自己的光环晃瞎了自己的眼镜，灼坏了自己的脑子，要想尽一切办法继续做出更好的东西。 说服他人有两个重要的终极诀窍。践行，才是真正的学习；也只有践行，才可能带来真正的改变；只有改变，才会成为榜样。若是已经成为了榜样，根本不需要说服过程，用不着费那些口舌。就是这样。榜样其实不需要完美。只需要确实不断进步，就已经是神一样的榜样了……有效沟通，真的很难。与其花时间精力推销，还真不如把那时间花在自己身上，默默地成为榜样好了。 第一个：让对方自己得出结论，而不是把结论塞给对方。第二个，实际上是第一个的升级版：自己成为榜样，对方若是认同，自然就会追随。 解决问题 解决问题的能力，是人生最重要的能力。遇到解决不了的问题，就烦恼，就痛苦；同样遇到问题，别人解决不了，你能解决，那你就高人一等；别人都解决不了，只有你能解决，那你就可以算作英雄了 —— 这么说并不夸张，因为历史上所有的英雄，本质上来看其实都是解决问题的高手。 （一）有些问题是永远解决不了的（二）有些问题是不用解决的（三）有些问题可能会自动消失（四）有些问题是自己造成的（五）有些问题是其他人的问题（六）有些问题是所有人的问题（七）大多数问题需要特定的人解决 面对永存问题，尽力就好。 “魔鬼在细节之中”，换个朴素的说法：细节很重要。说实话，我并不反对这个建议，但我很少把它当回事儿 —— 更多情况下，我觉得“细节很重要”是用来吓唬那些没做成过事儿甚至压根就没做过事儿的人的。因为最重要的东西没做好，细节再好没用。看看素描初学者的作品就知道了，看着石膏雕塑在纸上把头像上的某一只眼睛画得精准是完全没用的……永远问自己，“什么是最重要的？” —— 先去做那些真正重要、最重要的事儿，先去解决那些真正重要、最重要的问题，至于细节么，那是要等到前面那些事儿做完之后再去做的事情……所以，有些问题不用解决，至少不用在最重要的问题被解决之前解决。 完美主义彻底的完美主义者都是脆弱的。 事实上也确实如此，彻头彻尾的完美主义者是不懂“永存问题”这个概念的，他们离这世界的真相太远，又不自知，于是脑子里追求完美，行动上永远做不到，真的是压力山大，最终都有自杀倾向，这是事实。 演讲 最重要的是什么？ 最重要的是我要有足够好的内容。在讲演的时候，什么是足够好的内容？ 我有没有向听众传递他们之前未知的信息？（已知 vs. 未知） 我有没有向听众传递他们之前未重视的信息？（次要 vs. 重要） 我有没有向听众传递理解足够简单应用足够容易的方法论？（简单 vs. 复杂） 有一点问题就坐立不安的人，本质上只是天真。一般来说，公司内部的问题，基本上都是由于发展不够快，或者发展放缓造成的，够快地发展，持续地发展，相当于免疫力，大多数问题只不过是感冒，甚至不需要治疗，它们并不是癌症晚期之类的不治之症。 英语学习很多人问我，零基础如何开始学英语…… 我很难回答，因为我知道， 大多数人根本不是零基础，而是负基础 —— 这是我不太敢告诉他们的事情。很多人岁数一大把了（二十一岁在我眼里就是三把岁数了……），母语的语文功底还是几近于零，还想学外语，这不是负基础嘛！因为，所有语言的基础元素都是相通的，尽管细节上有差异…… 绝大多数人的母语是完全不过关的，只不过处于“识字而已”的水平 文章逻辑复杂一点，就各种凌乱，读不懂； 文章篇幅稍微长一点，就根本没耐心看完； 自己从来写不出一篇完整的文章； 大多数人看别人写的文章只能不服气，却无法做到有理有据地反驳重点； 很多人连个产品说明书都读不懂； 连个租房合同都不会写，甚至不会读，最终要去打官司，然后还要吃亏； 别说读书学习了，就是读个小说看个电影消遣一下，也常常被带入阴沟而不自知…… 基础很重要！ 这么朴素、简单、有效的建议，绝大多数人这一生都没听进去过 —— 然后，最令人啼笑皆非的是，一生都要为此付出巨大代价却又从不自知。 比如，国内校外英语培训机构的所有收入都来自于那些“一辈子都没学会主动查字典、用语法书的人” —— 这是个可以生出若干个上市公司的庞大产业，我从来不觉得那是教育，我只觉得那是在欺负人…… 不过，被欺负的人们在被欺负这件事儿上倒是主动得很，甚至享受得很，这真是颇有些令人意外。 再比如，各种庞氏骗局，连绵不断，生生不息。为什么呢？很多人没有过恰当的基础理财教育，不懂得 a) 10% 以上的利息就已经开始伴随着巨大的风险，不懂得 b) 本金安全比收益更重要（重要很多倍！）…… 就是这么两个基础概念的缺失，造成了一片又一片的受害者，业内叫“一茬又一茬的韭菜”…… “不一样”的观念 时间就是不可管理的，管理时间的意愿和炼丹求长生没啥太大区别…… 与其控制情绪，不如继续求知，学识才决定人的品行和生活的品质…… 外语发音不好，甚至说不流利又怎样？我使用外语的最大用途是阅读…… 写作技巧都不重要，践行才是创作呢……我就这样把自己活成了行为艺术家…… 想要学什么，我就去教什么，反正我学得快，至少比大多数人的学习经验更多一些，学习时间更长一些…… 谁说不能同时做好几件事情？我跑步的时候还听音乐呢，我走路的时候还听电子书呢，我甚至在写文章的时候也同时看电影呢！DOS 就是理解不了 Unix 罢？ 法定假日是限制企业的，不是限制我个人的，谁说过年之外我就不能回家看望父母了？ 有时候效率并不重要，长期努力更重要，音乐认知上我有过脑受损，但三十年过去了，不也恢复了不少吗？ 为什么要坚持锻炼呢？答案是： 本金最重要。 反思自己年轻的时候，少不经事，不懂得这个道理，于是，浪费了很多时间精力和情绪在自己其实压根就无法解决的问题上，也把很多时间精力和情绪寄托在他人身上，以为他们可以帮我们解决问题， 甚至错误地把责任横加在他们头上 ，想想真是浪费，也真是不应该。 正确的方法论可能是这样： 一方面，专注于自己的进步，让自己成为能解决更多问题、更大问题的人—— 只要时间足够久，进步是一定的； 把自己能解决的问题，都给解决了，为了自己，也为了别人。 另一方面，在自己的能力范围内，尽量帮助那些可能解决很大问题的人。但必须牢记，解决那些问题，可能并不是此人的责任，也不一定是此人能有的运气。 所谓的“平和”只不过是认真思考的结果。 惊喜与创造惊喜的方法论 你必须相信你自己会有好运的什么时候开始笃信自己将来一定会有好运的呢？大学的时候认真研究概率论的时候。如果生活在一定程度上是随机的，而有些事件是好的，有些事件是坏的，那么无论我现在遇到过的坏事儿有多少，好事儿还是会出现的，大小不同而已，早晚而已。这是多简单的道理啊！乐观是一种需要时间、需要耐心才能生成的一种态度。 为什么倒霉事儿相对较多呢？两个主要的原因， 没能力和实力做出 主动的选择 没有足够完善的逻辑思考能力所谓“尽量不做可能倒霉的事情”，其实只不过是打磨自己的逻辑思考能力，使其完善，乃至于你不大可能去做未来可能产生恶果的事情。 笃信逻辑，精于推演，是 活在未来的关键。有些事情，有些选择，在做的那一瞬间，就注定了未来一定会倒霉，这样的事情不能去做。我做事情，该公开的都是公开的；此为其一，其二，我不做需要别人给我保密的事情，那样没劲。 不要给自己建造围墙。围墙的作用除了可能提供一些庇护之外，更大的作用是让别人走不进来、也让你走不出去。开放（Open）就是可以创造好运和惊喜的，无论在哪个领域。 比特币这个例子我说过好多次了，我在 Twitter 上 Follow 了 18,000+ 账户，为什么呢？因为我不觉得预先筛选信息对我有好处。而且从逻辑上看，我们明明要的是 信息 ，却通过 人 来过滤，这是效率相当低下的方式。 迄今为止，别人能看到的，在我身上发生的最大惊喜，就是比特币。 ……当然还有更大的惊喜，只不过我没必要告诉别人而已。我怎么知道比特币的啊？这并不完全是意外，一定程度上，这是我特有的方法论的结果。就是因为我 Follow 了那么多人，我才会有机会“随便扫了一眼，看到一个惊悚的新闻标题”： “这个虚拟币价格超过了一美元！”有些东西、有些知识，一旦知道了，就是不可逆的，你不可能从此装作不知道。于是我就开始去研究这个东西去了…… 可问题是，如果我像绝大多数人一样，给自己建个围墙，提前过滤了很多信息，只关注自己觉得重要的人物，那么我估计早晚也会知道比特币的 —— 许多年后呗。 学习，从来都是创造惊喜、创造好运的最优路径。每个真正习得过技能的人终究有一天会发出惊叹：真没想到在这里可以用上！ 学习 就是掌握一系列新的 概念 。那么为什么持续学习一定会产生好运和惊喜呢？理由也很简单， 只有概念多到一定程度的时候，它们之间才有机会产生“意外的连接” —— 即，所谓的融会贯通。学习就是反复打磨概念与方法论，等着注定的惊喜注定地发生。 只有节点多到一定程度，才可能有“意外的连接”出现。要想办法认识很多真正拥有高效率的操作系统的人。 交流，可能是坐下来喝茶，也可能是读对方的文字，更可能是长期观察。甄别出那些有属于自己的高效操作系统的人，甄别出那些愿意打磨自己的操作系统的人，遇到了，必须 马上连接。 一旦概率论确立，这世界上开始有一些人能够理解随机的概念，开始明白 这世上有些事儿是不讲因果的 。 你抛一个硬币，结果是正面，为什么呢？为什么不是反面呢？不是因为你抛了一个硬币，也不是因为你上一次抛硬币的结果是反面…… 没有原因。反过来，当你抛出一个硬币的时候，因为我们知道那是随机事件，所以我们也知道那结果不是正面就是反面，至于究竟是哪一面，概率是 1:1 —— 虽然我们不知道确切的结果，但我们确切地知道可能性。 学习的时候不要问有什么用，因为不一定在将来在什么时候在什么地方会用到。本质上来看，这也是一种放弃直接因果判断，利用一定的随机性创造惊喜的方法论。 在一些时候，在一定程度上，跨越因果思考与判断，在生活、工作、学习中添加一点随机性，就是创造惊喜的方法论。 一定要想办法把自己打造成一个多任务操作系统。不要做一个低级的单任务操作系统。DOS 是没办法理解 Unix 的。人不能因为自己笨，就觉得别人也笨；更不能要求别人有义务跟自己一样笨。不过，我们反过来倒是能够理解，笨蛋不知道自己笨，即便别人指出来也不肯相信自己笨的。 通过恰当的统筹，让自己多开几个进程，齐头并进地去做一些事情，永远是提高效率的基本手段。 多管齐下，齐头并进，也是创造惊喜的好方法，理由很简单，效率高了，成果就多了，成果这东西，跟之前提到的“连接”啊、“节点”啊一样，越多越好，这些成果本身也是节点，它们之间也会产生连接，最终一样产生聚变，至于能够获得什么，我们还不知道，但我们知道一定会有所获得。 创造惊喜的方法论逻辑很重要、概率学很重要、统筹学很重要 你必须相信你自己会有好运的 尽量不做可能倒霉的事情 保持开放 持续学习 创造更多的连接 保留适当的随机 多管齐下，齐头并进 成功 = 技能 + 运气 所谓“运气”，是完全不可控的，它可能是好的，也可能是坏的，也可能是“0” —— 即，什么影响都没发生。我们不知道它什么时候发生，不知道它是好是坏，也不知道它好坏的程度到底如何；我们只知道最坏的情况下，坏运气可能导致“灭顶之灾”。与之相对，技能却是可控的 —— 通过刻意练习（deliberate practice），绝大多数技能都可以获得极大的提高。在“技能-运气”的横轴上，尽量选择去做靠近左端的活动，就是那些更多依赖技能，更少依赖运气的活动。下棋、学习，都是完全不靠运气的 —— 只靠积累。于此同时，无论做什么，都需要技能，而技能只能靠积累。在技能没有达到一定程度的时候，别指望运气。因为坏运气在这种情况下其实格外可怕。 通过选择来回避坏运气。选择很重要。甚至可以不夸张地讲，人生就是选择。对于选择这件事，我的好朋友铁岭有个精彩的陈述：所谓的（创业）成功，无非是解答题高手作对了选择题。 可这世界上真的有很多人不相信自己有选择的！更准确地讲，他们骨子里完全不相信自由意志的存在。说实话，我完全没办法理解那些不相信自由意志存在的人有什么接着活下去的必要…… 我们可以通过两个层面做出更优的选择： 提高技能值 降低坏运气的绝对值 惊喜（Serendipity） 原本想象不到的好事儿“竟然”发生了……或者反过来说也行，原本想象不到的坏事儿“竟然”没有发生……甚至，原本想象不到的坏事儿即便真的发生了，也没有造成“毁灭性打击”…… 学习（磨练技能）永远是创造惊喜的最根本手段：当坏运气发生的时候，有能力抵御、有能力承受，那么坏事可以变成好事—— 因为那些没有干掉我们的事儿会使我们变得更强（“What doesn’t kill you makes you stronger” —— 有首歌的歌名就是这句话。）……若是没有能力抵御、没有能力承受，那么坏事就铁板钉钉，又因为“因此要提前出局”所以要蒙受的损失大到无法估量…… 所谓的学习，本质上是在提高自身的“免疫力”，让自己不被病毒打倒。这个类比告诉我们，有的时候，我们甚至有必要主动给自己下毒 —— 这就是打疫苗的原理。你看，类比真的影响思维。 切换模式：苍蝇与蜜蜂的启示 问题显然不在眼睛上。因为瓶底朝着窗户，蜜蜂便不停地在亮处寻找出口，却碰到蜜蜂怎么也弄不懂的玻璃，对阳光的敏感和执着使它们不肯到瓶口 —— 那个黑暗的出口去。是呀，黑暗与出口怎么能联系在一起。 但是苍蝇可不管什么光明与黑暗，它们四下乱飞乱闯，瓶子又这么小，碰上瓶口的机会太多了，一群头脑简单、貌似全无所追求的苍蝇就这样获得了自由。 “这件事说明，实验、坚持不懈、试错、冒险、即兴发挥、最佳途径、迂回前进、混乱、刻板和随机应变，所有这些都有助于应付变化。” 无论是谁，若是只有一根筋，总有一天会倒霉。独立思考这事儿，说难也难，因为绝大多数人都是“人家说什么就信什么”，别说独立了，连思考都不做；说简单就特别简单， 凡事儿多琢磨一会儿。一旦真开始想了（思考），就可能得到不一样的结论； 收获多起来之后，遇到重要的事儿，一般都舍不得不想 —— 知道不多想想就会吃亏的。 思考过一根筋的窘境之后，怎么可能再是一根筋的人了呢？知识的获得就是不可逆的。 刚刚冲进一个新领域的时候，我会把自己调整为“苍蝇模式” 。在我找到“门道”之前，我就是一只苍蝇，乱打乱撞实际上就是最佳的选择、最佳策略。 做销售，很快发现信任最重要；做教育很快发现榜样很重要；做留学咨询很快发现家长才是客户；做电商导流很快发现反向筛选客户很重要；做比特币很快发现买进来且拿住才最重要；做互联网创业早期项目投资很快发现行研最重要…… 找到门道之后怎么办？我会马上把自己调到另外一个模式“蜜蜂模式”。 经过如此这般的打磨，我的操作系统一定是升级了的 —— 起码我的是有两个模式的操作系统，不是吗？多任务、多模式的操作系统怎么可能与“一根筋”的操作系统相提并论呢？ 不仅要多模式，还要在很多重要的节点上多模式 调整焦点为什么能够随着大势成长的人永远是极少数呢？大多数人没有那样好的运气。 当一个大的趋势来临的时候，绝大多数人即便绞尽脑汁，也想不出那大势如何为己所用。很多人输就输在，对于新兴事物，看不见、看不起、看不懂、来不及……开始有足够数量的人看不起某种因新趋势的存在而产生的行为模式的时候，基本上总是那个趋势要发力的时间点。 不是问自己，这个大势如何才能为我所用？ 而是问自己，在这个大势中，我去做什么最划算？ 这两个问题的区别在于， 第一个问题的焦点是放在自己身上的； 第二个问题的焦点是放在大势本身上的。把焦点放在自己身上，而后开始思考，思考结果常常是，几乎所有的大势其实都与我没关系…… 把焦点放在大势自身上，而后开始思考，思考的结果常常是一样的： 必须跨界 —— 自己手里正在做的事情，常常与那大势完全没有关系，也并不适合与那大势共存。某个大势出现的时候，一定有一些特定的事情比其他的事情更适合“顺势而为”，万一那些特定的事情恰恰是自己正在做的，或者是最擅长做的，那真是天大的运气； 有办法、有能力让自己变得运气足够好的人 —— 源自于我们有不一样的操作系统： 我们不断升级概念和方法论 我们多任务运行 我们在不同的情况下切换不同的模式 我们还会在不同的时间点转换不同的焦点…… 我们就是那种勤于深入思考的人，更为关键的是，我们就是那种践行者。想到，就要琢磨清楚；搞明白到一定程度之后，就开始行动，在行动中继续思考，在行动中不断调整，在行动中获得更多的灵感，在行动中主动创造各种好运气…… 这就是所谓的“ 主动选择”了。 微信公众号 跳进来，自己动手开始写的目的有这么几个：我想知道这个生态里的每一个细节，不自己跳进来，只看别人做，一切分析在我看来还是“得来终觉浅”……我从来都知道“个人品牌”的重要性，所以，虽然在这事儿上起步晚（那是因为有一段时间我就是在休息），但终归我需要一个信息传播通道，既然微信公共平台已经成了大势，我就不应该任由它把我自己落下；我想验证一个猜想。在没有“早期初始红利”的情况下，什么样的 IP 依然可以迅速获得流量？我的猜想是：那些独特的内容 —— 那些打着作者独特印迹的内容，那些读者一看就知道是谁写的内容，那些天然被搬运工拿走也带着作者独特印迹的内容；而在这一点上，我运气足够好，因为我恰恰懂得如何生产这种内容……我认为如果我能短期之内集聚足够的流量的话，那我一定有什么办法，或者遇到什么机会，搞出一个完全不一样的东西。 果然，在这个过程中，很多之前尚处于模糊状态的念头开始清晰起来，很多之前在脑子里尚未关联起来的节点开始相互碰撞，很多昨天的想法在今天已经开始发酵，很多原本根本不可能认识的人（尤其是那些恰当的人）感觉在突然之间就从各个方向“冒了出来”…… “ IP 多维化 ”。只有一个维度的 IP，没有足够强大的商业潜力，最终只能沦为“发发广告收点钱”的奴隶 —— 这几乎是最没前途的商业模式。好的 IP 从来都是可以锻造出多个维度的，这不是什么新鲜事儿。相比火爆的《盗梦空间》，《星球大战》的 IP 更有潜力，因为后者早已是多维化的 IP，单单玩偶市场就大得不得了，且经久不衰，过去、现在，与将来；前者并非不可能多维，但相对后者明显在多维上有很大的劣势。 转换焦点，是整个征程的起点。 事实上，这就是我在多年后不可能再是一个托福培训教师的根本原因。每当我意识到某个大势存在，并且对之深入思考之后，得到的结论总是一样的： 我必须离开，我必须存在。其实这里套用的是崔健的歌词： 我想要离开，我想要存在，我想要死去之后从头再来…… 真正的大势，很少频繁出现，尤其对个体来说，能够感知的大势更少。 选择 活在未来而不是当下， 研究新生事物的时候更应该关注优点而不是缺点 平日里人们评价“某一个人格局不一样”的时候，本质上来看，其实就是指那个人关注的 焦点 不一样。我们更应该 对自己的未来自信 ，前提只不过是过去与现在以及未来，我们都在挣扎着进步。我们在自信这件事儿上，关注的焦点更多在于自己的未来 ，而不是，或者不仅仅是自己的过去或者现在。 我们不仅应该优先关注这个世界的未来，也要 活在未来而不是当下。为什么我们这么自信，自信自己可以活在未来呢？理由简单而又清晰，我们是掌握了方法论的人，一旦我们通过研究通过思考，发现某个属于未来的大势出现的时候，我们早已调整过自己的关注焦点： 不是问自己，这个大势如何才能为我所用？而是问自己，在这个大势中，我去做什么最划算？人们的平均寿命正在加长 —— 我想，在更长的一生中（好几辈子里），每个人其实都有机会，总能逮到几个大的罢？逮不到，别怪别人。 不能容错的系统肯定是脆弱的 任何一个在现实世界里运转的系统所面对的，必然是一个不完美的、不理想的、各种意外频繁发生的现实世界 。有一点错，就直接停止运转，那系统基本上就是个废物。我们最好给自己的操作系统设置一定的容错机制。绝大多数人在没有恰当训练之前，不懂得容错，就基本上跟废物差不多。看看那些易怒的人罢。有一点差池，他们就暴跳如雷，大脑充血，系统完全瘫痪…… 这不是废物是什么？其实他们比废物还可怕。暴怒的人不大像一个失灵了的冰箱，坏了也就坏了，暴怒的人更像失控的火车，要冲出轨道，毁掉停下来之前撞到的一切…… 没有冗余度设计的系统，通常不够健壮，不够可靠。这地球不是少了你就不运转了！有容错能力的系统更为强壮，有冗余度设计的系统运转更为持久……一切更为健壮的都要耗费更多的成本。学习范围广了，思考更为深入了。容错是自己的事儿。 自学自己的灵魂必须自己塑造你自己就是自己的灵魂的工程师。教，才是最好的学习方法。自学很简单，其实就是不断习得、积累、研究、打磨、升级那些概念和方法论。进一步来看，自学能力是靠积累增强的。开始自学的人，越学越快。自学的人好比给自己的脑子开了个黑洞，刚开始看不出来，因为那黑洞的质量太小，乃至于跟没有一样；但随着时间的推移，那黑洞的质量逐步积累，渐渐地，另外一个现象终究会产生 —— 很多知识就好像是“不由自主”地飞进他们的脑子里。 如何解释这个现象呢？善于自学的人，最终会形成一个重要的能力：融会贯通。 善于学习的人会越来越善于学习，学习能力会越来越强，因为在一个知识点上的感悟，不知道什么时候会在另外一个知识点上发挥效用。知识点（概念与方法论）就好像是有生命的东西一样，它们自己会发酵，它们自己会相互连接，它们自己会相互碰撞，进而产生出更多有生命的东西。 学习几乎是唯一一个可以必然产生惊喜（意外的好运，Serendipity）的日常活动。并且，那些伴随着惊喜的幸福感（多巴胺分泌）就是一直在持续增长。 自学这事儿， 方法并不首要，首要的是态度。 不为自己做的事儿，做久是不大可能的 ，于是，自然而然产生讨厌，产生抗拒，自然最终能放弃就马上放弃。 所以最终，离开学校之后，到了工作岗位上，绝大多数人都不是 给自己打工 ，而是 给别人打工 …… 这只不过是在延续他们长期的生活方式而已。 遇到一个普遍的现象，而后对其做出正确的分析，得到正确的结论，是一个人有良好的思维能力和习惯的重要表现和进一步成长的前提。有一类人做什么事儿都是为了自己而做，即便在某件事儿上做得并不好；另一类人做什么事儿都是为了别人而做，即便在某件事儿上做的还不错； 为自己而努力的人逐步变成所谓的精英，为别人对付事儿的人逐步变成所谓的庸众。是啊，为自己做事儿，就肯定更努力啊！为别人做事儿就自然而然地应付了事么！如果你想创业找个靠谱合伙人，那么请注意两个根基： 远离那些“表现型”选手 ，无论多费劲也要去找到那些“进取型”选手。明明是为了别人而活，却真切地感觉是“为了自己的利益”；这是最底层的价值观，位于“操作系统”的核心位置，很难与不同的操作系统相互兼容。尝试着改造他们是全无意义的，谁都做不到—— 除非有一天他们自己意识到了，自己改，可说实话这希望也太渺茫了。 远离那些应付了事的人 ，无论多费劲也要去找到那些“把事情当作自己的事儿来做”的人。明明是为了自己而活，却最终不仅显得也确实是“大公无私”。 “表现型”选手做事常常不是为了自己的进步 ，而是为了自己当下表现得多好，也就是说，为了获得更多的当时的认可。“进取型”选手做事是为了自己的进步 ，做事的收获，最大的部分不是来自外部的奖励或者赞赏，最大的部分是自己的进步；即便在做得不足够好的时候，甚至外部只有忽视和鄙视的时候，收获依然清晰：无论如何都有一些哪怕看不着但确实体会得到的进步啊！ 所谓的聪明，虽然可能也受先天条件限制，但聪明确实是可积累、可锻炼的。 霍金（Hawkings） Smart is the new sexy.聪明是新兴的性感。 法国生物学家拉马克（Jean-Baptiste Lamarck） 拉馬克认为 用进废退 这种后天获得的性状是可以遗传的，因此生物可把后天锻炼的成果遗传给下一代。 最新的研究表明，拉马克可能是对的。有一项研究表明， 人们的生活状态发生变化时，基因也会发生变化。 智商却是可以习得的、可以积累的，又因为这种通过锻炼习得的特性（Acquired Characteristics）竟然是可以遗传的……哇！这是多性感的一件事儿哦！并且，这世界有很多人是 Sapiosexual 的，只要够聪明，不怕无配偶啊！于是， 多读书罢，让自己更聪明一点，也为了下一代 。 如何真正消化一本书？ 书大抵上分为两种：虚构类（Fiction），非虚构类（Non-Fiction）。阅读，是为了理解，而理解这事儿，慢，即是快；快，便是无。 标题党的文章直接不看了——说实话，即便错过什么了，也没什么可惜。 这个小技巧真的不知道帮我节约了多少时间，提高了多少生活质量。 信息这东西，必须系统才有价值。碎片化的信息也许有用，但就算完全忽略，也不至于致命。舍了就舍了，没啥。这种勇气其实不少人都有，巴菲特就是其中之一。害怕错过什么，是一种情绪，来自于空虚的情绪：因为什么都没有，所以就渴望有一点什么，所以就特别害怕错过任何机会。 充实的人，是不怕错过什么的，因为已经充实，错过点什么，真的无所谓，机会有的是，错过一大把又如何，反正因为充实而能够相信自己确实有实力终归抓到至少一个适合自己的机会。 买好书，读好书，读懂好书，然后用知识改变自己的生活。 拿来一本书，就好像要打一场仗，打仗之前最好先考察一下地形吧？ 同样的道理，拿来一本书，不应该是抓起来就从第一个字开始读起，一直读到最后……应该先看看目录，再看看附录，仔细读读前言， 也不妨在网上先扫扫书评……要先大致对这本书有个了解，然后再开始行动比较好。 在读的过程中，不断整理这些概念与方法论之间的关系，其实是“消化”的必要过程。 在阅读的过程中，要不断向后总结，向前预期 —— 这是最基本的理解技巧。 绝大多数人除了输入之外什么都没有，连处理都没有。最终只有少数人的阅读理解过程是不断循环地“输入、处理、输出”的过程，尽管这里的“输出”某种意义上不过是“伪输出”…… 理解过的东西越多，理解新的东西就越快。说穿了，理解能力差，无非就是见识少，仅此而已。 重要的知识，从来都是通过反复学习才能获得的。一下就能学会得东西，通常上价值不大。 一定要用起来。 不用，学它干嘛？这与我读书的原则也是相通的：不用认真读的书，读它干嘛？这与我对生活的态度也是一样的，既然活着，就要活好，活得精彩。 暂时用不起来怎么办？教！我总是重复这句话：教是最好的学习方法。 分享，不仅需要能力支撑，也是培养能力的最重要手段。知识分享，没有成本，只有收益 —— 双方都有的收益。 分享的技巧很简单： 真诚，只分享自己确实觉得好的东西； 也是真诚，绝对不能居高临下地装蛋； 还是真诚，对方完全有可能不理解你。 这个概念、这个方法论、这个道理、这个知识，还可以用在什么地方？聪明的操作系统总是有更多的想法、更多的方案、更多的可能性。 万一想到了可以“出其不意”地使用的场景，那就赚大了，因为同样的东西到了你的手里却发挥了不一样的作用，你当然与众不同，也只能与众不同。 寻找那些终生学习的人，把他们当作朋友，把他们当作榜样。我就有个很长期的榜样：Bruce Eckel。我根本不认识他，也没有过任何传统意义上的交往，连 email 往来都没有。他是 Thinking In C++ 的作者。十多年前，他在网上发布 Thinking In C++ 第一版的写作计划，然后以极快的速度更新完成…… 毫无疑问，见识到有人这样，就成了后来我写书的时候“雷厉风行”的根本原因和动力。再反过来说，人家写书都可以这样，我们读书怎么可以拖拖拉拉呢？ 人群中的阅读量分布，大抵上应该是这样一个曲线： 若是把年平均阅读，换成“一生平均阅读”，那条曲线可能变成这个样子，嗯，你之前见过的那个曲线， 人与人之间差的岂止 10 倍，100 倍都很正常 ： 在哪儿都一样，真正尊重知识的人就是少数，古今中外都一样。每个月至少读一本好书，是那些关注自我成长的人的最低要求。学门外语（尤其是英语），根本没那么难，甚至很容易，能不能学，能不能学会，只不过是学习意识问题。 网络时代有很多方法可以去了解牛人们在做什么，牛人的共同特征是喜欢分享。他们正在看的东西，是他们筛选过后的，常常有很大参考价值。注意，是“参考价值”，不一定是“价值”。(这里有个很好的例子：Some Books for Software-oriented Humans，文章作者是 Pat Maddox, Rspec 核心开发团队 2 号人物。 什么是更好的知识？ 有价值的信息才可以算作知识。知识有两种： 无繁殖能力的知识 有繁殖能力的知识显然，有繁殖能力的知识，比无繁殖能力的知识更有价值；繁殖能力强的知识，比繁殖能力差的知识更有价值。 什么叫有繁殖能力的知识呢？最好靠举个例子说明罢。 科学方法论，就是一种有繁殖能力的知识，也是迄今为止我习得的最有繁殖能力的知识。再比如说，概率、统计，除了可以帮助我们更准确地理解这个世界之外，甚至可以直接用来赚钱…… 一般来说，有繁殖能力的知识： 可以积累，因为它有积累效应 必须应用，因为它有指导意义 值得传播，因为它可造福大众 把大量用来“牢记”的时间，直接输入到“践行”之中，好像更为牢靠，更为划算。保持好奇心很重要，但若是竟然养成了猎奇心理，那就算是掉进坑了。 如何研究新生事物？绝大多数人都是一根筋地生活的。对他们来说，最好什么都有唯一、正确、标准的答案、方式、手段；一旦答案是“ 看情况 ”，他们就一脸茫然，瞬间进入死机状态。 如何面对、如何研究新生事物？就是一个很好的例子和测试。绝大多数人其实使用一贯的模式（当然那是他们唯一的模式）去面对、研究新生事物。可事实上， 面对新生事物的时候，一定要切换模式，否则就事实上完全无法面对、彻底无法研究。 任何新生事物都是不完美的。 实际上，无论是过去、还是现在，抑或是将来，在任何时间点上出现的新生事物都不是完美的，它之所以出现，核心上来看，只是因为它相比之前的相对物更好而已，一旦它成功，它就不再是新生事物，而是现有世界的一部分，等待着被下一个新生事物所颠覆 —— 几年后、或者几十年后，甚至成千上百年之后。 最终，我们接纳任何新生事物，都不是因为它完美，而是因为它相对更好而已。 在面对、或者研究新生事物的时候，我们应该关注的是它的优点，而不是它的缺点。 也就是说，我们应该让自己的操作系统切换一下模式，从“优先关注缺点模式”，转换到“优先关注优点模式”。 类比是用来帮助我们理解新生事物的；类比不应该是我们用来定义新生事物的。 可是，一旦进入投资领域，这样的操作系统就完全无法运转了 ，因为投资行为的核心本质有这么两个： 投资必须自负盈亏，所以只能、且必须靠独立思考；只有投资未来才有真正的胜算，投资的收益才可能大到有意义的地步。 学习和投资的机会几乎无限多 —— 只有在这样的时代里，知识变现才是可能的，且知识变现的金额才可能是巨大的。仅仅是我的上一代 —— 我父亲的那个年代里 —— 就没有这样的时代恩惠。 学习就是用自己免费的时间与精力再加上少量的金钱去投资自己的未来。 人分为两种，主动升级自己操作系统的，和不升级自己操作系统的；主动升级自己操作系统的人又分为两种，多模式的和单模式的…… 除了在跨界和研究新生事物的时候我们需要调整模式之外，我们还需要在更多的地方调整模式…… 我们永远不要在容易和艰难之间选择，要在错误与正确之间选择 。要做正确的事情，哪怕很艰难也要做；错误的事情，越容易越不应该做。这很清楚，不是吗？ 超越绝大多数人的窍门其实很简单，就是想办法活在未来。生活幸福美满的窍门就在于比别人早半步，早太多了不安全，晚半步就始终遗憾，相对于别人不早不晚，其实就是一样，那就没意思。 如何活在未来呢？这听起来好像是不大可能的事情。但实际上却很简单，就两件事儿： 笃信逻辑。用逻辑去判断明天会发生什么。 你的孩子受教育程度越高，将来的收入就会越高。在我想明白并开始笃信的那一刻，我已经某种程度上“活在未来”了，只不过，我的未来需要时间证明，而我需要要用行动与耐心等待早已经决定的结果最终落实。 做事之前常常要在脑子里预演至少一次做好你的功课。 （Do your homework.）咱是谁啊？！ 有意识地提高自我要求，是切实提高自己水准的前提 —— 我的确相信这事儿。对自己抬高一点点要求，然后做足功课，更好一点的结果就是自然而然的了。 按照未来的你所需要的标准去学习、去工作，将会构建一个完全不同的生活。提前成为未来的你。多花点时间想想自己未来的样子，多花点时间预演一下，多抬高一点点的标准，多做足一点点的功课，就这样，差异应该就一点点地积累形成了。 关于圣人与榜样 这世界根本就没有强者，其实大家都是弱者 —— 只不过弱的程度不一样而已，或者弱的方面不同而已。所谓的原罪，很可能只不过是没有学会学习的结果…… 傲慢是因为认为别人不可能进步，以为自己的优势永存；嫉妒是因为认为自己不可能进步，以为他人的优势永存；懒惰是因为相信自己不可能进步，所以干脆放弃，一了百了；暴怒是因为不知道自己可以进步，所以弱者永远患得患失、永远输不起、吃不起亏；所以强者一旦发现自己的地位可能被动摇就自然而然地勃然大怒；贪婪是因为不知道自己的进步效果不是线性的，而是一个需要长期努力才可能出现的复利曲线，所以才生成的不切实际的欲望…… 所有人都有进步的可能，只不过是有没有放弃而已，若不放弃，那最多是进步程度大小不同而已。原来所谓的“ 宽容 ”、所谓的“ 淡定 ”，竟然如此容易获得 —— 惊喜，绝对是惊喜。嗯，进步（升级）是获得、制造 惊喜 的最有效手段。 自欺欺人是装给自己看；欺世盗名是装给别人看，反正都是装蛋。装蛋有无数种变体，可装蛋的本质，其实都是一样的：对自己的未来不自信。 不要以为你干过的蠢事别人不知道，只是人家没空、或者懒得挖出来而已。唐骏就是个很明显的例子。其实他何必呢？人又不笨，若是当初不投机取巧，不欺世盗名，现在也不会差到哪里去……这个时代的恩惠在于，普通人不必一定大富大贵，老老实实学习、老老实实成长、老老实实工作，做个中产阶级并不是很难 —— 早已不再是“必须你死才能我活”的时代了，真没什么必要欺世盗名的。 别装，千万别装。偶尔装装，不是不可以，但千万别装圣人 —— 绝对不可能的事情就不要做了，这跟不要尝试发明永动机是一个道理，多明显啊！ 其实真的没必要装。 其实大家都是可怜人，最初的时候大家都不怎么样 —— 不一样的只是某些天生条件而已，可那些基本上真的都是 “脑”外之物 —— 比如，遗传的长相，或者继承的财富。 智商这东西，其实不遗传的，大家都是从零开始。 也完全没必要顾镜自怜。 虽然不可否认的是，每个人的成长环境不同，但这世界正在发生变化。一个很重要但常常并不被重视的变化就是人类平均寿命的增加 —— 在今天这个社会，三十岁的时候醒悟过来，和一百年前的人十五岁的时候醒悟过来没什么太大的区别，时间段的增长，明显增加了可以获得并体验 复利效果的概率…… 这就是时代的恩惠。 花几十块钱（人民币或美元）买回来的一本书，哪怕是有其中一点点的内容（有时哪怕是一句话而已）给我带来惊喜，已经很划算了！ 这跟什么很像呢？这样的方法论可以用到其他什么地方呢？—— 习惯于这种提问，是让自己学会 融会贯通 的最直接手段…… 这样的方法论可以用在“向他人学习”的行为上。 无论学什么，都可以同时向多个人学习（就好像可以多买几本相同领域的书一并阅读一样）；只要满足一定条件的人，都可以成为学习对象（就好像挑书那样，设定一些基本条件）；总是可以在这个人身上学到这点，在那个人身上学到另外一点；甚至可以从烂人身上反向学习如何才能避免变成那种烂人？曾经，我也好像需要榜样的激励，后来放弃了。如果把榜样比作好书，理由就清晰了： 好书永远存在；经典书籍永远不止一本；经典书籍也有可能被颠覆的可能；新的好书永远源源不断；众多好书都各有千秋……同样的道理， 榜样永远存在；值得当作榜样的人其实有很多；曾经的榜样，很可能被颠覆，实际上经常被颠覆；新的榜样永远远远不断；即便是普通人也常常各有千秋…… “被装得最好的那个人蒙蔽”，是寻求单一榜样的最可怕后果。完美无缺的榜样，只存在于信息流动不畅通的时代里，不是吗？ 把绝大多数人都当做正常人处理，其实挺解脱的；把别人以为的榜样、偶像也当作正常人处理，自己就变得更正常了。与此同时的 惊喜是，学习对象更多了、学习范围更广了，真是令人大喜过望。 做个正常人，和大家一起做正常人，挺好的。 其实大家都是正常人。 不能改变的最根本原因在于不愿意改变。知道自己的缺点，也知道自己改不掉，其实并不是最坏的情况，最坏的情况是，自己确实有缺点，自己却完全不知道，甚至以为自己其实是完美的 —— 这才是真正不可容忍的缺陷。想改，却最终失败，大抵上都是“误以为改变是瞬间的事情”造成的。 改变常常是个过程，且是个很长的过程，不是瞬间能够完成的。能够瞬间完成的改变大多没有什么意义。比如，改变一下瞬间的站姿（其实也是个过程，虽然很短）很容易，但意义也不是很大，彻底改变日常的错误站姿，却需要矫正很长时间，肯定很有意义；但，就因为这是个长期的过程，这个改变的难度就无限提高了。 这世界是动态的，人们却总是不由自主地用静态的方式去思考、理解这个世界。 下个决心，是瞬间的事情，瞬间的决定，行动才是填补后面非瞬间的整个过程的实际内容。若是真想明白了这个道理，就可以直接把 “下决心的这个瞬间决定” 直接跳过 —— 它没必要存在；直接开始行动就好，这才是关键。 解锁这个关键之后，一切都显得明显了： 改变是个过程。改变最初的时候很难显现。改变需要足够的时间，所以也需要足够的耐心。改变结果出现的时候，已经耗费了很长时间、很多精力、很多耐心。看到自己的改变，会给自己更多的自信；改变是过程，获得、积累自信也是过程。看到别人已经改变的时候，不会盲目地羡慕，因为真正改变过自己的你，知道那意味着什么……最为关键的是，因为自己清楚变化是个过程，知道这个过程在最初的时候不明显，甚至完全看不到，所以，你就不会误以为身边的人都没什么变化…… 也不会因为（许多年后）突然有一天看到朋友的明显变化而感到惊诧甚至懊恼…… 刚开始用力过猛，就基本上注定会失败。绝大多数人成为父母之后，在孩子 0 ~ 3 岁的时候投入过多，耗费了过多的资源，到了孩子 15 ~ 18 岁的时候早已经耗尽资源，甚至，孩子早就成了 “事实上的负担”…… 用力过猛还有另外一个害处：动作变形…… 所以，很多父母把孩子当作自己的骄傲；用力再猛一点，就会把孩子当作自己的炫耀 —— 这已经开始令人讨厌了；用力再猛一点，就会把孩子当作自己当初不曾实现的愿望 —— 这已经开始变得可怜了…… 依照我的经历，我觉得健身是最容易的改变之一，因为它的外部限制因素很少，也几乎完全不依赖运气。但很多人在这种最简单的改变上，还是失败了。怎么失败的呢？就是最初的时候 “用力过猛” 造成的…… 四处告诉他人 “自己就要变了！”买很多配套服装、器材工具……早期过份勤奋，甚至不给自己喘息机会…… 因为早期经济投入太多，后期会出现经济危机；因为早期精力投入太多，后期会出现精力不足…… 因为早期过份勤奋，所以很多该做的事儿都被挤掉了，所以这些该做没做的事情最终会集中起来一起报复你，不信走着瞧！ 千万别用力过猛。避免这个误区的核心在于，心平气和地接受自己最初的弱小。既然改变是个过程，那么就可以把“改变”理解成一股势力，最初相当弱小的势力，它需要时间，需要投入，需要持续投入才能逐步壮大起来。它就跟花儿一样，上来就浇了太多的水，会被涝死的！ 人们普遍认为，在教育行业里，是老师在塑造学生。这好像很自然，但更多的时候，曾经长期从事教师职业的我，却更多的时候看到一个反过来的现象： 很多的时候，其实是那些学生在塑造老师。人是很容易被“ 反向塑造 ”的。你跟什么样的人打交道，哪怕你“高高在上”，你还是会反过来被他们塑造。再比如，同样是做销售，卖奢侈品的、卖高档商品的、卖中档商品的、买低档商品的，各自都会被塑造成不同的样子，不信你就观察一下。 千万不要做免费的、公益的事情。你还没到那时候。 我写书免费公开在网上，是因为我确实不需要指望它赚钱，更重要的是，我 自信到不需要用市场衡量我自己。 如果你做一件事情，是公益的，是免费的，你得到的只能是赞扬——哪怕你做得并不好。这是关键，你可能做得并不好，但由于你是免费的、公益的，所以人家只能对你客气 —— 这其实是不真实的反应。 反过来，你收哪怕一分钱试试？只要你出了问题就会有人骂你，甚至不出问题的时候都有人骂你。 不会回避商业，该收钱就收钱，不能免费、不能公益——这是为了得到真实的反馈。 如果在你做得并不好的时候，依然得到赞扬，你最终只能被麻痹。而你不可能一辈子回避商业的，一旦开始玩真的，你就傻了，因为真实的世界（商业世界）全然不是你过往经历的样子。你被麻痹得越久，你越难以从瘫痪状态恢复过来。 在你做的其实很好的时候，依然被骂，这其实是好事，会让你心理上更成熟，承受能力更强。 千万要小心自己被反向塑造成你原本不应该变成的样子。 近朱者赤，近墨者黑，这不是空话，这也不应该只被肤浅地理解。 认真筛选自己的朋友，很必要 —— 因为他们终究会成为塑造你的一股力量；认真筛选自己面对的所有人，同样必要 —— 因为他们的力量更大，人多势众，生生不息，连绵不绝，所以更要小心，需要更多挣扎。若有可能，要认真选择自己所身处的环境 —— 因为， 地理位置很重要，远比大多数人想象得更为重要。 出淤泥而不染，濯清涟而不妖，那是莲花，那不是人；而人想要摆脱 反向塑造 ，不仅不可能天然做到，而且需要很多努力、很多挣扎。 人要真诚热爱自己 —— 然而，很多人其实没有这样的勇气。 小时候练脑子，下棋绝对是好工具。 倒是看别人下棋很有意思 —— 这倒成了我从来戒不掉的爱好。 观棋不语真君子。落子不悔真君子。真君子罕见。 输了，就得认。悔棋的人，就是那种遇到麻烦不肯买单的人 —— 之前的每一步都是自己选的啊！ 一点都不夸张，任何人大概都有悔棋的冲动（准确地讲，跟悔棋没关系，就是看到失败那一刹那的恐慌和懊恼），可一旦某人提出要悔棋，那么有一个判断就可以确定了：竖子不足与谋。因为能说出来悔棋，已经说明了很多细节： 技不如人且不自知的人很可怕；不尊重规则的人无法合作；爱面子胜过一切的人不可能有什么有意义的进步 如何才能避免制造麻烦？最终的败局，其实来自于很多步之前的某一步错了 —— 从那一步开始，败局已定。后面的只不过都是其实毫无意义的挣扎而已。 于是，再往前推，就是“如何不走出那步败棋？” 而不是“我输了，悔棋行不行？” …… 观棋不语真的是很有意思的事情，你总是可以看到很多人厚下脸皮悔棋，可是他们其实不知道自己真正的败棋是哪一步，于是，最终还是输掉，花了半天的力气，只是让自己输得更彻底，显得更傻屄…… 所以说， 不制造麻烦的人不用解决麻烦。 “那我老婆不讲理怎么办呀？” 其实正确答案挺残酷的： 谁让你当初不认为“能讲道理”是择偶的最重要因素来着呢？ 什么门当户对啊，什么高矮胖瘦啊，什么学历血型啊，都扯淡而已，只有能讲道理这个要求不可或缺。这一步走错了，败局早已经确定。这事儿凄惨在，当初一个人不在意对方是不是能讲道理的人，就说明他自己并不是在意讲道理的人，所以，等有一天他自己觉得麻烦了的时候，他更可能没意识到的是他自己本身就是个麻烦…… 更甚的是，这样的人通常就是那种只知道悔棋，不知道反思，不知道改进的人 —— 更是无解。 人生不可能没有任何麻烦。于是，当遇到麻烦的时候，方法论应该很坚定： 对已经发生的麻烦，认了！ 检查一下根源究竟在哪里，自己的问题究竟在哪里？ 为了将来不再出现同样的麻烦，自己需要改正、改进的是什么？ 进而，如何才能 “未卜先知” 呢？方法论是： 多观察、多研究、多思考别人的失败与麻烦。《黑天鹅》的作者，纳西姆·尼古拉斯·塔勒布有个类比可以借用： 一杯水，放在冰箱里，会冻成冰，那个杯子的形状（水冻成冰之前的形状）可以推测出水冻成冰之后的形状；可反过来，如果一块儿冰放在桌子上，一会儿化成了水，我们看着那水的形状，无论如何都倒推不出化成水之前的冰究竟是怎样的形状……纳西姆·尼古拉斯·塔勒布说的是，研究方向不同，会造成研究难度不同；我的意思是，研究焦点不同，也会造成研究难度不同。研究他人的失败，就好像是第一种情况；研究他人的成功就好像是第二种情况。 我一向认为研究别人的成功很难，因为太多因素其实是隐蔽的；研究别人的失败相对容易，因为有更多更公开的因素可用来研究…… 更为关键的是，研究他人的失败，比研究他人的成功更有指导意义。 看到别人失败了，看到别人遇到麻烦了，就要琢磨自己如何才能避免那样的失败那样的麻烦 —— 其实这是人们每天都在做的事情啊！某次北京下大雨之后有人在车里生生被憋死，于是很多人都反应过来，四处求问，而后才知道原来虽然玻璃无法敲碎，但可以从后备箱逃生……而后才知道有些车竟然不可能这样！ 当一个人从逆境中走出来之后，回头再看那逆境，暗流涌动的背后却可能是个机会，一个塑造传奇的机会。历史总是这样，它就像一条河，时不时地莫名其妙就产生了一处漩涡，大多数人被卷入漩涡，葬身河底，可总有一些人，“配合”着那暗流，走出一条生路，就成了传奇。 特朗博的策略，其实并不是他独有的，细看历史上所有从逆境中走出来的人，大抵上都差不多： 他们就是很有才华；才华这东西，一点点不够用，必须很多很多；他们因为有才华而更为勤奋，更不愿、不敢、不甘浪费一点点生命；他们热爱家庭，那是生活的希望；他们善待朋友，那是他们生存于世的关联与证据；他们专注于做能做的事情，把最重要的事情做到最好；他们与之斗争的，不是哪个人、或者哪群人，而是那个把所有人都变成受害者的历史漩涡；他们最终从逆境里走了出来……当这样的人走出来的那一瞬间，过往的对错其实都不重要了，重要的只有一件事儿：他们走出来了。 《把时间当作朋友》 一切都靠积累。 《新生 —— 七年就是一辈子》 我们必须主动升级自己的操作系统。我们的操作系统由概念和方法论构成。我们要把自己进化为多任务、多模式的操作系统。不断进化的操作系统要与、也只能与其他不断进化的操作系统沟通。沟通的目的是分享，分享最终会形成惊喜…… “急智”其实并不存在，所有的“急智”，其实都是过往积累的结果与表现，而非“信手拈来”、“急中生智”。闲聊，即便常常确实是“生产途径”，但它也绝对是“生产途径”之一而已。更多的生产，或者说是绝大多数的生产，其实发生在闲聊之前的研究、探索与思考。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"把时间当作朋友","date":"2017-01-14T10:18:06.000Z","path":"2017/01/14/MyShare/take-time-as-friend/","text":"李笑来 把时间当作朋友 对年轻人来说，成长比成功更重要，而且，这才是人人都可以做到的事情，才是人人都值得追求的事情。而成长其实只有一条路——积累。 本书主张时间不可管理、一切都靠积累。主张一个人必须在开启心智、提高思考能力之后，才能够用正确的方法做正确的事情。也只有这样，时间才是朋友，否则，它就是敌人。人的理性建立在接受现实的基础上，不能接受现实，一切成长都是虚妄。只有坚强的人才能接受现实，只有接受现实，才有可能开始运用心智作出理性的决定，进而才有可能做时间的朋友。有用的道理往往都是简单的，甚至简单到令大多数人不由自主地忽视的地步。这本书所传递的信息，原本只不过属于常识，可由于种种原因，并没有被真正普及、理解，实在可惜。 作者微信公共帐号：学习学习再学习（xiaolai-xuexi）","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"人人都能用英语","date":"2017-01-13T10:19:06.000Z","path":"2017/01/13/MyShare/english-is-a-friend-for-everybody/","text":"李笑来 人人都能用英语 请李老师用140字概括一下怎样才能学好英语？我回复说：其实一个字就够了：“用”。这本书里的文字，全部的意义，只有两个字：“启发”。 作者真诚地希望读者在读过这些文字之后，（起码）在英语使用方面有所启发。这本书也是《把时间当做朋友》的具体延续。《把时间当做朋友》的主旨很简单：时间不会听从我们的管理，我们最多只能与时间做朋友；与时间做朋友的方法只不过是“用正确的方式做正确的事情”。而这本书，只不过是 把“正确的事情”聚焦在“用英语”上而已，而后再看看可能的“正确的方式”究竟是什么。 作者微信公共帐号：学习学习再学习（xiaolai-xuexi）","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"人人都是工程师","date":"2017-01-12T11:02:06.000Z","path":"2017/01/12/MyShare/everybody-can-be-engineer/","text":"李笑来《人人都是工程师》前言 在中国，对绝大多数人来说，English + Computer Skills = Freedom 程序设计也许是目前地球上最容易变现、最被高估、可事实上却实际上并不难以获得的技能。程序设计的学习难度被有意无意地过分高估了。 人们向来有把学不会的技能神秘化的倾向，也许是因为只有这样心里才舒服，觉得自己学不会正常一点。但，程序设计这个领域，实在是被过份高估了（其程度比第二语言习得领域还要高出许多许多），乃至于很多人只是因为被误导了才望而却步，根本不是做不了做不好的原因。这个领域里的每一项技能，都会让习得者有这样的慨叹，“这样简单的东西竟然这么有用！” 或者 “连这么简单的东西我都没学会的话，实在是太可惜了！” 在计算机这个领域的顶尖范围里，集聚着人类的精英，他们设计了一个又一个的方法论去优化自己的工作环境，优化自己的工作流程，优化自己的产品，没完没了地改善，没完没了地更迭…… 也就是说，在计算机这个领域里，有大量的概念与方法论都是走在最前沿的。学习程序设计，并不是肤浅地学一门编程语言，设计一些函数，更重要、更本质的是学习计算机科学家们用来改变世界的思考方式、行为模式。 这真是个神奇的时代。跟过去不一样了，现在很可能已经是“一门语言打天下”的时代了，学一门 javascript，就有可能什么都做了…… 这在哪怕仅仅是三五年前都是不可能的事情。不过，我们涉及的话题可能很多很多 —— 总而言之，前面有一条路通往“全栈工程师”的方向…… HTML, CSS, JAVASCRIPTPUG, LESS, COFFEESCRIPTMONGODB, RETHINKDBNODEJS, EXPRESSJSREACT, VUE, ANGULARRELUXELECTRONTDD…反正没有什么是不能学的…… 学习是一种生活方式，是少数人的生活方式生活方式决定了生活质量，这是最基本的逻辑。 既然学习是一种他们已经选择了的生活方式，所谓的“终生学习”只是必然的结果每天进步一点点地活着，没有最好，只有更好，不需要成功，只需要不断成长。 自学其实是一种社交活动 学习从来都不是单独孤立的行为，而是社交行为。 生活中，你遇到过这样的现象没有：“看见别人打针，自己先疼得受不了……” 这是因为我们的大脑中有一种神经元，叫做“镜像神经元”（Mirror Neuron），它会让我们“感同身受”，当我们看到另外一个人正在做什么的时候，镜像神经元会尽力给我们足够的刺激，让我们“体验”那个人的感受。以前人们不知道为什么喷嚏竟然会“传染”，现在科学家们很清楚了 —— 那就是镜像神经元在起作用。 镜像神经元的存在，使得我们有模仿能力、有通感能力、有同情心、有同理心…… 这也是为什么人类天然有社交需求的重要原因，因为我们的大脑皮层上都有很多的镜像神经元。 一切的学习起初都基于模仿，一切的模仿，都源自于看到真人的行为 —— 哪怕是在电影里看到，虽然其实只不过是影相而已，并非真人，但毕竟是真人的影相。 所以，无论学什么技能，都要找到用那种技能的人，这样我们的镜像神经元才可能更容易被激发，学习效果才会好。若是能找到热爱那项技能，乃至于一使用那项技能就很开心（最好的情绪之一）的人，那就更好了。激情这东西，是少数幸运儿才长期持有的东西，大多数人小时候挺多，过了十五六岁之后就开始有意无意磨灭了激情，且并不自知。 很多人误以为他们眼里的成功者靠的是“坚持”、靠的是“毅力”，这完全是自己的镜像神经元“尽力”的结果，是“调用自己过往经验去‘感同身受’的结果”…… 事实上呢？那些“成功者”其实并不在意成功，因为到死之前成长不应该也不可能结束，因为那是他们的生活方式，学习、进步、探索、迂回，甚至折腾、挫败和迷茫，都是他们生活中必不可少的内容，这是最初不自觉的选择，谈不上什么“坚持”，谈不上什么“毅力”…… 说实话，对他们来说，不让折腾才真痛苦呢，不学习才需要坚持和毅力呢！ 为什么要选择朋友的原因。人与人之间有很大的差异，最大的差异来自于性格养成，大多数人会沦为表现型人格，只有少数人才会在不断调整中保持、呵护、进一步培养“进取型”人格。他们自然而然地更为乐观，更有耐心，更有承受力，更有战斗力，更能生产与体验学习与进步的乐趣。与这样的人在一起，学习会更容易 —— 只因为镜像神经元会更容易地被正确激发。说清楚了，道理其实挺简单的。 刻意练习是必须自己完成的核心 重复才能练就技艺。刻意练习，必须自己完成。即便是在进取型人格占大多数的社交圈里，一切的改变也都来自于自己的刻意练习，用时间浇灌的践行，才能引发真正的改变与进步。 所谓的智商，其实是一个人最终积累出来的知识经验的总和 —— 若是这样理解的话，就不难理解为什么到最后人与人之间的聪明程度相差天壤。因为有一些人天天往前走啊，另外一些人早就不动了啊！所谓的刻意练习，说来也很简单，就是把那些现在做起来生疏的技能通过反复使用最终做到不假思索就可以做完且做好 —— 这与智商高低全无关系。 一切看起来复杂的技艺，其实都并不难，很多人最终学不会，其实只是练不成，就是说，他们并不是不理解那道理、那原理；可理解本身并无太大用处，因为真正需要做的是通过大量的重复与实践，把那道理、那原理转化为大脑皮层表面的沟回…… 缺少了刻意训练的环节，学什么都是白搭。 你若是去了健身房，并且还能持续频繁地去健身房锻炼，你的身材就是会变的，而且变化还会非常大，那可是一整年啊！事实上，三个月下来，总计一百小时左右，就会发生巨大的无法忽视的变化。对，仅仅一百小时，在绝大多数领域里，就足矣把绝大多数人甩在身后 —— 对一些人来说这个事实可能是解脱；对更多另人来说，这个事实其实非常残酷，因为仅仅一百个小时，他们就已经败下阵来，别说一辈子了，别说七年就是一辈子了，他们在生生世世中，第一百个小时之前就已经死去。 概念与方法论：最少必要知识 什么是“最少必要知识”呢？所谓“最少必要知识”，指的是为了能够实践某项技能，最起码要学会的那一点知识。 MAKE —— Minimal Actionable Knoweldge &amp; Experience。注意这里的一个词：Actionable，“可行动的/可执行的”。比如，开车的最少必要知识是什么呢？学会如何启动学会如何制动再加上一个字：慢 学习编程的最少必要知识是什么呢？ 你得习得几个程序员都应该有的起步方法论。 …… 然后呢？然后你就可以开始边学习，边实践，在学习中实践，在实践中学习更多，虽然有时掉进陷阱，有时误入歧途，但，请你放心，肯定不会死人的。是谓不断进步，是谓 “路漫漫其修远兮，吾将上下而求索”。 只使用 Google 不论你遇到什么困难，都可以去问 Google，这是目前地球上最大的“人工智能”项目。一切能问 Google 的，都不要去问人。 既然你准备当工程师，那么，在使用 Google 的时候，除了那些常用的符号之外，还需要常用以下几个关键字： tutorial example tricks cheatsheet cookbook awesome 在中国，你最好买一个 VPN 服务一切能节省时间的服务都值得购买，因为时间才是最宝贵、最稀缺，压根无法再生的资源，跟时间比，钱算个屁。 在国内，一个程序员的水平怎么样，基本只取决于一件事儿：英语水平 那些在国内学英语专业的人本科毕业去当老师或者靠研究生，真不如脱产学一年计算机呢，拿着这个优势，一下子就干掉国内 90% 的所谓程序员，年薪 60 万人民币，其实指日可待…… 尤其是那些英语系的女生，一脚踏进码农的世界，瞬间就是女神中的女神。 提高英语的最直接、最有效方式，就是从此在某个领域坚决只使用英语 —— 平时，一般人还真的很难有这个环境呢！现在机会来了，你想学习，你想学习计算机，你想成为一个工程师，你就要从今天开始在计算机领域里，只读英文文档。 触类旁通地想想吧，如果不把你的中文使用能力锁起来，那么在这个领域里，你的英文使用能力就一定不能发展起来 —— 就犹如上面那个小女孩的左臂没有被绑起来一样，直接导致右臂永远没有办法恢复 —— 因为大脑会走捷径，于是那一部分功能永远不可能被大脑的另外一部分学会。所以啊，还是那句话：“都已经给你说清楚了，你自己选。” 本来人人都是工程师，只不过很多人明里暗里自己放弃了而已。 我们每天都要给自己洗脑。可这并不是我发明的习惯啊！孔老夫子说，“吾日三省吾身”，你看看他老人家个人卫生习惯多好，不仅洗，还要天天洗，而且还是每天要给自己洗脑至少三次…… 学习其实是一种生活方式，学习本身就是最好的洗脑方式。只要我投入时间精力，长期来看，没有什么是我学不会的。我学会的东西越多，我再学新的东西就只能越来越快。学习不是目的，用起来才是真的，因为价值只能通过创造去实现。我知道我现在看起来很笨拙，但刚开始谁都是这样的，实践多了，就自然了，就自然地好起来了。在学习这件事儿上，他们不理解我是正常的，这方面我也不需要理解，因为我是一个独立的人。我不应该与他们争辩，因为我不想伤害他们；我也不应该被他们影响，因为我不想伤害自己。刻意练习永远是必要的，虽然它通常并不舒适，但它的复利效应确实巨大的。哪怕是为了下一代，我也要通过现在的努力成为学习专家，这样才有资格与我的孩子共同成长……我的路还很长，我要健康，我要干净，尤其是我的脑子更要干净。 所谓的原则，就是一定要恪守的形式准则，如果不能恪守，就不能称之为原则。做个有原则的人，是很重要的原则。 你学你的，用不着别人批准有一件事绝大多数人搞错了，导致了不一样的思路，不一样的结论，不一样的未来和结局： 学习这东西，不是一定要学到大师的程度才可以拿出来开始用的。 真实的学习过程是，学会一点最少必要知识（就是那些知道了之后就可以马上开始行动了的最少知识），然后就要马上开始实际操练…… 最终，大量的细节都是在实际操作过程中进一步学会的 —— 甚至，还有大量的细节如果不进行实际操练的话，就根本没机会学得到。 在中国，每个会开车的人其实早就应该意识到这种学习方式的神奇。在中国，驾校的培训实在是太粗糙、太简单、太粗暴了…… 交了钱，进了驾校，其实前前后后在练习场上实际操作的时间少得可怜 —— 然后就冲出来上路了，虽然各自进度有些差异，但总体上来看，真正的驾驶技能几乎 100% 都来自于在真实世界里实际操作，而非驾校培训，不是吗？ 绝大多数人的眼里，学习成了一条“漫长不归路” —— 听起来多可怕啊，学不成就别出来得瑟，学不成，就别回来见人！天呐。 既然在脑子里把学习这事儿类比为一条“漫长不归路”，那么“它一定是一步一步走过去的……”，于是，无论做什么事情，他们都感觉必须循序渐进，甚至，若是看到别人不循序渐进，就很生气。 循序渐进坑了一代又一代的人…… 仔细观察一下我们的真实生活，我们从来都是这样的：横空出世，向后钻研，向前突击……这才是真实的世界。 我们的教育体系，好像特别痴迷于把我们带到循序渐进的道路上去，父母们也觉得只有这样才放心（其实他们自己也是被弄脏了脑子自己不给自己洗脑的产物）…… 99% 的人循序渐进地从 ABCD 开始学，学英语 16 年，开口说不了，拿笔写不出…… 真不知道图个啥。 最简单的编程，被抬高成“工程师”的境界 —— 可另外一个事实又明显地摆在那里： 很多自称工程师的人，其实看到十四五岁的小黑客做的事情，也不得不心服口服 —— 若是必须、只能循序渐进才行的话，那些小黑客是不可能存在的，不是吗？小黑客们都不是靠循序渐进习得技能的。都是“横空出世”的，他们最开始做的事情，不是打基础，而是“突然有个问题要解决”，于是不管三七二十一只好“向前突破”，用尽各种方法（通常是很土的办法）先把问题解决掉…… 在这个过程中，能补的补（向后钻研），补不上的就先放在那里，留给以后…… 然后反复迂回前进。 鼓励身边的所有人…… 只因为，我实在是太清楚“鼓励”这东西有多么稀缺了。如果你自己是个上进的人，那你就像我一样，天天鼓励那些同道中人罢 —— 我相信这绝对是善事。 谁说学过之后用的不够熟练，就不能用了？！ 谁说没天分的人就不应该学东西了，谁说没天分的人学得不足够好就丢人了？ 我找到了捷径，可惜早已身不在起点。真的有很多捷径…… 比如，现在这篇文章里很多话都是“捷径”，因为你想通了，这些“捷径”就会帮你节省很多很多时间，节省很多很多精力，了却很多很多烦恼，甚至抄很多很多近路…… 捷径，不就是用来节省时间、提高效率的吗？ 我所说的、我所理解的全栈，究竟是什么没必要在语义上争论，但，在真正工程师的生活中，coding 应该基本上只占 20% —— 因为最终代码是用来表达思想的，用来解决问题的；所以，全栈工程师是那种有真正的问题需要解决，有真正有价值的想法需要实现，有品位的设计者、创造者。就好像我们都识字，都能写字，能写漂亮钢笔字的人也很多很多，可最终写好文章、写好教程、写好小说、写好诗歌的人才是“文字工程师”，剩下的都只是“识字而已”。 开始之前……注册一个 Github 帐号 从骨子里来看，习得任何技能的最根本技巧，就是一句话而已： 马上开始像那些已经精通这个技能的人一样生活。 因为从本质上来看，一切的学习与创造，都是学习者与创造者的生活方式、生活内容。去目标技能拥有者最活跃的地方生活，像他们一样生活，直至真的就那么生活 —— 这就是学习与创造的另外一个更为生动、更为本质的描述。所谓近朱者赤近墨者黑，讲的也是一样的道理 —— 因为激活大脑里的“镜像神经元”是学习与创造的最初起点。 Github 其实是目前地球上最先进、最高级、最高质量的社交网站，对，它就是个社交网站 —— 虽然貌似现在的人们普遍认为“社交网站”指的是另外一类东西。在那里，工程师们用他们固有的最高效的方式相互交流。他们写好代码就传到 Github 上去，用 Github 做开发中必须的重要事情： 备份自己的代码 文档与代码的版本管理 相互最高效地交流与协作 通过展现有效活动而获得更高信用 更方便地展示自己与自己的成果 每天都要有一整块的思考时间在传播自由的时代里，真有价值的东西总是会被发现。 工程师不是每天每时每刻都写代码的，他们用更多的时间思考。大家从小上学，挺辛苦地学会了识字、写字，可大多数人一辈子都不会写文章，就算写出来了，也传播不出去 —— 其实只是是因为确实没价值为什么呢？因为他们不思考，也不会思考，所以，等于没有什么东西值得表达 —— 尽管已经掌握了一定的表达技能。 工程师其实跟写书写文章的作者一样，无非是用他们特有的表达技巧去表达他们的思想，作者用自然语言文字，工程师用特定字符构成的代码…… 可关键在于，首先要有表达的标的，之后才有表达好坏的判断。工程师表达什么？他们发现问题之后解决问题，提高效率（通过大量的自动化任务）…… 那么他们天天要思考的事情多的去了，什么值得解决？要解决的话如何解决？我的解决方案是不是比别人的都更好、更优雅？为了搞定这个任务，我需要学会什么？我需要和人么样的人以什么养的方式合作？我能否持续地维护我的解决方案？我如何才能让更多的人支持我？ 与大家认为的“码农”并不一样，真正的工程师，时间分配大抵上是这样的，80% 的时间用来思考，20% 的时间把思考结果用代码表达出来（也许是通过带领团队）。这个思考的过程包括反复搜索(search 多了，就叫 research)，深入阅读各种文档（因为今天的工程师必定要用到大量别人写好的模块），还要思考自己写出来的代码如何写好文档才能让更多的人使用…… 而刚入门的时候，可能是反过来的，80% 的时间用来写代码，没有思想可以表达，就去模仿表达别人的思想…… 但，一定要有 20% 的时间花在真正的思考上，像工程师一样思考。很多人进步慢的根本原因在于，每天都在“学”，但从来不花大块的时间深入“想”。 从一开始就要养成习惯，每天要有起码一小时的时间专心思考： 我将要解决的问题是什么？ 最重要的问题是什么？ 它的核心关键在哪里？ 已有的解决方案都有哪些？ 我如何才能给出一个更好的方案？ 我的方案应该如何拆解，如何逐个实施？ 一边思考，一边写写画画，一小时不知不觉就会过去。 功夫在行外在中国想要成为工程师，竟然有很大的一个关键并不在于技术本身，而是在于英语阅读能力；再比如说，即便成为了一个入门级的工程师，驻足不前的根本原因并不在于技术难关无法攻克，而是在于平时的思考习惯不良，或者干脆没有真正深入思考的习惯…… 成年之后，我拥有比大多数人更为强大的学习能力，无非是在这个过程中养成了几个习惯： 我不怕麻烦，因为再麻烦的事儿，都可以拆分成无数个可处理的小块，于是就不麻烦了； 即便是天赋不好，通过一定量的练习，也可以做到比大部分人好，哪怕滥竽充数也充得更像； 经验告诉我，经过一段时间之后，一定会越来越有能力解决更大的麻烦… 基本开发环境设置一些最常用的命令（’#‘ 之后的文字是注释，输入命令的时候不能有它们）：ls #罗列当前目录下的内容cd #更换工作目录pwd #显示当前完整工作目录touch #创建一个文件mv #移动/更名文件或目录rm #删除文件活目录nano #使用 nano 编辑纯文本文件open #打开一个文件，就好像你在 Finder 里双击那个文件图标一样clear #清空屏幕sudo #用管理员身份去执行一个命令 “通读”是做工程师必须的能力。你不一定要全部能够理解（对任何人来说，最初都不可能做到），但你必须对整个文档有一个整体的认识。这就好像读书的时候，你能做到虽然不能完全读懂，但确实能够完整读完 —— 之后再多读几遍么！古人说的是对的：读书千遍其义自见。还有就是，若是从一开始就没有“通读”的意识，后面不知道会吃多大的亏，而且吃了多少亏自己都完全不知道…… 这很可怕。 很多工程师，用了好多年 Terminal，竟然都不知道竟然还有个快捷键能把光标前的两个词调换一下位置：按一下 esc 键，然后再按一下 t （通常标记为：⎋-t）…… 你想想看他们在过去的那么多年里，浪费了多少次键盘敲击？—— 虽然说起来、听起来没什么，可若是真的严肃起来去想，有什么比时间更重要的呢？浪费了大量的时间、浪费宝贵的生命，只不过是因为最初的时候没有养成“只要是重要的文档，必须通读至少一遍的习惯”而已。 “优秀是一种习惯”真的并不是空话，是放之四海皆准的道理。随后的过程中，我们会建立很多很多的好习惯，甚至这句话本身也会在各个地方重复 —— 生活质量就是这样一点一点提高的，放在哪个领域里其实都一样。 nodejs 有两个版本，一个叫 LTS（Long Term Support，提供长期支持的稳定版），一个叫 Current（提供最新功能的当下版，通常也不够稳定，尚需改进）。很多软件系统都采用这种方式，比如著名的 Ubuntu …… 所以，当我们需要安装什么软件的时候，必须到官方网站上看一看，看看当前的稳定版本是什么，然后选择它就是了。将来你成了高手，啥都敢于、且确实有能力尝鲜的时候，就随便你喽。 永远不要参与编程语言之间或编辑器之间的比较争论 —— 在工程师世界里，那是永无宁日的争论，但价值并不大，事实上，一切争论的价值都不大：平息争论的能力才是更有价值的能力，若是不能平息争论，就不要参与争论了，因为参与无法平息的争论，本质上就是，耗费了时间耗费了生命却没有任何结果 —— 这是一个很重要的价值观，它会帮你节省无数未来的时间精力，它也有可能让你成为那个最终能够平息争论的人。 学任何工具，第一件事情就是去把官方网站翻个遍，是必须的习惯。 拿来任何一个软件工具，快速熟悉并掌握各种快捷键，是一个好习惯 —— 基本上就是耗费半小时而后用一辈子的事情。 肯定无法一下子全读懂，但“即便读不懂也要读完”，是一个特别神奇的能力，古人都知道“读书千遍其义自见” —— 说的就是这事儿。你必须积累这种能力，切记。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"},{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"在最好的时代，成为一个超级个体","date":"2017-01-11T11:56:06.000Z","path":"2017/01/11/MyShare/to-be-a-super-individual/","text":"古典 超级个体应该是一群人，或者是一个特别善于和组织合作、共同成长的人；他既能站在科技前沿，又能深刻洞察人性；他具备多学科通识，又能精研某个领域，成为专家； 他比别人成长得更快，有很强的自我驱动能力，持续增值。 “我们已经有了关于商业、趋势、政治和财富的内容，为什么我们不就做一档关于个人的栏目呢？”和罗振宇碰这个节目定位好几次了，直到这句话突然跳出来，我看到他眼睛里放光。恩，我们真应该为个体做档节目。 记得第一次谈客户定位，我就被严肃告知：得到的用户都是一群上进、焦虑、不满足的人。“知识狂躁，这群人。”罗胖捧着脸，一脸痛苦。死磕自己满足这群人，不容易。我心里对应了一下自己，字字中枪。不过嘛，上进焦虑不满足，是件挺酷的事。上世纪美国50年代，美国的精英阶层也集体焦虑。心理学家罗洛梅却说“焦虑是人类面对威胁希望创造自我的正常状态。在这样一个高速发展的时代，焦虑的人才是真的健康、感觉到时代脉搏的人。”敏感才能感到变化、有才华才会有的选，而追求自由才想要把握自己的人生。每个人焦虑的人内心，都有一个很厉害又很自由的人。 2.这个时代的确需要我们变成这样的人。 所有人都在说未来是一个个体崛起的时代，我们用各种词汇描述这个现象：IP、社群、消费升级、设计感、情怀、粉丝经济，阿米巴、共享经济、联盟……今天，个体的能力、价值和需求都变得越来越重要。但是这句话只对了一半，个体崛起的时代，并不是“每一个”个体崛起的时代，而是少数个体崛起的时代。和你看到的所有互联网热潮一样，网络会让两极分化加剧——少部分人获得巨大的讯息、影响力和资源而迅速崛起；同时更多的人会被服务得越来越懒，成为平庸的跟随者。个人崛起的时代，是一部分“超级个体”崛起，和一大群普通个体追随的时代。这群“超级个体”是这样的人：科技 人性：能抓住趋势，善于利用科技，也有高感性能力；T型人才：良好的基础素质，在某一个领域有极致的专长；联盟思维：善于和组织、平台密切合作，共同成长；个人品牌：有自己的个人影响力；自我实现：有点品位、有点追求；每个人，包括我自己，都需要加速升级自己的眼界、心智和能力才能抓住这个趋势。而越是走在靠前的人，他们看得越清晰，所以就越发努力。 3.什么是一个人加速成长的必备条件？ 下面有一个有趣的案例：1968年墨西哥奥运会，跳高运动员福斯贝里（RICHARD FOSBURY）第一次在全世界面前施展他的背越式跳高。在那个流行跨越式或者俯卧式的年代，他的动作诡异而奇特，引来阵阵哄笑。随着横杆一次次升高，笑声没有了。在最后一跳成功后，他获得了奥运会金牌——全场起立鼓掌。跳高运动员福斯贝里福斯贝里是个典型的弯道超车选手，他的身体素质和成绩在普通跳法的时代很一般，更先进的起跳模式让他获胜。这就是加速成长的第一个要素，转换模式。《科学革命的结构》把这种转化称为 范式转换”paradigm transition trans。 飞机的发明就是典型的范式转化的结果。以前的发明家认为飞机应该像鸟儿一样，拍动翅膀起飞，他们尝试了无数方法让飞机的翼拍动，最后却无疾而终。而莱特兄弟那一代人想明白一件事——飞机不应该是鸟，而应该是帆船。飞机的翼应该像帆船的帆一样。一旦范式转化，所有的路径都清晰了，第一架飞机很快被发明出来。不过，仅仅转换模式还不足够，歌颂福斯贝尔创造性思维的人忽略了背越式跳高的第二个必要条件——橡胶垫。一直到上世界60年代，橡胶垫才被用来代替原来的沙坑，在这个之前，大头冲下的背越式跳高就是自杀动作。这是加速成长的第二个要素，学着应用新的工具和技术。在热兵器时代，再好的拳法和内功，也忌惮一个拿枪的人。看到趋势不掌握技术也没用。接下来的故事更有趣——在1972年慕尼黑奥运会上，福斯贝尔连预赛都没有进。在接下来的运动生涯中，也没有再复出——背越式跳高并不难学，他被更多身体素质好，学习能力快的人弯道超车了。这是加速成长的第三个要素，也是最重要的一个——修内功，提高核心素质。正好踩到趋势、技术要靠运气；如果不一定碰的上，最好的方式是提高自己的基础面，持续的关注趋势，学习新技术，发现机会就迎头赶上，把前浪拍死在沙滩上——这是不是更大几率的胜利？这几年的商业世界，先驱先烈，也是这样的游戏。正确的模式、工具技术和个人素质，是加速成长的三个要素。最后一个虽然听上去最不酷，其实花时间最长，也最重要。只听不动的人，往往眼界越来越高，手脚越来越低，变成一只知识瘫痪的“长颈鹿”。曾国藩说：“兵闻拙速，未睹巧之久也”，仅仅是精巧的东西长不了。职业发展是“拙速”，找到一个点，老老实实做事，踏踏实实练习，一年下来就会超过很多人，遇到一个机会，呼啦一下就起来了——成功是长久而持续的积累过程。 4.很多人认识我，是因为我写的一本书《拆掉思维里的墙》，所以我的标签好像是“畅销书作家”。其实在过去10年里，我大多数的时间都在做职业生涯的咨询、高管的教练、课程研发和授课，在我看来，这都是一件事——帮助他人加速发展，也从别人的经历中获得智慧。在这个专栏中，把自己这些年学习的近40门课程、相关的书籍，以及近千个案例中与一流高手交锋的智慧，分享给大家。王小波说，艺术来源于痛苦，但是没必要非来源你的痛苦啊。职业发展这个事也是一样——请相信，总有人用更好的方式在做你现在做的事。你需要的只是学习。 在《超级个体》里，我们准备这么干： 我们会每周探讨一个加速成长的主题——它可能是职业发展的基础能力、也可能是个人成长的底层概念、他们都来自大部分人有困扰的真问题。我把这些52个主题分成这么4大类：对事的竞争力、对人的影响力、对组织的领导力以及内在发动机——自己的个人成长。课程设置​我还加入了一些关于自我探索的测评和工具，一些积极心理学的内容。成功无论在数量还是在人生长度上，都是小概率事件。我们要学会在没成功之前快乐生活。这是一张正在进化中的图，这些主题会持续更新。 每次一个看得懂、记得住、能实操的工具、模型或方法论。知识同样符合28原则，任何一门领域真正核心的内容就是20%，最聪明的办法是用80%的时间学习其中20%的精华。这20%往往是一些核心的模型或工具——他们既是底层逻辑也是方法论。这也是为什么当别人问你上完一门课读完一本书学到些什么时，你的第一反应往往是说：恩，有这么一个模型、法则…………他们是聪明人做事的“套路”，观察世界的方式，有了这些会省你很多时间。拿着这些工具，希望这个专栏的订阅者能开始实践起来，只有当你实践起来，别人的知识变成你的知识，你的知识变成你的能力。所谓行到极处便是知，很多时候，做着做你就懂了。基于这些想法，每天的解都会围绕一张“成长卡”进行——我会把讲到的方法、策略、工具、或者模型浓缩在一张图上。你只要保存好这一年中对你有启发的“卡片”，慢慢的，你就有了自己的技术、自己的发展工具箱。 陪伴成长：我已经出版了两本书，最大的遗憾就是没有办法像讲课一样和读者及时的交流。比起一个千里传音的老师，我更希望做陪伴在你身边的成长教练——这也是我选择在得到开设这个专栏的原因——希望这是一个能陪伴你一年的文字。每周四周五，我都会在这里和你们深度互动、答疑、讨论这周的主题。等栏目走上正轨，我还会邀请更多有趣的超级个体来分享他们的独门经验，和大家一起探讨这个时代的成长方式。 在未来一年，我们一起来做三件事： 每周学习3个加速发展的工具和方法论、你可以逐渐打造一个属于你的超级工具箱 完整的梳理自己、系统展开能力地图，逐渐搭建自己的能力体系 认识更多各个领域的“超级个体”，看到人生不同的可能性有人问我，这群 “超级个体，到底超级在哪里？他们应该是这样一群人：他们理解科技又深具人性，精钻一门又有通识，与组织紧密合作又不失独立；他们是一群自主，自驱也自我成就，成功又幸福的人。在他们身上，做自己不仅是一种态度，更加是一种能力。这个时代就需要这样的超级个体。 ]新精英生涯古典：未来是个体崛起的时代文|MBA智库/子墨 古典老师，著名生涯规划师，高管教练，新精英生涯创始人，销量超过300万畅销书作者。少年文青，玩乐队，练散打，写小说，骑单车从长沙流浪到北京。2007年创办新精英生涯，现已成为中国最专业、培养认证生涯规划师最多的生涯教育与咨询服务商。对于创办新精英的初衷，古典老师说道，每个人进入职场都有个迷茫期，主要有两段。一个是刚刚大学毕业的时候，这个时候表现为不知道怎么面对职场；第二次迷茫期一般在职场中过了三年左右。他们有了一些基础技能以后，不知道怎么长远定位。而在30岁之前、35岁以后都还会有一次迷茫期，人都会阶段性的迷失自己的方向。因目睹无数中国教育下的一流人才的迷茫和纠结，意识到 “找到自我”比“去好大学”更重要。所以当时做新精英也是出于这样一个初心，希望可以帮助迷茫又困惑的职场年轻人，通过具有专业性、指引性、实战性的生涯规划培训和服务，确定自己的方向，跨越职场难关，合理规划自己的职业生涯，长成自己的样子！ 据统计“职业发展”已经成为“薪酬待遇”之后个人择业选择的第二大因素，然而面对新兴企业变化快的职场环境，越来越多的职场青年人对职业发展深感焦虑和迷茫，越来越多的HR和管理者希望通过生涯咨询的方式帮助员工找准职场方向。作为职业生涯这个市场中的一位创业者，古老师表示当下职业生涯是一个远远没有被开发的市场，就好像心理咨询一样。心理咨询市场也是没有被开发，但是如果爆发的话心理咨询市场会比职涯快很多。因为中国人观念都是有病了实在不行才去治，但是职涯就不同，可能每个人觉得有问题过来咨询这样的方式还挺好的；第二个是很少有人通过企业去解决职涯问题，虽然EAP项目能做但是落实在实处员工一般也不会真真正正的在那讲自己的事。而职涯很多企业都是采购职涯去做员工发展的，企业在这方面是有员工需求的，企业也需要员工发展好。 在提到对客户以及用户的把握上，“最重要的就是内容的输出，然后在持续的内容输出的前提下，把门槛降低”，古老师说道。他说，一个东西的流行主要就两个要求，一个让这个东西变得越来越重要，另外一个是变得越来越简单。而目前他们团队在做的就两件事，一个就是通过公关和品牌让产品变得越来越重要，第二就是通过技术让培训和咨询产品更落地更实战，从而让产品变得越来越简单。 古典老师在做客智库课堂（mbalib-class）时提出了超级个体的概念。从公司管理以及运营上，古老师做了更为详细的解释：他认为不管你是上班、自由职业还是创业，未来都是个人崛起的时代。未来的职场，将变成“平台+个体”，组织越来越需要牛人，但是牛人越来越不需要组织。 每个人都必须为自己的成长和职业发展负责，都要学会把自己的天赋和能力做成产品。但是，在未来职场的竞争里，领跑者永远只有少数人，他们就是超级个体。 超级个体并不是超级自由职业者，个体是要深度依赖于组织才能够发挥力量。超级个体并不是超级个人，超级个体应该是一群人，或者是一个特别善于和组织合作、共同成长的人；他既能站在科技前沿，又能深刻洞察人性；他具备多学科通识，又能精研某个领域，成为专家； 他比别人成长得更快，有很强的自我驱动能力，持续增值。 一句话，超级个体组成了未来职场的第一梯队。所以从这个角度来说，这些个体要有 自我驱动、自我管理和自我成就。自我驱动即管理者给他定目标但是不需要管理者来推动他去完成目标：自我管理，就是有一套可以管理自我情绪的方法。这一代人很需要也渴望自主性，但是如果没有自我管理手段，就会变成一个很乱的个体，永远无法成为超级个体。越是不需要被组织管理的人，越是需要有自我管理能力。 以前的企业是你不要有自我意识我来领导我来激励，但是现在的企业是你有自我意识，那你来自我领导、自我激励、自我管理，同时你也得承担自我管理的责任。当企业和个体能够在管理、领导这两个方面达到共识，它自然就形成一个自我成就的过程。因为在这一过程中，个体通过自己能力的提升给企业带来价值，而反过来企业也会把更多的利润比例分给他们。在古老师看来，超级个体是自己给自己自带资源，而 作为领导者是一定既是超级个体，也是好的管理者。 作为出版了两本书的古老师，最大的遗憾就是没有办法像讲课一样和读者及时的交流。比起一个千里传音的老师，他说：“我更希望做陪伴在你身边的成长教练！我们已经有了关于商业、趋势、政治和财富的内容，为什么我们不就做一档关于个人的栏目呢？”在他看来在越来越多商业、趋势的东西之下，个体越是容易被忽略。为个体发声，成为他一直以来的愿景。也正是基于这样的认识，才决定在得到APP推出一档新的栏目“超级个体”，围绕职业发展、个人成长，深度讲解一个主题。 对于目前高压、快节奏的生活，年轻人在理想与现实主义之间该如何找到自己的梦想的话题，古老师笑着说：“首先你必须有一个吧。所谓理想主义是你有一个梦想，而现实主义是你要为这个梦想，设置资源、提供能力和成就的路径。对于这三个方面如果没有研究的话，梦想永远是个梦想！很多人觉得自己有很多梦想，但是在这些梦想中间你有没有个排序？排序之后你有没有配备资源？如果配备资源你还得给自己设置路径，这就是现实主义。”就像他在《你的生命有什么可能》里说到的一样，理想主义者——我要一站到达，现实主义者——试试看，不行就算了，而现实的理想主义者——在迂回和修炼中，不断地去接近梦想！","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"你的生命有什么可能","date":"2017-01-10T15:25:06.000Z","path":"2017/01/10/MyShare/live-your-life/","text":"古典 你的生命有什么可能 即使在这个不那么公平的现实世界里，每个平凡人也都能活出各自的生命可能。 人生四个永恒的主题：影响力、爱、自由、智慧。 这本书将让我们打破自己心智的障碍，开始自由地思考和行走，然后看到人生的更多可能。本书探讨了以下问题：高竞争的工作、高不可攀的房价和房租、 拥挤的交通、糟糕的空气、不安全的食品……在竭尽全力才能生存的时代，年轻人如何追求自己的梦想？在这样的时代，我们的生命又有什么可能？如何才能越过现实和理想的鸿沟，找到和进入自己希望的人生？如何修炼自己在现实中活得更好的能力？如何在现实之中发展自己的兴趣？如何连接现实和理想？如何面对生命里的苦难、贫穷、不完美或者不公正？如何获得心灵的自由？ 人的生命如同水流，奔流的小溪终归静水流深的大河。——俞敏洪幸福人生不是外求，而是内修而来的。——张德芬它引导你探索内心的结构，剖析你成长的困惑，帮助你设计独特的人生蓝图。掩卷之后会为你补充力量，伴你出发并开始努力，在生涯发展的征途上，不断提高你收获幸福的概率。——毕淑敏“找到自己”比“去好大学”更重要，更多人将：成长，长成为自己的样子！——古典 序 你的生命有什么可能？一头奔入梦想不敢，留下过平庸的生活又不甘——这样的时代，我们的生命有什么可能？如何才能越过现实和理想的鸿沟，找到和进入自己希望的人生？ 他本来就应该想到： 你的人生不应该全信一本书，哪怕是神仙写的。 你可以送给你喜欢的人一双绿鞋子。 第一种人生策略是“遇见”：这些人用感觉来判断生活是否是自己想要的，期待自己能“遇见”想要的生活。他们的人生哲学大抵如下：打开一扇门，如果感觉不喜欢，就转身离去，打开下一扇门；喜欢就停留下来，但如果有一天这个地方变得不太好了，就继续试着开下一扇门。 第二种人生策略是“定位”：这些人相信世界上已经有一个最适合自己的人生目标，他们需要做的就是找到并实现它。他们的人生往往是这么玩的：先清晰地搞明白自己到底应该要什么，搞明白在哪里能获得，然后设定出一个清晰的计划，最终一步步地达成。 第三种人生策略是“创造”：这些人不愿意相信任何一种现成的人生答案，希望自己创造出一个；对他们来说，人生最重要的不是功成名就或即时享乐，而是一种“追寻的过程”。他们的人生哲学是这样的：创造的第一步是修炼——如果我无法一下子看到人生的终极意义和目标，那么我能做的就是先找到一个值得一试的目标，在达成的路上修炼自己的能力，扩大自己的眼界——反复重复这一过程——逐渐明白自己到底想要什么。当定见形成、能力变强，就没有什么能阻挡他们创造自己想要的自己和生活了。 定位人生最重要的条件，是你要生活在一个稳定和有序的时代。 如果以前的社会像一列慢悠悠喷着蒸汽向前的绿皮火车，那么今天的社会就像坐过山车——你永远不知道下一个弯路在哪儿。所以很多人等子弹飞到靶心，才发现物是人非。他们问：人生大叔，说好的幸福一辈子呢？人生大叔摊摊手：不是我不明白，是这世界变化快啊。 虽然定下来的确让我们安心，但 这是一个“定不下来”的年代。 以前老人们能对孩子们说：“听我的，因为我经历过你未来要经历的。”而今天，他们的孩子会说：“不，你从未经历过我将要经历的未来。” 今天的职业人需要到至少30岁才能逐渐理解趋势，看到自己的终生方向。 如果你学不会享受这种不确定感，不懂得在其中获得点乐子，这时代真的会要了你的老命。 开放的社会和互联网带来了人生的多元选择。80后大学生的大多数梦想都是下面四种：功成名就，让父母过好一些，组建自己的幸福家庭，为社会做贡献。 新一代人的生命没有上一代人的固定模板和样式，他们眼中的生命有无限可能。 当哈佛公开课在网上点击就可免费看时，你很难再像以前一样膜拜些什么人。大家的关注点重新回到自己身上——如何成为一个让自己喜欢的人？ 公司越来越小而美。这是一个个体的世界。 下面是书中的一些观点： 家庭背景对成长影响很大，拼爹确有其事；知识只能从一定程度上改变命运； 面对逐年加大的就业压力和文凭贬值，毕业生深陷于现实与理想的泥沼； 房租房贷占收入的比例很高，生活压力负担沉重； 本该由社会承担的教育、养老责任被硬性嫁接到家庭身上，独生子女发展中面临明显的“优势递减效应”； 他们希望以个人努力改变命运，却又无法逃离更大的社会力量的左右。 如果要把当代年轻人当成一个人，他/她应该是这样的：他的眼睛遥望着5000米外的七色彩虹，心中坚信每个人都平等自由，脚却踩在一片稀巴烂的烂泥之中； 他的脑子已经接受了要活出自我的想法，心里却困惑得要死，到底什么才是自己？ 人生有这么多可能，哪一个才是属于我的？ 目标有这么多个，哪个背后才是最好的？ 达成的方式有千百种，到底哪一条路确定能走通？ 我的想法那么好，家人反对怎么办？ 有人拼爹怎么办？房子怎么办？当他们的目光在美好的未来和脚下干瘪的现实之间来回切换时，迷茫、焦虑、浮躁由此产生，成为“定不下来”年代的时代病。 修炼与创造人生在“定不下来”的年代，人生不应该是规划出来的——规划意味着你的人生有一群“专家”比你更懂（还记得开头那本神仙的书吗？），规划还意味着早点确定，确定了就不要改变。连IBM这样的靠战略吃饭的公司也只制订五年战略规划。非要一个人做个长达10年甚至20年的生涯规划，除了有点励志的作用外，并不太靠谱。 在这个定不下来的年代，修炼和创造人生反而成为一种最有效的策略——以不变应万变——如果你不知道这世界和你将要去哪儿，最好的策略是先全力炼出一种在哪儿都能活好的能力，在有足够力量和眼界的时候，开始创造自己的人生！就像开头那个故事——你可以送她一双绿鞋子，还要成为一个值得的男人。 今天的人生发展不应该像狙击手，而应该更像导弹——先尽快地发射出去，让自己适应变化的环境，让自己飞得又快又稳；然后每秒都用激光重新定位目标，调整弹道，最后发现目标，一击必中。 当然，创造人生的模式也有自己的缺点，从心理感受来说，它让你面临比前面两种更多的不确定感：如果把人生比作航海，求遇见的人把命运之舵交给外界，自己回床位休息；求定位的人在打开自动巡航抵达目的地之前会有一程安心；而修炼之人则需要站在船长室，时刻把握着命运之舵，对每一种人生的不确定做出快速反应，在狂风暴雨中找到自己的星光。 所以这群人生的创造者总会有点“玩商”，他们善于把修炼本身变成一个有趣的经历，当过程值回票价，结果也就不那么患得患失了。 生涯是一门探讨人们如何在现实中生存、生活和生长的学问。 职业是人们实现生涯目标的手段之一，成功也只是幸福的副产品，生涯的真正目的是帮助人们发展自己的人生。 每个人先把自己修炼成生活的高手，然后用自己的独特天赋、不同的方式，追寻自己领悟的人生意义，在热爱的领域努力地玩，活出最喜欢的人生。这样的人生才精彩有趣，是不是？这就是这本书想谈的话题——你的生命有很多可能。这本书不准备做真理候选人，也不准备开山立派。只希望拆掉思维里的墙的你，能看到这个世界上的光。而当你看到光，希望你有能力成为一个走入光明的人。 价值观的修炼我如何知道自己要什么？如何找到自己想要的东西？找到了又如何保护自己坚信的东西？ 人生的四个永恒的主题：影响力、爱、自由、智慧。这是我自己最喜欢的一部分。我想努力地证明，即使在这个不公平的残酷世界，每个人也都能活出各自的生命可能。 在热爱的领域努力地玩！ 热爱，努力，玩耍。好的人生，就是在自己热爱的领域努力地玩。 热爱、努力、玩耍，孩子们整天过着这样的生活，他们总能找到自己热爱的领域，在其中全力以赴地努力，却又能对结果一笑而过。 有的人在热爱的领域里努力，却放不下得失之心来玩。他们对自己苛刻，活得太一本正经，像台永不疲倦的机器，忘记自己也有玩耍、快乐的要求。他们活得身心俱疲。 有些人在热爱的领域里玩耍，却因为害怕努力了也无法成功而从未真正全力以赴。当一份工作做不好，他们迅速转移并爱上另一个。他们表现得天马行空、毫不在意，掩饰自己对生活的无能。 还有些人在某个领域里努力地玩，却并不热爱——这些人往往看起来混得不错，是人生大赢家，只是他们从未意识到自己除了成功或失败，还能选择玩什么游戏、和谁玩、玩不玩——还能成为选择自己人生的人。 当你羡慕旁人时，有没有想过——也许那不是幸运，而是一种习得的能力。一个人命中的财富、成就和光环，也许的确有幸运的成分，但是那人展现出来的快乐、热爱和努力，都不是“遇上”的，而是“修炼”出来的。 所有的美好人生都是修炼和管理出来的。每一项人生要素背后，都有支撑它的能力。 兴趣：提升兴趣让我们持续发现新的事物，给生命注入玩耍和快乐的体验；能力：强化能力让我们固化自己的努力，得以掌控生活和工作，取得成就；价值观：固化价值观让我们产生定见，抗拒各种诱惑，聚焦热爱的领域，获得宁静与满足。 兴趣产生了快乐，努力产生了能力，而价值观则帮你发现热爱的领域。兴趣、能力与价值观是三种最重要的管理生命的能力——当你拥有强大的兴趣、能力和价值观，你就会很容易地发现自己热爱的领域，在里面努力投入地玩耍；而如果你缺失了这些幸福的能力，即使你有幸能找到这个领域，你也无力把握。 过好人生是一种能力，而非天赋。当你开始掌握正确的练习方法，每个人都有无限的可能。 兴趣让你发现适合的行业，能力让你进入能胜任的职位，而价值观则帮你筛选你喜欢的工作方式、同事和公司。 是兴趣推动你持续地在职业领域学习，发现新的机会；能力帮你持续地产生竞争力；而价值观则帮你在机会爆发的时候保持聚焦。 大学生就业难，年轻人职业适应力差，就是 过于强调“匹配”而非“修炼”的结果。 谈恋爱也是一样——你的兴趣决定你喜欢什么类型，能力决定你能搞定谁，而价值观则帮助你理解谁是一夜情、谁能与你长久走下去。如果不多见几个人，你怎么知道你对谁感兴趣？如果你从未与异性单独约会，你如何有搞定对方的能力？如果你没有体验过恋爱，你怎么会知道自己更看重精神交流还是稳定的生活？ 张学友说得好：等待着别人给幸福的人，往往都过得不怎么幸福。 成熟的爱情观应该是：爱情不是幸运，而是一种能力。先走出去，多接触人，在恋爱中学会恋爱——发现自己，修炼自己，使自己成为一个有趣的、有能力爱的、知道自己想要什么的人，你总能找到你想要的爱情。 兴趣为你打开一扇又一扇门，能力帮你走好一段路，而价值观则帮你不断关上不属于你的门。三者结合，让你在热爱的领域努力地玩。 任何人，不管家庭出身、学历和天赋如何，都可以通过修炼自己的兴趣、提升自己的能力和打磨自己的价值观，找到自我实现的平台，在现实的生活中，收获快乐、成就和幸福的人生。 幸福是一种能力。好的人生并非外求，而是内修而成。每个人都可以通过整合和管理自己的生命资源，最大化自己的人生价值，达到个人与社会的双重满意。也正是在这样的过程中，我们逐渐发现自己永不停歇的好奇、浑然不觉的天赋、发自灵魂的热爱，最终成长为自己的样子。 转动三叶草：掌控自己的人生比方说运动，你觉得NBA明星很帅，很明显你对打篮球感“兴趣”，而有人觉得足球更炫，他对足球更感兴趣；当你开始投入时间练习打球，发现有人跑得快，有人跳得高，有人则投得准，每个人都施展出不同的“能力”；即使是两个能力一模一样的人，因为“价值观”不同，也会有不同的球风——热爱“团队合作”的人喜欢把球传给最佳位置的人，看他们把球投进；而热爱“挑战”的人喜欢从最多人拦截的地方带球突破；而热爱“异性关注”的人在妹子围观的时候会突然爆发，女生们一走，他就蔫了。 我们先会对某一件事情感“兴趣”，这兴趣驱动我们学习和练习；持续地学习和练习让我们有“能力”完成很多事情；然后我们开始寻找一种合适的方式（往往是某种职业）把能力兑现成 自己想要的“价值”。而价值强化会使我们产生下一轮的兴趣。兴趣、能力和价值观的三叶草，就是这样旋转起来，让我们掌握和精通某一个领域的，然后进入更大一轮的“兴—能—价”循环。为了好记，也有人将其称为“性能佳”循环——让自己保持在这个循环中，你就是性能最佳的！ 想要知道更多专业知识（兴趣），把能力提高到专业水平（能力），可以帮助更多的人（价值观）。 永不衰竭的好奇心、高超的能力以及惊人又可怕的内心动力。 这本书也按照三叶草的循环写成：当我有零零碎碎的想法时，我只有一些小兴趣，这兴趣只够驱动我写一条140字的微博——如果你一大早看我发一些莫名其妙的小感叹，那就是它们了。如果很多人转，我会自我感觉不错，收获些价值，这价值让我有动力写一篇博文或者专栏，而如果这个专栏或者博文反响不错，就会吸引我把它们扩展成一个章节。这当然需要更大的能力：篇章结构、考据、案例、荐书……当然，如果你能看到这本书、购买这本书，更大的价值也将汇入我的三叶草，酝酿下一轮的转动。 —反对派讨厌规划师，会说，你凭什么规划我的人生？崇拜者则会说，大师，请你给我一个详细的、精确到每一天该干什么的规划吧！这种人该轮到规划师讨厌他。 你真正能控制和衡量的，是自己的三叶草转动的方向和节奏，正如我在《拆掉思维里的墙》（以下简称《拆墙》）中所说的：成功就是越走越近。 推动大家的生涯“发展”起来，看到更多可能，然后选择一个，走下去。找到你的生涯三叶草的起点，然后推动它开始循环，它会带你进入你所未知的人生。 情绪比你会说话：找到成长的突破点 当缺失“兴趣”的时候，我们表现出“厌倦”的情绪，再严重点会开始觉得“活得没意思”；当缺失“能力”的时候，我们表现出“焦虑”的情绪，再恶化就顿生“无力感”；当缺失“价值”的时候，我们表现出“失落”的情绪，持续很久以后内化成“自卑”。 HR会给这个人三板斧：要不要休息一段时间？要不要团队拉出去团建一下？要不要找个人进来搞搞培训？实在搞不定的话，要不要调个岗？ 如果是厌倦带来的倦怠，休假的确是一个不错的方法，培训只会让他越来越烦；业务培训是焦虑的员工最好的治愈方式，但如果是虚头巴脑的企业文化培训，只会占用大家时间，让人更加焦虑；而如果是价值缺失带来的倦怠，休假只会让人越休越不想工作。 接纳自己是成长的第一步。当你读懂了情绪背后的需求，你就能找到自己成长的方向。厌倦需要变化，焦虑需要学习，失落需要价值。 因为知道不重要，改变才重要。 我天生就没有……兴趣该怎么办？ 兴趣的确有基因或者外在的因素，但是影响微乎其微。兴趣与其说是一种天赋，不如说是一种自我技能——那些生活得有趣的人，往往是下意识掌握这种技术的人，而我们大部分人可以通过有意识地学习，让自己活得有趣。一旦明白兴趣是门自我管理的技术，那么任何人只要下定决心，就一定能够活得有趣。 你的兴趣从何而来？ 心理学认为，兴趣是一种情绪，而情绪是人类进化出来的一种生存工具。这种情绪能够穿过百万年的进化留下来，一定是因为其有莫大的好处。 有趣（interested）是一种和不确定相关度很高的情绪；愉悦（comfortable）是一种和确定性相关度很高的情绪。而有趣和愉悦，是两种完全不同甚至相反的情绪——当一件事情复杂、新奇且不确定的时候，人们就会感到有趣；而当一件事情简单、稳定和确定的时候，我们就会感觉到愉悦。愉悦的事情，不一定有趣，而有趣的事情，不一定会愉悦。变态辣鸡翅有趣而羊肉串愉悦，创业有趣而公务员愉悦。 好生活=愉悦+有趣 它们温暖、简单、安全，带给我们幸福与愉悦的感觉。 好的生活应该是愉悦又有趣的。动画片的设计最能说明这个问题：为了让注意力时间很短的孩子坐在荧屏前一个多小时，即使可能没有心理学知识，动画片大师也都直觉般使用了这个愉悦+有趣的模式——在大部分动画中，总有一个复杂、新奇、或神秘或搞怪的二号人物，又有一个直接、温暖、简单的主角，如驴子和史莱克、流川枫和樱木花道、佐助和鸣人、豪猪和小狮子王，所以这些动画片既愉悦又有趣。 兴趣是一种应对成长中的“不确定”的情绪——当我们遇到了“不确定”，我们会下意识地躲回自己的舒适区寻求“愉悦”。所有的成长都来自舒适区之外，这样一来，我们永远也无法成长。这时候“有趣”的情绪会出现，帮我们渡过难关——此时大脑跑出来个小人挑逗：“多好玩啊，要不试试看？”于是我们继续前进，越过那些不确定。兴趣鼓励我们走出安全区，让我们变得越来越强，而世界变得越来越大。兴趣是成长的催化剂。 大人把孩子抛起来玩耍，孩子会先有些恐惧，但是一旦被接住，他就会咯咯大笑，笑声像广场上飞起来的鸽子。几次之后，孩子只要一被抛起来，就呵呵地乐。他开始穿越这种不确定性带来的恐惧，觉得有趣，他的勇气变得更大，他的信任感变得更强。 有趣和愉悦的界线，在于“不确定性”的程度。过于不确定的生活毫无愉悦可言，充满焦虑；而一旦不确定太少，日子又无趣得很，日复一日能淡出个鸟来。有智慧的人懂得调配出适合自己的“不确定”。有趣如菜里的盐，而愉悦如菜本身，如调配得当，管自己、做项目、办公司、治大国如烹小鲜。 好的生活应该是愉悦加有趣，适当的不确定。但是很多人对“感兴趣”的事情持有幻想，他们认为感兴趣的事情应该是特别快乐、舒适、天生就会的。有这种信念的人把自己玩得很惨——他们终生寻找自己“感兴趣”的事情，一旦遇到困难与不确定，就声称自己“不感兴趣”，然后闪人，寻找下一个“感兴趣”的事情。其实，他要的不是兴趣，而是愉悦。 如果是不愉悦，则需要做减法，找到核心价值，降低其他目标，进入一个相对简单、清晰的职业环境中去；而如果是无趣，则需要做加法——提高一些难度，或让自己进入更复杂、更不确定的职业环境。 像这位仁兄一样，我们常常因为白饭吃多了，就以为自己想以腐乳为生。我把这种现象称为“火锅效应”——如果你问一个天天吃家常菜的人想吃点什么，他会说：“火锅！我最爱吃火锅！”但是如果你抓他吃一个月的火锅——哪怕变着花样，他估计就会哭着喊着要回家了。最好的生活，是经常吃米饭，偶尔点火锅。 如果你真的希望生活过得特有趣，就让我告诉你兴趣的真相吧：兴趣不是那件让你舒舒服服就成功拿到结果的事，兴趣是那件让你白天痛苦地想、晚上睡不好、早上五点爬起来，一边苦笑着骂娘一边咧着嘴干完的事情。这才是兴趣本来的样子。 有趣是一种力量 “兴趣是最好的老师。”该如何用好这个老师呢？兴趣老师的第一种功能是推动你探索和发现新的世界，为未来做好能力储备。在人生每一个成长的重要阶段，兴趣都会提前到达，提醒你将要面临的阶段，帮助你搜集好要使用的信息和能力。正如心理学家Berlyne所说：“每多获取一分信息，就会让我们对未来的复杂、沮丧或者无助多一分保障。我们的神经系统选择在那些除了紧急要求（包括睡觉、休息）之外少有的自由时刻做些有趣的事情，这真是个最佳选择。” 兴趣的种子在小苗阶段被杀灭，怎么会开花？所以，如果你发现自己对某件事情突然感兴趣起来，先别着急评价这会不会浪费你的精力，有没有偏离你的规划，是不是有足够回报，留出一段空间，先让自己顺着这个兴趣走几步。这也许是生活对你的提醒。也许在模模糊糊的兴趣背后，有一个全新的领域在等着你。如果你千年朽木脑袋突然抽出绿芽，难道不是因为春天来了？ 高手在单调的重复中生成，求快不配做高手。 高手们为什么可以扛得住这样长达几万小时的重复和单调？研究发现，每个行业的高手都知道各种让无聊的工作变得更有趣的策略——邮差懂得吹着口哨打发骑车的无聊，搬运工懂得唱出劳动号子来应对肩膀的疼痛，训练场上的球员懂得隔段时间给自己挥拳打气，而几乎所有的IT公司都有荤段子文化——在写代码的时候猛讲黄色笑话——他们太需要一些东西抵御码代码的无趣。我的兄弟老杜告诉我，他听贝多芬写代码，不知道是有欣赏贝多芬的趣味，还是贝多芬也能听出荤味来。总之，高手们都觉得修炼挺有趣，他们是“玩”成高手的。 研究还发现，只是强调重要性并不会使一件事情变得有趣，过度的强调会适得其反。有趣的事情不一定重要，所以 学会让重要的事情变得有趣，才是关键。 理智带来的驱动力，永远没有情绪发动机——兴趣推动得有力。当我去学习太极的时候，老师告诉我，练太极最好的心态就是“玩”。艺术家们最才华横溢的作品，往往是在前期“玩”的阶段创造出来的。 爱因斯坦只说“兴趣是最好的老师”，却没有详细说明这个老师好在哪儿。现在我们知道兴趣是个人成长中出现过的最好的老师——它在我们人生面临考验前，提醒我们提前学习；它在我们讨厌重复学习的时候，提供有力的鼓励，让我们发展出知识与技能。 如何利用好这个老师？为什么有些人的兴趣老师温柔而坚定地一门课教几十年，而有些人的老师则抽了风一样天天给你开新课？请接着看，如何养大一个兴趣。 如何养大一个兴趣（一）：兴趣金字塔 关注每一届星云奖和雨果奖。在国内的作家里，刘慈欣的《三体》系列对我影响最深。我曾经自己写过一小段面壁者罗辑（《三体》男主人公）的外传，发在自己的博客上了，有两万多的点击量。如果可以，我很希望从事和文字相关的工作。 直观兴趣（又称感官兴趣），自觉兴趣与潜在兴趣（志趣）。 我们的感官兴趣正如乐曲中的小女孩，好奇、多变而不稳定。外界的刺激决定着感官兴趣的长度和强度，这是我们最动物的一面。也正是因为这样，感官兴趣让我们当时很爽，却又无法让我们集中在任何一个事物上，形成能力。正如你刷完一天微博，或者大吃一顿自助餐后感觉到的那样——没有什么留下印象。 自觉兴趣是认知行为参与的兴趣。 自觉兴趣比感官兴趣更高级，第一个理由是思维的加入，这让我们的兴趣可以更加持久并定向在一个领域，从而在脑子里形成回路，产生能力。而能力又反过来让我们能体会和学习更多。“能力—兴趣”的循环，让我们慢慢精通某项能力，打开世界。 一开始接触的老师似乎很普通……但他们在启动热情，然后把小火花培养成熊熊之火，他们教的是热爱。第一阶段的学习目标似乎是让学习者参与，并且沉迷其中，使他们想了解更多的信息和专业知识。” 有趣的人往往懂得主动发展更高层的直觉兴趣——兴趣推动学习，学习带来了行动，在行动中发展出能力，能力又发展出更大的兴趣。有了关于京剧的知识，你也许会开始享受京剧的韵味；有了更多关于葡萄酒的知识，你也许会发现除了兑雪碧还有更多好玩的喝法；学习词源和词根，词汇学习也许变得没有那么枯燥了。你学得越多，你能感到的乐趣就越大，这就是有趣之人兴趣持久的秘密。 养兴趣和养花一样，有人养什么活什么，有人养什么死什么。关键是让兴趣与能力循环。 当我们把兴趣的源头从外求转为内寻，我们就有了一个让自己变得有趣的内在泉源，自得其乐的人最无敌。 不，这群世界级的高手在自觉兴趣之上，发展出一种更加强大而持久的兴趣，去对抗高手之路上世界级的重复和倦怠。这就是人类最高的兴趣等级：潜在兴趣，也称为志趣。志趣的秘密不仅在于有感官和认知能力，还加入了更深一层的内在发动机——志向与价值观。 内控的兴趣、明确的方向与强大的动力。 就像登山家看到险峰、极限单车运动员见到陡坡一样。他的助手觉得无趣，因为他们的兴趣在于成功，而爱迪生的兴趣在于奥秘。当他一点点展开自然的图卷时，他越来越兴奋并觉得有趣——这才是他的动力之源。 知之者不如好之者，好之者不如乐之者，乐之者不如志之者。 上天给了我们有限的时间、有限的天赋，却留给我们无数的机会与诱惑。志趣让我们坚定地专心。 如何养大一个兴趣（二）：兴趣饲养攻略 兴趣饲养三步法：第一步，让自己先沉浸在足够多的感官体验中，获得兴趣的第一步动力。第二步，在感官兴趣还没有消退时，尽快掌握更多的知识，使自己的感官兴趣进化到自觉兴趣。第三步，给自己找一个兑换价值的方式，把这个兴趣和你最感兴趣的价值绑定。别把自己的目标设定得太高，以免产生失落感。不断地重复这个过程，兴趣就会慢慢固化下来。 用同样的兴趣饲养攻略，我们审视一下为什么很多人“想学好英语”，却永远没有真的成行。第一是因为他们并没有真正被刺激到，“学好英语”顶多只是一个“我应该学好”或者“我渴望好一点”的概念，而不是一个真实的、浸泡式的体验，一个清晰的、可见的愿景。所以一旦刺激消失，他们就该干什么干什么去了。第二是因为他们没有及时地研究关于英语学习的各种观点和理论，找到自己想要付诸行动的。今天听听美剧，后天学学语法，不成系统，也无法进步。第三点最关键——他们有些学了也没用武之地，没有价值的兑换。有些目标订得太高，如“一年之内学好英语”，但是什么叫学好？多好才叫好？这样的目标即使你背过整本新概念4也没法儿达到。所以，他们的兴趣无法持续长大。反观很多不会英语却被丢到英语环境里的人，他们为什么都能迅速学会一口让自己生存下去的英语？因为第一他们有被刺激的环境，第二有足够多的学习资料和机会，第三是他们的英语能马上兑换出价值。而且作为初学者，国外其实有比国内更宽容的环境，他们也不害怕讲错。集齐感官、知识和价值兑换机制这三种维生素，每个人都能养好自己的一个兴趣！ 为什么你活得无趣？ 在“有用”的人看来，有趣的人总是显得不安分、特立独行、乐呵呵、莽撞、好奇与想象力四溅，终日做着些“没什么用”的事情。有趣的人时常会听到这样的批判：找工作能赚钱啊！——旅行有什么用？能赚到钱吗？跑步能锻炼身体！——跳舞有什么用？能锻炼吗？考个会计证能加薪啊！——学画画？能卖钱吗？结婚就安定下来了啊！——谈恋爱搞浪漫？还不是要结婚？有什么用？ 无用的人生卑微，而无趣的人生悲哀。 一旦一个人把 是否“有用” 作为事情的唯一评价标准，那么这个人活得无趣就天经地义。这种功利与短视的背后，是深刻的不安全感与焦虑。 和这样的无趣之人对话特别费劲——你和他们谈起一个好玩的东西，他会先问你：“赚钱吗？”然后是：“好弄吗？”如果答案是肯定的，他又会问：“肯定吗？”这些问题只要有一个是否定的，他们就不感兴趣，转移方向。 当课堂外的一分一秒都充满了确定性，当每一个行为都必须在系统里置换出有用的结果，兴趣这个老师就彻底被开除了，随之而来的好奇心、想象力、创造力更无从谈起。 读书只求有用，就如吃饭只管饱一样——我干吗非要有用啊？！ 事情可能有用，也有可能无用；有趣是投资能力，而不是消费生活。有趣能让我们拥有越来越多的可能，同时也越来越生机勃勃。而无趣之人逐渐长大，世界与他们越来越无关了。 有趣是种活着的、元气淋漓的状态，有趣证明我们还年轻，还在打开新的世界，还在长大，没有长老。 兴趣攻略：避免活得太有用 Different Night要想在生活中创造不确定性，先要留出生命中的空白。 我们的大脑喜欢空白，一旦出现空白，就会把自己潜意识里迫切的东西填进去。每周给自己设定一个different night（第八夜），不要设定任何比如说“我要养成一个习惯”或者“要发现自己的兴趣”这样的期待；然后以自己最放松的状态投入，随便干点什么——你可以漫步某个地方，约一个不常见的人，或者参加一个此前不会参加的聚会，总之，做点不一样的事情。 与有趣的人待在一起找到身边你觉得有趣的人，和他们待在一起，看看他们业余时间在干什么。作为讲师，总需要出差。头几年还觉得有趣，看看名胜古迹，几年下来全国好玩的地方都去过了。但全国也迅速地变得越来越一模一样，我对出差开始厌倦。直到我有一天想：既然地方被扫荡完了，为什么不找有趣的人？于是我做了一张中国好玩的人地图——每一个城市，我都标出来自己想认识的人，出发前给他们私信，要求拜访。@秋叶语录老师就是这么认识的。我开始爱出差去武汉了。 不跟团的自助游 加入一个全新的兴趣小组 我们从读书时代迅速进入博客时代、微博时代、读图时代、视频时代。这都是为了满足我们永不满足的感官兴趣——一个接着一个，一个接着一个，不要停。请注意这种碎片化信息流的危险，它们无穷无尽、日益刺激、频率切换太快，这些都让我们没有时间深度思考，进入自觉兴趣。 人的注意力资源有限，当你的大部分注意力都陷入感官刺激的泥潭，你也就没有精力发展出那个兴趣金字塔的尖，取而代之的是，你把自己发展成一块板砖——知识面狂宽，但是肤浅得可怕。也造成了潜意识思维的短路，因而既阻碍我们进行深入思考，也阻碍我们进行创造性思考。 你的头脑像不像被轰炸的汉堡？每分钟传来的无数信息让你丧失了注意力焦点，在一天的“轰炸”后，你累得要死，却一架飞机都没有打中。当你习惯了一分钟的烟花，你就可能再也感受不到整夜的宁静星空了。 专业的寿司食客在每两个寿司之间，会吃一块姜片，让自己的味觉重新回到原点，才能更好地感受下一个寿司的滋味。而在每天的感官轰炸中，你也可以给自己一段静默时间，让自己有机会发动更高层次的兴趣。电子静默就是个好方法。 一眨眼一小时就过去了；感觉做任何事情都尽在掌控又流畅；精神高度集中，目标专注；把一切烦恼抛诸脑后；有一种高度的兴奋和充实感……你正停留在你的“心流”（flow）里面。这是兴趣发展的极致。在大洋底下有很多看不见的洋流，神驰。 你喜欢从事的活动；你能专注的且不会忧虑的；有清晰目标的；有立即回馈的；有主控感的；时间感流逝停止的…… 你想到了什么？男生想到了玩游戏，女生想到了购物。这些都是喜欢的、能专注的、有清晰目标和立即回馈的活动，如果你只看不买的话，也没有忧虑。所以男女各自能在游戏和商店里待一整天，完全感受不到时间流逝。如果工作也能像玩游戏和逛街一样，那该有多好！（想想一个无论如何也无法通关的游戏、陪女友购物刷卡的人、一项难度太高的工作吧），而如果能力太高但挑战太低，则会产生厌倦（比如把你分到幼儿园组踢足球）。 一开始我们要提高技能（A），但是一旦感到自己厌倦了，就马上提高挑战难度（B），一直到自己觉得焦虑，然后开始学习新的技能，一直到厌倦感又来临，再继续提高挑战难度。 游戏设计的原理：在一开始的时候先让你很容易升级，也很容易拿到点数，继而逐渐提高升级的难度，也让你掌握越来越难的操作技能。如果游戏设计得好，你会一直玩下去。只要你对于自己的状态有觉察，同时有足够的挑战和技能可学，让工作像逛街一样其实不难。好的教练通过心流设定学习进度，好的电影通过心流设计剧情和镜头惊喜，好的老师通过心流让课堂不知不觉地进行。而你能做的事情，则是找到自己心流通道的宽度、斜度以及工作方式。 外一篇：有趣的王小波《一只特立独行的猪》 智慧本身就是好的，有一天我们都会死去，追求智慧的道路还会有人在走着。死掉以后的事我看不到，但在我活着的时候，想到这件事，心里就很高兴。我对自己的要求很低，我活在世上，无非想要明白些道理，遇见些有趣的事，倘能如我所愿，我的一生就算成功。 证明有趣与有用无关，证明不管生活多平庸，任何人下定决心，依然可以活得有趣。 兴趣的总结：每个人都能活得有趣！●兴趣不是一种天生的属性，而是一种自我管理技能。人人都可以活得有趣。●调试你生涯中的愉悦/兴趣比例。●提高你的兴趣层级，越高层级的兴趣越稳固，对生涯的影响也越深远。●有趣杀手：太追求“有用”、感官轰炸、走出心流通道。 温度计，热水壶，漱口杯，雨衣和降落伞。如果我能够重来一次，我会到处走走，什么都试试，并且轻装上路。 如果我能够从头活过，我会延长打赤脚的时光。从尽早的春天到尽晚的秋天。我会更经常地逃学。我不会考那么高的分数，除非是一不小心。我会多骑些旋转木马，我会采更多的雏菊。 成长空洞——填满你内心的空洞 我们每个人都希望变得比现在更好、更强大或更美丽、更自信或更自在，我们心里住着一个完美的自己、一个“希望成为的状态”，这就是自我概念。你只有把现在的自己和自我概念做对比，才会觉得“不满足”。在每个对生活和自己不满足的背后，都是每个人成长的需求。 如果你是个愤怒青年，你就应该拥有一个世界应该更好的信念，当你觉得自己做什么都无法让世界变好时，你就会对这种无力感到愤怒；而如果你是一个自卑的人，你脑子里一定住着个不知道从什么地方搞来的、大到完全无法填满的自我概念，你真实的自我穿着17厘米的内增高再加上大号的垫胸垫肩才撑得起来，生怕别人看到真正的自己。不过，愤怒和自卑的人都不可怕，可怕的是那种对生活完全失去兴趣和意见的人。他们没有什么成长的空洞，自我概念裹在真实的自我外面，他们已经没有什么可能 成长的空洞让我们感到自己心灵的空洞，这空洞感就变成了“内心的需要”。你想要一间可容身的房子、一份适合自己的工作、一个爱自己的恋人、一个听话乖巧的孩子……这都是你填满空洞的需要。因为你的自我概念认为这些你应该有，而真实的你却没有——这就产生了你的需求。 理想和现实的差距产生了空洞，这空洞产生了需求。 所以愤怒都是空洞的，王小波说，所有的痛苦本质上都是对自己无能的痛恨。人生就是一个不断发现空洞、填满空洞的过程。 我们的基因、家庭、环境、社会文化与人生经历共同创造了现在的我们，也建构了我们的自我概念，这让我们生出大大小小、各自不同的成长空洞。这些成长的空洞构成我们对“值得”的观念和想法，价值观就这样产生了。 基因+社会与家庭环境=自我概念自我概念-现在的自我=需求 虽然成长空洞人人不同，但每个人的努力方向都一样——填满那些空洞，成长为自己的样子。看到自己的成长空洞，了解这些洞需要用什么填，在有限的资源中按照什么顺序去填，就是找回自己、理解自己、成长为自己的过程。 玩“假我游戏”的人 房子填满安全感的洞、钞票填满自尊的洞、学历填满智慧的洞、消费填满快乐的洞 被物质充满的人，逐渐会认为物质才是真的自我 如果你身处一个什么都用钱才能买到的社会，你自然会认为——钱最重要。难怪很多人会把一定数量的钱当作生命目标呢。你肯定自然而然地认为——财富、物质和尽可能的满足自己需求，是生命最重要的三个部分。拜金、成功学和享乐主义，三者合谋，构建出这个建立在物质之上的虚假自我骗局。用物质填洞的人最大的悲剧是：没有人的能力能跑赢欲望 总有一天，你填入了所有东西，却无力地发现，那个空洞还在。物质也许能带来短暂的一次次快乐，但绝非幸福。快乐和幸福，本就是两个东西。你占据的东西，也在占据你。 在我们成年之前，我们一直都在寻找认同。 经历过真正爱情或友情的人都明白，心疼才不是一种文学的比喻手法，那是一种真实的生理体验。两个人互相用对方填满了自己的空洞，他们如此紧密地在一起，待了那么久，像一对连体姐妹。日子一长，你把这些被填满的部分认为是自己的一部分。这种感觉如此美丽，就好像“两个灵魂在一个身体”，而等到关系结束，两个人不得不分开，这种感觉又会如此痛苦——这种分离带来的强烈的撕裂感，就好像要扯掉一个已经长在你身上的器官一样。古往今来，已经有太多文字、歌曲、戏剧等艺术记录了这种情感的美妙与痛苦。 你会感到安全和快乐——慢慢的，你开始认为这些都是自己的一部分。当你获得越来越多的人的认同，你就觉得自己在不断地“成长”，越来越“有面子有地位”。当这种外界的认同成为你自我的主要部分，你开始认为，那个“被认同”的部分、你的名声、地位，才是你真实的自我。从那一刻开始，你就被别人的认同绑架了。 被认同填满的人，逐渐成为认同者的绑架对象一辈子按照他们的意愿来生活。为了不失去朋友或同事的认同，甘心一辈子做没有主张和方向的“老好人”，不和任何人冲突；为了不失去大众的认同，名人们甘心做一个粉丝眼中完美的“假人”，被粉丝绑架。这并非善良，而是无能的表现。 如果没有意识到你心里的洞、从内至外地去修炼，这个轮回会永无休止。所以，亲密关系中，你是谁，你就会遇到谁。你若盛开，清风自来。 寻求“被认同”是社会构成的基石，但是一旦过度追求“被认同的我”，真我就会遍体鳞伤。尤其在我们这个提倡以和为贵的文化中，每个人都乐此不疲，玩得好的甚至被称为美德。不知道你怎么想，看着那些被称为早慧、年纪轻轻就八面玲珑的孩子，我总觉得可怜又恶心。 玩“被认同”的游戏并不是自我成长之路。当认同一次次填充进来，你会上瘾一样地享受着这种既快乐又自虐的快感，渴求更多的自我妥协。正如席慕容在《独白》里面所说： 在一回首间，才忽然发现，原来，我的一生的种种努力，不过只是为了周遭的人都对我满意而已。为了要博得他人的称许与微笑，我战战兢兢地将自己套入所有的模式、所有的桎梏。走到途中，才忽然发现，我只剩下一副模糊的面目，和一条不能回头的路。 慢慢的，你会发现其实你并不是世界的中心，其实你谁也不是。你只是为别人认同而活的工具。你以为大家都喜欢和离不开你，其实是你离不开他们的喜爱。 谁被夸的时候都很快乐，但是遇到批评或指责，很多人的反应总是破罐子破摔。 做得不好，暴露出你成长的空洞，而自残的人的回应则是彪悍地说：根本不是“我”的问题，不是我努力想做却还差一点，而是先天的问题、环境的问题，或者是我根本就不想做好！ 破罐子破摔的回应虽然暂时能让自己舒服，但是相应地，成长的可能性全部破灭。从此以后，这件事情不可能做得更好，而关系也无法向前一步。不仅这样，在空洞旁边，已经培养起来的很多能力也忽然被割舍——因为手臂上的一个小地方发炎，你不愿意面对，就把整条手臂都剁了下来。 这比喻虽血腥却真实，这也是为什么我把这个类型的“假我”游戏叫作自残的人——为了逃避痛苦，他们不断地砍掉自己真实的自我的各个部分，最后缩小到自己都看不上的地步，自卑是自残者的必然结果。 你放弃了痛苦，但也放弃了自己。 **人不见得比猴子好多少。我们总是挖健康的坑，来填事业的坑；挖自由的坑，来填安全的坑；挖自尊的坑，填成就的坑。当我们填坑的时侯，我们和早餐时的猴子一样，开心满足，认为这些都是白来的；而等到晚餐时分，当我们面对自己的坑洞时，会痛苦不堪，又希望挖下一个坑来填现在这个。比猴子的故事更加可悲的是，生命并不如果子一样是个零和游戏。有些坑一旦被挖出来，需要10倍的力量去往回填——比如健康、自尊；而有一些坑则再也填不回来——比如说青葱的恋爱、孩子的10岁生日会、你生命里的任何一段重要时光。 填坑的人常常集中在25~35岁之间，这阶段人的角色暴增，从单一的工作者和儿女，慢慢地加入管理者、丈夫或妻子、儿媳妇或姑爷、爸爸或妈妈的角色，每一项角色的增加，都意味着全新的自我概念，也意味着新的成长的空洞。这个阶段的人有太多的东西需要生长出来。他们一旦乱了手脚，就会从其他地方挖出一个坑来，填满眼前这个。事业出问题，牺牲身体；身体出问题，拖累家庭；家庭修补好了，孩子又出事；孩子勉强搞定，工作又开始亮红灯……挖了填，填了挖，你的生命就像一个永远无法停工的城市道路施工现场，四处救火，步步惊心。 我们渴望成长而产生空洞，我们用非我的东西填洞，我们逐渐认为填充物才是真实的自己，现在它们开始反过来占据我们，真实的自己被我们丢了。这就是虚假自我的游戏脚本。当你把“成长空洞”换成“钱、爱情、关系、认同、自尊”，再填上年代时间地点姓名，就构成了这世间的各种悲剧故事。** 那天是你用一块红布，蒙住我双眼也蒙住了天。你问我看见了什么，我说我看见了幸福。这个感觉真让我舒服，它让我忘掉我没地儿住。——崔健《一块红布》 来玩一场“真我游戏” 友谊和纯净的心才是真正的魔力。象征外界的魔力被销毁，而自己从心里升起真正的魔力，这就是一个魔力失去后自己重新找回来的故事。 失去、痛苦、面对、追寻、重获，这就是所有成长的脚本。 给自己来场成人礼！ 你必须脱离他人的认同，置身于真正的孤独，独立完成艰巨的任务，你必须学会自己认同自己，与自己独处。 成长就是一个完整的失去、痛苦、面对、追寻、重获的成长脚本。 在我们今天的社会里基本没有真正的成年礼，家长像宝贝一样拽着我们，一直到自己实在拽不动为止。而很多孩子不仅物质上啃老，在精神上也从未断过奶。 你经济不独立，精神不独立，失去家人的认同，你连事情都做不了，你还好意思说自己成熟？你父母的判断非常正确，你的确不成熟，你空有独立之心，却从来没有长大到能践行你的思想。 有人说旅行有三种意义：看风景，发现可能，还有找回自己。最后那种，就是成年礼。 年轻的时候，不管是读书、游历、交友、搞对象还是读大学，野得越远越好，这种远不应该仅是地理上的，更是心理上和文化上的。我同情那些一出生就生活在最大最好的城市里，觉得这里最好哪里也不愿意去的孩子。他们从来不明白，长大在远方。 拥抱变化，走出舒适什么样的人永远不会成长？第一是自我概念已经和真实自我完全重合的，他们完满了。第二是虽然有成长的想法，但是不愿意冒险的人。他们怕疼，怕冒险，所以他们从来不愿意尝试自己不懂的事、玩自己不确定能赢的game（游戏）。他们先为自己玩不好的游戏找出各种理由，然后安心地躲在舒适区，只玩安全的游戏。 你会很容易发现人的惰性本质——人们总是愿意在把握程度高的事情上反复花时间，而在真正重要的事情上不用力。慢慢的，他们自己停止了成长，然后找几个借口把重要的事情敷衍过去。不冒险其实是最大的冒险。要持续舒服的最好方式是让自己不舒服。 空洞里的填充物离开，你失手、失败、被抛弃、被生活欺骗、被事情淹没。这时候，痛苦、羞愧、后悔百感交集，像在大广场被扒光了衣服一样尴尬。但成长者并不会着急用别的东西掩盖和填充。他知道痛苦不来自填充之物，而来自自己对成长的渴求。一旦填埋这些空洞，真实的需求就会被深埋。接纳自己此刻的空洞与无能，是成长为自我最重要的一步。 成长者允许痛苦发生，好奇地看到空洞的底部真实自我的袒露，他理解每个痛苦都源于强烈的成长需要。最好的方法是努力让自己从底部向上生长，把这个洞填满。自我成长者总是能够读出空洞背后的成长希望——他们知道，失落越大，空洞越大，背后的力量也就越强大。 你永远也不知道自己有多坚强、勇敢和努力。如果没有那段经历。 愤怒带出无能的空洞，也告诉我们需要提供能力。失恋带来无价值的空洞，也让我们需要努力爱自己。厌倦带来不新鲜的空洞，也提醒我们生命需要更多可能。正如每一次新生都伴随着母亲的痛苦，每一种痛苦都是新生的启示，你要学会读懂它。 见过孩子玩过家家游戏吗？他们全情投入，扮演老鹰的人不可一世，而扮演小鸡的人则吓得吱哇乱叫。他们知道要全力投入，要努力获胜，才能享受这个游戏。但是等到游戏结束，他们又嘻嘻哈哈地在一起，完全看不出老鹰小鸡的区别，他们知道，游戏的目的是为了“好玩”。 **我们的关注点便从麻木的、患得患失的虚假自己，变成了真实的、慢慢成长的自己；我们计量自我价值的方式，也就从物质、成就和他人评价，转变为自己的成就感、充实以及学到的东西；当我们的立足点从不可捉摸的外界和他人观点，变成了稳定宁静的成长需求，当我们自己不立于流沙之上，就能看到实情——什么时候你该更投入，什么时候你可以撤回来。当成长比成功更重要、过程比结果更重要、价值比价格更重要时，你就拥有了看透却不看破的心态。 这种转变创造出一种更大的格局和智慧：以入世的心态来玩，却以出世的心态来发现价值。这格局孕育着更大的成长速度，成功是成长，失败也成长。** 期待我们幸福，又懂得用自己的方式寻找自己的幸福；当我们看到一个洞出现，我们不着急在其他地方挖一个洞填上，而是找到生命的重心，寻求平衡稳定。 马斯洛不是也说吗，人生的巅峰体验来自“成长的过程中牵涉到自我与环境的配合……是‘内在需求’与‘外在需求’一致、‘我想要’及‘我必须’之间的协调。唯有如此，你才能自由自在、快快乐乐、全心全意地拥抱自己的志向。你的命运就是自己的选择及意愿。 当我们说一个人的内心强大，就是指这种永远能站在真实自我之上，对于痛苦强大的洞见和选择，在不确定的结果背后确定的价值汲取能力。 真我游戏的修炼者终生在自己的道上修习这种能力，他们在任何情境中，都能收获自己想要的价值。 这样的人在顺境中成长，在逆境中也能成长；在富足的时候幸福，在困苦的时候也幸福； 亚当夏娃的价值观童话 单反穷三代，苹果毁一生 记得彼此尊重。死亡是人类最好的礼物，当生命有了限度，每个人的价值就会浮现。 马斯洛需求高管会 我到底希望做一家什么企业？如果要做这样的企业，这家企业最核心的竞争力是什么？对比现在，我最缺什么？ 一个清晰的价值观，能让你重新管理你的需求，重新掌控自己的人生。因为自我概念决定了你的空洞，所以当你决定你希望成为什么样的人的时候，你就确定了什么对你的生命有“价值”、什么是“值得”做的；当很多事情都值得做的时候，你必须选出“最值得的”，这就是你的“价值观”。有了价值观，你就找到了成长为自己的样子的最佳路径。 价值观——给生活来点定见！ 春雨老师的价值观就是买手机吗？当然不是，他的价值观是新奇。“新奇”是一种抽象的目标，新手机是这个价值观在现实世界的具体目标。具体目标会随着你的行动和环境改变。如果春雨生在非洲大陆原始部落，就会满脑子琢磨怎么搞一只火烈鸟春天生出的最新鸟蛋。 他的“价值观”马上就会改变——在那里，钱不值一文。 价值观来自对内心感受的评价，没有对错，只有真实与否 社会流行的价值观。有的高尚点变成了“道德”，有的有地域“风俗”；有的很重要，被强制执行，叫作“法律”，你和小伙伴之间定的叫“规矩”，还有些三天两头变，叫作“流行”。 当你开始学会自己认同自己，他人认同也就没有那么重要了。所以特立独行的人只有两种：内心强大到不需要认同，或者自卑到认为大家都不可能认同。当然，做前者好些。 一旦了解了价值观与情绪的关系，你就能明白为什么符合价值观的东西会成为你的核心发动机——来自情绪的动力比来自理智的动力强大一万倍。回顾一下你的赖床经历就能明白，如果你“不想起来”，你的大脑就会飞转，给自己找到千百种理由继续赖着。但是如果你有一件“特别想去干”的事，你根本就睡不着，清早醒来，绝尘而去。 我翻译的《适合比成功更重要》中提到，价值观（value）来自拉丁文词根valeo，意思是“坚强起来”。当你找到真正有价值的事情，任何胆小的人都会坚强起来。即使看似温驯的小动物，也会在保护幼崽的时候变得强大无比；胆小的人在遇到自己坚守的事情时会变得坚忍强大。为什么伟大的公司必须有伟大的价值观？因为伟大之路障碍重重，非坚硬的价值观不能破。所以该走哪条路才能成功？走你“最坚硬的一面”的路。 一旦一个人习惯于集体主义的环境，他们就很难区分“道德”和“价值观”，因为在他们看来两者是完全一致的，单一价值观和极端集体主义都会狠狠修理任何与道德观不同的价值观，一直到大家都老实为止——这个时候，“对的”就是“你应该”的，你应该的，为什么你还不做？ 比如许多中年人，当他们认定一件事情是“对”的，就会持续地要求你去做，并且对你的不作为感到发自内心的诧异和困惑——既然是“对”的，你怎么可能“不愿意”呢？ 仔细听他们说话，你就会发现他们的逻辑，先努力在脑中找到一个道德原则，让自己先爬到高处，然后转身以此要求你——如果不听话，就受“这是不对的！”的道德折磨、良心审判吧！比如我父母想有个小孩子玩，就绝不会说我想玩小孩，你快给我生一个，而是从“不孝有三，无后为大”，或者“让爷爷在有生之年四代同堂”，或者“我们的朋友都说30岁以后生孩子对身体不好”开始。 我从来不希望我父母改变，没有被烦到的时候，甚至还觉得好玩。因为他们也是受害者。在小时候，别人就是这样要求他们的；而当他们长大，他们也是在内心这样战战兢兢、如履薄冰地审判自己。道德是个好东西——但他们是被道德绑架的人。 价值观就是“什么是重要的”和“这些东西之间有什么关系”的观念 什么比什么更重要？到底是“精彩的生活”还是“助人”重要？每个人都有自己的观念。这就是“什么是重要的”。 到底是“智慧”有了，就会有“自由”，还是只要足够“自由”，就会产生“智慧”？“安全感”和“精彩的生活”是冲突的吗？有人说年轻要努力赚钱，老了才自由，还有些人说年少要游历，别总想着赚钱，到底谁是对的？关于生活，每个人也都有自己的想法，这就是“它们有什么关系”。 这种关于“价值”的“观念”，感悟、形成、冲突又汇聚，最后慢慢稳定下来，形成你的稳定的价值观，也就是你对生活的“定见”。 She is not Rachel.（她不是瑞秋。） 剧集会结束，红颜会老去，而生活中的真实关系，会面临比电视剧中更复杂、更琐碎的麻烦，只有最坚硬的价值观才能抵御。 “冒险是人类精神皇冠上最伟大最闪烁的一颗宝石”，但我们还是不敢冒险。 压了葫芦浮了瓢，哪壶不开提哪壶。生活是个系统工程：如果过于钻牛角尖，往往就会忽略现实的其他因素；但如果过于散焦，又会牵绊太多，什么都得不到。这时候就要探讨价值之间有什么关系。最高效率实现的价值观系统，就是最好的价值观系统。 想宽些，要生一个孩子，除了钱，还需要什么？思考之下不难理解，还需要身体、心情、出国时机，甚至是父母亲的身体状况等。想深一步，要生一个孩子是为了实现自己什么价值？追求的也许是自己心目中的“社会认同”“内心和谐”。这个价值观系统如下图： 西谚“小心你的梦想实现”就是这个意思——实现了却发现这并非梦想，比无法实现梦想更加可怕。 人要活得明白、活得清爽，掂量得出好歹，就需要反复打磨自己的价值观系统。 阅历阅历，第一需要经历，第二需要审阅。前者只能自己使劲，生涯规划师则可以加速后者，帮你照镜子，帮你更快地了解自己，不需要栽太多跟头。 重要性让你按照你认为的这些价值的重要程度排列：有什么是不可或缺的？有什么是没那么重要的？哪些即使不太满足也能生活？哪些是一旦抽离就会让生命大楼坍塌的？保护好最重要的，找机会做次重要的。 从价值观来看，真实比伟大更重要。太极拳经云：守正出奇。一旦重要性确认了，我们就能找到生活的重心，一旦守住了重心，其他部分的价值缺失，即使摇摇晃晃，也能回来。 就算会有一天/没人与我合唱/至少在我的心中/还有个尚未崩坏的地方——五月天 舒适的生活：一种充足丰富的生活家庭安全：家人的身体、精神安全自由：独立与自由地做选择健康：身体和心理健康家庭安全：家人的身体、精神安全健康：身体和心理健康快乐：一种享受和闲暇的生活自尊：自我尊重成就感：持续地有所成就智慧：对生命的成熟洞见 你心中无数次预演这个情景——你推开键盘，冲着老板大吼一声：要加班，毋宁死！但当你听到背后有脚步声、屏幕上有身影闪过，就马上转过身去堆起笑脸说：“老大您来啦，我这儿正忙着哪。”当看到自己的价值观与别人不一样的时候，我们开始焦虑，偷偷地调整自己的价值排序。这种人其实有一个最深藏的核心价值——你把“认同”排在第一位。 一旦把“获得大家认同”的价值观放到首位，就等于你把“永远随着别人的要求来委屈自己”作为生命的必然脚本，而你如果决定出演这么一场戏，你死得一点都不冤。 8. 为什么你总不知道自己要什么？ 完美主义你有一个虚幻的价值观叫“完美”。你希望“既可以要到这个，又可以保持那个”“既学好，又不难”“既可以获得，又不用付出”。 一个选择了“完美”的人，就是选择了“不损失”的人，背后真正的价值其实是“安全感”。因为值得去的地方永无捷径，困难重重，所以这种人也就是间接选择了“不可能”或者“累死你”的人。 面对问题—安全—求完美—纠结不选择—拖延—事情变糟糕（要么就是必须选一个，要么就是两个都选不上了）—自卑—更不安全 安全感是重要的价值观，但是完美并不指向“安全”——因为所有的完美都是减出来的，而不是加出来的。不用取舍的完美不是一种目标，而是一种幻觉——即使生命真的有完美存在，那也是在做出巨大的付出和牺牲之后留下的东西。 只要这样，本身就是价值。 1000万—大房子—对老婆有交代—不上班看书—智慧不孝有三，无后为大。你只有早点生孩子才算孝顺！（生孩子—孝顺—认同）没有事业的男人叫什么男人？（事业—男人？）劳斯莱斯，成功人士的选择。（名车—成功—有能力）你上这么个二流学校，都不好意思跟人说！（学校—社会地位）在北京收入至少要一万二，才有可能活得像个人样！（钱—舒适生活）钻石恒久远，一颗永流传。（钻石—爱情）办了健身卡，你就能有健康的体魄。（服务—健康）爱她，就请她吃哈根达斯。（冰激凌—爱情） 比如父母对你说：“成绩真好！真是我的好孩子！”你强化的就是“成绩认同”。这样的孩子会努力在各方面做到最优秀而期待认同，想象一下他们在不以成绩定对错的职场、感情中感到的无助——他们努力提高成绩，却发现并无认同；他们甚至不知道该提高哪些方面来获取认同——他们越努力就越远离。 社会也在反复地给我们输入各种价值观链接，比如深深链接在我们内心深处的农业社会的乡土价值观“房子—安全感”，再比如在商业文化冲击下形成的“有钱—幸福”的价值链。这些链接如街道纵横交错，变成我们心中的世界地图。 这些价值观系统在我们生命中，有意、无意、善意、恶意地被传达、固化，并无数次被强化，就像分子的结构组合，在我们生命中慢慢地固定，形成 我们对世界的看法（世界观）以及如何应对的心智模式（人生观）。 如果缺乏有意识的觉察，我们不仅不会主宰自己的人生，反过来还会被这些地图主宰，带到沟里去。可悲的是，我们还一直以为那是自己想要的。 如果我们把过去的路标认为是唯一的通途，通还好，一旦不通，人生就会越走越窄。 我们需要明白路标并非终点，目标并非目的，月亮并非手指。我们可以走不同的路，达到最终的目的。 成为智慧的人，除了在家里看书，还有很多很多方式。一个追求智慧的人，在生活的任何空隙都能找到智慧；他也能意识到，除了买座大房子之外，还有很多方式让太太满意。最后他也许会发现，智慧之路其实并不遥远，生活和工作中有各种通往智慧的路：可以在下班路上坚持听自己喜欢的有声书；可以空出陪客户喝酒的一天时间去附近大学蹭课；可以和太太做一次深谈，发现她最需要的其实是多陪陪她……他可以在这样的宁静和充实之下，慢慢地成为一个智慧的人。而且有这种心态的人，赚到1000万的概率也会大很多吧。 真的高手，总在城市的任何角落，找到回家的路。 9. 假如你迷失了梦想的路但在真正的生活中，为什么人们总是只看到手指呢？甚至骑单车去。当找到手指背后的月亮，然后从月亮往回看，你会发现条条大路通罗马。生活的高手最常用的招数，就是“价值探戈”。探戈你没跳过也一定见过，先后退一步，站稳重心，然后找到节奏向前走一步。还记得前面谈到的价值链吗？比如“钱—幸福”“房子—安全感”“公务员—稳定”“早结婚—父母安心”。当你想达成的目标暂时无力达成，不妨在价值链上后退一步，想清楚自己到底要什么，然后再找到可以实现的方式，向前一步。 成功是一个重要的人生目标，但是如果你找到“世俗成功”背后指向的“成就感”和“幸福”，你将意识到，成功的经历带来成果，而失败的经历带来智慧，不管成功与否，都不要因此丢掉自己的幸福感。 生活如城市的街道，街道不会欺骗你，只是你自己会迷路，忘记为什么出发。当洞见了目标与目的、路标与终点、手指与月亮的关系，别忘了在绝境时跳这曲探戈——我们每个人都能在或丰满或干瘪的现实里面，吮吸幸福，找到自己的人生价值。 10. 生活高手的价值探戈什么是生活的高手？真正的生活的高手掌握着这种技能——让自己在任何资源和方式中，都能吸吮到自己想要的价值。这是一种生活的修炼，有了这种技能，你就能随时活得幸福。 越是生活的高手，他们越能找到各种通往价值的幸福之路，而这条幸福之路越不依赖外物，就越容易到达终点。没有可能，他们就用资源创造可能；没有资源，他们就把自己当作资源；即使一切都没有，他们依然可以选择面对苦难的态度。 而所谓强大的内心，就拥有这样一种技能，这种精神正如沙漠里盛开的花朵，它们无法选择自己播种的地方，于是深深地把根插入干涸的土地，吸取每一分养料。热爱生命的人，也应该有这种勇气、智慧和技术。 晚年的奥黛丽·赫本说：物质越丰裕，我要的越少；许多人想登上月球，我却想多看看树。 I Went to the Woods——（美）亨利·戴维·梭罗I went to the woodsbecause I wanted to live deliberately.I wanted to live deepand suck out all the marrow of life！To put to rout all that was not life…and not，when I came to die，discover that I had not lived. 我步入丛林，因为我希望认真地活。我希望活得深刻，吸吮生命中所有的精髓！把非生命的一切全都击溃，以免，当生命终结，我却发现自己从未活过。 定见的修炼 明白了，当我明白我要不成荷塘其实是因为我要了电影，心里就舒服多了。这就是知足吧。永跃若有所悟。知足常乐。这就是舍得之乐。舍得：吃饭＞电影＞荷塘 不完美的 完美，平衡之乐。 付出：疯狂付出，换回来所有——吃饭+电影+荷塘 价值观冲突只有三条途径：舍得、平衡和付出。如果你既不愿意放弃，又要完美，还不愿意付出，那就只好等待奇迹出现——对此奇迹也表示很无奈。 什么是好的选择？付出自己最能付出的，换回来自己最重要的，就是好的选择。 生活中只有一种英雄主义，那就是在认清生活真相之后依然热爱生活。——罗曼·罗兰 梦想与他人的期待冲突怎么办？ 我把那些指向你的目标价值的建议，称为“给我的建议”，把那些其实是指向别人的目标价值的建议称为“他对你的期待”。你甚至可以将其简化为“他建议我”和“他期待我”。 当我们涉世未深时，大部分人会坚信别人的建议就一定是毫无私心的“给我的建议”，所以当发现背后还有“他期待我”的时候，我们会愤怒失望，觉得被欺骗和背叛了。慢慢的，我们习惯了，却又偏向另外一边——我们认为别人的建议一定另有其意，不会那么简单。 其实大部分情况下，别人的建议都带有“他建议我”和“他期待我”的因素，一旦想到我们自己都经常驾驭着欲望干点傻事，你就可以对别人的动机释然了。关键是接下来你对待这些建议的态度。 事实上，我们不可能同时满足所有人的要求，最后的方案只能是谁闹得更厉害、谁的声音更大，我们就听谁的。在不同人的期望和建议中，我们疲于奔命。这深深伤害了你最好的朋友——“你自己”。当别人打着“为你好”的旗号伤害“你自己”这个朋友的时候，你不仅不让他躲开，还按住他说：“别还手，这都是自己人。 不管你要对爸爸妈妈、亲亲爱爱，还是小强小明好，第一步都是照顾好自己，因为这一切都是通过“你自己”来实现的——一个伤心的母亲不可能教育出快乐的孩子，一个无奈哀叹的女子不可能带来家庭幸福，一个不幸福的上司也不可能带给下属幸福——一个对自己都不好的人，难道还期待他们对你比对自己好吗？ 叛逆和成熟最大的区别，在于前者并无主见，让往东偏往西，让往南则往北；成熟者则内心有定见，如果你说往西，他会继续往东，而如果你说往东，他仍继续往东。 13. 谢谢你，但我有更重要的事情要做生活的智慧能让我们游刃有余——不是每个期待都需要被满足：我们可以接纳他人的期待，但并不一定要满足它们。 生命不长，你会遇到很多很多的期待，但是能够满足的只有不多的几个，你会把谁的、哪些期待排在前面？我喜欢美国心理协会会长塞利格曼（Seligman）的说法，他认为人生只有两个时期，一个是扩张期，一个是收缩期。他这样描述一个人从第一时期进入第二时期的转变：“你慢慢发现，你接触过的事物、你所爱的人，并非达成任何目标的手段，而是以这些事物本身为目的。你对那些新鲜、疯狂的事情不再感兴趣，你离别人的期望越来越远。” 谢谢，这很好，但是我有更重要的事情要做。 14. 成长为自己的样子正如我们在真我假我游戏中说的那样，找到的迟早会丢掉。自己的样子不是“找到”的，而是“生长”出来的。这种对于自己想要的生命的坚定想法，我称之为“定见”。 你是否也有过这样的经历？你曾梦到过你想要的生活，你曾见过自己的梦想在别人身上实现。这一切打动了你，也打开了你的幻想之门。你有那么一瞬间，那么清晰地确定过自己的渴望……但是当你从幻想中清醒过来时，你沮丧地发现，那只是一个梦，而你只是一个距离目标很远的人。别沮丧，那是定见的第一层修炼——体验。我们需要在生活中遇到自己的价值代表，然后体验它。 定见的第二层修炼：确认。 一个人总在推动身边的人去做某事，其实那是他内心未竟的愿望，他只是暂时缺乏勇气自己主张——但是当爸爸问他要去哪里时，他会说：“我要去……卖面条。”阿宝爱他的父亲，不想让父亲失望，几分钟后，他背上那愚蠢的面条车，出发去看神龙武士。 就像阿宝一样，当我们对生活有了自己的见解，却没有勇气公开表达，我们就遇到了定见的第三层修炼——主张。当你知道自己想要什么时，面对那些渴望的眼睛，你敢公开主张吗？你敢向父母主张自己的生活吗？你敢向领导主张自己的观点吗？你敢向同伴主张自己的与众不同之处吗？又或者，当与众不同成为一种潮流，你敢主张自己的平凡吗？主张是我们定见修炼的重要一关，决定我们是成为一个心怀不满、内在分裂的人，还是成为一个愿意尝试、身心如一的人。 在你第一次主张之后，命运之轮开始转动。在你第一次主张之后，压力与斗争也随之而来。害怕冲突的懦弱的人，无法前行。 定见的最后阶段——践行。阿宝也想过放弃，他曾半夜逃下山未果，曾想过与父亲一起逃难，但是最后他依然坚持下来，成为自己希望成为的样子。践行这个阶段的最大困难是——我们总在等待一个救世主出现，其实到了最后，我们发现，从来就没有救世主——我们必须亲身践行自己的生活选择。正如特蕾莎修女所说：“不要等待谁来带领你，先独自去做吧，从一个人到另一个人。” 体验、确认、主张与践行带来我们的定见。 我们总羡慕英雄横空出世、内心坚定，可我们真的不知道一个人曾经要多么在意，才会显得毫不在意。定见意味着一次次地发现、确认、主张、践行，生命不息，修炼不止。没有人会说做自己是一件简单的事，但是每个走过的人都说真的值。 成长，长成为自己的样子。 守住自己的底线 请记得向对的方向迈一步，因为当你开始迈出这一步，这个世界的光明就变得大了一些，当越来越多的人迈出这一步，世界就会变得越来越好。而如果每个人都在这时候躲一步，世界就会变得越来越黑暗。 自我概念与真实自我之间有成长空洞，这空洞产生了需求； 虚假自我的游戏总是失去—填充—假我—失去，而真实自我的游戏是失去—接纳—追寻—获得；价值观是关于人生什么是“重要的”“值得的”的观念。它包括“什么最重要”和“它们有什么关系”。价值观的修炼在于：发现自己的需求，理解这些需求，选择自己的生活方向，并在实际生活中体验、检验和践行这种选择，形成对人生的定见，并且修炼出在任何情况下都能获取人生价值的能力。 外一篇：这世界有普世价值吗？ 分配者和回应者都需要面对自利和追求公平的权衡，他们都需要在内心回答一个问题——你愿意损失多少私利来追求公平？ 无数证据说明，我们渴望获利，但是我们同时也渴望公平，人类并不是被自私占据的种族。 研究结果显示，同卵双胞胎不管是作为分配者还是回应者，都有显著的相关性，而异卵双胞胎则没有显示出相关性。换言之，对公平的诉求，深深根植于人类的基因之中。 人类文明的六种共同美德 知识、技能与才干——能力全息图 能力也是一样。当我们看到了高手的能力的全貌，我们会大大加快自己能力的提升速度，成为顶尖的高手。 知识：我们知道和理解的东西，广度和深度是评价标准。技能：我们能操作和完成的技术，熟练程度是评价标准。才干：我们无意识使用的技能、品质和特质。有强烈的个人特色，无评价标准。 知识：生涯理论基础、多年积累的案例、大量的阅读技能：写作能力、分析与综合能力、概念化能力、数据收集、沟通能力（如和插图画手）才干：好奇心、幽默感、求真 不同的人其风格千差万别：如果你写作能力强，你文章的阅读快感就强一点；如果你逻辑能力强，你的文章就精练一点；如果你数据收集能力强，你的文章就会有一堆好例子；如果你优势在于沟通能力，插图画手能彻底领悟你的意图，插图就会好看一点。这些技能每个人都在认真练习，也都能学得差不多。但是才干层面则完全不同，王鹏的实用主义、赵昂的洞察力、老马的犀利、春雨的文艺、我的嬉皮笑脸，这些风格我们谁也置换不了，因为我们从小就开始练习啦。 如何炼成某一领域的高手？ 只要你的搜索技术好，基本上大部分知识是廉价甚至免费的。其次，搜索技术改变了知识存储的方式，人们只要记得关键词，知道在哪里找就好。最后，这个年代的人面对太多全新的问题，相关的知识也不断更新，以至于无法知道哪些是被验证过的、哪些是扯淡。这就需要我们有独立思考的能力。这个年代，知识的差距转向了能力的较量——搜索能力、好奇心、独立思考能力——谁能在同样的知识海洋中学得更快、更多、更精准，谁就容易获胜。 拐个弯，谈谈中国式英语教学的问题，他们把英语当成一种知识来教——你清晰地知道［θ］是从喉咙发出的气流通过上颌冲出唇齿之间摩擦发出的清辅音，但是你不一定能发得标准。你可以对虚拟语气的12种可能了如指掌，但还是无法脱口而出：如果我是你，我死了算了（If I were you，I would rather die）。 语言是技能，而不是知识。知识能学到，而技能只能习得。 知识学习是瞬间的，知道与不知道之间几乎可以瞬间转变。技能则需要漫长的笨拙期——如果你不接受自己笨拙的开始，你永远也不会学好任何技能。也正因为这面心智之墙，很多知识优胜者死死不愿走入技能的练习领域。这也是为什么“好学生”往往不如“坏学生”混得好的原因——“混社会”是门技能啊。 明星有“明星感”，老师有“个人魅力”，商业决策者有“精准的直觉”，一流的运动员有特殊的“节奏”，好的员工有天生的“责任心”，这些不一定是“天赋”，而是经过大量技能练习后，才干与天赋交融的体现。人家是练出来的。 才干如此“自动自发，习焉不察”，以至于很多人从来不知 剑招—剑术—剑意对应到职业生涯里面来，就是“知识—技能—才干”。这么短的时间里，“如何出剑”的知识和“出得熟练”的技能，显然不可能马上掌握，只有传递“剑意”才能成功。而才干的核心，就是自动自发、无知有能，所以“剑招”忘记得越干净越好。 上乘武功的才干一致，技能相通，只是知识略有不同。正如当你站在17楼往下看，你就一定会比楼下的人明白，去某个公交站怎么走。当你在某一个领域做到顶尖，你就会很容易掌握另一个领域的知识和技能，在外人看来，就是一通百通了。 真正的高手，就是这样炼成的。 只有结合了生涯和写作的技能，才干才能外化出职业能力——才干才有了被识别的价值。 如果你只是希望通过找到天赋少付出些努力来超车，你就根本没有资格谈天赋。 好不容易炼出来的专业浪费了怎么办？ 知识是最没有迁移能力的，即使你读到了医科博士，也照样不一定会做麻婆豆腐，隔行如隔山，说的是知识的差距。 但是到了技能层面，事情就变得不一样了。大部分职业技能都由70%的通用技能（如运营、执行、营销、沟通、管理）和30%的专业技能组成。你完全可以把以前学到的技能迁移到新的工作里使用，再加上新学习的技能，工作就能迅速上手。职业与职业之间并无太大的差距。 而到了才干层面，职业之间的界限完全被打破。不仅是职业的界限，工作中培养的才干会蔓延到你生活中的每一个方面，你不想使用都不行。 彼得·德鲁克在《管理的实践》中说，他认真地研究了当时（20世纪50年代）大学中所开设的课程，发现其中只有两门对培养管理者最有帮助——短篇小说写作与诗歌鉴赏。诗歌帮助一个学生用感性的、富有想象力的方式去影响他人，而短篇小说的写作则培养对人及人际的入微体察。诗歌和领导力、写作和管理，虽然知识和技能都相去甚远，但在才干上高度一致。 这门学科带给我理科生的思考框架、工科生的实用观——这让我在研究生涯的时候，一方面不会太文艺（我已经够文艺的了），能区分科学和忽悠；一方面很注意实用的技术，我宁愿设计一个简单能用的模型，也不愿复杂得谁都不明白。 我的MBTI（迈尔斯—布里格斯个性类型测量表）老师一直好奇我作为一个ENFP（外向、直觉、情感、感知，一种人格测试的术语，简单来说就是“伟大的激发者+著名的不靠谱者”），为什么对细节、字号、颜色、字体有那么多设计要求。她认为这和我的人格不符。我会告诉她，这是我在一个格子间里每天改12小时设计图，就因为一个破字号或者线条就需要重新返工练出来的吗？估计就是在那时，我人格分裂了，一个说：“我要做伟大的激发者！”一个说：“别瞎想，图又来啦，你还是靠谱点吧！” 《星际争霸》是使神族的吗？什么时候防守，什么时候进攻，什么时候攀科技树，什么时候开分基地（公司），都有规律。当下即道场，把经历炼成才干带走，怎么会浪费？ 职场的技能迁移策略 “如果我努力做好现在的工作，把能力炼得很好，可万一这不是我要的工作，那怎么办？”“如果你努力做好现在的工作，赚到了钱，万一这不是你要的工作，那怎么办？”我反问。“那我就带着钱走，换下一份工作呗。”“能力也一样。”我告诉他。 你到底适合哪一棵树呢？你总得做几次模考，才知道考试大概能考多少分；你得玩几局，才知道自己适合玩哪个英雄，是不是？职场这棵树也是这样——枝繁叶茂，你站在下面，永远只能看到上面几米的风景——如果你不试着爬一爬，你永远也不知道自己适合哪棵树，即使你在树下做再多的测评、看再多的帖子，也不行。很多人都在树下等待一个最好的答案，等到某一天被当年的同龄人的“猿粪”砸到，才追悔莫及。 如果不试着爬几米，你永远也不知道自己适合哪棵树。一旦你开始决定爬几步，那个问题又开始浮现出来：万一我跑到树顶，发现不是自己的树，那我岂不是在浪费时间？ 我们可以很容易地从一个行业转入另外一个行业，而不需要从头来过，这个技术就是：技能迁移。 以前一维到头的工作观可以改变——只要你懂得技能迁移，就可以从一个貌似完全没有关系的领域，一步步迁移到自己喜欢的目标职业。 横跨七个完全不同的行业，一点点积累自己的能力，从一个贫民窟的小男孩，到演员协会的会长、《GE剧场》的主持人，继而到州长和美国总统。我想你也猜到了，他是美国年龄最大的总统——里根，在他70岁成为总统的那一瞬间，没有人知道他走过了漫长的迁移之路。 六次转行成总统——技能迁移之神里根 —因为他是电影人中的军人，也是军人中最懂得电影的人 里根用以前的各种经历和技能组合出自己独特的政治魅力：穷孩子、电台节目解说员、电影演员、电视节目主持 找到自己最有可能进入的领域，在其中积累新的能力，在恰当的时候迁移到“更适合”的新的工作中去，通过不断地修炼、迁移和组合，找到你最适合的领域，同时也就拥有了你独特的竞争力。 里根不是一个天资过人的人，作为播音员，他不算太出名；作为演员，他的演技三流；作为主持人，他后来被《GE剧场》主动放弃；而作为政治家，甚至连盟国的首脑也认为他智商不高，知识有限。撒切尔夫人1986年在英国会见他之后曾评论道：“在他的两耳之间空无一物。”（指他没有脑子。）他不是一个拿着一手好牌的天才，但是他把这手牌打到了极致。 功不唐捐卡梅隆——《阿凡达》为什么这么牛 “功不唐捐”出自《法华经》。意思是：你付出的努力和功德，从来不会白白地付出，终有一天，会回到你身上来。胡适先生给人题字，除了喜欢写“为者常成，行者常至”，另一个就是“功不唐捐”。 所谓功不唐捐，就是努力地做好每件小事，回头发现自己无意中做了件大事 《真实的谎言》，片中他成立的“数字领域”特技公司第一次在片中小试牛刀。还从给特技人员画受力分析图，解释大船沉没原理，到为杰克画素描。“外界的质疑声一直是成就卡梅隆电影帝国的基础。 有人去山里寻找灵感，有人与人交谈寻找灵感，卡梅隆这种找灵感的方式，伟大而疯狂，让人望尘莫及。在安静的海底，他注视着泰坦尼克号的残骸，杰克和罗丝的爱情故事如海草般慢慢浮上来。 《深渊》+《终结者Ⅱ》+《真实的谎言》=《泰坦尼克号》《泰坦尼克号》+之前的所有积累=《阿凡达》 卡梅隆也摸索出自己的导演风格：不用著名演员，把所有钱都花在特效上。《泰坦尼克号》中的两位主演莱昂纳多·迪卡普里奥和凯特·温斯莱特虽年少成名，但也不是商业巨星。而《阿凡达》里的澳大利亚人萨姆·沃辛顿，更是陌生脸孔，一般人闻所未闻。 12岁 写科幻小说，被认为是《深渊》的原型14岁 看到电影《2001太空漫游》而迷上科幻电影，开始尝试拍短片17岁 上大学读物理系，然后辍学23岁 看到电影《星球大战》，决定从事电影制作26岁 为《星球大战》《杀出银河系》等影片制作模型与特技27岁 导演《食人鱼Ⅱ：繁殖》 什么都不想，全力把眼前的事情做好，做到更好，做到极致的好，然后总有一天会有回报。 或者回报也不重要——当你全心投入，这过程就值回票价，回报只是个惊喜。越是在遥远的未来，你越会发现当年所有的功夫都没有白费。不知道什么时候，以前的经历就派上了用场。这就是功不唐捐。 等待一个确定的机会才开始投入的人，机会永远等不及你。卡梅隆的工作方式，就是 把当下当道场，在任何时候做到极致，看似最笨，往往却是最聪明的 洋葱、萝卜和西红柿，不相信世界上有南瓜这种东西。他们认为那是一种空想，南瓜不说话，只是默默地成长。——舒比格《当世界年纪还小的时候》 新喜剧之王黄渤 一个人要达到高峰，需要做多少准备，走多长的路，承担多久的不理解——如果你每一步都希望听到掌声，那么也许你只能永远在自己舒服的小天地玩。只有那些敢于走得更远的人，才知道自己到底有可能到哪儿。 如果你是一个依靠别人评价而活的人，你从理想中获得的痛苦远远比快乐要多。因为大众往往不寻求品位，也看不到成长，只是寻求刺激，他们夸或者踩你，并不意味着他们真的有什么坚持的观点和品位，他们评价仅仅是为了排遣自己的寂寞。当他们发现下一个目标，就会集体奔腾而去，你的光荣和耻辱都不值一文。 一朵花开需要一个春天，而其间有多少人路过会停下来，又笑着摇摇头。Bob Dylan 其实每个人都是这样，你最大的优势不在于你的学校、学历和专业。你的优势在于你的生活、生长、受的教育、朋友、世界观，还在于你对待周遭世界的认真程度。真正优秀的人，会认真做好每一件事情——因为他们知道即使老板不为认真发工资，未来也必会给认真发工资。 不想当飞行员的程序员不是好老师 人生过往的经历好像散落的珍珠，而机会好像一条线，把所有的可能性穿了起来。这并不是命运的神奇，因为这神奇的命运其实是他努力而就的。我想赞颂的是他的韧性，一个人在没有看到线的时候，依然能够好好地孕育珍珠，才能够在线出现的时候，有东西可以穿。 因为你知道，所谓功不唐捐，就是如果你不知道未来要去哪里，最好的方法就是把手头事情做到最好，因为现在，连接着未来。 三种未来职场的核心竞争力 未来10年的中国，人们需要学会新的能力发展策略，因为未来的20年，中国的职业将会面临前所未有的变动：① 互联网、移动互联网带来的全球化和全国化。② 中国的人口红利消失，从中国制造变为中国创造。③ 中国经济腾飞，从Made in China（中国制造）到Made for China（为中国制造），这也意味着全球化竞争的开始。在未来的20年里，依靠行业、学历、专业、企业、地域的职业资源和能力会慢慢减弱；改变越来越快，成功与失败都会更快；人们越来越开始为自己的职业生涯负责，每个人都需要学会新的能力策略。 终生学习未来10年会是一个职业和职业需求都迅速变化的年代。先把学历读到无比高，然后一辈子靠这个混的策略早就过时了。未来的职业发展大概以3~5年为一个阶段，每个阶段之间需要系统地重新学习新的领域。在职培训、证书与学历教育将会成为常事，间隔年的旅行和学习会成为潮流。企业也会逐渐在内部建立学习中心甚至企业大学，同时送有潜质的员工出去学习。 欢迎来到终生学习的年代。 播放器不能识别WMA或者MP4格式的文件，你就必须用一个转码软件转码，电脑才能读出这段视频。 同样的道理，很多人的职业发展不顺，不是因为能力不强，而是不知道如何把过去的能力和资源“转码”出来，让新的东家能读懂。以家庭妇女重返职场为例，很多女性生完孩子，重回职场，都面临尴尬的局面：过去的职位不太喜欢，或不再适合职场妈妈；新的职业看上去门槛很高，自己缺乏专业能力；离开职场的两年间，社会发生了很大变化，觉得自己跟不上节奏，于是只好不甘心地重回家庭。 起床喂次奶，没睡过一个好觉，孩子走路前你需要时时刻刻抱着，练就一双汉子般的臂膀，这是不是“高度责任心”？有没有磨练你的“耐心和毅力”？ 从20岁就开始了，一生坚持了70多年。当所有领域的感悟迁移到管理领域，被翻译为管理学的专业术语，彼得·德鲁克的文字就变得更有历史纵深感，成为当之无愧的管理学大师。 最后，总结一下从生涯规划来看的能力观： &gt; 能力三核：能力由知识、技能和才干三者组成。知识无法迁移，技能能在大部分职业中迁移，而才干则贯穿人的所有部分。越高度提纯，越内化。 把知识炼成技能，使技能内化为才干。一通百通。 功不唐捐，连点成线。正是因为能力可以迁移，我们没有必要找到最终boss（首领）才开始修炼能力。最佳的策略是在每个阶段都全力投入，提高能力，遇到新的挑战再重新整合。 未来的三大能力策略：学习、整合与翻译。 扎克伯格的成功之道：修炼内职业生涯 除了技术，好的创业者需要人的部分——更深刻地理解他的未来用户：最精英的一群年轻人需要些什么？真正理解人们的需求，需要和他们泡在一起、混在一起，甚至成为其中一员——哈佛大学的学生宿舍恰恰给了他这个机会。 超过10年的成功的互联网产品开发经验微软95万年薪的offer（纳贤帖）名校人脉（Harvardconnection让他手上有近七成的哈佛学生资料）两次创业“失败”经历（被关闭的Facemash和退出的Harvardconnection） 我们很容易看到一个人外功（外职业生涯）的飞跃——拿出某个成果、职位升迁、成功上市，却很难看到内功（内职业生涯）的发展——他从哪里积累到的知识、如何识别机会、怎样获取资源……我们被闪亮的红色高度线闪瞎了眼睛，却看不见灰色苦涩的深度线。 从内外生涯的关系，你能看出成功的某些规律——红色的外职业生涯有两个特点： 跳跃前进：外职业生涯的上升是跳跃性的r型，往往是一鸣惊人，八方震惊。看上去得来全不费功夫。 迭代效用：这意味着成功最慢的是前面几步，越到后面，资源越密集，发展越快。这两者结合起来使得成功人士的履历（外职业生涯线）往往很容易给人飞黄腾达、连升三级的感觉。 而内功（内职业生涯）则恰恰相反： 稳重潜行：内职业生涯呈现U型，这意味着在上升之前，需要经历一个漫长的积累期，才有可能跃升一个台阶。这期间需回想一下你听广播练听力，第一周没有提升，第二周没有提升，第三周还没有提升，很多人就此放弃，认为自己“没有英语细胞”；而有些人不小心坚持到第四周，突然有一天早上，发现自己很多词语“不知不觉”地听懂了！真正的英语学习者都有这样的经历，坚持很久，突然上了一台阶。你不是没有英语细胞，而是不懂得生涯发展的规律。 演讲、太极、咨询、冥想、看财报……大部分内职业生涯的高手，都体会过这种漫长的平台期后，突然跃升的快乐。 大部分的“成功学”故事只会告诉你这个人遇到什么机遇，不告诉你为什么机遇只垂青他；只告诉你他有多激扬潇洒，不告诉你他有多厚重坚实；只告诉你他收获多少，不告诉你他付出更多——一种可能是，如果告诉你，你就不上他的课了，这过程可真比“努力就能成功”难一万倍，也不好玩一万倍！另一种可能是他们也把自己催眠了，无法透过闪闪发光的外职业生涯线，看到背后那条真正坚实有力的内职业生涯线。 好东西就是聪明人下的笨功夫 才捕捉到了给电梯旁边加上一块LED屏幕的创意。从想到到说服商家花了半年时间，从群雄割据到统一市场，又用了三年。“……世界上最可怕的两个词，一个叫执着，一个叫认真。认真的人改变自己，执着的人改变命运。” 职业生涯的成功犹如熔岩，在地下奔腾积累多时，一朝爆发，于是无可匹敌。而我们往往只看到别人走到山顶，在地上挖个洞，就火山爆发了。能不浮躁？ 只有他们才知道，需要多么努力，才能显得毫不费力。 职业生涯的内功与外功 内职业是外职业的前提，内职业生涯带动外职业生涯 要有多努力，才能显得毫不费力 企业按照小强的职位，给他一个难度为10分的任务，由于小强的内职业发展快于外职业生涯，他能做到12分。企业尝到甜头，于是尝试给他20分的任务（外职业生涯上升），而他的能力发展到可以回馈24分，于是企业决定给他一个50分难度的职位。 而小明的外职业生涯比内职业发展得要快。当企业也给他一个10分的任务时，他觉得自己的能力被低估了，他应该做一些更大的事情，于是他心不在焉地做出来8分。企业看到10分的难度做不到，于是主动下调到6分，小明彻底觉得自己被愚弄了，于是回报4分。最后企业只好给他4分的职位了。 希望得到明确的职场目标和许诺才开始学习，这种“不主动”是职场新人常犯的毛病。无论是职业还是商业，都是一门先给后得的艺术，而越是大的跃升，需要给的就越多；越是完美的商业模式，就需要越长的回报。这需要源源不断的内职业发展来支持。 首先，内职业生涯需要外职业生涯的指导。只有定期了解企业和行业需要什么样的人，才有可能方向正确地培养自己的内功。其次，内职业生涯的套现往往会吸引来很多资源，而资源会重新导入内职业生涯，形成下一轮的职业发展高潮。 较好的状态是，内职业生涯保持超前外职业生涯一步，这样的状态最舒心。内职业生涯超前一大段时，你会容易出现职业倦怠，比较虐心，觉得无趣，打不起精神，觉得没有价值感。 努力就一定有回报吗？ 如果你是一个真诚、勇敢同时又有一定阅历的人，你一定无法回避这个事实：我们这个世界，不是一个公平的世界。 这个社会有很多资源稀缺，且分配不公。这些资源有的可以通过努力获得，比如说眼界、工资、能力；有一些需要几代人的努力，比如说更好的教育、平台、名声、地位；还有一些则完全无法通过后天的努力弥补，如天赋、体质和机遇。 如果你是一个真诚、勇敢同时又有一定阅历的人，你会清晰地意识到，如果人生是一场长跑，我们就是站在不同的起跑线、穿着不同的鞋的人——有人打赤脚，有人穿回力到最新款耐克跑鞋，还有人甚至根本不跑，而是开着法拉利——向着不同的终点奔跑。 正如在操场上跑圈，当你第一圈超过前面那个看起来比你健壮得多的男生，你千万不要窃喜。你不是比他强，只是比他的起步线靠前一点。他已经跑了15圈，这是他最后一圈的冲刺。而后面那个看起来文弱的女生像小鹿一样轻松地点着地滑过你，你也不要沮丧——她出身体育世家，六岁开始田径训练，每天以你想象不到的毅力跑10公里，至今已经12年啦。 还是安心算你的圈，跑你的步吧。 贫富由什么决定？ 《我花了18年，才能和你在一起喝咖啡》。 无论是他们的商学院知识、斗志、商业模式，还是精英思维，都无法让他们抵御穷困起跑线带来的绝望。今天如果你把那些成功人士拉到社会底层，也许有三分之一的人永远无法回到原位，还有三分之一的人甚至不及他看不上的穷人。富贵靠什么？努力只占一小部分，命运比努力要重要得多。 请尊敬你身边的穷人们，他们也许不比你懒惰，不比你无能，仅仅是因为命运的安排而活得不如你光鲜。如果你陷入过命运的深渊，你也一定能体会他们的绝望。 你以为我矮小、卑微、不美，我就没有心、没有灵魂吗？…… 如果上帝给我点美貌和一些财富，我也会让你难以离开我，就像我现在难以离开你一样。我不是凭借习俗、常规，甚至也不是肉体在这里与你对话——我凭借我的灵魂与你的灵魂对话。就像有一天我们死去，一同站在上帝面前，彼此平等，就像我们原本那样。 幸福，没那么贵 巨大财富背后的巨大好运 除了顶级成功者们自身的努力，他们还有一个共同点——他们幸运地在恰当的时候，遇见一个前所未有的经济发展高潮，抓住了自己的机会。 第一，恰逢一个百年不遇的经济高增长时期。第二，他们都在增长的关键行业（大陆的互联网和台湾的电子、香港的地产），抓住了一个机会。第三，他们当时基本都在27~40岁之间，而且在这个关键领域已有一段时间创业积累——等你看到机会再开始往往就跟不上了。 从生涯的角度看，27~35岁是人们开始创业的最好时机——此时人的智力、社会视野和眼界慢慢成熟，人脉也渐广，同时还没有太多的家庭和思想负担，正好可以开始。一旦过了这个时机，不是负担太重，就是害怕失败，很多人宁愿做职业经理人。 如果第二条“在关键行业抓到关键机会”考的是后天的眼力的话，第一条和第三条则有很大幸运成分在——谁也无法独立掀起大潮，而谁又能管得住自己的年龄？ 他们恰好在百年不遇的经济腾飞时期（天时）、在合适的行业（地利）、在最合适的年龄（人和）做好了准备，才成就了他们幸运的财富传奇。这让我想起中国一句古话： 生死有命，富贵在天。 只要努力，定有小成，但是极端的贫穷和富有很大程度由机遇决定，成功路上的竞争，并不公平。 成功可以复制，可没法粘贴啊 在每一个人生的十字路口，我们都会遇到这样的情况——我们像站在任何一个城乡接合部的车站，这里停着无数快载满人的车，在每一辆车上，都站着一个人在卖力兜售：快上快上，马上走了！这个时候，你会上哪一辆车？到底哪一辆车，是你的命运终点？ 《小马过河》的老故事吗？小马希望过河又不敢，老马建议他问问朋友们。老黄牛说河流很浅，过河就是a piece of cake（小菜一碟）；小松鼠说河水深不可测，有去无回。小马困惑了……回去问妈妈。 老马鼓励小马自己试试看——当然老马自己走过，知道那条河不至于把她亲儿淹死——最后小马成功渡河，并且理解到： 别人的建议，总是别人的。主意只能你自己“生成”一个。 当你安装上建议翻译器，你会发现他们每一个人都希望你“好”，之所以建议不同，是因为他们对“好”的标准完全不同，因为他们本身就是不一样的人啊。就像那些拉你上车的长途汽车售票员，他们每个人都希望你坐上他们自己的车，这天经地义。问题是：你自己想去什么地方？ 每个人对“靓仔”的评价标准不同，其实大家对“好”和“幸福”的标准也各异。二姨觉得“少走弯路”是好，发小儿认为“精彩的生命”是好，室友认为“更多的可能”是好，而父母则认为“家庭和谐”是好。所以虽然每个人都很真诚，但他们都在说“如果我是你，我会……”的建议。这些建议都没有问题，而志明之所以困惑，背后真正的问题是：我到底是谁？我想要什么？ 志明和你们每一个人一样，都是独特的。你们有自己独特的人生意义，有独特的能力、天赋和独特的思考方式（上帝保佑你真的有），对未来也有各自不同的期待，你们还有独特的能力和资源，能创造与其他人不同的自己的生活。 每个渴望成为独立个体的人，都需要创建自己的定见——一开始肯定没有，那么就多收集各路信息，小范围地试试错，先上一辆最想上的车，舒服就坐下去，不舒服尽快下车，然后回到车站，这次你的选择一定会更加精准——定见不诞生于别人的建议之中，而是在自己一次次的试错里。我们不是“找”到自己的样子，而是“成长”为自己的样子。 什么？你问，如果是我，我会如何回答？ 我也有自己的定见。我会说，如果我是你，我会尽快开始尝试一下。因为如果不尝试，我们永远也不知道前路是否适合。我痛恨像傻子一样站在路口等待答案，期待某一天会出现大师般的人告诉我该如何，我也痛恨某一天我随便上了一辆车，仅仅是因为那一瞬间有人声音很大，而我又恰巧寂寞难耐。 &gt;●所有的建议都是“如果我是你……”的建议；●你的人生方向是你自己“找”出来的，不是听回来的；●你得知道自己想要什么，至少你应该开始试着去知道。 如何再造一个乔布斯？ 乔布斯的才干，从他不可复制的生活经历中打磨出来。 什么叫才干？在“能力”一章里我们提到其定义：“个人所展现的自发而持久的并能产生效益的思维、感觉或行为模式。”才干常用来形容人的个性、品质和特征，它对职业业绩优秀有很大的贡献，在生活和工作中被无意识地使用。 看到自己很自然地在上课前走到陌生的学生堆里面去聊天，看到自己蹲下来听某个人说话，看到自己舒服地坐在咨询椅上，对面的来询者逐渐放松下来……我深深地意识到我真的有“亲和力”的才干。而我竟然20多年对此一无所知！ 与其说乔布斯改变了世界，不如说是世界选择了让乔布斯发动这个改变。 他生活在20世纪60年代的硅谷，这让他与世界上最伟大的IT领袖成为朋友或者敌人。他的导师是甲骨文公司的拉里·埃里森，他的敌人是IBM和微软的比尔·盖茨，先友后敌的是百事可乐CEO史考利和Google的拉里·佩齐…… 一个人伟大，往往不仅因为他的经历，更因为他的伙伴、他的对手，还有他的时代。 伟大从来都是天时地利人和交集的东西。 在20年前，商界人士无法想象：一个百年的化工公司竟在10年内被数码产品商打败，手机厂商则在10年之内逐渐取代数码产品，而一个硬件厂商在五年内动摇世界份额第一的手机厂商。这个世界变化越来越快，而且不可预测。 再回观苹果，它现在面临几大强敌——做搜索引擎的Google、做手机的三星（以及中国市场的小米），还有做电子书的Kindle。乔布斯改变了世界，他猜到了开头，却没有猜到结尾——这个世界改变得比他想象的快多了。 我也不知道，崔健说：“不是我不明白，是这世界变化快。” 如果只剩第一名，其他人的机会在哪里？第二名的机会在于与第一名完全不同，第三名的机会也许在于服务比较好，而其他人的机会则在于更细分的市场，或者让那些无法取代的、针对个体的服务或咨询必须出现。这是我看到的趋势，也是新精英现在努力的方向。 回到关于复制成功的主题，即使两个一模一样的人，也无法通过模仿对方获得成功，因为这个时代变化太快。那些当年让你成功的因素，也许会让你在10年后的社会惨败。 大部分人的耀眼成功，都是汇聚了天时地利人和。即使他本尊亲临，也无法复盘。不管如何努力，再造一个乔布斯的计划，一定会全盘失败。 如果有人问围棋大师，哪一步是你下出的最好一步？大师也只能摇头无语——最好的一步只有在那盘棋局中才能显现，脱离棋局去说“最好”毫无意义。成功人士的巨大成功，也许就是那个年代的棋局里最好的一步。 你与成功者经历不同、内在才干不同，最后即使你能搞定前两者，能让你成功的环境和时代也早已改变。所以成功无法复制。齐白石说“学我者生，似我者死”，就是这个意思。这个世界上只有一种方式一定不能成功，那就是模仿别人的成功。 成功的道理，追忆起来头头是道，面对未来如履薄冰。 成功漏斗模型——成功人士看不见 第一，打篮球不光是投篮，重要的是要跑位；第二，不要朝球的位置跑，要朝传球的方向跑。 职业生涯规划多年，我深深理解这个道理。尤其对于“体力”不好的职场新人，不要向现在的职业最高点方向走，要向未来的职业方向走；不要做现在能兑换价值的事情，要做未来能兑换价值的事情。一个职业经理人，如果没有生存问题，30岁前，不要想着赚钱，而是要赚本钱。 刚进入职场，体力和能力不是最强时，记得向传球的方向跑。也许对行业趋势的分析能帮你看到前景。如果你期待更大的成功，则需要看到更大的格局与趋势，耐心下一盘更大的棋。 趋势与机会到处都有，但是如果你只是看到，就仅仅是观众。而决定参与和投身其中，则需要极强的判断力。二者差异巨大，看到趋势那叫视力，而投入趋势，才叫眼光。 看到趋势，决定参与，就一定能够成功？其实也不一定，你还需要拥有参与的能力与才干。就好比当年三国，天下大乱，各地枭雄辈出，谁都知道赢了就是皇帝，但是又有几个人能够剑锋所指、人心所向？曹操把着天子，孙权占着江东，刘备流着皇叔血统，这都是才干与资源。 比错过趋势更加闹心的，是看到趋势却发现自己完全插不上手——以此献给刚刚进入职场，忙于思考公司战略、时代机遇、商业模式、定位等的职场新人，当我们眼光越来越高，手越来越低的时候，我们会慢慢变成一只长颈鹿。 也以此提醒“吸引力法则”的盲从者，我觉得比吸引不到机会更闹心的情况是，机会吸引来了，你却Hold（把控）不住。我觉得吸引力法则的真意应该是，如果要吸引外界，先吸引自己。 总之，需要拥有能力，你才能成为竞争者，而不是观众。 1/70，这也许就是机遇和坚持最好的注脚。 成功者 正如右图所示，从漏斗底部向上看，你能总结的就是：“我看到了一个趋势，然后就坚持一直走下去，最后成功了。”或者说得再文艺一些，“发现心中热爱，坚持追随，不要放弃，就是成功”。 这于你是实话，你看到了趋势（时代机遇），且心中热爱（兴趣匹配），然后一直坚持（有达到生存底线的能力与才干，并且不断提升），不言放弃——长生才能救世——一直到有一天，你遇到了机遇。 但是如果你走回去看看，会发现很多发现趋势、内心热爱却缺乏能力资源的人，只沦为了观众（为考公务员又被刷下来的人们默哀一下吧）。很多看到趋势、拥有才干却在竞争中被刷下来的人，成了炮灰（中国中小企业的平均寿命是2.97年）。还有一些死在最后一关的人，他们也许比成功者坚持得更久，却还是没有等到机遇，他们没有成为先驱，反成先烈，音容宛在（还记得大明湖畔的团购网站吗？）。坚持与努力是成功的必要条件，但成功的条件有很多，有时候，还需要一点点幸运。 上帝开的努力银行 踏实前行型：原来成功与能力不完全相关——成功不能证明你真的有价值，当龙卷风袭来，猪都会飞；不成功也不能证明你很糟糕，那只是下一个故事的开始——关键是走在路上的状态。我们慢慢明白，成功就是用自己的节奏越走越近。 我最喜欢的是创造型：既然我们处于一个全新的时代，有着与众不同的才干，拥有一个能够改变的未来，为什么我们不创造一个自己喜欢的成功故事？从那些传奇的成功故事中汲取属于自己的智慧，在全新的世界，搭建一个有无穷可能的未来。就是这些现实的理想主义者，在慢慢改变世界。 行文至此，我想对职业的成功做一个总结：&gt; 努力必有收获。小付出小收获，大努力至少定有小成； 成功=眼光+能力+坚持，巨大的成功=成功+机遇； 内职业生涯发展是外职业生涯发展之源； 通过生涯的学习，掌握规划、技能迁移、竞争力组合等手段，可以加快成功； 求快不配做高手； 有个叫上帝的人，他开了一家努力银行。每个人都有一个自己名下的努力账户。每个人每天都在往里面存自己的努力。有的人存得多，有的人存得少。有人存了第二天就取，有的人则在很多年以后一次性取出来。 努力银行上帝在干什么呢？上帝要保证每个人账目公平，不能有错账。上帝还要标注那些存努力存得最多的金卡客户，给他们分配更多的回报。上帝很忙很忙。但事实总是这样，总是那么几个最努力的人有最多的回报，这工作也太不好玩啦。所以每隔10年，上帝就调出所有的金卡客户，抽一次奖，然后随机把一个巨大的成功分给中奖的那个幸运的家伙。所以，宝宝，只要努力，就会有合理的回报。而那些巨大的成功，往往来自幸运——但是请先确定，你努力地拿到了金卡。 你的人生有什么可能？我们的生命有多少维度，有什么可能？ 人生的四种方向：高度、深度、宽度和温度 我的生涯 高度：问问自己：我能否热衷于成为一个对于世界、群体、组织或家庭有重要与深远影响的人？我能开创或管理多么伟大的组织或公司？我能多大程度地用自己的方式改变世界？生涯高度是一个外显的维度，我们可以通过 社会地位、财富收入、名声与权力大小判断一个人的生涯高度。 生涯的第二个发展维度：深度 终极价值：卓越与智慧传说雅典被罗马攻陷之日，两个士兵闯入阿基米德的房间，看见他在桌子前面整理几何手稿，他的最后一句话是：等等，让我算完这个算式。我相信这个关于阿基米德的故事。所有在深度路上的追寻者，一辈子都在用生命说这句话：等等，让我想明白这个问题。 生涯深度指的是人们 在思想、智慧、艺术与体能上达到的卓越与精进程度。 正如于丹解读的《论语》名气最大却不一定是最专业的，影响力最大的人，并不一定是最精通这一领域的人。生涯的另一个维度就此展开，生涯深度的追寻者们渴求真理、寻求极致、反复打磨，让自己炉火纯青，他们希望站在人类知识的顶峰、思考的极限边缘。 我的生涯深度：问问自己：你是否曾渴望在某一个领域达到最高的知识或技能水平？你是否对突破自己某方面的极限感到兴奋？你是否愿意在某一个专一的技术领域投入自己巨大的努力？生涯深度往往通过行业内的专业奖项评定。如学术界的学术地位、科学界的诺贝尔奖、新闻界的普利策奖、体育界的奥林匹克金牌等。 生涯的第三个发展维度：宽度终极价值：爱与和谐 有没有意识到，在更高和更深的两个维度之外，我们的生命还蕴藏着另一个维度：宽度。高度如攀山，越高位置越少；深度如挖洞，越深知音越少。而这个维度则会让我们从山上和洞里走出来，越走越宽，越来越多地与世界联系。 我的生涯宽度：问问自己：你是否渴望体验生命中更多的角色？你的各种角色是否都发展完整和成熟？你的各种角色之间是否平衡？1957—1990年，著名的美国生涯大师舒伯以生涯彩虹图表达了对终生生涯发展的见解，总结出人生最常见的八种角色：子女、学生、休闲者、公民、工作者、持家者等。舒伯指出：生涯的重要任务是帮助人们形成一个整合的、恰当的、清晰的自我概念。 不管怎样——特蕾莎修女人们经常是不讲道理的、没有逻辑的和以自我为中心的。不管怎样，你要原谅他们。即使你是友善的，人们可能还是会说你自私和动机不良。不管怎样，你还是要友善。当你功成名就，你会有一些虚假的朋友和一些真实的敌人。不管怎样，你还是要取得成功。即使你是诚实的和率直的，人们可能还是会欺骗你。不管怎样，你还是要诚实和率直。你多年来营造的东西，有人在一夜之间把它摧毁。不管怎样，你还是要去营造。如果你找到了平静和幸福，他们可能会嫉妒你。不管怎样，你还是要快乐。你今天做的善事，人们往往明天就会忘记。不管怎样，你还是要做善事。 即使把你最好的东西给了这个世界。也许这些东西永远都不够，不管怎样，把你最好的东西给这个世界。 即使把你最好的东西给了这个世界。也许这些东西永远都不够，不管怎样，把你最好的东西给这个世界。 生涯温度指的是我们对生命的热度，我们对生活有多大的热爱与激情，能多大程度活出自己本来的面目。生涯温度的追寻者们渴求自由，探索内在世界，追寻真实鲜活的生命状态，寻找自己存在的意义与天命。 这是生涯最内在的一个维度，是评判标准最个性化的一个维度，却也是与幸福相关度最紧密的一个维度。 我的生涯温度：你希望以怎样的激情与热度投入生活？你是否时常有“那就是我”的自我感？如果时间暂停三天，你做什么都能成功，你会做些什么？正是因为这个维度如此不容易察觉，所以很多人用其他三个维度来评价这个维度，比如说认为“功成名就”“优秀卓越”“儿孙满堂”等已然足够。他们认为，这样我们就“应该”温度很高了吧。其实温度就是温度，各人吃饭各人饱，自己温度自己掌握。 第二次的返场，杨丽萍最后一个走了出来，观众有节奏地鼓掌。那一瞬间，每个人都理解了她的想法。我联想到我上课的最后一天，一定会忍不住哭起来，因为为了这个讲台，我曾付出那么多，只有我自己知道，太不容易了。 但杨丽萍让我们所有人失望了。她轻轻鞠躬，就好像任何一次演出返场一样，利落地离开了。这谢幕超越之前的整场演出，成为我当晚印象最深的艺术。当所有人都恋恋不舍时，她挥一挥手，蹦跳着离开。追寻温度者，当自在如是。我们为她可惜，而在她看来，我们的可惜才是可惜的。有人把杨丽萍作为生涯不平衡的例子，这想法挺可笑；有人则说这是她为艺术做的牺牲，我觉得他们不懂。说杨丽萍热爱舞蹈都是亵渎，她就是舞蹈本身。这样的生命没什么不好，而且值得尊敬——她明白自己的人生路向，明白自己所为何来。她跳舞不为名利、不为权力，艺术顶峰也只是一个台阶，她踏在其上，向终极自由一个箭步冲去。 曾有人问登山家：“为什么要登山？”登山家的回答是：“因为山在那里。”“为什么你要这样生活？”“因为这是我的生活。”这也是一种选择。 你的生命有无限可能那么，我们的人生，到底有多少种可能？如你看到的那样，我们的生涯有四个维度，除了追寻 功成名就 之路，至少还有另外三个可能：追寻智慧、爱与关系和自由。人们陷入生涯困境，往往因为他们匆匆忙忙，却只能看到一个人生方向。当你看到立体的生命出现，而每一个维度又可以有自己的方式时，生命就有无限可能。 幸福的方式不止一种 这意味着虽然他们所处的环境、收入、社会地位千差万别，却各自都有让生涯变得幸福和有价值的可能。一个企业家、一个全职太太、一个工程师、一个老农，还有更多更多不同生活状态的人，他们对幸福定义的方式各自不同。当我们看到人生的方向有很多种时，我们都能在自己的道路上通过努力获得幸福。 你更尊敬哪一种人？ “我们可以从学历和工资层面知道两者的差别，但是这两个人为自己的生活所付出的努力和智慧，不会有明显的区别。那位老校工之所以是老校工，也许并非个人不够努力，而是生活的选择，或者错过了某个机会。而那位清华的教授，除了个人的努力和天赋，也许还有家庭的经济、教养环境和社会机遇的帮助。他们的职位无论高低，都受很多非自己的因素影响。我们不应该用职位的高低判断人格的高低。” 一个不好好讲课的教授，跟一个刚才认真擦黑板的校工相比，后者的生命更有价值。因为我们并没有能力选择自己生命的起点和终点，但是我们能够选择在路上以什么样的态度和姿势前进。” 此事震撼了杨澜，她回忆说：“诺贝尔奖也好，科学成就也好，社会承认也好，都不足以弥补他的失去和永远的心痛。如果我做节目，还停留在讲述人们所谓的成功故事层面的话，我们也就失去了对人性更深层的了解和体会，最终归于浅薄。”杨澜隐隐约约感觉到了生命其他维度的存在。 生涯不仅有高度，还有宽度。正如坐标系显示的一样，这两条轴线只在原点相交——即使再高的高度，也无法弥补任何一点宽度。它们本就是两个维度的东西。不识字的农民，还是诺贝尔奖得主？这是一个重大的选择。 机会的不公平、人生的不平等，但依然能找出自己的人生发展方向，活出自己最好的可能。我们尊敬这样的人。 你的人生模型是什么样的？ 比如在我们的文化中，男性的模型像个微冷的大金字塔——高度为主，兼顾宽度和深度，温度最次；而女性的模型则像一个温暖的圆抱枕——宽度第一，温度第二，深度和高度差不多就好。这也是为什么男人在高度宽度为主的职业，如政治、经济、商业、学术、专业技术等，能有更多优势；而女性会在温度和宽度方面，比如家庭关系、公益组织、助人、身心灵等方面，更有优势。 只有一个方向的人生就像一场考试——大家进入世界这个大教室，看一模一样的教材，然后参加同一场考试，等待一次又一次的判卷和排名。而四度的人生并不是这样。我常想，世界不应该这样，世界应该是一座大图书馆——早上一开馆，我们就欢呼雀跃地跑进去，找到自己最喜欢的一本书——你可以从头到尾地看完，也可以跳着选择不同的书，如果你有兴趣，还能自己写一本——这样的人生，才有无限可能。 人生最痛苦的事情，莫过于你内心选择了一条生涯之路，却非要绑架着自己走另一条路。大家越行越爽越开心，你越走越远越寂寞。你需要每天挥刀自宫——先努力灭掉自己内心的想法，再应付外界的俗事，很多努力才能换来一点点成功。心中苍凉，四顾孤独，大家还觉得你很不错。那种苍凉只有经历过的人才知道。 追寻高度的方式是竞争与超越。 追寻高度的人生正如登山，越往上走，视野越开阔，可能性越多，同时也能被越多人看到，影响与改变世界。但选择高度的同时，你也选择了高处不胜寒，选择了孤独和竞争。越往上走，能站的人越少。为了上到顶峰，你必须放弃很多。但顶峰永远只能站一个人，总有一天有人会把你踢下来。 追寻深度的方式是修炼与精进。 追寻深度的人生正如向下挖洞，专注一点，反复钻研，不断否认与超越自己，在苦修中超凡入胜。深度的挖掘使你的方向越来越聚焦，也越来越极致，但视野也越来越狭窄。追寻深度的生涯选择面很小，无法回头，一旦选择，唯一的突破方式就是前行，做到极致。相比追寻高度来说，追寻深度更容易名垂千古——只要你挖出来的路还有人走着，别人就不会忘记你。写《红楼梦》的曹雪芹你一定还记得，他的当朝皇帝是谁，你一定早忘了。 追寻温度的生涯是自燃式的绚丽。 按照温度的法则来生活的人，终其一生与开心人做快乐事，他们被自由与激情环绕，活得绚烂多姿。但温度追随者的风险也正在于此，追寻温度者过于自我，不容易有稳定的安全感与关系，而且因为太过挥霍生命，容易过早自燃殆尽。 一个人到了30多岁，就应该慢慢地意识和选择自己的生涯四度的排序，一旦这些维度确定，人生的格局和限制就都逐渐明晰起来。多看看不同的生活形态，接触些不同的人。有一些会让你惊叹，却觉得自己绝无可能；有一些会让你觉得：我就是要那样的生活。慢慢地，一些选择会离开你视野，另外一些则越来越清晰。这时，人生天命慢慢浮现，定见因而产生。 年轻的时候，你不愿意放弃成功，不希望在竞争中落败；在工作3~5年之后，你又必须面对专业还是管理方向的选择，你一开始绝不放手，认为自己两个都行，慢慢地你在专业和管理领域的往返跑中精疲力竭，决定选择一个投入；年近三十，你发现自己需要承担来自家庭和社会的期望和压力，父母在变老，孩子们在长大，他们都希望你是一个对家庭负责的人；等到这一切你都竭尽全力地做完，你却发现自己已心力交瘁，内心冰冷，生活也离你热爱的方向越来越远。 于是你准备为这么多年失落的自我做些什么，你开始让自己追随内心，做些以前不敢或者没有时间做的事情，但是一旦你开始行动，从另外三个维度传来的抱怨声就会此起彼伏，大家纷纷觉得你变了一个人，对你表示失望。你刚自我一点，却发现孩子的班主任开始找你；好不容易搞定这个，公司的项目又出现强力竞争者；你扑到工作中力挽狂澜，却发现身体早已吃不消，大病 不完美才是真人生 生命的本质就是不完美，生涯的总体能量守恒。 如果你要些什么，你就必须放弃些什么。如果你要得特别多，你就需要放弃特别多。这才是人生。 天才不仅需要天赋，还需要做严肃的人生选择。 为什么非要成功？ 喜欢一个完美的人或事物，不能叫欣赏力——因为傻子都会。欣赏是总能绕过对方的缺陷，看到真正美丽的部分。 所以他们注定是一群庸人。而曾国藩说“小人求全，君子守缺”，就是这个意思。 没有人能同时过上功成名就、智慧卓越、生活宽广，同时又自由自在的生活。既然历史的各路枭雄天才都无法幸免，我想你也不能。 惨胜如败的一维度成功 生涯四度中，高度和深度外显，而宽度和温度则内含。如果一个人看不到生涯的全貌，他就会下意识地用单一的、外显的维度来评价自己的人生，同时也通过牺牲其他维度的方式来达到所谓的“成功”。这就是一维度的伪成功。我们抽取今天这个社会里两群最“成功”的人——高考状元与亿万富翁，谈谈一维度的伪成功。 学科压力大、极度自负与自卑、生活障碍、健康不佳、学科专业不适合、缺乏创造力等从他们身上反映出来。有些学生读到了硕士，依然不会自己洗衣服，上街买东西受骗，无法与同学交流，生活依靠钟点工照顾。这样的人，从经历与心理韧性来说，都很难担当“青年科学家”的重任。 而这些能力为什么没有被培养出来？在和朋友打闹、成群结伙地晃荡在学校和家之间的路上时，我们学习到友谊，而他们在学习。当我们16岁第一次自己出门，被别人骗光了钱的时候，我们学习到社会，而他们在学习。当我们18岁第一次给心爱的女孩子写情书的时候，当我们在泡妞或者被妞泡的时候，我们学习到爱情，而他们也许还在学习。等到我们成年，凭以上这些能力开始展开我们的生涯，让我们的生命变成立体而非直线的时候，他们只会学习了。 “学生过早地被灌输这种竞技思想，而他们的文化积累、人生感悟都不够，加之他们所演奏的绝大多数作品都是西方钢琴音乐，导致他们很难理解这种非本民族的东西……比如弹巴赫的音乐，他们连教堂都没有去过，没有见过自然也谈不上感受，所以难以弹出地道的巴赫……学生本人未必喜欢钢琴，要么弹到最后自己都不知道来干吗了，要么就仅仅平添一种谋生的手段。” 音乐的深度，需要生涯的宽度与温度来滋养，世界上不存在一维度的成功。 **不管是“学而优则仕”“音乐竞技化”“有钱就是爷”，还是“我爸是李刚”，都是典型的“高度衡量一切”的一维思维。而放弃其他维度的发展，无疑让原来立体的生命变成一条直线——当成绩（高度）被寄予了拯救人生这种不可能完成的任务时，也就产生了两种变态：一是所有的努力都放到了一只篮子里，但这只篮子里只有少数胜利者，这让人焦虑；二是人们为了唯一的希望，不惜扭曲自己，搭上所有的精力，这让人压抑。 像一个胖子非要把两条腿都穿进牛仔裤的同一条裤腿一样，一维成功使人焦虑且压抑。** 当这些焦虑又压抑的人成为社会的中坚分子，你怎么能期望他们不搞突击应付领导检查，不牺牲尊严去赢得竞争，不放弃自己的梦想去追逐名利？那是他们唯一的可能了。 你用短跑的速度冲刺，结果在马拉松的前1000米超出老远，还向观众挥手，觉得自己很成功。你这不叫成功，叫“二”。 这些离开人世的亿万富翁中，我把“伏法”“他杀”和“疾病”算作一类：被剥夺游戏权利。出于过于自信或者身不由己，这类人通常曾经深深透支了其他维度：“伏法”的透支了法律道德，“他杀”的透支了伦理良心，“疾病”的透支了身心健康。出来混，总是要还的。当要还的时候，他们还不起了。 我把“自杀”算作第二类：自动放弃游戏权利。这些人知道自己无力偿还，选择了不玩。就像在QQ游戏上拿到一手烂牌，你直接选择拔网线一样。 最后的“意外”我则不知道该归于哪一类，暂且不提。 这些离开人世的富翁虽然在财富上成就惊人，却在其他方面亏欠很多，他们都曾大大地透支自己的生命——这些透支像是对信用卡的拙劣操作：他们在自己生涯的其他方面不断刷卡，反复取现——这的确让他们在短期之内成功过，成为众人眼中的“赢家”，却也在某一天“催款单”来临的时候，让他们无力支付。 家庭、事业、健康是企业家最重要的三大支柱；旅游、进修和慈善是企业家热衷的三大活动； 我们到底在“混”什么？我们又在用什么方式“还”？为了高度和成就，人生是否一定要放弃一些东西？如果答案是“是”的话，那么孤独和凄凉是否是成功者的唯一结局？如果“不是”的话，我们放弃的限度又在哪里？ 缺乏自我：在中国这个以交际为核心的商业环境中，商业的成功往往在酒桌与交际中完成。富豪们白天主内处理管理，晚上主外处理关系，回到家里还要处理家事。各种关系下，是各种角色的扮演需要。在我调查的14个企业总裁或董事长中，每周能够自己掌控的“自由时间”平均不超过四小时，在家吃饭平均0.8次。他们和自己相处的时间很少——从自己的温度账户里透支了太多快乐——很容易崩盘。 缺乏支持系统：成功者被赋予了“强大”的社会形象，内心自负。早期多有独立打拼的创业经验，早已习惯高处不胜寒的孤独，其中还包括一些问题因为灰色黄色绿色无法与外人道，这让他们遇到问题喜欢独自承受。这些问题日积月累，终于让他们觉得即使停下来也比现在温暖——那是怎样冰冷的一种决心。 我更希望通过这些分析形成一个思考：成就我们的高度的代价到底是什么？牺牲其他维度的成功，到底是收益，还是仅仅是转账？ 如果当初那些离开我们的亿万富翁在生涯的一开始，就知道和明白高度的代价，他们还会那样选择吗？他们会不会在高度和内心温度以及生活与家庭的决策中稍微犹豫一下，然后走上那条不那么光鲜，但是可能更卓越、更温暖、更自由的道路？ 他们永远不知道那些东西值多少钱。 一维度的成功往往是伪成功——只求“快”的激素猪肉损人健康，求“有效”的速成教育毁人心智，求“来钱”的豆腐渣工程夺人性命…… 小心那些只用成功做唯一生命价值标准的人，他们是把自己当成工具的自我恐怖主义者。他们一定不会犹豫在一个只看GDP的国家污染环境，在一瓶只检测氮含量的牛奶里投放工业原料，在一次只看利润的交易中不择手段，在一份只看钱的工作里出卖朋友，在一个让自己少奋斗10年的结婚对象前放弃爱情，培养出一个只看排名和学校的孩子。 管理你的生命质量 找到生命的重心 生涯四度中，高度和深度都是外显而可测的；而深度和温度则是内在的，难以量化。越是生涯价值低的人，往往越渴求外在的维度表达，而总体价值越高的人，则越寻求整体维度的平衡。 同样的心理让我们中的大部分人急于寻求外在的维度名片上更加吓人的头衔、更加光鲜的证书、更加拉风的车子，我们都在证明自己的高度和深度。追求这些维度并没什么不妥，但是当贪婪过界，我们就会忍不住从那些内显的维度中提取，这就是浮躁的来源。 我们被这些越来越“成功”的指标淹没，我们的生涯系统也在慢慢被摧毁、腐烂。这让我们更加焦虑——因为我们心中知道，我们穷得只有这个了。 平衡是生涯四度最好的解答，无数证据指出，平衡是一个系统价值最大化的体现。 我们都知道，生命和所有运动一样，每个人的平衡方式都不同，要找到平衡，就要先找到自己的重心。但如何找到生涯的重心？ 那个时候我们多大？按照30年一代估算，大概是30~50岁之间。那个时候我们最需要有的是“从容强大的心灵”“有自己的方向”“稳定的经济收入”，而这几项获得与否，又与你毕业后几年的努力相关。 所以，毕业后那几年，你越是为了孝敬父母，就越应该让自己有一个健康、持续发展的职业生涯。 在你的每一个生命阶段里，生涯每个维度都有自己的需求，关键是找到核心的那个。有人高度不足是因为深度积累不够，所以没有竞争力；有人则因为温度不足，无法维系宽度…… 在一个阶段内，总有一个生命维度，是改变生命的杠杆，生涯平衡点就在其后面。 我瞄准一个绿球，呼出一口气，推出一杆，说：“你这么一说，他好像的确没起什么作用。但是从那以后，我们家的每个人都更加信任彼此。年龄越大，我就越了解父亲的牺牲有多大。我们也就越知道彼此能为这个家付出些什么，这让我们家这么多年虽然有很多冲突，但是一直很幸福。” 一直到晚上临睡的时候，她才突然说：“我想起自己家里的很多事，我突然明白，原来我的家里，缺的就是这些没用的付出。”说完这句话，她哭了。高度在很多时候可以转化为宽度、温度，效果却不会马上显现，信任会作为账户储存起来在很多年以后，酿成美酒。而一件事情有用没用，也许只有时间与生命知道。 成功的游戏规则我在前面的章节里谈得很详细。职场的成功大概有自己的固定套路：角度—深度—高度—格局—机遇。 刚刚进入社会，找到一个好的切入角度：好公司、好项目或者好职位。这个时候千万不要寻求高度，因为此时没有积累，直接立起来肯定会断。慢慢积累自己的深度，让自己有力量、足够强壮，然后找个机会上位，也就有了高度。如果光有高度没有格局，很快这面旗帜就会倒下，因为立不稳。格局让你看到更多，向四面八方生出旁枝，让自己立稳。从电线杆到金字塔，到这个地步，人能做的事情也就差不多了，接下来就看天时地利是否能推起这座金字塔了。 《老马的职业“鬼”话》马华兴（“新精英”资深职业规划师的犀利职场观）《管理的常识》陈春花（中国人写的最简单、通俗又深刻的管理书） 看到高手不等于你能超过他，但是如果你没有看到，就连门都没有。一旦你看到你所在领域的高手，马上就能知道自己是否具有登上顶峰的资质；如果你能找到与你气质接近的高手，马上就能知道 自己该如何走上顶峰。看原典、听本人的课、找到行业内真正的牛人，是成为高手的必经之路。 《学习之道》维茨金 在职业规划咨询中，我要求即使是实习咨询师做公益咨询的时候，也要来询者为咨询师和自己付喝咖啡的费用。因为任何人都知道，一旦一次咨询需要付费（即使是一杯咖啡钱），就会让来询者有期待、让咨询师有压力，真正的成长则从此开始。 问题，当你可以讲个笑话就搪塞过去而不用解决问题，当你对大家说“我也不懂，就是分享一下”的时候，你就已经选择了一个平庸的对手，而你的能力也被限制了。下棋的人应该知道，和庸手下一辈子的棋，还是庸手。 《一万小时天才理论》科伊尔《异类》格拉德威尔 过乔峰的降龙十八掌，你不觉得，那是因为他上了太多武功“课程”吗？ 对照现实和理想的饼图，看看有什么因素妨碍了你的理想实现，想想可以做点什么让你的理想尽可能实现。 很多认识我的人都很诧异，像我这么瞎忙的人，要做管理、要讲课、要研发、要写作、要上课，还要减肥，居然可以每年出去旅游两次。 很早我就发现，宽度方面的时间，是软时间，即可以压缩的时间。关系可以处可以不处，旅游可以去可以不去，聚会可以有可以没有，爱好可以做可以不做，反正也没有绩效考核。长久下去，真的给你放三天假，你都不知道找谁去。所以越是软时间，越需要提前变硬一点。我会在每年年初的时候，以硬性的方式定下旅游时间，列入日历，并和团队提前沟通好，这个时间段对我很重要，多重要的事情都不要安排。如果你安排得够早，同时能让大家理解这件事情的重要性，你的时间就能有保证。唯一保护软时间的方法，就是比硬时间更硬。 谁更有效？孩子是最诚实的人。 能为我花钱并不珍贵，为我花精力才珍贵。 提升爱的能力现代人经常困惑的问题是：如果我就是放不下工作，我就是没有那么多精力，那该怎么办？如果你不能投入更多的资源，却希望获得更多的质量，你也许必须提高你的技能。是的。高度有技能，深度有技能，为什么宽度和温度没有技能？以前你需要花一小时才能让夫妻关系恢复，现在通过学习两性沟通，你能15分钟做好，这是不是技能？以前你需要花三小时才能让孩子听话，现在通过学习教练式辅导，你能用几个问题解决，这是不是技能？以前你要和父母待一天才慢慢开始融洽，现在你找到关键点，很快就能进入状态，这是不是技能？如果你想要时间更短，却收获更多，你就必须提高生活的技能。 在家里挂一幅可刮擦的世界地图，把去过的地方刮开，这可以鼓励我们走遍世界。给父母设立一个旅游基金，恐吓他们说如果这里面的钱今年不用完，明年就没啦。这都是我的生涯宽度管理技术。 下面是一些培育“亲子关系”、很受业内人士推荐的书：《好妈妈胜过好老师》尹建莉《喂故事书长大的孩子》汪培珽《孩子你慢慢来》《亲爱的安德烈》《目送》龙应台《正面管教》简·尼尔森《父母效能训练手册（PET）》戈登《孩子，把你的手给我》海姆·G.吉诺特如果你感兴趣，还可以了解一下家庭教育指导师这个职位。 《男人来自火星，女人来自金星》约翰·格雷（描述两性关系的很好的书）《爱的五种语言》盖瑞·查普曼（恋爱中的男女适合看）《为家庭疗伤》李维榕（上集比下集好看） 温度 找到至少一种让自己开心的方式有一次在企业家沙龙的分享聚会上，我问了一个问题：在座有多少人知道，怎么样让你的员工在三分钟内开心起来？ 下面几乎都举手了，这是领导力的表现。 有多少人知道自己的老婆孩子要些什么？怎么样让他们在三分钟内开心起来？下面的举手变得稀稀拉拉，好像插秧。我再问：有多少人知道自己需要些什么？怎么样能让自己在三分钟内开心起来？下面没有什么人敢举手了。这是不是我们的尴尬？我们有很多取悦别人的方法，却对如何让自己开心所知甚少。其实每个人都有让自己开心的方式。 与自己的约会：●设想你要去约见一个与你一模一样的人，你希望让他非常快乐和开心，你会做些什么安排？●把这件事情记录下来，安排到你的日程里去，告诉你身边的人自己要留出这个时间段。每天10~20分钟就好。●坚持两周，你的生涯温度就会上升。 ●可以从看感兴趣的经典书开始，建立一个系统的知识框架，然后再精细地深入一门学习，这样不容易走火入魔。●区别知识与技能，系统地学习，但拿到一个心理学硕士学位也许并不能帮你解决温度问题。体验式或互动式的课程，更加适合非专业人士。●正经的心理学和身心灵学习里，没有什么方法是对每个人都有效或者任何时候都有效的“终极法则”，每个人都有适合自己的方式，如果你觉得老师的方式不适合自己，不是你有问题，离开就好。●别太功利，如果你希望提高自己的温度，就别再给自己又制定一个目标。 《真实的幸福》《活出最乐观的自己》《认识自己，接纳自己》马丁·塞利格曼（经典积极心理学三部曲，大部分的理论都在里面了）《幸福多了40%》索尼娅·柳博米尔斯基（又一本被名字毁掉了的好书，记录了很多积极心理学的技巧与干货） 《遇见未知的自己》张德芬（都市灵性小说、灵性入门课） 刚开始的时候，突然看到了整个人生的系统，发现自己的很多缺失和各种可能，人生处于打开状态。修补某个维度或者扩张某个维度，往往会迅速地提高整体的幸福度。这个阶段是一个发现可能、找回平衡的过程。 成长的三个阶段第二个阶段是提高效能的过程。当人生重新找回平衡，我们要做的事情就是提高每一个方面的效能，让人生的整体价值最大化。这个时候，投入哪个维度的学习，就会提升哪个维度的效能。第三个阶段则是做重要的选择。效能提高终有极限，在不同维度往返跑也会越来越难，人生总需要做真正严肃的选择。如果你只能挑一个维度深入，你会选择哪个？ 人生需要做真正严肃的选择。梦想残酷且美丽，美丽是因为你在最希望的路上行走，残酷则是因为你因此放弃了那么多的可能。只有勇敢的人能做出这种选择。 好的生命，是有事做、有人爱、有问题可想、有选择的自由。 如何解决现实和理想的冲突？ 你不甘走现实的路，却又不敢走理想的路。所以真正的问题其实是：怎样从现在的现实，走到未来的现实？ 先冲入现实之路吧。在这里修炼，获得必要的锻炼、给养、技术、技巧；在做好储备、更好地了解自己之后，你可以开始寻 找两条路的交会之处。你在现实之路上走得越远，朋友越多，发现与梦想之路的交会也就越容易。 如果把生活比作一场球赛，适应现实等于防守，而坚持理想等于进攻。如果一个球队一直进攻却毫无防守之力，会死得绝惨。今天你也能看到那么多忙于适应生活却忘记梦想的人——他们一直防守，从不进攻，这些人为什么要踢球呢？ 我们为什么要工作？ 职业的本质，是一种通过满足他人或社会需求而自我生存、发展和实现的社会交换形式。简单来说，职业是通过满足他人需求来实现自我的社会交换方式。 职业中自我实现的方式是什么？什么是工作的意义？我们为什么要工作？ 工作是为了活出自我，实现自己对世界的价值。稻盛和夫在《活着》中认为工作即道场，工作的目的是“自我修炼”，为了让自己拥有“美好心灵、圆满人格和智慧”。李开复说“做最好的自己”，乔布斯说“活着就是为了改变世界”，都属于此列。 生存、被认同和自我实现，分别对应着职业发展的三个阶段——工作（job）、职业（career）、事业（calling）。 让我能生存，让我被认同和被尊敬，同时在其中实现自我和社会的价值。 梦想如此美好，现实如此残酷。人们要么追寻理想，为生存碰得头破血流；要么放弃梦想，一头跳入生活的浊流（反正大家都黑，谁也别嫌弃谁），沿着社会设定的道路行进，却发现自己早就忘记了出发的理由。慢慢地，我们会遇到人生最可悲的事：30岁的你早上起来站在浴室镜子前，挂着假模假样的微笑，发现自己变成了小时候最讨厌的那种人。 大部分老一辈中国人就是这么想的——职业是用来谋生的手段，所以他们的游戏规则特别简单——尽可能在职业期攒更多的钱，用很少的钱照顾好自己，然后转投到下一代的生存期，让自己不要成为儿女的负担，让儿女少吃点苦，多读点书，尽量度过生存期。 这种职业观也传承给我们身边的大部分人——他们努力地在工作中赚更多钱、走到更高的位置，同时学习更多精细的花钱方法，投资到孩子的教育中去，希望他们能画出更加好看的一条曲线。但是，仅此而已。 很少明白职业能承载更深层次的可能——发挥天赋、找到自己、理解和发现工作背后的意义 我们所处时代普遍存在的神经症……很多现代人所受的痛苦，不是源于临床观察而定义的神经症，而是源于他们对生活的麻木感和空虚感。——荣格 追寻工作的意义 我们不仅希望通过工作换取体面的生活、受人尊敬，我们还期待工作本身给我们带来意义和价值——能激发我们的热情与好奇，能发挥我们的天赋，能实现我们内心的价值，让我们在热爱的领域努力地玩，能让世界因为我们的存在有些不同。 21世纪最重要的一次职业的革命，就是在工作中，人们开始寻找意义。 对期望在工作中找到人生意义的人来说，一定要经营自己生涯的第三条线：事业线。但值得去的地方永无捷径，你需要经过“探索——投入——建立——进入”四个阶段。 你一直渴望的。你有一种鱼遇到水的感觉——这条线的成长速度，远远高于职业线。 进入期：慢慢地，有一天你会发现，你在事业线中获得的职业收益，已经达到生存线——这意味着你实现了职业自由——仅凭自己的理想工作，也可以生存了。这是人生的现实理想逆转点，是人生攻防的大逆转，是你个人商业模式的break event（逆转点）——你可以从此全力以赴地经营自己的梦想了。 你一直渴望的。你有一种鱼遇到水的感觉——这条线的成长速度，远远高于职业线。 进入期：慢慢地，有一天你会发现，你在事业线中获得的职业收益，已经达到生存线——这意味着你实现了职业自由——仅凭自己的理想工作，也可以生存了。这是人生的现实理想逆转点，是人生攻防的大逆转，是你个人商业模式的break event（逆转点）——你可以从此全力以赴地经营自己的梦想了。 生存期：生存线与职业线相交之前形成了第一个阶段——生存期。这个阶段的主要任务是生存，求职以能力为导向。发展期：生存期之后、职业自由点之前形成了第二个阶段——发展期。这个阶段的主要任务是在现实中获取更多的能力和资源，扩大视野，更深入地了解自己，为自我实现做准备。自我实现期：职业自由点之后。这个阶段的任务是全力奔向自己的天命。 鲁迅没开始写作之前，都在干吗？ 从职业生涯来说，鲁迅是个典型的冲动型规划的家伙——因为看到自己的父亲重病，他决定医治更多人，于是开始从医（很多人的大学专业都是这么选的吧）。在日本学医看到了一段中国人围观中国人被砍头的影片，又接触到哲学，引发他对国民性的思考，让他认为文字更能救国，于是他转投文艺（刚毕业的鲁迅却找不到和文学对口的职业）。公务员的14年生涯，帮助鲁迅慢慢积累了从事文艺的能力和平台，写作和教学都是呈现自己文字能力的方式。 蔡元培（此公是近代史奇人之一，给中国的教育和文化带来了巨变，也是鲁迅的超级大贵人），鲁迅开始创办自己的文学刊物《语丝》《萌芽》，写作和翻译成为他主要的工作内容。以今天的观念来看，他成为一个“自媒体”。两年后，他自由撰稿的收入，达到每月500圆（近50000元）以上。至此，鲁迅彻底实现经济自由。从生涯三阶段来看，他顺利地完全跨入事业维持期阶段。 当人们遇见天命，当兴趣、天赋、特质、渴望和时代需求最好地结合在一起时，会产生意想不到的巨大力量。 他既非从小立志成为救国英雄，也并非在斗争中活得清苦。鲁迅的生活不比我们大部分人差——换算成2012年的购买力，鲁迅从31~55岁共24年的职业生涯中，总收入约为1109万元，平均年薪为48.2万元，平均月薪4万元。这让鲁迅能有一个让自己体体面面、养活三口之家、有闲钱买书买古玩的生活。在这个基础之上，斗士鲁迅才能从心而发，真正战斗起来。 梦是好的；否则，钱是要紧的。钱这个字很难听，或者要被高尚的君子们所非笑，……凡承认饭需钱买，而以说钱为卑鄙者，倘能按一按他的胃，那里面怕总还有鱼肉没有消化完，须得饿他一天之后，再来听他发议论。……自由固不是钱所能买到的，但能够为钱而卖掉。——《鲁迅全集》第一集 先养活自己，照顾好家庭，然后慢慢地摸索自己生命的可能；这期间有成功，也有失败。鲁迅在46岁中年时渐入佳境，找到自我实现的最佳路径。一旦找到，则投入自己的全部生命。在文字上毫不妥协的他，在职业生涯发展中展现出来巨大的韧性，令人尊敬。 我尊敬穷困的理想主义者，但是搞理想不一定非要穷困。因为要找到一个生活稳定的理想主义者，远远比我一个穷困潦倒的绝地斗士，概率要大很多。 如说是梦想投机分子，梦想和自我实现只是他们的另外一种成功学。这种梦想投机分子，根本就不配谈梦想。 鲁迅的职业生涯故事还告诉我们，如果他在46岁才开始全心写作，依然能成为现代影响力最大的几个作家之一。如果从现在开始，把你喝咖啡和刷微博的时间省下来，我想你的梦想一定也来得及实现。 李开复的生涯三阶段：从职业线起跳 对理解生涯三阶段的人来说，李开复的跳槽其实是顺应职业发展的必然选择。职业生涯就像个人的生命一样，是一个不断发展和突破的过程。就好像孩子，该叛逆的时候要叛逆，该结婚的时候要结婚。每一个阶段都有自己的不同需求，这些不同需求没有必要非在同一个职位完成、同一个组织完成。一个希望拥有完整的职业生涯体验的人，往往会发生两到三次的巨大变动。理解职业人发展规律的公司，懂得提前为他们的员工设计自我实现的 路径，实现个人与社会的双赢。 今天的社会中，如果一个人在35岁之前，还没找到能发挥自己特长的领域，这个人的职业发展则相当堪忧。30岁以后，我们的体能开始下降，努力不会成为核心竞争力，只能通过经验胜过年轻人、通过才干和资源胜过同龄人、通过聚焦来胜过更强者。 如果你在前两个阶段职业生涯发展顺利，到了这个年纪，就要专业有专业、要人脉有人脉、要财力也有财力，你具有冲击职业顶峰的能力。 —其实所谓“道”，并不是地上画好的线条，而是你回首的时候自己踏出来的那条路。 2005年7月，他从微软跳到谷歌，惹上一场国际官司。同年九月《做最好的自己》一书出版。这两者相互借力，使他在青年人中的影响力提升到一个前所未有的高度。他在谷歌中国的工作定位也就顺其自然：公共关系和中国工程院的运营。 进入这个阶段，职业发展从关注外在成功的职业阶段（career），进入关注内在成功的事业阶段（calling），也就是我们说的道法自然——成长为自己的样子。什么叫“自然”？“然”是“……的样子”的意思，“自然”就是“自己的样子”。 这个生涯故事也完美地说明一个生涯三阶段的道理——发展好当前的职业生涯是自我实现的重要手段。从山顶起跳，好歹也能落在山腰上。如果你暂时找不到自己清晰的梦想，那么踏踏实实地做好现在这份职业，让自己努力向顶峰走去。在上山途中积累的所有一切都会在梦想出现时刻，转化成自我实现的力量。你的职业线画得越好，你就为你的梦想积累越多的“存款”，当你的事业线出现的那一刻，你就能越快地投入与开始。 职业发展的规律是：生存、定位、发展、自我实现。时间可以缩短，但是阶段无法跨越。每一个人都可以成为自己的传奇，只要你努力、机敏、坚持，而且敢于放弃。 跟周杰伦学习如何做屌丝 其一，完美的工作不是一下子就能获得的，需要长期技能的积累和经验的积累，如何渡过这个难关？先让自己生存下来是关键。其二，大部分学生毕业的时候，最需要补的不是专业技能，而是适应社会的心态。这堂心态课可以在任何工作里面学到，心态往往比能力更加重要。综上所述，毕业后最好的职业规划选择应该是：找一份自己能做的工作，培养自己适应社会的心态。同时注意培养进入理想工作的能力，把完美工作作为长期目标来努力。 完美的工作是从不完美的工作中开始的。 真正让吴宗宪感动的是这个年轻人对自己创作的认真程度。打动吴宗宪的，与其说是才气，不如说是认真。我的很多名企的咨询经验也告诉我：不管能力有多大，企业往往只选择那些认真对待自己工作的人，这本身是一种最重要的能力。 进入行业内的第一平台并展示自己。 每一个人进入职场的时候，都会遇到类似的问题。犯下大错、领导批评、不被人认同……学习犯错是职业发展期中最重要的部分：如何对待错误，比错误本身更加重要。没有被上司的讽刺打倒的周杰伦，反而用更多的努力征服了他的上司。胜利者不一定是总赢的人，能够接受打击，能够仔细反思自己的问题，能够更加积极地对待事业，才能取得最终的胜利——我们可以做错的事，不要做错的人。 越早开始者，往往越容易成功。 一种方式是先努力发展职业线，暂时放下梦想，找到别的生存支点，然后在职业发展稳定的情况下，慢慢切回梦想领域。如李开复、鲁迅这种完全自食其力的榜样，最靠谱； 第二种方式是找到个有实力支持你且认同你事业的人，帮你扛着生存线。如恩格斯之于马克思，如凡·高的弟弟提奥之于凡·高，如EB（Etienne Balsan）之于香奈儿。这种方式你既有惊天才华，又能遇到贵人相助； 最后一种是你家底丰厚，完全不存在生存期，可以直接从事业线入手。如爷爷是英国首相的哲学家罗素勋爵，如老爸是开唱片公司的歌手陈慧琳同学。这种情况，呵呵——你知道一下就好了。 但是为什么很多人即使有好职业、贵人相助或者丰厚的身家，却依然没能开始事业期？原因很简单——大部分的人，从来没有真正走出过生存期。 自由=能力-欲望 这意味着什么？意味着我有足够的经济实力和空闲时间来看书、弹琴、旅游、和有趣的人交往，能让我兴致起来就飞去某个城市见老友，能参加一场有点贵的音乐会，或者去美国参加个学术大会。意味着有一天，当“新精英”可以自运营时，我可以跑到国外读个和职业发展毫无关系的蓝调硕士、哲学博士。也意味着我可以不把“新精英”看成赚钱的工具，而真正做点有意思的事。在同龄人中，我的收入中等，但是我享有比大多数人更多的——自由。 能力的加法需要时日，而欲望的减法则快捷很多；如果能力暂时不足，至少我们能控制自己的欲望。我们称失去自由的人为“奴”，当你的欲望大于能力，你就成为了把自己套死的“奴”——刷的比赚的多，谓之“卡奴”；开着无力承担的车，谓之“车奴”；住在需要45岁前全力以赴才能还清房贷的房子里，叫“房奴”。欲望为你自己套上了脚镣。 消费主义是理想主义的大敌。如果你拥有宽裕的财力，房子的确是个不错的投资和保值品；但是如果你需要把你未来10年的大部分收入都押到一个房子里去，如果你觉得即使吐血也要iPhone，如果你觉得没有某个牌子的包包、衣服或车就没法出门……如果你生活有了太多的“必须”，那你就成了消费欲的奴隶——无论你是卡奴、车奴还是房奴，无论你欲望的理由是面子、丈母娘还是好好爱自己，超越能力的欲望都会给你的理想带上锁链，使你卖身为奴——即使你能看到你的理想，你的欲望主子也不会放你过去。 控制你的欲望是自我实现的重要手段。 如何找到事业线？ 你的事业应该是能让你在“热爱的领域努力地玩”的领域，同时满足兴趣、能力和价值，符合你的生涯需求。但是如何进入这些职业？下面是一些常见的攻略。 财务自由的人如果不符合第一条，那么财务自由是另一个很重要的因素。在新的领域，只要有足够的无压力的时间，能力和资源都可以慢慢积累。这个时候，财务自由（一个人可以不通过工作就获得让自己能生活的收入）就变得重要。财务自由有很多方法：理财、期权股票、家庭支持等。很多生完孩子的职场女性、家庭相对宽裕的子女或者有成功经验的二次创业者，都适合这个方式。 Pro-Am（Professional Amateur），意思是：用业余时间来做，并不作为主业，却在专业水平方面达到了职业水平的人。 从事着很多无法一下子兑现价值的职业的人，都选择了用业余专业者的方式实现梦想。 “既然当年明月可以做着海关官员写出来《明朝那些事儿》，为什么我不能？” 世界上第一批乐手和运动员都是Pro-Am，这也是乐器和球类都可以play的原因。 什么人适合选择Pro-Am的事业方式？ ① 需要个人技艺，但是不太需要团队合作的职业，如音乐、艺术、文学、心理、职业咨询、色彩、健身、瑜伽教练、户外等方面，都容易出现Pro-Am。 ② 网站站长、个人博客、淘宝店长这些不需要固定上班时间也能完成的职业，也是Pro-Am的重要领域。你能想象Linux系统是几千个世界顶尖程序员自发免费开发出来的吗？这些行业往往需要漫长的积累期，前期回报不明显，全职进入往往无法跨越生存线。这个时候，Pro-Am往往是最好选择。 为生存，为做好，为世界。当一个人从职业期进入事业期，他的职业虽无变动，但立意转换，格局扩大，他变得心灵宁静，他的眼神也变得平静且坚定。 写书何尝不是如此？从我第一次战战兢兢地写《拆墙》，我就处在写作的生存期，并无太多积累，文体、素材都是最适合大众的路子。等到写这本书，已经走到职业发展的阶段，可以慢慢地按自己心中所想，搭自己喜欢的架子，建构一个完整的学科。这个时候重要的是，千万不要对畅销有太多的欲望，守住生存线就好。一旦有了这种定见，自由度大增。 现实和理想总如蝴蝶的双翼，只有一起扑腾才能飞。 写给你，其实也写给自己 无须讳言，就像你每一个以“我有一个朋友”开头的笑话其实都是你自己的糗事，这里每一篇《写给……的你》，都是我自己曾经的心路历程。我曾经愤怒、装睡、接触苦难、想走捷径、不完美，又崇尚身心灵、爱自由、想意义……我就是这样一个满身缺点、磕磕碰碰，又总相信生命无比美好的人。在走的路上想到了些什么，就记录下来给自己，成了这一章。 写给苦难中的你 如果你必须面对一个苦难，那么你一定已经拥有了改变这苦难的资源。千万别认为自己渺小、卑微、无力。每个人身上都有改变世界的因子，每个人都能用自己的方式去改变世界。 乔布斯就这样把每一次跌倒都变成一个机会——他每摔倒一次，就抓起一把命运的沙，吹走污泥，找到里面的宝石。 一切的经历都是学习，一切的苦难都是机遇。 当他被苦难击倒，他琢磨这苦难与目标的关系；当他重新回到路上，他带回其他人所不具备的智慧与能力——而我们大部分人，目标都太短浅，所以我们害怕失败；也正是因为我们害怕失败，才缺乏那些不寻常的精彩与可能。 总有一天，你的生命会像电影一样，在你眼前一闪而过，请确定它值得一看。 简单来说，如果一个人觉得自己活得苦哈哈（是指内心痛苦，不是物质清贫）还在疯狂付出，那么付出就只是一种自我逃避或者治愈的自助手段而已。自助比自残好很多，但并不算纯粹。而如果一个人不断付出，而且还内心快乐，活得幸福，这则是一个人自我实现后，最干净、纯粹的付出。 更让人吃惊的是，经过思考，他把自己遇到的苦难归因于“他们从小缺乏教育”，并且尝试靠自己来改变这一切。这真让人吃惊。他没有像有些网民一样，一边在网上抱怨高考制度黑暗，一边送孩子上最好的奥数班；他好像也没有意识到，他自己都只是一个高二的辍学生——他本人就是缺乏教育的受害者之一。如果当年把他吊在电扇的那群人听到这个想法，估计会狂笑着把电扇开到最大一档——教育？！你转晕了吧？ 这念头有多不自量力，阿里木就有多坚定。从在烤肉钱里面翻出300元递给一位求助的慈善人士开始，到在贵州大学建立奖学金5000元……一直到今天，阿里木一共捐出10万元善款，帮助了160名贫困学生。一根羊肉串利润三毛，这是他33万串的利润。在这期间，他继续住棚屋，在被老板娘骂“抠得要死”的小店吃馒头和凉粉，和他的老婆嬉皮笑脸地拌嘴，继续在夜市里面嬉皮笑脸地卖他的羊肉串。 有个笑话说：一个人去医院急诊室，发现医生都不见了。问干吗去了，答学雷锋日，上街学雷锋去了。和这个笑话一样，在教育培训界多年，我见过太多抓狂的情商教练、无人知晓的营销专家、迟到的时间管理讲师，和从来不按自己讲的方式管理公司的管理专家。 对于任何一个苦难，我们有能力，有态度，也有意义。每个人都能完成对苦难的修炼。 所以，我们应该有勇气，把苦难酿为美酒，把深渊变成大河，把破口补成鲜花，让苦难成为信仰，让自己成为改变自己命运的神。 生存模式：面对苦难与挫折，从此在苦难、损伤的地方一蹶不振，这种模式叫作生存。恢复模式：面对苦难时状态下降，但有自己的弹性，在一段时间后，他们慢慢恢复到原先的水平。升华模式：苦难没有打倒他们，却让他们得以在苦难中更强大，获得新的技能和思考，这种模式叫作升华。 写给愤怒的你 我认同民智的提升，我渴望民主。但是我天生与那些只攻击社会的黑暗面、制度不公而没有进一步行动的观点保持距离——我们如此愤怒地攻击社会、攻击时代，殊不知愤怒也是无能的代名词。 愤怒是好的，但愤怒也是不够的。愤怒意味着我们依然生机勃勃，依然没有被现实压倒屈服，依然愿意对世界感到不满，依然认为世界能比现在好。但愤怒也意味着我们把自己幸福的可能性托付于对方，依然与对方在同一个系统，依然在这个系统里被压迫，依然对这种压迫，无能为力。 你痛恨这件事情，结果却完全认同了这个方式。你不是痛恨这个游戏规则，只是痛恨自己玩不好。这样的愤怒并不能让世界更好，甚至也不会让自己更好。一万个、一亿个这样愤怒的人，也无法有主张地让世界变好——因为这些人好像推翻皇帝暴政的奴隶，他们逐渐会成为下一个皇帝的奴隶；即使这些人有一天真正成为某个领域的主人，他们会发现自己成了当年自己最痛恨的人。 你唯一的能量，花在表达你的仇人们有多么不道德上。你除了为这个世界上增加一个悲惨故事，并且自己全情出演主角之外，没什么意义。 如果你能善待自己，这已经是件了不起的事了。如果能够再进一步，就是悲悯。 如果你能够再强大一些，也许你会发现更多的真相。你会发现，那些当年你痛恨的人、那些让你愤怒的人，也是游戏的牺牲品——他们已经被世界狠狠地报复过了。他们不需要另一次鞭打，他们需要的也是帮助。 当一个人伤害你的时候，他已经被深深地伤害过，他不需要再一次鞭打，需要的是怜悯。 不再愤怒，做自己，帮身边人，改善世界。 他们曾经也愤怒过，但最终，现实的理想主义者不再愤怒，做自己，帮身边人，改善世界。你也许会说，你是个梦想家，但不是唯一的。如果有一天，你也能加入我们，世界将有所不同。 ① 你可以不喜欢这个游戏，但是你可以玩得很好。② 上策是玩得快乐也心安，中策是把自己搭进去至少还能赢，下策是抱怨这是个最糟糕的游戏。③ 除了同流合污和冰清玉洁，我们还有很多选择。关键是你要有离开这个游戏还能活的能力。④ 玩好不意味着一直要赢，而是找到自己的定见。成王败寇要认，但是 莫以成败论英雄，英雄是维护自己信念的人。 写给装睡的你 第一个结局：呼喊的人声势越来越浩大，积聚所有的力量，大家打开了铁屋子，重获新生。这个故事你不陌生，人类大部分的进步，都是这样的趋势。文艺复兴、启蒙运动、新中国成立，都是这样。 这个故事你也并不陌生，苏格拉底被希腊市民毒死、布鲁诺被烧死——先知往往死于非命。 这个故事你不陌生，我们身边很多的人，都是装睡的人。他们受过良好的教育，他们偷偷关注很多呼喊的人，他们清楚地知道好坏、善恶、科学、民主，他们能够从书上、网上找到很多生活应该这样和那样的理由和论据。 但是他们唯一不敢做的，就是站起身来帮忙。他们敢于在网上转各种骂政府骂社会的帖子，却不敢在真实的生活里拒绝领导的一次举杯；他们能写出一篇万字的洋洋洒洒的关于美国人的素质有多好的文章，却不敢在公交车上看到小偷时大喝一声；他们去庙里还愿，几万几万地敬，且每天念佛，他们相信因果报应，却毫不犹豫地往产品里面加各种添加剂。 比愚昧更加可怕的是装睡。装睡的人虚伪又懦弱，他们知道一切该如何，却从来不愿意投入。这就是装睡的人。装睡的人以为自己和房子倒塌没有关系，其实他们是最大的合谋者。因为发言只需一人，而沉默却需要合谋。 他说：“公平。”讲完这个故事，他接着说，如果在国外，那样的人搞不好会被群殴。 尊严这东西不是你的西服，可以在开始的时候脱下放一边，混出来以后再抖抖穿起来。心里面的界线像是我们的手脚，一旦砍掉，也许一辈子都无法生长回来。 但是“新精英”不想装睡——我们的目标不是把现有市场里面的资源全部占据，而是让更多外面的人理解生涯规划；我们也不是想让每一个人都非来“新精英”学习不可，但是我们期待更多人能成长为自己的样子——这也是我忍不住又要写不仅会让我失业，也可能会让我很多同事失业的第二本书的原因。 坚持这样的原则，一开始很难，后来就越来越容易——因为很多对手看到了我们的态度，成为了朋友。而新精英自己的发展也加速起来——我们发现把观察别人找缺点的时间和精力放在成长上，足够把自己的核心竞争力打造出来。“夫唯不争，故天下莫能与之争”就是这个道理吧。而如果反过来，一开始就抢客户，虽然开局很容易，后来就越走越难了。很多事情都如是。 我们有个牛×基金，每年给员工一个月薪水和15天假期，让他们做一件自己认为牛×的事情。有人用来横穿美国、环游台湾、飞回去和暗恋对象表白或者给自己刺一个纹身。只要你觉得这是成长的突破，并且通过员工委员会审核，我们都支持。 我们相信善意、相信分享、相信人们会成长为自己的样子。如果你相信一个东西，总得有人为他做些什么。 宋飞：“因为我爱学生、爱音乐、爱教育。因为我自己成长的过程没有经历过这个，所以我才想当一个老师，给其他学生带来我从小经历过的那种希望。” 宋飞：“因为，我不说话就已经不能给从事这个事业的学生带来平安和幸福了。那我宁可损失掉我自己的平安幸福、别人想象当中的这种完美。” 如果大学里面没有知识，只有欲望和交易，是不是洪水？是不是人们头脑里面的洪水？我们说，是的。后来我进入了学校，我慢慢看到，洪水来了。 这件事情有个喜忧参半、有中国特色的结尾：中国音乐学院补录了四名学生，而央视的节目在首播后没有按照惯例再重播；宋飞没有停止自己的教学生涯，继续当她的老师。 我感谢这期节目的所有工作人员，因为他们不仅把镜头对准了一个著名学府的腐败事件，更带我们去见证了一个明知难以回天却依然挺身抗争的弱女子的勇气。这无关名誉，也无关成败，只有一个醒着的人最宝贵的清醒与勇气。 我觉得不公平。有更多不装睡的人，那个铁屋子，就一定能打开。最先他们逮捕共产党员——马丁·尼默勒在德国，起初他们追杀共产主义者，我没有说话——因为我不是共产主义者；接着他们追杀犹太人，我没有说话——因为我不是犹太人；后来他们追杀工会成员，我没有说话——因为我不是工会成员；此后他们追杀天主教徒，我没有说话——因为我是新教教徒；最后他们奔我而来，却再也没有人站出来为我说话。 最后他们奔我而来，却再也没有人站出来为我说话。 写给怕走弯路的你 By acclamation, Michael Jordan is the greatest basketball player of all time.一片欢呼声中，乔丹成为历史上最伟大的篮球运动员。 乔丹在内心深深地享受这份宁静，他的棒球生涯是献给父亲的，并不精彩，但温暖。在父亲离开后的几年，他重新触到自己在篮球场上无法触及的生命的温度。乔丹的生涯走出一条巨大的曲线，父亲的离开让他直面生命的其他维度，他决定遵循自己的内心，为自己和父亲打两年球。谁又能说，那两年的乔丹，那个在篮球场上宛若上帝本人亲临，却在棒球场四处嘘声中灰头土脸的乔丹，他的手指上，没有戴着自己心中的冠军戒指？ 很多人不懂得这个道理，他们认为如果一个人既没有提升，又没有变得更加专业，那就一定是在无所事事、不务正业。他们无法理解为什么有人要放着好好的工作不干出门旅游一个月，他们无法理解为什么好好的日子不过要折腾些幺蛾子。其实也许那个人正在你看不到的维度努力挑战着自己的极限，修炼着自己的功课。企业管理者也是一样，规则和结果带来绩效和专业，而文化和包容则带来温度和宽度，所有伟大的企业，在有自己的高度和深度的同时，都一定有一个匹配的温度和宽度系统。 回到乔丹身上，在积累了越来越多的内心温度的同时，乔丹也在发现自己的限制——他的确无法把篮球场上的优秀带入棒球场中。 我想乔丹的收获有三。第一个是父亲的心结已了，他可以安心地打篮球了。第二是他在棒球场上重新深刻地认识了自己的篮球天赋。第三，他了解了失败，更加珍惜成功。 看上去的生涯 实际的生涯 所以站得远的外人，总会羡慕走在线上的人一帆风顺。只有当事人和同行者知道，那只是看上去很美，而其中坎坷又何足为外人道呢？因为自己没有走过，永远都不会明白。 我们在瞬间交换了一个秘密，只有那些经历过真实生涯的人才能明白的秘密。人生无直线，因为直线从不转弯。而转弯和改变，是人生必经之事。何况，你不走点弯路，怎么知道什么是直线呢？ 写给不完美的你 好的，不管结果如何，现在的你创造了这样一张独一无二的白纸，就像你也拥有了自己这样一个随机的独一无二的不完美生命。如果你将要用接下来一小时的时间，只能在这张纸上工作，你会如何处理这个缺陷？ 间学习和模仿那些台前侃侃而谈、随机应变的人，却总是差距很大（别人也在进步啊）。可惜的是他从来没有关注自己作为内向者的优势——他是一个能花三小时把PPT做到尽善尽美、图文并茂、每一个数据都清晰明白的人，而这往往不是一个随机应变者能下的笨功夫。转变思路以后，他成了公司里最能展示的几个人之一。 化疗、放疗和手术是癌症治疗的三种常用方式。化疗以化学毒物杀灭正在激活中的癌细胞，同时也会杀灭身体中大量正常的免疫细胞。化疗也无法杀灭休眠中的癌细胞和正常细胞，这也是为什么化疗后，往往会发生各种转移——如加压的地壳和爆发的火山口的关系，这个地方的增殖被扑灭，另一个地方的癌细胞又被激活起来。 作为病人的医生自己也选择了生活质量高，但是死亡率高的医疗方案。也许作为医生的角色，他们需要以杀灭疾病作为“绩效”，但他们自己懂得生活质量比杀灭疾病更重要。 比如人的智商，基因决定你是80~120的普通人，还是110~160的天才段位，而你的个人努力决定了你是靠80还是靠120那一端。 奥普拉并不是个例，科学实验的数据结果也类似——500个超出标准体重50%的胖子使用此种方法减肥，有一半人坚持到了最后，超重的部分平均减少42%。但是三个月以后，一旦恢复正常的饮食结构，这些人的超重部分又反弹到80%左右。最好的结果是有13%的参与者在三年后依然保持身材。时间越长，减肥的效果会慢慢减弱，你的体重又会回到稳定状态。 科学家还发现，体重波动对身体的损害比肥胖更大。简单来说，胡乱减肥比肥更具危害性。 （在《认识自己，接纳自己》中，塞利格曼列了哪些是能改变的、哪些是不能改变的表格。） 以前有一个著名的木桶理论——一个木桶能装多少水，取决于最短的一块板。在工业化时代，这个理论的确非常有效。但是在全球互联的时代，这个理论实际早已破产。 所以今天的企业发展从短板原理，变成长板原理——当你把桶倾斜，你会发现能装多少水决定于你的长板（核心竞争力），而当你有了一块长板，就可以围绕这块长板展开布局，为你赚到利润。如果你同时拥有系统化的思考，你就可以用合作或购买的方式，补足你其他的短板。 所以在职业生涯发展中，最好的能力策略是“一专多能零缺陷”。“一专”指让自己有一项非常非常强的专长；“多能”指有可能多储备几项能力搭配着使用。通过自身努力和对外合作，让自己的弱势变得及格即可；而最需要避免的情况是“性情大于才情”——你有些小优势，但是由于与你合作的成本太高，没有人愿意和你合作。这与应对疾病的策略一样，先让自己别得快速致死的“急性病”（比如工作态度、诚信、合作能力等基本的综合能力），然后和自己的“慢性病”（比如某些方面的天赋与技能不足）和平共处，专注发挥自己的优势去。 汪冰说：“你看，你总是在接到任务时迟迟不开始行动，但是最后结果又总不错。是不是你在一开始的时候，潜意识就开始酝酿，只是在最后一刻，才突然孵化出来？你这个大脑或许不是拖延症的居住地，而是一个孵化器。”春雨一拍他那个烫得已经很像鸡窝（鸡蛋孵化器）的大脑袋说：“哈哈，我喜欢这个想法！”从这以后，他还真的孵化出不少好点子。 写给不完美的你所以，亲爱的，不完美的你，生命被点上黑点、努力擦拭的你，在你的生命中，有没有不可抹掉的黑点？不如意的出生，缺失的机会和教育，不公平的社会环境……但是是什么让你今天依然活得坚挺？是什么让你今天愿意试试看一本叫《你的生命有什么可能》的书？是什么让你今天还有继续生活的勇气？在你的生命里，一定还有些部分在发光，一定还有something works（一些东西在发挥作用）。专注于生命可能的部分，让那部分发挥价值，此生就已足够。正如那句著名的祈祷词一样：让我有胸怀去接纳不可改变的，有勇气去改变可以改变的，并有智慧区分两者。修正自己是一种勇气，接纳自己的不完美也许更是，而接纳自己后掉头去追寻自己想要改变的，则是一种智慧的人生态度。加缪说：重要的不是治愈，而是带着伤痛前行。持续聚焦于做正确的事情，就没有机会做不正确的事情。持续做幸福的事情，控制好不幸福的事，幸福就会生长起来。 花园里种满了鲜花，就没有机会长草。专注于生命可能之事，让生命如夏花般怒放。 积极心理学：黑点不是重点，还有很多地方有空白。别花时间搞黑点啦，关键是把白纸的价值用出来！ 写给爱自由的你 发现了吗？在这个世界里，你的每一个行为都会与其他人发生作用。当你拥有无拘无束的“自由”的时候，对他人来说，你则拥有了一个毫无约束地伤害他人的特权——这种人没有人愿意和你玩。 当涉及别人，自由和责任同时出现了。 哈耶克在《自由宪章》里强调了法律对自由的重要性：“法律的目的不是取消或限制自由，而是维护和扩大自由。” 所以，你的自由以他人为界，你挥舞的拳头以我的鼻子为界。孔夫子在人生最高的境界“从心所欲”后面，加上了一个“不逾矩”。因为如果仅仅是从心所欲，那么一岁小孩都会，而从心所欲不逾矩，才是真正的自由。 那么，有钱就能有一切的自由吗？首先，有钱的确能让你提高自由度，但是赚钱本身就是件需要满足他人需求的不太自由的事，你该看到花钱的自由背后不自由的代价。即使天生有钱的富二代，也有要满足他们父母亲的需求的责任——一旦过了18岁，他们的父母亲也有给不给钱的自由。其次，世上有钱买不到的东西实在太多，友情、爱情、才华、格局、智慧……在所有钱无法购买的领域，你都没有自由。你的自由以他人为界，而你所期待的随心所欲的自由，并不存在。 但是当提到法律和社会制度下的“自由”时，几乎所有的正式文件都用了另一个词“liberty”。 比如说自由女神叫Statue of Liberty（别去美国丢人啊，free woman是“免费女郎”）。《独立宣言》中“每个人都被赋予了不可剥夺的权力，生存、自由以及对幸福的追寻”用的是“life, liberty and the pursuit of happiness”。亨利在1775年弗吉尼亚议会上的名言是：Give me liberty or give me death（不自由，毋宁死）。Liberty是什么意思呢？ 经济自由是指你有“自己决定钱花在哪里”的自由，而不是“爱买什么就买得起什么”的自由。 “按照自己希望的方式而非强制的方式”来生活，“决定什么东西和谁的需求对自己最重要，是一个自由人的基本权利和义务之一”。 你可以理解为什么处于任何环境下的人，都曾经、正在也永远会有选择的自由。 他可以选择在不喜欢的情况下慢慢适应现在的工作，以之作为生存和发展的跳板，也可以选择不好好干。他可以选择讨好父母获得学费，也可以选择自己攒钱不需要靠父母认同。他可以选择晚上加班读研，也可以选择保存精力不再苦读。他可以选择即使父母不愿意也要坚持，也可以选择妥协。他有选择的自由，但是没有选项的自由。 我希望人们放弃的是他们痛苦的根源，那就是：他们总渴望存在这样一种不可能的选项的 自由： 而对于一个成熟的自由人，游戏规则其实很简单：你有好好干还是大闹天宫的自由，而公司也有升你还是降你的自由；你有听或不听父母的自由，而你的父母同时也有发飙或不发飙的自由；你有追寻感兴趣的工作的自由，而企业也有寻找能力更强的人的自由。你可以自由地挑选哪一个更好，但是你并没有能力要求世界为你而改变。你们都平等地拥有选择的自由。追寻“选项自由”的人，他们像等待戈多一样，在人生站台等待这永不进站的“自由”；终其一生，自由没来，无奈倒总是准点。很多人沉醉于这种不切实际的幻想中还有一个更深层次的心智问题——不愿意或者无力承担自由背后的责任。 不想选择—觉得无奈—愤怒—受害—恨 不选择，其实是最糟糕的选择。 类似的选择困境其实很多：在家人的反对之下，我是否有追求自己想过的生活的自由？是否有用自己的方式工作的自由？我是否有交自己喜欢的朋友的自由？我是否有做自己想做的事情的自由？不是说人生而自由吗，为什么我们没有选择自己生活的自由？以小娟的故事为例，她有认为“自己想要的爱情方式和自己的需求”更重要的自由，也有选择如何应对的自由，但每个选择背后她也都需要为可预见的结果负责。 自由意味着责任，而责任需要能力承担。人们畏惧自由，往往是因为畏惧背后的责任与无能。如果你想要有决定自己未来的自由，一定要有决定自己未来的能力，并且愿意用这些能力为自己负责。 自由与责任成长是一个自由逐渐扩大的过程，你慢慢开始可以自由地花钱、居住、择偶、工作、生孩子……随着自由的好处越来越多，必须承担的责任也就越来越多。自由与责任不仅不是对立，反而是不可分割的。法律上规定18岁之前，孩子们尚不能为自己的行为完全负责，所以他们也并未获得完全的自由；精神病人不能自由选择自己的行为，所以也无须为此负法律责任。我们有开车的自由，同时就有遵守交规的责任。 自由与责任，一如太极的阴阳、鸟的双翼，同起同落。 2000年开始，大学生开始双向选择，享受到突如其来的就业的自由，却并没有承担起自我定位和求职的责任。正如哈耶克所说：“在自由社会中，我们不仅有了技术，而且还应该有让自己的技术被认知价值的能力。” 对现代的职业人来说：你当然有选择一份喜欢的工作的自由，所以你也需要承担起自我销售、与人竞争的责任。你当然有升职和自我实现的自由，所以你也需要承担起表明自己有能力胜任的责任。你当然有特立独行的自由，所以你也需要承担大家不支持你的责任。你当然有频繁跳槽、不断选择的自由，所以你也要承担起社会对频繁跳槽者的评判，以及也许你会选错的责任。女性有生孩子或者不生孩子的自由，所以也要承担起社会可能对生育期职场女性的歧视，承担起自我整合、重回职场的责任。大小城市的选择也是一个经典的自由与责任问题。如何选择大小城市，一个比较幸福的方式是，去大城市闯荡，到小城市养老。为什么我们年轻的时候都想闯荡天下，而老了又纷纷叶落归根？显而易见，大城市自由多，责任也多，压力大；而小城市相对不自由，但责任也小得多。 所谓成熟，就是懂得评价自己能承担的责任，选择自己能享受的自由。 即使是有人做错，却还是需要你来负责。 你站在一个十字路口，准备过马路。车行的路口亮起红灯，而行人通道亮起绿灯，你迈步前行。正走到马路中间，有一辆大卡车闯了红灯，向你冲来。你看了一眼红灯，确认是他违规。你有什么反应？A. 躲开，先自保。有可能的话，记下车牌举报。B. 站在马路中间，对这车大喊：你错了！然后，砰……啊……啊……啊……你会选择哪一个？肯定是A。但是我们生活中还有很多人选择B，为了证明对方错了，他们不惜把自己搭进去。 为了证明昔日恋人的分手是错的，他们与一个不喜欢的人在一起，“证明给你看你失去了什么”；为了证明别人的想法是错的，“就做出来给你看看”；为了证明世界不够好，他们宁愿自己过着糟糕的生活。 毕老师回答说：“你的钢笔和你的父母都不是你能够改变的，但是你的那支一毛二分钱的笔却是你能把握的。只要这支笔写出来的答案，与那支钢笔写出来的一样，就会获得同样的分数。而如果你能够持续写出更好的分数，你就能慢慢改变自己的生活。”我喜欢这个回答。我们渴求公平，正因为世界本不公平。所以重要的不是判断是否公平，而是如何面对不公平。世界没有给我们选项的自由，但我们总有选择的自由。 总有人在你生命里犯错，但是只有你在你的生命里负责。请担起责任来。2从“愤怒—无奈—恨”到“自由—责任—能力”循环，我大概花了一年时间。当看到问题，解决就变得简单——我大概花了一年多时间，让自己重新慢慢提高管理能力，开始重新自由一点。希望你比我快一些。 简单地说，过度地为别人负责的人，是剥夺别人自由的人。 乔布斯承担了苹果前进的大部分责任，所以他也获得了足够多的自由。 当你有了按时高质量交付的执行力，你就有了时间自主的自由；当你有了快速学习和迁移的能力，你就有了轻松跨行业的自由；当你有了照顾好自己的能力，你就有了安心等待自己喜欢的人、全情投入恋爱的自由；当你有了语言能力和健康的身体，你就有了周游世界的自由；当你有了背起自己的责任的能力，你就获得了全世界的自由。能力，是自由的第一要务。 能力越大，责任越大。他决定担起这份责任。 曾国藩无疑是近代史上的一只巨牛。他28岁中进士，然后在京当官10年，连升10级，从一个正处活活干到正厅局级，算是学霸。43岁时太平天国大乱，他带领3000湘军打仗，11年后攻陷天京，算是军神。他握天下兵权，算是皇帝候选人，但他选择了主动解散湘军。他55岁上书请求解除一切职务，注销爵位，未遂，创建江南制造总局。他61岁提出在美国设立“中国留学生事务所”，算是留学祖父。 如果你希望自由，控制欲望是你必需的修炼。在大清朝必需，在科幻小说里必需，现在在科技社会更必需。 高科技能让人们更自由的想法由来已久：从工业革命开始，人们就相信，当机器越来越多地替代人工作的时候，人们就可以从工作中解放出来，开始休闲。 问题就在这里，当技术让我们的效率提高一倍时，我们的欲望却无暇休闲，而是希望能提高三倍。在我的大学时代，当我们用一个下午亲手写完一封信，然后把纸张折成喜欢的形状，信封贴上邮票，用胶水或者饭粒封上封口，心里期待这封信件可以在三天后尽快地在心爱的人手上展开。但是当我们可以在三秒内就发出一封e-mail的时候，我们却认为每天至少要回复20封电子邮件才是正常的。我们原来期待十年磨一剑，现在我们希望三年上市。我们每天挤车一小时回家，站在公交车上看着开小车的人，心里想着有一天自己能开车上班该多好，但是当我们真的有了车，我们又开始频频按喇叭，希望自己能够在15分钟内到家，而这个时候，你或许已经住在一个开车也需要一小时的地方了。 今天，企业家不快乐，高分学生不幸福，高官不安心，因为他们都在用太多的精力饲养他们的欲望。中医说，在求不得和想得到之间，全是火气。 自由=能力-欲望。一个人的自由之路无非有两条，一条是给能力做加法，一条是给欲望做减法。提高能力让你能承担更多责任从而获得更多自由；而降低欲望则让你宁静下来，让生命变轻，把自由还给自由。 写给追寻生命意义的你 他问我：“你说人活着，为了什么？” 正如你问一个旅行的人：这次旅行最有意义的部分是什么？ 所以当所谓的成功人士试图把人生的意义总结成几句话告诉你的时候，你一定要清醒——那只是他自己的生命意义的其中一个说法而已，不是你的。所以，人生的意义，绝对不在别人那里，只在你那里。 即使我们的生命真的有终极的意义，我们也不可能在活着的时候知道它。因为一旦我们知道了自己生命的终极意义，知道这件事本身就会改变我们的人生，让我们拥有新的意义（听上去很拗口吧，不过就是这么回事）。但是，我们又那么渴望知道一个意义，该怎么办？ —我们不知不觉地长大，有一天，我们无法回避自己的存在，不得不开始思考，我的人生有什么意义？ 你希望自己的生命有什么样的意义？你能够为这个意义承担什么样的责任？你能为这个意义付出什么样的代价？你能为生命付出什么、承担什么责任，生命就可以有什么样的意义。 我不信神，在我看来，人生本没有什么设定的意义。如果想要有意义，你就只能自己创造一个。创造自己生命的意义，就是我的宗教。 这篇墓志铭会记录关于你的什么部分？它会如何评价你？会记录你此生做过的哪些重要事情？会提到你的什么贡献？找个安静不受打扰的时刻，写下你的人生墓志铭。 跋 愿你过上我从未看见与理解的生活 这本书是我的成长三部曲的第二部——这三本书是一个完整的体系，从打破思维障碍的《拆掉思维里的墙》，到看到更多《你的生命有什么可能》，到讨论如何自我成长的《成长为自己的样子》——所以这个跋，也像是《成长为自己的样子》这本书的序。 所以弯弯，重要的不是小心翼翼地活着、谁也不伤害、谁也不得罪。让谁都喜欢你，这不可能。关键是创造你自己的生命——让自己活出意义来、活出特色来，活得让自己对得起因为你而失去生命的牛牛羊羊猪猪，对得起人们为你注入的生命力。好的生命不是完美，也不是安全，而是值得。 亲爱的弯弯，这个世界并不公平。努力能在一定程度上改变命运，但是不一定能颠覆命运。所以记得，与别人相比是没有意义的，那是一种永无宁日、 绝无胜算的自我折磨。如果你有能力，记得要和自己比，让自己过得好一些，理解自己的心有多大，给人生做加法带来快乐，做减法带来安心，加加减减到让自己舒服。世界虽然没有给每个人提供完美的生活，却给每个人足够的资源让他们收获自己应得的。 有个叫上帝的人，他开了一家努力银行。每个人都有一个自己名下的努力账户。每个人每天都在往里面存自己的努力。有的人存得多，有的人存得少。有人存了第二天就取，有的人则在很多年以后一次性取出来。 上帝要保证每个人账目公平，不能有错账。上帝还要标注那些存努力存得最多的金卡客户，给他们分配更多的回报。上帝很忙很忙。但事实总是这样，总是那么几个最努力的人有最多的回报，这工作也太不好玩啦。所以每隔10年，上帝就调出所有的金卡客户，抽一次奖，然后随机把一个巨大的成功分给中奖的那个幸运的家伙。所以，宝宝，只要努力，就会有合理的回报。而那些巨大的成功，往往来自幸运——但是请先确定，你努力地拿到了金卡。 记得要活得精彩，活得认真，跟自己比。愿你过上我从未看见与理解的生活。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"IPCreator的书单","date":"2017-01-10T06:30:18.000Z","path":"2017/01/10/MyView/my-book-list/","text":"“美好的事物值得付出、等待和分享” 创新 创新者的基因 英文标题:The Innovator’s DNA：Mastering the Five Skills of Disruptive Innovators作者：Clayton M. Christensen豆瓣评分：7.4 观察，联系，发问，实验，交际 横向思维 英文标题:Lateral Thinking作者：Edward de Bono豆瓣评分：7.8 条条大道通罗马 六顶思考帽作者：Edward de Bono豆瓣评分：7.4 一个全面思考问题的模型，落实平行思维的工具蓝色思考帽：蓝色负责控制思考帽的使用顺序，它规划和管理整个思考过程，并负责做出结论。白色思考帽：白色是中立而客观的，关注客观的事实和数据。黄色思考帽：黄色代表价值与肯定。从正面考虑问题，表达乐观的、满怀希望的、建设性的观点。红色思考帽：红色是情感的色彩，表现自己的情绪、直觉、感受、预感等。黑色思考帽：黑色代表否定、怀疑、质疑的看法，合乎逻辑的批判。绿色思考帽：绿色代表茵茵芳草，象征勃勃生机，寓意创造力和想象力。 专利 图解专利法－专利知识12讲 一图胜千言 管理 像TED一样演讲 副标题:创造世界顶级演讲的9个秘诀作者：Carmine Gallo豆瓣评分：7.7 一个主题、三个要点、十八分钟 影响力英文标题:Influence: The Psychology of Persuasion作者：Robert B. Cialdini豆瓣评分：8.6 影响力的武器：互惠、承诺和一致、社会认同、喜好、权威、短缺 成长 你的生命有什么可能作者：古典豆瓣评分：8.4 成长，长成为自己的样子！ 拆掉思维里的墙作者：古典豆瓣评分：8.0 向自己的生命发问 把时间当作朋友 副标题:运用心智获得解放作者：李笑来豆瓣评分：8.5 要管理的不是时间，而是自己。 做最好的自己作者：李开复豆瓣评分：7.9 有勇气改变可以改变的事情，有胸怀来接受不可以改变的事情，有智慧来分辨两者的不同。 破解幸福密码作者：毕淑敏 豆瓣评分：7.6 幸福是一种心灵的感受，有意义的快乐就是幸福。 罗辑思维 副标题:运用心智获得解放作者：罗振宇豆瓣评分：7.2 独立、理性的思考通往自由的彼岸。 你要如何衡量你的人生 英文标题:How will you measure your life?作者：Clayton M. Christensen豆瓣评分：8.0 工作是为了更好地生活。 此生未完成 副标题:一个母亲、妻子、女儿的生命日记作者：于娟豆瓣评分：9.0 为什么是我？又为什么不是你？ 向死而生 副标题:我修的死亡学分作者：李开复豆瓣评分：7.3 不忘初心，心怀感恩，随缘随喜 投资 投资中最简单的事作者：邱国鹭豆瓣评分：8.7 定价权是核心竞争力，人弃我取逆向投资，便宜才是硬道理。 时寒冰说：未来二十年，经济大趋势（现实篇）作者：时寒冰豆瓣评分：8.3 感悟趋势之美 时寒冰说：未来二十年，经济大趋势（未来篇）作者：时寒冰豆瓣评分：8.0 感悟趋势之美 技术","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"管理之我见","date":"2017-01-09T06:30:18.000Z","path":"2017/01/09/MyView/my-view-of-management/","text":"基本概念 什么是管理？ 管事理人 什么是领导？ 让追随者“升官发财” 什么是狼性？ 以结果为导向，多为成功找方法 自我 自知者明、自胜者强、自律者自由 主管参考阅读：JMT主管管理技能培训 中层参考阅读：MTP管理才能发展培训 高层参考阅读：LTP领导力训练 关于分享 柳传志给杨元庆写过这样一封信：你最初是小鸡，你长成大鸡的时候没有人佩服你，当你长成火鸡的时候，也没有人佩服你，只有你变成鸵鸟的时候，别人才会佩服你，因为你比别人都大。所以，你的分享不会带来任何好处，只会给你带来不必要的管理困扰。参考阅读：王治全反思：被我“毁掉”的兄弟！ 关于黑天鹅 塔勒布在他后一本书《反脆弱》中给出的应对之道——黑天鹅的出现，和观察者有关。一只被喂养了很久的火鸡，它会觉得屠夫很爱它，对它来说，它在感恩节被宰杀就是一个黑天鹅事件，但这不会让屠夫吃惊。所以，塑造新的思维模式的办法就是，不要成为火鸡。应对科技挑战的最佳解决方式，就是让自己成为一家科技公司。参考阅读：刘湘明：应对科技挑战的最佳方式，就是让自己成为一家科技公司 关于“推销” 李笑来《新生——七年就是一辈子》之第19章节“如何克制自己的“推销”欲望”推销知识很难的更深层次的原因在于： 仅仅说是肯定没用的，得做，不然说没分量； 做都不一定是有用的，得有改变，没改变不算数； 有改变也不一定够，得有看得见的改变，看不见还是没分量； 有看得见的改变还是不一定成功，因为对方可能并不服气； 改变太大了也不行，因为对方一看，吓倒了，直接放弃了…… 真的感谢互联网，它给了我们另外一个可以分享的通道。自从我开始写博客之后，之前此类的烦恼彻底消失了。有分享欲望的时候，可以喷在网上，又由于没有了特定的对象，反倒没有了“获取认可”的压力，分享变成了一个纯粹开心的行为。能否有因获得认可而产生的快乐，只取决于两个因素， 我是否真的真诚（这个不用提）; 我是否运气好，消息能传递给那些能理解我的人（我好像这方面运气一直都不错）…… 于是，整个人就感觉少了很大一个负担， 该干嘛就去干嘛，说那么多有什么用？ 做了，就有变化，有变化，自己先开心，别人看不看得到其实并不重要罢？ 少说导致更专注，更专注导致变化最大化，有时候吓到别人，也怪不得自己罢？","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Management","slug":"Management","permalink":"http://ipcreator.me/tags/Management/"}]},{"title":"专利之我见","date":"2017-01-08T05:53:18.000Z","path":"2017/01/08/MyView/my-view-of-patent-strategy/","text":"基本概念 什么是专利？ 专有的权利 什么是专利的价值？ 风险控制、增值经营、竞争超越参考阅读：现代公司法务的核心商业价值构建 什么是好的专利？ 能带来价值的专利参考阅读：移动互联时代的知识产权新特征 什么是好的专利布局？ 产出更多更高价值专利的挖掘和扩展 如何有效实施专利布局？ 五位一体/沙漠寻路/三步六法","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Patent","slug":"Patent","permalink":"http://ipcreator.me/tags/Patent/"}]},{"title":"创新之我见","date":"2017-01-07T05:53:18.000Z","path":"2017/01/07/MyView/my-view-of-innovation/","text":"基本概念 什么是创新？ 你无我有、你有我优、你优我快 什么是体验？ 用起来很爽，很智能非常快 快速智能示例一 支持联系人拼音首字母键盘定位，智能屏蔽无数据按键 快速智能示例二支持联系人分组一键群发短信，智能屏蔽呼出按钮，以防用户误操作","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"},{"name":"Innovation","slug":"Innovation","permalink":"http://ipcreator.me/tags/Innovation/"}]},{"title":"成长之我见","date":"2017-01-06T05:53:18.000Z","path":"2017/01/06/MyView/my-view-of-growing-up/","text":"基本概念 什么是爱？ 陪伴就是爱 什么是幸福？ 健康、充实、知足和感恩 什么是成功？ 按自己的意愿过一生 什么是思维升级？ 技术/法律–&gt;商业思维 什么是自由？ 自由=能力-欲望参考阅读：《如何控制自己的情绪》 如何避免被洗脑？ 事情本身是否符合常识和逻辑 事情及对方的利益立场是什么 独立判断能力的重要性 美国的卡耐基说：成功来自于85%的人脉关系，15%的专业知识中国的李笑来说：学习重要，还是经营人脉重要？我的个人逻辑，分阶段调节不同比例，如：成长初级阶段（学校/应届生等）个人/人脉比例85/15，中级阶段（主管/经理等）50/50，高级阶段（总监/副总裁等）15/85 为什么系列 为什么要努力？ 拥有更多选择的自由 为什么要读书？ 开启心智，增长见识 为什么要留在大城市？ 见识参考阅读：《罗振宇：拒绝逃离北上广 见识决定命运》 痛点系列 功名VS幸福应试VS素质理论VS实践抽象VS具体宏观VS微观说说VS执行","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"酷派集团：“五位一体”高效管理7000件专利申请","date":"2017-01-05T09:22:06.000Z","path":"2017/01/05/MyView/my-article-for-newspaper/","text":"文章下载 酷派集团：“五位一体”高效管理7000件专利申请 “非苹果，即酷派。”酷派集团董事长郭德英在去年世界互联网大会上的豪言壮语仍言犹在耳，这份自信不仅源于酷派集团雄厚的技术研发实力，还得益于其前瞻性的专利布局和高效的专利管理。 酷派集团在手机领域耕耘多年，掌握了手机领域的诸多核心技术，在智能手机技术研发、专利布局、产品创新和提升用户体验等方面积累了丰富的经验。 在持续开展专利布局的同时，如何对7000余件专利申请进行高效管理？酷派集团给出的答案是：通过实施“一把手工程”、打造“五位一体”专利布局体系和采用“开放式”的创新模式，制定了以“提升商业竞争力”为核心目标的知识产权战略，以此发挥专利的最大价值。 “一把手”的管理理念 郭德英是酷派集团的首席发明人，自2001年提交第一件专利申请开始，截至目前，他已提交了100多件专利申请。以郭德英为代表的公司领导对技术创新和专利布局的高度重视，并身体力行地践行着专利布局是“一把手工程”的发展理念，是酷派集团高效开展专利管理工作的关键。 “企业开展专利管理的基础是以自主创新能力作为支撑，并服务于公司战略发展需要，但关键因素是公司领导的高度重视和支持，而酷派集团实施的‘一把手工程’为我们开展专利管理工作提供了有力支撑。”酷派集团知识产权部经理汪智勇在接受中国知识产权报记者采访时表示。 “截至目前，酷派集团在全球范围内已提交了7000余件专利申请，其中90%以上是发明专利申请，内容涉及多模多待、双系统、UI交互、手机安全等方面。”汪智勇向本报记者介绍，目前，酷派集团已有1500余件专利申请获得授权，其中包括数十件涉及通信领域基础技术的基础专利和数百件提升酷派集团智能手机高端市场竞争力的核心专利。 得益于公司领导的高度重视，酷派集团很早就开展了专利管理工作，并确立了以“提升商业竞争力”为核心目标的知识产权战略。汪智勇介绍，酷派集团实施的知识产权战略包括3个方面，即立足研发、聚焦市场，知识产权工作要全方位嵌入公司的生产经营环节；建立完善的知识产权防御体系，支撑公司的经营战略，并提高公司开拓市场的自由度；降低知识产权风险，同时加强知识产权运营。 “五位一体”的专利布局 打造“体验、技术、产品、专利和标准”五位一体的专利布局体系是酷派集团专利管理工作的第二大特色，其核心思想为技术、产品、专利和标准都是以提升用户体验为出发点及落脚点，并相互融合促进。 汪智勇介绍，通过给业务部门设置专利考核指标等方式，酷派集团把专利布局嵌入到了产品生命周期的各个环节，以确保创新技术、产品能在第一时间得到全面的专利保护。 “五位一体”的专利布局体系为酷派集团高质量、全方位开展专利挖掘和布局工作奠定了基础。汪智勇介绍， “五位一体”中的体验是指日常生活中典型的用户场景或痛点；技术是指解决用户痛点、提升用户体验的创新技术，并在第一时间将其转化为产品，同时开展专利布局，并争取使其成为行业标准；产品是指产品立项和创新要以用户需求为中心，在遵循标准的基础上，结合用户对产品的反馈进一步开展技术创新和专利布局；专利是指以创新技术或产品为载体开展专利布局，并争取将其纳入到标准中，进而成为标准专利。 “通过加大技术创新力度，有效提高了专利质量。与此同时,在专利布局时开展的专利检索和数据分析也为产品创新开拓了新的视角。”汪智勇表示，通过实施“五位一体”的专利布局体系，酷派集团不仅提升了用户体验，而且还达到了体验、技术、产品、专利和标准“五位一体”的良好效果。 “开放式”的创新模式 对于不同的企业而言，其都会根据所在行业采取不同的专利管理策略。在汪智勇看来，专利管理工作要服务于公司的商业战略，并根据自身情况“量体裁衣”，这就需要企业专利管理人员结合移动互联网时代的新形势，提前做好应对和转型升级。 通常来说，传统企业的创新模式是封闭式的，企业的技术研发人员都是自主研发，而在移动互联网时代，企业的技术创新往往需要从外界获取大量创新资源，这就要求企业专利管理人员积极引导企业创新模式从“封闭式”逐渐转为“开放式”，比如企业可以与用户、供应商、科研院所、服务机构、行业协会，甚至竞争对手等相关部门建立协同创新机制。汪智勇向记者举例说，酷派集团每年有很多技术创新点源自高校合作项目或竞争对手的用户论坛等外部渠道。 在汪智勇看来， 企业专利管理人员要始终坚持“专利战略服务于商业战略”，因此，专利管理人员不仅要具有传统的技术思维和法律思维，还要具备相应的商业思维，比如使专利管理工作服务于产品宣传和品牌建设等。","comments":true,"categories":[{"name":"专利","slug":"专利","permalink":"http://ipcreator.me/categories/专利/"}],"tags":[{"name":"Patent","slug":"Patent","permalink":"http://ipcreator.me/tags/Patent/"}]},{"title":"IPCreator专利清单","date":"2017-01-04T12:53:06.000Z","path":"2017/01/04/MyView/my-patent-list/","text":"检索方法1、打开专利检索网址大为；2、以“汪智勇”为关键字进行检索；3、在检索结果中，以申请（权利人）为“宇龙/Yulong” or “酷派/Coolpad”进行二次筛选便可得出结果。 备注 以下清单，基于2017.1.27日以前公开的专利库进行检索，未纳入未公开的相关专利申请（中国/PCT）。 专利清单 序号 公开号 专利名称 发明人 1 WO2013000123A1 PASTING METHOD AND TERMINAL THEREOF WANG ZHIYONG;YE BIQING;FENG YUHUI;LIU DONGHAI 2 WO2016106938A1 CONTACT-BASED SYSTEM SWITCHING METHOD AND APPARATUS AND TERMINAL LIU DONGHAI;WANG ZHIYONG 3 WO2016115760A1 TERMINAL SYSTEM CONTROL METHOD, DEVICE, AND TERMINAL LIU DONGHAI;WANG ZHIYONG 4 WO2016119288A1 DATA ACQUISITION METHOD, DATA ACQUISITION DEVICE AND TERMINAL XU XING;LIU DONGHAI;WANG ZHIYONG 5 WO2016173072A1 DATA INFORMATION PROCESSING METHOD, DATA INFORMATION PROCESSING DEVICE, AND TERMINAL ZHOU WEI;WANG ZHIYONG;PANG MIN 6 WO2016173075A1 SYSTEM SWITCHING METHOD AND DEVICE LIU DONGHAI;WU DIANQING;WANG ZHIYONG 7 WO2016192161A1 DATA PROCESSING METHOD AND DEVICE LIU DONGHAI;WANG ZHIYONG 8 WO2016192163A1 METHOD AND SYSTEM FOR REDUCING POWER CONSUMPTION OF MOBILE TERMINAL, AND MOBILE TERMINAL WU KEBIAO;WANG ZHIYONG 9 WO2017000341A1 INFORMATION PROCESSING METHOD, DEVICE, AND TERMINAL LIU DONGHAI;WANG ZHIYONG 10 WO2017000344A1 OPERATING METHOD AND TERMINAL BASED ON FINGERPRINT RECOGNITION LIU DONGHAI;WANG ZHIYONG 11 WO2017000354A1 FINGERPRINT PASSWORD VERIFICATION METHOD, SYSTEM, AND TERMINAL LIU DONGHAI;WANG ZHIYONG 序号 申请号 专利名称 发明人 1 CN201510344976.5 一种图像处理方法、装置及终端 吕楠;汪智勇;蒋罗 2 CN201510306351.X 一种用于降低移动终端功耗的方法和系统、以及移动终端 吴科标;汪智勇 3 CN201610567614.7 一种消息处理的方法及装置 吴殿清;汪智勇;闫娟;唐冬兰 4 CN201610565644.4 一种消息处理的方法及装置 吴殿清;汪智勇;闫娟;唐冬兰 5 CN2015082964 METHOD AND SYSTEM FOR REDUCING POWER CONSUMPTION OF MOBILE TERMINAL, AND MOBILE TERMINAL WU KEBIAO;WANG ZHIYONG 6 CN201610200631.7 一种指纹操作方法及终端设备 吴殿清;汪智勇;张娜;雷武 7 CN201610567587.3 一种消息处理的方法及装置 吴殿清;汪智勇;闫娟;唐冬兰 8 CN201610178390.0 基于智能水杯的信息调整方法、信息调整装置及智能水杯 吴殿清;汪智勇;闫娟;张娜 9 CN201610200353.5 一种多指纹混合登记的预警处理方法及移动终端 吴殿清;郭德英;汪智勇;张娜 10 CN201510236129.7 一种红外遥控方法及系统 吕楠;汪智勇;蒋罗 11 CN201510992251.7 一种应用程序下载安装方法及终端设备 刘东海;党乐;吴殿清;汪智勇 12 CN201610179140.9 用于智能水杯的控制方法、控制装置及智能水杯 吴殿清;汪智勇;闫娟;潘露杰 13 CN201610177989.2 用于智能水杯的控制方法、控制装置及智能水杯 涂欣;汪智勇;闫娟 14 CN201610184737.2 电梯控制方法、电梯控制装置和终端 梅各各;吴殿清;汪智勇;闫娟 15 CN201511019709.7 指纹识别的安全管理方法及装置、终端 刘东海;汪智勇 16 CN201610184821.4 通信处理方法及通信处理装置 潘晓;吴殿清;汪智勇;潘露杰 17 CN201610177915.9 基于智能水杯的信息调整方法、信息调整装置及智能水杯 吴殿清;汪智勇;闫娟;唐冬兰 18 CN201510369387.2 指纹密码的验证方法、系统和终端 刘东海;汪智勇 19 CN201510288979.1 虹膜信息采集方法、虹膜信息采集装置及终端 吕楠;蒋罗;汪智勇 20 CN201511018264.0 数据访问方法、数据访问系统和终端 刘东海;吴殿清;汪智勇 21 CN201510290387.3 水印嵌入方法、水印嵌入装置和终端 刘东海;汪智勇 22 CN201510458375.7 一种基于用户信息识别的设备控制方法及移动终端 刘东海;郭建军;李沙;吴殿清;汪智勇 23 CN201510460556.3 密码信息的验证方法、密码信息的验证系统和终端 刘东海;郭建军;吴殿清;汪智勇 24 CN201510615614.5 鉴权方法和终端 刘东海;汪智勇 25 CN201510374951.X 一种信息处理方法、装置以及终端 刘东海;汪智勇 26 CN201510374233.2 一种基于指纹识别的操作方法及终端 刘东海;汪智勇 27 CN201510282913.1 一种酒驾检测方法及终端、服务器 刘东海;汪智勇 28 CN201510456437.0 一种环境监控方法及用户终端 吴殿清;汪智勇;闫娟 29 CN201510734361.3 移动支付的监控方法、系统及智能终端 陈历伟;汪智勇 30 CN201510466796.4 指纹校验方法及装置 刘东海;郭建军;吴殿清;汪智勇 31 CN201510386218.X 一种数据处理方法及设备 刘东海;李仕伦;汪智勇 32 CN201510454769.5 一种室内环境监控方法及物联网终端 吴殿清;汪智勇;闫娟 33 CN201510854609.X 一种支付方法及其装置 陈历伟;汪智勇 34 CN201410464798.5 一种终端运行方法和装置 詹谷;黄焕荣;袁刚;汪智勇 35 CN201510848857.3 远程控制方法、远程控制装置、终端和远程控制系统 蒋罗;吕楠;汪智勇 36 CN201510623457.2 一种登录信息的配置方法、装置和移动终端 吴殿清;汪智勇;闫娟 37 CN201510618247.4 一种多系统间的应用安全保护方法及终端 刘东海;张碧君;汪智勇;吴殿清 38 CN201410303207.6 跨平台关联设备间的应用的安装方法及其系统 刘东海;汪智勇 39 CN201510615266.1 一种用户数据的保护方法及终端 刘东海;许奕波;吴殿清;汪智勇 40 CN201410195732.0 一种超级用户权限控制方法及装置 李仕伦;汪智勇;阳得常 41 CN201510611610.X 虹膜认证方法、虹膜认证装置及终端 梁文栋;黄习昌;闫娟;汪智勇 42 CN201410165760.8 一种安全驾驶的预警方法及系统 李仕伦;汪智勇;冯玉慧 43 CN201410066559.4 消息通知方法、消息通知装置、移动设备和消息通知系统 汪智勇;郭德英;郭建军;吴殿清;王文清 44 CN201510288853.4 一种数据处理方法和装置 刘东海;汪智勇 45 CN201510209238.X 一种系统切换方法和装置 刘东海;吴殿清;汪智勇 46 CN201510209832.9 数据信息处理方法、数据信息处理装置和终端 周威;汪智勇;庞敏 47 CN201510201478.5 系统切换方法、系统切换装置和终端 胡军杰;汪智勇 48 CN201410856593.1 多系统终端的系统切换方法、装置和终端 石爱民;汪智勇 49 CN201510054797.8 数据获取方法、数据获取装置和终端 许行;刘东海;汪智勇 50 CN201510044131.4 应用程序的运行控制方法、运行控制系统和终端 胡军杰;汪智勇 51 CN201410843159.X 基于联系人的系统切换方法及装置 刘东海;汪智勇 52 CN201410579593.1 丢失终端的管理方法及系统 刘东海;汪智勇;冯玉慧;叶必清;李仕伦 53 CN201510026623.0 一种终端系统的控制方法、装置和终端 刘东海;汪智勇 54 CN201410719656.9 一种汽车监控方法及系统 刘东海;汪智勇 55 CN201410453522.7 一种低电量提示方法、装置及终端设备 詹谷;黄焕荣;卓优;汪智勇 56 CN201410301262.1 一种基于虚拟键盘的文字输入方法及装置 林荣辉;汪智勇;陈运哲;战磊 57 CN201410204656.5 信息同步系统和信息同步方法 叶必清;汪智勇 58 CN201410056902.7 数据保护系统及方法 汪智勇;王正泽;王旭;郭德英;邓小英 59 CN201410099365.4 一种智能输入法切换方法及装置 叶必清;汪智勇 60 CN201410042322.2 一种终端及防止敏感信息泄露的方法 陈祥;汪智勇 61 CN201310625749.0 一种文件的传输方法及装置 李仕伦;汪智勇;叶必清 62 CN201310530882.8 商品信息的处理方法及装置 汪智勇;李俊;邓小英 63 CN201110451257.5 一种图片下载的方法、移动终端及服务器 冯玉慧;汪智勇;叶必清 64 CN201210527902.1 一种应用协同方法及移动终端 汪智勇;王文清;王正泽 65 CN2011076513 PASTING METHOD AND TERMINAL THEREOF WANG ZHIYONG;YE BIQING;FENG YUHUI;LIU DONGHAI 66 CN201110384354.7 一种应用程序安全预判装置及方法 汪智勇;朱宗伟;王新颖;冯玉慧 67 CN201110291506.9 终端和数据处理方法 罗彪;汪智勇;冯玉慧 68 CN201110283313.9 一种通信信息提醒方法、系统及移动终端 叶必清;廖迴敏;冯玉慧;汪智勇;刘东海;王新颖 69 CN201110301688.3 一种对数据进行操作的方法及移动终端 汪智勇;叶必清;冯玉慧 70 CN201110304416.9 一种应用程序的显示及分类方法、系统及移动终端 汪智勇;李自来;廖迴敏;冯玉慧 71 CN201110295666.0 好友搜索方法、设备和系统 冯玉慧;廖迴敏;王新颖;汪智勇 72 CN201110204888.7 应用程序管理方法和终端 汪智勇;叶必清;冯玉慧;刘东海;王新颖;张开营;廖迴敏 73 CN201110215246.7 终端和文件保存方法 汪智勇;冯玉慧;王新颖;廖迴敏 74 CN201110174335.1 应用程序管理装置和应用程序管理方法 汪智勇;叶必清;冯玉慧;刘东海 75 CN201110090127.3 一种应用程序访问权限设置方法、系统及移动终端 汪智勇;冯玉慧;李仕伦 76 CN201110084844.5 应用程序安装方法和终端 汪智勇;刘东海;冯玉慧 77 CN201110086742.7 手机应用分类管理方法及装置 冯玉慧;汪智勇 78 CN201110037376.6 一种应用程序监控方法及装置 汪智勇;叶必清;冯玉慧 79 CN201010624198.2 智能呈现联系人相关信息的方法、系统及移动终端 汪智勇;叶必清;冯玉慧;王志标;王玮;刘东海;李仕伦 80 CN201110044252.0 一种移动终端内应用程序的升级方法、移动终端及服务器 汪智勇;刘东海;冯玉慧 81 CN201110031882.4 一种基于android平台应用安装控制方法及系统 汪智勇;叶必清;冯玉慧 82 CN201010589186.0 信息处理方法及装置 叶必清;汪智勇;冯玉慧 83 CN201010596846.8 基于Android的应用程序升级方法、系统及应用开发平台 汪智勇;冯玉慧;刘东海;李仕伦;王玮;叶必清 84 CN201010598458.3 移动终端中应用运行条件的评估方法及装置、移动终端 汪智勇;冯玉慧;叶必清 85 CN201010523146.6 一种应用协同的操作方法、系统及移动终端 汪智勇;冯玉慧 86 CN201010578230.8 应用程序管理方法、装置以及终端 汪智勇;冯玉慧 87 CN201010508288.5 一种联系人菜单智能生成的方法、系统及移动终端 汪智勇;冯玉慧;孟宪衡;邱圣华 88 CN201020532495.X 一种触摸式移动终端 王灿;汪智勇;冯玉慧 89 CN201010531736.3 控制应用程序并行运行的方法、装置及具有该装置的终端 汪智勇;冯玉慧 90 CN201010286512.0 实现移动终端的一号多卡的方法和系统 邱圣华;张碧君;汪智勇;冯玉慧;孟宪衡;张毓华 91 CN201010282444.0 联系人分组方法及终端 汪智勇;冯玉慧;邱圣华;孟宪衡 92 CN201010270503.2 一种应用程序使用状态的提醒方法、系统及移动终端 汪智勇;冯玉慧 93 CN200910041406.3 一种终端功能协同方法及对应的终端 郭和平;汪智勇 94 CN200910040535.0 一种数据排序的方法及移动通信终端 汪智勇 95 CN200910038390.0 数据协同的方法、终端及系统 汪智勇 96 CN200810198086.8 一种终端监控方法、装置及系统 杨鹏辉;汪智勇 97 CN200810026989.8 一种信息显示方法、主机端及子机端 杨鹏辉;汪智勇","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Patent","slug":"Patent","permalink":"http://ipcreator.me/tags/Patent/"}]},{"title":"IPCreator的简历","date":"2017-01-03T11:37:06.000Z","path":"2017/01/03/MyView/my-resume/","text":"“合适的才是最好的” 联系方式 手机：13652311447 Email：ipcreator@yeah.net 个人信息 男/1984 研究生专业：中南大学/计算机应用技术 英语：国家六级 技术：高级程序员 个人博客：http://ipcreator.me 行业博客：http://blog.163.com/zhuxuanlv@126/ 工作经历宇龙酷派 （2012年8月 ~ 2016年6月） 职位：知识产权部经理职责：团队/制度流程建设、专利布局、奖项申报、专利诉讼等。 示范企业及专利奖项申报承担项目经理职责，全程组织申报材料的撰写、递送及答辩，2015年荣获深圳市专利奖并成功申报国家知识产权示范企业，带领团队连续三年获得中国专利优秀奖（十六届、十七届和十八届）。 公司级布局项目制定和落实集团专利储备战略，构建“沙漠寻路/三步六法”专利布局体系及配套制度/流程/模板，作为第一负责人，主导完成公司级布局项目10+个，均受到公司高层的充分肯定和专项表彰，其中，“体验、技术、产品、专利和标准”五位一体布局体系在中国知识产权报上发表和推广。 其他项目作为集团第一个欧洲项目的知识产权代表，建立了海外知识产权风险防控体系，创建了中国/美国/欧洲律所资源池，制定了公司律所招标流程/专利诉讼处理流程及配套模板；主导处理了集团在美国的第一个专利诉讼，并以最低代价胜诉结案；主导处理了集团在中国的第一个大额专利诉讼案件，包括无效请求和不侵权分析，最后以涉案专利被成功无效，原告主动撤诉大获全胜；作为公司专利运营项目第一负责人， 制定并推行专利运营流程及配套模板，创建国内外专利运营资源池， 并主导专利组合评估相关工作。 宇龙酷派 （ 2007年7月 ~ 2012年8月 ） 职位：开发工程师/软件项目经理职责：软件开发、项目管理、团队建设等。 F608/F603项目担任软件项目经理，负责F608/F603移动TD畅销机型的软件业务，先后荣获最佳产品质量奖，最佳项目团队奖，杰出贡献奖，参加软件项目经理手册、软件质量过程监控等流程及知识库建设，荣获知识库建设之星1次， 过程改进奖4次。 软件开发担任开发工程师，负责多个核心系统模块和应用的开发，其中，联系人应用在第三方组织的用户调查中荣获最高评分，个人先后获得最佳代码质量奖，最佳应用奖，最佳设计文档等奖项，并多次被评为天道酬勤之星。 其他项目负责运营商业务小组，培养出多名项目经理和高级工程师，荣获最佳导师称号，团队共通过国内外专利申请100+篇(专利清单)。 致谢感谢您花时间阅读我的简历，期待能有机会和您共事。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"2016年最精彩科学美图","date":"2017-01-02T12:24:06.000Z","path":"2017/01/02/MyShare/view-of-scientific-discovery/","text":"这一年有啥留恋：看2016年最精彩科学美图 随着2016年即将接近尾声，美国新闻聚合网站BuzzFeed评选出2016年最精彩的科学美图。这些美图展示了今年被发现的科学奇迹，包括揭示了从微观到宇宙尺度等不同物体的形态，比如国际空间站、鲨鱼、变色龙等，下面就让我们带领大家欣赏这些令人震撼的图片。 这张照片获得2016年度英国生态学会摄影大赛的总冠军，图中是古巴翠蜂鸟。 沙丘鹤正从西伯利亚向墨西哥长途迁徙，正在内布拉斯加州躲避风暴。这是美国《国家地理》杂志年度最佳图片。 7月16日，在450多米高空拍摄的航拍图，可以看到下面大块的海冰、融化的池塘以及开阔的水域。 11月10日，南极拉森冰架（Larsen C ice shelf）上的大裂谷。 保存在琥珀中的9900万年前恐龙尾部羽毛。 10月3日，在国际空间站上拍摄利比亚西部的撒哈拉沙漠。 火星轨道侦测器拍摄到的火星山谷。 这是西门子资助的、由皇家摄影协会主办的国际科学图片摄影大奖获奖作品之一。从小型液态燃料露营炉中缓缓上升的热空气形成无形湍流。纹影摄影（Schlieren photography）让我们可以看到和记录被火焰加热的空气与周围环境中冷空气之间的折射率差异。 “好奇”号火星探测器自拍照。 10月30日，搭载3名宇航员的俄罗斯“联盟”号飞船在哈萨克斯坦着陆。 世界野生动物基金会12月份发布报告宣称，在东南亚大湄公河地区发现了新的蝾螈物种。 天文学家们发现的最新证据显示，这可能是有史以来发现的最极端的脉冲星或旋转的中子星。 这只毛虫遭到黄蜂袭击，背部寄生蛹也开始爆发，它的生命已经到了最后时刻。图中的液滴是血淋巴，也就是毛虫的血液。这张照片获得2016年度英国生态学会摄影大赛学生类作品大奖。 这是眼线化妆品中发现的微小塑料块，又被称为微球体。由于其体型过小，无法在污水处理过程中清除出去，可对海洋生命造成危害。这张照片来自一个摄影项目，主要研究微小塑料对环境的影响。 这些蚂蚁正在吃用糖着色的食物，摄入液体让它们的身体变成蓝色。 这是在喜马拉雅山海拔4400多米处拍摄的照片，展示云海上空的银河系。 风喉蜥蜴又被称为“草原战士”，它们是由高度领土意识的生物，会不遗余力地保护自己的领地。这张照片是夏季时在印度马哈拉施特拉邦拍摄的，当时正处于蜥蜴交配季节。 10月份，通过哈勃太空望远镜观察大的螃蟹星云。它是一团巨大的气体云，形成于2600年前的恒星爆炸，距离我们大约有1600光年远。 这是在泰国旅游胜地普吉岛上发现的飞龙科树蜥(Acanthosaura phuketensis)，它们看起来就像迷你飞龙。 这是格陵兰鲨，属于睡鲨的一种。这些体型巨大、行动缓慢的生物正在大西洋深处优雅的游动。最新研究发现，格陵兰鲨是寿命最长的脊椎动物，有的标本至少已经活了392岁。 这些小星团正围绕透镜状星系NGC 5308旋转。这里所谓的“小”只是相对来说，每个星团都包含着数十万颗恒星。 这是在显微镜下看到的潜水甲虫腿部末端，它大约有2毫米长，可在交配时帮助黏在雌性甲虫背上。 从国际空间站上观看闪电和地球城市灯光，前面则是2艘俄罗斯飞船。 这些黑鳍礁鲨正在塞舌尔群岛的低潮浅水中潜伏，等待涨潮。 这是巴哈马群岛北部被称为“老虎滩”的地方，这里以常见虎鲨闻名。 这是在澳大利亚内陆通过银河系与河外星系全天默奇森广域阵列(Galactic and Extragalactic All-sky Murchison Widefield Array）射频望远镜拍摄到的宇宙射频图像。 在坦桑尼亚谢伦盖蒂平原上，鲁氏粗鲁氏秃鹫（黑白兀鹫）与非洲白背秃鹫正啄食斑马的遗骸。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Share","slug":"Share","permalink":"http://ipcreator.me/tags/Share/"}]},{"title":"罗辑思维","date":"2017-01-01T22:00:06.000Z","path":"2017/01/02/MyShare/iGet/luozhenyu-logic-thinking/","text":"逻辑思维 简介：罗振宇，又称“罗胖”。一个每天在微信上坚持60秒的男人，一个每周“死磕自己、愉悦大家”的说书人。《罗辑思维》是罗胖的个人知识型脱口秀节目。在节目中，罗胖天文地理、古今中西，无所不谈。每次都做足功课，为你颠覆直觉，清理误区，引入趣味，连接断层，随口八卦。不求立意高深，只为打破每个人的认知屏障和信息茧房，让你在短时间内得到一锅知识浓汤。 受众：爱智求真的跨界学习者；需要丰富谈资的社交达人；在变动的时代，渴望实现个人崛起的年轻人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"商业内参","date":"2017-01-01T21:00:06.000Z","path":"2017/01/02/MyShare/iGet/lixiang-reference-of-business-inside/","text":"商业内参 李翔商业内参大佬都在看马云：李翔从不人云亦云，有自己的判断。雷军：主编创业，李翔顺势而为。我一定会订阅并且关注《李翔商业内参》柳传志：《李翔商业内参》是为了让大家以更高的效率获得高质量的内容。陈可辛：很期待李翔帮助更多人理解商业变化。李开复：李翔是我认识的媒体人中非常有职业操守和有传媒精神的人。我一定会关注和订阅《李翔商业内参》。 李翔是谁中国最好的商业记者之一 李翔任《时尚先生》主编时主持的一期封面柳传志、王石、马云、史玉柱、沈文荣、李开复、俞敏洪、李书福、郭广昌、曹国伟、宋卫平、潘石屹、田溯宁、丁磊、程维、王兴、张旭豪……这几乎是中国最近三十多年商业明星的合影。毋庸置疑，李翔是中国最好的商业记者之一。也许是因为他的诚意，也许是因为他的敏锐，他总是能在这些企业家生命中的关键时刻，以恰当的方式，出现在他们面前。老一辈的企业家愿意从他那里听听年轻人的想法；而新一代的创业者愿意从他那里听听过去的掌故。一定程度上，他们超越了采访者和受访者的关系。 我们为什么要做商业内参？让我们的用户在竞争中取得领先优势 马云说过：“很多人输就输在，对于新兴事物，第一看不见，第二看不起，第三看不懂，第四来不及。” 我们的初心就是，让我们的用户在竞争中取得领先优势，让看不见、看不起、看不懂的人最终来不及跟上他们的脚步。 有一些事，是你本来就想做的，我们相信，李翔商业内参能帮你更高效地完成它。有一些事；是在你意料之外的，我们希望，《李翔商业内参》能让你有更广阔的视野，开启你更精彩的财富人生。 李翔商业内参能做到什么？怎么做到？ 每天 10 条左右的精选信息。这个产品能筛选出真正有价值的信息，缓解你的信息焦虑；能给出可行的建议，让你做重要决定时更有把握；能提示商业变量，使你不会错过转瞬即逝的机会。 李翔个人的解读和点评。这个时代，信息，大家都能看到，但能看出什么来，和每个人的认知能力高度相关。就像罗胖所说的，这个产品卖的不是信息，而是李翔基于超过十年的商业报道经验而获得的认知能力。 每条信息就像一个插件，即插即用。这个产品是根据应用场景来打造的，特点就是有用。你做 PPT 的时候需要金句，聊天的时候需要谈资，做判断的时候需要行内人的洞察或者记者圈的小道消息，这个产品全都能提供。 专注于极致内容的生产。这个产品基于付费订阅，内容团队不用写软文拉广告，他们能抵抗伤害内容品质的短期诱惑，专心为你提供好服务。 适宜人群企业家、创业者，以及所有对商业世界的变化感兴趣的人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"前哨","date":"2017-01-01T20:00:06.000Z","path":"2017/01/02/MyShare/iGet/wangyuquan-front-guard/","text":"前哨 每年拿5个亿为自己的判断买单，今天把他的侦查给你看。 为什么要订阅这个产品？他是你深入人类创新文明最前沿的侦察兵因为我们正处于一个急速变动的时代，创新科技呈几何级数加速发展，人类的未来会发生根本性重塑。这种时候，哪怕一点点视野上的差距，都将导致难以逾越的认知障碍，差之毫厘、失之千里。雇佣王煜全做你的私家“哨探”，他就是你的“望远镜”，视野比别人更开阔；他也是你的“显微镜”，认知比别人更清晰。 因为王煜全有三种能力。一是判断真伪的能力。哪些是真正可以改变未来的科技，哪些只是臆想和传说，在他眼里就隔着一张窗户纸，一点即透。二是判断价值的能力。哪些科技只是热闹好玩，哪些科技会对人类的未来产生重大影响。他给你的，不止是信息和知识，更是机会和行动纲领，帮你先人一步摸到全球科技创新的风口。三是判断时点的能力。他的探查与判断将是两年之后出现在媒体上的“大新闻”与“黑科技”，从现在就开始提前布局，两年之后抢占风口的就会是你。 他会成为你深入人类创新文明最前沿的侦察兵。帮助你，用最低的成本、最少的精力和时间，获得最顶级的视野。他会尽其所能，帮助你在对创新这件事的理解上，远超其他人。 作者简介王煜全官方头衔是：海银资本创始合伙人，资深市场营销和战略咨询专家。但是记不住最好，因为根本不重要。 他是个非常特别的投资人。一般的投资人，都是在美国融钱，然后跑到中国来投资，但他恰恰相反，他是带着中国新兴中产阶级的钱，跑到美国去投资，而且专投那些高科技创新企业。 他一口“京片子”，但却对北京不太熟，为什么？一年里有大半时间都在美国呗。每年他要拿5个亿的真金白银去投资，换来大量的知识和经验，并为他自己做出的所有判断买单。 适宜人群跨国协作的企业家、捕捉全球机会的投资者、寻找下一轮创新风口的创业者；对未来充满好奇心的年轻人，每个生活在这个急速变动时代的聪明人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"雪枫音乐会","date":"2017-01-01T20:00:06.000Z","path":"2017/01/02/MyShare/iGet/liuxuefeng-classic-music/","text":"雪枫音乐会 雪枫音乐会带你一年听懂260首古典音乐5月28日起，刘雪枫在得到App（罗辑思维出品）开设为期一年的订阅专栏，周一到周五，每天精选一首古典音乐讲给你听。 白岩松: 如果说古典音乐是宗教，那刘雪枫一定是最好的传教士。徐小平: 音乐给我带来了无限的欢乐和滔滔不绝的灵感，成为了我生活的底色。余华: 刘雪枫人生的追求、生活的乐趣，全在古典音乐里面，除了这个没有别的。谭盾: 雪枫在我眼里是音乐家，让更多的人走进音乐。胡歌：让我们一起和古典音乐成为朋友，享受我们属于我们的文明和智慧。欢迎订阅《雪枫音乐会》。 彻底被征服：小宝宝们的最爱：大宝宝更爱：启蒙国人的美学教育：音乐抒发情感，评论都是诗人：往来无白丁，专业留言密集： 白岩松说：“雪枫音乐会”，就是要拆掉人们进入古典音乐领域的“墙”。这面墙如果有个名字，可以叫“懂”。因为，这是让很多人困惑的致命障碍，在于“我怎么没听懂呢？” 刘雪枫中国著名的古典音乐评论家和推广者。出席过上千场国内外顶级音乐会。发表专业乐评近 200 万字。收藏古典音乐唱片 100000 张。曾任两本古典音乐杂志《爱乐》和《留声机》的主编。长期以来，和他一起听音乐会、收藏唱片的往来友好名单中陆续添加了投资家徐小平、主持人白岩松、作家余华和李陀、画家何多苓、诗人北岛和欧阳江河、歌唱家龚琳娜、京剧名伶史依弘和孙慧珠，还有演员孙淳和葛优等等“大人物”。 适宜人群艺术家、企业家、白领、教师、学生……适合所有爱音乐、享受音乐的朋友。只要你希望生活美一点，再美一点。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"超级个体","date":"2017-01-01T19:00:06.000Z","path":"2017/01/02/MyShare/iGet/gudian-super-individual/","text":"超级个体 未来是个人崛起的时代不管你是上班、自由职业还是创业，未来都是个人崛起的时代。整个时代都在加速往前跑，领跑者永远只有少数人，大部分人只能跟随。要成为领跑者，你需要快速成长，长成超级个体。 超级个体是什么样的？ 他有超强的个人影响力，又善于和各种组织合作，共同成长； 他既能站在科技前沿，又能深刻洞察人性； 他具备多学科通识，又能精研某个领域，成为专家； 他比别人成长得更快，有很强的自我驱动能力，持续增值。 一句话，超级个体是未来的第一梯队。 ##《超级个体》专栏主要内容 我们会每周探讨一个加速发展的职场主题，重新认知个体崛起时代的职场 如果把你当成一家公司，你的核心能力由这4个部分组成：产品能力（对事的竞争力）、媒体能力（对人的影响力）、运营能力（对组织的领导力）以及战略能力（自己的个人成长）。这4大类型8个板块的能力，构成一个人职业核心竞争力。 未来5年职场将有什么变化，如何应对？ 有哪些越来越火的新职业方式会出现？ 职场人如何获得更大限度的自由？ 个人魅力时代，如何塑造个人品牌？ 如何发现天赋并打造自己的优势？ 如何更快提升专业能力？ 怎样在奋斗的同时保持精力充沛？ 怎样快速做出不后悔的决策？ 什么是这个时代有效的「人脉管理」？ 怎样成为一个既自律又有趣的人？ 每次一个看得懂、记得住、能实操的工具、模型或方法论。知识同样符合二八原则，任何一个领域真正核心的内容就是20%，最聪明的办法是用80%的时间学习这20%的精华。这20%往往是一些核心的模型或工具——它们既是底层逻辑也是方法论，是聪明人做事的“套路”，观察世界的方式，有了这些会省你很多时间。 陪伴成长我希望做陪伴在你身边的成长教练——这也是我选择在“得到”开设这个专栏的原因。每周四和周五，我都会在这里和你们深度互动、答疑、讨论这周的主题。未来我还会邀请更多有趣的超级个体，来分享他们的独门经验，和大家一起探讨这个时代的成长方式。 在未来一年，我们一起来做三件事： 每周学习3个加速发展的工具和方法论，你可以逐渐打造一个属于你的超级工具箱 完整地梳理自己，系统展开能力地图，逐渐搭建自己的能力体系 认识更多各个领域的“超级个体”，看到人生不同的可能性 专栏主理人古典，著名生涯规划师，高管教练，新精英生涯创始人。著有畅销书《拆掉思维里的墙》，5年销量超过300万册，被翻译成4种语言。古典会在这个专栏里，每个星期围绕职业发展、个人成长，深度讲解一个主题，给你3个加速发展的实用工具和模型。他还会及时回答你的问题，解决你的困惑，用自己积累多年的经验，全力帮你快速精进，跻身职场第一梯队。 适宜人群未来是个人崛起的时代。不管是上班、自由职业还是创业，所有希望快速成长，超越别人，一路领跑的人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"硅谷来信","date":"2017-01-01T18:00:06.000Z","path":"2017/01/02/MyShare/iGet/wujun-letters-from-silicon-valley/","text":"硅谷来信 提升自己的快捷方法美国最杰出的商业哲学家吉米·罗恩（Jim Rohn）曾经有一个经典的论断——“你就是你平常花最多时间相处的五个人的平均值”。和优秀的人亲密接触，是提升自己的快捷方法。还有比这更快捷的方法吗？有。那就是和你亲密接触的优秀者，每天还在和更多优秀的人朝夕相处。 “吴军·硅谷来信”订阅专栏，给你提供一个提高朋友圈质量的机会。在这里，你将有一年的时间，和一位优秀人物，以及围绕在他身边的众多顶尖科学家、商界领袖和文化精英朝夕相处，去熟悉他们的思维方式，掌握一套深入洞察世事和人生的独特方法，进而寻找到成功的轨迹。 专栏的主理人吴军博士，计算机科学家，硅谷投资人，《浪潮之巅》、《文明之光》等畅销书的作者。他曾先后供职于谷歌和腾讯，是谷歌中、日、韩搜索算法的发明人；他既是活跃在硅谷的投资人，也是美国两家风险投资基金的董事和顾问；他先后写过六本书，横跨数学、教育、IT、文明史本本畅销，最新出版的《智能时代》在罗辑思维独家首发，首印1.5万册，不到10小时售罄； 硅谷来信的主要内容在“吴军·硅谷来信”订阅专栏，吴军博士会把他的见闻、想法，以书信的方式，第一时间与你分享。从2016年10月10日起，截至2017年10月9日，你会在每周收到至少五篇由吴军博士从硅谷发来的信件，每封信的开头都会写有你的名字。这些信件将主要围绕以下几大主题展开： 介绍新的、媒体尚未报道的科技成就的金融、科技类文章——如果你是希望参与跨国合作的企业家，或是正在捕捉全球机会的投资者，亦或是寻求下一个创新风口的创业者，这一部分内容，也许会对你有帮助； 国外优秀科技公司的先进做法及管理经验分享——如果你是一位创业者，或是普通企业中的管理者，这部分内容分享也许会对你有帮助； 教育主题的文章——由于吴军博士在给美国几所顶级的大学担任顾问，每年都要花时间走访各个大学，他会在信中与你分享这些名校的特点和教育理念，无论你是家长、学生还是教育从业者，这部分内容也许能给你一些启发； 对时事的评述文章——在这个信息过载的时代，对于即时资讯的在处理能力，往往决定了一个人的学习、思考结果，进而客观上决定了一个人最后的发展走向，如果你是一个爱智求真，不甘于盲从的人，在重要的热点事件发生时，希望吴军博士的分析和洞察，能够给你提供一个独特的视角，帮你辨伪存真。 世界各地的艺术、历史、风土人情，以及吴军博士生活中点点滴滴的经验、体会——勤奋工作和享受生活从来不是对立的，如果你是个热爱生活的人，这个专栏能带你去看一个更大的世界。 如果你没有太多时间浏览图文，“吴军·硅谷来信”专栏还邀请了前中央人民广播电台知名配音演员为你一字一句朗读信件，每天只需抽出大约10分钟的时间，即可完成一次小小的自我升级。期待一年之后，你的见识飞升，并且结交一帮可能让你终身收益的学友伙伴。 适宜人群适合每一位渴望提升洞察力，从而在纷繁复杂的世界一眼洞穿真相、做出正确决策的朋友。帮你成为迷茫时代里的明白人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"通往财富自由之路","date":"2017-01-01T17:00:06.000Z","path":"2017/01/02/MyShare/iGet/lixiaolai-lead-to-freedom-of-wealth/","text":"通往财富自由之路 李笑来是谁？中国最会赚钱的人之一，天使投资人，连续创业者，原新东方名师，区块链专家，著有《把时间当作朋友》、《新生——七年就是一辈子》等畅销读物。他真正摆脱财务束缚的起点，是他写的一本书——《TOEFL 核心词汇 21 天突破》，销量超过百万册。仅仅是《TOEFL 核心词汇 21 天突破》、《TOEFL iBT 高分作文》、《把时间当作朋友》等长销书，就已经让李笑来获得了足够多的“睡后收入”，实现了财富自由。比特币兴起之后，李笑来又比别人更早、更快地抓住机会，跻身亿万富翁的行列。 赚钱是所有人都必需的技能，可它偏偏是一种学校里不教的技能，是绝大多数人终其一生都没有习得、或没有学得足够好的技能。其实，大多数人不是没有机会，没有努力，而是选错了道路，用错了力气而已。在获取财富这个领域里，李笑来可算是个老司机，并且恰好还是个乐于分享的老司机。他坚信，在通往财富自由这条路上，人人都有至少一次机会。 为什么开设这个订阅专栏？ 没钱是一种病，不能放弃治疗 其实钱是世界上最干净的东西，每个人都应该学会科学、合理地赚钱。 可问题是，赚钱这玩意儿，不是每个人都会。 比如，很多赚不到钱的穷人，他们最大的悲哀不是没钱，而是不相信自己会有钱。 有钱不一定是努力的结果，但没钱不应该成为你不努力的理由； 再比如，钱这个东西，不足够多就等于没有。大部分人只靠工资，不可能变得“有钱”； 如果说没钱是一种病，那这个订阅专栏就是一个药方，希望能帮助更多的人修正错误的赚钱观念，找到实现财富自由的方法。 通往财富自由之路能做什么 不看可能多走很多弯路 在接下来的一年内，他将会跟大家分享下面这些内容： 赚钱的速度太慢等于失败，花钱的方法太差等于贫穷。该如何正确地赚钱和花钱？ 为什么说冒险常常并不赚钱？ 什么资产的复利效应最大？ 你最宝贵的财富是什么？最宝贵的个人资产是什么？ 只涨不跌的资产都有哪些？ 运气并不是虚无缥缈的事情，如何让运气更好？ 为什么说一时的风光是最错误的追求？ 为什么说个人最快的成长方式是成为创始人？ 个人商业模式升级的几个台阶都是什么？ 在这个专栏里，亿万富翁李笑来带着大家每周更新一个观念，一年 52 次深入探讨，请大家上车，一起赶路，通往财富自由。 适宜人群所有渴望实现财富自由，并对自己能实现财富自由深信不疑的人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"美丽风景合集","date":"2017-01-01T12:28:06.000Z","path":"2017/01/01/MyShare/view-of-journey/","text":"“美好的事物值得付出、等待和分享” 儿童乐园 地点：侨香路以南，广深高速以北，农林路以西特色：儿童、游乐场、免费推荐指数：★★★★★ 欢乐海岸 地点：南山区白石路8号与海园二路交界 特色：彩灯、喷泉、酒吧 推荐指数：★★★★★ 大沙河公园 地点：北环大道与沙河东路交叉口附近特色：广场、草地、运动推荐指数：★★★★★ 仙湖植物园简介 地点：罗湖区莲塘仙湖路特色：弘法寺、植物推荐指数：★★★★★ 月亮湾公园简介 地点：南山青青世界下边特色：百年荔枝古树、廉政主题推荐指数：★★★☆☆ 巽寮湾（xùn liáo wān）简介 地点：惠州市惠东县的大亚湾畔 特色：石奇美、水奇清、沙奇白 推荐指数：★★★★★","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Share","slug":"Share","permalink":"http://ipcreator.me/tags/Share/"}]},{"title":"每日一句","date":"2016-12-30T16:02:05.000Z","path":"2016/12/31/MyShare/view-of-english/","text":"自知者明 自胜者强 学以致用 知行合一 不忘初心 方得始终&gt; He who knows others is learned, and he who knows himself is wise. To conquer yourself is more powerful than to defeat other people. Study serve the practical purpose.Knowledge is action, action is knowledge. Don’t forget why start off, otherwise it is difficult to achieve the ultimate goal. 图文来源：金山词霸每日一句 Many people start a career with a dream, then get busy forgetting it. 很多人一开始为了梦想而忙，后来忙得忘了梦想。 Be yourself, don’t change for anyone. If they don’t like you at your worst, then they don’t deserve you at your best.勇敢的做自己，不要为任何人而改变。如果他们不能接受最差的你，也不配拥有最好的你。 Life is like angry birds.There are always several pigs laughing when you lose.人生就像愤怒的小鸟，当你失败时，总有几头猪在笑！ 词霸小编：【语法讲解】 there be结构的常见用法:1.there be +名词 +介词短语：There is a desk behind the door. 2.there be +非谓语动词(V-ing,V-ed 和 to do) There is a girl loving music.; There is a girl called Xiaoxiao.; There is lots of homework to do. 从以上三个句子中可以看出如果there be 后的名词与动词之间的关系.如果是","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"},{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"欢迎访问我的个人博客","date":"2016-12-30T16:01:06.000Z","path":"2016/12/31/MyView/my-hello-world/","text":"IPCreator = IP + Creator 网易中文博客 创新不难、专利有趣学以致用、知行合一自知者明、自胜者强不忘初心、方得始终 明代杨慎《临江仙》 滚滚长江东逝水，浪花淘尽英雄。是非成败转头空。青山依旧在，几度夕阳红。白发渔樵江渚上，惯看秋月春风。一壶浊酒喜相逢。古今多少事，都付笑谈中。 明代唐伯虎：《桃花庵歌》 桃花坞里桃明代花庵，桃花庵里桃花仙；桃花仙人种桃树，又摘桃花换酒钱。酒醒只在花间坐，酒醉还来花下眠；半醒半醉日复日，花开花落年复年。但愿老死花酒间，不愿鞠躬车马前；车尘马足贵者趣，酒盏花枝贫者缘。若将贫贱比贫者，一在平地一在天；若将贫贱比车马，他得驱驰我得闲。别人笑我太疯癫，我笑他人看不穿；不见五陵豪杰墓，无花无酒锄作田。 李笑来：Hello World学习其实只不过是一种生活方式，否则为什么会有的人就是停不下来呢？学习不需要坚持、不需要毅力、不需要信念，不需要各种“不得已而为之的概念”，它只不过是一种选择，一个一旦真选了就再也不可逆的选择。仅此而已。 123while (alive) &#123; learn();&#125; 嗯，七年就是一辈子，干嘛不玩得高兴一点？","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]}]
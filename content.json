[{"title":"Thinking in Java","date":"2017-03-08T23:30:06.000Z","path":"2017/03/09/Program/Java/thinking-in-java/","text":"本书赢得了全球程序员的广泛赞誉，即使是最晦涩的概念，在Bruce Eckel的文字亲和力和小而直接的编程示例面前也会化解于无形。从Java的基础语法到最高级特性（深入的面向对象概念、多线程、自动项目构建、单元测试和调试等），本书都能逐步指导你轻松掌握。从本书获得的各项大奖以及来自世界各地的读者评论中，不难看出这是一本经典之作。本书的作者拥有多年教学经验，对C、C++以及Java语言都有独到、深入的见解，以通俗易懂及小而直接的示例解释了一个个晦涩抽象的概念。本书共22章，包括操作符、控制执行流程、访问权限控制、复用类、多态、接口、通过异常处理错误、字符串、泛型、数组、容器深入研究、Java I/O系统、枚举类型、并发以及图形化用户界面等内容。这些丰富的内容，包含了Java语言基础语法以及高级特性，适合各个层次的Java程序员阅读，同时也是高等院校讲授面向对象程序设计语言以及Java语言的绝佳教材和参考书。]第4版特点：适合初学者与专业人员的经典的面向对象叙述方式，为更新的Java SE5/6增加了新的示例和章节。 测验框架显示程序输出。 作者简介 · · · · · ·Bruce Eckel是MindView公司（www.MindView.net）的总裁，该公司向客户提供软件咨询和培训。他是C++标准委员会拥有表决权的成员之一，拥有应用物理学学士和计算机工程硕士学位。除本书外，他还是《C++编程思想》的作者，并与人合著了《C++编程思想 第2卷》（这两本书的英文影印版及中文版均已由机械工业出版社引进出版）及其他著作。他已经发表了150多篇论文，还经常参加世界各地的研讨会并进行演讲。 目录 · · · · · ·读者评论前言简介 第1章 对象导论1.1 抽象过程1.2 每个对象都有一个接口1.3 每个对象都提供服务1.4 被隐藏的具体实现1.5 复用具体实现1.6 继承1.6.1 “是一个”（is-a）与“像是一个”（is-like-a）关系1.7 伴随多态的可互换对象1.8 单根继承结构1.9 容器1.9.1 参数化类型（范型）1.10 对象的创建和生命期1.11 异常处理：处理错误1.12 并发编程1.13 Java与Internet1.13.1 Web是什么1.13.2 客户端编程1.13.3 服务器端编程1.22 总结 第2章 一切都是对象2.1 用引用操纵对象2.2 必须由你创建所有对象2.2.1 存储到什么地方2.2.2 特例：基本类型2.2.3 Java中的数组2.3 永远不需要销毁对象2.3.1 作用域2.3.2 对象的作用域2.4 创建新的数据类型：类2.4.1 域和方法2.4.2 基本成员默认值2.5 方法、参数和返回值2.5.1 参数列表2.6 构建一个Java程序2.6.1 名字可见性2.6.2 运用其他构件2.6.3 static 关键字2.7 你的第一个Java程序编译和运行2.8 注释和嵌入式文档2.8.1 注释文档2.8.2 语法2.8.3 嵌入式HTML2.8.4 一些标签示例2.8.5 文档示例2.9 编码风格2.10 总结2.11 练习 第3章 操作符3.1 更简单的打印语句3.2 使用Java操作符3.3 优先级3.4 赋值3.4.1 方法调用中的别名问题3.5 算术操作符3.5.1 一元加、减操作符3.6 自动递增和递减3.7 关系操作符3.7.1 测试对象的等价性3.8 逻辑操作符3.8.1 短路3.9 直接常量3.9.1 指数记数法3.10 按位操作符3.11 移位操作符3.12 三元操作符 if-else3.13 字符串操作符 + 和 +=3.14 使用操作符时常犯的错误3.15 类型转换操作符3.15.1 截尾和舍入3.15.2提升3.16 Java没有“sizeof”3.17 操作符小结3.18 总结 第4章 控制执行流程4.1 true和false4.2 if-else4.3 迭代4.3.1 do-while4.3.2 for4.3.3 逗号操作符4.4 Foreach语法4.5 return4.6 break和 continue4.7 臭名昭著的“goto”4.8 switch4.9 总结 第5章 初始化与清理5.1 用构造器确保初始化5.2 方法重载5.2.1 区分重载方法5.2.2 涉及基本类型的重载5.2.3 以返回值区分重载方法5.3 缺省构造器5.4 this关键字5.4.1 在构造器中调用构造器5.4.2 static的含义5.5 清理：终结处理和垃圾回收5.5.1 finalize()的用途何在5.5.2 你必须实施清理5.5.3 终结条件5.5.4 垃圾回收器如何工作5.6 成员初始化5.6.1 指定初始化5.7 构造器初始化5.7.1 初始化顺序5.7.2. 静态数据的初始化5.7.3. 显式的静态初始化5.7.4. 非静态实例初始化5.8 数组初始化5.8.1 可变参数列表5.9 枚举类型5.10 总结 第6章 访问权限控制第7章 复用类第8章 多态第9章 接口第10章 内部类第11章 持有对象第12章 通过异常处理错误第13章 字符串第14章 类型信息第15章 泛型第16章 数组第17章 容器深入研究第18章 Java I/O系统第19章 枚举类型第20章 注解第21章 并发第22章 图形化用户界面 附录A 补充材料可下载的补充材料Thinking in C：Java的基础Java编程思想 研讨课Hands-on Java研讨课CDThinking in Objects研讨课Thinking in Enterprise JavaThinking in Patterns(with Java)Thinking in Patterns研讨课设计咨询与复审 附录B 资源软件编辑器与IDE书籍分析与设计Python我的著作列表索引","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://ipcreator.me/tags/Java/"}]},{"title":"Git automatically","date":"2017-03-08T23:30:06.000Z","path":"2017/03/09/Program/Windows/auto-git-daily/","text":"能够用命令行或者批处理的，尽量自动化，提高效率，时间就是生命… 12345678910111213141516171819@echo off@title auto update blog articles and git pushset fileSource=D:\\IPCreatorBlog\\sourceset fileDestination=C:\\IPCreatorBlogGit\\blog\\sourceset gitDir=C:\\IPCreatorBlogGit\\blogclscd %fileDestination%rd /s/q %fileDestination%Xcopy /e %fileSource% %fileDestination%cd %gitDir%git add -v .git commit -m \"Update blog daily\"git pushpause 1234567 user@LAPTOP-082RQVIH MINGW64 /c/IPCreatorBlogGit/blog (master)$ **git config --global alias.blog '!git add . &amp;&amp; git commit -m \"blog update\" &amp;&amp; git push'** user@LAPTOP-082RQVIH MINGW64 /c/IPCreatorBlogGit/blog (master)$ **git blog**On branch masterYour branch is up-to-date with 'origin/master'.nothing to commit, working tree clean 更多参考： Windows批处理(cmd/bat)使用小记 批处理常用命令总结 - 批处理命令简介 Git批处理脚本 请问如何写一个批处理自动打开 gitbash，然后自动执行一系列git命令（windows平台）？","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://ipcreator.me/tags/Java/"}]},{"title":"Thanks to...","date":"2017-03-08T15:59:06.000Z","path":"2017/03/08/Program/special-thanks/","text":"Standing on Shoulders of Giants 站在巨人的肩上，才有可能在有限的时间里取得最大的成绩… 发现趋势，追随趋势，顺势而安、乘势而起、造势而雄，不做旁观者，要成弄潮儿如果进入了痛苦的高原期，请记住：付出与收获成正比，成功之路本身就不轻松，与戴皇冠必承其重，此时，你需要坚信自己的判断和选择，坚持、坚持再坚持，基于量变到质变的法则，一般都会“踏破铁鞋无觅处，得来全不费工夫”，届时，”待到山花烂漫时，君在丛中笑”。 学之者不如好之者，好之者不如乐之者，兴趣是最好的老师 化整为零，先易后难，循序渐进，各个击破，坚持是成功的密码，自胜者强 若贪多求快，则欲速不达 若聚焦极致，则迎刃而解 别急，慢慢来，一切都来得及 架构思考、动手实践、检索分析、复盘总结、循环递进 保持节奏感、创造成就感 AndroidAndroid——See what’s new with Android - from phones to watches and more.郭霖的专栏——每当你在感叹，如果有这样一个东西就好了的时候，请注意，其实这是你的机会老罗的Android之旅——爱生活，爱Android胡凯eclipse_xuAndroid官方培训课程中文版(v0.9.7)湖前琴亭——好好做技术，认真写博文Android群英传——神兵利器Android源码设计模式解析与实战第一行代码：Android（第2版）Android系统源代码情景分析Android学习资源网站大全Android源码设计模式分析开源项目2015年最新Android基础入门教程 AITensorFlow——An open-source software library for Machine Intelligencetensorflowtensorflow examplesTensorFlowAndroidDemoTensorFlowAndroidMNISTTensorFlow 官方文档中文版deep_recommend_systemID-Card_with_TensorFlow_Opencv_in_Androidandroid-yolo——Real-time object detection on Android using the YOLO network with TensorFlowNewFeelings——Android平台相册应用，使用Google开源机器学习框架tensorflow处理图片以提供更好的图片浏览体验TensorFlow Android Camera Demo机器学习智能时代——大数据与智能革命重新定义未来数学之美程序员的数学——编程的基础是计算机科学，而计算机科学的基础是数学。程序员的数学 2概率统计程序员的数学 3线性代数 ToolsGithubCodingStack Overflow七牛GoogleEnglishGit教程Python教程hexo-theme-yiliaatom——A hackable text editor for the 21st Century鸟哥的Linux私房菜（第三版）深入理解计算机系统Python编程：从入门到实践C++ Primer 中文版（第 5 版）Java编程思想 （第4版）C程序设计语言免费的编程中文书籍索引 MethodologyANDROID学习之路编程入门指南 v1.5 Open Sourcelottie-androidAndroid-Universal-Image-Loaderandroid-gif-drawableawesome-android-uiandroid-open-project","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"Billy Lynn's Long Halftime Walk","date":"2017-03-08T15:30:06.000Z","path":"2017/03/08/MyView/Movie/billy-lynn's-long-halftime-walk/","text":"比利·林恩的中场战事的剧情简介 · · · · · · 伊拉克战争时期，来自美国德州的19岁技术兵比利·林恩（乔·阿尔文 Joe Alwyn 饰）因为一段偶然拍摄的视频而家喻户晓。那是一次规模不大却激烈非常的遭遇战，战斗中林恩所在的B班班长（范·迪塞尔 Vin Diesel 饰）遭到当地武装分子的伏击和劫持，而林恩为了营救班长不惜铤而走险冲锋陷阵。视频公布于世让他成为全美民众所崇拜的英雄，然而却鲜有人理解他和战友们所经历的一切。为了安葬班长，B班得到了短暂的休假，因此他们得以受邀参加一场在德州举行的橄榄球比赛。林恩的姐姐因某事件深感愧疚，她希望弟弟能借此机缘回归普通生活。而周围的经纪人、球迷、大老板、普通民众则对战争、卫国、士兵有着各种各样想当然的理解。球场上的庆典盛大开幕，林恩和战友们的心却愈加沉重与焦躁…… 本片根据作家本·方丹（Ben Fountain）的同名小说改编。 导演: 李安编剧: 让-克里斯托弗·卡斯特里 / 本·方丹主演: 乔·阿尔文 / 加内特·赫德兰 / 克里斯汀·斯图尔特 / 范·迪塞尔 / 李淳 / 麦肯兹·利 / 史蒂夫·马丁 / 克里斯·塔克 / 本·普拉特 / 阿图罗·卡斯特罗 / 亚斯特罗 / 博·纳普 / 伊斯梅尔·克鲁兹·科尔多瓦 / 巴尼·哈里斯 / 布鲁斯·麦金农类型: 剧情 / 战争制片国家/地区: 美国 / 英国 / 中国大陆语言: 英语上映日期: 2016-11-11(美国/中国大陆) / 2016-10-15(纽约电影节)片长: 110分钟(中国大陆) / 113分钟又名: 半场无战事 / 比利·林恩漫长的中场休息 / 比利·林漫长的中场行走 / 中场休息IMDb链接: tt2513074 水木丁 不要随便对经历过苦难的人说“我能理解你的心情。”，因为你理解不了。也不要对他们说”我懂你的感受”，因为你感受不到。比利从遥远的敌国，回到自己的祖国，他从前是一个普通人家的不引人注目的男孩，他的内心也许是孤独的。但是他现在成为了整个美国家喻户晓的英雄，他终于被人看见了，人人都知道他的名字，可他的孤独没有消失，反而膨胀起来，变成了和他的名气一样的大的东西。荣誉，爱情，金钱……在短短的几个小时之内一一从他身边经过，但是他感到的却是越来越孤独，人人觉得自己懂他，他们赞扬他，评价他，定义他，人人看到他站在眼前，但是没有谁真的能体会他的感受，人人在看他这他，却没有人看得到，他的悲伤那么大。（写下这句话，真是好想配张搞笑的图片，配合一下我们这个荒唐的人生啊）。用他自己的话来讲，人们在赞扬你生命中最惨的一天，那感觉真是…… Prufrock的情歌 一些小数据：美国17%的流浪人口是退役军人。曾在伊拉克和阿富汗服役的160万退役军人中，有45%正在申请残疾补助。33%已确认具有和役期相关的残疾。这些军人里，20%左右被确诊患有PTSD或抑郁症，剩下的80%里有许多人不愿意进医院，不愿意看心理医生，不愿意承认自己”有问题“。 惘然 版权归作者所有，任何形式转载请联系作者。作者：惘然（来自豆瓣）来源：https://movie.douban.com/review/8165734/ 电影有些情节很讽刺，比如比利·林恩对着国旗敬礼，看台上的大银幕对着他，他泪流满面。现场观众一定被他的爱国情怀所感染了。可实际上，李安的镜头一转，还是处男的比利·林恩脑海中正在想象和刚刚认识的啦啦队女孩在自家的床上翻云覆雨。电影有些情节很无奈，比如比利·林恩说：“有人来表扬你这辈子最惨的一天”。他成为英雄是因为一段战场上舍身救队长的视频。那一天他为了救队长与敌人近身肉搏，终于把敌人杀了。然后一回头，早已中枪的队长也已经咽气。没有什么胜利可言，大家都一败涂地。电影有些情节很伤感，比如比利·林恩对那个主动投怀送抱，对他表现出各种不舍的啦啦队女孩佐恩深情地说：“我差点带着你跑掉！”结果佐恩的反应是：“你怎么可以说这种话？怎么可以说不回伊拉克，你是英雄啊！”于是比利·林恩只能表示自己其实是开的一个玩笑。佐恩这才心满意足离去。哪怕是对你说“我爱你”的人，有可能爱的也只是他们想要的那个你。 《比利·林恩的中场战事》甚至几乎没有设置悬念，不走大片惯有的逻辑。就像李安说的：“观众一开始就知道他不可能不回去（伊拉克）的，可是我们还是要思索这个问题，想知道他发生了什么。基本上他的决定不是决定，而是一个了解，对他命运本身的了解。”比利·林恩最后对开车来想接他去找心理医生努力让他留在美国的姐姐说：“我想这就是我的命运”。所以这就是一部非常李安的电影。我们当然知道高伟同最后会办喜宴，李安想要拍出的是他发生了什么。我们当然知道王佳芝一定会放了易先生，李安想要拍出的是她发生了什么。我们当然知道比利·林恩还是要回到战场……李安从来拍的不只是故事，而是情绪，而是一个个鲜活饱满，甚至矛盾重重，但却是真实的人。是他们的选择，和他们的别无选择。 乌鸦火堂 现在正在打仗吗？跟我无关。我管你是什么战争英雄还是什么高级人物，我们所关心的，就是作为老板的我，能不能挣到更多钱。作为制片人的我，能不能接到下一单有噱头的生意。作为工作人员的我，能不能顺利让中场秀顺利结束。作为粉丝的我，能不能看到真命天女，能不能让我支持的球队获胜。你们从哪来，回哪儿去吧，该干什么干什么 版权归作者所有，任何形式转载请联系作者。作者：乌鸦火堂（来自豆瓣）来源：https://movie.douban.com/review/8173028/ 战争与表演，你都无法左右中国有句俗语：“用得着你，你就是孙猴子；用不着你，你就是猴孙子。”不比二战时期美国民众群情激昂，不比越战时期一边倒的反对。如今这个时代，美国人的危机感不在强烈，“战争英雄”这个头衔已经好久不见了。你之所以上战场，就是因为你是一名士兵，你救人，是你应该的。我之所以揍你，就是你们装逼，阻碍我们的工作。总之，他们不该在这里出现就像比利·林恩，之所以参军，是因为给姐姐报仇，而不得不入伍。电影开场悍马车中，几位都将自己入伍的原因说了一遍，理由五花八门，但没有一个是传统意义上的那种“热血青年”。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Movie","slug":"Movie","permalink":"http://ipcreator.me/tags/Movie/"}]},{"title":"Dev Bugs","date":"2017-03-08T14:59:06.000Z","path":"2017/03/08/Program/Android/android-trouble-resolver/","text":"什么是智者？就是一个坑不跌两回呗 The wiser man doesn’t fall into the same pit twice. 基础不牢、地动山摇 Without a solid foundation, the earth will shake. 解析网络数据jsoup Cookbook(中文版)Download jsoup Android图片缩放,压缩总结(inSampleSize,Matrix比较) Android中经常会遇到需要对图片进行缩放及压缩的操作,下面列出3种图片缩放方法: 一.图片缩放 1.inSampleSize(采样率) 优点:效率较高,解析速度快 缺点:采样率inSampleSize的取值只能是2的次方数(例如:inSampleSize=15,实际取值为8;inSampleSize=17,实际取值为16;实际取值会往2的次方结算),因此该方法不能精确的指定图片的大小 2.Matrix 优点:可以精确地指定图片的缩放大小 缺点:是在原bitmap的基础之上生成的,占内存,效率低. 3.ThumbnailUtils 2.2新加的类,实际上是将上述两种方法进行结合并做了封装. 二.图片压缩 往往图片压缩是为了节省网络流量,进行网络传输,一般需要将图片压缩成byte[] 数组. 12345public static byte[] BitmapToByte(Bitmap bitmap) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); bitmap.compress(CompressFormat.PNG, 80, baos);//其中80参数表示要压缩的比例 return baos.toByteArray(); &#125; AndroidUI自己先构想好，树形结构，嵌套/复用，图形化工具验证辅助知其然，知其所以然 Hello World Program in Eight Different Popular Programming LanguagesThis fact is true that Hello World program is the first program that a programmer writes when he/she start learning a new programming language. Today I thought that I should share the hello world program in different languages. A video is also added for easy understanding of the programs. Let’s take a look on these programs. Android Studio 之 JNI 开发详解 使用Android Studio 进行NDK开发和调试Jni接口-深入研究参数的传递在app level的build.gradle中添加com.android.tools.build:gradle-experimental依赖。在./app/build.gradle中添加gradle-experimental依赖 dependencies { compile &apos;com.android.tools.build:gradle-experimental:0.7.0&apos; } 再次在testJni()方法上按快捷键Alt + Enter并回车 #include &lt;jni.h&gt; JNIEXPORT jstring JNICALL Java_com_connorlin_jnitest_MainActivity_testJni(JNIEnv *env, jobject instance) { // TODO return (*env)-&gt;NewStringUTF(env, &quot;returnValue&quot;); } 你会发现成功自动生成JNI方法了。 副作用 这种方式有个副作用是 Run app 时可能会报错 此时，只要将gradle-experimental依赖注释掉即可正常运行，同时会保持自动生成代码的功能，直到关闭工程。这样我们在需要自动生成代码的时候，将gradle-experimental依赖再次打开即可。 什么是NDK？NDK全称是Native Development Kit，NDK提供了一系列的工具，帮助开发者快速开发C（或C++）的动态库，并能自动将so和java应用一起打包成apk。NDK集成了交叉编译器（交叉编译器需要UNIX或LINUX系统环境），并提供了相应的mk文件隔离CPU、平台、ABI等差异，开发人员只需要简单修改mk文件（指出“哪些文件需要编译”、“编译特性要求”等），就可以创建出so。 为什么使用NDK？1.)代码的保护。由于apk的java层代码很容易被反编译，而C/C++库反汇难度较大。2.)可以方便地使用现存的开源库。大部分现存的开源库都是用C/C++代码编写的。3.)提高程序的执行效率。将要求高性能的应用逻辑使用C开发，从而提高应用程序的执行效率。4.)便于移植。用C/C++写得库可以方便在其他的嵌入式平台上再次使用。 什么是JNI？JNI全称为：Java Native Interface。JNI 是本地编程接口，它使得在 Java 虚拟机内部运行的 Java 代码能够与用其它语言(如 C、C++)编写的代码进行交互。 为什么使用JNI？JNI的目的是使java方法能够调用c实现的一些函数。 安卓中的so文件是什么？Android中用到的so文件是一个c++的函数库。在android的JNI中，要先将相应的C语言打包成so库，然后导入到lib文件夹中供java调用。 编译运行前，别忘了把打开了\\app\\build\\intermediates\\classes\\debug\\的Terminal命令行工具关掉，否则占用这个文件夹会导致编译不成功。因为编译的时候，会把build里的东西全部删除再重新生成，如果占用的话，删除不了就会出错。 向您的项目添加 C 和 C++ 代码 从当前的activity获得根视图 getWindow().getDecorView() 无标题风格 在指定的activity中设定 android:theme=”@style/Theme.AppCompat.Light.NoActionBar” Android实现无标题栏全屏的三种方法You need to use a Theme.AppCompat theme (or descendant) with this activity. 【Android 应用开发】 ActionBar 基础 Android存储访问及目录Android中的Environment.getExternalStorageState使用 Android实现简单音乐播放器(MediaPlayer)MediaPlayer播放音频与视频 Gson使用指南 JSON (官网) 是一种文本形式的数据交换格式，它比XML更轻量、比二进制容易阅读和编写，调式也更加方便。其重要性不言而喻。解析和生成的方式很多，Java中最常用的类库有：JSON-Java、Gson、Jackson、FastJson等。 期望的json格式1&#123;\"name\":\"怪盗kidou\",\"age\":24,\"emailAddress\":\"ikidou@example.com\"&#125; 实际1&#123;\"name\":\"怪盗kidou\",\"age\":24,\"email_address\":\"ikidou@example.com\"&#125; 这对于使用PHP作为后台开发语言时很常见的情况，php和js在命名时一般采用下划线风格，而Java中一般采用的驼峰法，让后台的哥们改吧 前端和后台都不爽，但要自己使用下划线风格时我会感到不适应，怎么办?难到没有两全齐美的方法么? 我们知道Gson在序列化和反序列化时需要使用反射，说到反射就不得不想到注解,一般各类库都将注解放到annotations包下，打开源码在com.google.gson包下果然有一个annotations，里面有一个SerializedName的注解类，这应该就是我们要找的。 那么对于json中email_address这个属性对应POJO的属性则变成：12@SerializedName(\"email_address\")public String emailAddress; 这样的话，很好的保留了前端、后台、Android/java各自的命名习惯。 你以为这样就完了么? 如果接中设计不严谨或者其它地方可以重用该类，其它字段都一样，就emailAddress 字段不一样，比如有下面三种情况那怎么?重新写一个?123&#123;\"name\":\"怪盗kidou\",\"age\":24,\"emailAddress\":\"ikidou@example.com\"&#125;&#123;\"name\":\"怪盗kidou\",\"age\":24,\"email_address\":\"ikidou@example.com\"&#125;&#123;\"name\":\"怪盗kidou\",\"age\":24,\"email\":\"ikidou@example.com\"&#125; 为POJO字段提供备选属性名SerializedName注解提供了两个属性，上面用到了其中一个，别外还有一个属性alternate，接收一个String数组。注：alternate需要2.4版本12@SerializedName(value = \"emailAddress\", alternate = &#123;\"email\", \"email_address\"&#125;)public String emailAddress; 当上面的三个属性(email_address、email、emailAddress)都中出现任意一个时均可以得到正确的结果。注：当多种情况同时出时，以最后一个出现的值为准。1234Gson gson = new Gson();String json = \"&#123;\\\"name\\\":\\\"怪盗kidou\\\",\\\"age\\\":24,\\\"emailAddress\\\":\\\"ikidou_1@example.com\\\",\\\"email\\\":\\\"ikidou_2@example.com\\\",\\\"email_address\\\":\\\"ikidou_3@example.com\\\"&#125;\";User user = gson.fromJson(json, User.class);System.out.println(user.emailAddress); // ikidou_3@example.com 你们要的多数据库功能终于来了 数据库框架LitePal使用指南 Android数据库高手秘籍(四)——使用LitePal建立表关联 TouchListener PK OnTouchEvent + 多点触碰 TouchListener是基于监听的，而OnTouchEvent则是基于回调的！ OnTouchListener相关方法与属性 12345 onTouch(View v, MotionEvent event):这里面的参数依次是触发触摸事件的组件,触碰事件event 封装了触发事件的详细信息，同样包括事件的类型、触发时间等信息。比如event.getX(),event.getY()我们也可以对触摸的动作类型进行判断,使用event.getAction( )再进行判断;如:event.getAction == MotionEvent.ACTION_DOWN：按下事件event.getAction == MotionEvent.ACTION_MOVE:移动事件event.getAction == MotionEvent.ACTION_UP:弹起事件 onTouchEvent更多的是用于自定义的view,所有的view类中都重写了该方法,而这种触摸事件是基于回调的,也就是说:如果我们返回的值是false的话,那么事件会继续向外传播,由外面的容器或者Activity进行处理!当然还涉及到了手势(Gesture),这个我们会在后面进行详细的讲解!onTouchEvent其实和onTouchListener是类似的,只是处理机制不用,前者是回调,后者是监听模式！ 多点触碰 多点触碰就是多个手指在屏幕上进行操作，用的最多的估计是放大缩功能吧，比如很多的图片浏览器都支持缩放！理论上Android系统本身可以处理多达256个手指的触摸，当然这取决于手机硬件的支持；不过支持多点触摸的手机一般支持2-4个点，当然有些更多！我们发现前面两点都有用到MotionEvent，MotionEvent代表的是一个触摸事件；前我们可以根据event.getAction() &amp; MotionEvent.ACTION_MASK来判断是哪种操作，除了上面介绍的三种单点操作外，还有两个多点专用的操作：MotionEvent.ACTION_POINTER_DOWN:当屏幕上已经有一个点被按住，此时再按下其他点时触发。MotionEvent.ACTION_POINTER_UP:当屏幕上有多个点被按住，松开其中一个点时触发（即非最后一个点被放开时）。 简单的流程大概是这样：当我们一个手指触摸屏幕 ——&gt; 触发ACTION_DOWN事件接着有另一个手指也触摸屏幕 ——&gt; 触发ACTION_POINTER_DOWN事件,如果还有其他手指触摸，继续触发有一个手指离开屏幕 ——&gt; 触发ACTION_POINTER_UP事件，继续有手指离开，继续触发当最后一个手指离开屏幕 ——&gt; 触发ACTION_UP事件而且在整个过程中，ACTION_MOVE事件会一直不停地被触发我们可以通过event.getX(int)或者event.getY(int)来获得不同触摸点的位置： 比如event.getX(0)可以获得第一个接触点的X坐标，event.getX(1)获得第二个接触点的X坐标这样… 另外，我们还可以在调用MotionEvent对象的getPointerCount()方法判断当前有多少个手指在触摸~ Bitmap(位图)全解析 Drawable：通用的图形对象，用于装载常用格式的图像，既可以是PNG，JPG这样的图像， 也是前面学的那13种Drawable类型的可视化对象！我们可以理解成 一个用来放画的——画框！Bitmap(位图)：我们可以把他看作 一个画架，我们先把画放到上面，然后我们可以 进行一些处理，比如获取图像文件信息，做旋转切割，放大缩小等操作！Canvas(画布)：如其名，画布，我们可以在上面作画(绘制)，你 既可以用Paint(画笔)， 来画各种形状或者写字，又可以用Path(路径)来绘制多个点，然后连接成各种图形！Matrix(矩阵)：用于图形特效处理的，颜色矩阵(ColorMatrix)，还有 使用Matrix进行图像的 平移，缩放，旋转，倾斜等！而上述的这些都是Android中的底层图形类：android.graphics给我们提供的接口 Drawable资源使用注意事项Drawable分为两种： 一种是我们普通的图片资源，在Android Studio中我们一般放到res/mipmap目录下， 和以前的Eclipse不一样哦！另外我们如果把工程切换成Android项目模式，我们直接 往mipmap目录下丢图片即可，AS会自动分hdpi，xhdpi…！ 另一种是我们编写的XML形式的Drawable资源，我们一般把他们放到res/drawable目录 下，比如最常见的按钮点击背景切换的Selctor！ 在XML我们直接通过@mipmap或者@drawable设置Drawable即可 比如: android:background = “@mipmap/iv_icon_zhu” / “@drawable/btn_back_selctor” 而在Java代码中我们可以通过Resource的getDrawable(R.mipmap.xxx)可以获得drawable资源 如果是为某个控件设置背景，比如ImageView，我们可以直接调用控件.getDrawale()同样 可以获得drawable对象！ Android中drawable中的资源名称有约束，必须是：[a-z0-9_.]（即：只能是字母数字及和.）， 而且不能以数字开头，否则编译会报错： Invalid file name: must contain only [a-z0-9.]！ 小写啊！！！！小写！！！小写！——重要事情说三遍~ 圆形图片CircleImageView的使用和分析Android CircleImageView圆形ImageViewCircleImageView项目下载地址：https://github.com/hdodenhof/CircleImageView 自定义属性attrs：123456&lt;declare-styleable name=\"CircleImageView\"&gt; &lt;attr name=\"civ_border_width\" format=\"dimension\" /&gt; &lt;attr name=\"civ_border_color\" format=\"color\" /&gt; &lt;attr name=\"civ_border_overlay\" format=\"boolean\" /&gt; &lt;attr name=\"civ_fill_color\" format=\"color\" /&gt; &lt;/declare-styleable&gt; 属性介绍：civ_border_width： 设置边框的宽度，默认为0，即无边框。civ_border_color： 设置边框的颜色，默认为黑色。civ_border_overlay：设置边框是否覆盖在图片上，默认为false，即边框在图片外圈。civ_fill_color： 设置图片的底色，默认透明。注意：CircleImageView的默认ScaleType为CENTER_CROP，且只能为CENTER_CROP。 Limitations The ScaleType is always CENTER_CROP and you’ll get an exception if you try to change it. This is (currently) by design as it’s perfectly fine for profile images. Enabling adjustViewBounds is not supported as this requires an unsupported ScaleType If you use an image loading library like Picasso or Glide, you need to disable their fade animations to avoid messed up images. For Picasso use the noFade() option, for Glide use dontAnimate(). If you want to keep the fadeIn animation, you have to fetch the image into a Target and apply a custom animation yourself when receiving the Bitmap. Using a TransitionDrawable with CircleImageView doesn’t work properly and leads to messed up images. 三个绘图工具类Drawable以及Bitmap，都是加载好图片的，而本节我们要学习的绘图相关的 一些API，他们分别是Canvas(画布)，Paint(画笔)，Path(路径)！本节非常重要，同时也是我们 自定义View的基础 Intent之复杂数据的传递Android 基础入门教程 Intent传递数组写入数组1bd.putStringArray(\"StringArray\", new String[]&#123;\"呵呵\",\"哈哈\"&#125;); //可把StringArray换成其他数据类型,比如int,float等等…读取数组1String[] str = bd.getStringArray(\"StringArray\") Intent传递集合List&lt;基本数据类型或String&gt;写入集合：intent.putStringArrayListExtra(name, value)intent.putIntegerArrayListExtra(name, value)读取集合：intent.getStringArrayListExtra(name)intent.getIntegerArrayListExtra(name) List&lt; Object&gt;将list强转成Serializable类型,然后传入(可用Bundle做媒介)写入集合：putExtras(key, (Serializable)list)读取集合：(List) getIntent().getSerializable(key)PS:Object类需要实现Serializable接口 MediaPlayer播放音频与视频Android多媒体中的——MediaPlayer，我们可以通过这个API来播放音频和视频 该类是Androd多媒体框架中的一个重要组件，通过该类，我们可以以最小的步骤来获取，解码 和播放音视频。它支持三种不同的媒体来源： 本地资源 内部的URI，比如你可以通过ContentResolver来获取 外部URL(流) 对于Android所支持的的媒体格式列表 Android小项目之“音乐播放器”设置播放器的监听器：MediaPlayer提供了一些设置不同监听器的方法来更好地对播放器的工作状态进行监听，以期及时处理各种情况，如： setOnCompletionListener(MediaPlayer.OnCompletionListener listener)、setOnErrorListener(MediaPlayer.OnErrorListener listener)等,设置播放器时需要考虑到播放器可能出现的情况设置好监听和处理逻辑，以保持播放器的健壮性。 安装Apache服务器 一句话，通过官方网站和集成包，最为简单快捷 XAMPP Apache + MariaDB + PHP + Perl 上传文件到7牛，删除后服务器未能及时刷新如果调试需要，只能重命名后再上传，更换新的路径 JAVA中，字符串拼接尽量使用StringBuilder的append方法效率测试可参看java五种拼接字符串的方法 “”和null的差别s是一个String类的引用，null表示它不指向任何字符串对象，””表示s指向一个长度为0的字符串对象。如果调用s.length()之类的方法，s为null时会抛出NullPointerException，而””则能进行正常的计算。 模拟器离线通过DDMS的File Explorer查看文件提示com.android.ddmlib.AdbCommandRejectedException: device offline 【解决办法】在cmd下输入：Step1： adb kill-serverStep2： adb start-server或者打开进程管理器，把adb关掉，再重启adb。 button透明12半透明&lt;Button android:background=\"#11000000\" /&gt;透明&lt;Button android:background=\"#00000000\" /&gt; 原理：颜色和不透明度 (alpha) 值以十六进制表示法表示。任何一种颜色的值范围都是 0 到 255（00 到 ff）。对于 alpha，00 表示完全透明，ff 表示完全不透明。表达式顺序是“aabbggrr”，其中“aa=alpha”（00 到 ff）；“bb=blue”（00 到 ff）；“gg=green”（00 到 ff)；“rr=red”（00 到 ff）。所以要实现半透明只需将‘bb’,‘gg’,‘rr’的值都设为‘00’，只调节‘aa’的值（00到方法）就可以控制不同的透明度。 按钮点击效果变化 android selector 背景选择器的使用， button （未点击，点击，选中保持状态）效果实现Android Button、ImageView等自定义选中、按下、未选中等效果 android获取string.xml的值更多参考：android获取string.xml的值获取string.xml文件里面的值有几个不同的地方。1.在AndroidManifest.xml与layout等xml文件里:android:text=”@string/resource_name” 2.在activity里：方法一:this.getString(R.string.resource_name);方法二:getResources().getString(R.string.resource_name); 3.在其他java文件（必须有Context或pplication）方法一: context.getString(R.string.resource_name);方法二: application.getString(R.string.resource_name); Android Button、ImageView等自定义选中、按下、未选中等效果原文方法：自定义状态效果可以通过代码实现，也可以通过xml定义style实现。 android selector 背景选择器的使用， button （未点击，点击，选中保持状态）效果实现 升级到AndroidStudio2.3之后，添加ListView控件，程序异常原因：ListView控件使用了MATCH_PARENT，而该属性在ConstraintLayout布局中是不支持的Exception raised during rendering: MATCH_PARENT is not supported in ConstraintLayout (Details) Tip: Try to refresh the layout. 解决方案：去除该属性，或者改成LinearLayout提前检测：通过“Design”预览，看能否正常显示出来，如果不能，详细分析其警告信息 新建资源文件目录问题res目录下，新建layout目录文件，不能解析控件，在layout目录下，也不能新建目录，提示其只支持xml文件 AndroidStudio2.3不能显示logcat的问题可以通过Restart logging来恢复，另外，充分利用选中进程、filter和日志级别来第一时间找出有用的日志信息。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"Java tips","date":"2017-03-08T13:59:06.000Z","path":"2017/03/08/Program/Java/java-trouble-solver/","text":"咖啡需要慢慢品，Java也如此… Digester解析xml文件Java 处理 XML 的三种主流技术及介绍 DOM 易于上手，程序易于理解，但缺点在于占用内存大，不适合于解析较大的 XML 文件； SAX 基于事件模型占用系统资源少，能够胜任较大的 XML 文件解析，但解析过程较为繁琐查找元素不方便； Digester/JAXB 基于上述两种技术衍生而来。 Digester 就是一种用来把一个 XML 转化为一个与该 XML 结构类似的 JavaBean。你可以把 XML 根元素想象成一个 JavaBean， 该根元素的 attribute 就是这个 JavaBean 的各种 Field，当该根元素有其他子 tag 时，又要把这个子 tag 想象成一个个新的 XML，将其视为一个新的 JavaBean， 并作为一个 Field 加入到父 Bean 当中，然后以此类推，通过循环的方式将整个 XML 进行解析。 Java中static作用及用法详解static表示不要实例化就可以使用 static是静态修饰符，静态就是指在编译后所分配的内存会一直存在，直到程序退出内存才会释放这个空间，也就是只要程序在运行，那么这块内存就会一直存在。这样做有什么意义呢？在Java程序里面，所有的东西都是对象，而对象的抽象就是类，对于一个类而言，如果要使用他的成员，那么普通情况下必须先实例化对象后，通过对象的引用才能够访问这些成员，但是用static修饰的成员可以通过类名加“.”进行直接访问。static对象可以在它的任何对象创建之前访问，无需引用任何对象。 用public修饰的static成员变量和成员方法本质是全局变量和全局方法，当声明它类的对象市，不生成static变量的副本，而是类的所有实例共享同一个static变量。 用static修饰的代码块表示静态代码块，当Java虚拟机（JVM）加载类时，就会执行该代码块 static代码块也叫静态代码块，是在类中独立于类成员的static语句块，可以有多个，位置可以随便放，它不在任何的方法体内，JVM加载类时会执行这些静态的代码块，如果static代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。 static和final一块用表示什么static final用来修饰成员变量和成员方法，可简单理解为“全局常量”！ 对于变量，表示一旦给值就不可修改，并且通过类名可以访问。 对于方法，表示不可覆盖，并且可以通过类名直接访问。 特别要注意一个问题：对于被static和final修饰过的实例常量，实例本身不能再改变了，但对于一些容器类型（比如，ArrayList、HashMap）的实例变量，不可以改变容器变量本身，但可以修改容器中存放的对象，这一点在编程中用到很多。 静态代码块和静态方法的区别是：• 静态代码块是自动执行的;• 静态方法是被调用的时候才执行的. 总结如果一个成员被声明为static，它就能够在它的类的任何对象创建之前被访问，而不必引用任何对象。你可以将方法和变量都声明为static。static 成员的最常见的例子是main( ) 。因为在程序开始执行时必须调用main() ，所以它被声明为static。声明为static的变量实质上就是全局变量。当声明一个对象时，并不产生static变量的拷贝，而是该类所有的实例变量共用同一个static变量。声明为static的方法有以下几条限制：• 它们仅能调用其他的static方法。• 它们只能访问static数据。• 它们不能以任何方式引用this或super（关键字super 与继承有关，在下一章中描述）。如果你需要通过计算来初始化你的static变量，你可以声明一个static块，Static 块仅在该类被加载时执行一次。 深入理解Java中的final关键字final关键字的含义?final在Java中是一个保留的关键字，可以声明成员变量、方法、类以及本地变量。一旦你将引用声明作final，你将不能改变这个引用了，编译器会检查代码，如果你试图将变量再次初始化的话，编译器会报编译错误。 什么是final变量？凡是对成员变量或者本地变量(在方法中的或者代码块中的变量称为本地变量)声明为final的都叫作final变量。final变量经常和static关键字一起使用，作为常量。下面是final变量的例子：12public static final String LOAN = \"loan\";LOAN = new String(\"loan\") //invalid compilation error final变量是只读的。 什么是final方法?final也可以声明方法。方法前面加上final关键字，代表这个方法不可以被子类的方法重写。如果你认为一个方法的功能已经足够完整了，子类中不需要改变的话，你可以声明此方法为final。final方法比非final方法要快，因为在编译的时候已经静态绑定了，不需要在运行时再动态绑定。下面是final方法的例子：123456789101112class PersonalLoan&#123; public final String getName()&#123; return \"personal loan\"; &#125;&#125;class CheapPersonalLoan extends PersonalLoan&#123; @Override public final String getName()&#123; return \"cheap personal loan\"; //compilation error: overridden method is final &#125;&#125; 什么是final类？使用final来修饰的类叫作final类。final类通常功能是完整的，它们不能被继承。Java中有许多类是final的，譬如String, Interger以及其他包装类。下面是final类的实例：1234567 final class PersonalLoan&#123; &#125; class CheapPersonalLoan extends PersonalLoan&#123; //compilation error: cannot inherit from final class&#125; final关键字的好处下面总结了一些使用final关键字的好处 final关键字提高了性能。JVM和Java应用都会缓存final变量。 final变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销。 使用final关键字，JVM会对方法、变量及类进行优化。 不可变类创建不可变类要使用final关键字。不可变类是指它的对象一旦被创建了就不能被更改了。String是不可变类的代表。不可变类有很多好处，譬如它们的对象是只读的，可以在多线程环境下安全的共享，不用额外的同步开销等等。 相关阅读：为什么String是不可变的以及如何写一个不可变类。 关于final的重要知识点 final关键字可以用于成员变量、本地变量、方法以及类。 final成员变量必须在声明的时候初始化或者在构造器中初始化，否则就会报编译错误。 你不能够对final变量再次赋值。 本地变量必须在声明时赋值。 在匿名类中所有变量都必须是final变量。 final方法不能被重写。 final类不能被继承。 final关键字不同于finally关键字，后者用于异常处理。 final关键字容易与finalize()方法搞混，后者是在Object类中定义的方法，是在垃圾回收之前被JVM调用的方法。 接口中声明的所有变量本身是final的。 final和abstract这两个关键字是反相关的，final类就不可能是abstract的。 final方法在编译阶段绑定，称为静态绑定(static binding)。 没有在声明时初始化final变量的称为空白final变量(blank final variable)，它们必须在构造器中初始化，或者调用this()初始化。不这么做的话，编译器会报错“final变量(变量名)需要进行初始化”。 将类、方法、变量声明为final能够提高性能，这样JVM就有机会进行估计，然后优化。 按照Java代码惯例，final变量就是常量，而且通常常量名要大写： 1private final int COUNT = 10; 对于集合对象声明为final指的是引用不能被更改，但是你可以向其中增加，删除或者改变内容。譬如： 1234private final List Loans = new ArrayList();list.add(“home loan”); //validlist.add(\"personal loan\"); //validloans = new Vector(); //not valid 我们已经知道final变量、final方法以及final类是什么了。必要的时候使用final，能写出更快、更好的代码的。 匿名类java提高篇(十)—–详解匿名内部类 匿名类是不能有名字的类，它们不能被引用，只能在创建时用New语句来声明它们。匿名类的声明是在编译时进行的，实例化在运行时进行，这意味着for循环中的一个new语句会创建相同匿名类的几个实例，而不是创建几个不同匿名类的一个实例。匿名类的目的是在某个地方需要特殊的实现，因此在该处编写其实现，并获取它的实例，调用它的方法。不要在匿名内部类编写其他的方法，是不可见的。形式为：new &lt;类或接口&gt; &lt;类的主体&gt; 注意事项在使用匿名内部类的过程中，我们需要注意如下几点： 1、使用匿名内部类时，我们必须是继承一个类或者实现一个接口，但是两者不可兼得，同时也只能继承一个类或者实现一个接口。2、匿名内部类中是不能定义构造函数的。3、匿名内部类中不能存在任何的静态成员变量和静态方法。4、匿名内部类为局部内部类，所以局部内部类的所有限制同样对匿名内部类生效。5、匿名内部类不能是抽象的，它必须要实现继承的类或者实现的接口的所有抽象方法。 使用的形参为何要为final我们给匿名内部类传递参数的时候，若该形参在内部类中需要被使用，那么该形参必须要为final。也就是说：当所在的方法的形参需要被内部类里面使用时，该形参必须为final。 为什么必须要为final呢？ 首先我们知道在内部类编译成功后，它会产生一个class文件，该class文件与外部类并不是同一class文件，仅仅只保留对外部类的引用。当外部类传入的参数需要被内部类调用时，从java程序的角度来看是直接被调用： 123456789public class OuterClass &#123; public void display(final String name,String age)&#123; class InnerClass&#123; void display()&#123; System.out.println(name); &#125; &#125; &#125;&#125; 从上面代码中看好像name参数应该是被内部类直接调用？其实不然，在java编译之后实际的操作如下：1234567891011public class OuterClass$InnerClass &#123; public InnerClass(String name,String age)&#123; this.InnerClass$name = name; this.InnerClass$age = age; &#125; public void display()&#123; System.out.println(this.InnerClass$name + \"----\" + this.InnerClass$age ); &#125;&#125; 所以从上面代码来看，内部类并不是直接调用方法传递的参数，而是利用自身的构造器对传入的参数进行备份，自己内部方法调用的实际上时自己的属性而不是外部方法传递进来的参数。 直到这里还没有解释为什么是final？在内部类中的属性和外部方法的参数两者从外表上看是同一个东西，但实际上却不是，所以他们两者是可以任意变化的，也就是说在内部类中我对属性的改变并不会影响到外部的形参，而然这从程序员的角度来看这是不可行的，毕竟站在程序的角度来看这两个根本就是同一个，如果内部类该变了，而外部方法的形参却没有改变这是难以理解和不可接受的，所以为了保持参数的一致性，就规定使用final来避免形参的不改变。 简单理解就是，拷贝引用，为了避免引用值发生改变，例如被外部类的方法修改等，而导致内部类得到的值不一致，于是用final来让该引用不可改变。 故如果定义了一个匿名内部类，并且希望它使用一个其外部定义的参数，那么编译器会要求该参数引用是final的。 匿名内部类初始化我们一般都是利用构造器来完成某个实例的初始化工作的，但是匿名内部类是没有构造器的！那怎么来初始化匿名内部类呢？使用构造代码块！利用构造代码块能够达到为匿名内部类创建一个构造器的效果。 1234567891011121314151617181920212223242526272829303132public class OutClass &#123; public InnerClass getInnerClass(final int age,final String name)&#123; return new InnerClass() &#123; int age_ ; String name_; //构造代码块完成初始化工作 &#123; if(0 &lt; age &amp;&amp; age &lt; 200)&#123; age_ = age; name_ = name; &#125; &#125; public String getName() &#123; return name_; &#125; public int getAge() &#123; return age_; &#125; &#125;; &#125; public static void main(String[] args) &#123; OutClass out = new OutClass(); InnerClass inner_1 = out.getInnerClass(201, \"chenssy\"); System.out.println(inner_1.getName()); InnerClass inner_2 = out.getInnerClass(23, \"chenssy\"); System.out.println(inner_2.getName()); &#125;&#125; Java中匿名类的两种实现方式使用匿名内部类课使代码更加简洁、紧凑，模块化程度更高。内部类能够访问外部内的一切成员变量和方法，包括私有的，而实现接口或继承类做不到。然而这个不是我说的重点，我说的很简单，就是匿名内部类的两种实现方式：第一种，继承一个类，重写其方法；第二种，实现一个接口（可以是多个），实现其方法。下面通过代码来说明：1234567891011121314151617181920212223public class TestAnonymousInterClass&#123; public static void main(String args[])&#123; TestAnonymousInterClass test=new TestAnonymousInterClass(); test.show(); &#125; //在这个方法中构造了一个匿名内部类 private void show()&#123; Out anonyInter=new Out()&#123;// 获取匿名内部类实例 void show()&#123;//重写父类的方法 System.out.println(\"this is Anonymous InterClass showing.\"); &#125; &#125;; anonyInter.show();// 调用其方法 &#125; &#125; // 这是一个已经存在的类，匿名内部类通过重写其方法，将会获得另外的实现 class Out&#123; void show()&#123; System.out.println(\"this is Out showing.\"); &#125; &#125; 程序运行的输出结果为： this is Anonymous InterClass showing. 所以在这里看出，匿名内部类有了自己的实现。其实很简单，使用匿名内部类是因为我这地方需要有点什么特殊的实现，所以我就在这地方把具体实现也给了出来了。然后我就在这地方获取它的实例，调用它的方法。 接口的方式，只要把父类换成接口就行了，没必要给出代码了。 使用匿名内部类时我们不要忘了我们的目的，我们只是在这地方想对某个类有特殊的实现。而不要想得太多，在匿名内部编写其它的方法。在匿名内部类中编写的自己的方法是不可见的。此种做法是毫无意义的，当然一般也不会这么做。在这里只是告诉初学者对于匿名内部类不要想的太多，而要这么想：匿名内部类就是重写父类或接口的方法。 匿名内部类是没有名字的，所以我们没办法获得其类型，而只能把它当作超类或接口类型来使用。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://ipcreator.me/tags/Java/"}]},{"title":"Linux 十大常用命令","date":"2017-03-05T08:42:06.000Z","path":"2017/03/05/Program/Android/linux-tips/","text":"mkdir、rmdir、cd、ls、cat、less、cp、mv、rm 、chmod cd .. 返回上级目录（若当前目录为“/“，则执行完后还在“/“；”..”为上级目录的意思）；cd ../.. 返回上两级目录； 更多参考：6 Best Linux/Unix Command Cheat Sheet No 命令 功 能 实 例 1 mkdir 创建目录 mkdir domkdir do/alignmkdir –p blast/hba/209 2 rmdir 删除目录 rmdir tmp 3 cd 改变目录 Cdcd docd ..cd ../do/tree/7hba 4 ls 显示文件信息 lsls -lls .fastals /tmp/seqls –lR 5 cat 编辑文件 cat seq1cat &gt; seq1cat &gt;&gt; seq1 6 less 显示文件内容 more myseq 7 cp 复制文件 cp seq1 seq2cp ../seq/hba_human.sw .cp /tmp/seq1 .cp *.fasta ../keep/ 8 mv 更改文件名 mv seq1 seq2 9 rm 删除文件 rm seq2rm .txtrm tmp/seq.rm –rf tmp 10 chmod 改变权限 chmod –w seq1.fastachmod +w .needlechmod 755 命令 1：mkdir用途：创建目录实例 1：mkdir do含义：在当前目录下创建名为 do 的子目录实例 2：mkdir do/align含义：在子目录 do 下创建名为 align 的子目录（子目录 do 已经存在）实例 3：mkdir –p hba/tree含义：在当前目录下创建名为 hba 的子目录，并在子目录 hba 下创建名为 tree 的子目录 命令 2：rmdir用途：删除目录实例 1：rmdir tmp含义：删除当前目录下名为 tmp 的子目录，该子目录中没有文件和子目录命令 3：cd用途：改变目录实例 1：cd含义：回到用户主目录，即登录时进入的目录实例 2：cd do含义：进入子目录 do 实例 3：cd ..含义：回到上级目录实例 4：cd hba/tree含义：直接进入子目录 hba 下的 tree 子目录实例 5：cd ../do/align含义：进入上级目录 do 下的 align 子目录 命令 4：ls用途：显示文件或目录实例 1：ls含义：显示当前目录下子目录和文件名实例 2：ls -l含义：显示当前目录下子目录和文件名详细信息，包括属性、权限、大小和创建日期等实例 3：ls .fasta含义：显示当前目录下所有以.fasta 结尾的文件实例 4：ls hba/hba_含义：显示子目录 hba 下所有以 hba_起始的文件实例 5：ls /tmp含义：显示/tmp 目录所有子目录和文件实例 6：ls –lR含义：逐级显示当前目录及子目录下所有子目录和文件 命令 5：cat用途：显示或编辑文本文件实例 1：cat &gt; cat1含义：往 cat1 中逐行输入文本，用 Ctrl-D 结束输入实例 2：cat &gt;&gt; cat1含义：往 cat1 中逐行追加文本，用 Ctrl-D 结束输入实例 3：cat cat1含义：显示文本文件 cat1 中的内容 命令 6：less用途：显示文件内容实例 1：less 209hba.list含义：逐屏显示文件 209hba.list 内容，回车进一行，空格进一页，q 终止显示 命令 7：cp用途：复制文件实例 1：cp seq1 seq2含义：将文件 seq1 复制到文件 seq2 中，保留 seq1实例 2：cp *.fasta ../keep/含义：将所有文件名以.fasta 结尾的文件复制到上级目录的 keep 子目录中实例 3：cp ../seq/hba_human.sw .含义：将上级目录的 seq 子目录中名为 hba_human.sw 的文件复制到当前目录中实例 4：cp /tmp/tf/zmtf-pep.fasta blast/含义：将/tmp 目录中 tf 子目录中名为 zmtf-pep.fasta 的文件复制到当前目录中名为blast 的子目录中 命令 8：mv用途：更改文件名实例 1：mv seq1 seq2含义：将文件 seq1 改名为 seq2，不保留 seq1实例 2：mv hba_human.fasta pku08s1/hba含义：将当前目录下文件 hba_human.fasta 移到子目录 pku08s1 下的子目录hba 中 命令 9：rm用途：删除文件或目录实例 1：rm seq2含义：删除文件 seq2实例 2：rm .txt含义：删除所有以.txt 结尾的文件实例 3：rm –r temp/含义：删除子目录 temp 下所有子目录和文件，保留该目录实例 4：rm –r temp含义：删除子目录 temp 和该目录下所有子目录和文件 命令 10：chmod用途：改变文件或目录权限实例 1：chmod –w ppf1.fas含义：取消所有用户对 ppf1.fas 的写权限实例 2：chmod +w seq1含义：将当前目录下 seq1 设置为本用户可写，其他用户权限不变实例 3：chmod -w keep/含义：取消子目录 keep 写权限，不能在该目录下创建和删除文件或子目录实例 4：chmod 755 bin/*含义：将子目录 bin 下所有文件设置为本用户可读可写可执行，其它用户可读可执行","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ipcreator.me/tags/Linux/"}]},{"title":"Android Debug Bridge tips","date":"2017-03-05T07:25:06.000Z","path":"2017/03/05/Program/Android/adb-tips/","text":"图形化界面太低效，还存在DDMS连接不稳定的隐患，尽量通过命令行方式高效解决 原文详细请参考：ADB Usage Complete 常用命令的简单描述cat 显示文件内容cd 切换目录chmod 改变文件的存取模式/访问权限df 查看磁盘空间使用情况grep 过滤输出kill 杀死指定 PID 的进程ls 列举目录内容mount 挂载目录的查看和管理mv 移动或重命名文件ps 查看正在运行的进程rm 删除文件top 查看进程的资源占用情况 USB 连接通过 USB 连接来正常使用 adb 需要保证几点： 硬件状态正常。 包括 Android 设备处于正常开机状态，USB 连接线和各种接口完好。 Android 设备的开发者选项和 USB 调试模式已开启。 可以到「设置」-「开发者选项」-「Android 调试」查看。 如果在设置里找不到开发者选项，那需要通过一个彩蛋来让它显示出来：在「设置」-「关于手机」连续点击「版本号」7 次。 设备驱动状态正常。 这一点貌似在 Linux 和 Mac OS X 下不用操心，在 Windows 下有可能遇到需要安装驱动的情况，确认这一点可以右键「计算机」-「属性」，到「设备管理器」里查看相关设备上是否有黄色感叹号或问号，如果没有就说明驱动状态已经好了。否则可以下载一个手机助手类程序来安装驱动先。 通过 USB 线连接好电脑和设备后确认状态。1adb devices 如果能看到 xxxxxx device说明连接成功。 以 root 权限运行 adbdadb 的运行原理是 PC 端的 adb server 与手机端的守护进程 adbd 建立连接，然后 PC 端的 adb client 通过 adb server 转发命令，adbd 接收命令后解析运行。 所以如果 adbd 以普通权限执行，有些需要 root 权限才能执行的命令无法直接用 adb xxx 执行。这时可以 adb shell 然后 su 后执行命令，也可以让 adbd 以 root 权限执行，这个就能随意执行高权限命令了。 命令：1adb root 现在再运行 adb shell，看看命令行提示符是不是变成 # 了？ 有些手机 root 后也无法通过 adb root 命令让 adbd 以 root 权限执行，比如三星的部分机型，会提示 adbd cannot run as root in production builds，此时可以先安装 adbd Insecure，然后 adb root 试试。 相应地，如果要恢复 adbd 为非 root 权限的话，可以使用 adb unroot 命令。 安装 APK命令格式： adb install [-lrtsdg] 参数： adb install 后面可以跟一些可选参数来控制安装 APK 的行为，可用参数及含义如下： 参数 含义-l 将应用安装到保护目录 /mnt/asec-r 允许覆盖安装-t 允许安装 AndroidManifest.xml 里 application 指定 android:testOnly=”true” 的应用-s 将应用安装到 sdcard-d 允许降级覆盖安装-g 授予所有运行时权限运行命令后如果见到类似如下输出（状态为 Success）代表安装成功： 123[100%] /data/local/tmp/1.apk pkg: /data/local/tmp/1.apkSuccess 参考：PackageManager.java adb install 内部原理简介 adb install 实际是分三步完成： push apk 文件到 /data/local/tmp。 调用 pm install 安装。 删除 /data/local/tmp 下的对应 apk 文件。 所以，必要的时候也可以根据这个步骤，手动分步执行安装过程。 卸载应用命令：1adb uninstall [-k] &lt;packagename&gt; 表示应用的包名，-k 参数可选，表示卸载应用但保留数据和缓存目录。 命令示例：1adb uninstall com.qihoo360.mobilesafe 表示卸载 360 手机卫士。 复制设备里的文件到电脑命令：1adb pull &lt;设备里的文件路径&gt; [电脑上的目录] 其中 电脑上的目录 参数可以省略，默认复制到当前目录。 例：1adb pull /sdcard/sr.mp4 ~/tmp/ 小技巧：设备上的文件路径可能需要 root 权限才能访问，如果你的设备已经 root 过，可以先使用 adb shell 和 su 命令在 adb shell 里获取 root 权限后，先 cp /path/on/device /sdcard/filename 将文件复制到 sdcard，然后 adb pull /sdcard/filename /path/on/pc。 复制电脑里的文件到设备命令：1adb push &lt;电脑上的文件路径&gt; &lt;设备里的目录&gt; 例：1adb push ~/sr.mp4 /sdcard/ 小技巧：设备上的文件路径普通权限可能无法直接写入，如果你的设备已经 root 过，可以先 adb push /path/on/pc /sdcard/filename，然后 adb shell 和 su 在 adb shell 里获取 root 权限后，cp /sdcard/filename /path/on/device。 查看日志Android 系统的日志分为两部分，底层的 Linux 内核日志输出到 /proc/kmsg，Android 的日志输出到 /dev/log。 Android 日志命令格式：1[adb] logcat [&lt;option&gt;] ... [&lt;filter-spec&gt;] ... 常用用法列举如下： 按级别过滤日志 Android 的日志分为如下几个优先级（priority）： V —— Verbose（最低，输出得最多）D —— DebugI —— InfoW —— WarningE —— ErrorF —— FatalS —— Silent（最高，啥也不输出）按某级别过滤日志则会将该级别及以上的日志输出。 比如，命令：1adb logcat *:W 会将 Warning、Error、Fatal 和 Silent 日志输出。 （注：在 macOS 下需要给 :W 这样以 作为 tag 的参数加双引号，如 adb logcat “:W”，不然会报错 no matches found: :W。） 按 tag 和级别过滤日志 可以由多个 [:priority] 组成。 比如，命令：1adb logcat ActivityManager:I MyApp:D *:S 表示输出 tag ActivityManager 的 Info 以上级别日志，输出 tag MyApp 的 Debug 以上级别日志，及其它 tag 的 Silent 级别日志（即屏蔽其它 tag 日志）。 清空日志1adb logcat -c 内核日志命令：1adb shell dmesg 输出示例： [14201.684016] PM: noirq resume of devices complete after 0.982 msecs [14201.685525] PM: early resume of devices complete after 0.838 msecs [14201.753642] PM: resume of devices complete after 68.106 msecs [14201.755954] Restarting tasks … done. [14201.771229] PM: suspend exit 2016-08-28 13:31:32.679217193 UTC [14201.872373] PM: suspend entry 2016-08-28 13:31:32.780363596 UTC [14201.872498] PM: Syncing filesystems … done.中括号里的 [14201.684016] 代表内核开始启动后的时间，单位为秒。 通过内核日志我们可以做一些事情，比如衡量内核启动时间，在系统启动完毕后的内核日志里找到 Freeing init memory 那一行前面的时间就是。 屏幕截图命令：1adb shell screencap -p /sdcard/sc.png 然后将 png 文件导出到电脑：1adb pull /sdcard/sc.png 可以使用 adb shell screencap -h 查看 screencap 命令的帮助信息，下面是两个有意义的参数及含义： 参数 含义-p 指定保存文件为 png 格式-d display-id 指定截图的显示屏编号（有多显示屏的情况下）实测如果指定文件名以 .png 结尾时可以省略 -p 参数；否则需要使用 -p 参数。如果不指定文件名，截图文件的内容将直接输出到 stdout。 直接一行命令截图并保存到电脑的方法： Linux 和 Windows1adb shell screencap -p | sed \"s/\\r$//\" &gt; sc.png Mac OS X1adb shell screencap -p | gsed \"s/\\r$//\" &gt; sc.png 这个方法需要用到 gnu sed 命令，在 Linux 下直接就有，在 Windows 下 Git 安装目录的 bin 文件夹下也有。如果确实找不到该命令，可以下载 sed for Windows 并将 sed.exe 所在文件夹添加到 PATH 环境变量里。 而在 Mac 下使用系统自带的 sed 命令会报错：1sed: RE error: illegal byte sequence 需要安装 gnu-sed，然后使用 gsed 命令：1brew install gnu-sed 录制屏幕录制屏幕以 mp4 格式保存到 /sdcard：1adb shell screenrecord /sdcard/filename.mp4 需要停止时按 Ctrl-C，默认录制时间和最长录制时间都是 180 秒。 如果需要导出到电脑：1adb pull /sdcard/filename.mp4 可以使用 adb shell screenrecord –help 查看 screenrecord 命令的帮助信息，下面是常见参数及含义： 参数 含义–size WIDTHxHEIGHT 视频的尺寸，比如 1280x720，默认是屏幕分辨率。–bit-rate RATE 视频的比特率，默认是 4Mbps。–time-limit TIME 录制时长，单位秒。–verbose 输出更多信息。 重新挂载 system 分区为可写注：需要 root 权限。 /system 分区默认挂载为只读，但有些操作比如给 Android 系统添加命令、删除自带应用等需要对 /system 进行写操作，所以需要重新挂载它为可读写。 步骤： 进入 shell 并切换到 root 用户权限。 命令：12adb shellsu 查看当前分区挂载情况。 命令：1mount 输出示例：12345678910111213141516171819202122232425rootfs / rootfs ro,relatime 0 0tmpfs /dev tmpfs rw,seclabel,nosuid,relatime,mode=755 0 0devpts /dev/pts devpts rw,seclabel,relatime,mode=600 0 0proc /proc proc rw,relatime 0 0sysfs /sys sysfs rw,seclabel,relatime 0 0selinuxfs /sys/fs/selinux selinuxfs rw,relatime 0 0debugfs /sys/kernel/debug debugfs rw,relatime 0 0none /var tmpfs rw,seclabel,relatime,mode=770,gid=1000 0 0none /acct cgroup rw,relatime,cpuacct 0 0none /sys/fs/cgroup tmpfs rw,seclabel,relatime,mode=750,gid=1000 0 0none /sys/fs/cgroup/memory cgroup rw,relatime,memory 0 0tmpfs /mnt/asec tmpfs rw,seclabel,relatime,mode=755,gid=1000 0 0tmpfs /mnt/obb tmpfs rw,seclabel,relatime,mode=755,gid=1000 0 0none /dev/memcg cgroup rw,relatime,memory 0 0none /dev/cpuctl cgroup rw,relatime,cpu 0 0none /sys/fs/cgroup tmpfs rw,seclabel,relatime,mode=750,gid=1000 0 0none /sys/fs/cgroup/memory cgroup rw,relatime,memory 0 0none /sys/fs/cgroup/freezer cgroup rw,relatime,freezer 0 0/dev/block/platform/msm_sdcc.1/by-name/system /system ext4 ro,seclabel,relatime,data=ordered 0 0/dev/block/platform/msm_sdcc.1/by-name/userdata /data ext4 rw,seclabel,nosuid,nodev,relatime,noauto_da_alloc,data=ordered 0 0/dev/block/platform/msm_sdcc.1/by-name/cache /cache ext4 rw,seclabel,nosuid,nodev,relatime,data=ordered 0 0/dev/block/platform/msm_sdcc.1/by-name/persist /persist ext4 rw,seclabel,nosuid,nodev,relatime,data=ordered 0 0/dev/block/platform/msm_sdcc.1/by-name/modem /firmware vfat ro,context=u:object_r:firmware_file:s0,relatime,uid=1000,gid=1000,fmask=0337,dmask=0227,codepage=cp437,iocharset=iso8859-1,shortname=lower,errors=remount-ro 0 0/dev/fuse /mnt/shell/emulated fuse rw,nosuid,nodev,relatime,user_id=1023,group_id=1023,default_permissions,allow_other 0 0/dev/fuse /mnt/shell/emulated/0 fuse rw,nosuid,nodev,relatime,user_id=1023,group_id=1023,default_permissions,allow_other 0 0 找到其中我们关注的带 /system 的那一行：1/dev/block/platform/msm_sdcc.1/by-name/system /system ext4 ro,seclabel,relatime,data=ordered 0 0 重新挂载。 命令：1mount -o remount,rw -t yaffs2 /dev/block/platform/msm_sdcc.1/by-name/system /system 这里的 /dev/block/platform/msm_sdcc.1/by-name/system 就是我们从上一步的输出里得到的文件路径。 如果输出没有提示错误的话，操作就成功了，可以对 /system 下的文件为所欲为了。 重启手机命令：1adb reboot 检测设备是否已 root命令：12adb shellsu 此时命令行提示符是 $ 则表示没有 root 权限，是 # 则表示已 root。 使用 Monkey 进行压力测试Monkey 可以生成伪随机用户事件来模拟单击、触摸、手势等操作，可以对正在开发中的程序进行随机压力测试。 简单用法：1adb shell monkey -p &lt;packagename&gt; -v 500 表示向 指定的应用程序发送 500 个伪随机事件。 Monkey 的详细用法参考 官方文档。 查看进程命令：1adb shell ps 输出示例：12345678USER PID PPID VSIZE RSS WCHAN PC NAMEroot 1 0 8904 788 ffffffff 00000000 S /initroot 2 0 0 0 ffffffff 00000000 S kthreadd...u0_a71 7779 5926 1538748 48896 ffffffff 00000000 S com.sohu.inputmethod.sogou:classicu0_a58 7963 5926 1561916 59568 ffffffff 00000000 S org.mazhuang.boottimemeasure...shell 8750 217 10640 740 00000000 b6f28340 R ps 各列含义： 列名 含义USER 所属用户PID 进程 IDPPID 父进程 IDNAME 进程名 查看实时资源占用情况命令：1adb shell top 输出示例：1234567891011121314User 0%, System 6%, IOW 0%, IRQ 0%User 3 + Nice 0 + Sys 21 + Idle 280 + IOW 0 + IRQ 0 + SIRQ 3 = 307 PID PR CPU% S #THR VSS RSS PCY UID Name 8763 0 3% R 1 10640K 1064K fg shell top 131 0 3% S 1 0K 0K fg root dhd_dpc 6144 0 0% S 115 1682004K 115916K fg system system_server 132 0 0% S 1 0K 0K fg root dhd_rxf 1731 0 0% S 6 20288K 788K fg root /system/bin/mpdecision 217 0 0% S 6 18008K 356K fg shell /sbin/adbd ... 7779 2 0% S 19 1538748K 48896K bg u0_a71 com.sohu.inputmethod.sogou:classic 7963 0 0% S 18 1561916K 59568K fg u0_a58 org.mazhuang.boottimemeasure ... 各列含义： 列名 含义PID 进程 IDPR 优先级CPU% 当前瞬间占用 CPU 百分比S 进程状态（R=运行，S=睡眠，T=跟踪/停止，Z=僵尸进程） #THR 线程数VSS Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）RSS Resident Set Size 实际使用物理内存（包含共享库占用的内存）PCY 调度策略优先级，SP_BACKGROUND/SPFOREGROUNDUID 进程所有者的用户 IDNAME 进程名top 命令还支持一些命令行参数，详细用法如下： Usage: top [ -m max_procs ] [ -n iterations ] [ -d delay ] [ -s sort_column ] [ -t ] [ -h ] -m num 最多显示多少个进程 -n num 刷新多少次后退出 -d num 刷新时间间隔（单位秒，默认值 5） -s col 按某列排序（可用 col 值：cpu, vss, rss, thr） -t 显示线程信息 -h 显示帮助文档","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"APK Signature Scheme v2","date":"2017-03-04T05:30:06.000Z","path":"2017/03/04/Program/Android/android_signature_v1_and_v2/","text":"Android 7.0 introduces APK Signature Scheme v2, a new app-signing scheme that offers faster app install times and more protection against unauthorized alterations to APK files. By default, Android Studio 2.2 and the Android Plugin for Gradle 2.2 sign your app using both APK Signature Scheme v2 and the traditional signing scheme, which uses JAR signing. Although we recommend applying APK Signature Scheme v2 to your app, this new scheme is not mandatory. If your app doesn’t build properly when using APK Signature Scheme v2, you can disable the new scheme. The disabling process causes Android Studio 2.2 and the Android Plugin for Gradle 2.2 to sign your app using only the traditional signing scheme. To sign with only the traditional scheme, open the module-level build.gradle file, then add the line v2SigningEnabled false to your release signing configuration: 12345678910111213android &#123; ... defaultConfig &#123; ... &#125; signingConfigs &#123; release &#123; storeFile file(\"myreleasekey.keystore\") storePassword \"password\" keyAlias \"MyReleaseKey\" keyPassword \"password\" v2SigningEnabled false &#125; &#125; &#125; Caution: If you sign your app using APK Signature Scheme v2 and make further changes to the app, the app’s signature is invalidated. For this reason, use tools such as zipalign before signing your app using APK Signature Scheme v2, not after. For more information, read the Android Studio documents that describe how to sign an app in Android Studio and how to configure the build file for signing apps using the Android Plugin for Gradle. APK Signature Scheme v2 背景知识老司机要开车了，你准备好了吗？Android Studio 2.2 最近发布了许多新增功能和改进功能（详情请戳这里）对于Android开发者来说，我想大家应该都知道，在 Android 7.0 Nougat 中引入了全新的 APK Signature Scheme v2，所以我大致总结一下，我们开发者需要了解的新的打包的方式和签名步骤。 基本信息用于验证 APK 完整性的 APK 加密签名现在直接位于 ZIP Central Directory 前面。在 v1 中，签名通过整个 APK 文件的二进制内容进行计算并验证，而不是通过归档中每个文件的已解压文件内容。可同时通过 v1 和 v2 签名对 APK 进行签署，以使其仍能向后兼容以前的 Android 版本。 原因为什么谷歌要做这个事情呢？第一点毋庸置疑，肯定是处于安全性的考虑，之前的校验方式开发者可以在打包之后对apk做很多处理，第二为了性能考虑，安装校验的时候不需要再解压缩校验，从而提升安装速度（说句玩笑话，个人感觉没什么鸟用，也不需要关系） 那么问题来了全新的签名给我们程序员带来的麻烦却很大： 由于在 v1 中仅验证未解压的文件内容，因此，在 APK 签署后可进行许多修改 - 可以移动甚至重新压缩文件。事实上，编译过程中要用到的 zipalign 工具就是这么做的，它用于根据正确的字节限制调整 ZIP 条目，以改进运行时性能。而且我们也可以利用这个东西，在打包之后修改META-INF目录下面的内容，或者修改Zip的注释来实现多渠道的打包，在v1签名中都可以校验通过 v2 签名将验证归档中的所有字节，而不是单个 ZIP 条目，因此，在签署后无法再运行 zipalign。正因如此，现在，在编译过程中，Google将压缩、调整和签署合并成一步完成。 如有任何自定义任务篡改 APK 文件或对其进行后处理（无论以任何方式），那么v2 签名会有作废的风险，从而导致您的 APK 与 Android 7.0 及更高版本不兼容。 解决途径 如果我们选择手动签名（比如使用命令行）那么 Android SDK 中提供了一个名为 apksigner 的新工具，该工具可同时提供 v1 和 v2 APK 签署与验证。请注意，如果您使用 v2 签名，则在运行 apksigner之前，必须先运行 zipalign。 来自 JDK 的 jarsigner 工具与 Android v2 签名不兼容，因此，如果您要保留 v2 签名，您不能用它来重新签署 APK。 如果我们还想使用之前的打包方式，不做修改，那么Google也是为我们提供了配置方法的用来关闭v2签名：12v1SigningEnabled falsev2SigningEnabled false 总结虽然说现在Google有提供方法来关闭v2校验，但是我相信，一旦等到这种方式成熟之后，它会成为一个必需品，毕竟安全第一嘛，我们还是要接纳新事物的，好了，大概就讲这么多，有需要的可以看看。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"RollPlayer","date":"2017-03-03T01:42:06.000Z","path":"2017/03/03/Program/Android/my-favor-music-player/","text":"做自己喜欢又擅长的，同时解决生活中的实际痛点，简单极致、有用有趣，It’s my life. 项目需求功能要求：一个窗口，一个目录，一些自己喜欢的歌曲，随机选择歌曲，支持单曲循环播放，支持歌词显示；应用场景：徒步、登山、坐享时使用。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"如何正确地写出单例模式","date":"2017-03-03T00:31:06.000Z","path":"2017/03/03/Program/Concepts/how-to-write-singe-instance/","text":"Jark’s Blog 单例模式算是设计模式中最容易理解，也是最容易手写代码的模式了吧。但是其中的坑却不少，所以也常作为面试题来考。本文主要对几种单例写法的整理，并分析其优缺点。很多都是一些老生常谈的问题，但如果你不知道如何创建一个线程安全的单例，不知道什么是双检锁，那这篇文章可能会帮助到你。 懒汉式，线程不安全当被问到要实现一个单例模式时，很多人的第一反应是写出如下的代码，包括教科书上也是这样教我们的。1234567891011public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 这段代码简单明了，而且使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例。也就是说在多线程下不能正常工作。 懒汉式，线程安全为了解决上面的问题，最简单的方法是将整个 getInstance() 方法设为同步（synchronized）。123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance;&#125; 虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance() 方法。但是同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。这就引出了双重检验锁。 双重检验锁双重检验锁模式（double checked locking pattern），是一种使用同步块加锁的方法。程序员称其为双重检查锁，因为会有两次检查 instance == null，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的 if，如果在同步块内不进行二次检验的话就会生成多个实例了。12345678910public static Singleton getSingleton() &#123; if (instance == null) &#123; //Single Checked synchronized (Singleton.class) &#123; if (instance == null) &#123; //Double Checked instance = new Singleton(); &#125; &#125; &#125; return instance ;&#125; 这段代码看起来很完美，很可惜，它是有问题。主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 我们只需要将 instance 变量声明成 volatile 就可以了。123456789101112131415public class Singleton &#123; private volatile static Singleton instance; //声明成 volatile private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。 但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。 相信你不会喜欢这种复杂又隐含问题的方式，当然我们有更好的实现线程安全的单例模式的办法。 饿汉式 static final field这种方法非常简单，因为单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。12345678910public class Singleton&#123; //类加载时就初始化 private static final Singleton instance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; 这种写法如果完美的话，就没必要在啰嗦那么多双检锁的问题了。缺点是它不是一种懒加载模式（lazy initialization），单例会在加载类后一开始就被初始化，即使客户端没有调用 getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如 Singleton 实例的创建是依赖参数或者配置文件的，在 getInstance() 之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。 静态内部类 static nested class我比较倾向于使用静态内部类的方法，这种方法也是《Effective Java》上所推荐的。123456789public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 枚举 Enum用枚举写单例实在太简单了！这也是它最大的优点。下面这段代码就是声明枚举实例的通常做法。123public enum EasySingleton&#123; INSTANCE;&#125; 我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。但是还是很少看到有人这样写，可能是因为不太熟悉吧。 总结一般来说，单例模式有五种写法：懒汉、饿汉、双重检验锁、静态内部类、枚举。上述所说都是线程安全的实现，文章开头给出的第一种方法不算正确的写法。 就我个人而言，一般情况下直接使用饿汉式就好了，如果明确要求要懒加载（lazy initialization）会倾向于使用静态内部类，如果涉及到反序列化创建对象时会试着使用枚举的方式来实现单例。 Read MoreDouble Checked Locking on Singleton Class in JavaWhy Enum Singleton are better in JavaHow to create thread safe Singleton in Java10 Singleton Pattern Interview questions in Java","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"AndroidStudio技巧","date":"2017-03-03T00:31:06.000Z","path":"2017/03/03/Program/Android/tips-of-androidstudio/","text":"提高效率的 Android Studio 技巧汇总 工欲善其事必先利其器，磨刀不误砍柴工 Enter和Tab在代码提示时的区别 看图! Bookmarks!如其名，书签。帮助快速回到指定的位置，实际使用中简直爽得不行。 f11 将当前位置添加到书签中或者从书签中移除。 shift+f11 显示有哪些书签。 ctrl+/ 注释一行代码ctrl+shift+/注释代码块ctrl+b查看声明ctrl+f查找ctrl+r替换ctrl+shif+f 全路径查找ctrl+shift+r 全路径替换 ctrl+number-minus 代码折叠ctrl+number-plus代码展开ctrl+shift+minus折叠窗口内所有代码ctrl+shift+plus展开窗口内所有代码 ctrl+o复写方法ctrl+alt+o清除无效包引用 ctrl+alt+l 格式化代码 ctrl + h显示大纲 The File Structure Popupctrl+f12 此快捷键可以调出当前文件的大纲，并通过模糊匹配快速跳转至指定的方法。勾选上“show anonymous classes”后其功能相当于Eclipse中的ctrl+o Hide All Panelsctrl + shit +F12 关闭或者恢复其他窗口。在编写代码的时候非常方便的全屏编辑框，可以更加专心的coding… Parameter Infoctrl+p 在调用一些方法的时候免不了会忘记或者不知道此方法需要哪些参数。ctrl+p可以显示出此方法需要的参数。必备技能之一。 Lines Editctrl+y删除行 Find Actionsctrl+shift+a 对于没有设置快捷键或者忘记快捷键的菜单或者动作（Action），可能通过输入其名字快速调用。神技！！！ 例如想要编译，只需要输入”release”，则列表框中就会出现”assembleRelease”选项，选择就可以进行编译。 分析堆栈信息 Find Actions(ctrl+shift+a)输入 analyze stacktrace” 即可查看堆栈信息。 分析某个值的来源Find Actions(ctrl+shift+a)输入”Analyze Data Flow to Here”，可以查看某个变量某个参数其值是如何一路赋值过来的。对于分析代码非常有用。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"开源软件及国内发展现状","date":"2017-03-02T01:33:06.000Z","path":"2017/03/02/Program/Concepts/history-of-open-source/","text":"作者：魏永明（飞漫软件CEO）。本文经章文嵩、陈渝审阅。 1 开源是大势所趋随着计算机技术的发展，尤其是互联网技术和相关企业的兴起，开源软件在操作系统、编译工具链、数据库、WEB服务器、移动操作系统等各个方面已经成为主流。而且许多企业利用开源软件形成了独特的商业模式。比如谷歌的 Android 操作系统，从 2007 年开源发布第一个版本起，到今天已经发展到 4.1 版本，占据了智能手机操作系统一半以上的市场份额，谷歌也通过 Android 操作系统在移动互联网这一新兴行业中占据了领先和主导地位。再比如在服务器端广泛使用的关系型数据库 MySQL，在以开源软件和商业许可并行的模式下，得到了快速发展，并在 2008 年作价 10 亿美金由 Sun 收购（后者又在 2009 年被 Oracle 公司以 74 亿美金的高价收购）。相反，以前一直和开源软件做斗争的微软公司，却因为无法快速推出适应市场的 Windows Phone 操作系统，在移动互联网竞争中处于下风。为顺应潮流，微软也开始拥抱开源，比如向Samba项目贡献代码，放弃自己研发多年的大数据项目而选择Hadoop为其大数据的核心等。 显然，纵观 IT 行业这二十多年的发展，开源软件从黑客的理想之国，已经形成了一股推进计算机及相关行业不停进步的巨大力量。很多人可能尚未意识到，我们使用的电脑中运行有开源软件，手机中运行有开源软件，家里的电视也运行有开源软件，甚至小小的数码产品（如电子相框）中也运行有开源软件，尤其是互联网服务器端软件，几乎全部是开源软件。毫不夸张地说，开源软件已经渗透到了我们日常生活的方方面面。那么，开源软件到底什么，开源软件尤其是国内的开源软件及社区的现状如何，发展面临哪些困难和问题？ 2 开源软件的基本概念在讲述国内开源软件的发展情况之前，我们先就开源软件的一些基本概念做一些普及。 2.1 为什么会有开源软件？广义上讲，开源软件指所有公开源代码的软件，包括某些商业软件也可能是开源的。但我们通常所说的开源软件，是狭义上的，指任何人可以通过极低的成本（如仅仅访问互联网而无需其他额外费用）获得该软件源代码的软件，也就是其源代码向公众开放。和狭义上的开源软件相对应的，就是那些不向公众公开源代码的软件，通常就是商业软件。 实质上，在计算机出现的最初年代，几乎所有的软件都是开源的。那时的计算机企业，主要是以销售硬件产品为主，软件几乎都是附送的，加上那时的软件规模都不大，以源代码形式提供给用户还可以缓解一定的技术支持压力——有问题由用户自己修改解决。所以，最初的软件几乎都是以开源的方式提供的。因此，对着迷于计算机编程的工程师来讲，获得软件的源代码几乎是天经地义的事情。这样，当以微软为代表的企业开始实践纯软件产品的商业模式（核心思想是提供二进制可执行程序的使用许可，而不提供源代码），就引起了许多计算机编程爱好者的不满：给我一堆二进制程序，我如何才能按我自己的想法改进程序？在这种背景下，真正意义上的开源软件就自然而然地产生了。 2.2 开源软件的发展历程开源软件的发展，和互联网的发展密不可分。真正有规模的开源软件，应该是从上个世纪 90 年代开始进入公众视线，也就是互联网开始兴起的年代。我们大致可以将开源软件的发展分为如下三个阶段： 萌芽阶段（上世纪九十年代之前）。这个阶段主要以个人和大学为主，因为发布条件受限，大多数开源软件无法得到有效传播，而仅仅流传于互相熟悉的程序员和老师、学生之间。这个阶段的典型开源软件为 BSD 操作系统。 以非盈利组织为主的阶段。这个阶段应从上个世纪九十年代算起，说起这个阶段，我们不得不提到 Richard Stallman 发起的自由软件基金会，还有 Apache 基金会等。前者发起的 GNU 项目（1983 年发起，九十年代后随 Linux普及），成就了 Linux 操作系统；后者维护的 Apache WEB服务器，在互联网上几乎占据了统治地位。 以大型IT企业为主的阶段。这个阶段出现于 2005 年之后，以谷歌为代表的大型互联网企业，开始以各种方式发布开源软件，最为著名的是 Chrome 浏览器以及 Android 操作系统；当然还有 Intel、Nokia 等企业主导的 Moblin、MeeGo 等基于 Linux 的智能手机操作系统。 2.3 开源软件许可证笔者看来，软件作者选择向公众开放源代码，其理由无外乎如下三种： 第一，那些认为所有软件都应该以源代码方式发布的。如 Richard Stallman，他认为所有的软件都应该是开放源代码的，甚至为了建造一个理想中的全开源软件世界，创立了自由软件基金会，发明了 GPL 许可证，发起了 GNU 项目。 第二，通过开源软件展示自己的软件设计、算法和编码水平，并期望获得他人认可的。大部分小型软件或者程序的作者，或者由大学主持和维护的开源软件，出于这种目的向公众开放源代码。 第三，通过开源软件谋求获得广泛推广，并通过提供增值的产品或者服务来获得商业收益的。这通常是商业企业选择开源软件的原因。如 FireFox、MySQL、Android、WebKit 等属于这种情形。 为了达到上述三种不同的目的，人们在现有软件著作权的法律框架内，发明了多种用于开源软件的许可证。这些许可证从法律上帮助对开源软件有不同诉求的软件作者，获得自己想要的结果。要想具体了解这些许可证的实质内容，我们首先需要更加深入地了解软件著作权。 许多开发者对软件著作权只有一个初步的、模糊的认知。我们经常会在各种软件的启动画面或者关于对话框中刚看到类似“版权所有 (C) 2012 某公司；保留所有权利”的用语。这说明，软件著作权包含了很多权利，所以才有“保留所有权利”这样的说法。具体而言，软件著作权大致包括如下几个权利： 署名权。就是署上自己大名的权利，向人们说明这是我的作品。这里的“我”，可能是个人，也可能是法人单位。 修改权。就是是否可以修改软件，比如翻译软件界面中的文字。对非开源软件，就是是否允许你反编译软件并修改的权利。对开源软件来讲，就是修改其中可能存在的缺陷，或对一些代码进行优化、重构等等。 复制权。就是将软件进行复制的权利。和图书类比，就是你能不能抄写和/或复印图书。 发布权。就是将软件副本交给他人的权利，不管是收费的还是不收费的。 对商业软件而言，这些权利都被保留，意思是什么呢？就是说，你不能修改，也不能复制，还不能随便发布给别人。那用户能做什么，唯一的就是安装和使用这个软件了。当然，大部分商业软件都附带有一个《最终用户许可协议》，其中告诉了你能做什么，不能做什么。比如，你可以因为备份的原因复制这个软件。另外，还定义了很多免责条款，比如，如果 90 天内软件的存储介质损坏，可以免费替换；如果因为使用本软件导致数据丢失或损坏，概不负责之类的。 对开源软件而言，因为任何人可以几乎无成本获得软件的源代码或者最终程序，用户使用这个软件要是有了问题，都去询问作者，那作者就吃不消了。所以，开源软件也通常使用某个特定的许可证来约定作者以及使用者所承担的权利和义务。 自由软件基金会制定的 GPL 许可证，应该是开源软件使用的各种许可证中最为严格的。为了区别于其他开源软件，Richard Stallman 将使用 GPL 许可证的开源软件称为自由软件。GPL 许可证的核心内容是： 你可以随意复制和发布软件。如果以二进制方式发布软件，则必须能够让获得二进制版本的人，以不付出额外成本的方式获得其源代码。你可以随意修改源代码。一旦要发布修改后的软件，必须同时发布修改后的源代码。也就是说，修改版本也必须以 GPL 许可证发布。这就是 GPL 许可证被称为病毒许可证的一个最重要原因。如果 GPL 软件作为其他软件的一部分使用（后者称为 GPL 软件的衍生作品），不论是静态链接还是动态链接，衍生作品也要遵循 GPL 许可证。这是 GPL 许可证被称为病毒许可证的另外一个重要原因。无任何担保。就是说，使用 GPL 软件，出了问题不要找原作者，你需要自己负责。 Richard Stallman 希望通过这样严格的 GPL 许可证，来建立一个所有软件均遵循 GPL 的理想软件世界。除了 Richard Stallman 所倡导的理想王国之外，还有许多个人和组织，以不同于自由软件的方式来发展开源软件。这些开源软件所使用的许可证相比 GPL 要宽松一些，或者很宽松。这些开源软件作者，通常属于本节前面所讲的第二、第三种人，所以他们使用的许可证有如下共同点： &gt;免担保，责任由使用者自负。随便复制和发布。不限制商用。 这些许可证的不同点在于： Apache 许可证：如有修改，必须保留已有的版权声明，且必须包含新的版权声明。通俗理解，就是要 保留原作者信息，也就是署名权。 BSD 许可证：不允许在衍生软件作品中提原作者的名字，其理由是，因为你的修改可能污染原有代码，破坏原作品的品质。 MIT 许可证：在衍生软件作品中，必须提原作者的名字；其理由是，原有代码作者应得到充分尊重。 Mozilla 许可证（MPL）：就原有软件所做修改，必须可以以各种可能的方式发布其源代码（包括使用 GPL 许可证），且应该有修改说明。 除了上述许可证之外，还有一个广泛使用的 LGPL 许可证。该许可证最初是针对函数库专门制定的。为了避免类似 C 基础库这样的软件因为采用 GPL 许可证而让使用它的软件（衍生作品）成为 GPL 软件，从而定义了 LGPL 许可证。试想，如果 C 基础库也采用 GPL 许可证，那就失去了它本身存在的实际价值，因为其他任何非 GPL 软件都不能使用采用 GPL 的 C 基础库。所以，LGPL 定义，当 C 基础库这样的软件以动态链接的形式由其他软件使用时，这些软件就可以不遵守 GPL 许可证，甚至可以是商业软件。 另外，本某种角度看，LGPL 和 MPL 本质上是一样的。 当然，除了上面的各种许可证，还有的开源软件作者根本不关心保留什么权利，或者对其作品做什么样的约束，相反，这些作者开源其软件，就是为了“有用”，任何人拿这种软件做什么，对原作者来讲，都是无所谓的。这种软件亦称为“礼物软件”，相当于作者放弃了有关软件著作权的所有权利，也就是所谓置于“公共领域（public domain）”当中——随你怎么用。 2.4 为什么开源软件会得到快速发展并广泛应用？很多人不理解，既然作者这么大方地将源代码都公开了，只是为了“有用”，且不提供任何“担保”，看起来原作者是无法直接获利的，那为什么没有直接的利益驱动，开源软件却能够得到这么快速的发展和广泛应用呢？ 笔者初探其原因，大致有四： 开源软件虽说不提供任何担保，但既然原作者愿意公开源代码，说明作者对代码的质量还是非常有信心的。实际上，开源软件的作者通常都是编码高手（俗称“黑客”），其质量甚至超过某些商业软件。 开源软件因为其免费特征，能够得到大量用户的使用和验证，通过形成和用户（往往也是编码高手）之间的互动和交流，能够以最快的速度修复可能的缺陷，改善软件设计。Linux 内核的发展就形成了一个以全世界内核高手为主的松散社区，通过快速迭代开发，加上其免费特征，迅速占据了原先由商业 UNIX 系统控制的服务器操作系统领域。 因为任何人都可以得到其源代码，所以很多用户就可以自行修改其源代码，以满足自己的一些特别需求。 因为开源软件的涉及面非常广，利用已有的各种成熟开源软件，任何具有一定实力的组织，均可在较短时间内形成一个基本成熟的软件平台，进而可和已有的商业软件平台进行竞争。谷歌的 Android 系统属于此种情况的典型。 所以，尽管开源软件的发展历程并不是一帆风顺的，但基于以上原因，开源软件显现出了其强大的生命力。各种基于开源软件的成功商业模式，也为开源软件的发展注入了加速剂。有关围绕开源软件的成功商业模式，可见本文第 4 章。 3 国内开源软件的发展及社区现状3.1 国内开源软件的发展简史国内开源软件的发展大致始于 1997 年前后。那时，中国第一个（局部）互联网（CERNET）刚刚建立不久，1995 年在清华大学建立的著名水木清华 BBS 就是开源软件。自那之后，Linux 内核以及 GNU 项目中的成百上千个开源软件突然展现在国人的面前。在这之前，国内软件开发者，几乎没有人会认为获得程序的源代码是天经地义的事情（写到此处，笔者再次感叹文化和背景的不同所带来的认知差别）。但随着带有源代码的 Linux 操作系统随着互联网以及廉价光盘的广泛传播，当你能看到这些优秀的软件是如何设计和编写出来的的时候，我相信，大部分程序开发者都会和笔者一样——那心情岂止是“激动”两个字可以形容的？ 在这样的背景下，中国也出现了一些开源软件。最初由国人开发的开源软件，主要解决的是 Linux 系统的汉化问题，流传最为广泛的应该是可以显示和输入中文的伪终端应用程序 CCE。在 1998 年之后的两三年内，出现了如下三个开源软件： 章文嵩博士开发的 LVS（Linux Virtual Server），后来被 Linux 内核收录，成为使用 Linux 操作系统搭建集群服务器的重要核心软件组件。 当时的清华大学博士生苏哲开发的 Smart Boot Manager，是一种引导管理器，类似现在流行的 GRUB，主要解决引导多种操作系统的问题。苏哲后来主持开发的 SCIM 系统，被各种流行的 Linux 发行版收录，成为了 Linux 操作系统上提供多语种输入法支持的标准框架。 笔者开发的 MiniGUI，后来由笔者创立的北京飞漫软件技术有限公司继续维护和发展，在功能手机、数码相框、工业控制系统和工业仪表中得到了广泛应用。 上述三个开源软件，成为中国开源软件早期的代表作，在国际上具有较强的影响力，很多台湾同行也知道这些软件，提起来往往是赞不绝口。 在此之后，国内开源软件的发展长期处于停滞状态，这和 2000 年左右 DotCOM 泡沫的破裂有一定的关系。DotCOM 泡沫的破裂，让许多梦想通过开源软件来创造商业奇迹的 Linux 发行版厂商很是受伤。比如，笔者曾经供职过的蓝点软件，在 NASDAQ OTCBB 板借壳上市，半年之内股价从 20 多美金跌到 0.2 美金，后于 2001 年贱卖。RedHat 等知名 Linux 发行版厂商也深受其害，另外一些抗跌能力不强的从事开源软件相关业务的企业更是一蹶不振，甚至关门大吉。 DotCOM 泡沫的破裂，给很多支持开源软件的理想主义者浇了一桶凉水，开源软件的商业化发展步伐减缓，从而影响了国内开源软件的发展。2000年前后几年，以北京、武汉等地的 LUG（Linux User Group）为代表的各类开源软件组织非常活跃，而从 2003 年开始，逐渐降温甚至消失。 但是，国际上深信理想主义的黑客文化并没有因为 Linux 发行版厂商的商业化遇阻而停止发展，Linux 内核、GNU 项目、GNOME 和 KDE 等等软件继续向前发展。同时，2005 年后，又出现了如下在当前 IT 领域有着举足轻重影响力的几款开源软件： Mozilla 基金会（以 Mozilla 基金会下属 Mozilla 公司的成立为准）以及 FireFox 浏览器。Mozilla 公司通过 FireFox 浏览器获得了来自谷歌等公司的大量合作收入，从而实践了没有赞助也能自负盈亏的商业模式。 WebKit 浏览器引擎。WebKit 浏览器是苹果 Safari 浏览器、谷歌 Chrome 浏览器使用的浏览器核心引擎。WebKit 其实是由苹果公司发起的开源项目，在早期 KDE 系统的 KHTML 和 KJS 两个子系统基础上发展而来。 谷歌的 Android 操作系统。Android 操作系统的上层虽然是虚拟机和 Java 应用，但底层却使用了大量开源软件，如 Linux 内核、SQLite 内嵌式数据库、FreeType 矢量字体渲染库等等。 显然，从 2005 年起，开源软件的发展从一个低谷重新引来了发展的高潮，而这次，与前述的第三个阶段吻合，即以大型 IT 企业为主导进行发展。在此期间，国内也出现了为数不多的一些开源软件项目，其中以清华大学陈渝副教授主持的 SkyEye 最具代表性。该项目旨在提供一个面向嵌入式软件开发和调试的 ARM 或其他架构的纯软件仿真器（虚拟机）。该项目持续活跃长达七年时间，吸引了许多来自海外的高手参与，是为数不多具有国际影响力，且充分体现了国际化协作、分享的开源软件项目。 与此同时，RedHat 以及国内的红旗等公司，也开始通过提供针对服务器的 Linux 定制版本而获得可观收入，之后，Ubuntu 这一在桌面系统上广泛应用的 Linux 发行版也实践了其成功的商业模式，占据了绝大部分 Linux 桌面发行版的市场份额。 2008年金融危机后，传统企业为了降低IT的总拥有成本逐步使用Linux和开源软件，尤其是金融企业，世界上主要证券交易所如纽约交易所、NASDAQ、东京交易所、伦敦交易所等先后迁移到Linux。这标志着开源软件进入了不可逆转的发展通道。 从 2005 年开始，国内的开源软件也开始进入上面所说的由大型企业主导的第三个阶段，参与开源项目的企业当中，最为活跃的是淘宝，接下来是新浪、百度、腾讯和华为等。同时，随着“开源中国”等社区的兴起，个人主持或者参与的开源软件逐渐多了起来。根据“开源中国”收录的开源软件，当前已经有一千多个由国人开发或者主持的开源软件。这和十年前相比，已经有了非常大的进步。有兴趣的读者可访问 http://www.oschina.net 了解。其中值得一提的开源软件有： TFS。TFS是一款由淘宝开发的分布式对象存储系统，于2010年9月开源，在淘宝它存储了几百亿张图片和交易快照。新浪微博已在生产系统中使用TFS作图片等对象存储。淘宝承诺发布的开源版本与自身使用的版本保持高度一致，并同步更新，这为国内开源软件的发展起到了积极的推动作用，TFS已经成为国内企业利用开源方式形成核心竞争力的典范。 TAIR。TAIR 是一个高性能、可扩展、高可靠的分布式key/value存储系统，淘宝在2010年6月开源。在淘宝约有600台TAIR服务器广泛应用在Web服务器和数据库中间作对象缓存。国内的豆丁网等公司已使用TAIR。 OceanBase。OceanBase是一个高性能海量数据库系统，由淘宝开发，于 2011 年 5 月开源。淘宝在其收藏夹等多项功能中使用该数据库，已经历实际应用的检验。 RT-Thread。这是一个由国人主持开发的开源实时操作系统，曾获得“第六届中日韩开源软件竞赛”的技术优胜奖（其他两个技术优胜奖获得者为淘宝OceanBase 和红旗Qomo Linux）。RT-Thread 目前也获得了诸多商业应用。 Linux Deepin。这是近几年发展起来的面向桌面的中文 Linux 发行版，由一群来自武汉的 Linux 高手发起并维护。 ucore：2010 年暑假开始，陈渝博士组织清华大学学生开展教学用开源操作系统ucore的设计与实现，并直接用于清华大学的操作系统课程，学生可参考实验文档和ucore源码通过实践逐步深入掌握操作系统。这相对国内操作系统旧有的教学方法有较大改变，获得了国内外操作系统教学领域专家的认可，并将在教育部的支持下进行更大范围内的推广。 3.2 国内开源软件的特点和问题但国内开源软件也存在很多问题，如缺乏重量级软件，缺乏持续维护和更新，质量一般，用户不多等等。另外，如开源中国创始人所言，国人所开发的这些开源软件，和国际主流开源软件脱节严重，绝大多数的状态是单打独斗。 比如淘宝主导或参与的开源软件，大多数和互联网服务器后台、云计算相关，这些项目的主要用户是淘宝自己。因为门户之见，这些软件很难被其他的互联网企业所使用，大家不停地“造轮子”而忽视了开源软件发展必须具备的“共享”、“协作”之精神。当然，这种情况正在改变，比如上面提到的淘宝 TFS 系统已被其他互联网企业使用，ucore 项目也得到了诸多国内、国外大学积极响应和支持。 笔者希望国内的开源软件作者能够和国际主流的开源软件步伐保持一致，摒弃门户之见，要么加入国际化的开源软件，要么将自己主持的开源软件逐步国际化。这样，我们的开源软件才能得到源源不断的前进动力，也才能在国际化舞台上扮演更加重要的角色。 3.3 新的力量但不论如何，国内大型 IT 企业参与开源软件本身就是一个良好的开端，将为中国开源软件的发展起到非常大的促进作用。 与此同时，各种开源社区活动也越来越活跃，比如具有政府背景的“开源软件高峰论坛”和草根性质的“我们的开源软件”巡回展演等。在最近的“我们的开源软件”巡回展演中，参与介绍的开源软件多达几十种，参会人员众多，而这一切都是社区成员通过“微博”等方式发起和组织的。 这表明，开源软件即将在国内引起新一轮的发展浪潮。 4 开源我的软件？在高物价、高房价的今天，大部分人对此问题的第一反应是：“我就一刚解决温饱的码农，我开源，谁养我？”这问题，和我们在十年前推广开源软件理念时遇到的问题几乎一样。但其实，这话已经大大落后于时代了！我们不仅仅可以通过使用其他人的开源软件赚钱，还可以通过开源自己的软件来赚钱。 4.1 别人靠开源软件如何赚钱？在证明上述论点之前，我们先看看别人是如何利用开源软件赚钱的。靠开源软件赚钱的方式（经过验证的）无外乎有如下几种： 双许可证模式。即在采取严格的开源软件许可证的同时（通常选择 GPL），给商业用户提供非 GPL 许可方式。这本质上是一种贩卖软件许可的行为，但开源软件带给开发者一个很大的好处，即传播迅速，快速迭代。笔者主持的 MiniGUI 项目就采用这种模式，在过去的五年当中，获得了几千万元的软件许可收费。当然，使用这个模式最成功的当属MySQL。 基础软件采用宽松许可证，同时向基础软件的商业用户贩卖增值服务或者增强组件、开发工具等的许可。 这种模式可用于类似 RT-Thread 这类的基础性软件上，RT-Thread 本身可以是开源且可无偿商用的，但其上的各种增值组件，如网络、文件系统、图形系统等，可以是商业软件。国外采用这种模式的以各类 CMS 系统为主。比如 Drupal 和 Concrete 系统，其基本系统是开源且免费的，但其上的许多插件、主题、模版等是收费的。有兴趣的读者可访问 http://www.concrete5.org 网站，其中还有“Marketplace（市场）”频道。 混合模式，既贩卖工具等软件的许可，同时还向用户提供付费服务的模式。 比如 Ubuntu Linux 发行版。 成为平台型软件，并承载自己的互联网业务。这种模式在大型互联网企业中应用广泛。比如谷歌开发并开源 Chrome 浏览器，短短几年抢占了微软的很多市场份额，通过在 Chrome 中默认使用谷歌搜索引擎而获得极大的收入；再比如谷歌开源 Android，一方面为了遏制苹果 iOS 的增长势头，一方面通过预置 Google 搜索而获得了大量来自移动互联网的流量收入。 显然，有了先驱们的成功案例，作为开源软件参与者，不论是企业还是个人，都可能名利双收。 4.2 IT 企业为何要参与开源软件？IT 行业中的企业，即使是销售硬件产品的企业，也在不停地开发各种软件，同时也大量使用各种开源软件。对这类企业，开源自己开发的软件其动力是什么？ 作为企业，参与或者主导一个开源软件，其最为明显的动力应该是上述的第四个商业模式，即打造一个平台型软件。但是，就中国 IT 企业来讲，笔者尚未看到有此种实力，或者此种抱负的企业存在，毕竟，打造一个平台需要长期的投入，一般情况需要五年或者更长的时间。貌似中国没有一个企业有这个耐心来投入五年这么长的时间在一个软件上。 那么为什么企业还要参与到开源软件的开发中？笔者认为，谋不了大利就谋点小利，企业主导或参与开源软件，至少有如下几个好处： 提高企业的美誉度。在利用开源软件的同时，也参与到开源软件当中，企业的美誉度会得到很大的提升。 员工更有激情。因为自己的作品能够公之于众，虽然著作权本质上属于企业，但作为实际的编码者，可以通过开源自己的作品来获得额外的成就感和满足感。这对于稳定开发团队、提高开发人员的积极性会有很大的帮助。 当然，也许过不了几年，中国也能出现实践第四种商业模式的大型 IT 企业，让我们拭目以待吧！ 4.3 个人开发者如何利用开源软件获益？如果你是一名开源软件的开发者，打算利用自己的软件开创一家软件公司，该如何做？第一，我们要确定好自己的商业模式；第二，为自己的开源软件选择恰当的许可证。 如果决定选择双许可证模式，应选择 GPL 这样较为严格的许可证，这是这种商业模式能够成功的基础。当然，选择双许可证会阻碍产品在商业用户中的推广。尤其是对初生的开源软件来讲，显然是一种两难的境地。MiniGUI 之所以可以采用双许可证模式，是因为在成立公司之前和最初的一段时间内，MiniGUI 采取的是 LGPL 许可证，之后在软件足够成熟的时候才改为 GPL 许可证，另外，MiniGUI 用于功能手机等系统中时，因为这种设备一般使用实时操作系统，缺乏应用 LGPL/GPL 许可证的技术条件，所以面向这种设备收取许可费也是天经地义的事情。MySQL 采用双许可证模式得以成功的原因，在于 MySQL AB 公司并不会对仅仅用于WEB服务器的 MySQL 商用行为收费，因为这种情况下，商业用户并不会发布 MySQL 的副本——它只是在服务器上运行而已。 所以，看起来上面提到的第二种、第三种商业模式是最适合个人开发者或者初创公司的商业模式，能够很快的速度推广和迭代软件本身，还能够确保有足够的收入来保证下一步的发展。在这种模式下，应该选择较为宽松的许可证。但大部分开源软件作者，因为并不真正理解开源软件的许可证，所以采取了错误的许可证（指在法律上是错误的）。比如 RT-Thread，一方面采用 GPL V2 许可证，一方面又承诺不会对商业使用收费。这其实没有解决根本的法律问题，也就是，使用 RT-Thread 开发的衍生作品，到底要不要遵循 GPL？这个问题和是否收费没有直接关系。要解决这个问题，其实很简单，采用类似 Apache、BSD 或者 MIT 许可证即可。有读者会问，那为什么不能采用 LGPL 许可证？就 RT-Thread 这样的软件来讲，采用 LGPL 和 GPL 没有本质的区别，因为 RT-Thread 的应用场合下一般不支持函数库的动态链接，这导致失去了适用 LGPL 许可证的技术条件。 那么上面提到的最后一种模式，是否适用于个人开发者或者初创公司？笔者的答案是，这种模式是大公司的玩法，小团队或者小公司是没法做这类事情的。 当然，一家软件公司的成败所涉及因素很多，不仅仅取决于产品和服务等技术因素，也取决于很多其他的因素，比如大的市场环境、政策因素等等。因此，真正拿自己的开源软件经营一家企业的并不多，更多人开发开源软件，还是因为个人兴趣，以及对获得业界尊重和名望的驱使。 但真正能够获得业界尊重的开源软件开发者及其开源软件，其实也并不多。也就是说，要通过开发开源软件获得上面所说的“名”，需要开发者具有较高的开发水平和相关能力。这其中主要的能力有： 好的选题。好的选题应该能够跟得上 IT 领域的前沿技术，最好避免重复造轮子的尴尬境地。 较高水平的软件架构设计能力以及编码能力。既然开放了软件的源代码，那自然希望有人去看，并欣赏这些源代码。所以，拥有较高水平的软件架构设计能力、编码能力，是开源软件能够获得用户青睐的一大条件。较高水平的文档能力。除了编码之外，要让你的开源软件得到大量的用户，你还需要能够编写漂亮的文档，起码要能够撰写很好的安装指导说明文件。 适度的宣传能力。不论好坏，适当宣传自己的开源软件，是获得公众认知的一个良好方式。宣传并不意味着需要花钱，你可以参加各种开源会议，或者在微博上进行宣传，或者通过一些开源社区帮助你来宣传自己的作品。 适度的坚持。好的软件是打磨出来的，如果仅仅靠一时兴趣弄个软件并开源，并没有持续改善，那肯定会半途而废。 当然，除了自己创作一个全新的开源软件之外，要获得上面所说的“名”，还有一个办法是加入到已有的知名开源软件的开发中，尤其是海外的知名开源软件开发中。你可以从帮助他们“汉化”软件开始，然后提交补丁，最后成为主要的开发者。 5 大专院校应该成为开源软件的主力军一个有趣的现象是，很多开源软件其实就是作者在大专院校或者研究机构工作或学习时发起的，比如本文提到的三个国内早期的开源软件项目。甚至某些开源软件由特定的大学主持和维护，如 BSD 操作系统、PostgreSQL 关系数据库、Minix 操作系统等等。 从国际视角看，开源软件的发展离不开一些知名大学的参与，BSD 和 MIT 许可证分别由加州大学伯克利分校和麻省理工学院定义，并由两所大学在其众多开源软件中使用，也被其他开源软件广泛应用。值得一提的是，苹果公司 Mac 操作系统和 iOS 操作系统，均使用了加州大学伯克利分校开发的 BSD 操作系统内核。 从现实情况看，国内在各大公司工作的程序员们，除非因为供职单位支持，否则很难独立发起和维护一个大型的开源软件，但在大专院校和科研机构工作的老师和学生，则有得天独厚的条件（主要是有大量的时间，并可能和科研课题和教学任务相结合）来发起和持续维护一个开源软件项目。清华大学陈渝副教授主持的 SkyEye 和 ucore 两个开源项目就是典型的案例。笔者希望国内有更多的大专院校和科研单位（尤其是教师）能够积极参与到开源软件的发展当中，并成为国内开源软件的主力军。 6 政府和开源社区应该做什么？说实话，笔者并不认为政府在开源软件的发展中应该起主导作用。政府要做的就是制定公平、合理的规则，促进相关法律法规的完善。 从法律上讲，你编写了一个程序，你就自动获得这个程序的软件著作权。在实际操作中，法律要求进行软件著作权的登记，就如同房产证一样，你非要有个政府颁发的证书才能得到法律的承认。我们暂且不论这个做法是否合理，也不论登记收费这事儿，你需要了解的是，在中国，如果你打算遵循 GPL 许可证开源你的软件，你就无法登记著作权！ 当然，众所周知，中国的知识产权保护力度不够，不仅仅阻碍了软件产业的发展，也阻碍了开源软件的发展。 还有，在中国，要注册一家非公益性的 NGO 组织（国外各种软件基金会都是这类组织），是非常非常困难的。这导致截止今天，中国没有任何一家支持开源软件为己任的非营利性基金会组织。 政府所要做的，就是撤销那些违背历史发展大潮的法规和规定，并建立完善的知识产权保护制度，加强对盗版等的打击力度，教育国民尊重他人劳动成果，而不是仅仅停留在口头上。 政府，把上面这些问题解决好了，比直接参与推动开源软件什么的，要强许多倍！比如，加大知识产权的保护力度，一方面可以让商业软件在传统贩卖软件使用许可的商业模式下得到良性发展的机会，也可以让一部分人转向使用免费的开源软件，进而促进开源软件的发展。 当然，在现阶段，通过从财政中拿出来一些钱，设立一些奖励基金之类的东西，给开源软件的作者以一些奖励，也许是更有效的途径。 开源软件本就应该是以松散、自组织的形式开发和发展，开源社区的存在，为开源软件开发者和使用者提供赖以生存的土壤。开源社区可以是网站、论坛，也可以是松散的交流、展演等。当然，开源社区第一步要解决的问题就是自己的生存问题。 笔者的建议是，开源社区应该尝试在现有法律框架下，以有限责任公司的治理结构来做国外开源基金会所做的工作。通过这样一种方式，可以有效避免无法注册 NGO 组织的问题，然后从企业（尤其是那些大型互联网企业）当中募集捐款，通过赞助一些开源项目，逐步推进开源软件社区的良性发展。 另外，国内开源社区还需要从使用者社区转向开发者社区，为开发者参与开源软件提供便利，如建立类似 GitHub/SourceForge 那样的开源软件托管站点，为开源软件项目提供邮件列表、论坛、博客服务等等。 7 结语——给那些仅仅使用开源软件但不做贡献的企业将开源软件和商业结合，不管是在自己的项目中使用开源软件，还是靠自己的开源软件来赚钱，都无可厚非。关键是，我们需要 尊重开源软件著作权的拥有者，按照开源软件所采纳的许可证办事，只有这样，开源软件才能得到长足发展。 通常，开源软件的作者发布开源软件，是希望获得最多用户使用的，在此基础上，作者要么会获得业界的追捧而一夜成名，要么获得一定的商业利益。所以，从某种角度上讲，使用开源软件本身就是对开源软件的一种支持。 但是，这并不意味着你可以随意使用他人的开源软件。合法使用开源软件的前提，就是遵守开源软件的许可证规定的各种义务。 当然，更有积极意义的方式是，将使用开源软件中遇到的问题或者修正、增强代码提交给开源软件的作者，帮助其改善作品。其实，这是任何使用开源软件的企业都能做到的。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"Android模拟器影响系统音量的解决方法","date":"2017-03-01T13:06:06.000Z","path":"2017/03/01/Program/Android/android-emulator-system-sound/","text":"用常识思维解决问题，既简单又快捷…有时候离解决方案只有一步之遥。 问题描述 系统配置：Acer Predator G9-593 AndroidStudio：2.2.3 AndroidSDK：更新到2017.03.01的最新版本 AndroidStudio一打开模拟器，正在播放的音乐音量瞬间变小 程序员离开了音乐，就如烟鬼离开了烟，不解决不痛快 常识思维Google一下，相关页面较少，表明这是个不常见的问题，另外，阅读他人给出的解决方案，譬如：重装AndroidStudio、SDK甚至Win10系统等，一看还就是“电脑出问题，不是重启就是关机后再开机”的老套路，不明所以又爱自以为是。 稍微有个靠谱的推荐解决方案，就是设置”系统检测到通讯活动存在时，自动降低音量“选项，但我尝试之后，结果仍是“鞋子虽好，但不适合我”。 解决方法 自己动手，丰衣足食，既然是音量高低的问题，那就先到系统设置查找声音相关选项，按照自己的习惯，先遍历各个按钮和选项…等下，这不就是音量设置选项吗？拉大一点尝试一下，还不行，切换到杜比音效选项，发现处于关闭状态，打开尝试一下，OK…“你知不知道，我等到花儿也谢了…”歌神的歌声又开始飘扬了… 注意一个坑，要选中“Speakers”，Properties按钮才可用 不要怕点怕设置，要敢于尝试，大不了再恢复默认设置嘛…从电脑和手机，从系统到应用，一般都支持恢复默认选项，如果你开发的软件还不支持该功能，建议还是尽快纳入TODO List… 其实，音量设置的总开关在Volume Mixer，可以自由设定… 后话 Google上找到了一样的解决方案…又一个GG远胜于BD的例子","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"Android安全攻防战，反编译与混淆技术完全解析","date":"2017-02-27T05:57:06.000Z","path":"2017/02/27/Program/Android/awesome-articles-of-android/","text":"Android安全攻防战，反编译与混淆技术完全解析（上） Android安全攻防战，反编译与混淆技术完全解析（下） 之前一直有犹豫过要不要写这篇文章，毕竟去反编译人家的程序并不是什么值得骄傲的事情。不过单纯从技术角度上来讲，掌握反编译功能确实是一项非常有用的技能，可能平常不太会用得到，但是一旦真的需要用到的了，而你却不会的话，那就非常头疼了。另外既然别人可以反编译程序，我们当然有理由应该对程序进行一定程度的保护，因此代码混淆也是我们必须要掌握的一项技术。那么最近的两篇文章我们就围绕反编译和混淆这两个主题来进行一次完全解析。 反编译我们都知道，Android程序打完包之后得到的是一个APK文件，这个文件是可以直接安装到任何Android手机上的，我们反编译其实也就是对这个APK文件进行反编译。Android的反编译主要又分为两个部分，一个是对代码的反编译，一个是对资源的反编译，我们马上来逐个学习一下。 在开始学习之前，首先我们需要准备一个APK文件，为了尊重所有开发者，我就不拿任何一个市面上的软件来演示了，而是自己写一个Demo用来测试。 这里我希望代码越简单越好，因此我们建立一个新项目，在Activity里加入一个按钮，当点击按钮时弹出一个Toast，就这么简单，代码如下所示：123456789101112131415public class MainActivity extends AppCompatActivity &#123; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Button button = (Button) findViewById(R.id.button); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; Toast.makeText(MainActivity.this, \"you clicked button\", Toast.LENGTH_SHORT).show(); &#125; &#125;); &#125;&#125; activity_main.xml中的资源如下所示：12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingLeft=\"@dimen/activity_horizontal_margin\" android:paddingRight=\"@dimen/activity_horizontal_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\"&gt; &lt;Button android:id=\"@+id/button\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"Button\"/&gt;&lt;/RelativeLayout&gt; 然后我们将代码打成一个APK包，并命名成Demo.apk，再把它安装到手机上，结果如下所示： 好的，到这里准备工作就已经基本完成了，接下来就让我们开始对这个Demo程序进行反编译吧。 反编译代码要想将APK文件中的代码反编译出来，我们需要用到以下两款工具： dex2jar 这个工具用于将dex文件转换成jar文件下载地址：http://sourceforge.net/projects/dex2jar/files/jd-gui 这个工具用于将jar文件转换成java代码下载地址：http://jd.benow.ca/将这两个工具都下载好并解压，然后我们就开始对Demo程序进行反编译。解压dex2jar压缩包后，你会发现有很多个文件，如下图所示： 其中我们要用到的是d2j-dex2jar.bat这个文件，当然如果你是linux或mac系统的话就要用d2j-dex2jar.sh这个文件。然后我们将Demo.apk文件也进行解压，如果不知道怎么直接解压的可以先将文件重命名成Demo.zip，然后用解压软件打开。解压之后你会发现里面有一个classes.dex文件，如下图所示： 这个classes.dex文件就是存放所有java代码的地方了，我们将它拷贝到dex2jar解压后的目录下，并在cmd中也进入到同样的目录，然后执行： d2j-dex2jar classes.dex 执行结果如下图所示： 没有报任何错误，这就说明我们已经转换成功了。现在观察dex2jar目录，你会发现多了一个文件，如下图所示： 可以看到，classes-dex2jar.jar这个文件就是我们借助工具之后成功转换出来的jar文件了。但是对于我们而言，jar文件也不是可读的，因此这里还需要再借助一下jd-gui这个工具来将jar文件转换成java代码。下面就很简单了，使用jd-gui工具打开classes-dex2jar.jar这个文件，结果如下图所示： OK，由此可见，我们的代码反编译工作已经成功了，MainActivity中的代码非常清晰，基本已经做到了90%以上的还原工作。但是如果想要做到100%的代码还原还是非常有难度的，因为像setContentView()方法传入的参数，其实就是一个资源的id值而已，那么这里反编译也就只能将相应的id值进行还原，而无法变成像R.layout.activity_main这样直观的代码展示。另外，除了MainActivity之外，还有很多其它的代码也被反编译出来了，因为当前项目有引用support-v4和support-v7的包，这些引用的library也会作为代码的一部分被打包到classes.dex文件当中，因此反编译的时候这些代码也会一起被还原。好的，学完了反编译代码，接下来我们看一下如何反编译资源。 反编译资源其实细心的朋友可能已经观察到了，刚才Demo.apk的解压目录当中不是已经有资源文件了吗，有AndroidManifest.xml文件，也有res目录。进入res目录当中，内容如下图所示： 这不是所有资源文件都在这里了么？其实这些资源文件都是在打包的时候被编译过了，我们直接打开的话是看不到明文的，不信的话我们打开AndroidManifest.xml文件来瞧一瞧，内容如下图所示： 可以看到，这代码是完全没法阅读的。当然如果你去打开activity_main.xml看看，结果也不会好到哪儿去： 由此可见，直接对APK包进行解压是无法得到它的原始资源文件的，因此我们还需要对资源进行反编译才行。要想将APK文件中的资源反编译出来，又要用到另外一个工具了：apktool 这个工具用于最大幅度地还原APK文件中的9-patch图片、布局、字符串等等一系列的资源。下载地址：http://ibotpeaches.github.io/Apktool/install/关于这个工具的下载我还要再补充几句，我们需要的就是apktool.bat和apktool.jar这两个文件。目前apktool.jar的最新版本是2.0.3，这里我就下载最新的了，然后将apktool_2.0.3.jar重命名成apktool.jar，并将它们放到同一个文件夹下就可以了，如下图所示： 接下来的工作就很简单了，我们将Demo.apk拷贝到和这两个文件同样的目录当中，然后cmd也进入到这个目录下，并在cmd中执行如下命令： apktool d Demo.apk 其中d是decode的意思，表示我们要对Demo.apk这个文件进行解码。那除了这个基本用法之外，我们还可以再加上一些附加参数来控制decode的更多行为： -f 如果目标文件夹已存在，则强制删除现有文件夹（默认如果目标文件夹已存在，则解码失败）。-o 指定解码目标文件夹的名称（默认使用APK文件的名字来命名目标文件夹）。-s 不反编译dex文件，也就是说classes.dex文件会被保留（默认会将dex文件解码成smali文件）。-r 不反编译资源文件，也就是说resources.arsc文件会被保留（默认会将resources.arsc解码成具体的资源文件）。常用用法就这么多了，那么上述命令的执行结果如下图所示： 这就说明反编译资源已经成功了。当然即使你在和我执行一模一样的操作，也有可能会在这里反编译失败，比如说会报如下错误： 出现这个错误的原因很有可能是你之前使用过apktool的老版本进行过反编译操作，然后apktool就会在你系统的C:\\Users\\Administrator\\apktool\\framework这个目录下生成一个名字为1.apk的缓存文件，将这个缓存文件删除掉，然后再重新执行反编译命令应该就可以成功了。现在你会发现在当前目录下多了一个Demo文件夹，这个文件夹中存放的就是反编译的结果了。我们可以打开AndroidManifest.xml来瞧一瞧，如下图所示： 怎么样？这样就完全能看得懂了吧，然后可以再到res/layout中看一下activity_main.xml文件，如下图所示： 可以看到，activity_main.xml中的内容基本和源代码中的内容是一致的，外层是一个RelativeLayout，里面则是一个Button。你可以再到其它目录中去看一看别的资源，基本上都是可以正常还原的，这样我们就把反编译资源的方法也已经掌握了。 重新打包那么对于反编译出来的文件夹，我们能不能重新把它打包成APK文件呢？答案是肯定的，只不过我实在想不出有什么义正言辞的理由可以让我们这么做。有的人会说汉化，没错，汉化的方式确实就是将一个APK进行反编译，然后翻译其中的资源再重新打包，但是不管怎么说这仍然是将别人的程序进行破解，所以我并不认为这是什么光荣的事情。那么我们就不去讨论本身这件事情的对或错，这里只是站在技术的角度来学习一下重新打包的相关知识。首先我们来看一下通过apktool反编译后的包目录情况，如下图所示： 其中，original文件夹下存放的是未经反编译过、原始的AndroidManifest.xml文件，res文件夹下存放的是反编译出来的所有资源，smali文件夹下存放的是反编译出来的所有代码，AndroidManifest.xml则是经过反编译还原后的manifest文件。这里值得一提的是smali文件夹，如果你进入到这个文件夹中你会发现它的目录结构和我们源码中src的目录结构是几乎一样的，主要的区别就是所有的java文件都变成了smali文件。smali文件其实也是真正的源代码，只不过它的语法和java完全不同，它有点类似于汇编的语法，是Android虚拟机所使用的寄存器语言，语法结构大概如下所示： 看上去有点晕头转向是吗？但是如果你一旦能够看得懂smali文件的话，那么你就可以做很恐怖的事情了——你可以随意修改应用程序内的逻辑，将其进行破解！不过我对这种黑技术并没有什么太大的兴趣，因此我也没有去做具体研究，但即使是这样，也已经可以对程序的逻辑做一定程度的修改了。比如说当我们点击按钮时会弹出you clicked button这样一句Toast，逻辑是写在MainActivity按钮点击事件的匿名类当中的，因此这段代码反编译之后一定就会在MainActivity$1.smali这个文件当中，让我们打开瞧一瞧，部分代码如下所示： 虽说多数的代码我是看不懂的，但其中第47行实在太明显了，Toast显示的内容不就是在这里定义的么，那么如果我们想把Demo程序hack掉，就可以将这段字符串给改掉，比如说我把它改成Your app is been hacked。关于smali的语法，网上的资料也非常多，如果你对这门技术十分感兴趣的话可以直接上网去搜，这里我只是简单介绍一下，就不再深入讲解相关知识了。改了一处代码后我们再来改一处资源吧，比如这里想要把Demo的应用图标给换掉，那么首先我们要准备好一张新的图片，如下图所示：然后从AndroidManifest.xml文件中可以看出，应用图标使用的是ic_launcher.png这张图片，那么我们将上面篮球这张图片命名成ic_launcher.png，然后拷贝到所有以res/mipmap开头的文件夹当中完成替换操作。在做了两处改动之后，我们现在来把反编译后的Demo文件夹重新打包成APK吧，其实非常简单，只需要在cmd中执行如下命令： apktool b Demo -o New_Demo.apk 其中b是build的意思，表示我们要将Demo文件夹打包成APK文件，-o用于指定新生成的APK文件名，这里新的文件叫作New_Demo.apk。执行结果如下图所示： 现在你会发现在同级目录下面生成了一个新的APK文件： 不过不要高兴得太早了，目前这个New_Demo.apk还是不能安装的，因为它还没有进行签名。那么如果这是别人的程序的话，我们从哪儿能拿到它原来的签名文件呢？很显然，这是根本没有办法拿到的，因此我们只能拿自己的签名文件来对这个APK文件重新进行签名，但同时也表明我们重新打包出来的软件就是个十足的盗版软件。这里大家学学技术就好了，希望不要有任何人去做什么坏事情。那么这里我就用一个之前生成好的签名文件了，使用Android Studio或者Eclipse都可以非常简单地生成一个签名文件。有了签名文件之后在cmd中执行签名命令就可以进行签名了，命令格式如下： jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore 签名文件名 -storepass 签名密码 待签名的APK文件名 签名的别名 其中jarsigner命令文件是存放在jdk的bin目录下的，需要将bin目录配置在系统的环境变量当中才可以在任何位置执行此命令。签名之后的APK文件现在已经可以安装到手机上了，不过在此之前Android还极度建议我们对签名后的APK文件进行一次对齐操作，因为这样可以使得我们的程序在Android系统中运行得更快。对齐操作使用的是zipalign工具，该工具存放于/build-tools/目录下，将这个目录配置到系统环境变量当中就可以在任何位置执行此命令了。命令格式如下： zipalign 4 New_Demo.apk New_Demo_aligned.apk 其中4是固定值不能改变，后面指定待对齐的APK文件名和对齐后的APK文件名。运行这段命令之后就会生成一个New_Demo_aligned.apk文件，如下所示： 这个New_Demo_aligned.apk就是我们重新打包签名对齐后的文件了，现在把它安装到手机上，效果如下图所示： 可以看到，应用图标已经成功改成了篮球，另外点击按钮后弹出的Toast的提示也变成了我们修改后的文字，说明重新打包操作确实已经成功了。好的，我们把反编译代码、反编译资源、重新打包这三大主题的内容都已经掌握了，关于反编译相关的内容就到这里，下篇文章会介绍Android代码混淆方面的相关技术，感兴趣的朋友请继续阅读： Android安全攻防战，反编译与混淆技术完全解析（下） 。 在上一篇文章当中，我们学习了Android程序反编译方面的知识，包括反编译代码、反编译资源、以及重新打包等内容。通过这些内容我们也能看出来，其实我们的程序并没有那么的安全。可能资源被反编译影响还不是很大，重新打包又由于有签名的保护导致很难被盗版，但代码被反编译就有可能会泄漏核心技术了，因此一款安全性高的程序最起码要做到的一件事就是：对代码进行混淆。 混淆代码并不是让代码无法被反编译，而是将代码中的类、方法、变量等信息进行重命名，把它们改成一些毫无意义的名字。因为对于我们而言可能Cellphone类的call()方法意味着很多信息，而A类的b()方法则没有任何意义，但是对于计算机而言，它们都是平等的，计算机不会试图去理解Cellphone是什么意思，它只会按照设定好的逻辑来去执行这些代码。所以说混淆代码可以在不影响程序正常运行的前提下让破解者很头疼，从而大大提升了程序的安全性。 今天是我们Android安全攻防战系列的下篇，本篇文章的内容建立在上篇的基础之上，还没有阅读过的朋友可以先去参考 Android安全攻防战，反编译与混淆技术完全解析（上） 。 混淆 本篇文章中介绍的混淆技术都是基于Android Studio的，Eclipse的用法也基本类似，但是就不再为Eclipse专门做讲解了。 我们要建立一个Android Studio项目，并在项目中添加一些能够帮助我们理解混淆知识的代码。这里我准备好了一些，我们将它们添加到Android Studio当中。 首先新建一个MyFragment类，代码如下所示：1234567891011121314151617181920212223public class MyFragment extends Fragment &#123; private String toastTip = \"toast in MyFragment\"; @Nullable @Override public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) &#123; View view = inflater.inflate(R.layout.fragment_layout, container, false); methodWithGlobalVariable(); methodWithLocalVariable(); return view; &#125; public void methodWithGlobalVariable() &#123; Toast.makeText(getActivity(), toastTip, Toast.LENGTH_SHORT).show(); &#125; public void methodWithLocalVariable() &#123; String logMessage = \"log in MyFragment\"; logMessage = logMessage.toLowerCase(); System.out.println(logMessage); &#125;&#125; 可以看到，MyFragment是继承自Fragment的，并且MyFragment中有一个全局变量。onCreateView()方法是Fragment的生命周期函数，这个不用多说，在onCreateView()方法中又调用了methodWithGlobalVariable()和methodWithLocalVariable()方法，这两个方法的内部分别引用了一个全局变量和一个局部变量。 接下来新建一个Utils类，代码如下所示：1234567891011121314public class Utils &#123; public void methodNormal() &#123; String logMessage = \"this is normal method\"; logMessage = logMessage.toLowerCase(); System.out.println(logMessage); &#125; public void methodUnused() &#123; String logMessage = \"this is unused method\"; logMessage = logMessage.toLowerCase(); System.out.println(logMessage); &#125;&#125; 这是一个非常普通的工具类，没有任何继承关系。Utils中有两个方法methodNormal()和methodUnused()，它们的内部逻辑都是一样的，唯一的据别是稍后methodNormal()方法会被调用，而methodUnused()方法不会被调用。 下面再新建一个NativeUtils类，代码如下所示：12345678910public class NativeUtils &#123; public static native void methodNative(); public static void methodNotNative() &#123; String logMessage = \"this is not native method\"; logMessage = logMessage.toLowerCase(); System.out.println(logMessage); &#125;&#125; 这个类中同样有两个方法，一个是native方法，一个是非native方法。最后，修改MainActivity中的代码，如下所示：12345678910111213141516171819202122232425262728293031323334public class MainActivity extends AppCompatActivity &#123; private String toastTip = \"toast in MainActivity\"; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); getSupportFragmentManager().beginTransaction().add(R.id.fragment, new MyFragment()).commit(); Button button = (Button) findViewById(R.id.button); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; methodWithGlobalVariable(); methodWithLocalVariable(); Utils utils = new Utils(); utils.methodNormal(); NativeUtils.methodNative(); NativeUtils.methodNotNative(); Connector.getDatabase(); &#125; &#125;); &#125; public void methodWithGlobalVariable() &#123; Toast.makeText(MainActivity.this, toastTip, Toast.LENGTH_SHORT).show(); &#125; public void methodWithLocalVariable() &#123; String logMessage = \"log in MainActivity\"; logMessage = logMessage.toLowerCase(); System.out.println(logMessage); &#125;&#125; 可以看到，MainActivity和MyFragment类似，也是定义了methodWithGlobalVariable()和methodWithLocalVariable()这两个方法，然后MainActivity对MyFragment进行了添加，并在Button的点击事件里面调用了自身的、Utils的、以及NativeUtils中的方法。注意调用native方法需要有相应的so库实现，不然的话就会报UnsatisefiedLinkError，不过这里其实我也并没有真正的so库实现，只是演示一下让大家看看混淆结果。点击事件的最后一行调用的是LitePal中的方法，因为我们还要测试一下引用第三方Jar包的场景，到LitePal项目的主页去下载最新的Jar包，然后放到libs目录下即可。 完整的build.gradle内容如下所示：12345678910111213141516171819202122232425apply plugin: 'com.android.application'android &#123; compileSdkVersion 23 buildToolsVersion \"23.0.2\" defaultConfig &#123; applicationId \"com.example.guolin.androidtest\" minSdkVersion 15 targetSdkVersion 23 versionCode 1 versionName \"1.0\" &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' &#125; &#125;&#125;dependencies &#123; compile fileTree(dir: 'libs', include: ['*.jar']) compile 'com.android.support:appcompat-v7:23.2.0'&#125; 好的，到这里准备工作就已经基本完成了，接下来我们就开始对代码进行混淆吧。 混淆APK在Android Studio当中混淆APK实在是太简单了，借助SDK中自带的Proguard工具，只需要修改build.gradle中的一行配置即可。可以看到，现在build.gradle中minifyEnabled的值是false，这里我们只需要把值改成true，打出来的APK包就会是混淆过的了。如下所示：1234release &#123; minifyEnabled true proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'&#125; 其中minifyEnabled用于设置是否启用混淆，proguardFiles用于选定混淆配置文件。注意这里是在release闭包内进行配置的，因此只有打出正式版的APK才会进行混淆，Debug版的APK是不会混淆的。当然这也是非常合理的，因为Debug版的APK文件我们只会用来内部测试，不用担心被人破解。那么现在我们来打一个正式版的APK文件，在Android Studio导航栏中点击Build-&gt;Generate Signed APK，然后选择签名文件并输入密码，如果没有签名文件就创建一个，最终点击Finish完成打包，生成的APK文件会自动存放在app目录下。除此之外也可以在build.gradle文件当中添加签名文件配置，然后通过gradlew assembleRelease来打出一个正式版的APK文件，这种方式APK文件会自动存放在app/build/outputs/apk目录下。那么现在已经得到了APK文件，接下来就用上篇文章中学到的反编译知识来对这个文件进行反编译吧，结果如下图所示： 很明显可以看出，我们的代码混淆功能已经生效了。 下面我们尝试来阅读一下这个混淆过后的代码，最顶层的包名结构主要分为三部分，第一个a.a已经被混淆的面目全非了，但是可以猜测出这个包下是LitePal的所有代码。第二个android.support可以猜测出是我们引用的android support库的代码，第三个com.example.guolin.androidtest则很明显就是我们项目的主包名了，下面将里面所有的类一个个打开看一下。首先MainActivity中的代码如下所示： 可以看到，MainActivity的类名是没有混淆的，onCreate()方法也没有被混淆，但是我们定义的方法、全局变量、局部变量都被混淆了。再来打开下一个类NativeUtils，如下所示： NativeUtils的类名没有被混淆，其中声明成native的方法也没有被混淆，但是非native方法的方法名和局部变量都被混淆了。接下来是a类的代码，如下所示： 很明显，这个是MainActivity中按钮点击事件的匿名类，在onClick()方法中的调用代码虽然都被混淆了，但是调用顺序是不会改变的，对照源代码就可以看出哪一行是调用的什么方法了。再接下来是b类，代码如下所示： 虽然被混淆的很严重，但是我们还是可以看出这个是MyFragment类。其中所有的方法名、全局变量、局部变量都被混淆了。最后再来看下c类，代码如下所示： c类中只有一个a方法，从字符串的内容我们可以看出，这个是Utils类中的methodNormal()方法。 我为什么要创建这样的一个项目呢？因为从这几个类当中很能看出一些问题，接下来我们就分析一下上面的混淆结果。 首先像Utils这样的普通类肯定是会被混淆的，不管是类名、方法名还是变量都不会放过。除了混淆之外Utils类还说明了一个问题，就是minifyEnabled会对资源进行压缩，因为Utils类中我们明明定义了两个方法，但是反编译之后就只剩一个方法了，因为另外一个方法没有被调用，所以认为是多余的代码，在打包的时候就给移除掉了。不仅仅是代码，没有被调用的资源同样也会被移除掉，因此minifyEnabled除了混淆代码之外，还可以起到压缩APK包的作用。 接着看一下MyFragment，这个类也是混淆的比较彻底的，基本没有任何保留。那有些朋友可能会有疑问，Fragment怎么说也算是系统组件吧，就算普通方法名被混淆了，至少像onCreateView()这样的生命周期方法不应该被混淆吧？其实生命周期方法会不会被混淆和我们使用Fragment的方式有关，比如在本项目中，我使用的是android.support.v4.app.Fragment，support-v4包下的，就连Fragment的源码都被一起混淆了，因此生命周期方法当然也不例外了。但如果你使用的是android.app.Fragment，这就是调用手机系统中预编译好的代码了，很明显我们的混淆无法影响到系统内置的代码，因此这种情况下onCreateView()方法名就不会被混淆，但其它的方法以及变量仍然会被混淆。 接下来看一下MainActivity，同样也是系统组件之一，但MainActivity的保留程度就比MyFragment好多了，至少像类名、生命周期方法名都没有被混淆，这是为什么呢？根据我亲身测试得出结论，凡是需要在AndroidManifest.xml中去注册的所有类的类名以及从父类重写的方法名都自动不会被混淆。因此，除了Activity之外，这份规则同样也适用于Service、BroadcastReceiver和ContentProvider。 最后看一下NativeUtils类，这个类的类名也没有被混淆，这是由于它有一个声明成native的方法。只要一个类中有存在native方法，它的类名就不会被混淆，native方法的方法名也不会被混淆，因为C++代码要通过包名+类名+方法名来进行交互。 但是类中的别的代码还是会被混淆的。 除此之外，第三方的Jar包都是会被混淆的，LitePal不管是包名还是类名还是方法名都被完完全全混淆掉了。 这些就是Android Studio打正式APK时默认的混淆规则。 那么这些混淆规则是在哪里定义的呢？其实就是刚才在build.gradle的release闭包下配置的proguard-android.txt文件，这个文件存放于/tools/proguard目录下，我们打开来看一下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# This is a configuration file for ProGuard.# http://proguard.sourceforge.net/index.html#manual/usage.html-dontusemixedcaseclassnames-dontskipnonpubliclibraryclasses-verbose# Optimization is turned off by default. Dex does not like code run# through the ProGuard optimize and preverify steps (and performs some# of these optimizations on its own).-dontoptimize-dontpreverify# Note that if you want to enable optimization, you cannot just# include optimization flags in your own project configuration file;# instead you will need to point to the# \"proguard-android-optimize.txt\" file instead of this one from your# project.properties file.-keepattributes *Annotation*-keep public class com.google.vending.licensing.ILicensingService-keep public class com.android.vending.licensing.ILicensingService# For native methods, see http://proguard.sourceforge.net/manual/examples.html#native-keepclasseswithmembernames class * &#123; native &lt;methods&gt;;&#125;# keep setters in Views so that animations can still work.# see http://proguard.sourceforge.net/manual/examples.html#beans-keepclassmembers public class * extends android.view.View &#123; void set*(***); *** get*();&#125;# We want to keep methods in Activity that could be used in the XML attribute onClick-keepclassmembers class * extends android.app.Activity &#123; public void *(android.view.View);&#125;# For enumeration classes, see http://proguard.sourceforge.net/manual/examples.html#enumerations-keepclassmembers enum * &#123; public static **[] values(); public static ** valueOf(java.lang.String);&#125;-keepclassmembers class * implements android.os.Parcelable &#123; public static final android.os.Parcelable$Creator CREATOR;&#125;-keepclassmembers class **.R$* &#123; public static &lt;fields&gt;;&#125;# The support library contains references to newer platform versions.# Dont warn about those in case this app is linking against an older# platform version. We know about them, and they are safe.-dontwarn android.support.** 这个就是默认的混淆配置文件了，我们来一起逐行阅读一下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950-dontusemixedcaseclassnames 表示混淆时不使用大小写混合类名。-dontskipnonpubliclibraryclasses 表示不跳过library中的非public的类。-verbose 表示打印混淆的详细信息。-dontoptimize 表示不进行优化，建议使用此选项，因为根据proguard-android-optimize.txt中的描述，优化可能会造成一些潜在风险，不能保证在所有版本的Dalvik上都正常运行。-dontpreverify 表示不进行预校验。这个预校验是作用在Java平台上的，Android平台上不需要这项功能，去掉之后还可以加快混淆速度。-keepattributes *Annotation* 表示对注解中的参数进行保留。-keep public class com.google.vending.licensing.ILicensingService-keep public class com.android.vending.licensing.ILicensingService表示不混淆上述声明的两个类，这两个类我们基本也用不上，是接入Google原生的一些服务时使用的。-keepclasseswithmembernames class * &#123; native &lt;methods&gt;;&#125;表示不混淆任何包含native方法的类的类名以及native方法名，这个和我们刚才验证的结果是一致的。-keepclassmembers public class * extends android.view.View &#123; void set*(***); *** get*();&#125;表示不混淆任何一个View中的setXxx()和getXxx()方法，因为属性动画需要有相应的setter和getter的方法实现，混淆了就无法工作了。-keepclassmembers class * extends android.app.Activity &#123; public void *(android.view.View);&#125;表示不混淆Activity中参数是View的方法，因为有这样一种用法，在XML中配置android:onClick=”buttonClick”属性，当用户点击该按钮时就会调用Activity中的buttonClick(View view)方法，如果这个方法被混淆的话就找不到了。-keepclassmembers enum * &#123; public static **[] values(); public static ** valueOf(java.lang.String);&#125;表示不混淆枚举中的values()和valueOf()方法，枚举我用的非常少，这个就不评论了。-keepclassmembers class * implements android.os.Parcelable &#123; public static final android.os.Parcelable$Creator CREATOR;&#125;表示不混淆Parcelable实现类中的CREATOR字段，毫无疑问，CREATOR字段是绝对不能改变的，包括大小写都不能变，不然整个Parcelable工作机制都会失败。-keepclassmembers class **.R$* &#123; public static &lt;fields&gt;;&#125;表示不混淆R文件中的所有静态字段，我们都知道R文件是通过字段来记录每个资源的id的，字段名要是被混淆了，id也就找不着了。-dontwarn android.support.** 表示对android.support包下的代码不警告，因为support包中有很多代码都是在高版本中使用的，如果我们的项目指定的版本比较低在打包时就会给予警告。不过support包中所有的代码都在版本兼容性上做足了判断，因此不用担心代码会出问题，所以直接忽略警告就可以了。 好了，这就是proguard-android.txt文件中所有默认的配置，而我们混淆代码也是按照这些配置的规则来进行混淆的。经过我上面的讲解之后，相信大家对这些配置的内容基本都能理解了。不过proguard语法中还真有几处非常难理解的地方，我自己也是研究了好久才搞明白，下面和大家分享一下这些难懂的语法部分。 proguard中一共有三组六个keep关键字，很多人搞不清楚它们的区别，这里我们通过一个表格来直观地看下： 关键字 描述keep 保留类和类中的成员，防止它们被混淆或移除。keepnames 保留类和类中的成员，防止它们被混淆，但当成员没有被引用时会被移除。keepclassmembers 只保留类中的成员，防止它们被混淆或移除。keepclassmembernames 只保留类中的成员，防止它们被混淆，但当成员没有被引用时会被移除。keepclasseswithmembers 保留类和类中的成员，防止它们被混淆或移除，前提是指名的类中的成员必须存在，如果不存在则还是会混淆。keepclasseswithmembernames 保留类和类中的成员，防止它们被混淆，但当成员没有被引用时会被移除，前提是指名的类中的成员必须存在，如果不存在则还是会混淆。 除此之外，proguard中的通配符也比较让人难懂，proguard-android.txt中就使用到了很多通配符，我们来看一下它们之间的区别： \b通配符 描述 \b匹配类中的所有字段 匹配类中的所有方法 \b匹配类中的所有构造函数 匹配任意长度字符，但不含\b包名分隔符(.)。比如说我们的完整类名是com.example.test.MyActivity，使用com.，或者com.exmaple.都是无法匹配的，因为无法匹配包名中的分隔符，正确的匹配方式是com.exmaple..，或者com.exmaple.test.，这些都是可以的。但如果你不写任何其它内容，只有一个，那就表示匹配所有的东西。 匹配任意长度字符，并且包含包名分隔符(.)。比如proguard-android.txt中使用的-dontwarn android.support.就可以匹配android.support包下的所有内容，包括任意长度的子包。** 匹配任意参数类型。比如void set(**)就能匹配任意传入的参数类型，** get()就能匹配任意返回值的类型。… 匹配任意长度的任意类型参数。比如void test(…)就能匹配任意void test(String a)或者是void test(int a, String b)这些方法。 虽说上面表格已经解释的很详细了，但是很多人对于keep和keepclasseswithmembers这两个关键字的区别还是搞不懂。确实，它们之间用法有点太像了，我做了很多次试验它们的结果都是相同的。其实唯一的区别就在于类中声明的成员存不存在，我们还是通过一个例子来直接地看一下，先看keepclasseswithmember关键字： -keepclasseswithmember class * { native ;} 这段代码的意思其实很明显，就是保留所有含有native方法的类的类名和native方法名，而如果某个类中没有含有native方法，那就还是会被混淆。 但是如果改成keep关键字，结果会完全不一样： -keep class * { native ;} 使用keep关键字后，你会发现代码中所有类的类名都不会被混淆了，因为keep关键字看到class *就认为应该将所有类名进行保留，而不会关心该类中是否含有native方法。当然这样写只会保证类名不会被混淆，类中的成员还是会被混淆的。 比较难懂的用法大概就这些吧，掌握了这些内容之后我们就能继续前进了。 回到Android Studio项目当中，刚才打出的APK虽然已经成功混淆了，但是混淆的规则都是按照proguard-android.txt中默认的规则来的，当然我们也可以修改proguard-android.txt中的规则，但是直接在proguard-android.txt中修改会对我们本机上所有项目的混淆规则都生效，那么有没有什么办法只针对当前项目的混淆规则做修改呢？当然是有办法的了，你会发现任何一个Android Studio项目在app模块目录下都有一个proguard-rules.pro文件，这个文件就是用于让我们编写只适用于当前项目的混淆规则的，那么接下来我们就利用刚才学到的所有知识来对混淆规则做修改吧。 这里我们先列出来要实现的目标： 对MyFragment类进行完全保留，不混淆其类名、方法名、以及变量名。对Utils类中的未调用方法进行保留，防止其被移除掉。对第三方库进行保留，不混淆android-support库，以及LitePal库中的代码。 下面我们就来逐一实现这些目标。首先要对MyFragment类进行完全保留可以使用keep关键字，keep后声明完整的类名，然后保留类中的所有内容可以使用*通配符实现，如下所示： -keep class com.example.guolin.androidtest.MyFragment { *;} 然后保留Utils类中的未调用方法可以使用keepclassmembers关键字，后跟Utils完整类名，然后在内部声明未调用的方法，如下所示： -keepclassmembers class com.example.guolin.androidtest.Utils { public void methodUnused();} 最后不要混淆第三方库，目前我们使用了两种方式来引入第三方库，一种是通过本地jar包引入的，一种是通过remote\b引入的，其实这两种方式没什么区别，要保留代码都可以使用**这种通配符来实现，如下所示： -keep class org.litepal.* { ;} -keep class android.support.* { ;} 所有内容都在这里了，现在我们重新打一个正式版的APK文件，然后再反编译看看效果： 可以看到，现在android-support包中所有代码都被保留下来了，不管是包名、类名、还是方法名都没有被混淆。LitePal中的代码也是同样的情况： 再来看下MyFragment中的代码，如下所示： 可以看到，MyFragment中的代码也没有被混淆，按照我们的要求被完全保留下来了。最后再来看一下Utils类中的代码： 很明显，Utils类并没有被完全保留下来，类名还是被混淆了，methodNormal()方法也被混淆了，但是methodUnused()没有被混淆，当然也没有被移除，因为我们的混淆配置生效了。 经过这些例子的演示，相信大家已经对Proguard的用法有了相当不错的理解了，那么根据自己的业务需求来去编写混淆配置相信也不是什么难事了吧？ Progaurd的使用非常灵活，基本上能够覆盖你所能想到的所有业务逻辑。这里再举个例子，之前一直有人问我使用LitePal时的混淆配置怎么写，其实真的很简单，LitePal作为开源库并不需要混淆，上面的配置已经演示了如何不混淆LitePal代码，然后所有代码中的Model是需要进行反射的，也不能混淆，那么只需要这样写就行了：-keep class extends org.litepal.crud.DataSupport { ;} 因为LitePal中所有的Model都是应该继承DataSupport类的，所以这里我们将所有继承自DataSupport的类都进行保留就可以了。关于混淆APK的用法就讲这么多，如果你还想继续了解关于Proguard的更多用法，可以参考官方文档：http://proguard.sourceforge.net/index.html#manual/usage.html 混淆Jar在本篇文章的第二部分我想讲一讲混淆Jar包的内容，因为APK不一定是我们交付的唯一产品。就比如说我自己，我在公司是负责写SDK的，对于我来说交付出去的产品就是Jar包，而如果Jar包不混淆的话将会很容易就被别人反编译出来，从而泄漏程序逻辑。 实际上Android对混淆Jar包的支持在很早之前就有了，不管你使用多老版本的SDK，都能在 /tools目录下找到proguard这个文件夹。然后打开里面的bin目录，你会看到如下文件： 其中proguardgui.bat文件是允许我们以图形化的方式来对Jar包进行混淆的一个工具，今天我们就来讲解一下这个工具的用法。在开始讲解这个工具之前，首先我们需要先准备一个Jar包，当然你从哪里搞到一个Jar包都是可以的，不过这里为了和刚才的混淆逻辑统一，我们就把本篇文章中的项目代码打成一个Jar包吧。Eclipse中导出Jar包的方法非常简单，相信所有人都会，可是Android Studio当中就比较让人头疼了，因为Android Studio并没有提供一个专门用于导出Jar包的工具，因此我们只能自己动手了。我们需要知道，任何一个Android Studio项目，只要编译成功之后就会在项目模块的build/intermediates/classes/debug目录下生成代码编译过后的class文件，因此只需通过打包命令将这些class文件打包成Jar包就行了，打开cmd，切换到项目的根目录，然后输入如下命令： jar -cvf androidtest.jar -C app/build/intermediates/classes/debug . 在项目的根目录下就会生成androidtest.jar这个文件，这样我们就把Jar包准备好了。现在双击proguardgui.bat打开混淆工具，如果是Mac或Ubuntu系统则使用sh proguardgui.sh命令打开混淆工具，界面如下图所示： 其实从主界面上我们就能看出，这个Proguard工具支持Shrinking、Optimization、Obfuscation、Preverification四项操作，在左侧的侧边栏上也能看到相应的这些选项。Proguard的工作机制仍然还是要依赖于配置文件，当然我们也可以通过proguardgui工具来生成配置文件，不过由于配置选项太多了，每个都去一一设置太复杂，而且大多数还都是我们用不到的配置。因此最简单的方式就是直接拿现有的配置文件，然后再做些修改就行了。那么我们从/tools/proguard目录下将proguard-android.txt文件复制一份出来，然后点击主界面上的Load configuration按钮来加载复制出来的这份proguard-android.txt文件，完成后点击Next将进入Input/Output界面。Input/Output界面是用于导入要混淆的Jar包、配置混淆后文件的输出路径、以及导入该Jar包所依赖的所有其它Jar包的。我们要混淆的当然就是androidtest.jar这个文件，那么这个Jar包又依赖了哪些Jar包呢？这里就需要整理一下了。首先我们写的都是Java代码，Java代码的运行要基于Jre基础之上，没有Jre计算机将无法识别Java的语法，因此第一个要依赖的就是Jre的rt.jar。然后由于我们导出的Jar包中有Android相关的代码，比如Activity、Fragment等，因此还需要添加Android的\b编译库，android.jar。除此之外，我们使用的AppCompatActivity和Fragment分别来自于appcompat-v7包和support-v4包，那么这两个Jar包也是需要引入的。最后就是代码中还引入了litepal-1.3.1.jar。整理清楚了之后我们就来一个个添加，Input/Output有上下两个操作界面，上面是用于导入要混淆的Jar包和配置混淆后文件的输出路径的，下面则是导入该Jar包所依赖的所有其它Jar包的，全部导入后结果如下图所示： 这些依赖的Jar包所存在的路径每台电脑都不一样，你所需要做的就是在你自己的电脑上成功找到这些依赖的Jar包并导入即可。不过细心的朋友可能会发现，我在上面整理出了五个依赖的Jar包，但是在图中却添加了六个。这是我在写这篇文章时碰到的一个新的坑，也是定位了好久才解决的，我觉得有必要重点提一下。由于我平时混淆Jar包时里面很少会有Activity，所以没遇到过这个问题，但是本篇文章中的演示Jar包中不仅包含了Activty，还是继承自AppCompatActivity的。而AppCompatActivity的继承结构并不简单，如下图所示： 其中AppCompatActivity是在appcompat-v7包中的，它的父类FragmentActivity是在support-v4包中的，这两个包我们都已经添加依赖了。但是FragmentActivity的父类就坑爹了，如果你去看BaseFragmentActivityHoneycomb和BaseFragmentActivityDonut这两个类的源码，你会发现它们都是在support-v4包中的： 可是如果你去support-v4的Jar包中找一下，你会发现压根就没有这两个类，所以我当时一直混淆报错就是因为这两个类不存在，继承结构在这里断掉了。而这两个类其实被规整到了另外一个internal的Jar包中，所以当你要混淆的Jar包中有Activity，并且还是继承自AppCompatActivity或FragmentActivity的话，那么就一定要记得导入这个internal Jar包的依赖，如下图所示： 接下来点击Next进入Shrink界面，这个界面没什么需要配置的东西，但记得要将Shrink选项钩掉，因为我们这个Jar包是独立存在的，没有任何项目引用，如果钩中Shrink选项的话就会认为我们所有的代码都是无用的，从而把所有代码全压缩掉，导出一个空的Jar包。继续点击Next进入Obfuscation界面，在这里可以添加一些混淆的逻辑，和混淆APK时不同的是，这里并不会自动帮我们排除混淆四大组件，因此必须要手动声明一下才行。点击最下方的Add按钮，然后在弹出的界面上编写排除逻辑，如下图所示： 很简单，就是在继承那一栏写上android.app.Activity就行了，其它的组件原理也相同。继续点击Next进入Optimiazation界面，不用修改任何东西，因为我们本身就不启用Optimization功能。继续点击Next进入Information界面，也不用修改任何东西，因为我们也不启用Preverification功能。接着点击Next，进入Process界面，在这里可以通过点击View configuration按钮来预览一下目前我们的混淆配置文件，内容如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162-injars /Users/guolin/AndroidStudioProjects/AndroidTest/androidtest.jar-outjars /Users/guolin/androidtest_obfuscated.jar-libraryjars /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/rt.jar-libraryjars /Users/guolin/Library/Android/sdk/platforms/android-23/android.jar-libraryjars /Users/guolin/AndroidStudioProjects/AndroidTest/app/build/intermediates/exploded-aar/com.android.support/appcompat-v7/23.2.0/jars/classes.jar-libraryjars /Users/guolin/AndroidStudioProjects/AndroidTest/app/build/intermediates/exploded-aar/com.android.support/support-v4/23.2.0/jars/classes.jar-libraryjars /Users/guolin/AndroidStudioProjects/AndroidTest/app/build/intermediates/exploded-aar/com.android.support/support-v4/23.2.0/jars/libs/internal_impl-23.2.0.jar-libraryjars /Users/guolin/AndroidStudioProjects/AndroidTest/app/libs/litepal-1.3.1.jar-dontshrink-dontoptimize-dontusemixedcaseclassnames-keepattributes *Annotation*-dontpreverify-verbose-dontwarn android.support.**-keep public class com.google.vending.licensing.ILicensingService-keep public class com.android.vending.licensing.ILicensingService# keep setters in Views so that animations can still work.# see http://proguard.sourceforge.net/manual/examples.html#beans-keepclassmembers public class * extends android.view.View &#123; void set*(***); *** get*();&#125;# We want to keep methods in Activity that could be used in the XML attribute onClick-keepclassmembers class * extends android.app.Activity &#123; public void *(android.view.View);&#125;-keepclassmembers class * extends android.os.Parcelable &#123; public static final android.os.Parcelable$Creator CREATOR;&#125;-keepclassmembers class **.R$* &#123; public static &lt;fields&gt;;&#125;-keep class * extends android.app.Activity-keep class * extends android.app.Service-keep class * extends android.content.BroadcastReceiver-keep class * extends android.content.ContentProvider# Also keep - Enumerations. Keep the special static methods that are required in# enumeration classes.-keepclassmembers enum * &#123; public static **[] values(); public static ** valueOf(java.lang.String);&#125;# Keep names - Native method names. Keep all native class/method names.-keepclasseswithmembers,allowshrinking class * &#123; native &lt;methods&gt;;&#125; 恩，由此可见其实GUI工具只是给我们提供了一个方便操作的平台，背后工作的原理还是通过这些配置来实现的，相信上面的配置内容大家应该都能看得懂了吧。接下来我们还可以点击Save configuration按钮来保存一下当前的配置文件，这样下次混淆的时候就可以直接Load进来而不用修改任何东西了。最后点击Process!按钮来开始混淆处理，中间会提示一大堆的Note信息，我们不用理会，只要看到最终显示Processing completed successfully，就说明混淆Jar包已经成功了，如下图所示： 混淆后的文件我将它配置在了/Users/guolin/androidtest_obfuscated.jar这里，如果反编译一下这个文件，你会发现和刚才反编译APK得到的结果是差不多的：MainActivity的类名以及从父类继承的方法名不会被混淆，NativeUtils的类名和其中的native方法名不会被混淆，Utils的methodUnsed方法不会被移除，因为我们禁用了Shrink功能，其余的代码都会被混淆。由于结果实在是太相似了，我就不再贴图了，参考本篇文章第一部分的截图即可。 好了，本篇文章的内容就到这里，混淆技术掌握这么多相信已经足够大家在平时的工作当中使用了。当然除了使用混淆之外，还有一些加固软件也能提升程序的安全性，不过这些软件都是第三方的，并非Google原生支持，所以我就不进行讲解和推荐了。那么我们Android安全攻防战系列的文章到此结束，感谢大家有耐心看到最后。 关注我的技术公众号，每天都有优质技术文章推送。关注我的娱乐公众号，工作、学习累了的时候放松一下自己。 微信扫一扫下方二维码即可关注：","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"多媒体技术基础之---重新认识声音","date":"2017-02-27T03:25:06.000Z","path":"2017/02/27/Program/Concepts/the-essence-of-sound/","text":"wjlkoorey 声音一个最基本的常识就是“它是一种能量”，初中物理课上我们也学过声音的三要素分别是音色、音调和响度。 音色：简单理解，就是一种声音的固有特征。比如，电子琴和小提琴发出的声音是有明显区别的，笛子和古筝也有各自的声音特征。有些声音模仿秀的选手可以通过训练，达到模仿不同人或者不同乐器的效果。 音调：也就是我们所说的频率，单位是赫兹Hz，频率越高听起来越刺耳、越尖锐，频率越低听起来越低沉、越浑厚。医学研究表明，人的听觉系统能察觉的最低频率为20Hz，最高为20000Hz，超出这个范围人类一般就听不到了。其实现实生活中根本就不存在完全能听到20Hz~20kHz这样的人，并且随着年龄的增长、体质的变化，人能听到的声音只会是这个区间的一个子集。 人对不同频率、不同分贝的声音的生理反应也是有差别的，正如我们中医里提到的“五音”(角、徵、宫、商、羽)和身体脏腑(心、肝、脾、肺、肾)以及对人心神(喜、怒、忧、思、悲)的影响是一样的。 例如“宫”调，风格悠扬沉静、淳厚庄重，根据五音通五脏的理论，宫调入脾，对消化系统的作用比较明显。这就是为什么很多古代电视或者电影里，皇庭寿宴席的时候一般都是奏宫乐。如果对中华文化感兴趣的朋友肯定注意到，我们古代繁体字的药材的“藥”和音乐的“樂”的字根是一样的，可见老祖宗造字时并不是瞎画的，这说明声音的确还是可以治病。现在精通音律的老师傅是越来越少了。感慨一句，中华文明，博大精深，后继者何也？呜呼。。。扯远了，收一下。 而人一般能发出的声音频率也是男女有别，大致范围如下： 低音中音高音男82 Hz～392Hz123 Hz～493Hz164 Hz～698Hz女220 Hz～1.1kHz 响度：就是声音的大小，一般用“分贝”来表示，单位是dB，这个参数说明了声音所携带的能量的大小，声音越大，在相同传播介质里所能传递的距离就远。 在物理世界里，我们的声音在传输过程中都是连续，像下面这个样子： 可是如果要让计算机来处理它，就牵扯到我们经常说的数字化了。关于声音在数字化过程中有三个核心步骤：采样、量化和编码。 采样：在模拟声音的时间轴上周期性地取点，将时域连续的模拟信号变成离散信号的过程就叫做采样。每秒钟的采样点越多，数字化之后的声音就越接近原模拟声音。每秒钟的采样次数就叫做采样频率，根据奈奎斯特定律，采样频率fs和被采样声音的最高频率fmax的关系如下： fs≥2fmax PS：有些地方把声音的频谱范围也叫做声音的带宽，指的是声音从最低频率到最高频率之间的宽度。 量化：用于表示在采样点所获取的声音能量值。量化就是将空域连续的模拟信号转换成离散信号的过程。量化精度越高，所能表示的声音采样范围就越大，量化误差就也越小，相应地，所占用的存储空间也就越大。简而言之，就是对于采样所得到的样本点，我们打算用几位二进制数来表示它。例如，如果是8bit的量化精度，那么我们最多能表示的采样点就只有256个；如果是16bit，最多能表示的采样点就可以多达65536个。 编码：对于经过采样量化后的数据按一定的算法进行编码处理。在计算机里最接近模拟声音的编码方式就是PCM脉冲编码方式。那么对于上述量化结果，我们发现这段音频采样点的量化空间最多也就是11个，我们用4bit就可以完全表示它们了。所以量化精度就是4bit，可表示的样本空间是[0~15]，因此，上述编码序列就是{3，5，6，7，8，5，4，8，10，8，5，1，1，2，5}。 当然，真正到了量化阶段时又分均匀量化和非均匀量化，量化的同时就自动编码成PCM格式的数据了。通常意义来说，量化和编码都是同时进行的。 ITU-T建议的G.711是最早公布的语音编码标准，它规定了A律13折线和u律15折线PCM编码的两种方案。这里就不再继续展开了，都是数学层面的东东，不纠结。中国和欧洲采用的A律13折线的PCM编码方式，北美和日本采用的是u律15折线的PCM编码方式。 在计算机里我们就认为PCM就是数字音频信号的原始无损格式，其存储方式通常是.wav文件，即wav格式的音频文件就是原始的未经任何压缩处理的数字音频文件，这样的文件大部分情况下都来自于录音设备。如果你使用音频格式转换工具将mp3转成wav的话，那么很不幸的是你的这个wav并不是无损格式的文件，因为mp3格式的文件是对原始wav文件经过有损压缩后得来的，而这个过程不是可逆的，即mp3转成的wav只有原始wav的部分信息。但从人的听觉系统来说，一般人是分辨不出来其中的差别，除非用专业发烧级音响设备，再加上一双有着专业特性的耳朵，区别还是很明显的。 例如，我们手头现在有款奥林巴斯的LS-14专业数码录音笔，我们将采样频率设为44100Hz，量化精度为16bit，采用双声道的模式进行音频录制，每秒钟所产生的数据量为44100x16x2=176400 bit，那么3分钟将会产生的声音数据约为30.28MB。显然，这个结果显然不太令人满意，接下来就有了各种音频压缩算法的出现，也就是多媒体技术术语里所说的编码器，其实就是压缩算法而已。目的只有一个：在高保真原有音质的前提下，最大限度地对数字化之后的PCM编码文件进行压缩，以降低其所占的磁盘空间。整个过程可以描述如下： 幸运的是，现在PCM编码方式已经固化在很多音频设备的DSP芯片里了，不需要我们关心。一种编码算法一定对应一种相应的解码算法才行，不然编来有毛用。我们可以看到，整个过程中PCM编码格式充当了各种编解码器之间转换的中间桥梁，这也就是为什么我们说PCM格式的声音文是计算机里的“模拟文件”的原因了。不管是不同音频压缩格式之间的互相转换，还是最终输送给数模转换器的格式都是PCM格式。上面几种格式里有个flac和其他几种格式有着本质的区别，flac是无损压缩格式，和它齐名还有家喻户晓的ape格式。什么意思？无损格式的音频文件是在对原始wav文件压缩是没有删减过滤它的任何信息的情况下，完全通过算法活生生的把wav文件的体重给减了下来，而且flac和ape可以完整还原原始wav的所有信息，一个毫毛都不差。ape的压缩比高达55%。这和那些有损压缩的mp3、ogg、aac等是没法相比的，因为人家是无损的，就这么简单。有些人喜欢听CD，而另外一些人则喜欢听mp3，其实他们根本就不是一个级别的，也没有可比性的。最后，献上天王的一首单曲以飨各位看官肯花宝贵的时间听我在这里唧唧歪歪的大半天，配上森海或者AKG的耳机好好享受一下生活吧(不敢保证每个人能都听到那种感觉，毕竟人家mp3也不是盖的)。 人生不止眼前的代码和BUG，还有耳朵与音乐。 附件：Billie.Jean-ape和Billie.Jean-mp3 多媒体技术基础之—Come on！来点儿音乐吧其实要说在Linux系统下播放音乐，确实是一件让人非常抓狂的事情，抛开各种音频格式的商业授权不说，即使提供给你相应的解码库，能玩儿得转的人那又是少之又少。可能有些盆友说ubuntu这方面确实做得不错，一旦默认安装好，几乎不用装任何其他东西，常见的是音频文件都可以正常播放了。因为我天生就有股喜欢折腾的劲儿，所以关于ubuntu确实不怎么感冒，只能说萝卜白菜各有所爱吧。今天我们以wav文件(也就是上一篇博文所提到的PCM格式的音频文件)为例，看看在Linux下怎么播放它，顺便会简单介绍一下Linux系统的音频驱动框架的基础知识。 说到Linux系统下的音频系统驱动框架，最常见的有OSS和ALSA。我们先来简单了解一下这两个框架，以及它们的历史渊源。 OSS全称是Open Sound System，叫做开放式音频系统，最早是Unix系统上一种统一的音频接口。这种基于文件系统的统一访问方式，就意味着对声音的操作完全可以像对普通文件那样执行open，read，write和close等操作，这也正是得益于文件系统的强大有力支撑。OSS中，主要提供了一下几种音频设备的抽象设备文件： /dev/mixer：用来访问声卡中内置的混音器mixer，用于调整音量大小和选择音源； /dev/dsp、/dev/audio：读这个设备就相当于录音，写这个设备就相当于放音。/dev/dsp与/dev/audio的主要区别在于所采样的PCM编码方式的不同，/dev/audio使用的是μ律编码(存在这个设备文件的目的主要是为了与SunOS兼容，所以在非SunOS系统中尽量不要使用)，而/dev/dsp使用8-bit（无符号）的线性编码； /dev/sequencer、/dev/sequencer2：主要用于访问声卡内置的，或者连接在MIDI接口的合成器synthesizer。 还有其他的诸如/dev/adsp、/dev/dmmidi、/dev/midi等等，一些不常用的就先不管了。看一下我的CentOS 5.3内核版本2.6.21系统中的音频设备文件： 我们可以直接使用Unix/Linux的命令来放音和录音，例如，命令cat /dev/dsp &gt;xyz 可用来录音，录音的结果放在xyz文件中；命令cat xyz &gt;/dev/dsp播放声音文件xyz。当然，我们还可以通过open、close、read、write、ioctl等这些文件的操作函数直接控制这些设备，达到对声音应用程序级别的访问与控制。那么这么看来OSS应该还算比较完美了，Linux下的声音编程应该没有难度才对，怎么会说Linux下声音变成是一件很头疼的事儿呢？ 其实OSS自从诞生到OSSv3版及其之前，都是Linux的原始声音系统，并集成在内核代码里。当OSS被4Front Technologies收购后，于2002年OSSv4作为商业软件的出现时，它的命运就被我们接下来要介绍的ALSA给改写了。其实严格意义上来说，商业化不是导致OSS没落的根本原因，也有技术层面的因素在，比如OSS的混音功能。由于先天的设计缺陷，OSS对混音的支持非常糟糕，由于当时的声卡本身是支持多路输出的混合，所以OSS就偷懒了，将混音的任务交给了声卡，所以那个年代的程序猿们为了操作混音器，代码里充斥着大量的ioctl函数，现在看起来相当难受。 ALSA全称是Advanced Linux Sound Architecture，叫做Linux系统下的高级音频架构，它主要为声卡提供的驱动组件，以替代原先的 OSS。这个项目最早始于1998年Gravis Ultrasound所开发的驱动，它一直作为一个单独的软件包开发，直到2002年他被引进入Linux内核的开发版本(2.5.4-2.5.5)。自从2.6版本开始ALSA成为Linux内核中默认的标准音频驱动程序集，而OSS则被标记为废弃。所以，现在看来OSS被ALSA替代，闭源和商业化都只是外因，内因还是其设计的缺陷。虽然2007年4Front又宣布OSSv4重新在GPL协议下重新开源，但已经人去楼空秋已暮了，现在ALSA对OSS的支持也比较好了，不知道OSS还能否王者归来。其实这些都不重要，对于开发者来说，简单、便捷、高效、实用才是王道，优美的框架结构，完善的文档支持强过口水战百倍。目前ALSA已经成为Linux系统里主流的音频系统框架，在2.6.21的内核里已经看不到OSS的影子了。在内核设备驱动层面，ALSA提供了alsa-driver，同时在应用层，ALSA也为我们提供了alsa-lib，应用程序只要调用alsa-lib所提供的API，就可以完成对底层音频硬件的控制： 上图向我们展示了ALSA的一个简单的结构，用户空间的alsa-lib对应用程序提供统一的API接口，这样可以隐藏了驱动层的实现细节，简化了应用程序的实现难度。内核空间中，alsa-soc其实是对alsa-driver的进一步封装，针对嵌入式设备提供了一些列增强的功能，通常也被叫做ASoC，即Alsa-soc的缩写，像Android系统中底层就用了ASoC。想了解ALSA更多细节的盆友可以访问他们的官网：http://www.alsa-project.org/main/index.php/Main_Page 下面，我们首先看一下OSS下如何播放wav文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475点击(此处)折叠或打开/*playsound.c*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;linux/soundcard.h&gt;#define AUDIO_DEVICE \"/dev/dsp\"int play_sound(char *filename,int rate,int bits)&#123; struct stat stat_buf; unsigned char *buf = NULL; int result,arg,status,handler,fd; fd = open(filename,O_RDONLY); if(fd&lt;0) return -1; if(fstat(fd,&amp;stat_buf)) &#123; close(fd); return -1; &#125; if(!stat_buf.st_size) &#123; close(fd); return -1; &#125; buf=malloc(stat_buf.st_size); if(!buf)&#123; close(fd); return -1; &#125; if(read(fd,buf,stat_buf.st_size)&lt;0)&#123; free(buf); close(fd); return -1; &#125; handler = open(AUDIO_DEVICE,O_WRONLY); if(-1 == handler)&#123; return -1; &#125; arg = rate*2; status = ioctl(handler,SOUND_PCM_WRITE_RATE,&amp;arg); if(-1 == status) return -1; arg = bits; status = ioctl(handler,SOUND_PCM_WRITE_BITS,&amp;arg); if(-1 == status) return -1; result = write(handler,buf,stat_buf.st_size); if(-1 == result) return -1; free(buf); close(fd); close(handler); return result;&#125;int main(int argc,char** argv)&#123; play_sound(argv[1],atoi(argv[2]),atoi(argv[3])); return 0;&#125; 因为只是演示用，所以错误判断就少了一些。另外，为了让我们的播放程序自动获得音频文件的参数，诸如采样率，量化精度等，我又提供了一个shell脚本player：点击(此处)折叠或打开 #!/bin/sh[ “$#” -eq 0 ] &amp;&amp; {echo “Usage: $0 filename”exit}BITS=file $1 | cut -d&#39; &#39; -f9RATE=file $1 | cut -d&#39; &#39; -f12 echo “Playing…$(file $1)”./playsound $1 $RATE $BITS 将上述C文件编译，然后，在命令行之./player 文件名，不出意外的话就可以听到声音了，只可惜没办法演示这个过程： 我的系统确实可以听到，但是声音比较小，如果你在命令行执行amixer的话，应该可以看到下面的输出信息： 我的声卡音量居然只有75%(因为我用的虚拟机)，然后一句“amixer set Master 100%”命令下去，再重新播放声音，应该就很happy了。 其实大家可能有点疑惑，不是前面介绍了半天ALSA的好处了，怎么用OSS来示范，是不是专拣软柿子捏啊。再说了，现在很多人的系统几乎都不支持OSS了，上面的代码有毛用。其实我也很不甘心，所以又重新装了CentOS6.3的虚拟系统，用ALSA的API再来播一下wav看得行不，经过N个小时的折腾，皇天不负有心人—It’s OK！(新手入门，大家来找BUG吧 :) ) 内核版本2.6.32，看一下/dev目录下确实没有dsp和mixer设备文件了，取而代之的/dev/snd目录。在centos5.3里我们也见到过这个目录，但当时还只是试用阶段，现在alsa已经完全扶正了：播放代码如下：点击(此处)折叠或打开123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;linux/soundcard.h&gt;#include &lt;alsa/asoundlib.h&gt;#define ALSA_MAX_BUF_SIZE 65535int play_sound(char* filename,int rate,int bits,int channel,int order)&#123; long loops; int rc,size,dir; snd_pcm_t *handle; snd_pcm_hw_params_t *params; snd_pcm_uframes_t frames,periodsize; snd_mixer_t *mixer; snd_mixer_elem_t *pcm_element; char *buffer; unsigned int val; FILE *fp = fopen(filename,\"rb\"); rc = snd_pcm_open(&amp;handle,\"default\",SND_PCM_STREAM_PLAYBACK,0); snd_pcm_hw_params_alloca(&amp;params); snd_pcm_hw_params_any(handle,params); snd_pcm_hw_params_set_access(handle,params,SND_PCM_ACCESS_RW_INTERLEAVED); switch(order)&#123; case 1: snd_pcm_hw_params_set_format(handle,params,SND_PCM_FORMAT_S16_LE); break; case 2: snd_pcm_hw_params_set_format(handle,params,SND_PCM_FORMAT_S16_BE); break; defualt: break; &#125; snd_pcm_hw_params_set_channels(handle,params,channel); val = rate; snd_pcm_hw_params_set_rate_near(handle,params,&amp;val,0); snd_pcm_hw_params_get_buffer_size_max(params,&amp;frames); frames = frames &lt; ALSA_MAX_BUF_SIZE? frames:ALSA_MAX_BUF_SIZE; rc = snd_pcm_hw_params_set_buffer_size_near(handle,params,&amp;frames); snd_pcm_hw_params_get_period_size_min(params,&amp;periodsize,NULL); if(!periodsize)&#123; periodsize=size/4; &#125; rc = snd_pcm_hw_params_set_period_size_near(handle,params,&amp;periodsize,NULL); rc = snd_pcm_hw_params(handle,params); snd_mixer_open(&amp;mixer,0); snd_mixer_attach(mixer,\"default\"); snd_mixer_selem_register(mixer,NULL,NULL); snd_mixer_load(mixer); for(pcm_element = snd_mixer_first_elem(mixer);pcm_element;pcm_element=snd_mixer_elem_next(pcm_element)) &#123; if(snd_mixer_elem_get_type(pcm_element)==SND_MIXER_ELEM_SIMPLE &amp;&amp; snd_mixer_selem_is_active(pcm_element)) &#123; if(!strcmp(snd_mixer_selem_get_name(pcm_element),\"Master\")) &#123; snd_mixer_selem_set_playback_volume_range(pcm_element,0,100); snd_mixer_selem_set_playback_volume_all(pcm_element,(long)100); &#125; &#125; &#125; buffer = (char*)malloc(size); while(1) &#123; rc = fread(buffer,1,size,fp); if(0== rc) break; while((rc = snd_pcm_writei(handle,buffer,size))&lt;0) &#123; usleep(200); if(-EPIPE == rc) snd_pcm_prepare(handle); else if(0 &gt; rc) printf(\"error fomr writei\\n\"); &#125; &#125; snd_pcm_drain(handle); snd_pcm_close(handle); free(buffer); snd_mixer_close(mixer); fclose(fp); return 0;&#125;int main(int argc,char** argv)&#123; play_sound(argv[1],atoi(argv[2]),atoi(argv[3]),atoi(argv[4]),atoi(argv[5])); return 0;&#125; 然后将player脚本也对应修改一下： 点击(此处)折叠或打开#!/bin/sh[ \"$#\" -eq 0 ] &amp;&amp; &#123;echo \"Usage: $0 filename\"exit&#125;ORDER=`file $1 | cut -d' ' -f3`BITS=`file $1 | cut -d' ' -f9`CHANNEL=`file $1 | cut -d' ' -f11`RATE=`file $1 | cut -d' ' -f12`#channelif [ \"$CHANNEL\" == \"stereo\" ]; thenCHANNEL=2elseCHANNEL=1fi#platform-byte-orderif [ \"$ORDER\" == \"(little-endian)\" ]; thenORDER=1elseORDER=2fiecho \"Playing...$(file $1)\"./playsound $1 $RATE $BITS $CHANNEL $ORDER 编译C文件时，由于我们用了alsa库，所以gcc的编译选项要加上-lasound才可以。如果播放时声音很小，可以用amixer来调节音量。如果不幸的是你系统里找不到amixer命令的话，就用yum install alsa-utils或者下载alsa源码来安装吧。 附件是测试用的音频文件，另外，后面我会将完整支持OSS和ALSA两种架构的最终播放代码放在github上，有需要的盆友到时候可以拿去鼓捣鼓捣，今天就先到这里吧。 附件:news.wav CentOS6.4完全安装FFmpeg手记 鼓捣媒体的人对FFmpeg应该不会陌生，它不仅功能强大，结构优美，灵活、易扩展，也是很其他多媒体播放器的基础，例如VLC，Mplayer等等，还有好多商业播放器都用了ffmpeg，但这些商业软件却没有遵守GPL公约，所以它们都被钉在了ffmpeg官网的“耻辱柱”上。关于ffmpeg还有一点题外话，那就是有一个叫做libav的开源项目。libav是从ffmpeg分化出来的一个项目，而这个项目诞生的原因和技术本身并没有任何关系，最大的分歧在于ffmpeg内部有一帮人对于ffmpeg项目的管理方式觉得不happy了，所以他们就自立门户，成立了libav这个项目。有意思的是libav官网的logo和ffmpeg官网的logo有点“小过节”，libav把ffmpeg官网那个偏着脑袋的logo给端正了，至于他们想传达的意义我觉得每个人都应该有自己的理解和认识。好了，开场预热就到这里，该干活了。 CentOS6.4的内核版本2.6.32-358，GCC版本是4.4.7，安装ffmpeg的版本是1.2，ffmpeg官网最新的版本是2.1，看着版本号差异挺大，其实从1.2到2.1中间仅隔了一个2.0版，是2013年7月10号刚发布。 安装前的准备工作当然是先安装各种工具： 点击(此处)折叠或打开[root@localhost src]# pwd/usr/local/src[root@localhost src]# yum install automake autoconf make gcc gcc-c++ libtool zlib zlib-devel curl curl-devel alsa-lib alsa-lib-devel gettext gettext-devel expat expat-devel ffmpeg作为一个多媒体框架和平台，最大的优势就在于可以很灵活地支持多种编解码和其他特性，只要第三方外部库支撑都可以做到。本次安装下列第三包依赖包： faac：全称是Free Advanced Audio Coder，是MPEG-4和MPEG-2 AAC的一款常用的开源编解码器； lame：一款常见的mp3的开源编解码器； libass：先说一下ASS/SSA，其全称是Advanced Substation Alpha/Substation Alpha，是一种功能极为强大的字幕格式，主要用在视频文件里显示字幕。而libASS是一个轻量级的对ASS/SSA格式字幕进行渲染的函数库，使用C编写,效率非常高； libdc1394：这是面向高级语言编程接口的一个库，主要提供了对符合IEEE 1394规范的数码摄录设备的一组操作接口。符合1395规范的数码相机标准的全称是1394-based Digital Camera Specifications，简称为IIDC或DCAM。安装dc1394需要先安装raw1394； libfreetype2：freetype是一个用C语言实现的一个字体光栅化库，它可以用来将字符栅格化并映射成位图以及提供其他字体相关业务的支持。freetype提供了一个简单、易用并统一的接口来访问字体文件的内容。freetype不仅被自由桌面系统软件所使用，同时它也是现代视频游戏广泛使用的栅格化引擎； libvorbis：这个库主要用于处理ogg格式的音频文件，而ogg全称是ogg vorbis，一种类似mp3的音频压缩格式。不同于mp3的是ogg完全免费、开放和没有专利限制的。ogg文件格式可以不断地进行大小和音质的改良，而不影响旧有的编码器或播放器，主要由Xiph.org基金会开发； libtheora：theora也是Xiph.org基金会开发，是一种有损的影像压缩格式； openssl：这个就不多说了，很多安全框架的基础； rtmpdump：一个开源的rtmp格式的流媒体库，RTMP(Real Time Messaging Protocol)是Adobe Systems公司为它自家的flash播放器和服务器之间音频、视频和数据传输开发的一种开放的传输协议； speex：speex是一套主要针对语音的开源免费、无专利保护的音频压缩格式，致力于通过提供一个可以替代高性能语音编解码来降低语音应用输入门槛。相对于其它编解码器，speex非常适合网络应用，因为它专为2-44kpbs语音码流所设计，所以在网络应用上有着自己独特的优势； twolame：一个开源的mp2格式的编解码库； vo-aacenc：AAC格式的常用的音频编码器； xvidcore：是一个开放源代码的MPEG-4视频编解码器； x264：目前最流行，最常见的H.264视频格式的一个开源的编解码器； 将需要的软件包全部下载后，剩下的事儿就非常简单：“三大步”—configure &amp;&amp; make &amp;&amp; make install 安装顺序如下：faac、lame、libtheora(需要先安装libogg)、libvorbis、vo-aacenc、xvidcore、x264、libdc1394(需要先安装libraw1394)、libass(需要先依次安装libfreetype2、fribidi和fonconfig)、openssl、librtmp、libspeex、twolame、yasm，最后安装ffmpeg。 在通过源码包安装上述软件时，如果在configure阶段没有用–prefix指定安装目录，默认情况下安装的顶级目录是/usr/local，可执行程序会被安装到/usr/local/bin，动态库被安装到/usr/local/lib，头文件在/usr/local/include等等。这样会有一个小小的麻烦，例如当先安装libogg后，再安装libtheora时，你有可能会收到如下的错误提示信息：checking pkg-config is at least version 0.9.0… yeschecking for OGG… nochecking for Ogg… no Could not run Ogg test program, checking why… The test program compiled, but did not run. This usually means that the run-time linker is not finding Ogg or finding the wrong version of Ogg. If it is not finding Ogg, you’ll need to set your LD_LIBRARY_PATH environment variable, or edit /etc/ld.so.conf to point to the installed location Also, make sure you have run ldconfig if that* is required on your system If you have an old version installed, it is best to remove it, although you may also be able to get things to work by modifying LD_LIBRARY_PATHconfigure: error: libogg is required to build this package! please see http://www.xiph.org/ for how to obtain a copy. 明明安装了ogg但theora却认为咱们没安装。原因在哪里，当然是动态库的查找路径了，想了解详情的童鞋请移步这里。我的解决办法是在 /etc/ld.so.conf.d/目录下创建一个名为local-libraries.conf的文件，内容很简单，只有一行： 点击(此处)折叠或打开[root@localhost src]# cat /etc/ld.so.conf.d/local-libraries.conf/usr/local/lib[root@localhost src]# 然后执行ldconfig -v，然后再安装libtheora就很happy了。 当然还没完，当你在安装libass时，当你把所有依赖包都先安装之后，在configure阶段，它总会提醒你说：Package requirements (freetype2 &gt;= 9.10.3) were not met 任凭你怎么执行ldconfig都没用。不过你要是注意到错误提示信息其实问题的解决也就挺简单，在configure阶段在探测依赖包时用到了一个叫做pkg-config的工具，它会自动去查找当前系统是否支持某些类型的动态库文件，主要是通过一个.pc文件。而一些标准so库源码包里都会提供一个这样的文件以便pkg-config来用，而问题就在pkg-config查找.pc文件的路径上。关于这个工具更多细节就不展开了，感兴趣的朋友可以去google一下。这里我的解决办法是： 点击(此处)折叠或打开[root@localhost libass-0.10.1]# export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH 然后安装libass时也就很happy了。 最后，在安装ffmpeg前需要先安装yasm，版本至少1.2.0以上。 下面是我的安装ffmpeg时相关软件包的配置情况，以便各位参考： 1 faac[root@localhost faac]#./bootstrap[root@localhost faac]#./configure –prefix=/usr/local/ –enable-shared[root@localhost faac]#make &amp;&amp; make install 2 lame[root@localhost lame-3.98.4]#./configure –prefix=/usr/local/ –enable-shared[root@localhost lame-3.98.4]#make &amp;&amp; make install 3 libogg[root@localhost libogg-1.3.0]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libogg-1.3.0]#make &amp;&amp; make install 4 libtheora[root@localhost libtheora-1.1.1]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libtheora-1.1.1]#ldconfig -v[root@localhost libtheora-1.1.1]#make &amp;&amp; make install 5 libvorbis[root@localhost libvorbis-1.3.3]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libvorbis-1.3.3]#make &amp;&amp; make install 6 vo-aacenc[root@localhost vo-aacenc-0.1.2]#./configure –prefix=/usr/local/ –enable-shared[root@localhost vo-aacenc-0.1.2]#make &amp;&amp; make install 7 xvidcore[root@localhost xvidcore-1.3.2]#./configure –prefix=/usr/local/[root@localhost xvidcore-1.3.2]#make &amp;&amp; make install 8 yasm[root@localhost yasm-1.2.0]#./configure –prefix=/usr/local/[root@localhost yasm-1.2.0]#make &amp;&amp; make install 9 x264[root@localhost x264-snapshot-20130505-2245]#./configure –prefix=/usr/local/ –enable-shared –enable-pic[root@localhost x264-snapshot-20130505-2245]#make &amp;&amp; make install 10 libraw1394[root@localhost libraw1394-2.0.5]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libraw1394-2.0.5]#make &amp;&amp; make install 11 libdc1394[root@localhost libdc1394-2.2.1]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libdc1394-2.2.1]#make &amp;&amp; make install 12 libfreetype[root@localhost libfreetype2-master]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libfreetype2-master]#make &amp;&amp; make install 13 fribidi[root@localhost fribidi-0.19.4]#./configure –prefix=/usr/local/ –enable-shared[root@localhost fribidi-0.19.4]#make &amp;&amp; make install 14 fonconfig[root@localhost fontconfig-2.9.0]#./configure –prefix=/usr/local/ –enable-shared[root@localhost fontconfig-2.9.0]#make &amp;&amp; make install 15 libass[root@localhost libass-0.10.1]#./configure –prefix=/usr/local/ –enable-shared[root@localhost libass-0.10.1]#make &amp;&amp; make install (xuyao ) 16 openssl[root@localhost openssl-1.0.1c]#./config –prefix=/usr/local/ –openssldir=/usr/local/openssl threads zlib-dynamic shared[root@localhost openssl-1.0.1c]#make &amp;&amp; make install 17 librtmp[root@localhost rtmpdump-2.3]#make SYS=posix[root@localhost rtmpdump-2.3]#make install 18 libspeex[root@localhost speex-1.2rc1]#./configure –prefix=/usr/local/ –enable-shared –enable-sse[root@localhost speex-1.2rc1]#make &amp;&amp; make install 19 twolame[root@localhost twolame-0.3.13]#./configure –prefix=/usr/local/ –enable-shared[root@localhost twolame-0.3.13]#make &amp;&amp; make install 20 FFmpeg[root@localhost ffmpeg-1.2]#./configure –prefix=/usr/local/ –enable-gpl –enable-version3 –enable-nonfree –enable-shared –enable-zlib –enable-bzlib –enable-libfaac –enable-libmp3lame –enable-libtheora –enable-libvo-aacenc –enable-libvorbis –enable-libx264 –enable-libxvid –enable-pic –enable-pthreads –enable-libdc1394 –enable-libass –enable-pic –enable-openssl –enable-libtwolame –enable-libspeex –enable-librtmp –enable-libfreetype[root@localhost ffmpeg-1.2]#make &amp;&amp; make install 安装完成后，测试一下： 为了方便各位测试，本文中用到的所有软件包已经放在网盘里，有需要的朋友请到这里下载。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Multimedia","slug":"Multimedia","permalink":"http://ipcreator.me/tags/Multimedia/"}]},{"title":"多媒体技术基础之---视频","date":"2017-02-27T03:19:06.000Z","path":"2017/02/27/Program/Concepts/the-essence-of-video/","text":"wjlkoorey 我们都知道，视频本质上源于电影。2014年冯导的《私人订制》里葛大爷对“全球最俗大导”说了那么一番话，印象比较深刻：“经过考证，电影是大众娱乐，起源于走马灯。本身就是一俗艺术，和雅压根儿就不沾边。”而当代科学史研究者们大都依据文学家范成大（1126—1193）的诗文记载，认为南宋时才有走马灯。走马灯的两个主要特点分别是：一、利用热气流作动力；二、以涡轮装置带动灯上画面转动。 以这两点继续追溯可以到北宋年间，著名北宋诗人吴潜观灯有感，写下:“半勺兰膏暖焰生，恍疑赤壁夜鏖兵。骑乘猛燎奔驰疾，人运长枪转战轻。旗影静移云母帐，剑铓微掣水晶营。何人幻此圆机妙，独向元宵策美名。”从内容到形式详述走马灯闪亮登场的过程。也就是说走马灯距今已有将近1300多年的历史了。然而，在当代电影起源发展史上走马灯却很少被人提起。 关于电影的起源，美国人会告诉你说是爱迪生发明的；法国人会说是卢米埃尔兄弟发明的。其实 电影是建立在一种名为“视觉暂留原理”的基础上。人脑保留视像的时间会比眼睛真正记录它的时间略长一点。如果不是这样，我们对世界的视觉感知就会不断被眨眼的动作打断。但实际上，在双眼闭上的那一刹那，大脑会“保存”视像。类似地，当静止的图像以最短的间隔从人眼前闪过时，大脑也会发挥保存图像的作用。电影不是真的在动，而是一组以每秒24格的速度放映的静止画面，这样的速度使人觉得动作是连续的。 该原理是比利时著名物理学家约瑟夫普拉多于1829年发现。随后，普拉多依据此原理于1832年发明了“诡盘”。“诡盘”能使被描画在锯齿形的硬纸盘上的画片因运动而活动起来，而且能使视觉上产生的活动画面分解为各种不同的形象。“诡盘”的出现，标志着电影的发明进入到了科学实验阶段。随后的美国人霍尔纳、奥地利的冯乌却迪奥斯、法国的W尼埃普斯、美国旧金山摄影师爱德华幕布里奇、法国生理学家马莱都为随后电影业的发展做出过巨大的贡献。 1889年，美国发明大王爱迪生在发明了电影留影机后，又经过5年的实验后，发明了电影视镜。他将摄制的胶片影像在纽约公映，轰动了美国。但他的电影视镜每次仅能供一人观赏，一次放几十英尺的胶片，内容是跑马、舞蹈表演等。他的电影视镜是利用胶片的连续转动，造成活动的幻觉，电影视镜传到我国后被称之为 “西洋镜”。如果大家看过徐克导演，李连杰、关之琳主演的《黄飞鸿》，“十三姨”手里经常拿着的那个拍电影的东西就是西洋镜。但“十三姨”那会儿用的西洋镜已经是法国卢米埃尔兄弟改良过之后的版本。 1895年，法国的奥古斯特卢米埃尔和路易卢米埃尔兄弟，在爱迪生的 “电影视镜”和他们自己研制的 “连续摄影机”的基础上，研制成功了“活动电影机”。“活动电影机”有摄影、放映和洗印等三种主要功能。它以每秒16画格的速度拍摄和放映影片，图像清晰稳定。1895年3月22日，他们在巴黎法国科技大会上首放影片《卢米埃尔工厂的大门》获得成功。同年12月28日，他们在巴黎的卡普辛路14号大咖啡馆里，正式向社会公映了他们自己摄制的一批纪实短片，有《火车到站》、《水浇园丁》、《婴儿的午餐》、《工厂的大门》等12部影片。卢米埃尔兄弟是第一个利用银幕进行投射式放映电影的人，因此他们也被后人誉为近代电影的开山鼻祖。 这里我们来看一下电影中“帧”的概念。根据“视觉残留原理”24帧/秒是可以给人带来基本流畅、感觉不到卡顿的基本体验的最低播放频率。 传统的电影都是用连续长胶片拍摄，主要在银幕上播放。另外还有一点，就是电影在放映时胶片是连续的。例如，前面一个胶片离放映窗还有2/3的距离时，下一张胶片的1/3就已经进入放映窗了。这样一来老式电影播放时会经常出现时快时慢，无连续感等现象。所以在放映电影时通常都会给放映窗口增加一个遮光器，即放映窗有个电机带动着一个黑色的扇叶不停的转动，将每格胶片遮挡两次，这样就将每秒24帧的频率提升一倍到48Hz(注意：早期电影的拍摄和放映仍旧是以24帧/秒的帧率进行的)，这样一来我们的眼睛就会觉得图像更加连贯和流畅了。 当模拟电视出现后，出现了一对名词“隔行扫描”和“逐行扫描”，以及PAL制和NTSC制两个概念。为了不冲淡主题，关于这两个知识点大家可以如果想进一步了解，可以点击“这里”。简而言之，在隔行扫描的显示设备中，每一帧图像被分割为两场画面交替显示。第一场(奇数场)电子枪只扫一帧图像的所有描奇数行，依次扫描1、3、5…行，而第二场(偶数场)电子枪只扫描偶数行，依次扫描2、4、6…行等等。逐行扫描显示一帧图像时，电子枪只要一行接着一行扫，不用区分奇偶场，扫完所有行就OK了。关于PAL制和NTSC制区别记住下述两点： PAL制电视机供电频率50Hz，场频50场/秒，帧频率25帧/秒，扫描线625行。代表国家中国、德国、新加坡等； NTSC制电视机供电频率60Hz，场频60场/秒，帧频30帧/秒，扫描线525行。代表地区美国日本等。 当然，不管是通过无线电还是互联网来传输电影或者视频，都避不开数字化的话题。现在的数字摄像机已不像传统的胶片摄像机那样简陋，数字摄像机在拍摄的时候我们只要设置好我们需要的参数就可以了。那么在数字视频中，帧的概念已经不同于传统胶卷上一个图像的意义了。之前我们计算过，一部1024×768分辨率，采用aRGB色彩空间存储，8位深度，时常90分钟的视频，需要占用的带宽是3Mbps，占用的存储空间是15.83GB左右。 所以，对于数字图像，我们一般有两方面的压缩。一是帧内压缩，就是采用YUV色彩空间，然后配合各种压缩算法(例如H.264，mpeg4等等)在不影响用户视觉体验的前提下，最大限度的降低图像本身所占用的空间；二是帧间压缩，因为通常情况下，相邻两帧图像之间其实有很多重复，相似信息，可以采用帧间自适应、行程编码、预测编码、运动补偿等方式。 采用压缩算法时，在制作或者转换视频时一般将几帧图像分为一个组GOP，为了防止运动变化，帧数不宜过多。在用ffmpeg转换视频时有一个参数可以设置这个GOP。数字视频里每个帧都被归成三类：关键帧I，非关键帧P或者B。一个GOP就是一个I帧、数个P、B帧的分组。 I帧：表示关键帧，是一帧画面的完整的所有信息；解码时只需要本帧数据就可以显示画面； P帧：表示前向预测帧，表示的是这一帧跟之前的一个关键帧I（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面； B帧：是双向预测帧，即B帧是本帧与前后帧的差别。B帧一般需要参考其前向的I帧或者P帧，以及后一个P帧的数据才能完整解码一帧图像数据。 所以说，只有关键帧才可以独立的完整复原图像，P帧和B帧都是图像的相对信息差量，他们单独存在时并不能完整解码视频文件的一帧图像信息。 说的云里雾里的，让我们看个实际的例子。那就是本周五即将上映的《美国队长2》的宣传片： 我们用Elecard截取其中一个片段，看一下它的帧编码、显示顺序情况： 这个文件的帧编码信息是，红色为I帧，蓝色为P帧，绿色为B帧，其帧编码顺序是： IPPPPPPPPPPPPPPPPPPPBBPBBPBBPBBBPBBPBPBPBBP… 但是显示设备解码显示时却不能按照这样的顺序进行，为什么？因为解码B帧时需要参考其前面的I帧或者P帧，以及后面的P帧才可以完整解码B帧的画面。下面我们将用表格分析一下帧的显示顺序和编码顺序的区别：(为了画表格方便，我将I帧后面紧挨着的19个P帧缩减为3个，但这并不影响分析效果)。修改后的编码顺序为： 视频帧编码顺序和显示顺序分别如下表所示： 本文只是简单对视频文件中基本帧的概念作了介绍，方便入门的朋友学习了解。至于编解码、音视频同步、显示等技术领域暂时还不涉及，有需要再说吧。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Multimedia","slug":"Multimedia","permalink":"http://ipcreator.me/tags/Multimedia/"}]},{"title":"多媒体技术基础之---图像","date":"2017-02-27T03:04:06.000Z","path":"2017/02/27/Program/Concepts/the-essence-of-picture/","text":"wjlkoorey 2012年11月13日，83岁的柯达公司退休工程师布赖斯·拜尔(Bryce Bayer)离开了这个世界，永远离开了我们，离开了爱戴他的人们，而他在数字图像领域的杰出成就不应该就这样被淹没在历史的洪流里，所以，谨以2014年第一篇博文献给伟大的布赖斯·拜尔先生。 图像的历史 根据维基百科的记载，世界上的第一张照片是法国人约瑟夫·尼塞福尔·涅普斯于1826年拍摄完成。1825年时，涅普斯委托法国光学仪器商人夏尔·雪弗莱（Charles Chevalier）为他的暗箱（camera obscura）制作光学镜片，并于1826年(有说1827年)将其发明的感光材料放进暗箱，拍摄现存最早的照片。作品在其法国勃艮第的家里拍摄完成，通过其阁楼上的窗户拍摄，曝光时间超过8小时。 当年，他拍照时采用的感光剂是氯化银(silver chloride)。氯化银的一个非常重要的特性是当光线照射氯化银时，氯化银会分解成纯银和氯气，纯银在空气中很快氧化变成黑色。因此，底片颜色越深代表光线越强，颜色越浅代表光线越弱。黑白照片就是这样拍出来的。为了避免冲淡主题，如果想了解照片又是如何洗出来的盆友们，请点击[这里](http://zhishi.maigoo.com/7845.html)。 为了了解图像基础，我们首先需要一些额外知识来做铺垫和填充：图像的本质。不像声音，图像其实是我们人的视觉系统对外界的一种感受。 听着有点玄乎，还是让我们先从彩色图像说起吧！(因为黑白图像实在太简单了) 图像的本质 人类的视觉系统为什么能感知各种各样的颜色呢？这个问题最早可以追溯到18世纪，当时的Young（1809）和Helmholtz（1824）共同提出了人类视觉的三原色学说(也就是我们现在经常说提到的RGB色彩空间的鼻祖)，他们认为即：人类的视网膜存在三种视锥细胞，分别含有对红、绿、蓝三种光线敏感的视色素，当一定波长的光线作用于视网膜时，以一定的比例使三种视锥细胞分别产生不同程度的兴奋，这样的信息传至中枢，就产生某一种颜色的感觉。 到了70年代，由于实验技术的进步，关于视网膜中有三种对不同波长光线特别敏感的视锥细胞的假说，已经被许多出色的实验所证实。例如： ①有人用不超过单个视锥直径的细小单色光束，逐个检查并绘制在体(最初实验是在金鱼和蝾螈等动物进行，以后是人)视锥细胞的光谱吸收曲线，发现所有绘制出来的曲线不外三种类型，分别代表了三类光谱吸收特性不同的视锥细胞，一类的吸收峰值在420nm处，一类在534nm处，一类在564nm处，差不多正好相当于蓝、绿、红三色光的波长。与上述视觉三原色学说的假设相符。 ②用微电极记录单个视锥细胞感受器电位的方法，也得到了类似的结果，即不同单色光所引起的不同视锥细胞的超极化型感受器电位的大小也不同，峰值出现的情况也符合于三原色学说。 19世纪中期，英国物理学家麦克斯韦以视觉三原色作为前提和假设，提出红绿蓝作为基色，可以拍出彩色图片的论断。1861年，在麦克斯韦的指导下，人类的第一张彩色照片诞生了。拍摄采用的方法也非常简单，就是在镜头前分别用红丝带、绿丝带、蓝丝带过滤光线，曝光形成三张底片，然后用三部放映机向同一处投影这三张底片，每部放映机的镜头前都拧上对应颜色的镜头，它们的合成效果就是一张彩色照片。 然而，真正意义上的彩色胶卷其实是柯达公司1933年生产。虽然2013年柯达刚刚宣布破产，但也无法否认他曾在影像界的王者地位。 图像数字化的原理第二次世界大战结束后，随着原子能技术、微电子、计算机、分子生物和遗传工程等领域的重大突破，标志着人类第三次科技革命的开始。随后的年代里，听到的最多的一个词就是“数字化”，到处都在谈数字化，就像当我们时下都说的“土豪”这个词。那时，如果你和人见面不聊点“e时代”的东西，还真不好意思。 很多人都可能不知道，图像领域数字化的理论基础是爱因斯坦的光电理论，通过图像传感器(image sensor)将光信号转换成电信号，然后再将模拟的电信号转换成数字信号来完成。**图像传感器本质上就是一个感光元件**，它与我们常见的太阳能电池有一些类似之处，**整块感光元件就是一个太阳能电池矩阵，每个像素点对应一个感光单位。** 当光照射到感光单元后，它会测量出光的强度然后产生一个相应的电信号，在经过模数转换电路A/D对电信号进行采样，紧接着是量化和编码并存储。这就是完成了图像的数字化。 然而，图像传感器有个非常大的缺陷：它只能感受光的强弱，无法感受光的波长。由于光的颜色是由波长决定的，所以图像传播器无法记录光的颜色值，也就是说，它只能拍黑白照片，这当然是无法容忍的。在前面麦克斯韦等人的影响下，人们开始尝试如何将彩色图片进行数字化。根据RGB三原色理论，一种解决办法就是照相机内置三个图像传感器，分别记录红、绿、蓝三种颜色，然后再将这三个值合并。这种方法能产生最准确的颜色信息，但是成本太高(现在很多高端大气上档次的人在追求这种模式，也已经有厂家推出了相应的设备，但价格非一般人能负担得起)。 1974年，柯达公司的工程师布赖斯·拜尔提出了一个全新方案，只用一块图像传感器，就解决了颜色的识别。他的做法是在图像传感器前面，设置一个滤光层(Color filter array)，上面布满了滤光点，与下层的像素点逐一对应。也就是说，如果传感器是1600×1200个像素，那么它的上层就有1600×1200个滤光点。 每个感光单元就是一个像素，它前面的遮光片点只能允许通过红、绿、蓝之中的一种颜色，这意味着在它下层的像素点只可能有四种颜色：红、绿、蓝、黑(表示没有任何光通过)，就像给每个像素点都“戴”了一个单色光的过滤眼镜一样。它的工作原理如下： 每个感光单元就像有刻度的小桶，光线就像雨一样洒在小桶里，小桶的容量越大，所能度量的雨的大小范围(图像的动态范围)就越大，桶的刻度越多(色彩位数越高)度量的精度就越高。 有些童鞋可能就纳闷了，既然每个像素点只能记录一种颜色，到底是如何拍出彩色图像的呢？所以说，感光元件上的滤光点的排列是有讲究的，这也是布赖斯·拜尔的智慧：每个绿点的四周，分布着2个红点、2个蓝点、4个绿点。这意味着，整体上，绿点的数量是其他两种颜色点的两倍。这是因为研究显示人眼对绿色最敏感，所以滤光层的绿点最多。 我们可以看到，每个滤光点周围有规律地分布其他颜色的滤光点，那么就有可能结合它们的值，判断出光线本来的颜色。以黄光为例，它由红光和绿光混合而成，那么通过滤光层以后，红点和绿点下面的像素都会有值，但是蓝点下面的像素没有值，因此看一个像素周围的颜色分布有红色和绿色，但是没有蓝色-就可以推测出来这个像素点的本来颜色应该是黄色。这个过程可以表示如下，而这种计算颜色的方法，就叫做”去马赛克”(demosaicing)法： 虽然，每个像素的颜色都是算出来的，并不是真正的值，但是由于计算的结果相当准确，因此这种做法得到广泛应用。目前，绝大部分的数码相机都采用它，来生成彩色数码照片。高级的数码相机，还提供未经算法处理的原始马赛克图像，这就是raw格式(raw image format)。为了纪念发明者布赖斯·拜尔，它被称作”拜尔模式”或”拜尔滤光法” (Bayer filter)。 数码相机成像原理 OK，有了以上知识的普及和扫盲，下面让我们看一下数码相机的成像过程和原理，其实前面已经提到一点。 前面我们提到的那个感光元件，是数码相机或数码录像机的核心部件，目前业界有两种感光介质： 一种是CCD，是英文 Charge Coupled Device (即电荷耦合器件)的缩写，是一种特殊的半导体器件，也是用来采集信号的一种感应元件，技术要求很高，全世界只有 6 家公司掌握了 CCD研制的核心技术，成品率较低，成本较高。 另一种是CMOS，全称是Complementary Metal-Oxide-Semiconductor(即互补金属氧化物半导体)，它在微处理器和闪存等半导体技术上占有重要的地位，也是一种可用来感受光线变化的半导体，其组成元素主要是硅和锗，通过CMOS上带负电和带正电的晶体管来实现基本功能。这两个互补效应所产生的电流即可被处理芯片记录和解读成影像。 无论是CCD还是CMOS，其作用和地位都是完成光信号到电信号的转换。两者之争也是数码界一个亘古以来就很久远的话题，2009以前还是CCD的天下，2009年之后(标志性事件就是2008年索尼发布了背照式CMOS，代号Exmor R)，CMOS一下子又火了，CCD逐渐沦落。随着技术、生产工艺、科技的进步，说不定哪天CCD又把CMOS甩开八百里开外，这个谁也说不准，我们就不搅和到这场口水战里了。这里大家只要知道在数码录制设备里，CCD和CMOS都是感光元器件，完成光电信号的转换对我们来说就OK了。 以前传统相机拍照时，光线通过镜头汇聚，再通过按动快门打开快门门帘让汇聚光投射到胶片上来成像，相机机身只充当了一个暗箱的作用。数码相机的原理和其类似，数码相机肯定也有镜头，通过镜头的光线不像传统相机那样直接投射到胶片，而是直接投射到上面我们提到的感光元件的光敏单元上，这些感光器由半导体元件构成，由数字相机的内置智能控制装置对入射光线进行分析处理，并自动调整合适的焦距、暴光时间、色度、白平衡等参数，然后将这些数据传送给模/数转换器ADC(Analog Digital Converter)，ADC最后把这些电子模拟信号转换成数字信号。如果这个时候直接对数字信号进行存储，就是所谓的图像的Raw格式，照片的质量比普通的高，而且能在后期电脑上进行几乎无损的一些参数调整。严格意义上来说，Raw不应该算是一种图像格式，它仅仅是一个数据包而已。Raw仅仅是将数码相机图像传感器（CCD）感光产生的电信号数字化之后的采样值忠实地记录下来打包直接保存，并未进行任何计算和压缩，具有独特的设备相关性。它所记录的不是图像点的色彩、亮度信息，而是感光芯片的感光记录，是落在每个感光单元上的光线的多少，至于这个点处于什么位置，这个位置上是什么颜色的滤色片，需要根据芯片的型号来定义。目前，大多数数码相机的图像感光器的量化位一般都是12bit或14bit，就是说每个感光单元的感光信息用 12 或 14 位的二进制数字记录下来，对于 12 位的器件，每个点的亮度可以有2^12=4096 级的梯度区别，14 位的器件每个点的亮度可以有 2^14=16384 级的梯度区别，而一般JPEG 格式只能记录 24 位的 RGB 位图(尽管实际是以 YCbCr 色彩空间模型来记录，但图像处理、显示软件打开这些图像时，以及屏幕显示这些图片时，仍然要转换为 RGB分量)，但每个点 24位的数据要记录 R、G、B 三种颜色，分解到一种颜色就只能有 8 位了，最终能记录的亮度梯度就只有256 级了。数码相机早期还有一种格式，现在用的比较少，那就是TIFF 格式。虽然TIFF可记录 48 位(每个色彩 16 位)的图像信息，可以不丢失色彩位，但那样文件体积将变得十分庞大，而且多出的数据位只能用空白数据来填补，浪费存储资源。色彩位的差别直接关系到图像的动态范围和色彩饱和度，一旦保存为低色彩位的图像文件，将有相当量的感光信息被舍弃，这些舍弃的信息将无法找回。 另外，无论拍摄时采用 TIFF还是 JPEG，都是相机利用内部的图像处理芯片预先将数据计算过的，这个计算过程中就要用到相机的白平衡设置、色彩空间设置、曝光补偿设置等等，万一这些设置不准确，计算所产生的图像就会偏色或者曝光不准，一旦这种错误比较严重，信息损失过多，会导致照片报废。然而，JPEG图像格式是目前大众化数码相机缺省的图像保存格式。 总结好了，本文如果还有人没看明白，我只能很遗憾的说我已经尽了自己最大的努力，力争用最简单的文字来表述复杂的概念和理论，剩下的就只能靠每个人的修为了。最后，我再将数码相机成像的整个过程总结一下：从镜头进来的光线，投射到数码相机感光元件的很多个微小光敏感光单元上，每个感光单元以电信号的形式记录下照射到它上面的光的强度，然后通过DSP芯片的运算，将电信号通过预先内置在芯片里设定好的算法计算成符合现实标准的数码图像文件并加以存储，最后我们后期就可以编辑、修改、或者通过网络来传输图像了。 后记最后，如果有朋友选购数码相机时，看到一个数码相机声称其最高像素是2040万，但它标注的分辨率却为5184×3888=2015万像素，你也不能说人家在忽悠咱们。因为人家也没说2040万像素都拿来成像，这也符合相关标准。在你选择不同的拍照质量时，分辨率当然会降下来，用高分辨率的镜头拍出低分辨率的数字图像？你认为是怎么实现的呢？其似乎也不难，对于这种需求当今大多数相机都是通过主控芯片让感光器件“遮挡”部分感光单元，只让另一部分感光单元接受光照即可实现。关于图像质量的问题，每个感光单元的比特位直接决定了图像最终的表现亮度和色彩的性能，反映到图像上就是每个像素点所占的bit数，或者说字节数。以上便是我对数字图像入门知识的一点简单的记录和分享，毕竟不是专业搞图像的，欢迎各位路过的专业达人、高人、达人、大虾们指点拍砖。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Multimedia","slug":"Multimedia","permalink":"http://ipcreator.me/tags/Multimedia/"}]},{"title":"多媒体技术基础之---色彩空间","date":"2017-02-27T02:58:06.000Z","path":"2017/02/27/Program/Concepts/the-essence-of-color/","text":"wjlkoorey 上一篇博文里，我们已经了解到图像是如何数字化的，但是关于数字图像的存储和显示问题还没提到，但在了解数字图像的存储和显示之前，我们先得弄明白数字图像里一个让很多人迷糊的概念：色彩空间。有的技术文献里也将其表述为颜色模型、颜色空间等，说的都是同一个东西。 关于色彩空间，我们最熟悉的就是RGB了，即数字图像的每个像素点用3字节表示，每个字节分别表示该像素点红、绿和蓝色的分量，根据视觉三原色理论，那么这个像素点的最终颜色也就确定了下来。刚开始的时候，确实使用3个字节（38位）来分别表示一个像素里面的Red,Green和Blue的发光强度数值，后来又增加了一字节用于表示透明度，也就是在Photoshop里经常看到的Alpha值。前三个字节只表示红绿蓝三基色的值，最后一个字节表示前面三种基色叠加结果的透明度的值。在这个前提下，假如我们有一副1440900分辨率的一张图片，按照RGB的方式，每个像素点用4字节表示，则这幅图片将占：14409004= 5184000Byte=5MB左右的存储空间；如果是3320*1876分辨率的一张照片则高达24MB。当然，这个体积对目前的存储系统来说已经不是什么大问题了，但对我们目前的网络带宽还是提出了非常严峻的挑战。再进一步，如果我们要制作视频，按照电影理论：每秒钟至少24帧图像连续播放，人的视觉才不会感觉停留和卡顿。依然以1440×900解析率的片源为例，每秒钟的数据量则高达120MB字节！！！每秒啊，这是什么概念，如果是90分钟的总播放时长，你能想象要占多少存储空间？耗费多少网络带宽么？关于视频先搁置起来，以后再细说。 那如何在尽量不降低图片质量的情况下，如何才能最大限度的减小文件数据呢？当然，大家肯定想到应该是各种图像压缩算法该登场了。确实没错，但经过前人的实践证明，在采用RGB颜色模型记录数字图像时，无论采用何种算法，整体压缩比非常的不理想，因为原始数据确实太大了。这时候，英国著名科学家Iain Ainsworth经过大量科学研究得出了一条结论：The human visual system (HVS) is less sensitive to colour than to luminance (brightness)。也就是说 人类视觉系统对亮度的感觉比对颜色更加敏感。利用这一特性，将图像的亮度信息和颜色信息分离，并使用不同长度的bit位进行存储，这样可以在对主观感觉影响很小的前提下，更加有效的存储图像数据 因此，另一种颜色空间模型—YUV及其它的各种裂变体就如雨后春笋般遍地而生了。估计当年很多人和我一样，在学计算机多媒体信息处理这门课时，看到这个概念和后面的各种变种，那真是一个头，两个大。不过今天，我力争用最少的语言，最直白的逻辑来向大家阐述清楚这个概念。 说到YUV色彩空间，从它衍生出的其他几种颜色空间经常会让人产生混淆，最常见的就是YUV经常和YCbCr混用，还有YPbPr的出现让本来就已经很“混乱”的家族又变成了一锅浆糊。下面我们就来一一了解谈谈这几种东东。 YUV首先我们简单了解一下YUV的由来。在早期从黑白电视机向彩色电视机(都是模拟信号的年代)过度的那段时间里，工程师们为了继续沿用黑白电视机的基础技术和架构，根据前面说过人的视觉对图像的亮度比图像的色彩更敏感的特性，发明了YUV颜色空间。因为当年的黑白电视机里都已经具备处理图像信号亮度的器件，所以，彩色电视机的工程师们就只增加了两个色差信号U(蓝色色差)和V(红色色差)，就形成了我们所说的YUV颜色空间。所以说，YUV的真正意义在于：在模拟电视系统里，实现了亮度信号Y和色差信号U、V的分离，主要用于优化彩色视频信号的传输，后向兼容老式黑白电视系统，同时与原始的RGB相比，YUV只需占用极少的频宽，而RGB要求三个独立的视频信号同时传输。既然YUV是派生于RGB，那它们之间就肯定有换算公式。请客官们少安毋躁。 YCbCr 当从模拟图像发展到数字图像年代的时候，伟大的科学家们又在YUV颜色空间的基础上提出了YCbCr颜色空间。也就是说，YCbCr颜色空间主要用于彩色数字图像信息的编码、压缩和传输用的。例如，MPEG和JPEG两大组织的各种图像、视频压缩算法都是基于YCbCr颜色空间来提出的，例如H.264,mpeg其实都是在YCbCr颜色空间里运算的。 YPbPr 也是用在模拟的彩色信号处理领域，可以认为YPbPr是YCbCr的模拟版本。那么什么时候会见到YPbPr呢？那就是当你的显示设备的视频输入接口或者输出设备的视频输出接口还有下面这样一组时，你就会见到YPbPr了： 为了显示图像，你还得配备一根这样的视频连接线： 其中绿线传输Y信号，蓝线传输Pb信号，红线传输Pr信号。 最后，我们用来总结一下上述几种颜色空间的应用场合和它们之间的转换关系： 上图中，直接在网络上传送模拟信号的年代已经过去了，这里将其画出来的主要目的是告诉大家它们曾经存在过。 因此，综上所述，目前在计算机行业的数字图形图像处理领域，当我们提到YUV时，其实就隐含的指示了我们所说的是YCbCr，把模拟信号年代那些东东赶紧统统扫出脑袋吧(当然除非你目前还在搞模拟视频的相关研究和开发就恕小生无理了)。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Multimedia","slug":"Multimedia","permalink":"http://ipcreator.me/tags/Multimedia/"}]},{"title":"Linux系统中“动态库”和“静态库”那点事儿","date":"2017-02-27T02:24:06.000Z","path":"2017/02/27/Program/Concepts/the-anatomy-of-linux-library/","text":"wjlkoorey 更多参考：深入理解C语言的函数调用过程 今天我们主要来说说Linux系统下基于动态库(.so)和静态(.a)的程序那些猫腻。在这之前，我们需要了解一下源代码到可执行程序之间到底发生了什么神奇而美妙的事情。 在Linux操作系统中，普遍使用ELF格式作为可执行程序或者程序生成过程中的中间格式。ELF（Executable and Linking Format，可执行连接格式） 是UNIX系统实验室（USL）作为应用程序二进制接口（Application BinaryInterface，ABI）而开发和发布的。工具接口标准委员会（TIS）选择了正在发展中的ELF标准作为工作在32位Intel体系上不同操作系统之间可移植的二进制文件格式。本文不对ELF文件格式及其组成做太多解释，以免冲淡本文的主题，大家只要知道这么个概念就行。以后再详解Linux中的ELF格式。源代码到可执行程序的转换时需要经历如下图所示的过程： l 编译是指把用高级语言编写的程序转换成相应处理器的汇编语言程序的过程。从本质上讲，编译是一个文本转换的过程。对嵌入式系统而言，一般要把用C语言编写的程序转换成处理器的汇编代码。编译过程包含了C语言的语法解析和汇编码的生成两个步骤。编译一般是逐个文件进行的，对于每一个C语言编写的文件，可能还需要进行预处理。 l 汇编是从汇编语言程序生成目标系统的二进制代码（机器代码）的过程。机器代码的生成和处理器有密切的联系。相对于编译过程的语法解析，汇编的过程相对简单。这是因为 对于一款特定的处理器，其汇编语言和二进制的机器代码是一一对应的 汇编过程的输入是汇编代码，这个汇编代码可能来源于编译过程的输出，也可以是直接用汇编语言书写的程序。 l 连接是指将汇编生成的多段机器代码组合成一个可执行程序。一般来说，通过编译和汇编过程，每一个源文件将生成一个目标文件。连接器的作用就是将这些目标文件组合起来，组合的过程包括了代码段、数据段等部分的合并，以及添加相应的文件头。 GCC是Linux下主要的程序生成工具，它除了编译器、汇编器、连接器外，还包括一些辅助工具。在下面的分析过程中我会教大家这些工具的基本使用方法，Linux的强大之处在于，对于不太懂的命令或函数，有一个很强大的“男人”时刻stand by your side，有什么不会的就去命令行终端输入：man [命令名或函数名]，然后阿拉神灯就会显灵了。 对于最后编译出来的可执行程序，当我们执行它的时候，操作系统又是如何反应的呢？我们先从宏观上来个总体把握，如图2所示： 作为UNIX操作系统的一种，Linux的操作系统提供了一系列的接口，这些接口被称为系统调用（System Call）。在UNIX的理念中，系统调用”提供的是机制，而不是策略”。C语言的库函数通过调用系统调用来实现，库函数对上层提供了C语言库文件的接口。在应用程序层，通过调用C语言库函数和系统调用来实现功能。一般来说，应用程序大多使用C语言库函数实现其功能，较少使用系统调用。 那么最后的可执行文件到底是什么样子呢？前面已经说过，这里我们不深入分析ELF文件的格式，只是给出它的一个结构图和一些简单的说明，以方便大家理解。 ELF文件格式包括三种主要的类型：可执行文件、可重定向文件、共享库。 1．可执行文件（应用程序）可执行文件包含了代码和数据，是可以直接运行的程序。 2．可重定向文件（.o）可重定向文件又称为目标文件，它包含了代码和数据（这些数据是和其他重定位文件和共享的object文件一起连接时使用的）。 .o文件参与程序的连接（创建一个程序）和程序的执行（运行一个程序），它提供了一个方便有效的方法来用并行的视角看待文件的内容，这些.o文件的活动可以反映出不同的需要。Linux下，我们可以用gcc -c编译源文件时可将其编译成.o格式。 3．共享文件（*.so）也称为动态库文件，它包含了代码和数据（这些数据是在连接时候被连接器ld和运行时动态连接器使用的）。动态连接器可能称为ld.so.1，libc.so.1或者 ld-linux.so.1。我的CentOS6.0系统中该文件为：/lib/ld-2.12.so 一个ELF文件从连接器（Linker）的角度看，是一些节的集合；从程序加载器（Loader）的角度看，它是一些段（Segments）的集合。ELF格式的程序和共享库具有相同的结构，只是段的集合和节的集合上有些不同。 那么到底什么是库呢？库从本质上来说是一种可执行代码的二进制格式，可以被载入内存中执行。库分静态库和动态库两种。 静态库：这类库的名字一般是libxxx.a，xxx为库的名字。利用静态函数库编译成的文件比较大，因为整个函数库的所有数据都会被整合进目标代码中，他的优点就显而易见了，即编译后的执行程序不需要外部的函数库支持，因为所有使用的函数都已经被编译进去了。当然这也会成为他的缺点，因为如果静态函数库改变了，那么你的程序必须重新编译。 动态库：这类库的名字一般是libxxx.M.N.so，同样的xxx为库的名字，M是库的主版本号，N是库的副版本号。当然也可以不要版本号，但名字必须有。相对于静态函数库，动态函数库在编译的时候并没有被编译进目标代码中，你的程序执行到相关函数时才调用该函数库里的相应函数，因此动态函数库所产生的可执行文件比较小。由于函数库没有被整合进你的程序，而是程序运行时动态的申请并调用，所以程序的运行环境中必须提供相应的库。动态函数库的改变并不影响你的程序，所以动态函数库的升级比较方便。linux系统有几个重要的目录存放相应的函数库，如/lib /usr/lib。 当要使用静态的程序库时，连接器会找出程序所需的函数，然后将它们拷贝到执行文件，由于这种拷贝是完整的，所以一旦连接成功，静态程序库也就不再需要了。然而，对动态库而言，就不是这样。动态库会在执行程序内留下一个标记指明当程序执行时，首先必须载入这个库。由于动态库节省空间，linux下进行连接的缺省操作是首先连接动态库，也就是说，如果同时存在静态和动态库，不特别指定的话，将与动态库相连接。 OK,有了这些知识，接下来大家就可以弄明白我所做的事情是干什么了。都说例子是最好老师，我们就从例子入手。 1、静态链接库 我们先制作自己的静态链接库，然后再使用它。制作静态链接库的过程中要用到gcc和ar命令。 准备两个库的源码文件st1.c和st2.c，用它们来制作库libmytest.a，如下： 静态库文件libmytest.a已经生成，用file命令查看其属性，发现它确实是归档压缩文件。用ar -t libmytest.a可以查看一个静态库包含了那些obj文件： 接下来我们就写个测试程序来调用库libmytest.a中所提供的两个接口print1()和print2()。 看到没，静态库的编写和调用就这么简单，学会了吧。这里gcc的参数-L是告诉编译器库文件的路径是当前目录，-l是告诉编译器要使用的库的名字叫mytest。 2、动态库静态库*.a文件的存在主要是为了支持较老的a.out格式的可执行文件而存在的。目前用的最多的要数动态库了。 动态库的后缀为*.so。在Linux发行版中大多数的动态库基本都位于/usr/lib和/lib目录下。在开发和使用我们自己动态库之前，请容许我先落里罗嗦的跟大家唠叨唠叨Linux下和动态库相关的事儿吧。 有时候当我们的应用程序无法运行时，它会提示我们说它找不到什么样的库，或者哪个库的版本又不合它胃口了等等之类的话。那么应用程序它是怎么知道需要哪些库的呢？我们前面已几个学了个很棒的命令ldd，用就是用来查看一个文件到底依赖了那些so库文件。 Linux系统中动态链接库的配置文件一般在/etc/ld.so.conf文件内，它里面存放的内容是可以被Linux共享的动态联库所在的目录的名字。我的系统中，该文件的内容如下： 然后/etc/ld.so.conf.d/目录下存放了很多*.conf文件，如下： 其中每个conf文件代表了一种应用的库配置内容，以mysql为例： 如果您是和我一样装的CentOS6.0的系统，那么细心的读者可能会发现，在/etc目录下还存在一个名叫ld.so.cache的文件。从名字来看，我们知道它肯定是动态链接库的什么缓存文件。对，您说的一点没错。为了使得动态链接库可以被系统使用，当我们修改了/etc/ld.so.conf或/etc/ld.so.conf.d/目录下的任何文件，或者往那些目录下拷贝了新的动态链接库文件时，都需要运行一个很重要的命令：ldconfig，该命令位于/sbin目录下，主要的用途就是负责搜索/lib和/usr/lib，以及配置文件/etc/ld.so.conf里所列的目录下搜索可用的动态链接库文件，然后创建处动态加载程序/lib/ld-linux.so.2所需要的连接和(默认)缓存文件/etc/ld.so.cache(此文件里保存着已经排好序的动态链接库名字列表)。也就是说：当用户在某个目录下面创建或拷贝了一个动态链接库，若想使其被系统共享，可以执行一下”ldconfig目录名”这个命令。此命令的功能在于让ldconfig将指定目录下的动态链接库被系统共享起来，即：在缓存文件/etc/ld.so.cache中追加进指定目录下的共享库。请注意：如果此目录不在/lib,/usr/lib及/etc/ld.so.conf文件所列的目录里面，则再次单独运行ldconfig时，此目录下的动态链接库可能不被系统共享了。单独运行ldconfig时，它只会搜索/lib、/usr/lib以及在/etc/ld.so.conf文件里所列的目录，用它们来重建/etc/ld.so.cache。因此，等会儿我们自己开发的共享库就可以将其拷贝到/lib、/etc/lib目录里，又或者修改/etc/ld.so.conf文件将我们自己的库路径添加到该文件中，再执行ldconfig命令。非了老半天功夫，终于把基础打好了，猴急的您早已按耐不住激情的想动手尝试了吧！哈哈。。。OK，说整咱就开整，接下来我就带领大家一步一步来开发自己的动态库，然后教大家怎么去使用它。我们有一个头文件my_so_test.h和三个源文件test_a.c、test_b.c和test_c.c，将他们制作成一个名为libtest.so的动态链接库文件：OK，万事俱备，只欠东风。如何将这些文件编译成一个我们所需要的so文件呢？可以分两步来完成，也可以一步到位：方法一： 1、先生成目标.o文件： 2、再生成so文件：-shared该选项指定生成动态连接库（让连接器生成T类型的导出符号表，有时候也生成弱连接W类型的导出符号），不用该标志外部程序无法连接。相当于一个可执行文件。-fPIC：表示编译为位置独立的代码，不用此选项的话编译后的代码是位置相关的所以动态载入时是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。方法二：一步到位。至此，我们制作的动态库文件libtest.so就算大功告成了。 接下来，就是如何使用这个动态库了。动态链接库的使用有两种方法：既可以在运行时对其进行动态链接，又可以动态加载在程序中是用它们。接下来，我就这两种方法分别对其介绍。 +++动态库的使用+++用法一：动态链接。 使用“-ltest”标记来告诉GCC驱动程序在连接阶段引用共享函数库libtest.so。“-L.”标记告诉GCC函数库可能位于当前目录。否则GNU连接器会查找标准系统函数目录。这里我们注意，ldd的输出它说我们的libtest.so它没找到。还记得我在前面动态链接库一节刚开始时的那堆唠叨么，现在你应该很明白了为什么了吧。因为我们的libtest.so既不在/etc/ld.so.cache里，又不在/lib、/usr/lib或/etc/ld.so.conf所指定的任何一个目录中。怎么办？还用我告诉你？管你用啥办法，反正我用的ldconfig pwd搞定的： 执行结果如下：偶忍不住又要罗嗦一句了，相信俺，我的唠叨对大家是有好处。我为什么用这种方法呢？因为我是在给大家演示动态库的用法，完了之后我就把libtest.so给删了，然后再重构ld.so.cache，对我的系统不会任何影响。倘若我是开发一款软件，或者给自己的系统DIY一个非常有用的功能模块，那么我更倾向于将libtest.so拷贝到/lib、/usr/lib目录下，或者我还有可能在/usr/local/lib/目录下新建一文件夹xxx，将so库拷贝到那儿去，并在/etc/ld.so.conf.d/目录下新建一文件mytest.conf，内容只有一行“/usr/local/lib/xxx/libtest.so”，再执行ldconfig。如果你之前还是不明白怎么解决那个“not found”的问题，那么现在总该明白了吧。 方法二：动态加载。动态加载是非常灵活的，它依赖于一套Linux提供的标准API来完成。在源程序里，你可以很自如的运用API来加载、使用、释放so库资源。以下函数在代码中使用需要包含头文件：dlfcn.h1234567891011121314151617181920212223函数原型说明const char *dlerror(void)当动态链接库操作函数执行失败时，dlerror可以返回出错信息，返回值为NULL时表示操作函数执行成功。void *dlopen(const char *filename, int flag)用于打开指定名字（filename）的动态链接库，并返回操作句柄。调用失败时，将返回NULL值，否则返回的是操作句柄。void *dlsym(void *handle, char *symbol)根据动态链接库操作句柄（handle）与符号（symbol），返回符号对应的函数的执行代码地址。由此地址，可以带参数执行相应的函数。int dlclose (void *handle)用于关闭指定句柄的动态链接库，只有当此动态链接库的使用计数为0时，才会真正被系统卸载。2.2在程序中使用动态链接库函数。 dlsym(void *handle, char *symbol)filename:如果名字不以“/”开头，则非绝对路径名，将按下列先后顺序查找该文件。 （1）用户环境变量中的LD_LIBRARY值； （2）动态链接缓冲文件/etc/ld.so.cache （3）目录/lib,/usr/lib flag表示在什么时候解决未定义的符号（调用）。取值有两个： 1） RTLD_LAZY : 表明在动态链接库的函数代码执行时解决。 2） RTLD_NOW :表明在dlopen返回前就解决所有未定义的符号，一旦未解决，dlopen将返回错误。 dlsym(void *handle, char *symbol) dlsym()的用法一般如下： void（*add）（int x,int y）； /*说明一下要调用的动态函数add */add=dlsym（\"xxx.so\",\"add\"）； /* 打开xxx.so共享库，取add函数地址 */add（89,369）； /* 带两个参数89和369调用add函数 */ 看我出招： 执行结果：使用动态链接库，源程序中要包含dlfcn.h头文件，写程序时注意dlopen等函数的正确调用，编译时要采用-rdynamic选项与-ldl选项(不然编译无法通过)，以产生可调用动态链接库的执行代码。 OK，通过本文的指导、练习相信各位应该对Linux的库机制有了些许了解，最主要的是会开发使用库文件了。由于本人知识所限，文中某些观点如果不到位或理解有误的地方还请各位个人不吝赐教。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ipcreator.me/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"http://ipcreator.me/tags/Network/"}]},{"title":"Linux网络编程","date":"2017-02-27T02:11:06.000Z","path":"2017/02/27/Program/Concepts/the-anatomy-of-network-programming/","text":"Linux的整个网络协议栈都构建与Linux Kernel中，整个栈也是严格按照分层的思想来设计的，整个栈共分为五层，分别是 ： 1． 系统调用接口层，实质是一个面向用户空间应用程序的接口调用库，向用户空间应用程序提供使用网络服务的接口。2． 协议无关的接口层，就是SOCKET层，这一层的目的是屏蔽底层的不同协议（更准确的来说主要是TCP与UDP，当然还包括RAW IP， SCTP等），以便与系统调用层之间的接口可以简单，统一。简单的说，不管我们应用层使用什么协议，都要通过系统调用接口来建立一个SOCKET，这个SOCKET其实是一个巨大的sock结构，它和下面一层的网络协议层联系起来，屏蔽了不同的网络协议的不同，只把数据部分呈献给应用层（通过系统调用接口来呈献）。3． 网络协议实现层，毫无疑问，这是整个协议栈的核心。这一层主要实现各种网络协议，最主要的当然是IP，ICMP，ARP，RARP，TCP，UDP等。这一层包含了很多设计的技巧与算法，相当的不错。4． 与具体设备无关的驱动接口层，这一层的目的主要是为了统一不同的接口卡的驱动程序与网络协议层的接口，它将各种不同的驱动程序的功能统一抽象为几个特殊的动作，如open，close，init等，这一层可以屏蔽底层不同的驱动程序。5． 驱动程序层，这一层的目的就很简单了，就是建立与硬件的接口层。可以看到，Linux网络协议栈是一个严格分层的结构，其中的每一层都执行相对独立的功能，结构非常清晰。其中的两个“无关”层的设计非常棒，通过这两个“无关”层，其协议栈可以非常轻松的进行扩展。在我们自己的软件设计中，可以吸收这种设计方法。 更多参考： Linux 网络栈剖析 Linux网络编程：原始套接字的魔力【上】 Linux网络编程：原始套接字的魔力【下】 Linux网络编程：原始套接字的魔力【续】 揭开网络编程常见API的面纱【上】 揭开网络编程常见API的面纱【下】 Linux网络编程：基于UDP的程序开发回顾篇 Linux网络编程：基于TCP的程序开发回顾篇 Linux环境下网络编程杂谈 linux 内核网络，数据接收流程图 linux 内核网络,数据发送流程图 (十六)洞悉linux下的Netfilter&amp;iptables：开发自己的hook函数【实战】(下) (十五)洞悉linux下的Netfilter&amp;iptables：开发自己的hook函数【实战】(上) (十四)洞悉linux下的Netfilter&amp;iptables：开发一个match模块【实战】 (十三)洞悉linux下的Netfilter&amp;iptables：为防火墙增添功能模块【实战】 (十二)洞悉linux下的Netfilter&amp;iptables：iptables命令行工具源码解析【下】 (十一)洞悉linux下的Netfilter&amp;iptables：iptables命令行工具源码解析【上】 (十)洞悉linux下的Netfilter&amp;iptables：网络地址转换原理之SNAT (九)洞悉linux下的Netfilter&amp;iptables：网络地址转换原理之DNAT (八)洞悉linux下的Netfilter&amp;iptables：状态防火墙 (七)洞悉linux下的Netfilter&amp;iptables：如何理解连接跟踪机制？【下】 (六)洞悉linux下的Netfilter&amp;iptables：如何理解连接跟踪机制？【中】 (五)洞悉linux下的Netfilter&amp;iptables：如何理解连接跟踪机制？【上】 (四)洞悉linux下的Netfilter&amp;iptables：包过滤子系统iptable_filter (三)洞悉linux下的Netfilter&amp;iptables：内核中的rule，match和target (二)洞悉linux下的Netfilter&amp;iptables：内核中的ip_tables小觑 (一)洞悉linux下的Netfilter&amp;iptables：什么是Netfilter？ Linux Netfilter实现机制和扩展技术 协议简介虽然对于网络的正式介绍一般都参考了 OSI（Open Systems Interconnection）模型，但是本文对 Linux 中基本网络栈的介绍分为四层的 Internet 模型（如图 1 所示）。图 1. 网络栈的 Internet 模型网络栈的 Internet 模型这个栈的最底部是链路层。链路层是指提供对物理层访问的设备驱动程序，这可以是各种介质，例如串口链路或以太网设备。链路层上面是网络层，它负责将报文定向到目标位置。再上一层称为传输层，负责端到端的通信（例如，在一台主机内部）。尽管网络层负责管理主机之间的通信，但是传输层需要负责管理主机内部各端之间的通信。最后一层是应用层，它通常是一个语义层，能够理解要传输的数据。例如，超文本传输协议（HTTP）就负责传输服务器和客户机之间对 Web 内容的请求与响应。实际来说，网络栈的各个层次有一些更为人所熟知的名字。在链路层上，可以找到以太网，这是最常用的一种高速介质。更早的链路层协议包括一些串口协议，例如 SLIP（Serial Line Internet Protocol）、CSLIP（Compressed SLIP）和PPP（Point-to-Point Protocol）。最常见的网络层协议是 IP（Internet Protocol），但是网络层中还存在一些满足其他需求的协议，例如 ICMP（Internet Control Message Protocol）和ARP（ Address Resolution Protocol）。在传输层上是 TCP（Transmission Control Protocol）和 UDP（User Datagram Protocol）。最后，应用层中包含很多大家都非常熟悉的协议，包括标准的 Web 协议 HTTP 和电子邮件协议 SMTP（Simple Mail Transfer Protocol）。 核心网络架构现在继续了解 Linux 网络栈的架构以及如何实现这种 Internet 模型。图 2 提供了 Linux 网络栈的高级视图。最上面是用户空间层，或称为应用层，其中定义了网络栈的用户。底部是物理设备，提供了对网络的连接能力（串口或诸如以太网之类的高速网络）。中间是内核空间，即网络子系统，也是本文介绍的重点。流经网络栈内部的是 socket 缓冲区（sk_buffs），它负责在源和汇点之间传递报文数据。您很快就将看到 sk_buff 的结构。图 2. Linux 高级网络栈架构Linux 高级网络栈架构首先，让我们来快速浏览一下 Linux 网络子系统的核心元素，后续章节中会更详细进行介绍。顶部（请参阅图 2）是系统调用接口。它简单地为用户空间的应用程序提供了一种访问内核网络子系统的方法。位于其下面的是一个协议无关层，它提供了一种通用方法来使用底层传输层协议。然后是实际协议，在 Linux 中包括内嵌的协议 TCP、UDP，当然还有 IP。然后是另外一个协议无关层，提供了与各个设备驱动程序通信的通用接口，最下面是设备驱动程序本身。 系统调用接口系统调用接口可以从两个角度进行描述。用户发起网络调用时，通过系统调用接口进入内核的过程应该是多路的。最后调用 ./net/socket.c 中的 sys_socketcall 结束该过程，然后进一步将调用分路发送到指定目标。系统调用接口的另一种描述是使用普通文件操作作为网络 I/O。例如，典型的读写操作可以在网络 socket 上执行（socket 使用一个文件描述符表示，与一个普通文件一样）。因此，尽管有很多操作是网络专用的（使用 socket 调用创建一个 socket，使用 connect 调用连接一个收信方，等等），但是也有一些标准的文件操作可以应用于网络对象，就像操作普通文件一样。最后，系统调用接口提供了在用户空间应用程序和内核之间转移控制的方法。 协议无关接口socket 层是一个协议无关接口，它提供了一组通用函数来支持各种不同协议。socket 层不但可以支持典型的 TCP 和 UDP 协议，而且还可以支持 IP、裸以太网和其他传输协议，例如 SCTP（Stream Control Transmission Protocol）。通过网络栈进行的通信都需要对 socket 进行操作。Linux 中的 socket 结构是 struct sock，这个结构是在 linux/include/net/sock.h 中定义的。这个巨大的结构中包含了特定 socket 所需要的所有状态信息，其中包括 socket 所使用的特定协议和在 socket 上可以执行的一些操作。网络子系统可以通过一个定义了自己功能的特殊结构来了解可用协议。每个协议都维护了一个名为 proto 的结构（可以在 linux/include/net/sock.h 中找到）。这个结构定义了可以在从 socket 层到传输层中执行特定的 socket 操作（例如，如何创建一个 socket，如何使用 socket 建立一个连接，如何关闭一个 socket 等等）。 网络协议网络协议这一节对一些可用的特定网络协议作出了定义（例如 TCP、UDP 等）。它们都是在 linux/net/ipv4/af_inet.c 文件中一个名为 inet_init 的函数中进行初始化的（因为 TCP 和 UDP 都是 inet 簇协议的一部分）。 inet_init 函数使用 proto_register 函数来注册每个内嵌协议。这个函数是在 linux/net/core/sock.c 中定义的，除了可以将这个协议添加到活动协议列表中之外，如果需要，该函数还可以选择分配一到多个 slab 缓存。通过 linux/net/ipv4/ 目录中 udp.c 和 raw.c 文件中的 proto 接口，您可以了解各个协议是如何标识自己的。这些协议接口每个都按照类型和协议映射到 inetsw_array，该数组将内嵌协议与操作映射到一起。inetsw_array 结构及其关系如图 3 所示。最初，会调用 inet_init 中的 inet_register_protosw 将这个数组中的每个协议都初始化为 inetsw。函数 inet_init 也会对各个 inet 模块进行初始化，例如 ARP、ICMP 和 IP 模块，以及 TCP 和 UDP 模块。 Socket 协议的相互关系回想以下在创建 socket 时，需要指定类型和协议，例如my_sock = socket( AF_INET, SOCK_STREAM, 0 )。AF_INET 表示一个 Internet 地址簇，它使用的是一个流 socket，定义为 SOCK_STREAM（如此处的 inetsw_array 所示）。 注意在 图 3 中，proto 结构定义了传输特有的方法，而 proto_ops 结构则定义了通用的 socket 方法。可以通过调用 inet_register_protosw 将其他协议加入到 inetsw 协议中。例如，SCTP 就是通过调用 linux/net/sctp/protocol.c 中的 sctp_init 加入其中的。有关 SCTP 的更多信息，请参阅 参考资料 一节的内容。socket 中的数据移动是使用一个所谓的 socket 缓冲区（sk_buff）的核心结构实现的。sk_buff 中包含了报文数据，以及涉及协议栈中多个层次的状态数据。所发送或接收的每个报文都是使用一个 sk_buff 表示的。sk_buff 结构是在 linux/include/linux/skbuff.h 中定义的，如图 4 所示。图 4. Socket 缓冲区及其与其他结构的关系如图所示，多个 sk_buff 可以针对某个给定连接链接在一起。每个 sk_buff 都在设备结构（net_device）中标识报文发送的目的地，或者接收报文的来源地。由于每个报文都是使用一个 sk_buff 表示的，因此报文头都可以通过一组指针（th、iph 和 mac[用于 Media Access Control 或者 MAC 头]）方便地进行定位。由于 sk_buff 是 socket 数据管理的中心，因此创建了很多支持函数来对它们进行管理。其中有些函数用于创建和销毁 sk_buff 结构，或对它进行克隆或排队管理。针对给定的 socket，Socket 缓冲区可以链接在一起，这样可以包含众多信息，包括到协议头的链接、时间戳（报文是何时发送或接收的），以及与这个报文相关的设备。 设备无关接口协议层下面是另外一个无关接口层，它将协议与具有很多各种不同功能的硬件设备连接在一起。这一层提供了一组通用函数供底层网络设备驱动程序使用，让它们可以对高层协议栈进行操作。首先，设备驱动程序可能会通过调用 register_netdevice 或 unregister_netdevice 在内核中进行注册或注销。调用者首先填写 net_device 结构，然后传递这个结构进行注册。内核调用它的 init 函数（如果定义了这种函数），然后执行一组健全性检查，并创建一个 sysfs 条目，然后将新设备添加到设备列表中（内核中的活动设备链表）。在 linux/include/linux/netdevice.h 中可以找到这个 net_device 结构。这些函数都是在 linux/net/core/dev.c 中实现的。要从协议层向设备中发送 sk_buff，就需要使用 dev_queue_xmit 函数。这个函数可以对 sk_buff 进行排队，从而由底层设备驱动程序进行最终传输（使用 sk_buff 中引用的 net_device 或 sk_buff-&gt;dev 所定义的网络设备）。dev 结构中包含了一个名为 hard_start_xmit 的方法，其中保存有发起 sk_buff 传输所使用的驱动程序函数。报文的接收通常是使用 netif_rx 执行的。当底层设备驱动程序接收一个报文（包含在所分配的 sk_buff 中）时，就会通过调用 netif_rx 将 sk_buff 上传至网络层。然后，这个函数通过 netif_rx_schedule 将 sk_buff 在上层协议队列中进行排队，供以后进行处理。可以在 linux/net/core/dev.c 中找到 dev_queue_xmit 和 netif_rx 函数。最近，内核中引入了一种新的应用程序编程接口（NAPI），该接口允许驱动程序与设备无关层（dev）进行交互。有些驱动程序使用的是 NAPI，但是大多数驱动程序仍然在使用老式的帧接收接口（比例大约是 6 比 1）。NAPI 在高负载的情况下可以产生更好的性能，它避免了为每个传入的帧都产生中断。 设备驱动程序网络栈底部是负责管理物理网络设备的设备驱动程序。例如，包串口使用的 SLIP 驱动程序以及以太网设备使用的以太网驱动程序都是这一层的设备。在进行初始化时，设备驱动程序会分配一个 net_device 结构，然后使用必须的程序对其进行初始化。这些程序中有一个是 dev-&gt;hard_start_xmit，它定义了上层应该如何对 sk_buff 排队进行传输。这个程序的参数为 sk_buff。这个函数的操作取决于底层硬件，但是通常 sk_buff 所描述的报文都会被移动到硬件环或队列中。就像是设备无关层中所描述的一样，对于 NAPI 兼容的网络驱动程序来说，帧的接收使用了 netif_rx 和 netif_receive_skb 接口。NAPI 驱动程序会对底层硬件的能力进行一些限制。有关更详细的信息，请参阅 参考资料 一节的内容。设备驱动程序在 dev 结构中配置好自己的接口之后，调用 register_netdevice 便可以使用该配置。在 linux/drivers/net 中可以找出网络设备专用的驱动程序。 展望Linux 源代码是学习有关大多数设备类型的设备驱动程序设计最佳方法，包括网络设备驱动程序。在这里可以找到的是各种设计的变化以及对可用内核 API 的使用，但是所学到的每一点都会非常有用，都可以作为新设备驱动程序的起点。除非您需要一种新协议，否则网络栈中的其余代码都是通用的，都会非常有用。即使现在，TCP（用于流协议）或 UDP（用于基于消息的协议）的实现都可以作为开始新开发有用模块使用。 笔记摘抄 在开发面向连接的TCP和面向无连接的UDP程序时，我们所关心的核心问题在于数据收发层面，数据的传输特性由TCP或UDP来保证： 先简单复习一下TCP报文的格式，因为我们本身不是讲协议的设计思想，所以只会提及和我们接下来主题相关的字段，如果想对TCP协议原理进行深入了解那么《TCP/IP详解卷1》无疑是最好的选择。 下IP报文的首部格式： 直接从链路层收发数据帧，听起来好像很神奇的样子。在Linux系统中要从链路层(MAC)直接收发数帧，比较普遍的做法就是用libpcap和libnet两个动态库来实现。但今天我们就要用原始套接字来实现这个功能。 链路层中是根据MAC地址来确定唯一一台主机。以太帧格式如下： 面向连接的TCP程序设计 基于TCP的程序开发分为服务器端和客户端两部分，常见的核心步骤和流程： 基于无连接的UDP程序设计 同样，在开发基于UDP的应用程序时，其主要流程如下： 1、socket(family,type,protocol) 当我们在开发网络应用程序时，使用该系统调用来创建一个套接字。该API所做的工作如下所示： 2、bind (sockfd, sockaddr, addrlen) 该系统调用在内核中的执行过程如下： 3、listen(sockfd, backlog) 这里我们可以看到面向无连接的套接字和原始套接字是不用listen的，只有流式套接字才有效。 4、connect(sockfd, sockaddr, addrlen) 从这幅图中我们确实看到，connect()系统调用不但可以面向连接的套接字，也可用于无连接及原始套接字。 5、accept(sockfd, sockaddr, addrlen) 同样地，我们看到只有面向连接的流式套接字调用accept()才有意义。最终调用的是tcp_prot对象的accept成员函数。 数据接收 在接收数据的过程，主要分两个阶段：BOTTOM-HALF和TOP-HALF。 BOTTOM-HALF： ![](http://blog.chinaunix.net/attachment/201208/3/23069658_1344005514lM97.jpg) BOTTOM-HALF最后将收到的skb填充到socket套接字的接收队列里，参见下图。 TOP-HALF： 紧承BOTTOM-HALF阶段，该阶段的主要任务就是从接收队列里拿出一个skb然后将其传递到用户空间去，如下： 数据发送 同样的，数据发送也分两个阶段，对照接收的情况，发送数据时肯定也存在一个发送队列，这样想就对了。前面关于发送数据包时我们介绍过的API有write()、send()、sendto()还有一个sendmsg()没介绍到。 TOP-HALF如下： BOTTOM-HALF如下所示： 经过这么一份探索，我们对这几个数据收发的API至少理解的要比别人深刻些了吧。至于不同函数之间的回调、调用关系是如何搭建的，我们在协议栈分析章节再做进一步讨论。最后来一张全家福： linux 内核网络，数据接收流程图 linux 内核网络,数据发送流程图","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ipcreator.me/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"http://ipcreator.me/tags/Network/"}]},{"title":"从头构建自己的Linux系统","date":"2017-02-27T02:03:06.000Z","path":"2017/02/27/Program/Concepts/start-up-of-linux/","text":"wjlkoorey 在博文“Linux系统启动过程分析”中我们了解了linux系统的启动流程，今天我们就来手动一步一步从头来构建一个最小的linux系统，然后用模拟器将其加载起来。常见的模拟器有Qemu、Bochs、VMWare、VPC、Virtual Box和Xen等，以及特殊的模拟UML(User-Mode-Linux)，这里我们选择用VMWare。 我们制作的Linux系统有shell功能，支持Web Server，telnet等服务，以及ifconfig，vi等常见工具。准备工作： 在http://www.kernel.org 下载内核源代码 linux-2.6.21.tar.bz2； 在http://www.busybox.org 下载busybox源码 busybox-1.14.4.tar.bz2。 在本地新建一个目录，例如/home/DIY，当然你可以随便选择，然后将下载的内核源码和busybox源码包拷贝到/home/DIY目录下； A)、构造根文件系统 我们都知道标准的发行版linux其目录结构一般是如下这个样子： 我们制作的linux运行起来之后当然也应该有个类似的目录结构。这里我们只选择一些必须的目录，因为我们构建的是“最小”的Linux系统。 在/home/DIY目录下依次执行如下命令： 在rootfs/etc目录下分别建立如下各个文件group、inittab、profile、protocols、rcS和services：点击(此处)折叠或打开 ###################### /etc/group ###################### from hereroot:x:0:ftp:x:800:nogroup:x:65534: ######################/etc/inittab ###################### from here::sysinit:/etc/rcStty1::askfirst:-/bin/sh –logintty2::askfirst:-/bin/sh –logintty3::askfirst:-/bin/sh –login ######################/etc/profile ###################### from here #!/bin/sh cat &lt;&lt;EOF Welcome to DIY EOFexport PATH=/bin:/sbin:/usr/bin:/usr/sbin ######################/etc/protocols ###################### from here Internet (IP) protocols#ip 0 IPicmp 1 ICMPigmp 2 IGMPggp 3 GGPipencap 4 IP-ENCAPst 5 STtcp 6 TCPegp 8 EGPigp 9 IGPpup 12 PUPudp 17 UDPhmp 20 HMPxns-idp 22 XNS-IDPrdp 27 RDPiso-tp4 29 ISO-TP4xtp 36 XTPddp 37 DDPidpr-cmtp 38 IDPR-CMTPidrp 45 IDRPrsvp 46 RSVPgre 47 GREesp 50 IPSEC-ESPah 51 IPSEC-AHskip 57 SKIPrspf 73 RSPF CPHBvmtp 81 VMTPeigrp 88 EIGRPospf 89 OSPFIGPax.25 93 AX.25ipip 94 IPIPetherip 97 ETHERIPencap 98 ENCAPpim 103 PIMipcomp 108 IPCOMPvrrp 112 VRRPl2tp 115 L2TPisis 124 ISISsctp 132 SCTPfc 133 FC ######################/etc/rcS ###################### from here #!/bin/sh export PATH=/bin:/sbin:/usr/bin:/usr/sbinmount -t proc none /procmount -t sysfs none /sysmount -t tmpfs tmpfs /dev -o size=512K,mode=0755echo DIY &gt; /proc/sys/kernel/hostname mkdir -p /var/run /var/log /var/lock /var/state \\ /var/tmp /var/mnt /dev/pts /dev/shmmount devpts /dev/pts -t devpts echo /bin/mdev &gt; /proc/sys/kernel/hotplugmdev -s ifconfig lo 127.0.0.1 upifconfig eth0 192.168.1.1 netmask 255.255.255.0 up telnetd -l /bin/shhttpd -h /www ###################/etc/services ################# from heressh 22/tcpssh 22/udptelnet 23/tcptelnet 23/udphttp 80/tcp www www-httphttp 80/udp www www-httplogin 513/tcpshell 514/tcp cmd 再在rootfs/www目录下建立一个index.html文件，内容如下：点击(此处)折叠或打开 Success! Welcome to DIY linux! 最后rootfs目录的组织结构如下： 其他的命令行工具由接下来的busybox生成。 B)、编译busybox 在Linux系统中常用的工具，如 bash、grep命令、sed 命令、telnetd等，这里为了方便省事，我就用busybox来代替了。现在的busybox拥有非常多的工具，真正成为一个“Busy”的box。后面的例子将尝试只使用 busybox来充当所有应用层所需要的工具集。包括Shell，网络配置，web服务器，telnet等。而busybox也由此得到一个称号“嵌入式世界的瑞士军刀”。 将修改后的“ busybox.config.txt ”复制到busybox-1.14.4目录下重命名为“.config”，注意文件名前面的点“.”绝对不能省略。 之后弹出如下界面： 在配置界面下，我们依次选择：Busybox Settings =&gt; Build Options 然后选中(按空格键)，这里我们将编译生成静态库的busybox，如下图中所示选项： 配置busybox的安装目录，依次选择：Busybox Settings =&gt; Installation Options ，如下： 保存配置后执行编译命令make： 编译完成后执行make install： 这样我们编译的busybox工具就安装到前面我们创建的rootfs目录中了，此时rootfs目录下的组织结构就变成了如下这个样子： 不管是bin，sbin，usr/bin还是usr/sbin目录下的命令都是到/bin/busybox应用程序的软连接。目前rootfs这个目录结构和我们常见的linux发行版的目录结构还是有些差异，所以我们继续往rootfs中增加dev，proc，tmp，var，lib，root和sys目录： 这样子就更像一个“标准”linux发行版的样子了。接下来我们来制作一个ramdisk的初始化文件，名为initrd。Linux内置支持以RAM磁盘的形式来启动。关于Linux系统的启动流程请参见博文“Linux系统启动过程分析”里的详细描述。 C)、制作initrd文件 D)、编译Linux内核源码 解压内核源码，然后将我修改后的内核配置文件“ linux.config.txt ”拷贝到linux-2.6.21目录下，重命名为“.config”，如下： 执行make menuconfig可以查看哪些配置项已经被选上： 执行make命令开始编译内核： 我们提供的内核配置文件linux.conf将模块已经静态编译到内核中去了，这样就会造成内核比较大，如果是采用动态加载模块的话，需要将所有模块安装到前面制作的ramdisk里。编译好的内核镜像，一般位于：• 对于x86平台，压缩后的核心是 arch/x86/boot/bzImage；• 对于MIPS平台，压缩后的核心是 arch/powerpc/boot/zImage；• 对于arm平台，压缩后的核心是 arch/arm/boot/zImage……E)、用VMWare加载内核将arch/x86/boot/bzImage和/home/DIY/initrd文件拷贝到linux系统的/boot目录下，然后修改/boot/grub/menu.lst，在其中添加如下一项：点击(此处)折叠或打开title DIY Your OS root (hd0,0) kernel /bzImage rw root=/dev/ram rootfs_size=8M initrd /initrd PS：因为我们制作的initrd文件大小就是8M，所以rootfs_size=8M。 重启VMware，在启动界面我们自己built的linux系统： 启动后效果如下： 我们可以看到eth0接口已经up了，其IP地址默认为192.168.1.1，因为我虚拟机的IP地址池是192.168.6.*网段的，所以手动将eth0的接口IP设置为192.168.6.135：然后通过web和telnet访问我们自己做的系统，最终的访问结果如下： 小结：通过今天的学习相信大家对Linux系统的运行原理和启动流程的认识又上了一个新的台阶，更重要的是学会了如何手动构建一个“最小”的Linux“发行版”系统。那么，现在回过头来再看那些商业版的Linux系统，其实本质和我们今天做工作的差不多，所以，如果有条件我们也可以发行一个自己的系统了:)。 Linux系统启动过程分析 经过对Linux系统有了一定了解和熟悉后，想对其更深层次的东西做进一步探究。这当中就包括系统的启动流程、文件系统的组成结构、基于动态库和静态库的程序在执行时的异同、协议栈的架构和原理、驱动程序的机制等等。 本人在综合了现有网上大家智慧的基础上，结合对2.6.32的内核代码的研读，基于CentOS 6.0系统对Linux的启动流程做了些分析。由于才疏学浅，知识所限，有些地方分析不妥之处还请各位高手不吝赐教。 OK，我们言归正传。对于一台安装了Linux系统的主机来说，当用户按下开机按钮时，一共要经历以下几个过程，如图： 其中，每个过程都执行了自己该做的初始化部分的事情，有些过程又可分为好几个子过程。接下来，我们就对每个阶段做一个详细分析和讲解。 BIOS自检 稍有计算机基础的人都应该听过BIOS(Basic Input / Output System)，又称基本输入输出系统，可以视为是一个永久地记录在ROM中的一个软件，是操作系统输入输出管理系统的一部分。早期的BIOS芯片确实是&quot;只读&quot;的，里面的内容是用一种烧录器写入的，一旦写入就不能更改，除非更换芯片。现在的主机板都使用一种叫Flash EPROM的芯片来存储系统BIOS，里面的内容可通过使用主板厂商提供的擦写程序擦除后重新写入，这样就给用户升级BIOS提供了极大的方便。 BIOS的功能由两部分组成，分别是POST码和Runtime服务。POST阶段完成后它将从存储器中被清除，而Runtime服务会被一直保留，用于目标操作系统的启动。BIOS两个阶段所做的详细工作如下： 步骤1：上电自检POST(Power-on self test)，主要负责检测系统外围关键设备（如：CPU、内存、显卡、I/O、键盘鼠标等）是否正常。例如，最常见的是内存松动的情况，BIOS自检阶段会报错，系统就无法启动起来； 步骤2：步骤1成功后，便会执行一段小程序用来枚举本地设备并对其初始化。这一步主要是根据我们在BIOS中设置的系统启动顺序来搜索用于启动系统的驱动器，如硬盘、光盘、U盘、软盘和网络等。我们以硬盘启动为例，BIOS此时去读取硬盘驱动器的第一个扇区(MBR，512字节)，然后执行里面的代码。实际上这里BIOS并不关心启动设备第一个扇区中是什么内容，它只是负责读取该扇区内容、并执行。 至此，BIOS的任务就完成了，此后将系统启动的控制权移交到MBR部分的代码。 PS: 在个人电脑中，Linux的启动是从0xFFFF0地址开始的。 系统引导 我们首先来了解一下MBR，它是Master Boot Record的缩写。硬盘的0柱面、0磁头、1扇区称为主引导扇区。它由三个部分组成，主引导程序(Bootloader)、 硬盘分区表DPT（Disk Partition table）和硬盘有效标志（55AA），其结构图如下所示： 磁盘分区表包含以下三部分： 1）、Partition ID （5：延申 82：Swap 83：Linux 8e：LVM fd：RAID） 2）、Partition起始磁柱 3）、Partition的磁柱数量 通常情况下，诸如lilo、grub这些常见的引导程序都直接安装在MBR中。我们以grub为例来分析这个引导过程。 grub引导也分为两个阶段stage1阶段和stage2阶段(有些较新的grub又定义了stage1.5阶段)。 1)、stage1：stage1是直接被写入到MBR中去的，这样机器一启动检测完硬件后，就将控制权交给了GRUB的代码。也就是上图所看到的前446个字节空间中存放的是stage1的代码。BIOS将stage1载入内存中0x7c00处并跳转执行。stage1（/stage1/start.S）的任务非常单纯，仅仅是将硬盘0头0道2扇区读入内存。而0头0道2扇区内容是源代码中的/stage2/start.S，编译后512字节，它是stage2或者stage1_5的入口。而此时，stage1是没有识别文件系统的能力的。如果感觉脑子有些晕了，那么下面的过程就直接跳过，去看stage2吧！ 【外传】定位硬盘的0头0道2扇区的过程： BIOS将stage1载入内存0x7c00处并执行，然后调用BIOS INIT13中断，将硬盘0头0道2扇区内容载入内存0x7000处，然后调用copy_buffer将其转移到内存0x8000处。在定位0头0道2扇区时通常有两种寻址方式：LBA和CHS。如果你是刨根问底儿型的爱好者，那么此时去找谷哥打听打听这两种方式的来龙去脉吧。 2)、stage2：严格来说这里还应该再区分个stage1.5的，就一并把stage1.5放在这里一起介绍了，免得大家看得心里乱哄哄的。好的，我们继续说0头0到2扇区的/stage2/start.S文件，当它的内容被读入到内存之后，它的主要作用就是负责将stage2或stage1.5从硬盘读到内存中。如果是stage2，它将被载入到0x820处；如果是stage1.5，它将被载入到0x2200处。这里的stage2或者stage1_5不是/boot分区/boot/grub目录下的文件，因为这个时候grub还没有能力识别任何文件系统。 ? 如果start.S加载stage1.5：stage1.5它存放在硬盘0头0道3扇区向后的位置，stage1_5作为stage1和stage2中间的桥梁，stage1_5有识别文件系统的能力，此后grub才有能力去访问/boot分区/boot/grub目录下的 stage2文件，将stage2载入内存并执行。 ? 如果start.S加载stage2：同样，这个stage2也不是/boot分区/boot/grub目录下的stage2，这个时候start.S读取的是存放在/boot分区Boot Sector的stage2。这种情况下就有一个限制：因为start.S通过BIOS中断方式直接对硬盘寻址（而非通过访问具体的文件系统），其寻址范围有限，限制在8GB以内。因此这种情况需要将/boot分区分在硬盘8GB寻址空间之前。 假如是情形2，我们将/boot/grub目录下的内容清空，依然能成功启动grub；假如是情形1，将/boot/grub目录下stage2删除后，则系统启动过程中grub会启动失败。 启动内核 当stage2被载入内存执行时，它首先会去解析grub的配置文件/boot/grub/grub.conf，然后加载内核镜像到内存中，并将控制权转交给内核。而内核会立即初始化系统中各设备并做相关的配置工作，其中包括CPU、I/O、存储设备等。 关于Linux的设备驱动程序的加载，有一部分驱动程序直接被编译进内核镜像中，另一部分驱动程序则是以模块的形式放在initrd(ramdisk)中。 Linux内核需要适应多种不同的硬件架构，但是将所有的硬件驱动编入内核又是不实际的，而且内核也不可能每新出一种硬件结构，就将该硬件的设备驱动写入内核。实际上Linux的内核镜像仅是包含了基本的硬件驱动，在系统安装过程中会检测系统硬件信息，根据安装信息和系统硬件信息将一部分设备驱动写入 initrd 。这样在以后启动系统时，一部分设备驱动就放在initrd中来加载。这里有必要给大家再多介绍一下initrd这个东东： initrd 的英文含义是 bootloader initialized RAM disk，就是由 boot loader 初始化的内存盘。在 linu2.6内核启动前，boot loader 会将存储介质中的 initrd 文件加载到内存，内核启动时会在访问真正的根文件系统前先访问该内存中的 initrd 文件系统。在 boot loader 配置了 initrd 的情况下，内核启动被分成了两个阶段，第一阶段先执行 initrd 文件系统中的init，完成加载驱动模块等任务，第二阶段才会执行真正的根文件系统中的 /sbin/init 进程。 另外一个概念：initramfs initramfs 是在 kernel 2.5中引入的技术，实际上它的含义就是：在内核镜像中附加一个cpio包，这个cpio包中包含了一个小型的文件系统，当内核启动时，内核将这个 cpio包解开，并且将其中包含的文件系统释放到rootfs中，内核中的一部分初始化代码会放到这个文件系统中，作为用户层进程来执行。这样带来的明显的好处是精简了内核的初始化代码，而且使得内核的初始化过程更容易定制。疑惑的是：我的内核是2.6.32-71.el6.i686版本，但在我的/boot分区下面却存在的是/boot/initramfs-2.6.32-71.el6.i686.img类型的文件，没搞明白，还望高人解惑。我只知道在2.6内核中支持两种格式的initrd，一种是2.4内核的文件系统镜像image-initrd，一种是cpio格式。接下来我们就来探究一下initramfs-2.6.32-71.el6.i686.img里到底放了那些东西。 在tmp文件夹中解压initrd.img里的内容： 如果initrd.img文件的格式显示为“initrd.img:ISO 9660 CD-ROM filesystem data”，则可直接输入命令“mount -o loop initrd.img /mnt/test”进行挂载。 通过上的分析和我们的验证，我们确实得到了这样的结论： grub的stage2将initrd加载到内存里，让后将其中的内容释放到内容中，内核便去执行initrd中的init脚本，这时内核将控制权交给了init文件处理。我们简单浏览一下init脚本的内容，发现它也主要是加载各种存储介质相关的设备驱动程序。当所需的驱动程序加载完后，会创建一个根设备，然后将根文件系统rootfs以只读的方式挂载。这一步结束后，释放未使用的内存，转换到真正的根文件系统上面去，同时运行/sbin/init程序，执行系统的1号进程。此后系统的控制权就全权交给/sbin/init进程了。l 初始化系统经过千辛万苦的跋涉，我们终于接近黎明的曙光了。接下来就是最后一步了：初始化系统。/sbin/init进程是系统其他所有进程的父进程，当它接管了系统的控制权先之后，它首先会去读取/etc/inittab文件来执行相应的脚本进行系统初始化，如设置键盘、字体，装载模块，设置网络等。主要包括以下工作：1)、执行系统初始化脚本(/etc/rc.d/rc.sysinit)，对系统进行基本的配置，以读写方式挂载根文件系统及其它文件系统，到此系统算是基本运行起来了，后面需要进行运行级别的确定及相应服务的启动。rc.sysinit所做的事情(不同的Linux发行版，该文件可能有些差异)如下：（1）获取网络环境与主机类型。首先会读取网络环境设置文件”/etc/sysconfig/network”，获取主机名称与默认网关等网络环境。（2）测试与载入内存设备/proc及usb设备/sys。除了/proc外，系统会主动检测是否有usb设备，并主动加载usb驱动，尝试载入usb文件系统。（3）决定是否启动SELinux。（4）接口设备的检测与即插即用（pnp）参数的测试。（5）用户自定义模块的加载。用户可以再”/etc/sysconfig/modules/.modules”加入自定义的模块，此时会加载到系统中。（6）加载核心的相关设置。按”/etc/sysctl.conf”这个文件的设置值配置功能。（7）设置系统时间（clock）。（8）设置终端的控制台的字形。（9）设置raid及LVM等硬盘功能。（10）以方式查看检验磁盘文件系统。（11）进行磁盘配额quota的转换。（12）重新以读取模式载入系统磁盘。（13）启动quota功能。（14）启动系统随机数设备（产生随机数功能）。（15）清楚启动过程中的临时文件。（16）将启动信息加载到”/var/log/dmesg”文件中。 当/etc/rc.d/rc.sysinit执行完后，系统就可以顺利工作了，只是还需要启动系统所需要的各种服务，这样主机才可以提供相关的网络和主机功能，因此便会执行下面的脚本。2)、执行/etc/rc.d/rc脚本。该文件定义了服务启动的顺序是先K后S，而具体的每个运行级别的服务状态是放在/etc/rc.d/rc.d（=0~6）目录下，所有的文件均是指向/etc/init.d下相应文件的符号链接。rc.sysinit通过分析/etc/inittab文件来确定系统的启动级别，然后才去执行/etc/rc.d/rc.d下的文件。/etc/init.d-&gt; /etc/rc.d/init.d/etc/rc -&gt;/etc/rc.d/rc/etc/rc.d -&gt;/etc/rc.d/rc.d/etc/rc.local-&gt; /etc/rc.d/rc.local/etc/rc.sysinit-&gt; /etc/rc.d/rc.sysinit也就是说，/etc目录下的init.d、rc、rc.d、rc.local和rc.sysinit均是指向/etc/rc.d目录下相应文件和文件夹的符号链接。我们以启动级别3为例来简要说明一下。/etc/rc.d/rc3.d目录，该目录下的内容全部都是以 S 或 K 开头的链接文件，都链接到”/etc/rc.d/init.d”目录下的各种shell脚本。S表示的是启动时需要start的服务内容，K表示关机时需要关闭的服务内容。/etc/rc.d/rc.d中的系统服务会在系统后台启动，如果要对某个运行级别中的服务进行更具体的定制，通过chkconfig命令来操作，或者通过setup、ntsys、system-config-services来进行定制。如果我们需要自己增加启动的内容，可以在init.d目录中增加相关的shell脚本，然后在rc*.d目录中建立链接文件指向该shell脚本。这些shell脚本的启动或结束顺序是由S或K字母后面的数字决定，数字越小的脚本越先执行。例如，/etc/rc.d/rc3.d /S01sysstat就比/etc/rc.d/rc3.d /S99local先执行。3)、执行用户自定义引导程序/etc/rc.d/rc.local。其实当执行/etc/rc.d/rc3.d/S99local时，它就是在执行/etc/rc.d/rc.local。S99local是指向rc.local的符号链接。就是一般来说，自定义的程序不需要执行上面所说的繁琐的建立shell增加链接文件的步骤，只需要将命令放在rc.local里面就可以了，这个shell脚本就是保留给用户自定义启动内容的。4)、完成了系统所有的启动任务后，linux会启动终端或X-Window来等待用户登录。tty1,tty2,tty3…这表示在运行等级1，2，3，4的时候，都会执行”/sbin/mingetty”，而且执行了6个，所以linux会有6个纯文本终端，mingetty就是启动终端的命令。除了这6个之外还会执行”/etc/X11/prefdm-nodaemon”这个主要启动X-Window至此，系统就启动完毕了。以上分析不到的地方还请各位大虾不吝指正。关于Linux的其他分析内容下次再继续写。最后附上一张非常完整的系统启动流程图，适合各个水平阶段的读者。 参考文献：http://www.cnblogs.com/scnutiger/archive/2009/09/30/1576795.htmlhttp://www.it.com.cn/f/edu/0411/24/51090.htmhttp://bbs.chinaunix.net/thread-2046548-1-1.htmlhttp://space.itpub.net/8111049/viewspace-680043http://dongdiy.blog.51cto.com/1908223/366909http://icarusli.iteye.com/blog/625755http://www.54sa.net/?p=549http://roclinux.cn/?p=1301","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ipcreator.me/tags/Linux/"}]},{"title":"小议Linux系统下的文件系统","date":"2017-02-27T01:14:06.000Z","path":"2017/02/27/Program/Concepts/the-anatomy-of-file-system/","text":"wjlkoorey Linux的老江湖们对这个概念当然不会陌生，然而刚接触Linux的新手们就会被文件系统这个概念弄得晕头转向，恰好我当年正好属于后者。 从windows下转到Linux的童鞋听到最多的应该是fat32和ntfs(在windows 2000之后所出现的一种新型的日志文件系统)，那个年代经常听到说“我要把C盘格式化成ntfs格式，D盘格式化成fat32格式”。一到Linux下，很多入门Linux的书籍中当牵扯到文件系统这个术语时，二话不说，不管三七二十一就给出了下面这个图，然后逐一解释一下每个目录是拿来干啥的、里面会放什么类型的文件就完事儿了，弄得初学者经常“丈二和尚摸不着头脑”。难道这就是Linux下的文件系统。而且新手一直被“灌输”一个思想：Linux下一切都是文件，不再像Windows那样用扩展名来为文件分类等等。这就让那些喜欢刨根问底的fresh-fish很是不爽，他们本着对学术的严谨、技术的狂热的态度，一心想弄明白：到底什么才是文件系统。本文的目的就是和大家分享一下我当初是如何学习Linux的文件系统的，也算是一个“老”油条的一些心得吧。 更多参考： 戏说文件系统之ext2【上】 戏说文件系统之ext2【下】 戏说文件系统之ext2【续】 戏说文件系统之ext3【上】 “文件系统”的主语是“文件”，那么文件系统的意思就是“用于管理文件的(管理)系统”，而这套管理系统所管理的对象当然就是文件了。在大多数操作系统里，“文件是数据的集合”这个基本点是一致的，而这些数据最终都是存储在存储介质里，如硬盘、光盘、U盘等。 另一方面，用户在管理数据时也是文件为基本单位，他们所关心的问题是：1、我的文件在什么地方放着？2、我如何将数据存入某个文件？3、如何从文件里将数据读出来？3、不再需要的文件怎么将其删除？ 简而言之，文件系统就是一套用于定义文件的命名和组织数据的规范，其根本目的是便对文件进行查询和存取。 Unix/Linux系统中的文件系统有个很重要的特性就挂载，即文件系统在使用前必须被挂载在一个实际的目录下才能使用，这是因为类Unix系统中的文件系统都遵循了FHS(Filesystem Hierarchy Standard)。在FHS中详细定义了类Unix操作系统中各种应用软件、管理工具、开发工具、脚本和帮助文件所处的位置。这样，通过该标准，软件发布商和用户在不同的发行版的linux系统里都能预测软件安装后，文件和目录所处的位置。 文件系统为了实现对文件更好的管理、组织方式，引入了目录的概念。目录里不但可以保存文件还可以保存目录，以目录为依托，最终会形成一个目录树的结构。根据FHS的规定，Linux不同的发行版都存在如下的目录结构：上图中一个比较特殊的目录就是硬盘的根目录“/”，如果我们将一块硬盘格式化成ext3或ext4格式后，通过mount命令将其挂载到根目录下，就形成了我们通常所说的“根文件系统”。根文件系统不是一个新实体，而是指挂载在根目录下的存储设备(或某个分区)实际所使用的文件系统类型。当“根文件系统”被挂载后，内存中就有了如上所示的目录结构树。这里提醒一点，千万不要以为你在命令行输入“cd /usr/src/”等命令时是在“操作”硬盘，其实你是在内存的VFS的目录树里。这里就不展开了，后面剖析VFS时再详细介绍。作为用户在使用文件系统时，对于某个具体的存储设备，例如U盘或硬盘，无非是首先执行诸如mk2fs或mkfs.xxx这样的命令对存储设备进行格式化，将其格式化成某种类型的文件系统，然后用mount命令将该存设备挂载到某个具体的目录下，然后对该目录下的文件进行“增、删、改、查”就可以实现对该存储设备上数据的操作。 这里就有几个关键点需要大家留意了，以便我们后面分析VSF机制时心里能做到“提前亮”。在类Unix系统中讨论文件系统，不可回避的要就要牵扯到挂载(mount)机制，在windows下这个过程已经被微软封装了，普通用户察觉不到，至少在我接触windows这么些年从来没听谁跟我提起过windows下的mount机制。所以我们在分析源码时可以留意一下挂载的实现机制。另一个就是目录，这个再熟悉不过，Unix/Linux和Windows，几乎所有的操作系统都至此，其目的就是用来对文件进行组织便于用户管理，即站在用户的角度来说就是回答了“我的文件在哪儿放着”的问题。 在Linux早期设计阶段，文件系统与内核代码是整合在一起的，这样做的缺点是显而易见的。假如，我的系统只能识别ext3格式的文件系统，我的U盘是fat32格式，那么很不幸的是我的U盘将不会被我的系统所识别，所以fat32格式的U盘在我们的系统上将无法使用。为了支持不同种类的文件系统，Linux采用了在Unix系统中已经广泛采用的设计思想，通过虚拟文件系统VFS来屏蔽下层各种不同类型文件系统的实现细节和差异。其实VFS最早是由Sun公司提出的，目的是实现网络文件系统NFS(Network File System)，其基本思想是将各种文件系统的公共部分抽取出来，形成一个抽象层。对用户的应用程序而言，VFS提供了文件系统的系统调用接口。而对具体的文件系统来说，VFS通过一系列统一的外部接口屏蔽了实现细节，使得对文件的操作不再关心下层文件系统的类型，更不用关心具体的存储介质，这一切都是透明的。 小结一下：所谓文件系统就是操作系统用来明确磁盘或分区上的文件以及数据结构的一种方法，也就是磁盘上文件的组织方法。普通用户所看到的文件系统，是以目录结构而存在的一个多级分层的树状结构，但作为开发人员我们得知道其实每个目录下都可以挂载不同类型的文件系统。最后一点是，每个文件系统可以占用磁盘的一个分区，而不是整个硬盘，这一点请注意。VFS并不是一个实际的文件系统，它是类Unix操作系统给我们提供的一种用于统一管理具体文件系统的机制。当我们要开发一种新的文件系统时，需要遵照VFS的规范，才能享受VFS带来的好处。 未完，待续…","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"File System","slug":"File-System","permalink":"http://ipcreator.me/tags/File-System/"}]},{"title":"显示卡的“心脏” GPU工作原理介绍","date":"2017-02-27T00:58:06.000Z","path":"2017/02/27/Program/Concepts/the-anatomy-of-GPU/","text":"designapp 图形处理器(英语：Graphics Processing Unit，缩写：gpu)，又称显示核心、视觉处理器、显示芯片，是一种专门在个人电脑、工作站、游戏机和一些移动设备(如平板电脑、智能手机等)上图像运算工作的微处理器。 用途是将计算机系统所需要的显示信息进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。显卡作为电脑主机里的一个重要组成部分，承担输出显示图形的任务，对于从事专业图形设计的人来说显卡非常重要。 gpu由于历史原因，是为了视频游戏而产生的(至今其主要驱动力还是不断增长的视频游戏市场)，在三维游戏中常常出现的一类操作是对海量数据进行相同的操作，如：对每一个顶点进行同样的坐标变换，对每一个顶点按照同样的光照模型计算颜色值。 gpu的众核架构非常适合把同样的指令流并行发送到众核上，采用不同的输入数据执行。在 2003-2004年左右，图形学之外的领域专家开始注意到gpu与众不同的计算能力，开始尝试把gpu用于通用计算(即GPgpu)。之后NVIDIA发布了CUDA，amd和等公司也发布了OpenCL，gpu开始在通用计算领域得到广泛应用，包括：数值分析，海量数据处理(排序，Map- Reduce等)，金融分析等等。 简而言之，当程序员为cpu编写程序时，他们倾向于利用复杂的逻辑结构优化算法从而减少计算任务的运行时间，即Latency。当程序员为gpu编写程序时，则利用其处理海量数据的优势，通过提高总的数据吞吐量(Throughput)来掩盖 Lantency。 目前，cpu和gpu的区别正在逐渐缩小，因为gpu也在处理不规则任务和线程间通信方面有了长足的进步。另外，功耗问题对于gpu比cpu更严重。 gpu是显示卡的“心脏”，也就相当于cpu在电脑中的作用，它决定了该显卡的档次和大部分性能，同时也是2D显示卡和3D显示卡的区别依据。 2D显示芯片在处理3D图像和特效时主要依赖cpu的处理能力，称为“软加速”。3D显示芯片是将三维图像和特效处理功能集中在显示芯片内，也即所谓的“硬件加速”功能。显示芯片通常是显示卡上最大的芯片(也是引脚最多的)。gpu使显卡减少了对cpu的依赖，并进行部分原本cpu的工作，尤其是在3D图形处理时。gpu所采用的核心技术有硬体T&amp;L、立方环境材质贴图和顶点混合、纹理压缩和凹凸映射贴图、双重纹理四像素256位渲染引擎等，而硬体T&amp;L技术可以说是gpu的标志。 gpu工作原理-工作原理简单的说gpu就是能够从硬件上支持T&amp;L(Transform and LighTIng，多边形转换与光源处理)的显示芯片，因为T&amp;L是3D渲染中的一个重要部分，其作用是计算多边形的3D位置和处理动态光线效果，也可以称为“几何处理”。一个好的T&amp;L单元，可以提供细致的3D物体和高级的光线特效;只不过大多数PC中，T&amp;L的大部分运算是交由cpu处理的(这就也就是所谓的软件T&amp;L)，由于cpu的任务繁多，除了T&amp;L之外，还要做内存管理、输入响应等非3D图形处理工作，因此在实际运算的时候性能会大打折扣，常常出现显卡等待cpu数据的情况，其运算速度远跟不上今天复杂三维游戏的要求。即使cpu的工作频率超过 1GHz或更高，对它的帮助也不大，由于这是PC本身设计造成的问题，与cpu的速度无太大关系。 gpu图形处理，可以大致分成 5 个步骤，如下图箭头的部分。分别为 vertex shader、primiTIve processing、rasterisaTIon、fragment shader、tesTIng and blending。 第一步，vertex shader。是将三维空间中数个(x，y，z)顶点放进 gpu 中。在这一步骤中，电脑会在内部模拟出一个三维空间，并将这些顶点放置在这一空间内部。接着，投影在同一平面上，也是我们将看到的画面。同时，存下各点距离投影面的垂直距离，以便做后续的处理。 这个过程就像是本地球观看星星一般。地球的天空，就像是一个投影面，所有的星星，不管远近皆投影在同一面上。本地球的我们，抬起头来观看星星，分不出星星的远近，只能分辨出亮度。gpu 所投影出的结果，和这个情况类似。 从地球所看到的星空，星星就像是投影到一球面上，除非使用特别的仪器，不然分不出星星和地球的距离 第二步，primitive processing。是将相关的点链接在一起，以形成图形。在一开始输入数个顶点进入 gpu 时，程序会特别注记哪些点是需要组合在一起，以形成一线或面。就像是看星座的时候一样，将相关连的星星连起来，形成特定的图案。 第三步，rasterisation。因为电脑的屏幕是由一个又一个的像素组成，因此，需要将一条连续的直线，使用绘图的演算法，以方格绘出该直线。图形也是以此方式，先标出边线，再用方格填满整个平面。 第四步，fragment shader。将格点化后的图形着上颜色。所需着上的颜色也是于输入时便被注记。在游玩游戏时，这一步相当耗费 gpu 的计算资源，因为光影的效果、物体表面材质皆是在这一步进行，这些计算决定着游戏画面的精细程度。因此在游玩游戏时，调高游戏画面品质大幅增加这一步的计算负担，降低游戏品质。 将一个三角形，用方格呈现近似原始图案，并着上颜色。一块又一块的方格，就是显示器上的像素 最后一步，testing and blending。便是将第一步所获得的投影垂直距离取出，和第四步的结果一同做最后处理。在去除被会被其他较近距离的物体挡住的物体后，让剩下的图形放进 gpu 的输出内存。之后，结果便会被送到电脑屏幕显示。 gpu工作原理-主要供应商gpu有非常多的厂商都生产，和cpu一样，生产的厂商比较多，但大家熟悉的却只有INA，以至于大家以为gpu只有三大厂商。 英特尔英特尔的gpu基本为集成显卡芯片，用于英特尔的主板和英特尔的cpu。可能你想不到，要是只按市场占有率计算，英特尔随着他主板及cpu发售的集成gpu占据了整个gpu市场的60%以上。 他的gpu主要有：唯一一款独立显卡芯片Intel 740(i740)。Extreme Graphics系列、GMA系列(集成于芯片组中)。现在的HD Graphics系列[1] 、Iris? Graphics系列[2] 、Iris? Pro Graphics[2] 系列等(集成于cpu中)。 NVIDIANVIDIA是现在最大的独立显卡芯片生产销售商。他的gpu包括大家熟悉的Geforce系列 ，包括GTX、GTS、GT等。专业工作站的Quadro系列 ，超级计算的Tesla系列 ，多显示器商用的NVS系列 ，移动设备的Tegra系列 。 以前也销售集成在主板上的集成显卡芯片，这些随着主板芯片组一起发售，但是由于amd收购ATI后自身主板芯片组gpu能力提高，NVIDIA芯片组如日中天的景象已经消失了。曾经为游戏机Xbox、PS3供应gpu。 amd(ATI)amd是世界上第二大的独立显卡芯片生产销售商，他的前身就是ATI，2006年amd以54亿美元收购ATI。他的gpu主要是大家熟悉的Radeon系列，包括以前的X、HD系列，近几年的R9、R7、R5、R3，现在的RX系列等。专业工作站的FireGL系列，超级计算的FireStream系列，多显示器商用的FireMV系列，现在前三者已合并为FirePro系列 。 早期ATI还生产过Wonder系列、Mach系列、Rage系列芯片。除了独立显卡之外amd还拥有集成显卡芯片，集成于芯片组、APU中。由于amd收购ATI后，其主板市场迅速扩大，已经夺取了NVIDIA在amd处理器主板芯片组的半壁江山。就现在的发售量和发售盈利方面，amd的gpu市场占有率方面仍然略输于NVIDIA。amd也是游戏机Xbox 360、Wii、Wii U、PS4、Xbox One的gpu供应商。 3dfx是一家于1994年成立的生产3D gpu及显卡的公司。曾经生产了Voodoo系列显卡，并且研发了SLI技术。由于经营不善等问题于2002年被NVIDIA收购。 MatroxMatrox当年和NVIDIA，ATI一起争夺独立显卡芯片市场份额的一家公司，在曾经的一个时期Matrox的显卡和NVIDIA，ATI曾经在性能上比肩过。但由于后来其开发能力日渐衰退，在GF5时期，也就是ATI的9000系列时期，Matrox由于性能上整整落后了GF5900和Raden9800一个世代而逐渐被淘汰，淡出了民用独立显卡市场。但时下Matrox仍然在工程用专业显卡方面有自己的地位。 这些显卡用于工程主图和多头输出仍然很强力。与NVIDIA和amd的专业显卡不同，NVIDIA，ATI的专业显卡涉足的是3D领域，而Matrox得专业显卡涉足的是2D领域，也就是CAD。但由于OpenCL、CUDA的日渐普及，DX10以上显卡将在所有支持CUDA的程序上表现出惊人的性能，也就是说当CUDA在各种运用软件普及的那天，Matrox也必将退出2D专业卡的市场。 SiS和VIA矽统和威盛时下是对孪生兄弟，但他们曾经也是分开的两家公司，并且都生产自己主板的集成显卡芯片。但这可怜的两兄弟已经逐步在淡出主板市场了，也就必定将淡出gpu市场。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"http://ipcreator.me/tags/GPU/"}]},{"title":"硬盘的存储原理和内部架构","date":"2017-02-27T00:58:06.000Z","path":"2017/02/27/Program/Concepts/the-anatomy-of-hard-disk/","text":"wjlkoorey 本来想写个文件系统的专题，结果发现对硬盘的内部架构和存储原理还是比较模糊，因为不了解“一点”硬盘的存储原理对文件系统的认识老是感觉镜花水月，不踏实。经过搜集整理资料就由了本文的问世。借用Bean_lee兄一句话：成果和荣耀归于前辈。 首先，让我们看一下硬盘的发展史：1956年9月13日，IBM的IBM 350 RAMAC(Random Access Method of Accounting and Control)是现代硬盘的雏形，整个硬盘需要50个直径为24英寸表面涂有磁浆的盘片，它相当于两个冰箱的体积，不过其存储容量只有5MB。1971年，IBM开始采用一种名叫Merlin的技术生产硬盘，这种技术据称能使硬盘头更好地在盘片上索引。1973年，IBM 3340问世，主流采用采用红色。这个大家伙每平方英寸存储1.7MB的数据，在当时已经创了一个纪录。许多公司共享这些系统，需要时按照时间和存储空间租用它。租赁价值为7.81美元每兆，这个价格比当时汽油的价格还贵38%。它拥有“温彻斯特”这个绰号，也就是我们现在所熟知的“温氏架构”。来源于它两个30MB的存储单元，恰好是当时出名的“温彻斯特来福枪”的口径和填弹量。至此，硬盘的基本架构被确立。1979年，IBM发明了Thin Film磁头，使硬盘的数据定位更加准确，因此使得硬盘的密度大幅提升。1980年，两位前IBM员工创立的公司开发出5.25英寸规格的5MB硬盘，这是首款面向台式机的产品，而该公司正是希捷公司（Seagate）公司。1982年，日立发布了全球首款容量超过1GB的硬盘。这就是容量为1.2GB的H-8598硬盘。这块硬盘拥有10片14英寸盘片，两个读写磁头。1980年代末，IBM推出MR（Magneto Resistive磁阻）技术令磁头灵敏度大大提升，使盘片的存储密度较之前的20Mbpsi（bit/每平方英寸）提高了数十倍，该技术为硬盘容量的巨大提升奠定了基础。1991年，IBM应用该技术推出了首款3.5英寸的1GB硬盘。1970年到1991年，硬盘碟片的存储密度以每年25%~30%的速度增长；从1991年开始增长到60%～80%；至今，速度提升到100%甚至是200%。从1997年开始的惊人速度提升得益于IBM的GMR（Giant Magneto Resistive，巨磁阻）技术，它使磁头灵敏度进一步提升，进而提高了存储密度。1993年，康诺（Conner Peripherals）推出了CP30344硬盘容量是340MB。1995年，为了配合Intel的LX芯片组，昆腾与Intel携手发布UDMA 33接口—EIDE标准将原来接口数据传输率从16.6MB/s提升到了33MB/s。同年，希捷开发出液态轴承（FDB，Fluid Dynamic Bearing）马达。所谓的FDB就是指将陀螺仪上的技术引进到硬盘生产中，用厚度相当于头发直径十分之一的油膜取代金属轴承，减轻了硬盘噪音与发热量。1996年，希捷收购康诺（Conner Peripherals）1998年2月，UDMA 66规格面世。2000年10月，迈拓（Maxtor）收购昆腾。2003年1月，日立宣布完成20.5亿美元的收购IBM硬盘事业部计划，并成立日立环球存储科技公司（Hitachi Global StorageTechnologies, Hitachi GST）。2005年日立环储和希捷都宣布了将开始大量采用磁盘垂直写入技术（perpendicular recording），该原理是将平行于盘片的磁场方向改变为垂直（90度），更充分地利用的存储空间。2005年12月21日，希捷宣布收购迈拓（Maxtor）。2007年1月，日立环球存储科技宣布将会发售全球首只1Terabyte的硬盘，比原先的预定时间迟了一年多。硬盘的售价为399美元，平均每美分可以购得27.5MB硬盘空间。2011年3月，西部数据以43亿美元的价格，收购日立环球存储科技。2011年4月，希捷宣布与三星强化策略伙伴关系。 从硬盘问世至今已经过了56个年头，不管是容量、体积还是生产工艺都较之前有了重大革新和改进，但一直都保持了“温氏”的架构(固态硬盘除外，它不是我们今天的主角)。经过封装后的硬盘，对我们一般呈现出如下的样子： 背面： 打开后盖： 硬盘主要由盘体、控制电路板和接口部件组成。盘体就是一个密封，封装了多个盘片的腔体；控制电路包含硬盘BIOS，主控芯片和硬盘缓存等单元；接口部件包含电源、数据接口主从跳线等。 硬盘的盘片一般采用合金材料，多数为铝合金(IBM曾经开发过玻璃材质的盘片，好像现在有些厂家也生产玻璃材质的盘片，但不多见)，盘面上涂着磁性材料，厚度一般在0.5mm左右。有些硬盘只装一张盘片，有些则有多张。硬盘盘片安装在主轴电机的转轴上，在主轴电机的带动下作高速旋转。每张盘片的容量称为单碟容量，而一块硬盘的总容量就是所有盘片容量的总和。早期硬盘由于单碟容量低，所以盘片较多。现代的硬盘盘片一般只有少数几片。 盘片上的记录密度很大，而且盘片工作时会高速旋转，为保证其工作的稳定，数据保存的长久，所以硬片都是密封在硬盘内部。不可自行拆卸硬盘，在普通环境下空气中的灰尘、指纹、头发丝等细小杂质都会对硬盘造成永久损害。一个被大卸八块的硬盘如下： 接下来我们了解一下硬盘的盘面，柱面，磁道和扇区的概念。 盘面 硬盘一般会有一个或多个盘片，每个盘片可以有两个面(Side)，即第1个盘片的正面称为0面，反面称为1面；第2个盘片的正面称为2面，反面称为3面...依次类推。每个盘面对应一个磁头(head)用于读写数据。第一个盘面的正面的磁头称为0磁头，背面称为1磁头；第二个盘片正面的磁头称为2磁头，背面称为3磁头，以此类推。盘面数和磁头数是相等的。 一张单面的盘片需要一个磁头，双面的盘片则需要两个磁头。硬盘采用高精度、轻型磁头驱动和定位系统。这种系统能使磁头在盘面上快速移动，读写硬盘时，磁头依靠磁盘的高速旋转引起的空气动力效应悬浮在盘面上，与盘面的距离不到1微米(约为头发直径的百分之一)，可以在极短的时间内精确定位到计算机指令指定的磁道上。 早期由于定位系统限制，磁头传动臂只能在盘片的内外磁道之间移动。因此，不管开机还是关机，磁头总在盘片上。所不同的是，关机时磁头停留在盘片启停区，开机时磁头“飞行”在磁盘片上方。 磁道 每个盘片的每个盘面被划分成多个狭窄的同心圆环，数据就是存储在这样的同心圆环上，我们将这样的圆环称为磁道(Track)，每个盘面可以划分多个磁道。关机时磁头停留在硬盘的着陆区(Landing Zone)，这个着陆区以前是位于离盘心最近的区域，不存放任何数据。在后期的硬盘工艺中有些硬盘生产厂商将这个区域被移动到了盘片的外面，如下所示： 在每个盘面的最外圈，离盘心最远的地方是“0”磁道，向盘心方向依次增长为1磁道，2磁道，等等。硬盘数据的存放就是从最外圈开始。 扇区 根据硬盘规格的不同，磁道数可以从几百到成千上万不等。每个磁道上可以存储数KB的数据，但计算机并不需要一次读写这么多数据。在这一这基础上，又把每个磁道划分成若干弧段，每段称为一个扇区(Sector)。扇区是硬盘上存储的物理单位，每个扇区可存储128×2N次方（N＝0,1,2,3）字节的数据。从DOS时代起，每扇区是128×22＝512字节，现在已经成了业界不成文的规定，也没有哪个硬盘厂商试图去改变这种约定。也就是说即使计算机只需要硬盘上存储的某个字节，也须一次把这个字节所在的扇区中的全部512字节读入内存，再选择所需的那个字节。扇区的编号是从1开始，而不是0，这一点需要注意。另外，硬盘在划分扇区时，和软盘是有一定区别的。软盘的一个磁道中，扇区号一般依次编排，如1号，2号，3号...以此类推。但在硬盘磁道中，扇区号是按照某个间隔跳跃着编排。比如，2号扇区并不是1号扇区后的按顺序的第一个而是第八个，3号扇区又是2号扇区后的按顺序的第八个，依此类推，这个“八”称为交叉因子。 这个交叉因子的来历有必要详述一下，我们知道，数据读取经常需要按顺序读取一系列相邻的扇区(逻辑数据相邻)。如对磁道扇区按物理顺序进行编号，很有可能出现当磁头读取完第一个扇区后，由于盘片转速过快来不及读取下一个扇区，(要知道物理相邻扇区位置距离是极小的)，必须等待转完一圈，这极大浪费了时间。所以就用交叉来解决这个问题。增加了交叉因子后的扇区编号一般是下面这个样子： 柱面 柱面其实是我们抽象出来的一个逻辑概念，前面说过，离盘心最远的磁道为0磁道，依此往里为1磁道，2磁道，3磁道….，不同面上相同磁道编号则组成了一个圆柱面，即所称的柱面(Cylinder)。这里要注意，硬盘数据的读写是按柱面进行，即磁头读写数据时首先在同一柱面内从0磁头开始进行操作，依次向下在同一柱面的不同盘面(即磁头上)进行操作，只有在同一柱面所有的磁头全部读写完毕后磁头才转移到下一柱面，因为选取磁头只需通过电子切换即可，而选取柱面则必须通过机械切换。电子切换比从在机械上磁头向邻近磁道移动快得多。因此，数据的读写按柱面进行，而不按盘面进行。 读写数据都是按照这种方式进行，尽可能提高了硬盘读写效率。 簇 将物理相邻的若干个扇区称为了一个簇。操作系统读写磁盘的基本单位是扇区，而文件系统的基本单位是簇(Cluster)。在Windows下，随便找个几字节的文件，在其上面点击鼠标右键选择属性，看看实际大小与占用空间两项内容，如大小：15 字节 (15 字节)， 占用空间：4.00 KB (4，096 字节)。这里的占用空间就是你机器分区的簇大小，因为再小的文件都会占用空间，逻辑基本单位是4K，所以都会占用4K。 簇一般有这几类大小 4K，8K，16K，32K，64K等。簇越大存储性能越好，但空间浪费严重。簇越小性能相对越低，但空间利用率高。NTFS格式的文件系统簇的大小为4K。 硬盘读写数据的过程 现代硬盘寻道都是采用CHS(Cylinder Head Sector)的方式，硬盘读取数据时，读写磁头沿径向移动，移到要读取的扇区所在磁道的上方，这段时间称为寻道时间(seek time)。因读写磁头的起始位置与目标位置之间的距离不同，寻道时间也不同。目前硬盘一般为2到30毫秒，平均约为9毫秒。磁头到达指定磁道后，然后通过盘片的旋转，使得要读取的扇区转到读写磁头的下方，这段时间称为旋转延迟时间(rotational latencytime)。 一个7200（转/每分钟）的硬盘，每旋转一周所需时间为60×1000÷7200=8.33毫秒，则平均旋转延迟时间为8.33÷2=4.17毫秒（平均情况下，需要旋转半圈）。平均寻道时间和平均选装延迟称为平均存取时间。 所以，最后看一下硬盘的容量计算公式： 硬盘容量=盘面数×柱面数×扇区数×512字节 在博文“Linux启动过程分析”中我们提到过MBR，它是存在于硬盘的0柱面，0磁头，1扇区里，占512字节的空间。这512字节里包含了主引导程序Bootloader和磁盘分区表DPT。其中Bootloader占446字节，分区表占64字节，一个分区要占用16字节，64字节的分区表只能被划分4个分区，这也就是目前我们的硬盘最多只能支持4个分区记录的原因。 即，如果你将硬盘分成4个主分区的话，必须确保所有的磁盘空间都被使用了(这不是废话么)，一般情况下我们都是划分一个主分区加一个扩展分区，然后在扩展分区里再继续划分逻辑分区。当然，逻辑分区表也需要分区表，它是存在于扩展分区的第一个扇区里，所以逻辑分区的个数最多也只能有512/16=32个，并不是想分多少个逻辑分区都可以。 注意，我们所说的扩展分区也是要占用分区表项的。例如，如果我们的硬盘只划分一个主分区和一个逻辑分区，此时的分区表的排列如下： Device Boot Start End Blocks Id System/dev/sda1 * 1 19 152586 83 Linux/dev/sda2 20 2569 20482875 83 Extended/dev/sda5 2570 19457 4128705 82 Linux 主分区为1号分区，扩展分区占用了2号分区，3和4号扩展分区被预留了下来，逻辑分区从5开始编号依次递增，这里我们只划分了一个逻辑分区。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"File System","slug":"File-System","permalink":"http://ipcreator.me/tags/File-System/"}]},{"title":"CPU的内部架构和工作原理","date":"2017-02-27T00:06:06.000Z","path":"2017/02/27/Program/Concepts/the-anatomy-of-cpu/","text":"wjlkoorey 更多参考 处理器体系结构（了解CPU的基本运行原理）——《深入理解计算机系统》CPU的实模式与保护模式（简介） 一直以来，总以为CPU内部真是如当年学习《计算机组成原理》时书上所介绍的那样，是各种逻辑门器件的组合。当看到纳米技术时就想，真的可以把那些器件做的那么小么？直到看了Intel CPU制作流程及AMD芯片的制作流程的介绍不禁感慨，原来科技是如此的发达。 本文我们以Intel为例对CPU的工作原理做简单介绍，仅仅是简单介绍，那么AMD，ARM，MIPS甚至PowerPC你应该会触类旁通才对。 还记得那是1968年7月18日，鲍勃-诺斯和戈登-摩尔的新公司在美国加利福尼亚州，美丽的圣弗朗西斯科湾畔芒延维尤城的梅多费大街365号开张了。并在成立不久斥资15000美元从一家叫INTELCO的公司手中买下了Intel名称的使用权。由此Intel这位半导体巨人开始了他在IT行业传奇般的历史。 1971年11月15日，这一天被当作全球IT界具有里程碑意义的日子而被写入许多计算机专业教科书。Intel公司的工程师特德·霍夫发明了世界上第一个微处理器—4004，这款4位微处理器虽然只有45条指令，而且每秒只能执行5万条指令。甚至比不上1946年由美国陆军宾夕法尼亚大学研制的世界第一台计算机ENIAC。但它的集成度却要高很多，一块4004的重量还不到一盅司。 他因发明了微处理器，被英国《经济学家》杂志称为“第二次世界大战以来最有影响的科学家之一”。Intel公司的CPU发展历程如下表所示： 以及后面的Pentium 1,2,3和4，再到酷睿、酷睿2，这里就不再一一列举。Intel从8086开始，就进入了我们所谓的x86时代。而80386的诞生则标志着Intel正是进入了32位微处理器的时代。从80386到Pentium 4这个年代的CPU，就是传说中的IA-32时代。 我们都知道CPU的根本任务就是执行指令，对计算机来说最终都是一串由“0”和“1”组成的序列。CPU从逻辑上可以划分成3个模块，分别是控制单元、运算单元和存储单元，这三部分由CPU内部总线连接起来。如下所示： 控制单元： 控制单元是整个CPU的指挥控制中心，由指令寄存器IR(Instruction Register)、指令译码器ID(Instruction Decoder)和操作控制器OC(Operation Controller)等，对协调整个电脑有序工作极为重要。它根据用户预先编好的程序，依次从存储器中取出各条指令，放在指令寄存器IR中，通过指令译码(分析)确定应该进行什么操作，然后通过操作控制器OC，按确定的时序，向相应的部件发出微操作控制信号。操作控制器OC中主要包括节拍脉冲发生器、控制矩阵、时钟脉冲发生器、复位电路和启停电路等控制逻辑。 运算单元：是运算器的核心。可以执行算术运算(包括加减乘数等基本运算及其附加运算)和逻辑运算(包括移位、逻辑测试或两个值比较)。相对控制单元而言，运算器接受控制单元的命令而进行动作，即运算单元所进行的全部操作都是由控制单元发出的控制信号来指挥的，所以它是执行部件。 存储单元：包括CPU片内缓存和寄存器组，是CPU中暂时存放数据的地方，里面保存着那些等待处理的数据，或已经处理过的数据，CPU访问寄存器所用的时间要比访问内存的时间短。采用寄存器，可以减少CPU访问内存的次数，从而提高了CPU的工作速度。但因为受到芯片面积和集成度所限，寄存器组的容量不可能很大。寄存器组可分为专用寄存器和通用寄存器。专用寄存器的作用是固定的，分别寄存相应的数据。而通用寄存器用途广泛并可由程序员规定其用途，通用寄存器的数目因微处理器而异。这个是我们以后要介绍这个重点，这里先提一下。 我们将上图细化一下，可以得出CPU的工作原理概括如下： 总的来说，CPU从内存中一条一条地取出指令和相应的数据，按指令操作码的规定，对数据进行运算处理，直到程序执行完毕为止。 上图中我没有画总线，只是用逻辑方式对其进行呈现。原因早期Intel的微处理器，诸如8085，8086/8088CPU，普遍采用了地址总线和数据总线复用技术，即将部分(或全部)地址总线与数据总线共用CPU的一些引脚。例如8086外部地址总线有20根，数据总线复用了地址总线的前16根引脚。复用的数据总线和地址总线虽然可以少CPU的引脚数，但却引入了控制逻辑及操作序列上的复杂性。所以，自80286开始，Intel的CPU才采用分开的地址总线和数据总线。 不管是复用还是分开，对我们理解CPU的运行原理没啥影响，上图没画总线的目的就是怕有些人太过于追求细节，一头扎下去，浮不起来，不能从宏观上藐视敌人。 OK，总结一下， CPU的运行原理 就是：控制单元在时序脉冲的作用下，将指令计数器里所指向的指令地址(这个地址是在内存里的)送到地址总线上去，然后CPU将这个地址里的指令读到指令寄存器进行译码。对于执行指令过程中所需要用到的数据，会将数据地址也送到地址总线，然后CPU把数据读到CPU的内部存储单元(就是内部寄存器)暂存起来，最后命令运算单元对数据进行处理加工。周而复始，一直这样执行下去，天荒地老，海枯枝烂，直到停电。 如果你对这段话还是觉得比较晕乎，那么就看我们老师是怎么讲的： 1、取指令：CPU的控制器从内存读取一条指令并放入指令寄存器。指令的格式一般是这个样子滴： 操作码就是汇编语言里的mov,add,jmp等符号码；操作数地址说明该指令需要的操作数所在的地方，是在内存里还是在CPU的内部寄存器里。 2、指令译码：指令寄存器中的指令经过译码，决定该指令应进行何种操作(就是指令里的操作码)、操作数在哪里(操作数的地址)。 3、 执行指令，分两个阶段“取操作数”和“进行运算”。 4、 修改指令计数器，决定下一条指令的地址。 关于CPU我们从宏观上把握到这个程度就OK了，后面我们会逐步进入微观阶段，依次介绍80X86寄存器及其用途，NASM汇编和AT&amp;T的区别，以及C代码中嵌入的汇编语言的写法。之所以介绍汇编语言目的不是说用汇编去写代码，那是相当的不现实，除非你是硬件驱动工程师。稍微偏上层一点的开发人员懂点低等的东西，对自己理解整个系统的架构和原理是相当有好处的。 未完，待续… 寻访x86处理器“实模式”和“保护模式”的前世今生 8086的诞生，标志着Intel 正式进入了x86时代，这是个多么具有纪念意义的日子：1978-6-8。同时，8086的诞生也是处理器内存寻址技术的第一次飞跃。 对于一根实际的、实实在在的、物理的、可看得见、摸得着的内存条而言，处理器把它当做8位一个字节的序列来管理和存取，每一个内存字节都有一个对应的地址，我们叫它物理地址，用地址可以表示的长度叫做寻址空间。而CPU是如何去访问内存单元里的数据的方式就叫做寻址。 8086得CPU在内存寻址方面第一次引入了一个非常重要的概念—-段。在8086之前都是4位机和8位机的天下，那是并没有段的概念。当程序要访问内存时都是要给出内存的实际物理地址，这样在程序源代码中就会出现很多硬编码的物理地址。这样的程序可想而知，难重定位，可控性弱，结构丑陋，那个年代写这样的程序在我们现在看来是多么让人恼火的一件事儿。 8080问世后四年也就是1978年，Intel开始设计16位CPU，正常来说8086的寻址空间应该是216=64KB才对，但Intel就偏偏不这干，8086的目标寻址空间直指1M，也就是说8086的地址总线位宽要达到20位。如何让16位的内部寄存器对20位的外部地址空间进行寻址，Intel的工程师们从当时的PDP-11小型机身上找到了灵感。PDP-11是美国迪吉多电脑(Digital Equipment Corp.)公司于1970到1980年代热销的16位迷你电脑，PDP-11的内存管理单元(MMU)可以将16位地址映射到24位地址空间里(至于人家是怎么弄，我就真不晓得了)。 为了支持分段机制，Intel在8086的CPU里新增了4个寄存器，分别是代码段CS，数据段DS，堆栈段SS和其他ES(以后深入介绍一下这几个兄弟伙，这涉及到进程的在内存的运行情况)。这样一来，一个物理地址就由两个部分组成，分别是“段地址”:“段内偏移量”。例如，ES=0x1000，DI=0xFFFF，那么这个数据ES:DI在内存里的绝对物理地址就是：AD(Absolute Address)=(ES)*(0x10)+(DI)=0x1FFFF就是讲段基地址左移4位然后加上段内偏移量就得到了物理内存里的绝对地址，经过这么一个变换，就可以得到一个20位的地址，8086就可以对20位的1M内存空间进行寻址了。如下： 很明显，这种方式可以寻址的最高地址为0xFFFF:0xFFFF，其地址空间为0x00000~0x10FFEF，因为8086的地址总线是20位，最大只能访问到1MB的物理地址空间，即物理地址空间是0x00000~0xFFFFF。当程序访问0x100000~0x10FFEF这一段地址时，因为其逻辑上是正常的，CPU并不会认为其访问越界而产生异常，但这段地址确实没有实际的物理地址与其对应，怎么办？此时CPU采取的策略是，对于这部分超出1M地址空间的部分，自动将其从物理0地址处开始映射。也就是说，系统计算实际物理地址时是按照对1M求模运算的方式进行的，在有些技术文献里你会看到这种技术被称之为wrap-around。还是通过一幅图来描述一下吧： 根据前面的讲解我们可以发现段基址有个特征，其低4位全为0，也就是说每个段的起始地址一定是16的整数倍，这是分段的一个基本原则。这样每个段的最小长度是16字节，而最大长度只能是64KB。这里我们可以计算一下，1MB的物理地址空间能划分成多少个段。如果每个段的长度为16字节，这样1MB物理地址空间最多可以划分成64K个段；如果每个段的长度为64KB，那么1MB的物理地址空间最多能划分成16个段。8086这种分段基址虽然实现了寻址空间的提升，但是也带来一些问题：1、同一个物理地址可以有多种表示方法。例如0x01C0:0x0000和0x0000:0x1C00所表示的物理地址都是0x01C00。2、地址空间缺乏保护机制。对于每一个由段寄存器的内容确定的“基地址”，一个进程总是能够访问从此开始64KB的连续地址空间，而无法加以限制。另一方面，可以用来改变段寄存器内容的指令也不是什么“特权指令”，也就是说，通过改变段寄存器的内容，一个进程可以随心所欲地访问内存中的任何一个单元，而丝毫不受限制。不能对一个进程的内存访问加以限制，也就谈不上对其他进程以及系统本身的保护。与此相应，一个CPU如果缺乏对内存访问的限制，或者说保护，就谈不上什么内存管理，也就谈不上是现代意义上的中央处理器。总结一下：8086和后来的80186，这种只能访问1MB地址空间的工作模式，我们将其称之为“实模式”。我的理解就是“实际地址模式”,因为通过段基址和段偏移算出来的地址，经过模1MB之后得出来的地址都是实际内存的物理地址。 由于8086的上述问题，1982年，Intel在80286的CPU里，首次引入的地址保护的概念。也就是说80286的CPU能够对内存及一些其他外围设备做硬件级的保护设置（实质上就是屏蔽一些地址的访问）。自从最初的x86微处理器规格以后，它对程序开发完全向下兼容，80286芯片被制作成启动时继承了以前版本芯片的特性，工作在实模式下，在这种模式下实际上是关闭了新的保护功能特性，因此能使以往的软件继续工作在新的芯片下。后续的x86处理器都是在计算机加电启动时都是工作在实模式下。也就是说，在保护模式下，程序不能再随意的访问物理内存了，有些内存地址CPU做了明确的保护限制。1985年80386的问世，使Intel完成了从16位到32位CPU的飞跃，这中间80286毫无疑问的就成了这次飞跃的跳板。80286的地址线已经达到24位，可寻址空间是16MB，但Intel当初设计80286时提出的目标是向下兼容，这也是Intel一贯的作风，正是这种作风为Intel后面设计80386时增添了几根儿烦恼丝。所以，在“实模式”下，80286所表现的行为和8086所表现的完全一样。80386是32位CPU，也就是说它的ALU数据总线是32位，地址总线的位宽和CPU内部数据总线的位宽是一致的，都是32位，其寻址范围可达4GB。如果重新设计80386的架构，其结构应该相当简洁才对。但是80386却很遗憾的无法做到这一点，作为一个产品系列中的成员分子，80386必须继续维持“前辈”们的那些段寄存器，必须支持实模式，同时还要支持保护模式。可以看得出来，80386其实也不容易。 所以，Intel决定在80386的段寄存器(CS,DS,SS,ES)的基础上构筑保护模式，并且继续保留段寄存器为16位,同时又增添了两个段寄存器FS和GS。显然，为了实现保护模式，光是用段寄存器来确定一个基地址是不够的，至少还要有一个地址段的长度，并且还需要一些诸如访问权限之类的其他信息。所以，这里需要的是一个数据结构(这个数据结构就叫做“段描述符”，以后会看到)，而并非一个单纯的基地址。对此， Intel设计人员的基本思路是：在保护模式下改变段寄存器的功能，使其从一个单纯的段基址变成指向一个“段描述符”的指针。因此，当一个访存指令发出一个内存地址时， CPU按照下面过程实现从指令中的32位逻辑地址到32位线性地址，再到物理地址的转换：1、首先根据指令的性质来确定该使用哪一个段寄存器，例如操作指令中的地址在代码段CS里，而数据指令中的地址在数据段DS里。这一点与实地址模式相同。2、根据段寄存器里的内容，找到相应的“段描述符”结构。3、然后，从“段描述符”里得到的才是段基址。4、将指令中的地址作为偏移量，然后和段描述符结构中规定的段长度进行比较，看齐是否越界。5、根据指令的性质和段描述符中的访问权限来确定当前指令操作是否越权。6、最后才将指令中的地址作为偏移量，与段基址相加得到线性地址，或者叫虚拟地址。7、最后根据线性地址算出实际的物理地址。所以，实模式就是80186及其之前的CPU只能寻址1MB物理地址空间，且寻到的就是实实在在的物理地址的模式，用户程序想干啥干啥，无法无天；而保护模式，就是说用户成的程序，某些地址你是不能访问的，或者说是有限制性的访问，且你访问到的地址不再是物理地址了，而是一个虚拟的地址。这个虚拟地址要经过一系列算法处理，最终映射到实际物理地址单元里去。现在运行在X86CPU上的主流操作系统，如Linux，FreeBSD，Windows95以后的版本以及OS/2等都是工作在保护模式下。一般情况下，处理器只有在上电启动，引导阶段，初始化系统时才会进入实模式，当实模式阶段的任务完成后，它就切换到了保护模式。当切换到保护模式后就很难再回到实模式了，几乎不可能。(注意我的用词) 未完，待续…","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://ipcreator.me/tags/CPU/"}]},{"title":"聊聊clean code","date":"2017-02-26T14:57:06.000Z","path":"2017/02/26/Program/Concepts/the-ways-of-keep-code-clean/","text":"王烨clean code，顾名思义就是整洁的代码，或者说清晰、漂亮的代码，相信大多数工程师都希望自己能写出这样的代码。 也许这是个千人千面的话题，每个工程师都有自己的理解。比如我，从一个天天被骂代码写得烂的人，逐渐学习成长，到现在也能写的出“人模人样”的代码来了。这期间算是积累了一点经验心得，想和大家分享，抛砖引玉。 本文主要针对面向对象编程的clean code来阐述，面向过程代码的思路会比较不同，不在本文的讨论范畴。 代码整洁的大前提代码大部分时候是用来维护的，而不是用来实现功能的这个原则适用于大部分的工程。我们的代码，一方面是编译好让机器执行，完成功能需求；另一方面，是写给身边的队友和自己看的，需要长期维护，而且大部分项目都不是朝生夕死的短命鬼。 大部分情况下，如果不能写出清晰好看的代码，可能自己一时爽快，后续维护付出的代价和成本将远高于你的想象。 对清晰好看代码的追求精神，比所有的技巧都要重要。优秀的代码大部分是可以自描述的，好于文档和注释当你翻看很多开源代码时，会发现注释甚至比我们自己写的项目都少，但是却能看的很舒服。当读完源码时，很多功能设计就都清晰明了了。通过仔细斟酌的方法命名、清晰的流程控制，代码本身就可以拿出来当作文档使用，而且它永远不会过期。 相反，注释不能让写的烂的代码变的更好。如果别人只能依靠注释读懂你的代码的时候，你一定要反思代码出现了什么问题（当然，这里不是说大家不要写注释了）。 说下比较适合写注释的两种场景： public interface，向别人明确发布你功能的语义，输入输出，且不需要关注实现。功能容易有歧义的点，或者涉及比较深层专业知识的时候。比如，如果你写一个客户端，各种config参数的含义等。 设计模式只是手段，代码清晰才是目的之前见过一些所谓“高手”的代码都比较抽象，各种工厂、各种继承。想找到一个实现总是要山路十八弯，一个工程里大部分的类是抽象类或者接口，找不到一两句实现的代码，整个读起代码来很不顺畅。我跟他聊起来的时候，他的主要立场是：保留合适的扩展点，克服掉所有的硬编码。 其实在我看来，也许他的代码被“过度设计”了。首先必须要承认的是，在同一个公司工作的同事，水平是参差不齐的。无论你用了如何高大上的设计，如果大多数人都不能理解你的代码或者读起来很费劲的话，其实这是一个失败的设计。 当你的系统内大部分抽象只有一个实现的时候，要好好思考一下，是不是设计有点过度了，清晰永远是第一准则。 代码整洁的常见手段记住原则后，我们开始进入实践环节，先来看下有哪些促成clean code的常见手段。 code review很多大公司会用git的pull request机制来做code review。我们重点应该review什么？是代码的格式、业务逻辑还是代码风格？我想说的是，凡是能通过机器检查出来的事情，无需通过人。比如换行、注释、方法长度、代码重复等。除了基本功能需求的逻辑合理没有bug外，我们更应该关注代码的设计与风格。比如，一段功能是不是应该属于一个类、是不是有很多相似的功能可以抽取出来复用、代码太过冗长难懂等等。 我个人非常推崇集体code review，因为很多时候，组里相对高级的工程师能够一眼发现代码存在较大设计缺陷，提出改进意见或者重构方式。我们可以在整个小组内形成一个好的文化传承和风格统一，并且很大程度上培养了大家对clean code的热情。 勤于重构好的代码，一般都不是一撮而就的。即使一开始设计的代码非常优秀，随着业务的快速迭代，也可能被改的面目全非。 为了避免重构带来的负面影响（delay需求或者带来bug），我们需要做好以下的功课：① 掌握一些常见的“无痛”重构技巧，这在下文会有具体讲解。② 小步快跑，不要企图一口吃成个胖子。改一点，测试一点，一方面减少代码merge的痛苦，另一方面减少上线的风险。③ 建立自动化测试机制，要做到即使代码改坏了，也能保证系统最小核心功能的可用，并且保证自己修改的部分被测试覆盖到。④ 熟练掌握IDE的自动重构功能。这些会很大程度上减少我们的体力劳动，避免犯错。 静态检查现在市面上有很多代码静态检查的工具，也是发现bug和风格不好的比较容易的方式。可以与发布系统做集成，强制把主要问题修复掉才可以上线。目前美团点评技术团队内部的研发流程中已经普遍接入了Sonar质量管理平台。 多读开源代码和身边优秀同学的代码感谢开源社区，为我们提供了这么好的学习机会。无论是JDK的源码，还是经典的Netty、Spring、Jetty，还是一些小工具如Guava等，都是clean code的典范。多多学习，多多反思和总结，必有收益。 代码整洁的常见技巧前面的内容都属于热身，让大家有个整体宏观的认识。下面终于进入干货环节了，我会分几个角度讲解编写整洁代码的常见技巧和误区。 通用技巧单一职责这是整洁代码的最重要也是最基本的原则了。简单来讲，大到一个module、一个package，小到一个class、一个method乃至一个属性，都应该承载一个明确的职责。要定义的东西，如果不能用一句话描述清楚职责，就把它拆掉。 我们平时写代码时，最容易犯的错误是：一个方法干了好几件事或者一个类承载了许多功能。 先来聊聊方法的问题。个人非常主张把方法拆细，这是复用的基础。如果方法干了两件事情，很有可能其中一个功能的其他业务有差别就不好重用了。另外语义也是不明确的。经常看到一个get()方法里面竟然修改了数据，这让使用你方法的人情何以堪？如果不点进去看看实现，可能就让程序陷入bug，让测试陷入麻烦。 再来聊聊类的问题。我们经常会看到“又臭又长”的service/biz层的代码，里面有几十个方法，干什么的都有：既有增删改查，又有业务逻辑的聚合。每次找到一个方法都费劲。不属于一个领域或者一个层次的功能，就不要放到一起。 我们team在code review中，最常被批评的问题，就是一个方法应该归属于哪个类。 优先定义整体框架我写代码的时候，比较喜欢先去定义整体的框架，就是写很多空实现，来把整体的业务流程穿起来。良好的方法签名，用入参和出参来控制流程。这样能够避免陷入业务细节无法自拔。在脑海中先定义清楚流程的几个阶段，并为每个阶段找到合适的方法／类归属。 这样做的好处是，阅读你代码的人，无论读到什么深度，都可以清晰地了解每一层的职能，如果不care下一层的实现，完全可以跳过不看，并且方法的粒度也会恰到好处。 简而言之，我比较推崇写代码的时候“广度优先”而不是“深度优先”，这和我读代码的方式是一致的。当然，这件事情跟个人的思维习惯有一定的关系，可能对抽象思维能力要求会更高一些。如果开始写代码的时候这些不够清晰，起码要通过不断地重构，使代码达到这样的成色。 清晰的命名老生常谈的话题，这里不展开讲了，但是必须要mark一下。有的时候，我思考一个方法命名的时间，比写一段代码的时间还长。原因还是那个逻辑：每当你写出一个类似于”temp”、”a”、”b”这样变量的时候，后面每一个维护代码的人，都需要用几倍的精力才能理顺。 并且这也是代码自描述最重要的基础。 避免过长参数如果一个方法的参数长度超过4个，就需要警惕了。一方面，没有人能够记得清楚这些函数的语义；另一方面，代码的可读性会很差；最后，如果参数非常多，意味着一定有很多参数，在很多场景下，是没有用的，我们只能构造默认值的方式来传递。 解决这个问题的方法很简单，一般情况下我们会构造paramObject。用一个struct或者一个class来承载数据，一般这种对象是value object，不可变对象。这样，能极大程度提高代码的可复用性和可读性。在必要的时候，提供合适的build方法，来简化上层代码的开发成本。 避免过长方法和类一个类或者方法过长的时候，读者总是很崩溃的。简单地把方法、类和职责拆细，往往会有立竿见影的成效。以类为例，拆分的维度有很多，常见的是横向／纵向。例如，如果一个service，处理的是跟一个库表对象相关的所有逻辑，横向拆分就是根据业务，把建立／更新／修改／通知等逻辑拆到不同的类里去；而纵向拆分，指的是把数据库操作/MQ操作/Cache操作/对象校验等，拆到不同的对象里去，让主流程尽量简单可控，让同一个类，表达尽量同一个维度的东西。 让相同长度的代码段表示相同粒度的逻辑这里想表达的是，尽量多地去抽取private方法，让代码具有自描述的能力。举个简单的例子12345678910public void doSomeThing(Map params1,Map params2)&#123;Do1 do1 = getDo1(params1);Do2 do2 = new Do2();do2.setA(params2.get(\"a\"));do2.setB(params2.get(\"b\"));do2.setC(params2.get(\"c\"));mergeDO(do1,do2);&#125;private void getDo1(Map params1);private void mergeDo(do1,do2)&#123;...&#125;; 类似这种代码，在业务代码中随处可见。获取do1是一个方法，merge是一个方法，但获取do2的代码却在主流程里写了。这种代码，流程越长，读起来越累。很多人读代码的逻辑，是“广度优先”的。先读懂主流程，再去看细节。类似这种代码，如果能够把构造do2的代码，提取一个private 方法，就会舒服很多。 面向对象设计技巧贫血与领域驱动不得不承认，Spring已经成为企业级Java开发的事实标准。而大部分公司采用的三层/四层贫血模型，已经让我们的编码习惯，变成了面向DAO而不是面向对象。 缺少了必要的模型抽象和设计环节，使得代码冗长，复用程度比较差。每次撸代码的时候，从mapper撸起，好像已经成为不成文的规范。 好处是上手简单，学习成本低。但是每次都不能重用，然后面对两三千行的类看着眼花的时候，我的心是很痛的。关于领域驱动的设计模式，本文不会展开去讲。回归面向对象，还是跟大家share一些比较好的code技巧，能够在一个通用的框架下，尽量好的写出漂亮可重用的code。 个人认为，一个好的系统，一定离不开一套好的模型定义。梳理清楚系统中的核心模型，清楚的定义每个方法的类归属，无论对于代码的可读性、可交流性，还是和产品的沟通，都是有莫大好处的。 为每个方法找到合适的类归属，数据和行为尽量要在一起如果一个类的所有方法，都是在操作另一个类的对象。这时候就要仔细想一想类的设计是否合理了。理论上讲，面向对象的设计，主张数据和行为在一起。这样，对象之间的结构才是清晰的，也能减少很多不必要的参数传递。 不过这里面有一个要讨论的方法：service对象。如果操作一个对象数据的所有方法都建立在对象内部，可能使对象承载了很多并不属于它本身职能的方法。 例如，我定义一个类，叫做person，。这个类有很多行为，比如：吃饭、睡觉、上厕所、生孩子；也有很多字段，比如：姓名、年龄、性格。 很明显，字段从更大程度上来讲，是定义和描述我这个人的，但很多行为和我的字段并不相关。上厕所的时候是不会关心我是几岁的。如果把所有关于人的行为全部在person内部承载，这个类一定会膨胀的不行。 这时候就体现了service方法的价值，如果一个行为，无法明确属于哪个领域对象，牵强地融入领域对象里，会显得很不自然。这时候，无状态的service可以发挥出它的作用。但一定要把握好这个度，回归本质，我们要把属于每个模型的行为合理的去划定归属。 警惕staticstatic方法，本质上来讲是面向过程的，无法清晰地反馈对象之间的关系。虽然有一些代码实例（自己实现单例或者Spring托管等）的无状态方法可以用static来表示，但这种抽象是浅层次的。说白了，如果我们所有调用static的地方，都写上import static，那么所有的功能就由类自己在承载了。 让我画一个类图？尴尬了……画不出来。 而单例的膨胀，很大程度上也是贫血模型带来的副作用。如果对象本身有血有肉，就不需要这么多无状态方法。 static真正适用的场景：工具方法，而不是业务方法。巧用method objectmethod object是大型重构的常用技巧。当一段逻辑特别复杂的代码，充斥着各种参数传递和是非因果判断的时候，我首先想到的重构手段是提取method object。所谓method object，是一个有数据有行为的对象。依赖的数据会成为这个对象的变量，所有的行为会成为这个对象的内部方法。利用成员变量代替参数传递，会让代码简洁清爽很多。并且，把一段过程式的代码转换成对象代码，为很多面向对象编程才可以使用的继承／封装／多态等提供了基础。 举个例子，上文引用的代码如果用method object表示大概会变成这样1234567891011121314151617181920class DoMerger&#123; map params1; map params2; Do1 do1; Do2 do2; public DoMerger(Map params1,Map params2)&#123; this.params1 = params1; this.params2 = parmas2; &#125; public void invoke()&#123; do1 = getDo1(); do2 = getDo2(); mergeDO(do1,do2); &#125; private Do1 getDo1(); private Do2 getDo2(); private void mergeDo()&#123; print(do1+do2); &#125;&#125; 面向接口编程面向接口编程是很多年来大家形成的共识和最佳实践。最早的理论是便于实现的替换，但现在更显而易见的好处是避免public方法的膨胀。一个对外publish的接口，一定有明确的职责。要判断每一个public方法是否应该属于同一个interface，是很容易的。 整个代码基于接口去组织，会很自然地变得非常清晰易读。关注实现的人才去看实现，不是嘛？ 正确使用继承和组合这也是个在业界被讨论过很久的问题，也有很多论调。最新的观点是组合的使用一般情况下比继承更为灵活，尤其是单继承的体系里，所以倾向于使用组合，否则会让子类承载很多不属于自己的职能。 个人对此观点持保留意见，在我经历过的代码中，有一个小规律，我分析一下。 protected abstract 这种是最值得使用继承的，父类保留扩展点，子类扩展，没什么好说的。 protected final 这种方法，子类是只能使用不能修改实现的。一般有两种情况：① 抽象出主流程不能被修改的，然而一般情况下，public final更适合这个职能。如果只是流程的一部分，需要思考这个流程的类归属，大部分变成public组合到其他类里是更合适的。② 父类是抽象类无法直接对外提供服务，又不希望子类修改它的行为，这种大多数情况下属于工具方法，比较适合用另一个领域对象来承载并用组合的方式来使用。 protected 这种是有争议的，是父类有默认实现但子类可以扩展的。凡是有扩展可能的，使用继承更理想一些。否则，定义成final并考虑成组合。 综上所述，个人认为继承更多的是为扩展提供便利，为复用而存在的方法最好使用组合的方式。当然，更为大的原则是明确每个方法的领域划分。 代码复用技巧模板方法这是我用得最多的设计模式了。每当有两个行为类似但又不完全相同的代码段时，我总是会想到模板方法。提取公共流程和可复用的方法到父类，保留不同的地方作为abstract方法，由不同的子类去实现。 并在合适的时机，pull method up（复用）或者 pull method down（特殊逻辑）。 最后，把不属于流程的、但可复用的方法，判断是不是属于基类的领域职责，再使用继承或者组合的方法，为这些方法找到合适的安家之处。 extract method很多复用的级别没有这么大，也许只是几行相同的逻辑被copy了好几次，何不尝试提取方法（private）。又能明确方法行为，又能做到代码复用，何乐不为？ 责任链经常看到这样的代码，一连串类似的行为，只是数据或者行为不一样。如一堆校验器，如果成功怎么样、失败怎么样；或者一堆对象构建器，各去构造一部分数据。碰到这种场景，我总是喜欢定义一个通用接口，入参是完整的要校验／构造的参数，出参是成功/失败的标示或者是void。然后有很多实现器分别实现这个接口，再用一个集合把这堆行为串起来。最后，遍历这个集合，串行或者并行的执行每一部分的逻辑。 这样做的好处是：① 很多通用的代码可以在责任链原子对象的基类里实现；② 代码清晰，开闭原则，每当有新的行为产生的时候，只需要定义行的实现类并添加到集合里即可；③ 为并行提供了基础。 为集合显式定义它的行为集合是个有意思的东西，本质上它是个容器，但由于泛型的存在，它变成了可以承载所有对象的容器。很多非集合的类，我们可以定义清楚他们的边界和行为划分，但是装进集合里，它们却都变成了一个样子。不停地有代码，各种循环集合，做一些相似的操作。 其实很多时候，可以把对集合的操作显示地封装起来，让它变得更有血有肉。 例如一个Map，它可能表示一个配制、一个缓存等等。如果所有的操作都是直接操作Map，那么它的行为就没有任何语义。第一，读起来就必须要深入细节；第二，如果想从获取配置读取缓存的地方加个通用的逻辑，例如打个log什么的，你可以想象是多么的崩溃。 个人提倡的做法是，对于有明确语义的集合的一些操作，尤其是全局的集合或者被经常使用的集合，做一些封装和抽象，如把Map封装成一个Cache类或者一个config类，再提供GetFromCache这样的方法。 总结本文从clean code的几个大前提出发，然后提出了实践clean code的一些手段，重点放在促成clean code的一些常用编码和重构技巧。当然，这些只代表笔者本人的一点点感悟。好的代码，最最需要的，还是大家不断追求卓越的精神。欢迎大家一起探索交流这个领域，为clean code提供更多好的思路与方法。 作者简介王烨，现在是美团点评旅游后台研发组的工程师，之前曾经在百度、去哪儿和优酷工作过，专注Java后台开发。对于网络编程和并发编程具有浓厚的兴趣，曾经做过一些基础组件，也翻过一些源码，属于比较典型的宅男技术控。期待能够与更多知己，在coding的路上并肩前行~联系邮箱：wangye03@meituan.com 常见性能优化策略的总结 晓明 本文要感谢我职级评定过程中的一位评委，他建议把之前所做的各种性能优化的案例和方案加以提炼、总结，以文档的形式沉淀下来，并在内部进行分享。力求达到如下效果： 形成可实践、可借鉴、可参考的各种性能优化的方案以及选型考虑点，同时配合具体的真实案例，其他人遇到相似问题时，不用从零开始。 有助于开阔视野，除了性能优化之外，也能提供通用的常见思路以及方案选型的考虑点，帮助大家培养在方案选型时的意识、思维以及做各种权衡的能力。 文章在内部分享后，引起强烈分享，得到了不少同事和朋友的认可和好评，觉得对日常的工作有很好的指导作用。考虑到这些经验可能对业界同行也有帮助，所以在美团点评技术团队博客公开。 常见性能优化策略分类代码之所以把代码放到第一位，是因为这一点最容易引起技术人员的忽视。很多技术人员拿到一个性能优化的需求以后，言必称缓存、异步、JVM等。实际上，第一步就应该是分析相关的代码，找出相应的瓶颈，再来考虑具体的优化策略。有一些性能问题，完全是由于代码写的不合理，通过直接修改一下代码就能解决问题的，比如for循环次数过多、作了很多无谓的条件判断、相同逻辑重复多次等。 数据库数据库的调优，总的来说分为以下三部分： SQL调优这是最常用、每一个技术人员都应该掌握基本的SQL调优手段（包括方法、工具、辅助系统等）。这里以MySQL为例，最常见的方式是，由自带的慢查询日志或者开源的慢查询系统定位到具体的出问题的SQL，然后使用explain、profile等工具来逐步调优，最后经过测试达到效果后上线。这方面的细节，可以参考MySQL索引原理及慢查询优化。 架构层面的调优这一类调优包括读写分离、多从库负载均衡、水平和垂直分库分表等方面，一般需要的改动较大，但是频率没有SQL调优高，而且一般需要DBA来配合参与。那么什么时候需要做这些事情？我们可以通过内部监控报警系统（比如Zabbix），定期跟踪一些指标数据是否达到瓶颈，一旦达到瓶颈或者警戒值，就需要考虑这些事情。通常，DBA也会定期监控这些指标值。 连接池调优我们的应用为了实现数据库连接的高效获取、对数据库连接的限流等目的，通常会采用连接池类的方案，即每一个应用节点都管理了一个到各个数据库的连接池。随着业务访问量或者数据量的增长，原有的连接池参数可能不能很好地满足需求，这个时候就需要结合当前使用连接池的原理、具体的连接池监控数据和当前的业务量作一个综合的判断，通过反复的几次调试得到最终的调优参数。 缓存分类本地缓存（HashMap/ConcurrentHashMap、Ehcache、Guava Cache等），缓存服务（Redis/Tair/Memcache等）。 使用场景什么情况适合用缓存？考虑以下两种场景： 短时间内相同数据重复查询多次且数据更新不频繁，这个时候可以选择先从缓存查询，查询不到再从数据库加载并回设到缓存的方式。此种场景较适合用单机缓存。高并发查询热点数据，后端数据库不堪重负，可以用缓存来扛。 选型考虑如果数据量小，并且不会频繁地增长又清空（这会导致频繁地垃圾回收），那么可以选择本地缓存。具体的话，如果需要一些策略的支持（比如缓存满的逐出策略），可以考虑Ehcache；如不需要，可以考虑HashMap；如需要考虑多线程并发的场景，可以考虑ConcurentHashMap。其他情况，可以考虑缓存服务。目前从资源的投入度、可运维性、是否能动态扩容以及配套设施来考虑，我们优先考虑Tair。除非目前Tair还不能支持的场合（比如分布式锁、Hash类型的value），我们考虑用Redis。 设计关键点什么时候更新缓存？如何保障更新的可靠性和实时性？更新缓存的策略，需要具体问题具体分析。这里以门店POI的缓存数据为例，来说明一下缓存服务型的缓存更新策略是怎样的？目前约10万个POI数据采用了Tair作为缓存服务，具体更新的策略有两个： 接收门店变更的消息，准实时更新。给每一个POI缓存数据设置5分钟的过期时间，过期后从DB加载再回设到DB。这个策略是对第一个策略的有力补充，解决了手动变更DB不发消息、接消息更新程序临时出错等问题导致的第一个策略失效的问题。通过这种双保险机制，有效地保证了POI缓存数据的可靠性和实时性。缓存是否会满，缓存满了怎么办？对于一个缓存服务，理论上来说，随着缓存数据的日益增多，在容量有限的情况下，缓存肯定有一天会满的。如何应对？① 给缓存服务，选择合适的缓存逐出算法，比如最常见的LRU。② 针对当前设置的容量，设置适当的警戒值，比如10G的缓存，当缓存数据达到8G的时候，就开始发出报警，提前排查问题或者扩容。③ 给一些没有必要长期保存的key，尽量设置过期时间。 缓存是否允许丢失？丢失了怎么办？根据业务场景判断，是否允许丢失。如果不允许，就需要带持久化功能的缓存服务来支持，比如Redis或者Tair。更细节的话，可以根据业务对丢失时间的容忍度，还可以选择更具体的持久化策略，比如Redis的RDB或者AOF。 缓存被“击穿”问题对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑另外一个问题：缓存被“击穿”的问题。 概念：缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。如何解决：业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。类似下面的代码：12345678910111213141516public String get(key) &#123; String value = redis.get(key); if (value == null) &#123; //代表缓存值过期 //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db if (redis.setnx(key_mutex, 1, 3 * 60) == 1) &#123; //代表设置成功 value = db.get(key); redis.set(key, value, expire_secs); redis.del(key_mutex); &#125; else &#123; //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可 sleep(50); get(key); //重试 &#125; &#125; else &#123; return value; &#125;&#125; 异步使用场景针对某些客户端的请求，在服务端可能需要针对这些请求做一些附属的事情，这些事情其实用户并不关心或者用户不需要立即拿到这些事情的处理结果，这种情况就比较适合用异步的方式处理这些事情。 作用缩短接口响应时间，使用户的请求快速返回，用户体验更好。避免线程长时间处于运行状态，这样会引起服务线程池的可用线程长时间不够用，进而引起线程池任务队列长度增大，从而阻塞更多请求任务，使得更多请求得不到技术处理。线程长时间处于运行状态，可能还会引起系统Load、CPU使用率、机器整体性能下降等一系列问题，甚至引发雪崩。异步的思路可以在不增加机器数和CPU数的情况下，有效解决这个问题。常见做法一种做法，是额外开辟线程，这里可以采用额外开辟一个线程或者使用线程池的做法，在IO线程（处理请求响应）之外的线程来处理相应的任务，在IO线程中让response先返回。 如果异步线程处理的任务设计的数据量非常巨大，那么可以引入阻塞队列BlockingQueue作进一步的优化。具体做法是让一批异步线程不断地往阻塞队列里扔数据，然后额外起一个处理线程，循环批量从队列里拿预设大小的一批数据，来进行批处理（比如发一个批量的远程服务请求），这样进一步提高了性能。 另一种做法，是使用消息队列（MQ）中间件服务，MQ天生就是异步的。一些额外的任务，可能不需要我这个系统来处理，但是需要其他系统来处理。这个时候可以先把它封装成一个消息，扔到消息队列里面，通过消息中间件的可靠性保证把消息投递到关心它的系统，然后让这个系统来做相应的处理。 比如C端在完成一个提单动作以后，可能需要其它端做一系列的事情，但是这些事情的结果不会立刻对C端用户产生影响，那么就可以先把C端下单的请求响应先返回给用户，返回之前往MQ中发一个消息即可。而且这些事情理应不是C端的负责范围，所以这个时候用MQ的方式，来解决这个问题最合适。 NoSQL和缓存的区别先说明一下，这里介绍的和缓存那一节不一样，虽然可能会使用一样的数据存储方案（比如Redis或者Tair），但是使用的方式不一样，这一节介绍的是把它作为DB来用。如果当作DB来用，需要有效保证数据存储方案的可用性、可靠性。 使用场景需要结合具体的业务场景，看这块业务涉及的数据是否适合用NoSQL来存储，对数据的操作方式是否适合用NoSQL的方式来操作，或者是否需要用到NoSQL的一些额外特性（比如原子加减等）。 如果业务数据不需要和其他数据作关联，不需要事务或者外键之类的支持，而且有可能写入会异常频繁，这个时候就比较适合用NoSQL（比如HBase）。 比如，美团点评内部有一个对exception做的监控系统，如果在应用系统发生严重故障的时候，可能会短时间产生大量exception数据，这个时候如果选用MySQL，会造成MySQL的瞬间写压力飙升，容易导致MySQL服务器的性能急剧恶化以及主从同步延迟之类的问题，这种场景就比较适合用Hbase类似的NoSQL来存储。 JVM调优什么时候调？通过监控系统（如没有现成的系统，自己做一个简单的上报监控的系统也很容易）上对一些机器关键指标（gc time、gc count、各个分代的内存大小变化、机器的Load值与CPU使用率、JVM的线程数等）的监控报警，也可以看gc log和jstat等命令的输出，再结合线上JVM进程服务的一些关键接口的性能数据和请求体验，基本上就能定位出当前的JVM是否有问题，以及是否需要调优。 怎么调？如果发现高峰期CPU使用率与Load值偏大，这个时候可以观察一些JVM的thread count以及gc count（可能主要是young gc count），如果这两个值都比以往偏大（也可以和一个历史经验值作对比），基本上可以定位是young gc频率过高导致，这个时候可以通过适当增大young区大小或者占比的方式来解决。如果发现关键接口响应时间很慢，可以结合gc time以及gc log中的stop the world的时间，看一下整个应用的stop the world的时间是不是比较多。如果是，可能需要减少总的gc time，具体可以从减小gc的次数和减小单次gc的时间这两个维度来考虑，一般来说，这两个因素是一对互斥因素，我们需要根据实际的监控数据来调整相应的参数（比如新生代与老生代比值、eden与survivor比值、MTT值、触发cms回收的old区比率阈值等）来达到一个最优值。如果发生full gc或者old cms gc非常频繁，通常这种情况会诱发STW的时间相应加长，从而也会导致接口响应时间变慢。这种情况，大概率是出现了“内存泄露”，Java里的内存泄露指的是一些应该释放的对象没有被释放掉（还有引用拉着它）。那么这些对象是如何产生的呢？为啥不会释放呢？对应的代码是不是出问题了？问题的关键是搞明白这个，找到相应的代码，然后对症下药。所以问题的关键是转化成寻找这些对象。怎么找？综合使用jmap和MAT，基本就能定位到具体的代码。 多线程与分布式使用场景离线任务、异步任务、大数据任务、耗时较长任务的运行**，适当地利用，可达到加速的效果。 注意：线上对响应时间要求较高的场合，尽量少用多线程，尤其是服务线程需要等待任务线程的场合（很多重大事故就是和这个息息相关），如果一定要用，可以对服务线程设置一个最大等待时间。 常见做法如果单机的处理能力可以满足实际业务的需求，那么尽可能地使用单机多线程的处理方式，减少复杂性；反之，则需要使用多机多线程的方式。 对于单机多线程，可以引入线程池的机制，作用有二： 提高性能，节省线程创建和销毁的开销限流，给线程池一个固定的容量，达到这个容量值后再有任务进来，就进入队列进行排队，保障机器极限压力下的稳定处理能力在使用JDK自带的线程池时，一定要仔细理解构造方法的各个参数的含义，如core pool size、max pool size、keepAliveTime、worker queue等，在理解的基础上通过不断地测试调整这些参数值达到最优效果。如果单机的处理能力不能满足需求，这个时候需要使用多机多线程的方式。这个时候就需要一些分布式系统的知识了。首先就必须引入一个单独的节点，作为调度器，其他的机器节点都作为执行器节点。调度器来负责拆分任务，和分发任务到合适的执行器节点；执行器节点按照多线程的方式（也可能是单线程）来执行任务。这个时候，我们整个任务系统就由单击演变成一个集群的系统，而且不同的机器节点有不同的角色，各司其职，各个节点之间还有交互。这个时候除了有多线程、线程池等机制，像RPC、心跳等网络通信调用的机制也不可少。后续我会出一个简单的分布式调度运行的框架。 度量系统（监控、报警、服务依赖管理）严格来说，度量系统不属于性能优化的范畴，但是这方面和性能优化息息相关，可以说为性能优化提供一个强有力的数据参考和支撑。没有度量系统，基本上就没有办法定位到系统的问题，也没有办法有效衡量优化后的效果。很多人不重视这方面，但我认为它是系统稳定性和性能保障的基石。 关键流程如果要设计这套系统，总体来说有哪些关键流程需要设计呢？① 确定指标② 采集数据③ 计算数据，存储结果④ 展现和分析 需要监控和报警哪些指标数据？需要关注哪些？按照需求出发，主要需要二方面的指标： 接口性能相关，包括单个接口和全部的QPS、响应时间、调用量（统计时间维度越细越好；最好是，既能以节点为维度，也可以以服务集群为维度，来查看相关数据）。其中还涉及到服务依赖关系的管理，这个时候需要用到服务依赖管理系统单个机器节点相关，包括CPU使用率、Load值、内存占用率、网卡流量等。如果节点是一些特殊类型的服务（比如MySQL、Redis、Tair），还可以监控这些服务特有的一些关键指标。数据采集方式通常采用异步上报的方式，具体做法有两种：第一种，发到本地的Flume端口，由Flume进程收集到远程的Hadoop集群或者Storm集群来进行运算；第二种，直接在本地运算好以后，使用异步和本地队列的方式，发送到监控服务器。 数据计算可以采用离线运算（MapReduce/Hive）或者实时/准实时运算（Storm/Spark）的方式，运算后的结果存入MySQL或者HBase；某些情况，也可以不计算，直接采集发往监控服务器。 展现和分析提供统一的展现分析平台，需要带报表（列表/图表）监控和报警的功能。 真实案例分析案例一：商家与控制区关系的刷新job背景这是一个每小时定期运行一次的job，作用是用来刷新商家与控制区的关系。具体规则就是根据商家的配送范围（多个）与控制区是否有交集，如果有交集，就把这个商家划到这个控制区的范围内。 业务需求需要这个过程越短越好，最好保持在20分钟内。 优化过程原有代码的主要处理流程是： 拿到所有门店的配送范围列表和控制区列表。遍历控制区列表，针对每一个控制区：a. 遍历商家的配送范围列表，找到和这个控制区相交的配送范围列表。b. 遍历上述商家配送范围列表，对里面的商家ID去重，保存到一个集合里。c. 批量根据上述商家ID集合，取到对应的商家集合。d. 遍历上述商家集合，从中拿到每一个商家对象，进行相应的处理（根据是否已是热门商家、自营、在线支付等条件来判断是否需要插入或者更新之前的商家和控制区的关系）。e. 删除这个控制区当前已有的，但是不应该存在的商家关系列表。分析代码，发现第2步的a步骤和b步骤，找出和某控制区相交的配送范围集合并对商家ID去重，可以采用R树空间索引的方式来优化。具体做法是： 任务开始先更新R树，然后利用R树的结构和匹配算法来拿到和控制区相交的配送范围ID列表。再批量根据配送范围ID列表，拿到配送范围列表。然后针对这一批配送范围列表（数量很小），用原始多边形相交匹配的方法做进一步过滤，并且对过滤后的商家ID去重。这个优化已经在第一期优化中上线，整个过程耗时由40多分钟缩短到20分钟以内。 第一期优化改为R树以后，运行了一段时间，随着数据量增大，性能又开始逐渐恶化，一个月后已经恶化到50多分钟。于是继续深入代码分析，寻找了两个优化点，安排第二期优化并上线。 这两个优化点是： 第2步的c步骤，原来是根据门店ID列表从DB批量获取门店，现在可以改成mget的方式从缓存批量获取（此时商家数据已被缓存）；第2步的d步骤，根据是否已是热门商家、自营、在线支付等条件来判断是否需要插入或者更新之前的商家和控制区的关系。上线后效果通过日志观察，执行时间由50多分钟缩短到15分钟以内，下图是截取了一天的4台机器的日志时间（单位：毫秒）：poi优化效果图可以看到，效果还是非常明显的。 案例二：POI缓存设计与实现背景2014年Q4，数据库中关于POI（这里可以简单理解为外卖的门店）相关的数据的读流量急剧上升，虽然说加入从库节点可以解决一部分问题，但是毕竟节点的增加是会达到极限的，达到极限后主从复制会达到瓶颈，可能会造成数据不一致。所以此时，急需引入一种新的技术方案来分担数据库的压力，降低数据库POI相关数据的读流量。另外，任何场景都考虑加DB从库的做法，会对资源造成一定的浪费。 实现方案基于已有的经过考验的技术方案，我选择Tair来作为缓存的存储方案，来帮DB分担来自于各应用端的POI数据的读流量的压力。理由主要是从可用性、高性能、可扩展性、是否经过线上大规模数据和高并发流量的考验、是否有专业运维团队、是否有成熟工具等几个方面综合考量决定。 详细设计第一版设计缓存的更新策略，根据业务的特点、已有的技术方案和实现成本，选择了用MQ来接收POI改变的消息来触发缓存的更新，但是这个过程有可能失败；同时启用了key的过期策略，并且调用端会先判断是否过期，如过期，会从后端DB加载数据并回设到缓存，再返回。通过两个方面双保险确保了缓存数据的可用。 第二版设计第一版设计运行到一段时间以后，我们发现了两个问题： 某些情况下不能保证数据的实时一致（比如技术人员手动改动DB数据、利用MQ更新缓存失败），这个时候只能等待5分钟的过期时间，有的业务是不允许的。加入了过期时间导致另外一个问题：Tair在缓存不命中的那一刻，会尝试从硬盘中Load数据，如果硬盘没有再去DB中Load数据。这无疑会进一步延长Tair的响应时间，这样不仅使得业务的超时比率加大，而且会导致Tair的性能进一步变差。为了解决上述问题，我们从美团点评负责基础架构的同事那里了解到Databus可以解决缓存数据在某些情况下不一致的问题，并且可以去掉过期时间机制，从而提高查询效率，避免tair在内存不命中时查询硬盘。而且为了防止DataBus单点出现故障影响我们的业务，我们保留了之前接MQ消息更新缓存的方案，作了切换开关，利用这个方案作容错，整体架构如下： 上线后效果上线后，通过持续地监控数据发现，随着调用量的上升，到DB的流量有了明显地减少，极大地减轻了DB的压力。同时这些数据接口的响应时间也有了明显地减少。缓存更新的双重保障机制，也基本保证了缓存数据的可用。见下图：poi缓存优化效果图 案例三：业务运营后台相关页面的性能优化背景随着业务的快速发展，带来的访问量和数据量的急剧上升，通过我们相应的监控系统可以发现，系统的某些页面的性能开始出现恶化。 从用户方的反馈，也证明了这点。此时此刻，有必要迅速排期，敏捷开发，对这些页面进行调优。 欢迎页需求背景：欢迎页是地推人员乃至总部各种角色人员进入外卖运营后台的首页，会显示地推人员最想看到最关心的一些核心数据，其重要性不言而喻，所以该页面的性能恶化会严重影响到用户体验。因此，首先需要优化的就是欢迎页。通过相应定位和分析，发现导致性能恶化的主要原因有两个：数据接口层和计算展现层。解决方案：对症下药，分而治之。经过仔细排查、分析定位，数据接口层采用接口调用批量化、异步RPC调用的方式来进行有效优化，计算展现层决定采用预先计算、再把计算好的结果缓存的方式来提高查询速度。其中，缓存方案根据业务场景和技术特点，选用Redis。定好方案后，快速开发上线。上线效果：上线后性能对比图，如下：组织架构页需求背景：组织架构页，采用了四层树形结构图，一起呈现加载，第一版上线后发现性能非常差。用户迫切希望对这个页面的性能进行调优。解决方案：经过分析代码，定位到一个比较经典的问题：里面执行了太多次小数据量的SQL查询。于是采用多个SQL合并成大SQL的方式，然后使用本地缓存来缓存这些数据，合理预估数据量和性能，充分测试后上线。上线效果：上线后性能对比图，如下：订单关联楼宇页需求背景：随着订单量日益增大，订单表积累的数据日益增多，订单关联楼宇页的性能也日益变差（响应时间线性上升）。而这个页面和地推人员的业绩息息相关，所以地推人员使用该页面的频率非常高，性能日益恶化极大地影响了地推人员的用户体验。解决方案：经过分析与设计，决定采用当时已有的订单二级索引月分表来代替原始的订单表来供前端的查询请求；并且限制住筛选的时间条件，使得筛选的开始时间和结束时间不能跨月（事先和用户沟通过，可以接受，能满足用户的基本需求），这样就只需一个月分索引表即可，通过适当的功能限制来达到性能的调优。这样从二级索引月分表中根据各种查询条件查到最终的分页的订单ID集合，然后再根据订单ID从订单库来查出相应的订单数据集合。上线效果：上线后发现在调用量几乎没怎么变的情况下，性能提升明显，如下图：其他除了上面介绍的之外，优化还涉及前端、分布式文件系统、CDN、全文索引、空间索引等几方面。限于篇幅，我们留到未来再做介绍。 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"Android硬件加速原理与实现简介","date":"2017-02-26T14:57:06.000Z","path":"2017/02/26/Program/Android/the-essence-of-hardware-accelarate-in-android/","text":"子健 在手机客户端尤其是Android应用的开发过程中，我们经常会接触到“硬件加速”这个词。由于操作系统对底层软硬件封装非常完善，上层软件开发者往往对硬件加速的底层原理了解很少，也不清楚了解底层原理的意义，因此常会有一些误解，如硬件加速是不是通过特殊算法实现页面渲染加速，或是通过硬件提高CPU/GPU运算速率实现渲染加速。 本文尝试从底层硬件原理，一直到上层代码实现，对硬件加速技术进行简单介绍，其中上层实现基于Android 6.0。 了解硬件加速对App开发的意义对于App开发者，简单了解硬件加速原理及上层API实现，开发时就可以充分利用硬件加速提高页面的性能。以Android举例，实现一个圆角矩形按钮通常有两种方案：使用PNG图片；使用代码（XML/Java）实现。简单对比两种方案如下。 方案 原理 特点使用PNG图片（BitmapDrawable） 解码PNG图片生成Bitmap，传到底层，由GPU渲染 图片解码消耗CPU运算资源，Bitmap占用内存大，绘制慢使用XML或Java代码实现（ShapeDrawable） 直接将Shape信息传到底层，由GPU渲染 消耗CPU资源少，占用内存小，绘制快 页面渲染背景知识页面渲染时，被绘制的元素最终要转换成矩阵像素点（即多维数组形式，类似安卓中的Bitmap），才能被显示器显示。页面由各种基本元素组成，例如圆形、圆角矩形、线段、文字、矢量图（常用贝塞尔曲线组成）、Bitmap等。元素绘制时尤其是动画绘制过程中，经常涉及插值、缩放、旋转、透明度变化、动画过渡、毛玻璃模糊，甚至包括3D变换、物理运动（例如游戏中常见的抛物线运动）、多媒体文件解码（主要在桌面机中有应用，移动设备一般不用GPU做解码）等运算。绘制过程经常需要进行逻辑较简单、但数据量庞大的浮点运算。 CPU与GPU结构对比CPU（Central Processing Unit，中央处理器）是计算机设备核心器件，用于执行程序代码，软件开发者对此都很熟悉；GPU（Graphics Processing Unit，图形处理器）主要用于处理图形运算，通常所说“显卡”的核心部件就是GPU。 下面是CPU和GPU的结构对比图。其中：黄色的Control为控制器，用于协调控制整个CPU的运行，包括取出指令、控制其他模块的运行等；绿色的ALU（Arithmetic Logic Unit）是算术逻辑单元，用于进行数学、逻辑运算；橙色的Cache和DRAM分别为缓存和RAM，用于存储信息。 从结构图可以看出，CPU的控制器较为复杂，而ALU数量较少。因此CPU擅长各种复杂的逻辑运算，但不擅长数学尤其是浮点运算。 以8086为例，一百多条汇编指令大部分都是逻辑指令，数学计算相关的主要是16位加减乘除和移位运算。一次整型和逻辑运算一般需要1~3个机器周期，而浮点运算要转换成整数计算，一次运算可能消耗上百个机器周期。更简单的CPU甚至只有加法指令，减法用补码加法实现，乘法用累加实现，除法用减法循环实现。现代CPU一般都带有硬件浮点运算器（FPU），但主要适用于数据量不大的情况。CPU是串行结构。以计算100个数字为例，对于CPU的一个核，每次只能计算两个数的和，结果逐步累加。和CPU不同的是，GPU就是为实现大量数学运算设计的。从结构图中可以看到，GPU的控制器比较简单，但包含了大量ALU。GPU中的ALU使用了并行设计，且具有较多浮点运算单元。 硬件加速的主要原理，就是通过底层软件代码，将CPU不擅长的图形计算转换成GPU专用指令，由GPU完成。 扩展：很多计算机中的GPU有自己独立的显存；没有独立显存则使用共享内存的形式，从内存中划分一块区域作为显存。显存可以保存GPU指令等信息。 并行结构举例：级联加法器为了方便理解，这里先从底层电路结构的角度举一个例子。如下图为一个加法器，对应实际的数字电路结构。 A、B为输入，C为输出，且A、B、C均为总线，以32位CPU为例，则每根总线实际由32根导线组成，每根导线用不同的电压表示一个二进制的0或1。Clock为时钟信号线，每个固定的时钟周期可向其输入一个特定的电压信号，每当一个时钟信号到来时，A和B的和就会输出到C。 现在我们要计算8个整数的和。 对于CPU这种串行结构，代码编写很简单，用for循环把所有数字逐个相加即可。串行结构只有一个加法器，需要7次求和运算；每次计算完部分和，还要将其再转移到加法器的输入端，做下一次计算。整个过程至少要消耗十几个机器周期。 而对于并行结构，一种常见的设计是级联加法器，如下图，其中所有的clock连在一起。当需要相加的8个数据在输入端A1~B4准备好后，经过三个时钟周期，求和操作就完成了。如果数据量更大、级联的层级更大，则并行结构的优势更明显。 由于电路的限制，不容易通过提高时钟频率、减小时钟周期的方式提高运算速度。并行结构通过增加电路规模、并行处理，来实现更快的运算。但并行结构不容易实现复杂逻辑，因为同时考虑多个支路的输出结果，并协调同步处理的过程很复杂（有点像多线程编程）。 GPU并行计算举例假设我们有如下图像处理任务，给每个像素值加1。GPU并行计算的方式简单粗暴，在资源允许的情况下，可以为每个像素开一个GPU线程，由其进行加1操作。数学运算量越大，这种并行方式性能优势越明显。 Android中的硬件加速在Android中，大多数应用的界面都是利用常规的View来构建的（除了游戏、视频、图像等应用可能直接使用OpenGL ES）。下面根据Android 6.0原生系统的Java层代码，对View的软件和硬件加速渲染做一些分析和对比。 DisplayListDisplayList是一个基本绘制元素，包含元素原始属性（位置、尺寸、角度、透明度等），对应Canvas的drawXxx()方法（如下图）。 信息传递流程：Canvas(Java API) —&gt; OpenGL(C/C++ Lib) —&gt; 驱动程序 —&gt; GPU。 在Android 4.1及以上版本，DisplayList支持属性，如果View的一些属性发生变化（比如Scale、Alpha、Translate），只需把属性更新给GPU，不需要生成新的DisplayList。 RenderNode一个RenderNode包含若干个DisplayList，通常一个RenderNode对应一个View，包含View自身及其子View的所有DisplayList。 Android绘制流程（Android 6.0）下面是安卓View完整的绘制流程图，主要通过阅读源码和调试得出，虚线箭头表示递归调用。 从ViewRootImpl.performTraversals到PhoneWindow.DecroView.drawChild是每次遍历View树的固定流程，首先根据标志位判断是否需要重新布局并执行布局；然后进行Canvas的创建等操作开始绘制。 如果硬件加速不支持或者被关闭，则使用软件绘制，生成的Canvas即Canvas.class的对象；如果支持硬件加速，则生成的是DisplayListCanvas.class的对象；两者的isHardwareAccelerated()方法返回的值分别为false、true，View根据这个值判断是否使用硬件加速。View中的draw(canvas,parent,drawingTime) - draw(canvas) - onDraw - dispachDraw - drawChild这条递归路径（下文简称Draw路径），调用了Canvas.drawXxx()方法，在软件渲染时用于实际绘制；在硬件加速时，用于构建DisplayList。View中的updateDisplayListIfDirty - dispatchGetDisplayList - recreateChildDisplayList这条递归路径（下文简称DisplayList路径），仅在硬件加速时会经过，用于在遍历View树绘制的过程中更新DisplayList属性，并快速跳过不需要重建DisplayList的View。 Android 6.0中，和DisplayList相关的API目前仍被标记为“@hide”不可访问，表示还不成熟，后续版本可能开放。硬件加速情况下，draw流程执行结束后DisplayList构建完成，然后通过ThreadedRenderer.nSyncAndDrawFrame()利用GPU绘制DisplayList到屏幕上。 纯软件绘制 VS 硬件加速（Android 6.0）下面根据具体的几种场景，具体分析一下硬件加速前后的流程与加速效果。 渲染场景 纯软件绘制 硬件加速 加速效果分析页面初始化 绘制所有View 创建所有DisplayList GPU分担了复杂计算任务在一个复杂页面调用背景透明TextView的setText()，且调用后其尺寸位置不变 重绘脏区所有View TextView及每一级父View重建DisplayList 重叠的兄弟节点不需CPU重绘，GPU会自行处理TextView逐帧播放Alpha / Translation / Scale动画 每帧都要重绘脏区所有View 除第一帧同场景2，之后每帧只更新TextView对应RenderNode的属性 刷新一帧性能极大提高，动画流畅度提高修改TextView透明度 重绘脏区所有View 直接调用RenderNode.setAlpha()更新 加速前需全页面遍历，并重绘很多View；加速后只触发DecorView.updateDisplayListIfDirty，不再往下遍历，CPU执行时间可忽略不计 场景1中，无论是否加速，遍历View树并都会走Draw路径。硬件加速后Draw路径不做实际绘制工作，只是构建DisplayList，复杂的绘制计算任务被GPU分担，已经有了较大的加速效果。场景2中，TextView设置前后尺寸位置不变，不会触发重新Layout。 软件绘制时，TextView所在区域即为脏区。由于TextView有透明区域，遍历View树的过程中，和脏区重叠的多数View都要重绘，包括与之重叠的兄弟节点和他们的父节点（详见后面的介绍），不需要绘制的View在draw(canvas,parent,drawingTime)方法中判断直接返回。 硬件加速后，也需要遍历View树，但只有TextView及其每一层父节点需要重建DisplayList，走的是Draw路径，其他View直接走了DisplayList路径，剩下的工作都交给GPU处理。页面越复杂，两者性能差距越明显。 场景3中，软件绘制每一帧都要做大量绘制工作，很容易导致动画卡顿。硬件加速后，动画过程直接走DisplayList路径更新DisplayList的属性，动画流畅度能得到极大提高。 场景4中，两者的性能差距更明显。简单修改透明度，软件绘制仍然要做很多工作；硬件加速后一般直接更新RenderNode的属性，不需要触发invalidate，也不会遍历View树（除了少数View可能要对Alpha做特殊响应并在onSetAlpha()返回true，代码如下）。12345678910111213141516171819202122public class View &#123; // ... public void setAlpha(@FloatRange(from=0.0, to=1.0) float alpha) &#123; ensureTransformationInfo(); if (mTransformationInfo.mAlpha != alpha) &#123; mTransformationInfo.mAlpha = alpha; if (onSetAlpha((int) (alpha * 255))) &#123; // ... invalidate(true); &#125; else &#123; // ... mRenderNode.setAlpha(getFinalAlpha()); // ... &#125; &#125; &#125; protected boolean onSetAlpha(int alpha) &#123; return false; &#125; // ...&#125; 软件绘制刷新逻辑简介实际阅读源码并实验，得出通常情况下的软件绘制刷新逻辑： 默认情况下，View的clipChildren属性为true，即每个View绘制区域不能超出其父View的范围。如果设置一个页面根布局的clipChildren属性为false，则子View可以超出父View的绘制区域。当一个View触发invalidate，且没有播放动画、没有触发layout的情况下： 对于全不透明的View，其自身会设置标志位PFLAG_DIRTY，其父View会设置标志位PFLAG_DIRTY_OPAQUE。在draw(canvas)方法中，只有这个View自身重绘。对于可能有透明区域的View，其自身和父View都会设置标志位PFLAG_DIRTY。 clipChildren为true时，脏区会被转换成ViewRoot中的Rect，刷新时层层向下判断，当View与脏区有重叠则重绘。如果一个View超出父View范围且与脏区重叠，但其父View不与脏区重叠，这个子View不会重绘。clipChildren为false时，ViewGroup.invalidateChildInParent()中会把脏区扩大到自身整个区域，于是与这个区域重叠的所有View都会重绘。 总结至此，硬件加速相关的内容就介绍完了，这里做个简单总结： CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。页面由各种基础元素（DisplayList）构成，渲染时需要进行大量浮点运算。 硬件加速条件下，CPU用于控制复杂绘制逻辑、构建或更新DisplayList；GPU用于完成图形计算、渲染DisplayList。 硬件加速条件下，刷新界面尤其是播放动画时，CPU只重建或更新必要的DisplayList，进一步提高渲染效率。 实现同样效果，应尽量使用更简单的DisplayList，从而达到更好的性能（Shape代替Bitmap等）。 参考资料与扩展阅读GPU—并行计算利器显示卡的“心脏”GPU工作原理介绍Matlab的GPU加速处理器体系结构：了解CPU的基本运行原理CPU的内部架构和工作原理什么是异构多处理系统，为什么需要异构多处理系统Android应用程序UI硬件加速渲染的Display List构建过程分析Android应用程序UI硬件加速渲染的Display List渲染过程分析Android Choreographer源码分析Android Project Butter分析 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"CPU","slug":"CPU","permalink":"http://ipcreator.me/tags/CPU/"},{"name":"GPU","slug":"GPU","permalink":"http://ipcreator.me/tags/GPU/"}]},{"title":"实例详解机器学习如何解决问题","date":"2017-02-26T14:34:06.000Z","path":"2017/02/26/BusinessAI/example-of-machine-learning-in-meituan/","text":"huawolf 前言随着大数据时代的到来，机器学习成为解决问题的一种重要且关键的工具。不管是工业界还是学术界，机器学习都是一个炙手可热的方向，但是学术界和工业界对机器学习的研究各有侧重，学术界侧重于对机器学习理论的研究，工业界侧重于如何用机器学习来解决实际问题。我们结合美团在机器学习上的实践，进行一个实战（InAction）系列的介绍（带“机器学习InAction系列”标签的文章），介绍机器学习在解决工业界问题的实战中所需的基本技术、经验和技巧。本文主要结合实际问题，概要地介绍机器学习解决实际问题的整个流程，包括对问题建模、准备训练数据、抽取特征、训练模型和优化模型等关键环节；另外几篇则会对这些关键环节进行更深入地介绍。 下文分为1）机器学习的概述，2）对问题建模，3）准备训练数据，4）抽取特征，5）训练模型，6）优化模型，7）总结 共7个章节进行介绍。 机器学习的概述： 什么是机器学习？随着机器学习在实际工业领域中不断获得应用，这个词已经被赋予了各种不同含义。在本文中的“机器学习”含义与wikipedia上的解释比较契合，如下：Machine learning is a scientific discipline that deals with the construction and study of algorithms that can learn from data. 机器学习可以分为无监督学习（unsupervised learning）和有监督学习（supervised learning），在工业界中，有监督学习是更常见和更有价值的方式，下文中主要以这种方式展开介绍。如下图中所示，有监督的机器学习在解决实际问题时，有两个流程，一个是离线训练流程（蓝色箭头），包含数据筛选和清洗、特征抽取、模型训练和优化模型等环节；另一个流程则是应用流程（绿色箭头），对需要预估的数据，抽取特征，应用离线训练得到的模型进行预估，获得预估值作用在实际产品中。在这两个流程中，离线训练是最有技术挑战的工作（在线预估流程很多工作可以复用离线训练流程的工作），所以下文主要介绍离线训练流程。 model 什么是模型（model）？模型，是机器学习中的一个重要概念，简单的讲，指特征空间到输出空间的映射；一般由模型的假设函数和参数w组成（下面公式就是Logistic Regression模型的一种表达，在训练模型的章节做稍详细的解释）；一个模型的假设空间（hypothesis space），指给定模型所有可能w对应的输出空间组成的集合。工业界常用的模型有Logistic Regression（简称LR）、Gradient Boosting Decision Tree（简称GBDT）、Support Vector Machine（简称SVM）、Deep Neural Network（简称DNN）等。=P\\left%20(%20y=1|x;w%20\\right%20)%20=\\frac{1}{1+e^{-wx}}) 模型训练就是基于训练数据，获得一组参数w，使得特定目标最优，即获得了特征空间到输出空间的最优映射，具体怎么实现，见训练模型章节。 为什么要用机器学习解决问题？目前处于大数据时代，到处都有成T成P的数据，简单规则处理难以发挥这些数据的价值；廉价的高性能计算，使得基于大规模数据的学习时间和代价降低；廉价的大规模存储，使得能够更快地和代价更小地处理大规模数据；存在大量高价值的问题，使得花大量精力用机器学习解决问题后，能获得丰厚收益。 机器学习应该用于解决什么问题？目标问题需要价值巨大，因为机器学习解决问题有一定的代价；目标问题有大量数据可用，有大量数据才能使机器学习比较好地解决问题（相对于简单规则或人工）；目标问题由多种因素（特征）决定，机器学习解决问题的优势才能体现（相对于简单规则或人工）；目标问题需要持续优化，因为机器学习可以基于数据自我学习和迭代，持续地发挥价值。 对问题建模本文以DEAL（团购单）交易额预估问题为例（就是预估一个给定DEAL一段时间内卖了多少钱），介绍使用机器学习如何解决问题。首先需要： 收集问题的资料，理解问题，成为这个问题的专家；拆解问题，简化问题，将问题转化机器可预估的问题。深入理解和分析DEAL交易额后，可以将它分解为如下图的几个问题：deal_problem 单个模型？多个模型？如何来选择？按照上图进行拆解后，预估DEAL交易额就有2种可能模式，一种是直接预估交易额；另一种是预估各子问题，如建立一个用户数模型和建立一个访购率模型（访问这个DEAL的用户会购买的单子数），再基于这些子问题的预估值计算交易额。 不同方式有不同优缺点，具体如下：模式 缺点 优点单模型 1. 预估难度大 风险比较高 1. 理论上可以获得最优预估（实际上很难） 一次解决问题多模型 1. 可能产生积累误差 训练和应用成本高 1. 单个子模型更容易实现比较准地预估 可以调整子模型的融合方式，以达到最佳效果选择哪种模式？1）问题可预估的难度，难度大，则考虑用多模型；2）问题本身的重要性，问题很重要，则考虑用多模型；3）多个模型的关系是否明确，关系明确，则可以用多模型。如果采用多模型，如何融合？可以根据问题的特点和要求进行线性融合，或进行复杂的融合。以本文问题为例，至少可以有如下两种：model_merg 模型选择对于DEAL交易额这个问题，我们认为直接预估难度很大，希望拆成子问题进行预估，即多模型模式。那样就需要建立用户数模型和访购率模型，因为机器学习解决问题的方式类似，下文只以访购率模型为例。要解决访购率问题，首先要选择模型，我们有如下的一些考虑： 主要考虑1）选择与业务目标一致的模型；2）选择与训练数据和特征相符的模型。 训练数据少，High Level特征多，则使用“复杂”的非线性模型（流行的GBDT、Random Forest等）；训练数据很大量，Low Level特征多，则使用“简单”的线性模型（流行的LR、Linear-SVM等）。补充考虑1）当前模型是否被工业界广泛使用；2）当前模型是否有比较成熟的开源工具包（公司内或公司外）；3）当前工具包能够的处理数据量能否满足要求；4）自己对当前模型理论是否了解，是否之前用过该模型解决问题。为实际问题选择模型，需要转化问题的业务目标为模型评价目标，转化模型评价目标为模型优化目标；根据业务的不同目标，选择合适的模型，具体关系如下：select_model 通常来讲，预估真实数值（回归）、大小顺序（排序）、目标所在的正确区间（分类）的难度从大到小，根据应用所需，尽可能选择难度小的目标进行。对于访购率预估的应用目标来说，我们至少需要知道大小顺序或真实数值，所以我们可以选择Area Under Curve（AUC）或Mean Absolute Error（MAE）作为评估目标，以Maximum likelihood为模型损失函数（即优化目标）。综上所述，我们选择spark版本 GBDT或LR，主要基于如下考虑：1）可以解决排序或回归问题；2）我们自己实现了算法，经常使用，效果很好；3）支持海量数据；4）工业界广泛使用。 准备训练数据深入理解问题，针对问题选择了相应的模型后，接下来则需要准备数据；数据是机器学习解决问题的根本，数据选择不对，则问题不可能被解决，所以准备训练数据需要格外的小心和注意： 注意点：待解决问题的数据本身的分布尽量一致；训练集/测试集分布与线上预测环境的数据分布尽可能一致，这里的分布是指（x,y）的分布，不仅仅是y的分布；y数据噪音尽可能小，尽量剔除y有噪音的数据；非必要不做采样，采样常常可能使实际数据分布发生变化，但是如果数据太大无法训练或者正负比例严重失调（如超过100:1）,则需要采样解决。 常见问题及解决办法待解决问题的数据分布不一致：1）访购率问题中DEAL数据可能差异很大，如美食DEAL和酒店DEAL的影响因素或表现很不一致，需要做特别处理；要么对数据提前归一化，要么将分布不一致因素作为特征，要么对各类别DEAL单独训练模型。数据分布变化了：1）用半年前的数据训练模型，用来预测当前数据，因为数据分布随着时间可能变化了，效果可能很差。尽量用近期的数据训练，来预测当前数据，历史的数据可以做降权用到模型，或做transfer learning。y数据有噪音：1）在建立CTR模型时，将用户没有看到的Item作为负例，这些Item是因为用户没有看到才没有被点击，不一定是用户不喜欢而没有被点击，所以这些Item是有噪音的。可以采用一些简单规则，剔除这些噪音负例，如采用skip-above思想，即用户点过的Item之上，没有点过的Item作为负例（假设用户是从上往下浏览Item）。采样方法有偏，没有覆盖整个集合：1）访购率问题中，如果只取只有一个门店的DEAL进行预估，则对于多门店的DEAL无法很好预估。应该保证一个门店的和多个门店的DEAL数据都有；2）无客观数据的二分类问题，用规则来获得正/负例，规则对正/负例的覆盖不全面。应该随机抽样数据，进行人工标注，以确保抽样数据和实际数据分布一致。 访购率问题的训练数据收集N个月的DEAL数据（x）及相应访购率（y）；收集最近N个月，剔除节假日等非常规时间 （保持分布一致）；只收集在线时长&gt;T 且 访问用户数 &gt; U的DEAL （减少y的噪音）；考虑DEAL销量生命周期 （保持分布一致）；考虑不同城市、不同商圈、不同品类的差别 （保持分布一致）。 抽取特征完成数据筛选和清洗后，就需要对数据抽取特征，就是完成输入空间到特征空间的转换（见下图）。针对线性模型或非线性模型需要进行不同特征抽取，线性模型需要更多特征抽取工作和技巧，而非线性模型对特征抽取要求相对较低。extract_fea 通常，特征可以分为High Level与Low Level，High Level指含义比较泛的特征，Low Level指含义比较特定的特征，举例来说： DEAL A1属于POIA，人均50以下，访购率高； DEAL A2属于POIA，人均50以上，访购率高； DEAL B1属于POIB，人均50以下，访购率高； DEAL B2属于POIB，人均50以上，访购率底； 基于上面的数据，可以抽到两种特征，POI（门店）或人均消费；POI特征则是Low Level特征，人均消费则是High Level特征；假设模型通过学习，获得如下预估： 如果DEALx 属于POIA（Low Level feature），访购率高；如果DEALx 人均50以下（High Level feature），访购率高。所以，总体上，Low Level 比较有针对性，单个特征覆盖面小（含有这个特征的数据不多），特征数量（维度）很大。High Level比较泛化，单个特征覆盖面大（含有这个特征的数据很多），特征数量（维度）不大。长尾样本的预测值主要受High Level特征影响。高频样本的预测值主要受Low Level特征影响。 对于访购率问题，有大量的High Level或Low Level的特征，其中一些展示在下图：fea_list 非线性模型的特征1）可以主要使用High Level特征，因为计算复杂度大，所以特征维度不宜太高；2）通过High Level非线性映射可以比较好地拟合目标。线性模型的特征1）特征体系要尽可能全面，High Level和Low Level都要有；2）可以将High Level转换Low Level，以提升模型的拟合能力。 特征归一化特征抽取后，如果不同特征的取值范围相差很大，最好对特征进行归一化，以取得更好的效果，常见的归一化方式如下： Rescaling归一化到[0,1] 或 [-1，1]，用类似方式 特征选择特征抽取和归一化之后，如果发现特征太多，导致模型无法训练，或很容易导致模型过拟合，则需要对特征进行选择，挑选有价值的特征。 Filter：假设特征子集对模型预估的影响互相独立，选择一个特征子集，分析该子集和数据Label的关系，如果存在某种正相关，则认为该特征子集有效。衡量特征子集和数据Label关系的算法有很多，如Chi-square，Information Gain。Wrapper：选择一个特征子集加入原有特征集合，用模型进行训练，比较子集加入前后的效果，如果效果变好，则认为该特征子集有效，否则认为无效。Embedded：将特征选择和模型训练结合起来，如在损失函数中加入L1 Norm ，L2 Norm。 训练模型完成特征抽取和处理后，就可以开始模型训练了，下文以简单且常用的Logistic Regression模型（下称LR模型）为例，进行简单介绍。设有m个（x,y）训练数据，其中x为特征向量，y为label，；w为模型中参数向量，即模型训练中需要学习的对象。所谓训练模型，就是选定假说函数和损失函数，基于已有训练数据（x,y），不断调整w，使得损失函数最优，相应的w就是最终学习结果，也就得到相应的模型。 ###模型函数1）假说函数，即假设x和y存在一种函数关系： 2）损失函数，基于上述假设函数，构建模型损失函数（优化目标），在LR中通常以（x,y）的最大似然估计为目标： 优化算法梯度下降（Gradient Descent）即w沿着损失函数的负梯度方向进行调整，示意图见下图，的梯度即一阶导数（见下式），梯度下降有多种类型，如随机梯度下降或批量梯度下降。 随机梯度下降（Stochastic Gradient Descent），每一步随机选择一个样本，计算相应的梯度，并完成w的更新，如下式， 批量梯度下降（Batch Gradient Descent）,每一步都计算训练数据中的所有样本对应的梯度，w沿着这个梯度方向迭代，即 gradient_descent牛顿法（Newton’s Method）牛顿法的基本思想是在极小点附近通过对目标函数做二阶Taylor展开，进而找到L(w)的极小点的估计值。形象地讲，在wk处做切线，该切线与L(w)=0的交点即为下一个迭代点wk+1（示意图如下）。w的更新公式如下，其中目标函数的二阶偏导数，即为大名鼎鼎的Hessian矩阵。 拟牛顿法（Quasi-Newton Methods）：计算目标函数的二阶偏导数，难度较大，更为复杂的是目标函数的Hessian矩阵无法保持正定；不用二阶偏导数而构造出可以近似Hessian矩阵的逆的正定对称阵，从而在”拟牛顿”的条件下优化目标函数。BFGS： 使用BFGS公式对H(w)进行近似，内存中需要放H(w),内存需要O(m2)级别；L-BFGS：存储有限次数（如k次）的更新矩阵，用这些更新矩阵生成新的H(w),内存降至O(m)级别；OWLQN: 如果在目标函数中引入L1正则化，需要引入虚梯度来解决目标函数不可导问题，OWLQN就是用来解决这个问题。newtonCoordinate Descent对于w，每次迭代，固定其他维度不变，只对其一个维度进行搜索，确定最优下降方向（示意图如下），公式表达如下：coordinate_descent 优化模型经过上文提到的数据筛选和清洗、特征设计和选择、模型训练，就得到了一个模型，但是如果发现效果不好？怎么办？【首先】反思目标是否可预估，数据和特征是否存在bug。【然后】分析一下模型是Overfitting还是Underfitting，从数据、特征和模型等环节做针对性优化。 Underfitting &amp; Overfitting所谓Underfitting，即模型没有学到数据内在关系，如下图左一所示，产生分类面不能很好的区分X和O两类数据；产生的深层原因，就是模型假设空间太小或者模型假设空间偏离。所谓Overfitting，即模型过渡拟合了训练数据的内在关系，如下图右一所示，产生分类面过好地区分X和O两类数据，而真实分类面可能并不是这样，以至于在非训练数据上表现不好；产生的深层原因，是巨大的模型假设空间与稀疏的数据之间的矛盾。underfitting_overfitting 在实战中，可以基于模型在训练集和测试集上的表现来确定当前模型到底是Underfitting还是Overfitting，判断方式如下表： 训练集表现 测试集表现 问题&lt; 期望目标值 &lt; 期望目标值 Underfitting 期望目标值 接近或略逊于训练集 合适期望目标值 远差于训练集 Overfitting 怎么解决Underfitting和Overfitting问题？ 问题 数据 特征 模型Underfitting 清洗数据 1. 增加特征 删除噪音特征 1. 调低正则项的惩罚参数 换更“复杂”的模型（如把线性模型换为非线性模型） 多个模型级联或组合Overfitting 增加数据 1. 进行特征选择 降维（如对特征进行聚类、主题模型进行处理等） 提高正则项的惩罚参数 减少训练迭代次数 换更“简单”的模型（如把非线性模型换为线性模型）4.总结综上所述，机器学习解决问题涉及到问题建模、准备训练数据、抽取特征、训练模型和优化模型等关键环节，有如下要点： 理解业务，分解业务目标，规划模型可预估的路线图。数据：y数据尽可能真实客观；训练集/测试集分布与线上应用环境的数据分布尽可能一致。特征：利用Domain Knowledge进行特征抽取和选择；针对不同类型的模型设计不同的特征。模型：针对不同业务目标、不同数据和特征，选择不同的模型；如果模型不符合预期，一定检查一下数据、特征、模型等处理环节是否有bug；考虑模型Underfitting和Qverfitting，针对性地优化。 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码 12345678![](http://latex.codecogs.com/png.latex?x^&#123;%27&#125;=\\frac&#123;x-min(x)&#125;&#123;max(x)-min(x)&#125;)![](http://latex.codecogs.com/png.latex?h_&#123;w&#125;\\left%20(%20x%20\\right%20)=P\\left%20(%20y=1|x;w%20\\right%20)%20=\\frac&#123;1&#125;&#123;1+e^&#123;-wx&#125;&#125;)![](http://latex.codecogs.com/png.latex?L\\left%20(%20w%20%20\\right%20)=\\sum_&#123;i=1&#125;^&#123;m&#125;y^&#123;(i)&#125;logh_&#123;w&#125;(x^&#123;(i)&#125;)+(1-y^&#123;(i)&#125;)log(1-h_&#123;w&#125;(x^&#123;(i)&#125;)))![](http://latex.codecogs.com/png.latex?L^&#123;%27&#125;\\left%20(%20w\\right%20)=\\sum_&#123;i=1&#125;^&#123;m&#125;(y^&#123;(i)&#125;-h_&#123;w&#125;(x^&#123;(i)&#125;))x^&#123;(i)&#125;)![](http://latex.codecogs.com/png.latex?w:=w+\\eta%20L^&#123;%27&#125;(w)=w+\\eta%20(y^&#123;(i)&#125;-h_&#123;w&#125;(x^&#123;(i)&#125;))x^&#123;(i)&#125;)![](http://latex.codecogs.com/png.latex?w:=w+\\eta%20L^&#123;%27&#125;(w)=w+\\eta%20\\sum_&#123;i=1&#125;^&#123;m&#125;(y^&#123;(i)&#125;-h_&#123;w&#125;(x^&#123;(i)&#125;))x^&#123;(i)&#125;)![](http://latex.codecogs.com/png.latex?w:=w-\\frac&#123;L^&#123;%27&#125;(w)&#125;&#123;L^&#123;%27%27&#125;(w)&#125;=w-H^&#123;-1&#125;L^&#123;%27&#125;(w))","comments":true,"categories":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/categories/AI/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"机器学习中的数据清洗与特征处理综述","date":"2017-02-26T14:24:06.000Z","path":"2017/02/26/BusinessAI/data-clean-and-remark-feature-in-meituan/","text":"caohao 背景随着美团交易规模的逐步增大，积累下来的业务数据和交易数据越来越多，这些数据是美团做为一个团购平台最宝贵的财富。通过对这些数据的分析和挖掘，不仅能给美团业务发展方向提供决策支持，也为业务的迭代指明了方向。目前在美团的团购系统中大量地应用到了机器学习和数据挖掘技术，例如个性化推荐、筛选排序、搜索排序、用户建模等等，为公司创造了巨大的价值。 本文主要介绍在美团的推荐与个性化团队实践中的数据清洗与特征挖掘方法。主要内容已经在内部公开课”机器学习InAction系列”讲过，本博客的内容主要是讲座内容的提炼和总结。 综述机器学习框架如上图所示是一个经典的机器学习问题框架图。数据清洗和特征挖掘的工作是在灰色框中框出的部分，即“数据清洗=&gt;特征，标注数据生成=&gt;模型学习=&gt;模型应用”中的前两个步骤。灰色框中蓝色箭头对应的是离线处理部分。主要工作是 从原始数据，如文本、图像或者应用数据中清洗出特征数据和标注数据。对清洗出的特征和标注数据进行处理，例如样本采样，样本调权，异常点去除，特征归一化处理，特征变化，特征组合等过程。最终生成的数据主要是供模型训练使用。灰色框中绿色箭头对应的是在线处理的部分。所做的主要工作和离线处理的类似，主要的区别在于1.不需要清洗标注数据，只需要处理得到特征数据，在线模型使用特征数据预测出样本可能的标签。2.最终生成数据的用处，最终生成的数据主要用于模型的预测，而不是训练。在离线的处理部分，可以进行较多的实验和迭代，尝试不同的样本采样、样本权重、特征处理方法、特征组合方法等，最终得到一个最优的方法，在离线评估得到好的结果后，最终将确定的方案在线上使用。另外，由于在线和离线环境不同，存储数据、获取数据的方法存在较大的差异。例如离线数据获取可以将数据存储在Hadoop，批量地进行分析处理等操作，并且容忍一定的失败。而在线服务获取数据需要稳定、延时小等，可以将数据建入索引、存入KV存储系统等。后面在相应的部分会详细地介绍。 本文以点击下单率预测为例，结合实例来介绍如何进行数据清洗和特征处理。首先介绍下点击下单率预测任务，其业务目标是提高团购用户的用户体验，帮助用户更快更好地找到自己想买的单子。这个概念或者说目标看起来比较虚，我们需要将其转换成一个技术目标，便于度量和实现。最终确定的技术目标是点击下单率预估，去预测用户点击或者购买团购单的概率。我们将预测出来点击或者下单率高的单子排在前面，预测的越准确，用户在排序靠前的单子点击、下单的就越多，省去了用户反复翻页的开销，很快就能找到自己想要的单子。离线我们用常用的衡量排序结果的AUC指标，在线的我们通过ABTest来测试算法对下单率、用户转化率等指标的影响。 特征使用方案在确定了目标之后，下一步，我们需要确定使用哪些数据来达到目标。需要事先梳理哪些特征数据可能与用户是否点击下单相关。我们可以借鉴一些业务经验，另外可以采用一些特征选择、特征分析等方法来辅助我们选择。具体的特征选择，特征分析等方法我们后面会详细介绍。从业务经验来判断，可能影响用户是否点击下单的因素有： 距离，很显然这是一个很重要的特征。如果购买一个离用户距离较远的单子，用户去消费这个单子需要付出很多的代价。 当然，也并不是没有买很远单子的用户，但是这个比例会比较小。用户历史行为，对于老用户，之前可能在美团有过购买、点击等行为。用户实时兴趣。单子质量，上面的特征都是比较好衡量的，单子质量可能是更复杂的一个特征。是否热门，用户评价人数，购买数等等。在确定好要使用哪些数据之后，我们需要对使用数据的可用性进行评估，包括数据的获取难度，数据的规模，数据的准确率，数据的覆盖率等， 数据获取难度例如获取用户id不难，但是获取用户年龄和性别较困难，因为用户注册或者购买时，这些并不是必填项。即使填了也不完全准确。这些特征可能是通过额外的预测模型预测的，那就存在着模型精度的问题。数据覆盖率数据覆盖率也是一个重要的考量因素，例如距离特征，并不是所有用户的距离我们都能获取到。PC端的就没有距离，还有很多用户禁止使用它们的地理位置信息等。用户历史行为，只有老用户才会有行为。用户实时行为，如果用户刚打开app，还没有任何行为，同样面临着一个冷启动的问题。数据的准确率单子质量，用户性别等，都会有准确率的问题。 特征获取方案Ok，在选定好要用的特征之后，我们需要考虑一个问题。就是这些数据从哪可以获取？只有获取了这些数据我们才能用上。否则，提一个不可能获取到的特征，获取不到，提了也是白提。下面就介绍下特征获取方案。 离线特征获取方案离线可以使用海量的数据，借助于分布式文件存储平台，例如HDFS等，使用例如MapReduce，Spark等处理工具来处理海量的数据等。在线特征获取方案在线特征比较注重获取数据的延时，由于是在线服务，需要在非常短的时间内获取到相应的数据，对查找性能要求非常高，可以将数据存储在索引、kv存储等。而查找性能与数据的数据量会有矛盾，需要折衷处理，我们使用了特征分层获取方案，如下图所示。服务架构出于性能考虑。在粗排阶段，使用更基础的特征，数据直接建入索引。精排阶段，再使用一些个性化特征等。特征与标注数据清洗在了解特征数据放在哪儿、怎样获取之后。下一步就是考虑如何处理特征和标注数据了。下面3节都是主要讲的特征和标注处理方法 ##标注数据清洗首先介绍下如何清洗特征数据，清洗特征数据方法可以分为离线清洗和在线清洗两种方法。 离线清洗数据离线清洗优点是方便评估新特征效果，缺点是实时性差，与线上实时环境有一定误差。对于实时特征难以训练得到恰当的权重。在线清洗数据在线清洗优点是实时性强，完全记录的线上实际数据，缺点是新特征加入需要一段时间做数据积累。 样本采样与样本过滤特征数据只有在和标注数据合并之后，才能用来做为模型的训练。下面介绍下如何清洗标注数据。主要是数据采样和样本过滤。 数据采样，例如对于分类问题：选取正例，负例。对于回归问题，需要采集数据。对于采样得到的样本，根据需要，需要设定样本权重。当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。采样的方法包括随机采样，固定比例采样等方法。 除了采样外，经常对样本还需要进行过滤，包括 1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括偏差检测，例如聚类，最近邻等。基于统计的异常点检测算法例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法 特征分类在分析完特征和标注的清洗方法之后，下面来具体介绍下特征的处理方法，先对特征进行分类，对于不同的特征应该有不同的处理方法。 根据不同的分类方法，可以将特征分为(1)Low level特征和High level特征。(2)稳定特征与动态特征。(3)二值特征、连续特征、枚举特征。 Low level特征是较低级别的特征，主要是原始特征，不需要或者需要非常少的人工处理和干预，例如文本特征中的词向量特征，图像特征中的像素点，用户id，商品id等。Low level特征一般维度比较高，不能用过于复杂的模型。High level特征是经过较复杂的处理，结合部分业务逻辑或者规则、模型得到的特征，例如人工打分，模型打分等特征，可以用于较复杂的非线性模型。Low level 比较针对性，覆盖面小。长尾样本的预测值主要受high level特征影响。 高频样本的预测值主要受low level特征影响。 稳定特征是变化频率(更新频率)较少的特征，例如评价平均分，团购单价格等，在较长的时间段内都不会发生变化。动态特征是更新变化比较频繁的特征，有些甚至是实时计算得到的特征，例如距离特征，2小时销量等特征。或者叫做实时特征和非实时特征。针对两类特征的不同可以针对性地设计特征存储和更新方式，例如对于稳定特征，可以建入索引，较长时间更新一次，如果做缓存的话，缓存的时间可以较长。对于动态特征，需要实时计算或者准实时地更新数据，如果做缓存的话，缓存过期时间需要设置的较短。 二值特征主要是0/1特征，即特征只取两种值：0或者1，例如用户id特征：目前的id是否是某个特定的id，词向量特征：某个特定的词是否在文章中出现等等。连续值特征是取值为有理数的特征，特征取值个数不定，例如距离特征，特征取值为是0~正无穷。枚举值特征主要是特征有固定个数个可能值，例如今天周几，只有7个可能值：周1，周2，…，周日。在实际的使用中，我们可能对不同类型的特征进行转换，例如将枚举特征或者连续特征处理为二值特征。枚举特征处理为二值特征技巧：将枚举特征映射为多个特征，每个特征对应一个特定枚举值，例如今天周几，可以把它转换成7个二元特征：今天是否是周一，今天是否是周二，…，今天是否是周日。连续值处理为二值特征方法：先将连续值离散化（后面会介绍如何离散化)，再将离散化后的特征切分为N个二元特征，每个特征代表是否在这个区间内。 特征处理与分析在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。 特征归一化，离散化，缺省值处理主要用于单个特征的处理。 归一化不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。离散化在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，…，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。缺省值处理有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。 特征降维在介绍特征降维之前，先介绍下特征升维。在机器学习中，有一个VC维理论。根据VC维理论，VC维越高，打散能力越强，可容许的模型复杂度越高。在低维不可分的数据，映射到高维是可分。可以想想，给你一堆物品，人脑是如何对这些物品进行分类，依然是找出这些物品的一些特征，例如：颜色，形状，大小，触感等等，然后根据这些特征对物品做以归类，这其实就是一个先升维，后划分的过程。比如我们人脑识别香蕉。可能首先我们发现香蕉是黄色的。这是在颜色这个维度的一个切分。但是很多东西都是黄色的啊，例如哈密瓜。那么怎么区分香蕉和哈密瓜呢？我们发现香蕉形状是弯曲的。而哈密瓜是圆形的，那么我们就可以用形状来把香蕉和哈密瓜划分开了，即引入一个新维度：形状，来区分。这就是一个从“颜色”一维特征升维到二维特征的例子。 那问题来了，既然升维后模型能力能变强，那么是不是特征维度越高越好呢？为什么要进行特征降维&amp;特征选择？主要是出于如下考虑：1. 特征维数越高，模型越容易过拟合，此时更复杂的模型就不好用。2. 相互独立的特征维数越高，在模型不变的情况下，在测试集上达到相同的效果表现所需要的训练样本的数目就越大。 3. 特征数量增加带来的训练、测试以及存储的开销都会增大。4.在某些模型中，例如基于距离计算的模型KMeans，KNN等模型，在进行距离计算时，维度过高会影响精度和性能。5.可视化分析的需要。在低维的情况下，例如二维，三维，我们可以把数据绘制出来，可视化地看到数据。当维度增高时，就难以绘制出来了。在机器学习中，有一个非常经典的维度灾难的概念。用来描述当空间维度增加时，分析和组织高维空间，因体积指数增加而遇到各种问题场景。例如，100个平均分布的点能把一个单位区间以每个点距离不超过0.01采样；而当维度增加到10后，如果以相邻点距离不超过0.01小方格采样单位超一单位超正方体，则需要10^20 个采样点。 正是由于高维特征有如上描述的各种各样的问题，所以我们需要进行特征降维和特征选择等工作。特征降维常用的算法有PCA，LDA等。特征降维的目标是将高维空间中的数据集映射到低维空间数据，同时尽可能少地丢失信息，或者降维后的数据点尽可能地容易被区分 PCA算法通过协方差矩阵的特征值分解能够得到数据的主成分，以二维特征为例，两个特征之间可能存在线性关系（例如运动的时速和秒速度），这样就造成了第二维信息是冗余的。PCA的目标是发现这种特征之间的线性关系，并去除。LDA算法考虑label，降维后的数据点尽可能地容易被区分 特征选择特征选择的目标是寻找最优特征子集。特征选择能剔除不相关(irrelevant)或冗余(redundant )的特征，从而达到减少特征个数，提高模型精确度，减少运行时间的目的。另一方面，选取出真正相关的特征简化模型，协助理解数据产生的过程。特征选择的一般过程如下图所示：特征选择的过程 ( M. Dash and H. Liu 1997 )主要分为产生过程，评估过程，停止条件和验证过程。 特征选择-产生过程和生成特征子集方法完全搜索(Complete)广度优先搜索( Breadth First Search )广度优先遍历特征子空间。枚举所有组合，穷举搜索，实用性不高。分支限界搜索( Branch and Bound )穷举基础上加入分支限界。例如：剪掉某些不可能搜索出比当前最优解更优的分支。其他，如定向搜索 (Beam Search )，最优优先搜索 ( Best First Search )等启发式搜索(Heuristic)序列前向选择( SFS ， Sequential Forward Selection )从空集开始，每次加入一个选最优。序列后向选择( SBS ， Sequential Backward Selection )从全集开始，每次减少一个选最优。增L去R选择算法 ( LRS ， Plus-L Minus-R Selection )从空集开始，每次加入L个，减去R个，选最优（L&gt;R)或者从全集开始，每次减去R个，增加L个，选最优(L&lt;R)。其他如双向搜索( BDS ， Bidirectional Search )，序列浮动选择( Sequential Floating Selection )等 随机搜索(Random)随机产生序列选择算法(RGSS， Random Generation plus Sequential Selection)随机产生一个特征子集，然后在该子集上执行SFS与SBS算法。模拟退火算法( SA， Simulated Annealing )以一定的概率来接受一个比当前解要差的解，而且这个概率随着时间推移逐渐降低遗传算法( GA， Genetic Algorithms )通过交叉、突变等操作繁殖出下一代特征子集，并且评分越高的特征子集被选中参加繁殖的概率越高。随机算法共同缺点:依赖随机因素，有实验结果难重现。 特征选择－有效性分析对特征的有效性进行分析，得到各个特征的特征权重，根据是否与模型有关可以分为1.与模型相关特征权重，使用所有的特征数据训练出来模型，看在模型中各个特征的权重，由于需要训练出模型，模型相关的权重与此次学习所用的模型比较相关。不同的模型有不同的模型权重衡量方法。例如线性模型中，特征的权重系数等。2.与模型无关特征权重。主要分析特征与label的相关性，这样的分析是与这次学习所使用的模型无关的。与模型无关特征权重分析方法包括(1)交叉熵，(2)Information Gain，(3)Odds ratio，(4)互信息，(5)KL散度等 特征监控在机器学习任务中，特征非常重要。 个人经验，80%的效果由特征带来。下图是随着特征数的增加，最终模型预测值与实际值的相关系数变化。特征重要性对于重要的特征进行监控与有效性分析，了解模型所用的特征是否存在问题，当某个特别重要的特征出问题时，需要做好备案，防止灾难性结果。需要建立特征有效性的长效监控机制我们对关键特征进行了监控，下面特征监控界面的一个截图。通过监控我们发现有一个特征的覆盖率每天都在下降，与特征数据提供方联系之后，发现特征数据提供方的数据源存在着问题，在修复问题之后，该特征恢复正常并且覆盖率有了较大提升。特征监控 在发现特征出现异常时，我们会及时采取措施，对服务进行降级处理，并联系特征数据的提供方尽快修复。对于特征数据生成过程中缺乏监控的情况也会督促做好监控，在源头解决问题。 机器学习InAction系列讲座介绍：结合美团在机器学习上的实践，我们进行一个实战（InAction）系列的介绍（带“机器学习InAction系列”标签的5篇文章），介绍机器学习在解决问题的实战中所需的基本技术、经验和技巧。本文主要介绍了数据清洗与特征处理，其他四篇文章主要介绍了机器学习解决问题流程和模型训练、模型优化等工作。 参考《elements of statistical learning》http://en.wikipedia.org/wiki/Supervised_learninghttp://www.cnblogs.com/heaad/archive/2011/01/02/1924088.htmlhttp://zh.wikipedia.org/zh-cn/维数灾难http://www.cs.waikato.ac.nz/ml/weka/http://blog.csdn.net/lihaifeng555/article/details/4543752http://blog.csdn.net/abcjennifer/article/details/8002329http://www.cnblogs.com/leftnoteasy/archive/2011/01/08/lda-and-pca-machine-learning.html 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码","comments":true,"categories":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/categories/AI/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"深入FFM原理与实践","date":"2017-02-26T14:20:06.000Z","path":"2017/02/26/BusinessAI/ffm-learning-in-meituan/","text":"del2z, 大龙 前言FM和FFM模型是最近几年提出的模型，凭借其在数据量比较大并且特征稀疏的情况下，仍然能够得到优秀的性能和效果的特性，屡次在各大公司举办的CTR预估比赛中获得不错的战绩。美团点评技术团队在搭建DSP的过程中，探索并使用了FM和FFM模型进行CTR和CVR预估，并且取得了不错的效果。本文旨在把我们对FM和FFM原理的探索和应用的经验介绍给有兴趣的读者。 在计算广告领域，点击率CTR（click-through rate）和转化率CVR（conversion rate）是衡量广告流量的两个关键指标。准确的估计CTR、CVR对于提高流量的价值，增加广告收入有重要的指导作用。预估CTR/CVR，业界常用的方法有人工特征工程 + LR(Logistic Regression)、GBDT(Gradient Boosting Decision Tree) + LR[1][2][3]、FM（Factorization Machine）[2][7]和FFM（Field-aware Factorization Machine）[9]模型。在这些模型中，FM和FFM近年来表现突出，分别在由Criteo和Avazu举办的CTR预测竞赛中夺得冠军[4][5]。 考虑到FFM模型在CTR预估比赛中的不俗战绩，美团点评技术团队在搭建DSP（Demand Side Platform）[6]平台时，在站内CTR/CVR的预估上使用了该模型，取得了不错的效果。本文是基于对FFM模型的深度调研和使用经验，从原理、实现和应用几个方面对FFM进行探讨，希望能够从原理上解释FFM模型在点击率预估上取得优秀效果的原因。因为FFM是在FM的基础上改进得来的，所以我们首先引入FM模型，本文章节组织方式如下： 首先介绍FM的原理。其次介绍FFM对FM的改进。然后介绍FFM的实现细节。最后介绍模型在DSP场景的应用。 FM原理FM（Factorization Machine）是由Konstanz大学Steffen Rendle（现任职于Google）于2010年最早提出的，旨在解决稀疏数据下的特征组合问题[7]。下面以一个示例引入FM模型。假设一个广告分类的问题，根据用户和广告位相关的特征，预测用户是否点击了广告。源数据如下[8] Clicked? Country Day Ad_type1 USA 26/11/15 Movie0 China 1/7/14 Game1 China 19/2/15 Game“Clicked?”是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。 Clicked? Country=USA Country=China Day=26/11/15 Day=1/7/14 Day=19/2/15 Ad_type=Movie Ad_type=Game1 1 0 1 0 0 1 00 0 1 0 1 0 0 11 0 1 0 0 1 0 1由上表可以看出，经过One-Hot编码之后，大部分样本数据特征是比较稀疏的。上面的样例中，每个样本有7维特征，但平均仅有3维特征具有非零值。实际上，这种情况并不是此例独有的，在真实应用场景中这种情况普遍存在。例如，CTR/CVR预测时，用户的性别、职业、教育水平、品类偏好，商品的品类等，经过One-Hot编码转换后都会导致样本数据的稀疏性。特别是商品品类这种类型的特征，如商品的末级品类约有550个，采用One-Hot编码生成550个数值特征，但每个样本的这550个特征，有且仅有一个是有效的（非零）。由此可见，数据稀疏性是实际问题中不可避免的挑战。 One-Hot编码的另一个特点就是导致特征空间大。例如，商品品类有550维特征，一个categorical特征转换为550维数值特征，特征空间剧增。 同时通过观察大量的样本数据可以发现，某些特征经过关联之后，与label之间的相关性就会提高。例如，“USA”与“Thanksgiving”、“China”与“Chinese New Year”这样的关联特征，对用户的点击有着正向的影响。换句话说，来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，而在“Thanksgiving”却不会有特别的消费行为。这种关联特征与label的正向相关性在实际问题中是普遍存在的，如“化妆品”类商品与“女”性，“球类运动配件”的商品与“男”性，“电影票”的商品与“电影”品类偏好等。因此，引入两个特征的组合是非常有意义的。 多项式模型是包含特征组合的最直观的模型。在多项式模型中，特征 xixi 和 xjxj 的组合采用 xixjxixj 表示，即 xixi 和 xjxj 都非零时，组合特征 xixjxixj 才有意义。从对比的角度，本文只讨论二阶多项式模型。模型的表达式如下 y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1nwijxixj(1)(1)y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1nwijxixj其中，nn 代表样本的特征数量，xixi 是第 ii 个特征的值，w0w0、wiwi、wijwij 是模型参数。 从公式(1)(1)可以看出，组合特征的参数一共有 n(n−1)2n(n−1)2 个，任意两个参数都是独立的。然而，在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是，每个参数 wijwij 的训练需要大量 xixi 和 xjxj 都非零的样本；由于样本数据本来就比较稀疏，满足“xixi 和 xjxj 都非零”的样本将会非常少。训练样本的不足，很容易导致参数 wijwij 不准确，最终将严重影响模型的性能。 那么，如何解决二次项参数的训练问题呢？矩阵分解提供了一种解决思路。在model-based的协同过滤中，一个rating矩阵可以分解为user矩阵和item矩阵，每个user和item都可以采用一个隐向量表示[8]。比如在下图中的例子中，我们把每个user表示成一个二维向量，同时把每个item表示成一个二维向量，两个向量的点积就是矩阵中user对item的打分。 类似地，所有二次项参数 wijwij 可以组成一个对称阵 WW（为了方便说明FM的由来，对角元素可以设置为正实数），那么这个矩阵就可以分解为 W=VTVW=VTV，VV 的第 jj 列便是第 jj 维特征的隐向量。换句话说，每个参数 wij=⟨vi,vj⟩wij=⟨vi,vj⟩，这就是FM模型的核心思想。因此，FM的模型方程为（本文不讨论FM的高阶形式） y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,vj⟩xixj(2)(2)y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,vj⟩xixj其中，vivi 是第 ii 维特征的隐向量，⟨⋅,⋅⟩⟨⋅,⋅⟩ 代表向量点积。隐向量的长度为 kk（k&lt;&lt;nk&lt;&lt;n），包含 kk 个描述特征的因子。根据公式(2)(2)，二次项的参数数量减少为 knkn个，远少于多项式模型的参数数量。另外，参数因子化使得 xhxixhxi 的参数和 xixjxixj 的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计FM的二次项参数。具体来说，xhxixhxi 和 xixjxixj 的系数分别为 ⟨vh,vi⟩⟨vh,vi⟩ 和 ⟨vi,vj⟩⟨vi,vj⟩，它们之间有共同项 vivi。也就是说，所有包含“xixi 的非零组合特征”（存在某个 j≠ij≠i，使得 xixj≠0xixj≠0）的样本都可以用来学习隐向量 vivi，这很大程度上避免了数据稀疏性造成的影响。而在多项式模型中，whiwhi 和 wijwij 是相互独立的。 显而易见，公式(2)(2)是一个通用的拟合方程，可以采用不同的损失函数用于解决回归、二元分类等问题，比如可以采用MSE（Mean Square Error）损失函数来求解回归问题，也可以采用Hinge/Cross-Entropy损失来求解分类问题。当然，在进行二元分类时，FM的输出需要经过sigmoid变换，这与Logistic回归是一样的。直观上看，FM的复杂度是 O(kn2)O(kn2)。但是，通过公式(3)(3)的等式，FM的二次项可以化简，其复杂度可以优化到 O(kn)O(kn)[7]。由此可见，FM可以在线性时间对新样本作出预测。 ∑i=1n∑j=i+1n⟨vi,vj⟩xixj=12∑f=1k⎛⎝(∑i=1nvi,fxi)2−∑i=1nv2i,fx2i⎞⎠(3)(3)∑i=1n∑j=i+1n⟨vi,vj⟩xixj=12∑f=1k((∑i=1nvi,fxi)2−∑i=1nvi,f2xi2)我们再来看一下FM的训练复杂度，利用SGD（Stochastic Gradient Descent）训练模型。模型各个参数的梯度如下 ∂∂θy(x)=⎧⎩⎨⎪⎪1,xi,xi∑nj=1vj,fxj−vi,fx2i,ifθisw0ifθiswiifθisvi,f∂∂θy(x)={1,ifθisw0xi,ifθiswixi∑j=1nvj,fxj−vi,fxi2,ifθisvi,f其中，vj,fvj,f 是隐向量 vjvj 的第 ff 个元素。由于 ∑nj=1vj,fxj∑j=1nvj,fxj 只与 ff 有关，而与 ii 无关，在每次迭代过程中，只需计算一次所有 ff 的 ∑nj=1vj,fxj∑j=1nvj,fxj，就能够方便地得到所有 vi,fvi,f 的梯度。显然，计算所有 ff 的 ∑nj=1vj,fxj∑j=1nvj,fxj 的复杂度是 O(kn)O(kn)；已知 ∑nj=1vj,fxj∑j=1nvj,fxj 时，计算每个参数梯度的复杂度是 O(1)O(1)；得到梯度后，更新每个参数的复杂度是 O(1)O(1)；模型参数一共有 nk+n+1nk+n+1 个。因此，FM参数训练的复杂度也是 O(kn)O(kn)。综上可知，FM可以在线性时间训练和预测，是一种非常高效的模型。 FM与其他模型的对比FM是一种比较灵活的模型，通过合适的特征变换方式，FM可以模拟二阶多项式核的SVM模型、MF模型、SVD++模型等[7]。 相比SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二项多项式核SVM需要计算核矩阵，核矩阵复杂度就是N平方。 相比MF而言，我们把MF中每一项的rating分改写为 rui∼βu+γi+xTuyirui∼βu+γi+xuTyi，从公式(2)(2)中可以看出，这相当于只有两类特征 uu 和 ii 的FM模型。对于FM而言，我们可以加任意多的特征，比如user的历史购买平均值，item的历史购买平均值等，但是MF只能局限在两类特征。SVD++与MF类似，在特征的扩展性上都不如FM，在此不再赘述。 FFM原理FFM（Field-aware Factorization Machine）最初的概念来自Yu-Chin Juan（阮毓钦，毕业于中国台湾大学，现在美国Criteo工作）与其比赛队员，是他们借鉴了来自Michael Jahrer的论文[14]中的field概念提出了FM的升级版模型。通过引入field的概念，FFM把相同性质的特征归于同一个field。以上面的广告分类为例，“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。同理，商品的末级品类编码生成了550个特征，这550个特征都是说明商品所属的品类，因此它们也可以放到同一个field中。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。在FFM中，每一维特征 xixi，针对其它特征的每一种field fjfj，都会学习一个隐向量 vi,fjvi,fj。因此，隐向量不仅与特征相关，也与field相关。也就是说，“Day=26/11/15”这个特征与“Country”特征和“Ad_type”特征进行关联的时候使用不同的隐向量，这与“Country”和“Ad_type”的内在差异相符，也是FFM中“field-aware”的由来。 假设样本的 nn 个特征属于 ff 个field，那么FFM的二次项有 nfnf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。 y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,fj,vj,fi⟩xixj(4)(4)y(x)=w0+∑i=1nwixi+∑i=1n∑j=i+1n⟨vi,fj,vj,fi⟩xixj其中，fjfj 是第 jj 个特征所属的field。如果隐向量的长度为 kk，那么FFM的二次参数有 nfknfk 个，远多于FM模型的 nknk 个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 O(kn2)O(kn2)。 下面以一个例子简单说明FFM的特征组合方式[9]。输入记录如下 User Movie Genre PriceYuChin 3Idiots Comedy, Drama $9.99这条记录可以编码成5个特征，其中“Genre=Comedy”和“Genre=Drama”属于同一个field，“Price”是数值型，不用One-Hot编码转换。为了方便说明FFM的样本格式，我们将所有的特征和对应的field映射成整数编号。 Field name Field index Feature name Feature indexUser 1 User=YuChin 1Movie 2 Movie=3Idiots 2Genre 3 Genre=Comedy 3Price 4 Genre=Drama 4Price 5那么，FFM的组合特征有10项，如下图所示。⟨v1,2,v2,1⟩⋅1⋅1+⟨v1,3,v3,1⟩⋅1⋅1+⟨v1,3,v4,1⟩⋅1⋅1+⟨v1,4,v5,1⟩⋅1⋅9.99+⟨v2,3,v3,2⟩⋅1⋅1+⟨v2,3,v4,2⟩⋅1⋅1+⟨v2,4,v5,2⟩⋅1⋅9.99+⟨v3,3,v4,3⟩⋅1⋅1+⟨v3,4,v5,3⟩⋅1⋅9.99+⟨v4,4,v5,3⟩⋅1⋅9.99⟨v1,2,v2,1⟩⋅1⋅1+⟨v1,3,v3,1⟩⋅1⋅1+⟨v1,3,v4,1⟩⋅1⋅1+⟨v1,4,v5,1⟩⋅1⋅9.99+⟨v2,3,v3,2⟩⋅1⋅1+⟨v2,3,v4,2⟩⋅1⋅1+⟨v2,4,v5,2⟩⋅1⋅9.99+⟨v3,3,v4,3⟩⋅1⋅1+⟨v3,4,v5,3⟩⋅1⋅9.99+⟨v4,4,v5,3⟩⋅1⋅9.99其中，红色是field编号，蓝色是特征编号，绿色是此样本的特征取值。二次项的系数是通过与特征field相关的隐向量点积得到的，二次项共有 n(n−1)2n(n−1)2 个。 FFM实现Yu-Chin Juan实现了一个C++版的FFM模型，源码可从Github下载[10]。这个版本的FFM省略了常数项和一次项，模型方程如下。 ϕ(w,x)=∑j1,j2∈C2⟨wj1,f2,wj2,f1⟩xj1xj2(5)(5)ϕ(w,x)=∑j1,j2∈C2⟨wj1,f2,wj2,f1⟩xj1xj2其中，C2C2 是非零特征的二元组合，j1j1 是特征，属于field f1f1，wj1,f2wj1,f2 是特征 j1j1 对field f2f2 的隐向量。此FFM模型采用logistic loss作为损失函数，和L2惩罚项，因此只能用于二元分类问题。 minw∑i=1Llog(1+exp{−yiϕ(w,xi)})+λ2∥w∥2minw∑i=1Llog⁡(1+exp⁡{−yiϕ(w,xi)})+λ2‖w‖2其中，yi∈{−1,1}yi∈{−1,1} 是第 ii 个样本的label，LL 是训练样本数量，λλ 是惩罚项系数。模型采用SGD优化，优化流程如下。 参考 Algorithm1Algorithm1, 下面简单解释一下FFM的SGD优化过程。算法的输入 trtr、vava、papa 分别是训练样本集、验证样本集和训练参数设置。 根据样本特征数量（tr.ntr.n）、field的个数（tr.mtr.m）和训练参数（papa），生成初始化模型，即随机生成模型的参数；如果归一化参数 pa.normpa.norm 为真，计算训练和验证样本的归一化系数，样本 ii 的归一化系数为R[i]=1∥X[i]∥R[i]=1‖X[i]‖对每一轮迭代，如果随机更新参数 pa.randpa.rand 为真，随机打乱训练样本的顺序；对每一个训练样本，执行如下操作计算每一个样本的FFM项，即公式(5)(5)中的输出 ϕϕ；计算每一个样本的训练误差，如算法所示，这里采用的是交叉熵损失函数 log(1+eϕ)log⁡(1+eϕ)；利用单个样本的损失函数计算梯度 gΦgΦ，再根据梯度更新模型参数；对每一个验证样本，计算样本的FFM输出，计算验证误差；重复步骤3~5，直到迭代结束或验证误差达到最小。在SGD寻优时，代码采用了一些小技巧，对于提升计算效率是非常有效的。 第一，梯度分步计算。采用SGD训练FFM模型时，只采用单个样本的损失函数来计算模型参数的梯度。 L=Lerr+Lreg=log(1+exp{−yiϕ(w,xi)})+λ2∥w∥2L=Lerr+Lreg=log⁡(1+exp⁡{−yiϕ(w,xi)})+λ2‖w‖2∂L∂w=∂Lerr∂ϕ⋅∂ϕ∂w+∂Lreg∂w∂L∂w=∂Lerr∂ϕ⋅∂ϕ∂w+∂Lreg∂w上面的公式表明，∂Lerr∂ϕ∂Lerr∂ϕ 与具体的模型参数无关。因此，每次更新模型时，只需计算一次，之后直接调用 ∂Lerr∂ϕ∂Lerr∂ϕ 的值即可。对于更新 nfknfk 个模型参数，这种方式能够极大提升运算效率。 第二，自适应学习率。此版本的FFM实现没有采用常用的指数递减的学习率更新策略，而是利用 nfknfk 个浮点数的临时空间，自适应地更新学习率。学习率是参考AdaGrad算法计算的[11]，按如下方式更新 w′j1,f2=wj1,f2−η1+∑t(gtwj1,f2)2−−−−−−−−−−−−√⋅gwj1,f2wj1,f2′=wj1,f2−η1+∑t(gwj1,f2t)2⋅gwj1,f2其中，wj1,f2wj1,f2 是特征 j1j1 对field f2f2 隐向量的一个元素，元素下标未标出；gwj1,f2gwj1,f2 是损失函数对参数 wj1,f2wj1,f2 的梯度；gtwj1,f2gwj1,f2t 是第 tt 次迭代的梯度；ηη 是初始学习率。可以看出，随着迭代的进行，每个参数的历史梯度会慢慢累加，导致每个参数的学习率逐渐减小。另外，每个参数的学习率更新速度是不同的，与其历史梯度有关，根据AdaGrad的特点，对于样本比较稀疏的特征，学习率高于样本比较密集的特征，因此每个参数既可以比较快速达到最优，也不会导致验证误差出现很大的震荡。 第三，OpenMP多核并行计算。OpenMP是用于共享内存并行系统的多处理器程序设计的编译方案，便于移植和多核扩展[12]。FFM的源码采用了OpenMP的API，对参数训练过程SGD进行了多线程扩展，支持多线程编译。因此，OpenMP技术极大地提高了FFM的训练效率和多核CPU的利用率。在训练模型时，输入的训练参数ns_threads指定了线程数量，一般设定为CPU的核心数，便于完全利用CPU资源。 第四，SSE3指令并行编程。SSE3全称为数据流单指令多数据扩展指令集3，是CPU对数据层并行的关键指令，主要用于多媒体和游戏的应用程序中[13]。SSE3指令采用128位的寄存器，同时操作4个单精度浮点数或整数。SSE3指令的功能非常类似于向量运算。例如，aa 和 bb 采用SSE3指令相加（aa 和 bb 分别包含4个数据），其功能是 aa 中的4个元素与 bb 中4个元素对应相加，得到4个相加后的值。采用SSE3指令后，向量运算的速度更加快捷，这对包含大量向量运算的FFM模型是非常有利的。 除了上面的技巧之外，FFM的实现中还有很多调优技巧需要探索。例如，代码是按field和特征的编号申请参数空间的，如果选取了非连续或过大的编号，就会造成大量的内存浪费；在每个样本中加入值为1的新特征，相当于引入了因子化的一次项，避免了缺少一次项带来的模型偏差等。 FFM应用在DSP的场景中，FFM主要用来预估站内的CTR和CVR，即一个用户对一个商品的潜在点击率和点击后的转化率。 CTR和CVR预估模型都是在线下训练，然后用于线上预测。两个模型采用的特征大同小异，主要有三类：用户相关的特征、商品相关的特征、以及用户-商品匹配特征。用户相关的特征包括年龄、性别、职业、兴趣、品类偏好、浏览/购买品类等基本信息，以及用户近期点击量、购买量、消费额等统计信息。商品相关的特征包括所属品类、销量、价格、评分、历史CTR/CVR等信息。用户-商品匹配特征主要有浏览/购买品类匹配、浏览/购买商家匹配、兴趣偏好匹配等几个维度。 为了使用FFM方法，所有的特征必须转换成“field_id:feat_id:value”格式，field_id代表特征所属field的编号，feat_id是特征编号，value是特征的值。数值型的特征比较容易处理，只需分配单独的field编号，如用户评论得分、商品的历史CTR/CVR等。categorical特征需要经过One-Hot编码成数值型，编码产生的所有特征同属于一个field，而特征的值只能是0或1，如用户的性别、年龄段，商品的品类id等。除此之外，还有第三类特征，如用户浏览/购买品类，有多个品类id且用一个数值衡量用户浏览或购买每个品类商品的数量。这类特征按照categorical特征处理，不同的只是特征的值不是0或1，而是代表用户浏览或购买数量的数值。按前述方法得到field_id之后，再对转换后特征顺序编号，得到feat_id，特征的值也可以按照之前的方法获得。 CTR、CVR预估样本的类别是按不同方式获取的。CTR预估的正样本是站内点击的用户-商品记录，负样本是展现但未点击的记录；CVR预估的正样本是站内支付（发生转化）的用户-商品记录，负样本是点击但未支付的记录。构建出样本数据后，采用FFM训练预估模型，并测试模型的性能。 #(field) #(feature) AUC Logloss站内CTR 39 2456 0.77 0.38站内CVR 67 2441 0.92 0.13由于模型是按天训练的，每天的性能指标可能会有些波动，但变化幅度不是很大。这个表的结果说明，站内CTR/CVR预估模型是非常有效的。 在训练FFM的过程中，有许多小细节值得特别关注。 第一，样本归一化。FFM默认是进行样本数据的归一化，即 pa.normpa.norm 为真；若此参数设置为假，很容易造成数据inf溢出，进而引起梯度计算的nan错误。因此，样本层面的数据是推荐进行归一化的。 第二，特征归一化。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到 [0,1][0,1] 是非常必要的。 第三，省略零值特征。从FFM模型的表达式(4)(4)可以看出，零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。 后记本文主要介绍了FFM的思路来源和理论原理，并结合源码说明FFM的实际应用和一些小细节。从理论上分析，FFM的参数因子化方式具有一些显著的优势，特别适合处理样本稀疏性问题，且确保了较好的性能；从应用结果来看，站内CTR/CVR预估采用FFM是非常合理的，各项指标都说明了FFM在点击率预估方面的卓越表现。当然，FFM不一定适用于所有场景且具有超越其他模型的性能，合适的应用场景才能成就FFM的“威名”。 参考文献http://blog.csdn.net/lilyth_lilyth/article/details/48032119http://www.cnblogs.com/Matrix_Yao/p/4773221.htmlhttp://www.herbrich.me/papers/adclicksfacebook.pdfhttps://www.kaggle.com/c/criteo-display-ad-challengehttps://www.kaggle.com/c/avazu-ctr-predictionhttps://en.wikipedia.org/wiki/Demand-side_platformhttp://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdfhttp://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdfhttp://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdfhttps://github.com/guestwalk/libffmhttps://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGradhttp://openmp.org/wp/openmp-specifications/http://blog.csdn.net/gengshenghong/article/details/7008704https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码","comments":true,"categories":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/categories/AI/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"Online Learning算法理论与实践","date":"2017-02-26T14:13:06.000Z","path":"2017/02/26/BusinessAI/online-learning-in-meituan/","text":"孔东营 背景Online Learning是工业界比较常用的机器学习算法，在很多场景下都能有很好的效果。本文主要介绍Online Learning的基本原理和两种常用的Online Learning算法：FTRL（Follow The Regularized Leader）[1]和BPR（Bayesian Probit Regression）[2]，以及Online Learning在美团移动端推荐重排序的应用。 什么是Online Learning准确地说，Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。Online Learning的流程包括：将模型的预测结果展现给用户，然后收集用户的反馈数据，再用来训练模型，形成闭环的系统。如上图所示： Online Learning有点像自动控制系统，但又不尽相同，二者的区别是：Online Learning的优化目标是整体的损失函数最小化，而自动控制系统要求最终结果与期望值的偏差最小。 传统的训练方法，模型上线后，更新的周期会比较长（一般是一天，效率高的时候为一小时），这种模型上线后，一般是静态的（一段时间内不会改变），不会与线上的状况有任何互动，假设预测错了，只能在下一次更新的时候完成更正。Online Learning训练方法不同，会根据线上预测的结果动态调整模型。如果模型预测错误，会及时做出修正。因此，Online Learning能够更加及时地反映线上变化。 Online Learning的优化目标 如上图所示，Online Learning训练过程也需要优化一个目标函数（红框标注的），但是和其他的训练方法不同，Online Learning要求快速求出目标函数的最优解，最好是能有解析解。 怎样实现Online Learning 前面说到Online Learning要求快速求出目标函数的最优解。要满足这个要求，一般的做法有两种：Bayesian Online Learning和Follow The Regularized Leader。下面就详细介绍这两种做法的思路。 Bayesian Online Learning 贝叶斯方法能够比较自然地导出Online Learning的训练方法：给定参数先验，根据反馈计算后验，将其作为下一次预测的先验，然后再根据反馈计算后验，如此进行下去，就是一个Online Learning的过程，如下图所示。 举个例子， 我们做一个抛硬币实验，估算硬币正面的概率μμ。我们假设μμ的先验满足 p(μ)=Beta(α,β) p(μ)=Beta⁡(α,β) 对于观测值Y＝1Y＝1，代表是正面，我们可以算的后验： p(μ|Y=1)=Beta(α+1,β) p(μ|Y=1)=Beta⁡(α+1,β) 对于观测值Y＝0Y＝0，代表是反面，我们可以算的后验： p(μ|Y=0)=Beta(α,β+1) p(μ|Y=0)=Beta⁡(α,β+1) 按照上面的Bayesian Online Learning流程，我们可以得到估算μμ的Online Learning算法： 初始化 αα,ββ for i = 0 … n 如果 YiYi是正面 α=α+1α=α+1 如果 YiYi是反面 β=β+1β=β+1 最终: μ∼Beta(α,β)μ∼Beta⁡(α,β)，可以取μμ的期望，μ=αα+βμ=αα+β 假设抛了NN次硬币，正面出现HH次，反面出现TT次，按照上面的算法，可以算得： μ=α+Hα+β+N μ=α+Hα+β+N 和最大化似然函数： log[p(μ∣α,β)⋅p(Y=1∣μ)H⋅p(Y=0∣μ)T] log[p(μ∣α,β)⋅p(Y=1∣μ)H⋅p(Y=0∣μ)T] 得到的解是一样的。 上面的例子是针对离散分布的，我们可以再看一个连续分布的例子。 有一种测量仪器，测量的方差σ2σ2是已知的， 测量结果为：Y1,Y2,Y3,…,YnY1,Y2,Y3,…,Yn, 求真实值μμ的分布。 仪器的方差是σ2σ2, 所以观测值Y满足高斯分布： p(Y∣μ)=N(Y∣μ,σ2) p(Y∣μ)=N(Y∣μ,σ2) 观测到 Y1,Y2,Y3,…,YnY1,Y2,Y3,…,Yn, 估计参数 μμ 。 假设参数 μμ 满足高斯分布： p(μ)=N(μ∣m,v2) p(μ)=N(μ∣m,v2) 观测到YiYi, 可以计算的后验： p(μ∣Yi)=N(μ∣Yiv2+mσ2σ2+v2,σ2v2σ2+v2) p(μ∣Yi)=N(μ∣Yiv2+mσ2σ2+v2,σ2v2σ2+v2) 可以得到以下的Online Learning算法： 初始化 mm,v2v2 for i = 0 … n 观测值为YiYi 更新 m=Yiv2+mσ2σ2+v2 m=Yiv2+mσ2σ2+v2 v2=σ2v2σ2+v2 v2=σ2v2σ2+v2 上面的两个结果都是后验跟先验是同一分布的（一般取共轭先验，就会有这样的效果），这个后验很自然的作为后面参数估计的先验。假设后验分布和先验不一样，我们该怎么办呢？ 举个例子：假设上面的测量仪器只能观测到YY，是大于0，还是小于0，即Yi∈{−1，1}Yi∈{−1，1},Yi=−1Yi=−1，代表观测值小于0，Yi=1Yi=1代表观测值大于0。 此时，我们仍然可以计算后验分布： p(μ∣Yi＝1)=I(μ&gt;0)p(μ)∫+∞0p(μ)du p(μ∣Yi＝1)=I(μ&gt;0)p(μ)∫0+∞p(μ)du p(μ∣Yi＝−1)=I(μ&lt;0)p(μ)∫0−∞p(μ)du p(μ∣Yi＝−1)=I(μ&lt;0)p(μ)∫−∞0p(μ)du 但是后验分布显然不是高斯分布（是截断高斯分布），这种情况下，我们可以用和上面分布KL距离最近的高斯分布代替。 观测到Yi=1Yi=1 KL(p(μ∣Yi=1)||N(μ∣m~,v~2)) KL(p(μ∣Yi=1)||N(μ∣m~,v~2)) 可以求得： m~=m+v⋅υ(mv) m~=m+v⋅υ(mv) v~2=v2(1−ω(mv)) v~2=v2(1−ω(mv)) 观测到Yi=−1Yi=−1 KL(p(μ∣Yi=−1)||N(μ∣μ~,v~2)) KL(p(μ∣Yi=−1)||N(μ∣μ~,v~2)) 可以求得： m~=m−v⋅υ(−mv) m~=m−v⋅υ(−mv) v~2=v2(1−ω(−mv)) v~2=v2(1−ω(−mv)) 两者综合起来，可以求得： m~=m+Yiv⋅υ(Yimv) m~=m+Yiv⋅υ(Yimv) v~2=v2(1−ω(Yimv)) v~2=v2(1−ω(Yimv)) 其中： υ(t)=ϕ(t)Φ(t) υ(t)=ϕ(t)Φ(t) ϕ(t)=12πexp(−12t2) ϕ(t)=12πexp(−12t2) Φ(t)=∫t−∞ϕ(t)dt Φ(t)=∫−∞tϕ(t)dt ω(t)=υ(t)∗(t−υ(t)) ω(t)=υ(t)∗(t−υ(t)) 有了后验我们可以得到Online Bayesian Learning流程： 初始化 mm,v2v2 for i = 0 … n 观测值为YiYi 更新 m=m+Yi⋅v⋅υ(Yi⋅mv) m=m+Yi⋅v⋅υ(Yi⋅mv) v2=v2(1−ω(Yi⋅mv)) v2=v2(1−ω(Yi⋅mv)) Bayesian Online Learning最常见的应用就是BPR（Bayesian Probit Regression）。 BPR 在看Online BPR前，我们先了解以下Linear Gaussian System(具体可以参考[3]的4.4节)。 xx是满足多维高斯分布： p(x)=N(x∣μx,Σx) p(x)=N(x∣μx,Σx) yy是xx通过线性变换加入随机扰动ΣyΣy得到的变量： p(y∣x)=N(y∣Ax+b,Σy) p(y∣x)=N(y∣Ax+b,Σy) 已知xx，我们可以得到yy的分布： p(y)=N(y∣AμX+b,Σy+AΣxAT) p(y)=N(y∣AμX+b,Σy+AΣxAT) 上面这个结论的具体的推导过程可以参考[3]的4.4节，这里我们直接拿来用。 我们可以假设特征权重 ww 满足独立高斯分布，即 p(w)=N(w∣μ,Σ) p(w)=N(w∣μ,Σ) ： μ=[μ1,μ2,…,μD]T μ=[μ1,μ2,…,μD]T Σ=⎡⎣⎢⎢⎢⎢⎢σ210⋮00σ22⋮0……⋱…00⋮σ2D⎤⎦⎥⎥⎥⎥⎥ Σ=[σ120…00σ22…0⋮⋮⋱⋮00…σD2] YY是一维变量，是ww与特征向量xx的内积，加入方差为β2β2的扰动： p(y∣w)=N(y∣xTw,β2) p(y∣w)=N(y∣xTw,β2) 根据上面的式子可以得出： p(y∣w)=N(y∣xTμ,xTΣx+β2) p(y∣w)=N(y∣xTμ,xTΣx+β2) 由于我们只能观测到YY，是大于0，还是小于0，即Yi∈{−1，1}Yi∈{−1，1},Yi=−1Yi=−1，代表观测值小于0，Yi=1Yi=1代表观测值大于0。 对于观测值，我们可以先用KL距离近似yy的分布，我们可以算出后验： p(y∣Yi)=N(y∣m~,v~2) p(y∣Yi)=N(y∣m~,v~2) m~=xTμ+Yiυ(Yi⋅xTμxTΣx+β2−−−−−−−−−√) m~=xTμ+Yiυ(Yi⋅xTμxTΣx+β2) v~2=(xTΣx+β2)(1−ω(Yi⋅xTμxTΣx+β2−−−−−−−−−√)) v~2=(xTΣx+β2)(1−ω(Yi⋅xTμxTΣx+β2)) 有了yy的近似分布，我们可以计算出后验： p(w∣y)∝p(y∣w)p(w) p(w∣y)∝p(y∣w)p(w) 可以求得： p(wd∣y)=N(wd∣μ~d,σ~d) p(wd∣y)=N(wd∣μ~d,σ~d) μ~d=μd+Yixi,d⋅σ2dxTΣx+β2−−−−−−−−−√⋅υ(Yi⋅xTμxTΣx+β2−−−−−−−−−√) μ~d=μd+Yixi,d⋅σd2xTΣx+β2⋅υ(Yi⋅xTμxTΣx+β2) σ~d=σd⋅[1−xi,d⋅σ2dxTΣx+β2ω(Yi⋅xTμxTΣx+β2−−−−−−−−−√)] σ~d=σd⋅[1−xi,d⋅σd2xTΣx+β2ω(Yi⋅xTμxTΣx+β2)] Online Bayesian Probit Regression 训练流程如下： 初始化 μ1μ1,σ21σ12, μ2μ2,σ22σ22 , … , μDμD,σ2DσD2 for i = 1 … n 观测值为YiYi for d = 1 … D 更新 μd=μd+Yixi,d⋅σ2dxTiΣxi+β2−−−−−−−−−√⋅υ⎛⎝⎜Yi⋅xTiμxTiΣxi+β2−−−−−−−−−√⎞⎠⎟ μd=μd+Yixi,d⋅σd2xiTΣxi+β2⋅υ(Yi⋅xiTμxiTΣxi+β2) σd=σd⋅⎡⎣⎢1−xi,d⋅σ2dxTiΣxi+β2ω⎛⎝⎜Yi⋅xTiμxTiΣx+β2−−−−−−−−−√⎞⎠⎟⎤⎦⎥ σd=σd⋅[1−xi,d⋅σd2xiTΣxi+β2ω(Yi⋅xiTμxiTΣx+β2)] FTRL 除了Online Bayesian Learning，还有一种做法就是FTRL（Follow The Regularized Leader）。 FTRL的网上资料很多，但是大部分介绍怎么样产生稀疏化解，而往往忽略了FTRL的基本原理。顾名思义，FTRL和稀疏化并没有关系，它只是一种做Online Learning的思想。 先说说FTL（Follow The Leader）算法，FTL思想就是每次找到让之前所有损失函数之和最小的参数。流程如下： 初始化 ww for t = 1 … n 损失函数 ftft 更新 w=argminw∑i=1tfi(w) w=argminw∑i=1tfi(w) FTRL算法就是在FTL的优化目标的基础上，加入了正规化，防止过拟合： w=argminw∑i=1tfi(w)+R(w) w=argminw∑i=1tfi(w)+R(w) 其中，R(w)R(w)是正规化项。 FTRL算法的损失函数，一般也不是能够很快求解的，这种情况下，一般需要找一个代理的损失函数。 代理损失函数需要满足几个要求： 代理损失函数比较容易求解，最好是有解析解 优化代理损失函数求的解，和优化原函数得到的解差距不能太大 为了衡量条件2中的两个解的差距，这里需要引入regret的概念。 假设每一步用的代理函数是ht(w)ht(w) 每次取 wt=argminwht−1(w) wt=argminwht−1(w) Regrett=∑t=1Tft(wt)−∑t=1Tft(w∗) Regrett=∑t=1Tft(wt)−∑t=1Tft(w∗) 其中w∗=argminw∑ti=1fi(w)w∗=argminw∑i=1tfi(w)，是原函数的最优解。就是我们每次代理函数求出解，离真正损失函数求出解的损失差距。当然这个损失必须满足一定的条件，Online Learning才可以有效，就是： limt→∞Regrettt=0 limt→∞Regrettt=0 随着训练样本的增多，这两个优化目标优化出的参数的实际损失值差距越来越小。 代理函数 ht(w)ht(w) 应该该怎么选呢？ 如果ft(w)ft(w) 是凸函数，我们可以用下面的代理损失函数： ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2 ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2 其中gigi 是fi(wi)fi(wi)次梯度（如果 fi(wi)fi(wi)是可导的，次梯度就是梯度）。ηtηt满足： ηt=α∑ti=1g2t−−−−−−−√ ηt=α∑i=1tgt2 为了产生稀疏的效果，我们也可以加入l1正规化： ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2＋λ1|w| ht=∑i=1tgi⋅w+∑i=1t(12ηt−12ηt−1)||w−wt||2＋λ1|w| 只要ft(w)ft(w) 是凸函数，上面的代理函数一定满足： limt→∞Regrettt=0 limt→∞Regrettt=0 上面的式子我们可以得出ww的解析解： wt+1,i={0−ηt(zt,i−sgn(zt,i)λ1))|zt,i|&lt;λ1otherwise wt+1,i={0|zt,i|&lt;λ1−ηt(zt,i−sgn(zt,i)λ1))otherwise 其中 zt,i=∑s=1tgs,i+∑s=1t(1ηt,i−1ηt−1,i)wt,i zt,i=∑s=1tgs,i+∑s=1t(1ηt,i−1ηt−1,i)wt,i 可以得到FTRL的更新流程如下： 输入αα, λ1λ1 初始化 w1…Nw1…N, z1..N=0z1..N=0 , n1..N=0n1..N=0 for t = 1 … T 损失函数 ftft for i = 1 ..N 计算 gt,i=∂fi(wt−1)wt−1,i gt,i=∂fi(wt−1)wt−1,i zt+=gt,i+1α(ni+g2t,i−−−−−−−√−ni−−√)wt,i zt+=gt,i+1α(ni+gt,i2−ni)wt,i ni+=g2t,i ni+=gt,i2 更新 wt+1,i={0−ηt(zt,i−sgn(zt,i)λ1))|zt,i|&lt;λ1otherwise wt+1,i={0|zt,i|&lt;λ1−ηt(zt,i−sgn(zt,i)λ1))otherwise Online Learning实践 前面讲了Online Learning的基本原理，这里以移动端推荐重排序为例，介绍一下Online Learning在实际中的应用。 推荐重排序介绍 目前的推荐系统，主要采用了两层架构，首先是触发层，会根据上下文条件和用户的历史行为，触发用户可能感兴趣的item，然后由排序模型对触发的item排序，如下图所示： 推荐重排序既能融合不同触发策略，又能较大幅度提高推荐效果（我们这里主要是下单率）。在移动端，屏幕更加小，用户每次看到的item数目更加少，排序的作用更加突出。 美团重排序Online Learning架构 美团Online Learning架构如下图所示： 线上的展示日志，点击日志和下单日志会写入不同的Kafka流。读取Kafka流，以HBase为中间缓存，完成label match（下单和点击对映到相应的展示日志），在做label match的过成中，会对把同一个session的日志放在一起，方便后面做skip above： 训练数据生成 移动端推荐的数据跟PC端不同，移动端一次会加载很多item，但是无法保证这些item会被用户看到。为了保证数据的准确性，我们采用了skip above的办法，如下图所示： 假设用户点击了第i个位置，我们保留从第1条到第i+2条数据作为训练数据，其他的丢弃。这样能够最大程度的保证训练样本中的数据是被用户看到的。 特征 用的特征如下图所示： 算法选择 我们尝试了FTRL和BPR效果，线下实验效果如下表： 算法 AUC 模型参数个数 FTRL 0.8432 200W BPR 0.8441 1500W BPR的效果略好，但是我们线上选用了FTRL模型，主要原因是FTRL能够产生稀疏化的效果，训练出的模型会比较小。 模型训练 训练算法不断地从HBase中读取数据，完成模型地训练，训练模型放在Medis（美团内部地Redis）中，线上会用Medis中的模型预测下单率，根据预测的下单率，完成排序。 线上效果 上线后，最终的效果如下图所示，和base算法相比，下单率提高了5%。 参考资料 [1] McMahan H B, Holt G, Sculley D, et al. Ad Click Prediction: a View from the Trenches. Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 2013. [2] Graepel T, Candela J Q, Borchert T,et al. Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine. Proceedings of the 27th International Conference on Machine Learning ICML. 2010. [3] Murphy K P. Machine Learning: A Probabilistic Perspective. The MIT Press. 2012. 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫： 公众号二维码","comments":true,"categories":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/categories/AI/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"外卖排序系统特征生产框架","date":"2017-02-26T14:04:06.000Z","path":"2017/02/26/BusinessAI/framework-of-get-features-in-meituan/","text":"海文 背景外卖的排序策略是由机器学习模型驱动的，模型迭代效率制约着策略优化效果。如上图所示，在排序系统里，特征是最为基础的部分：有了特征之后，我们离线训练出模型，然后将特征和模型一起推送给线上排序服务使用。特征生产Pipeline对于策略迭代的效率起着至关重要的作用。经过实践中的积累和提炼，我们整理出一套通用的特征生产框架，大大节省开发量，提高策略迭代效率。 外卖排序系统使用GBDT（Gradient Boosting Decision Tree）树模型，比较复杂。受限于计算能力，除了上下文特征（如时间、地域、终端类型、距离等）之外，目前使用的主要是一些宽泛的统计特征，比如商家销量、商家单均价、用户的品类偏好等。这些特征的生产流程包括：离线的统计、离线到在线的同步、在线的加载等。 图2 特征生产流程 如上图，目前外卖排序的特征生产流程主要有： 特征统计：基于基础数据表（如曝光表、点击表、订单表等），统计若干时段内特定维度的总量、分布等，如商家月均销量、用户不同品类下单占比。统计结果存储于Hive表。这部分工作，简单的可基于ETL，复杂的可基于Spark。产出的特征可供离线训练和线上预测，本文主要围绕线上展开。 特征推送：Hive表里的数据需要存入KV，以便线上实时使用。这一步，首先要将Hive表里的记录映射成POJO类（称为Domain类），然后将其序列化，最后将序列化串存入KV。这部分工作比较单一，基于MapReduce实现。 特征获取：在线服务根据需求，从KV中取出数据，并反序列化为Domain对象。 特征加载：针对模型所需特征列表，取得对应的Domain对象。这步通过调用特征获取实现。 前两步为离线操作，后两步为在线操作。特征同步由离线推送和在线获取共同完成。离线生产流程是一个周期性的Pipeline，目前是以天为周期。 为此，我们设计了一套通用的框架，基于此框架，只需要简单的配置和少量代码开发，就可以新增一组特征。下文将详细介绍框架的各个部分。 特征统计 排序模型用到的特征大部分是统计特征。有些特征比较简单，如商家的月均销量、商家单均价等，可用ETL统计(GROUP BY + SUM/AVG)；有些特征稍微复杂，如用户的品类偏好（在不同品类上的占比）、用户的下单额分布（不同金额区段的占比），用ETL就比较繁琐。针对后一种情况，我们开发了一套Spark程序来统计。我们发现，这种统计需求可以规约成一种范式：针对某些统计对象（用户、商家）的一些维度（品类、下单额），基于某些度量值（点击、下单）做统计（比例/总和）。 同一对象，可统计不同维度；同一维度，有不同的度量角度；同一度量角度，有不同的统计方式。如下图： 图3 特征统计范式 例如，对于用户点击品类偏好、用户下单品类偏好、用户下单额分布、用户下单总额等特征，可做范式分解： 图4 特征统计范式示例 其中， 统计对象、统计维度、度量值对应于Hive表中的字段（维度一般来自维度表，度量值一般来自事实表，主要是曝光、点击、下单）。为了增加灵活性，我们还允许对原始Hive字段做加工，加工后的值作为统计维度、度量值（加工的接口我们分别称为维度算子和度量算子）。 统计量基于度量值做的一些聚合操作，如累加、求均值、拼接、求占比、算分位点（分布）。前两者输出一个数值，后三者输出形如”Key1:Value1,Key2:Value2”的KeyValue列表。 另外，统计通常是在一定时间窗口内进行的，由于不同时期的数据价值不同（新数据比老数据更有价值），我们引入了时间衰减，对老数据降权。 基于以上考虑，整个统计流程可以分解为（基于Spark）： 图5 特征统计流程 按统计对象字段做聚合（GROUP BY）。统计对象字段由配置给定。对于外卖排序主要为uuid、poi_id。这一步可能会有数据倾斜，需要更多优化。 计算维度。支持维度算子，可以对原始维度字段做处理，如对金额字段做分段处理，以分段后的金额作为维度。 按统计维度聚合（GROUP BY）。这是在对象聚合的基础上做的二次聚合。维度字段由配置给定，可以有多个字段，表示交叉特征统计，如不同时段的品类偏好，维度字段为：时段、品类。 时间衰减并累加。衰减各个时间的度量值，并把所有时间的度量值累加，作为加权后的度量值。时间字段和度量字段由配置给定。时间字段主要为日期，度量字段主要为曝光、点击、下单。经过维度聚合后，度量值都在特定维度值对应的记录集上做累加，每个维度对应一个度量值，维度和度量值是一个KeyValue的映射关系。 计算度量值。度量字段也可以通过度量算子做进一步处理，算子得到的结果作为度量值。也可以有多个字段，如点击和曝光字段，配合除法算子，可以得到点击率作为度量值。 计算统计量。经过对象和维度聚合后，对象、维度、度量值建立了二级映射关系：对象维度度量值，相当于一个二维Map：Map&lt;对象, Map&lt;维度, 度量值&gt;&gt;。统计量是对Map&lt;维度, 度量值&gt;做一个聚合操作。每个统计量对应输出Hive表中的一个字段。现在主要支持如下几种算子： 累加：对该维度的所有度量值求和； 求均值：该维度所有取值情况对应的度量值的均值； 拼接：把Map&lt;维度, 度量值&gt;序列化为”Key1:Value1, Key2:Value2”形式，以便以字符串的形式存储于一个输出字段内。为了防止序列化串太长，可通过配置设定只保留度量值最大的top N； 求占比：该维度所有取值情况对应的度量值占度量值总和的比重，即Map&lt;维度, 度量值/Sum(度量值)&gt;。然后再做拼接输出； 算分位点：有时候想直到某些维度的分布情况，比如用户下单金额的分布以考察用户的消费能力。分位点可以作为分布的一种简单而有效的表示方法。该算子输出每个分位点的维度值，形如”分位点1:维度值1, 分位点2:维度值2”。此时，度量值只是用来算比值。 维度算子、度量算子、统计算子都可以通过扩展接口的方式实现自定义。 如下是统计用户点击品类偏好、用户下单品类偏好、用户下单额分布的配置文件和Hive表示例([Toml][1]格式) 图6 特征统计配置示例 相对于ETL，这套Spark统计框架更为简单清晰，还可以同时统计多个相关的特征。通过简单的配置就可以实现特征的统计，开发量比较小。 特征同步 离线统计得到的特征存储在Hive表中，出于性能的考虑，不能在线上直接访问。我们需要把特征从Hive中推送到更为高效的KV数据库中，线上服务再从KV中获取。整个同步过程可以分为如下步骤： 图7 特征推送流程 ORM：将Hive表中的每行记录映射为Domain对象（类似于[Hibernate][2]的功能） 序列化：将Domain对象序列化，然后存储到KV中。一个Domain类包含一组相关的、可同时在一个任务中统计的特征数据。每个Domain对象都有一个key值来作为自己唯一的标志—实现key()接口。同时，由于不同类型的Domain都会存储在一起，我们还需要为每种类型的Domain设定一个Key值前缀prefix以示区别。因此，KV中的Key是Domain.prefix + Domain.key，Value是序列化串。我们支持json和protostuff两种序列化方式。 反序列化：在线服务根据key和Domain.prefix从KV中得到序列化串，并反序列化为Domain对象。 前两步为离线操作，第三步为在线操作（在预测代码中被调用）。 我们针对Hive开发了一套ORM库（见图8），主要基于Java反射，除了支持基本类型(int/long/float/double/String等)，还支持POJO类型和集合类型(List/Map)。因为ETL不支持json拼接，为了兼容基于ETL统计的特征数据，我们的POJO以及集合类型是基于自定义的规范做编解码。针对Spark统计的特征数据，后续我们可以支持json格式的编解码。 图8 Hive ORM示意 特征序列化和反序列我们统一封装为通用的KvService：负责序列化与反序列，以及读写KV。如下图： 图9 KvService 对于新特征，只需要定义一个Domain类，并实现接口key()即可，KvService自动完成Key值的拼接（以Domain的类名作为Key的prefix），序列化和反序列化，读写KV。 我们通过周期性的离线MapReduce任务，读取Hive表的记录，并调用KvService的put接口，将特征数据推送到KV中。由于KvService能够统一处理各种Domain类型，MapReduce任务也是通用的，无需为每个特征单独开发。 对于特征同步，只需要开发Domain类，并做少量配置，开发量也很小。目前，我们为了代码的可读性，采用Domain这种强类型的方式来定义特征，如果可以弱化这种需求的话，还可以做更多的框架优化，省去Domain类开发这部分工作。 特征加载 通过前面几步，我们已经准备好特征数据，并存储于KV中。线上有诸多模型在运行，不同模型需要不同的特征数据。特征加载这一步主要解决怎么高效便捷地为模型提供相应的特征数据。 离线得到的只是一些原始特征，在线还可能需要基于原始特征做更多的处理，得到高阶特征。比如离线得到了商家和用户的下单金额分布，在线我们可能需要基于这两个分布计算一个匹配度，以表征该商家是否在用户消费能力的承受范围之内。 我们把在线特征抽象为一个特征算子：FeatureOperator。类似的，一个特征算子包含了一组相关的在线特征，且可能依赖一组相关的离线特征。它除了封装了在线特征的计算过程，还通过两个Java Annotation声明该特征算子产出的特征清单(@Features)和所需要的数据清单(@Fetchers)。所有的数据获取都是由DataFetcher调用KvService的get接口实现，拿到的Domain对象统一存储在DataPortal对象中以便后续使用。 服务启动时，会自动扫描所有的FeatureOperator的Annotation（@Features、@Fetchers），拿到对应的特征清单和数据清单，从而建立起映射关系：FeatureFeatureOperatorDataFetcher。而每个模型通过配置文件给定其所需要的特征清单，这样就建立起模型到特征的映射关系（如图9）： Model → Feature → FeatureOperator → DataFetcher 不同的在线特征可能会依赖相同的离线特征，也就是FeatureOperatorDataFetcher是多对多的关系。为了避免重复从KV读取相同的数据以造成性能浪费，离线特征的获取和在线特征的抽取被划分成两步：先汇总所有离线特征需求，统一获取离线特征；得到离线特征后，再进行在线特征的抽取。这样，我们也可以在离线特征加载阶段采用并发以减少网络IO延时。整个流程如图10所示： 图10 模型和特征数据的映射关系 图11 特征加载流程 对于新特征，我们需要实现对应的FeatureOperator、DataFetcher。DataFetcher主要封装了Domain和DataPortal的关系。类似的，如果我们不需要以强类型的方式来保证代码的业务可读性，也可以通过优化框架省去DataFetcher和DataPortal的定制开发。 总结 我们在合理抽象特征生产过程的各个环节后，设计了一套较为通用的框架，只需要少量的代码开发（主要是自定义一些算子）以及一些配置，就可以很方便地生产一组特征，有效地提高了策略迭代效率。 参考文献 TOML. Hibernate ORM. 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫： 公众号二维码","comments":true,"categories":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/categories/AI/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"深度学习在美团点评的应用","date":"2017-02-26T13:56:06.000Z","path":"2017/02/26/BusinessAI/deep-learning-in-meituan/","text":"文竹 李彪 晓明 前言近年来，深度学习在语音、图像、自然语言处理等领域取得非常突出的成果，成了最引人注目的技术热点之一。美团点评这两年在深度学习方面也进行了一些探索，其中在自然语言处理领域，我们将深度学习技术应用于文本分析、语义匹配、搜索引擎的排序模型等；在计算机视觉领域，我们将其应用于文字识别、目标检测、图像分类、图像质量排序等。下面我们就以语义匹配、图像质量排序及文字识别这三个应用场景为例，来详细介绍美团点评在深度学习技术及应用方面的经验和方法论。 基于深度学习的语义匹配 语义匹配技术，在信息检索、搜索引擎中有着重要的地位，在结果召回、精准排序等环节发挥着重要作用。 传统意义上讲的语义匹配技术，更加注重文字层面的语义吻合程度，我们暂且称之为语言层的语义匹配；而在美团点评这样典型的O2O应用场景下，我们的结果呈现除了和用户表达的语言层语义强相关之外，还和用户意图、用户状态强相关。 用户意图即用户是来干什么的？比如用户在百度上搜索“关内关外”，他的意图可能是想知道关内和关外代表的地理区域范围，“关内”和“关外”被作为两个词进行检索，而在美团上搜索“关内关外”，用户想找的就是“关内关外”这家饭店，“关内关外”被作为一个词来对待。 再说用户状态，一个在北京和另一个在武汉的用户，在百度或淘宝上搜索任何一个词条，可能得到的结果不会差太多；但是在美团这样与地理位置强相关的场景下就会完全不一样。比如我在武汉搜“黄鹤楼”，用户找的可能是景点门票，而在北京搜索“黄鹤楼”，用户找的很可能是一家饭店。 如何结合语言层信息和用户意图、状态来做语义匹配呢？ 我们的思路是在短文本外引入部分O2O业务场景特征，融合到所设计的深度学习语义匹配框架中，通过点击/下单数据来指引语义匹配模型的优化方向，最终把训练出的点击相关性模型应用到搜索相关业务中。下图是针对美团点评场景设计的点击相似度框架ClickNet，是比较轻量级的模型，兼顾了效果和性能两方面，能很好地推广到线上应用。 图1 clicknet框架 表示层 对Query和商家名分别用语义和业务特征表示，其中语义特征是核心，通过DNN/CNN/RNN/LSTM/GRU方法得到短文本的整体向量表示，另外会引入业务相关特征，比如用户或商家的相关信息，比如用户和商家距离、商家评价等，最终结合起来往上传。 学习层 通过多层全连接和非线性变化后，预测匹配得分，根据得分和Label来调整网络以学习出Query和商家名的点击匹配关系。 在该算法框架上要训练效果很好的语义模型，还需要根据场景做模型调优：首先，我们从训练语料做很多优化，比如考虑样本不均衡、样本重要度、位置Bias等方面问题。其次，在模型参数调优时，考虑不同的优化算法、网络大小层次、超参数的调整等问题。经过模型训练优化，我们的语义匹配模型已经在美团点评平台搜索、广告、酒店、旅游等召回和排序系统中上线，有效提升了访购率/收入/点击率等指标。 小结 深度学习应用在语义匹配上，需要针对业务场景设计合适的算法框架，此外，深度学习算法虽然减少了特征工程工作，但模型调优上难度会增加，因此可以从框架设计、业务语料处理、模型参数调优三方面综合起来考虑，实现一个效果和性能兼优的模型。 基于深度学习的图像质量排序 国内外各大互联网公司（比如腾讯、阿里和Yelp）的线上广告业务都在关注展示什么样的图像能吸引更多点击。在美团点评，商家的首图是由商家或运营人工指定的，如何选择首图才能更好地吸引用户呢？图像质量排序算法目标就是做到自动选择更优质的首图，以吸引用户点击。 传统的图像质量排序方法主要从美学角度进行质量评价，通过颜色统计、主体分布、构图等来分析图片的美感。但在实际业务场景中，用户对图片质量优劣的判断主观性很强，难以形成统一的评价标准。比如: 有的用户对清晰度或分辨率更敏感； 有的用户对色彩或构图更敏感； 有的用户偏爱有视觉冲击力的内容而非平淡无奇的环境图。 因此我们使用深度学习方法，去挖掘图片的哪些属性会影响用户的判断，以及如何有效融合这些属性对图片进行评价。 我们使用AlexNet去提取图片的高层语义描述，学习美感、可记忆度、吸引度、品类等High Level特征，并补充人工设计的Low Level特征（比如色彩、锐度、对比度、角点）。在获得这些特征后，训练一个浅层神经网络对图像整体打分。该框架（如图2所示）的一个特点是联合了深度学习特征与传统特征，既引入高层语义又保留了低层通用描述，既包括全局特征又有局部特征。 图2 图像质量排序技术框架 对于每个维度图片属性的学习，都需要大量的标签数据来支撑，但完全通过人工标记代价极大，因此我们借鉴了美团点评的图片来源和POI标签体系。关于吸引度属性的学习，我们选取了美团Deal相册中点击率高的图片（多数是摄影师通过单反相机拍摄）作为正例，而选取UGC相册中点击率低的图片（多数是低端手机拍摄）作为负例。关于品类属性的学习，我们将美团一级品类和常见二级品类作为图片标签。基于上述质量排序模型，我们为广告POI挑选最合适的优质首图进行展示，起到吸引用户点击，提高业务指标的目的。图3给出了基于质量排序的首图优选结果。 图3 基于图像质量排序的首图优选 基于深度学习的OCR 为了提升用户体验，O2O产品对OCR技术的需求已渗透到上单、支付、配送和用户评价等环节。OCR在美团点评业务中主要起着两方面作用。一方面是辅助录入，比如在移动支付环节通过对银行卡卡号的拍照识别，以实现自动绑卡，又如辅助BD录入菜单中菜品信息。另一方面是审核校验，比如在商家资质审核环节对商家上传的身份证、营业执照和餐饮许可证等证件照片进行信息提取和核验以确保该商家的合法性，比如机器过滤商家上单和用户评价环节产生的包含违禁词的图片。相比于传统OCR场景（印刷体、扫描文档），美团的OCR场景主要是针对手机拍摄的照片进行文字信息提取和识别，考虑到线下用户的多样性，因此主要面临以下挑战： 成像复杂：噪声、模糊、光线变化、形变； 文字复杂：字体、字号、色彩、磨损、笔画宽度不固定、方向任意； 背景复杂：版面缺失，背景干扰。 对于上述挑战，传统的OCR解决方案存在着以下不足： 通过版面分析（二值化，连通域分析）来生成文本行，要求版面结构有较强的规则性且前背景可分性强（例如文档图像、车牌），无法处理前背景复杂的随意文字（例如场景文字、菜单、广告文字等）。 通过人工设计边缘方向特征（例如HOG）来训练字符识别模型，此类单一的特征在字体变化，模糊或背景干扰时泛化能力迅速下降。 过度依赖字符切分的结果，在字符扭曲、粘连、噪声干扰的情况下，切分的错误传播尤其突出。 针对传统OCR解决方案的不足，我们尝试基于深度学习的OCR。 基于Faster R-CNN和FCN的文字定位首先，我们根据是否有先验信息将版面划分为受控场景（例如身份证、营业执照、银行卡）和非受控场景（例如菜单、门头图）。 对于受控场景，我们将文字定位转换为对特定关键字目标的检测问题。主要利用Faster R-CNN进行检测，如下图所示。为了保证回归框的定位精度同时提升运算速度，我们对原有框架和训练方式进行了微调: 考虑到关键字目标的类内变化有限，我们裁剪了ZF模型的网络结构，将5层卷积减少到3层。训练过程中提高正样本的重叠率阈值，并根据业务需求来适配RPN层Anchor的宽高比。图4 基于Faster R-CNN的受控场景文字定位 对于非受控场景，由于文字方向和笔画宽度任意变化，目标检测中回归框的定位粒度不够，我们利用语义分割中常用的全卷积网络（FCN）来进行像素级别的文字/背景标注，如下图所示。为了同时保证定位的精度和语义的清晰，我们不仅在最后一层进行反卷积，而且融合了深层Layer和浅层Layer的反卷积结果图5 基于FCN的非受控场景文字定位 基于序列学习框架的文字识别为了有效控制字符切分和识别后处理的错误传播效应，实现端到端文字识别的可训练性，我们采用如下图所示的序列学习框架。框架整体分为三层：卷积层，递归层和翻译层。其中卷积层提特征，递归层既学习特征序列中字符特征的先后关系，又学习字符的先后关系，翻译层实现对时间序列分类结果的解码。图6 基于序列学习的端到端识别框架 由于序列学习框架对训练样本的数量和分布要求较高，我们采用了真实样本+合成样本的方式。真实样本以美团点评业务来源（例如菜单、身份证、营业执照）为主，合成样本则考虑了字体、形变、模糊、噪声、背景等因素。基于上述序列学习框架和训练数据，在多种场景的文字识别上都有较大幅度的性能提升，如下图所示。图7 深度学习OCR和传统OCR的性能比较 总结本文主要以深度学习在自然语言处理、图像处理两个领域的应用为例进行了介绍，但深度学习在美团点评可能发挥的价值远远不限于此。未来，我们将继续在各个场景深入挖掘，比如在智能交互、配送调度、智能运营等，在美团点评产品的智能化道路上贡献一份力量。 作者简介文竹，美团点评美团平台与酒旅事业群智能技术中心负责人，2010年从清华硕士毕业后，加入百度，先后从事机器翻译的研发及多个技术团队的管理工作。2015年4月加入美团，负责智能技术中心的管理工作，致力于推动自然语言处理、图像处理、机器学习、用户画像等技术在公司业务上的落地。 李彪，美团点评美团平台及酒旅事业群NLP技术负责人，曾就职搜狗、百度。2015年加入美团点评，致力于NLP技术积累和业务的落地，负责的工作包括深度学习平台和模型，文本分析在搜索、广告、推荐等业务上应用，智能客服和交互。 晓明，美团点评平台及酒旅事业群图像技术负责人，曾就职于三星研究院。2015年加入美团点评，主要致力于图像识别技术的积累和业务落地，作为技术负责人主导了图像机审、首图优选和OCR等项目的上线，推进了美团产品的智能化体验和人力成本的节省。 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫： 公众号二维码","comments":true,"categories":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/categories/AI/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"美团Android DEX自动拆包及动态加载简介","date":"2017-02-26T13:31:05.000Z","path":"2017/02/26/Program/Android/dynamic-load-android-dex-from-meituan/","text":"美团Android DEX自动拆包及动态加载简介jianshuai xiaoyang ·2015-06-15 10:00 概述 作为一个android开发者，在开发应用时，随着业务规模发展到一定程度，不断地加入新功能、添加新的类库，代码在急剧的膨胀，相应的apk包的大小也急剧增加， 那么终有一天，你会不幸遇到这个错误： 生成的apk在android 2.3或之前的机器上无法安装，提示INSTALL_FAILED_DEXOPT方法数量过多，编译时出错，提示： Conversion to Dalvik format failed:Unable to execute dex: method ID not in [0, 0xffff]: 65536 而问题产生的具体原因如下： 无法安装（Android 2.3 INSTALL_FAILED_DEXOPT）问题，是由dexopt的LinearAlloc限制引起的，在Android版本不同分别经历了4M/5M/8M/16M限制，目前主流4.2.x系统上可能都已到16M， 在Gingerbread或者以下系统LinearAllocHdr分配空间只有5M大小的， 高于Gingerbread的系统提升到了8M。Dalvik linearAlloc是一个固定大小的缓冲区。在应用的安装过程中，系统会运行一个名为dexopt的程序为该应用在当前机型中运行做准备。dexopt使用LinearAlloc来存储应用的方法信息。Android 2.2和2.3的缓冲区只有5MB，Android 4.x提高到了8MB或16MB。当方法数量过多导致超出缓冲区大小时，会造成dexopt崩溃。 超过最大方法数限制的问题，是由于DEX文件格式限制，一个DEX文件中method个数采用使用原生类型short来索引文件中的方法，也就是4个字节共计最多表达65536个method，field/class的个数也均有此限制。对于DEX文件，则是将工程所需全部class文件合并且压缩到一个DEX文件期间，也就是Android打包的DEX过程中， 单个DEX文件可被引用的方法总数（自己开发的代码以及所引用的Android框架、类库的代码）被限制为65536； 插件化？ MultiDex？解决这个问题，一般有下面几种方案，一种方案是加大Proguard的力度来减小DEX的大小和方法数，但这是治标不治本的方案，随着业务代码的添加，方法数终究会到达这个限制，一种比较流行的方案是插件化方案，另外一种是采用google提供的MultiDex方案，以及google在推出MultiDex之前Android Developers博客介绍的通过自定义类加载过程， 再就是Facebook推出的为Android应用开发的Dalvik补丁， 但facebook博客里写的不是很详细；我们在插件化方案上也做了探索和尝试，发现部署插件化方案，首先需要梳理和修改各个业务线的代码，使之解耦，改动的面和量比较巨大，通过一定的探讨和分析，我们认为对我们目前来说采用MultiDex方案更靠谱一些，这样我们可以快速和简洁的对代码进行拆分，同时代码改动也在可以接受的范围内； 这样我们采用了google提供的MultiDex方式进行了开发。 插件化方案在业内有不同的实现原理，这里不再一一列举，这里只列举下Google为构建超过65K方法数的应用提供官方支持的方案：MultiDex。 首先使用Android SDK Manager升级到最新的Android SDK Build Tools和Android Support Library。然后进行以下两步操作： 1.修改Gradle配置文件，启用MultiDex并包含MultiDex支持： android { compileSdkVersion 21 buildToolsVersion “21.1.0” defaultConfig { ... minSdkVersion 14 targetSdkVersion 21 ... // Enabling MultiDex support. MultiDexEnabled true } ... } dependencies { compile &apos;com.android.support:MultiDex:1.0.0&apos; }2.让应用支持多DEX文件。在官方文档中描述了三种可选方法： 在AndroidManifest.xml的application中声明android.support.MultiDex.MultiDexApplication；如果你已经有自己的Application类，让其继承MultiDexApplication；如果你的Application类已经继承自其它类，你不想/能修改它，那么可以重写attachBaseContext()方法： @Overrideprotected void attachBaseContext(Context base) { super.attachBaseContext(base); MultiDex.install(this);}并在Manifest中添加以下声明： &lt;?xml version=”1.0” encoding=”utf-8”?&gt; … 如果已经有自己的Application，则让其继承MultiDexApplication即可. Dex自动拆包及动态加载MultiDex带来的问题在第一版本采用MultiDex方案上线后，在Dalvik下MultiDex带来了下列几个问题： 在冷启动时因为需要安装DEX文件，如果DEX文件过大时，处理时间过长，很容易引发ANR（Application Not Responding）；采用MultiDex方案的应用可能不能在低于Android 4.0 (API level 14) 机器上启动，这个主要是因为Dalvik linearAlloc的一个bug (Issue 22586);采用MultiDex方案的应用因为需要申请一个很大的内存，在运行时可能导致程序的崩溃，这个主要是因为Dalvik linearAlloc 的一个限制(Issue 78035). 这个限制在 Android 4.0 (API level 14)已经增加了, 应用也有可能在低于 Android 5.0 (API level 21)版本的机器上触发这个限制；而在ART下MultiDex是不存在这个问题的，这主要是因为ART下采用Ahead-of-time (AOT) compilation技术，系统在APK的安装过程中会使用自带的dex2oat工具对APK中可用的DEX文件进行编译并生成一个可在本地机器上运行的文件，这样能提高应用的启动速度，因为是在安装过程中进行了处理这样会影响应用的安装速度，对ART感兴趣的可以参考一下ART和Dalvik的区别. MultiDex的基本原理是把通过DexFile来加载Secondary DEX，并存放在BaseDexClassLoader的DexPathList中。 下面代码片段是BaseDexClassLoader findClass的过程:123456789101112protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; List&lt;Throwable&gt; suppressedExceptions = new ArrayList&lt;Throwable&gt;(); Class c = pathList.findClass(name, suppressedExceptions); if (c == null) &#123; ClassNotFoundException cnfe = new ClassNotFoundException(\"Didn't find class \\\"\" + name + \"\\\" on path: \" + pathList); for (Throwable t : suppressedExceptions) &#123; cnfe.addSuppressed(t); &#125; throw cnfe; &#125; return c;&#125; 下面代码片段为怎么通过DexFile来加载Secondary DEX并放到BaseDexClassLoader的DexPathList中: 1234567891011121314151617181920212223242526272829303132333435363738394041424344private static void install(ClassLoader loader, List&lt;File&gt; additionalClassPathEntries, File optimizedDirectory) throws IllegalArgumentException, IllegalAccessException, NoSuchFieldException, InvocationTargetException, NoSuchMethodException &#123; /* The patched class loader is expected to be a descendant of * dalvik.system.BaseDexClassLoader. We modify its * dalvik.system.DexPathList pathList field to append additional DEX * file entries. */ Field pathListField = findField(loader, \"pathList\"); Object dexPathList = pathListField.get(loader); ArrayList&lt;IOException&gt; suppressedExceptions = new ArrayList&lt;IOException&gt;(); expandFieldArray(dexPathList, \"dexElements\", makeDexElements(dexPathList, new ArrayList&lt;File&gt;(additionalClassPathEntries), optimizedDirectory, suppressedExceptions)); try &#123; if (suppressedExceptions.size() &gt; 0) &#123; for (IOException e : suppressedExceptions) &#123; //Log.w(TAG, \"Exception in makeDexElement\", e); &#125; Field suppressedExceptionsField = findField(loader, \"dexElementsSuppressedExceptions\"); IOException[] dexElementsSuppressedExceptions = (IOException[]) suppressedExceptionsField.get(loader); if (dexElementsSuppressedExceptions == null) &#123; dexElementsSuppressedExceptions = suppressedExceptions.toArray( new IOException[suppressedExceptions.size()]); &#125; else &#123; IOException[] combined = new IOException[suppressedExceptions.size() + dexElementsSuppressedExceptions.length]; suppressedExceptions.toArray(combined); System.arraycopy(dexElementsSuppressedExceptions, 0, combined, suppressedExceptions.size(), dexElementsSuppressedExceptions.length); dexElementsSuppressedExceptions = combined; &#125; suppressedExceptionsField.set(loader, dexElementsSuppressedExceptions); &#125; &#125; catch(Exception e) &#123; &#125;&#125; Dex自动拆包及动态加载方案简介通过查看MultiDex的源码，我们发现MultiDex在冷启动时容易导致ANR的瓶颈， 在2.1版本之前的Dalvik的VM版本中， MultiDex的安装大概分为几步，第一步打开apk这个zip包，第二步把MultiDex的dex解压出来（除去Classes.dex之外的其他DEX，例如：classes2.dex， classes3.dex等等)，因为android系统在启动app时只加载了第一个Classes.dex，其他的DEX需要我们人工进行安装，第三步通过反射进行安装，这三步其实都比较耗时， 为了解决这个问题我们考虑是否可以把DEX的加载放到一个异步线程中，这样冷启动速度能提高不少，同时能够减少冷启动过程中的ANR，对于Dalvik linearAlloc的一个缺陷(Issue 22586)和限制(Issue 78035)，我们考虑是否可以人工对DEX的拆分进行干预，使每个DEX的大小在一定的合理范围内，这样就减少触发Dalvik linearAlloc的缺陷和限制； 为了实现这几个目的，我们需要解决下面三个问题： 在打包过程中如何产生多个的DEX包？如果做到动态加载，怎么决定哪些DEX动态加载呢？如果启动后在工作线程中做动态加载，如果没有加载完而用户进行页面操作需要使用到动态加载DEX中的class怎么办？我们首先来分析如何解决第一个问题，在使用MultiDex方案时，我们知道BuildTool会自动把代码进行拆成多个DEX包，并且可以通过配置文件来控制哪些代码放到第一个DEX包中， 下图是Android的打包流程示意图： 为了实现产生多个DEX包，我们可以在生成DEX文件的这一步中， 在Ant或gradle中自定义一个Task来干预DEX产生的过程，从而产生多个DEX，下图是在ant和gradle中干预产生DEX的自定task的截图:1234567891011121314151617tasks.whenTaskAdded &#123; task -&gt; if (task.name.startsWith('proguard') &amp;&amp; (task.name.endsWith('Debug') || task.name.endsWith('Release'))) &#123; task.doLast &#123; makeDexFileAfterProguardJar(); &#125; task.doFirst &#123; delete \"$&#123;project.buildDir&#125;/intermediates/classes-proguard\"; String flavor = task.name.substring('proguard'.length(), task.name.lastIndexOf(task.name.endsWith('Debug') ? \"Debug\" : \"Release\")); generateMainIndexKeepList(flavor.toLowerCase()); &#125; &#125; else if (task.name.startsWith('zipalign') &amp;&amp; (task.name.endsWith('Debug') || task.name.endsWith('Release'))) &#123; task.doFirst &#123; ensureMultiDexInApk(); &#125; &#125;&#125; 上一步解决了如何打包出多个DEX的问题了，那我们该怎么该根据什么来决定哪些class放到Main DEX，哪些放到Secondary DEX呢（这里的Main DEX是指在2.1版本的Dalvik VM之前由android系统在启动apk时自己主动加载的Classes.dex，而Secondary DEX是指需要我们自己安装进去的DEX，例如：Classes2.dex, Classes3.dex等）， 这个需要分析出放到Main DEX中的class依赖，需要确保把Main DEX中class所有的依赖都要放进来，否则在启动时会发生ClassNotFoundException, 这里我们的方案是把Service、Receiver、Provider涉及到的代码都放到Main DEX中，而把Activity涉及到的代码进行了一定的拆分，把首页Activity、Laucher Activity、欢迎页的Activity、城市列表页Activity等所依赖的class放到了Main DEX中，把二级、三级页面的Activity以及业务频道的代码放到了Secondary DEX中，为了减少人工分析class的依赖所带了的不可维护性和高风险性，我们编写了一个能够自动分析Class依赖的脚本， 从而能够保证Main DEX包含class以及他们所依赖的所有class都在其内，这样这个脚本就会在打包之前自动分析出启动到Main DEX所涉及的所有代码，保证Main DEX运行正常。 随着第二个问题的迎刃而解，我们来到了比较棘手的第三问题，如果我们在后台加载Secondary DEX过程中，用户点击界面将要跳转到使用了在Secondary DEX中class的界面， 那此时必然发生ClassNotFoundException, 那怎么解决这个问题呢，在所有的Activity跳转代码处添加判断Secondary DEX是否加载完成？这个方法可行，但工作量非常大； 那有没有更好的解决方案呢？我们通过分析Activity的启动过程，发现Activity是由ActivityThread 通过Instrumentation来启动的，我们是否可以在Instrumentation中做一定的手脚呢？通过分析代码ActivityThread和Instrumentation发现，Instrumentation有关Activity启动相关的方法大概有：execStartActivity、newActivity等等，这样我们就可以在这些方法中添加代码逻辑进行判断这个Class是否加载了，如果加载则直接启动这个Activity，如果没有加载完成则启动一个等待的Activity显示给用户，然后在这个Activity中等待后台Secondary DEX加载完成，完成后自动跳转到用户实际要跳转的Activity；这样在代码充分解耦合，以及每个业务代码能够做到颗粒化的前提下，我们就做到Secondary DEX的按需加载了， 下面是Instrumentation添加的部分关键代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public ActivityResult execStartActivity(Context who, IBinder contextThread, IBinder token, Activity target, Intent intent, int requestCode) &#123; ActivityResult activityResult = null; String className; if (intent.getComponent() != null) &#123; className = intent.getComponent().getClassName(); &#125; else &#123; ResolveInfo resolveActivity = who.getPackageManager().resolveActivity(intent, 0); if (resolveActivity != null &amp;&amp; resolveActivity.activityInfo != null) &#123; className = resolveActivity.activityInfo.name; &#125; else &#123; className = null; &#125; &#125; if (!TextUtils.isEmpty(className)) &#123; boolean shouldInterrupted = !MeituanApplication.isDexAvailable(); if (MeituanApplication.sIsDexAvailable.get() || mByPassActivityClassNameList.contains(className)) &#123; shouldInterrupted = false; &#125; if (shouldInterrupted) &#123; Intent interruptedIntent = new Intent(mContext, WaitingActivity.class); activityResult = execStartActivity(who, contextThread, token, target, interruptedIntent, requestCode); &#125; else &#123; activityResult = execStartActivity(who, contextThread, token, target, intent, requestCode); &#125; &#125; else &#123; activityResult = execStartActivity(who, contextThread, token, target, intent, requestCode); &#125; return activityResult;&#125;public Activity newActivity(Class&lt;?&gt; clazz, Context context, IBinder token, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, Object lastNonConfigurationInstance) throws InstantiationException, IllegalAccessException &#123; String className = \"\"; Activity newActivity = null; if (intent.getComponent() != null) &#123; className = intent.getComponent().getClassName(); &#125; boolean shouldInterrupted = !MeituanApplication.isDexAvailable(); if (MeituanApplication.sIsDexAvailable.get() || mByPassActivityClassNameList.contains(className)) &#123; shouldInterrupted = false; &#125; if (shouldInterrupted) &#123; intent = new Intent(mContext, WaitingActivity.class); newActivity = mBase.newActivity(clazz, context, token, application, intent, info, title, parent, id, lastNonConfigurationInstance); &#125; else &#123; newActivity = mBase.newActivity(clazz, context, token, application, intent, info, title, parent, id, lastNonConfigurationInstance); &#125; return newActivity;&#125; 实际应用中我们还遇到另外一个比较棘手的问题， 就是Field的过多的问题，Field过多是由我们目前采用的代码组织结构引入的，我们为了方便多业务线、多团队并发协作的情况下开发，我们采用的aar的方式进行开发，并同时在aar依赖链的最底层引入了一个通用业务aar，而这个通用业务aar中包含了很多资源，而ADT14以及更高的版本中对Library资源处理时，Library的R资源不再是static final的了，详情请查看google官方说明，这样在最终打包时Library中的R没法做到内联，这样带来了R field过多的情况，导致需要拆分多个Secondary DEX，为了解决这个问题我们采用的是在打包过程中利用脚本把Libray中R field（例如ID、Layout、Drawable等）的引用替换成常量，然后删去Library中R.class中的相应Field。 总结上面就是我们在使用MultiDex过程中进化而来的DEX自动化拆包的方案， 这样我们就可以通过脚本控制来进行自动化的拆分DEX，然后在运行时自由的加载Secondary DEX，既能保证冷启动速度，又能减少运行时的内存占用。 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"MySQL索引原理及慢查询优化","date":"2017-02-26T13:27:05.000Z","path":"2017/02/26/Program/Concepts/the-essence-of-mysql-index/","text":"NeverMore MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能够更好的使用它，已经成为开发工程师的必修课，我们经常会从职位描述上看到诸如“精通MySQL”、“SQL语句优化”、“了解数据库原理”等要求。我们知道一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，所以查询语句的优化显然是重中之重。 本人从13年7月份起，一直在美团核心业务系统部做慢查询的优化工作，共计十余个系统，累计解决和积累了上百个慢查询案例。随着业务的复杂性提升，遇到的问题千奇百怪，五花八门，匪夷所思。本文旨在以开发工程师的角度来解释数据库索引的原理和如何优化慢查询。 一个慢查询引发的思考select count(*)from taskwhere status=2 and operator_id=20839 and operate_time&gt;1371169729 and operate_time&lt;1371174603 and type=2;系统使用者反应有一个功能越来越慢，于是工程师找到了上面的SQL。并且兴致冲冲的找到了我，“这个SQL需要优化，给我把每个字段都加上索引”我很惊讶，问道“为什么需要每个字段都加上索引？”“把查询的字段都加上索引会更快”工程师信心满满“这种情况完全可以建一个联合索引，因为是最左前缀匹配，所以operate_time需要放到最后，而且还需要把其他相关的查询都拿来，需要做一个综合评估。”“联合索引？最左前缀匹配？综合评估？”工程师不禁陷入了沉思。多数情况下，我们知道索引能够提高查询效率，但应该如何建立索引？索引的顺序如何？许多人却只知道大概。其实理解这些概念并不难，而且索引的原理远没有想象的那么复杂。 MySQL索引原理 ##索引目的索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？ ##索引原理除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。 ###磁盘IO与预读前面提到了访问磁盘，那么这里先简单介绍一下磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。下图是计算机硬件延迟的对比图，供大家参考：various-system-software-hardware-latencies考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。 ###索引的数据结构前面讲了生活中索引的例子，索引的基本原理，数据库的复杂性，又讲了操作系统的相关知识，目的就是让大家了解，任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。 ###详解b+树b+树如上图，是一颗b+树，关于b+树的定义可以参见B+树，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 ###b+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 ###b+树性质1.通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 慢查询优化关于MySQL索引原理是比较枯燥的东西，大家只需要有一个感性的认识，并不需要理解得非常透彻和深入。我们回头来看看一开始我们说的慢查询，了解完索引原理之后，大家是不是有什么想法呢？先总结一下索引的几大基本原则 建索引的几大原则1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式3.尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 回到开始的慢查询根据最左匹配原则，最开始的sql语句的索引应该是status、operator_id、type、operate_time的联合索引；其中status、operator_id、type的顺序可以颠倒，所以我才会说，把这个表的所有相关查询都找到，会综合分析；比如还有如下查询 select from task where status = 0 and type = 12 limit 10;select count() from task where status = 0 ;那么索引建立成(status,type,operator_id,operate_time)就是非常正确的，因为可以覆盖到所有情况。这个就是利用了索引的最左匹配的原则 查询优化神器 - explain命令关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网explain-output，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。 慢查询优化基本步骤0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）3.order by limit 形式的sql语句让排序的表优先查4.了解业务方使用场景5.加索引时参照建索引的几大原则6.观察结果，不符合预期继续从0分析 几个慢查询案例下面几个例子详细解释了如何分析和优化慢查询 复杂语句写法很多情况下，我们写SQL只是为了实现功能，这只是第一步，不同的语句书写方式对于效率往往有本质的差别，这要求我们对mysql的执行计划和索引原则有非常清楚的认识，请看下面的语句 select distinct cert.emp_idfrom cm_log clinner join ( select emp.id as emp_id, emp_cert.id as cert_id from employee emp left join emp_certificate emp_cert on emp.id = emp_cert.emp_id where emp.is_deleted=0 ) cert on ( cl.ref_table=’Employee’ and cl.ref_oid= cert.emp_id ) or ( cl.ref_table=’EmpCertificate’ and cl.ref_oid= cert.cert_id )where cl.last_upd_date &gt;=’2013-11-07 15:03:00’ and cl.last_upd_date&lt;=’2013-11-08 16:00:00’;0.先运行一下，53条记录 1.87秒，又没有用聚合语句，比较慢 53 rows in set (1.87 sec)1.explain +—-+————-+————+——-+———————————+———————–+———+——————-+——-+——————————–+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+————+——-+———————————+———————–+———+——————-+——-+——————————–+| 1 | PRIMARY | cl | range | cm_log_cls_id,idx_last_upd_date | idx_last_upd_date | 8 | NULL | 379 | Using where; Using temporary || 1 | PRIMARY | | ALL | NULL | NULL | NULL | NULL | 63727 | Using where; Using join buffer || 2 | DERIVED | emp | ALL | NULL | NULL | NULL | NULL | 13317 | Using where || 2 | DERIVED | emp_cert | ref | emp_certificate_empid | emp_certificate_empid | 4 | meituanorg.emp.id | 1 | Using index |+—-+————-+————+——-+———————————+———————–+———+——————-+——-+——————————–+简述一下执行计划，首先mysql根据idx_last_upd_date索引扫描cm_log表获得379条记录；然后查表扫描了63727条记录，分为两部分，derived表示构造表，也就是不存在的表，可以简单理解成是一个语句形成的结果集，后面的数字表示语句的ID。derived2表示的是ID = 2的查询构造了虚拟表，并且返回了63727条记录。我们再来看看ID = 2的语句究竟做了写什么返回了这么大量的数据，首先全表扫描employee表13317条记录，然后根据索引emp_certificate_empid关联emp_certificate表，rows = 1表示，每个关联都只锁定了一条记录，效率比较高。获得后，再和cm_log的379条记录根据规则关联。从执行过程上可以看出返回了太多的数据，返回的数据绝大部分cm_log都用不到，因为cm_log只锁定了379条记录。如何优化呢？可以看到我们在运行完后还是要和cm_log做join,那么我们能不能之前和cm_log做join呢？仔细分析语句不难发现，其基本思想是如果cm_log的ref_table是EmpCertificate就关联emp_certificate表，如果ref_table是Employee就关联employee表，我们完全可以拆成两部分，并用union连接起来，注意这里用union，而不用union all是因为原语句有“distinct”来得到唯一的记录，而union恰好具备了这种功能。如果原语句中没有distinct不需要去重，我们就可以直接使用union all了，因为使用union需要去重的动作，会影响SQL性能。优化过的语句如下 select emp.idfrom cm_log clinner join employee emp on cl.ref_table = ‘Employee’ and cl.ref_oid = emp.idwhere cl.last_upd_date &gt;=’2013-11-07 15:03:00’ and cl.last_upd_date&lt;=’2013-11-08 16:00:00’ and emp.is_deleted = 0unionselect emp.idfrom cm_log clinner join emp_certificate ec on cl.ref_table = ‘EmpCertificate’ and cl.ref_oid = ec.idinner join employee emp on emp.id = ec.emp_idwhere cl.last_upd_date &gt;=’2013-11-07 15:03:00’ and cl.last_upd_date&lt;=’2013-11-08 16:00:00’ and emp.is_deleted = 04.不需要了解业务场景，只需要改造的语句和改造之前的语句保持结果一致 5.现有索引可以满足，不需要建索引 6.用改造后的语句实验一下，只需要10ms 降低了近200倍！ +—-+————–+————+——–+———————————+——————-+———+———————–+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————–+————+——–+———————————+——————-+———+———————–+——+————-+| 1 | PRIMARY | cl | range | cm_log_cls_id,idx_last_upd_date | idx_last_upd_date | 8 | NULL | 379 | Using where || 1 | PRIMARY | emp | eq_ref | PRIMARY | PRIMARY | 4 | meituanorg.cl.ref_oid | 1 | Using where || 2 | UNION | cl | range | cm_log_cls_id,idx_last_upd_date | idx_last_upd_date | 8 | NULL | 379 | Using where || 2 | UNION | ec | eq_ref | PRIMARY,emp_certificate_empid | PRIMARY | 4 | meituanorg.cl.ref_oid | 1 | || 2 | UNION | emp | eq_ref | PRIMARY | PRIMARY | 4 | meituanorg.ec.emp_id | 1 | Using where || NULL | UNION RESULT | | ALL | NULL | NULL | NULL | NULL | NULL | |+—-+————–+————+——–+———————————+——————-+———+———————–+——+————-+53 rows in set (0.01 sec)明确应用场景举这个例子的目的在于颠覆我们对列的区分度的认知，一般上我们认为区分度越高的列，越容易锁定更少的记录，但在一些特殊的情况下，这种理论是有局限性的 select *from stage_poi spwhere sp.accurate_result=1 and ( sp.sync_status=0 or sp.sync_status=2 or sp.sync_status=4 );0.先看看运行多长时间,951条数据6.22秒，真的很慢 951 rows in set (6.22 sec)1.先explain，rows达到了361万，type = ALL表明是全表扫描 +—-+————-+——-+——+—————+——+———+——+———+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——-+——+—————+——+———+——+———+————-+| 1 | SIMPLE | sp | ALL | NULL | NULL | NULL | NULL | 3613155 | Using where |+—-+————-+——-+——+—————+——+———+——+———+————-+2.所有字段都应用查询返回记录数，因为是单表查询 0已经做过了951条 3.让explain的rows 尽量逼近951 看一下accurate_result = 1的记录数 select count(),accurate_result from stage_poi group by accurate_result;+———-+—————–+| count() | accurate_result |+———-+—————–+| 1023 | -1 || 2114655 | 0 || 972815 | 1 |+———-+—————–+我们看到accurate_result这个字段的区分度非常低，整个表只有-1,0,1三个值，加上索引也无法锁定特别少量的数据 再看一下sync_status字段的情况 select count(),sync_status from stage_poi group by sync_status;+———-+————-+| count() | sync_status |+———-+————-+| 3080 | 0 || 3085413 | 3 |+———-+————-+同样的区分度也很低，根据理论，也不适合建立索引 问题分析到这，好像得出了这个表无法优化的结论，两个列的区分度都很低，即便加上索引也只能适应这种情况，很难做普遍性的优化，比如当sync_status 0、3分布的很平均，那么锁定记录也是百万级别的 4.找业务方去沟通，看看使用场景。业务方是这么来使用这个SQL语句的，每隔五分钟会扫描符合条件的数据，处理完成后把sync_status这个字段变成1,五分钟符合条件的记录数并不会太多，1000个左右。了解了业务方的使用场景后，优化这个SQL就变得简单了，因为业务方保证了数据的不平衡，如果加上索引可以过滤掉绝大部分不需要的数据 5.根据建立索引规则，使用如下语句建立索引 alter table stage_poi add index idx_acc_status(accurate_result,sync_status);6.观察预期结果,发现只需要200ms，快了30多倍。 952 rows in set (0.20 sec)我们再来回顾一下分析问题的过程，单表查询相对来说比较好优化，大部分时候只需要把where条件里面的字段依照规则加上索引就好，如果只是这种“无脑”优化的话，显然一些区分度非常低的列，不应该加索引的列也会被加上索引，这样会对插入、更新性能造成严重的影响，同时也有可能影响其它的查询语句。所以我们第4步调差SQL的使用场景非常关键，我们只有知道这个业务场景，才能更好地辅助我们更好的分析和优化查询语句。 无法优化的语句select c.id, c.name, c.position, c.sex, c.phone, c.office_phone, c.feature_info, c.birthday, c.creator_id, c.is_keyperson, c.giveup_reason, c.status, c.data_source, from_unixtime(c.created_time) as created_time, from_unixtime(c.last_modified) as last_modified, c.last_modified_user_idfrom contact cinner join contact_branch cb on c.id = cb.contact_idinner join branch_user bu on cb.branch_id = bu.branch_id and bu.status in ( 1, 2) inner join org_emp_info oei on oei.data_id = bu.user_id and oei.node_left &gt;= 2875 and oei.node_right &lt;= 10802 and oei.org_category = - 1 order by c.created_time desc limit 0 , 10;还是几个步骤0.先看语句运行多长时间，10条记录用了13秒，已经不可忍受 10 rows in set (13.06 sec)1.explain +—-+————-+——-+——–+————————————-+————————-+———+————————–+——+———————————————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——-+——–+————————————-+————————-+———+————————–+——+———————————————-+| 1 | SIMPLE | oei | ref | idx_category_left_right,idx_data_id | idx_category_left_right | 5 | const | 8849 | Using where; Using temporary; Using filesort || 1 | SIMPLE | bu | ref | PRIMARY,idx_userid_status | idx_userid_status | 4 | meituancrm.oei.data_id | 76 | Using where; Using index || 1 | SIMPLE | cb | ref | idx_branch_id,idx_contact_branch_id | idx_branch_id | 4 | meituancrm.bu.branch_id | 1 | || 1 | SIMPLE | c | eq_ref | PRIMARY | PRIMARY | 108 | meituancrm.cb.contact_id | 1 | |+—-+————-+——-+——–+————————————-+————————-+———+————————–+——+———————————————-+从执行计划上看，mysql先查org_emp_info表扫描8849记录，再用索引idx_userid_status关联branch_user表，再用索引idx_branch_id关联contact_branch表，最后主键关联contact表。rows返回的都非常少，看不到有什么异常情况。我们在看一下语句，发现后面有order by + limit组合，会不会是排序量太大搞的？于是我们简化SQL，去掉后面的order by 和 limit，看看到底用了多少记录来排序 select count()from contact cinner join contact_branch cb on c.id = cb.contact_idinner join branch_user bu on cb.branch_id = bu.branch_id and bu.status in ( 1, 2) inner join org_emp_info oei on oei.data_id = bu.user_id and oei.node_left &gt;= 2875 and oei.node_right &lt;= 10802 and oei.org_category = - 1+———-+| count() |+———-+| 778878 |+———-+1 row in set (5.19 sec)发现排序之前居然锁定了778878条记录，如果针对70万的结果集排序，将是灾难性的，怪不得这么慢，那我们能不能换个思路，先根据contact的created_time排序，再来join会不会比较快呢？于是改造成下面的语句，也可以用straight_join来优化selectc.id,c.name,c.position,c.sex,c.phone,c.office_phone,c.feature_info,c.birthday,c.creator_id,c.is_keyperson,c.giveup_reason,c.status,c.data_source,from_unixtime(c.created_time) as created_time,from_unixtime(c.last_modified) as last_modified,c.last_modified_user_idfromcontact cwhereexists (select1fromcontact_branch cbinner joinbranch_user buon cb.branch_id = bu.branch_idand bu.status in (1,2)inner joinorg_emp_info oeion oei.data_id = bu.user_idand oei.node_left &gt;= 2875and oei.node_right &lt;= 10802and oei.org_category = - 1wherec.id = cb.contact_id)order byc.created_time desc limit 0 ,10; 验证一下效果 预计在1ms内，提升了13000多倍！```sql10 rows in set (0.00 sec)本以为至此大工告成，但我们在前面的分析中漏了一个细节，先排序再join和先join再排序理论上开销是一样的，为何提升这么多是因为有一个limit！大致执行过程是：mysql先按索引排序得到前10条记录，然后再去join过滤，当发现不够10条的时候，再次去10条，再次join，这显然在内层join过滤的数据非常多的时候，将是灾难的，极端情况，内层一条数据都找不到，mysql还傻乎乎的每次取10条，几乎遍历了这个数据表！用不同参数的SQL试验下 select sql_no_cache c.id, c.name, c.position, c.sex, c.phone, c.office_phone, c.feature_info, c.birthday, c.creator_id, c.is_keyperson, c.giveup_reason, c.status, c.data_source, from_unixtime(c.created_time) as created_time, from_unixtime(c.last_modified) as last_modified, c.last_modified_user_idfrom contact cwhere exists ( select 1 from contact_branch cb inner join branch_user bu on cb.branch_id = bu.branch_id and bu.status in ( 1, 2) inner join org_emp_info oei on oei.data_id = bu.user_id and oei.node_left &gt;= 2875 and oei.node_right &lt;= 2875 and oei.org_category = - 1 where c.id = cb.contact_id ) order by c.created_time desc limit 0 , 10;Empty set (2 min 18.99 sec)2 min 18.99 sec！比之前的情况还糟糕很多。由于mysql的nested loop机制，遇到这种情况，基本是无法优化的。这条语句最终也只能交给应用系统去优化自己的逻辑了。通过这个例子我们可以看到，并不是所有语句都能优化，而往往我们优化时，由于SQL用例回归时落掉一些极端情况，会造成比原来还严重的后果。所以，第一：不要指望所有语句都能通过SQL优化，第二：不要过于自信，只针对具体case来优化，而忽略了更复杂的情况。 慢查询的案例就分析到这儿，以上只是一些比较典型的案例。我们在优化过程中遇到过超过1000行，涉及到16个表join的“垃圾SQL”，也遇到过线上线下数据库差异导致应用直接被慢查询拖死，也遇到过varchar等值比较没有写单引号，还遇到过笛卡尔积查询直接把从库搞死。再多的案例其实也只是一些经验的积累，如果我们熟悉查询优化器、索引的内部原理，那么分析这些案例就变得特别简单了。 写在后面的话本文以一个慢查询案例引入了MySQL索引原理、优化慢查询的一些方法论;并针对遇到的典型案例做了详细的分析。其实做了这么长时间的语句优化后才发现，任何数据库层面的优化都抵不上应用系统的优化，同样是MySQL，可以用来支撑Google/FaceBook/Taobao应用，但可能连你的个人网站都撑不住。套用最近比较流行的话：“查询容易，优化不易，且写且珍惜！” 参考参考文献如下：1.《高性能MySQL》2.《数据结构与算法分析》 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫： 公众号二维码","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"Android Support Library的前世今生","date":"2017-02-26T10:16:06.000Z","path":"2017/02/26/Program/Android/history-of-v4-and-v7/","text":"原文作者：都有米 在之前的开发经历中经常需要导入一些如v4、v7、v13等Android官方的支持包，遇到这些情况时都是网上搜索一下，按照前人给的示例添加依赖。这么稀里糊涂的使用后代码正常运行了，但心中不免会有一些疑问，如，Android官方为什么要提供支持包，都提供哪些支持包，这些支持包又提供了什么特性，开发者又应该如何选择使用这些支持包？ 为了解开这些疑问，周末在家仔细阅读了官方的开发者指导文档的相关内容。这篇文章就是读后整理的读书笔记。 Android官方为什么要提供支持包？为什么官方向开发者在提供了android sdk之外，还要提供一些零碎的开发支持jar包，全部放在framework中不好吗？恩，不好！因为这不是好不好的问题，这是Android平台快速发展带来的必然产物，这张图罗列了已经发布的Android版本及其对应的开发sdk的级别。 至于为什么提供支持包官方给出了大致三个原因： 1、向后兼容如，我们开的App需要支持的minSdkVersion=9，targetSdkVersion=11，在程序里使用了android 3.0 (API level 11)提供的ActionBar类，使用compileSdkVersion=11成功编译出apk。在android 3.0的设备上完美运行，但是app在android 2.3的设备就会crash，报找不到ActionBar的错误。这很好理解，因为旧版本上没有新版本里新增的类。为了避免使用了最新功能开发的app只能在最新系统的设备上运行的尴尬，官方把新版系统framework中新增加的接口提出来放到了Android Support Library（支持包）中，开发者在遇到上面的情况时，就可以使用支持包中具有同样功能的ActionBar类，这个支持包会打包进App里，这样使用了新版本系统上功能的App也可以向后兼容以前的老系统版本设备了。 使用支持包中的类除了让我们免于判断App运行的系统版本外，还可以使App在各个版本保持同样的用户体验。如在5.0以下系统使用material design。 App编译时用的android sdk（android.jar）不会打包进我们的App中。因为App编码是使用android.jar中的接口就是android设备里系统框架层（framework）对外提供的接口。 2、提供不适合打包进framework的功能Android官方对App开发提供了推荐设计，希望Android应用都有相对一致的交互设计来减少用户的使用成本，希望三方App类似系统应用从而完美融入到Android生态系统中。但是这都仅仅是推荐，不要求开发者一定要这样，如果有这种需求就可以使用官方支持包提供的这些功能，避免重复造轮子。如支持包中的DrawerLayout、Snackbar等类都是这种情况。 3、为了支持不同形态的设备通过使用支持包来在不同形态设备上提供功能，如手机、电视、可穿戴设备等。 官方提供了哪些支持包，都有哪些特性？现在Android官方发布了下面13类支持库，不同的支持库包含不同特征，适用的Android版本也不相同。通常情况下我们都使用到v4和v7这两个集合库，因为这两个库支持的android系统版本范围比较广，官方推荐的UI设计样式相关类也都在这两集合库中。 【※】v4 Support Libraries v4库被设计在Android 2.3 (API level 9)及其以上系统中使用。 Support Library的第1版（２０１１年３月发布）就只包含v4库，当时v4库只是一个库，支持Android 1.6 (API level 4)及其以上版本，这也是v4名字的由来。随着系统的迭代现在Android 1.6设备已经很少了，官方在Support Library的第24.2.0版本（２０１6年8月发布）的时候移除了对Android 2.2 (API level 8)及其以下版本的支持，但是名字依然是v4。v4悠久的历史长期的发展造就了它较大的体积。也是在24.2.0这个版本Goggle将原来的单个v4库拆分成了5个子库，我们在使用的时候可以直接依赖某个子库，从而减少依赖包的大小。下图可见Android 2.2 Froyo占有率约为0.1%。 Gradle编译脚本中整个v4库的依赖语句如下： compile ‘com.android.support:support-v4:24.2.1’ gradle中jar依赖语句格式如 compile ‘jar文件组（group/命名空间）:jar文件名（name）:jar文件版本（version）’。所以上面的语句意思是依赖Android支持库中第24.2.1版的support-v4库。由于在24.2.0版本support-v4库已经被拆分成5个子库，所以如下图所示依赖24.2.1版本的support-v4库除了导入support-v4库外还会导入它的5个子库，这个版本的support-v4库本身是一个空的包，所有具体的实现都在它依赖的子库中。下面依次看下v4库拆分出来的5个子库。 v4 compat library为一些框架的API提供兼容性包装。如，Context.obtainDrawable()、View.performAccessibilityAction()等。Gradle编译脚本中v4 compat库的依赖语句： compile ‘com.android.support:support-compat:24.2.1’ v4 core-utils library提供了一些工具类。如，AsyncTaskLoader、PermissionChecker等。Gradle编译脚本中v4 core-utils库的依赖语句： compile ‘com.android.support:support-core-utils:24.2.1’ v4 core-ui library提供很多UI相关组件。如，ViewPager、NestedScrollView、ExploreByTouchHelper等。Gradle编译脚本中v4 core-ui库的依赖语句： compile ‘com.android.support:support-core-ui:24.2.1’ v4 media-compat library多媒体框架相关部分。如，MediaBrowser、MediaSession等。Gradle编译脚本中v4 media-compat库的依赖语句： compile ‘com.android.support:support-media-compat:24.2.1’ v4 fragment library跟fragment相关部分。v4这个子库依赖了其他4个子库，所以我们一旦依赖这个库就会自动导入其他4个子库，这跟直接依赖整个support-v4效果类似。关于v4拆分这篇文章有介绍，有兴趣的可以点过去看看。Gradle编译脚本中v4 fragment 库的依赖语句如下： compile ‘com.android.support:support-fragment:24.2.1’ 【※】v7 Support Libraries 注意这里的Library用的也是复数，说明v7库和v4一样也是很多库的集合，不同的是v7各个库不是后来拆分出来的，而是最初发布时就是以各个独立的库的形式发布的，如发布的最早的v7库v7 gridlayout library。这些库的共同之处是发布之初都是支持Android 2.1 (API level 7)及其以上版本，所以把他们统称为v7支持库。需要注意的24.2.0版本以后的v7支持库支持范围也是Android 2.3 (API level 9)及其以上版本了，这是因为v7依赖的v4库支持版本范围改变了，这点在v4支持库小节有介绍。v7库集合里有7个子库，使用时根据需要选择导入哪些库。 v7 appcompat library支持UI设计样式、 material design相关，如ActionBar、AppCompatActivity、Theme等。Gradle编译脚本中v7 appcompat库的依赖语句： compile ‘com.android.support:appcompat-v7:24.2.1’v7 cardview library支持cardview控件，使用material design语言设计，卡片式的信息展示，在电视App中有广泛的使用。Gradle编译脚本中v7 cardview库的依赖语句： compile ‘com.android.support:cardview-v7:24.2.1’v7 gridlayout library支持gridlayout布局。Gradle编译脚本中v7 gridlayout库的依赖语句： compile ‘com.android.support:gridlayout-v7:24.2.1’v7 mediarouter library该库提供了 MediaRouter、MediaRouteProvider等与Google Cast相关的类。Gradle编译脚本中v7 mediarouter库的依赖语句： compile ‘com.android.support:mediarouter-v7:24.2.1’v7 palette library该库提供了palette类，使用这个类可以很方便提取出图片中主题色。比如在音乐App中，从音乐专辑封面图片中提取出专辑封面图片的主题色，然后将播放界面的背景色设置为封面的主题色，随着播放音乐的改变，播放界面的背景色也会巧妙的跟着改变，从而提供更好的用户体验。Gradle编译脚本中v7 palette库的依赖语句： compile ‘com.android.support:palette-v7:24.2.1’v7 recyclerview library该库提供了recyclerview类。这个库使用的频率很高，网上有很多文章介绍recyclerview。Gradle编译脚本中v7 recyclerview库的依赖语句： compile ‘com.android.support:recyclerview-v7:24.2.1’v7 Preference Support library这个库在设置界面常用到。提供了 CheckBoxPreference、ListPreference等类。Gradle编译脚本中v7 preference support库的依赖语句： compile ‘com.android.support:preference-v7:24.2.1’v8 Support Library v8支持库支持范围也是Android 2.3 (API level 9)及其以上版本。v8支持库集合中现在只有一个库。 v8 renderscript library这个库支持渲染脚本计算框架。对这个库有兴趣可以看渲染脚本开发指导。使用v8 renderscript库Gradle编译脚本的配置方法：defaultConfig { renderscriptTargetApi 18 renderscriptSupportModeEnabled true}【※】v13 Support Library v13支持库适用范围是Android 3.2 (API level 13)及其以上版本。这个库跟v4 fragment library功能基本一样，也是提供兼容fragment相关内容。区别是v4 fragment library需要依赖v4支持库集合里的其它4个子库，而v13 support library依赖的是Android 3.2 (API level 13)及其以上版本framework。也就是说v4支持库除了v4 fragment library以外，其它功能都在Android 3.2 (API level 13)及其以上版本的framework中提供了。所以我们的App如果只需要兼容到Android 3.2，那么fragment部分使用v13 Support Library中的相关类才是明智之举。Gradle编译脚本中v13 support库的依赖语句： compile ‘com.android.support:support-v13:24.2.1’v14 Preference Support Library 功能类似v7 Preference Support library，支持Android系统版本不一致，新增部分相关接口。Gradle编译脚本中v 库的依赖语句： compile ‘com.android.support:preference-v14:24.2.1’v17 Preference Support Library for TV 功能类似v7 Preference Support library，支持Android系统版本不一致，新增部分相关接口，为电视设备App提供相应的UI。Gradle编译脚本中v 库的依赖语句： compile ‘com.android.support:preference-leanback-v17:24.2.1’v17 Leanback Library 这也是在电视设备上使用的库，主要是和YouTube相关的。Gradle编译脚本中v17 Leanback库的依赖语句： compile ‘com.android.support:leanback-v17:24.2.1’Annotations Support Library 提供注解相关功能。Gradle编译脚本中Annotations Support库的依赖语句： compile ‘com.android.support:support-annotations:24.2.1’【※】Design Support Library 这个库现在使用的也比较多，它提供了material design设计风格的控件。如，navigation drawers、floating action buttons (FAB)、snackbars、tabs等。Gradle编译脚本中Design Support库的依赖语句： compile ‘com.android.support:design:24.2.1’【※】Multidex Support Library Android的单个.dex文件最多能引用65536个方法，在这之后的方法就无法引用了。当我们的方法数超过这个限制后就需要分成多个dex文件，该库就是用来支持多个dex文件构建应用程序的。Gradle编译脚本中Multidex Support库的依赖语句： compile ‘com.android.support:multidex:1.0.0’【※】Custom Tabs Support Library 这个库有很有意思，提供了一种新的打开网页的方式。以前的App要打开一个网页有两种选择，一个是用webview，这种方式工作量较大，第二种方式是调用浏览器应用来打开网页，这种方式要在两个应用中切换，用户的操作体验是割裂的，都不够理想。这个库提供了第三种选择，具体情况可以点击这篇文章了解。Gradle编译脚本中Custom Tabs Support库的依赖语句： compile ‘com.android.support:customtabs:24.2.1’Percent Support Library 百分比支持库提供了如PercentFrameLayout、PercentRelativeLayout布局，在这些布局中子view可以使用百分比来设置大小、位置等。Gradle编译脚本中Percent Support库的依赖语句： compile ‘com.android.support:percent:24.2.1’App Recommendation Support Library for TV 这个库是电视设备上用来提供视频内容推荐的。Gradle编译脚本中Recommendation Support库的依赖语句： compile ‘com.android.support:recommendation:24.2.1’如何选择使用支持包？ 其实在了解了支持包特性之后，这个问题也就迎刃而解了，这里再做下总结。在使用Android Support Library之前我们需要通过sdk manager安装Android Support Repository，然后再在gradle编译脚本中添加如下依赖语句就可以了。 compile ‘com.android.support:support-v4:24.2.1’ //以v4为例前面文章说过gradle中jar依赖语句格式如 compile jar文件组（group/命名空间）:jar文件名（name）:jar文件版本（version）。对于Android Support Library库的依赖语句jar文件名和jar文件版本两部分需要选择确定。 jar文件名：在选择之前要明确两件事，需要使用支持包的哪种特性、需要兼容的最低Android版本，然后就可以确定具体依赖哪个支持库。jar文件版本：支持库的版本需要跟compileSdkVersion保持一致。 注意：由于依赖的支持库会打包进apk，所以官方推荐开发者在编译时使用ProGuard工具预处理release版本的apk。ProGuard工具除了混淆源代码外，还会移除那些依赖的支持库中没有使用到的类，达到apk瘦身的效果。 结束以上就是关于Android Support Library全部了，谢谢。如果文章有错误或者有疑问请务必留言告诉我。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"Android热更新方案Robust","date":"2017-02-26T01:04:05.000Z","path":"2017/02/26/Program/Android/hot-update-of-android/","text":"原文作者：吴坤 张梦 定旭 晓阳 美团•大众点评是中国最大的O2O交易平台，目前已拥有近6亿用户，合作各类商户达432万，订单峰值突破1150万单。美团App是平台主要的入口之一，O2O交易场景的复杂性决定了App稳定性要达到近乎苛刻的要求。用户到店消费买优惠券时死活下不了单，定外卖一个明显可用的红包怎么点也选不中，上了一个新活动用户一点就Crash……过去发生过的这些画面太美不敢想象。客户端相对Web版最大的短板就是有发版的概念，对线上事故很难有即时生效的解决方式，每次发版都如临深渊如履薄冰，毕竟就算再完善的开发测试流程也无法保证不会将Bug带到线上。 从去年开始，Android平台出现了一些优秀的热更新方案，主要可以分为两类：一类是基于multidex的热更新框架，包括Nuwa、Tinker等；另一类就是native hook方案，如阿里开源的Andfix和Dexposed。这样客户端也有了实时修复线上问题的可能。但经过调研之后，我们发现上述方案或多或少都有一些问题，基于native hook的方案：需要针对dalvik虚拟机和art虚拟机做适配，需要考虑指令集的兼容问题，需要native代码支持，兼容性上会有一定的影响；基于Multidex的方案，需要反射更改DexElements，改变Dex的加载顺序，这使得patch需要在下次启动时才能生效，实时性就受到了影响，同时这种方案在android N [speed-profile]编译模式下可能会有问题，可以参考Android N混合编译与对热补丁影响解析。考虑到美团Android用户机型分布的碎片化，很难有一个方案能覆盖所有机型。 去年底的Android Dev Summit上，Google高调发布了Android Studio 2.0，其中最重要的新特性Instant Run，实现了对代码修改的实时生效（热插拔）。我们在了解Instant Run原理之后，实现了一个兼容性更强的热更新方案，这就是产品化的hotpatch框架－－Robust。 原理Robust插件对每个产品代码的每个函数都在编译打包阶段自动的插入了一段代码，插入过程对业务开发是完全透明。如State.java的getIndex函数： public long getIndex() { return 100; }被处理成如下的实现： public static ChangeQuickRedirect changeQuickRedirect; public long getIndex() { if(changeQuickRedirect != null) { //PatchProxy中封装了获取当前className和methodName的逻辑，并在其内部最终调用了changeQuickRedirect的对应函数 if(PatchProxy.isSupport(new Object[0], this, changeQuickRedirect, false)) { return ((Long)PatchProxy.accessDispatch(new Object[0], this, changeQuickRedirect, false)).longValue(); } } return 100L; }可以看到Robust为每个class增加了个类型为ChangeQuickRedirect的静态成员，而在每个方法前都插入了使用changeQuickRedirect相关的逻辑，当 changeQuickRedirect不为null时，可能会执行到accessDispatch从而替换掉之前老的逻辑，达到fix的目的。如果需将getIndex函数的返回值改为return 106，那么对应生成的patch，主要包含两个class：PatchesInfoImpl.java和StatePatch.java。PatchesInfoImpl.java: public class PatchesInfoImpl implements PatchesInfo { public List getPatchedClassesInfo() { List patchedClassesInfos = new ArrayList(); PatchedClassInfo patchedClass = new PatchedClassInfo(“com.meituan.sample.d”, StatePatch.class.getCanonicalName()); patchedClassesInfos.add(patchedClass); return patchedClassesInfos; }}StatePatch.java： public class StatePatch implements ChangeQuickRedirect { @Override public Object accessDispatch(String methodSignature, Object[] paramArrayOfObject) { String[] signature = methodSignature.split(“:”); if (TextUtils.equals(signature[1], “a”)) {//long getIndex() -&gt; a return 106; } return null; } @Override public boolean isSupport(String methodSignature, Object[] paramArrayOfObject) { String[] signature = methodSignature.split(&quot;:&quot;); if (TextUtils.equals(signature[1], &quot;a&quot;)) {//long getIndex() -&gt; a return true; } return false; } }客户端拿到含有PatchesInfoImpl.java和StatePatch.java的patch.dex后，用DexClassLoader加载patch.dex，反射拿到PatchesInfoImpl.java这个class。拿到后，创建这个class的一个对象。然后通过这个对象的getPatchedClassesInfo函数，知道需要patch的class为com.meituan.sample.d（com.meituan.sample.State混淆后的名字），再反射得到当前运行环境中的com.meituan.sample.d class，将其中的changeQuickRedirect字段赋值为用patch.dex中的StatePatch.java这个class new出来的对象。这就是打patch的主要过程。通过原理分析，其实Robust只是在正常的使用DexClassLoader，所以可以说这套框架是没有兼容性问题的。 大体流程如下： 插件的问题OK，到这里Robust原理就介绍完了。很简单是不是？而且sample这个例子中也验证成功了。难道一切这么顺利？其实现实并不是这样，我们将这套实现用到美团的主App时，问题出现了： Conversion to Dalvik format failed:Unable to execute dex: method ID not in [0, 0xffff]: 65536居然不能打出包来了！从原理上分析，除了引入的patch过程aar外，我们这套实现是不会增加别的方法的，而且引入的那个aar的方法才100个左右，怎么会造成美团的mainDex超过65536呢？进一步分析，我们一共处理7万多个函数，导致最后方法数总共增加7661个。这是为什么呢？ 看下patch前后的dex对比： 针对com.meituan.android.order.adapter.OrderCenterListAdapter.java分析一下，发现进行hotpatch之后增加了如下6个方法： public boolean isEditMode() { return isEditMode; }private int incrementDelCount() { return delCount.incrementAndGet(); }private boolean isNeedDisplayRemainingTime(OrderData orderData) { return null != orderData.remindtime &amp;&amp; getRemainingTimeMillis(orderData.remindtime) &gt; 0; }private boolean isNeedDisplayUnclickableButton(OrderData orderData) { return null != orderData.remindtime &amp;&amp; getRemainingTimeMillis(orderData.remindtime) &lt;= 0; }private boolean isNeedDisplayExpiring(boolean expiring) { return expiring &amp;&amp; isNeedDisplayExpiring; }private View getViewByTemplate(int template, View convertView, ViewGroup parent) { View view = null; switch (template) { case TEMPLATE_DEFALUT: default: view = mInflater.inflate(R.layout.order_center_list_item, null); } return view; }但是这些多出来的函数其实就在原来的产品代码中，为什么没有Robust的情况下不见了，而使用了插件后又出现在最终的class中了呢？只有一个可能，就是ProGuard的内联受到了影响。使用了Robust插件后，原来能被ProGuard内联的函数不能被内联了。看了下ProGuard的Optimizer.java的相关片段： if (methodInliningUnique) { // Inline methods that are only invoked once. programClassPool.classesAccept( new AllMethodVisitor( new AllAttributeVisitor( new MethodInliner(configuration.microEdition, configuration.allowAccessModification, true, methodInliningUniqueCounter))));}if (methodInliningShort) { // Inline short methods. programClassPool.classesAccept( new AllMethodVisitor( new AllAttributeVisitor( new MethodInliner(configuration.microEdition, configuration.allowAccessModification, false, methodInliningShortCounter))));}通过注释可以看出，如果只被调用一次或者足够小的函数，都可能被内联。深入分析代码，我们发现确实如此，只被调用了一次的私有函数、只有一行函数体的函数（比如get、set函数等）都极可能内联。前面com.meituan.android.order.adapter.OrderCenterListAdapter.java多出的那6个函数也证明了这一点。知道原因了就能有解决问题的思路。其实仔细思考下，那些可能被内联的只有一行函数体的函数，真的有被插件处理的必要吗？别说一行代码的函数出问题的可能性小，就算出问题了也可以通过patch内联它的那个函数来解决问题，或者patch这一行代码调用的那个函数。只调用了一次的函数其实是一样的。所以通过分析，这样的函数其实是可以不被插件处理的。那么有了这个认识，我们对插件做了处理函数的判断，跳过被ProGuard内联可能性比较大的函数。重新在团购试了一次，这次apk顺利的打包出来了。通过对打出来apk中的dex做分析，发现优化后的插件还是影响了内联效果，不过只导致方法数增加了不到1000个，所以算是临时简单的解决了这个问题。 影响原理上，Robust是为每个函数都插入了一段逻辑，为每个class插入了ChangeQuickRedirect的字段，所以最终肯定会增加apk的体积。以美团主App为例，平均一个函数会比原来增加17.47个字节，整个App中我们一共处理了6万多个函数，导致包大小由原来的19.71M增加到了20.73M。有些class没有必要添加ChangeQuickRedirect字段，以后可以通过将这些class过滤掉的方式来做优化。Robust在每个方法前都加上了额外的逻辑，那对性能上有什么影响呢？从图中可以看到，对一个只有内存运算的函数，处理前后分别执行10万次的时间增加了128ms。这是在华为4A上的测试结果。对启动速度上的影响：在同一个机器上的结果，处理前后的启动时间相差了5ms。 补丁的问题再来看看补丁本身。要制作出补丁，我们可能会面临如下两个问题： 如何解决混淆问题？ 被补的函数中使用了super相关的调用怎么办？其实混淆的问题比较好处理。先针对混淆前的代码生成patch.class，然后利用生成release包时对应的mapping文件中的class的映射关系，对patch.class做字符串上的处理，让它使用线上运行环境中混淆的class。被补的函数中使用了super相关的调用怎么办？比如某个Activity的onCreate方法中需要调用super.onCreate，而现在这个bad.Class的badMethod就是这个Activity的onCreate方法，那么在patched.class的patchedMethod中如何通过这个Activity的对象，调用它父类的onCreate方法呢？通过分析Instant Run对这个问题的处理，发现它是在每个class中都添加了一个代理函数，专门来处理super的问题的。为每个class都增加一个函数无疑会增加总的方法数，这样做肯定会遇到65536这个问题。所以直接使用Instant Run的做法显然是不可取的。在Java中super是个关键字，也无法通过别的对象来访问到。看来，想直接在patched.java代码中通过Activity的对象调用到它父类的onCreate方法有点不太可能了。不过通过对class文件做分析，发现普通的函数调用是使用JVM指令集的invokevirtual指令，而super.onCreate的调用使用的是invokesuper指令。那是不是将class文件中这个调用的指令改为invokesuper就好了？看如下的例子：产品代码SuperClass.java： public class SuperClass { String uuid; public void setUuid(String id) { uuid = id; } public void thisIsSuper() { Log.d(“SuperClass”, “thisIsSuper “+uuid); }}产品代码TestSuperClass.java： public class TestSuperClass extends SuperClass{ String subUuid; public void setSubUuid(String id) { subUuid = id; } @Override public void thisIsSuper() { Log.d(&quot;TestSuperClass&quot;, &quot;thisIsSuper no call&quot;); } }TestSuperPatch.java是DexClassLoader将要加载的代码： public class TestSuperPatch { public static void testSuperCall() { TestSuperClass testSuperClass = new TestSuperClass(); String t = UUID.randomUUID().toString(); Log.d(“TestSuperPatch”, “UUID “ + t); testSuperClass.setUuid(t); testSuperClass.thisIsSuper(); }}对TestSuperPatch.class的testSuperClass.thisIsSuper()调用做invokesuper的替换，并且将invokesuper的调用作用在testSuperClass这个对象上，然后加载运行： Caused by: java.lang.NoSuchMethodError: No super method thisIsSuper()V in class Lcom/meituan/sample/TestSuperClass; or its super classes (declaration of ‘com.meituan.sample.TestSuperClass’ appears in /data/app/com.meituan.robust.sample-3/base.apk)报错信息说在TestSuperClass和TestSuperClass的父类中没有找到thisIsSuper()V函数！但是实际上TestSuperClass和父类中是存在thisIsSuper()V函数的，而且通过apk反编译看也确实存在的，那怎么就找不到呢？分析invokesuper指令的实现，发现系统会在执行指令所在的class的父类中去找需要调用的方法，所以要将TestSuperPatch跟TestSuperClass一样作为SuperClass的子类。修改如下： public class TestSuperPatch extends SuperClass { …}然后再做一次尝试： 08-11 09:12:03.012 1787-1787/? D/TestSuperPatch: UUID c5216480-5c3a-4990-896d-58c3696170c508-11 09:12:03.012 1787-1787/? D/SuperClass: thisIsSuper c5216480-5c3a-4990-896d-58c3696170c5看一下testSuperCall的实现，将UUID.randomUUID().toString()的结果，通过setUuid赋值给了testSuperClass这个对象的父类的uuid字段。从日志可以看出，对testSuperClass.thisIsSuper处理后，确实是调用到了testSuperClass这个对象的super的thisIsSuper函数。OK，super的问题看来解决了，而且这种方式不会增加方法数。 上线后的效果Robust 靠谱吗？尝试修个线上的问题，我们是在07.14下午17:00多的时候上线的补丁，我们可以看到接下来的几天一直到07.17号将补丁下线，这个线上问题得到了明显的修复，补丁下线后看到07.18号这个问题又明显上升了。直到07.18号下班前又重新上线补丁。 补丁的兼容性和成功率如何？通过以上的理论分析，可以看到这套实现基本没有兼容性问题，实际上线的数据如下： 先简单解释下这几个指标：补丁列表拉取成功率=拉取补丁列表成功的用户/尝试拉取补丁列表的用户补丁下载成功率=下载补丁成功的用户/补丁列表拉取成功的用户patch应用成功率=patch成功的用户/补丁下载成功的用户 通过这个表能够看出，我们的patch信息拉取的成功最低，平均97%多，这是因为实际的网络原因，而下载成功后的patch成功率是一直在99.8%以上。而且我们做的是无差别下发，服务端没有做任何针对机型版本的过滤，线上的结果再次证明了Robust的高兼容性。 总结目前业界已有的Android App热更新方案，包括Multidesk和native hook两类，都存在一些兼容性问题。为此我们借鉴Instant Run原理，实现了一个兼容性更强的热更新方案－－Robust。Robust除了高兼容性之外，还有实时生效的优势。so和资源的替换目前暂时未做实现，但是从框架上来说未来是完全有能力支持的。当然，这套方案虽然对开发者是透明的，但毕竟在编译阶段有插件侵入了产品代码，对运行效率、方法数、包体积还是产生了一些副作用。这也是我们下一步努力的方向。 参考文献Instant Run, Android Tools Project Site, http://tools.android.com/tech-docs/instant-run.Oracle, The Java Virtual Machine Instruction Set, https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html.Oracle, ClassLoader, https://docs.oracle.com/javase/7/docs/api/java/lang/ClassLoader.html).ltshddx, https://github.com/ltshddx/jaop).w4lle, Android热补丁之AndFix原理解析.shwenzhang, Android N混合编译与对热补丁影响解析. 不想错过技术博客更新？想给文章评论、和作者互动？第一时间获取技术沙龙信息？ 请关注我们的官方微信公众号“美团点评技术团队”。现在就拿出手机，扫一扫：公众号二维码","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"GestureDetector","date":"2017-02-25T08:11:06.000Z","path":"2017/02/25/Program/Android/GestureDetector/","text":"GestureDetector public class GestureDetectorextends Object java.lang.Object ↳ android.view.GestureDetector Detects various gestures and events using the supplied MotionEvents. The GestureDetector.OnGestureListener callback will notify users when a particular motion event has occurred. This class should only be used with MotionEvents reported via touch (don’t use for trackball events). To use this class: Create an instance of the GestureDetector for your View In the onTouchEvent(MotionEvent) method ensure you call onTouchEvent(MotionEvent). The methods defined in your callback will be executed when the events occur. If listening for onContextClick(MotionEvent) you must call onGenericMotionEvent(MotionEvent) in onGenericMotionEvent(MotionEvent). 参考文章：Android - GestureDetector 实现界面左右滑动效果的优化Android GestureDetector简单手势检测（左右滑动、上下滑动）","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"名人名言","date":"2017-02-22T00:31:05.000Z","path":"2017/02/22/MyView/English/my-translations/","text":"frome az quotes A person who never made a mistake never tried anything new.——Albert Einstein 从不犯错的人也从不尝试新事物。——艾尔伯特 爱因斯坦 I didn’t fail the test, I just found 100 ways to do it wrong.——Benjamin Franklin 我并没有失败，只是找到了100种错误的方法。——本杰明 富兰克林 Don’t find fault, find a remedy.——Henry Ford 不要找错，寻求补救。——亨利 福特 “Life is not easy for any of us. But what of that? We must have perseverance and above all confidence in ourselves. We must believe that we are gifted for something and that this thing must be attained.”——Marie Curie 生活对每人而言均不易，但那又如何？我们对自己必须要坚持不懈和充满信心，我们必须要相信自己在某些方面拥有天赋并且一定能够有所实现。——玛丽·居里 “It is godlike ever to think on something beautiful and on something new.”——Democritus 思考美丽的事物永远是神圣的，思考新事物也如此。 ——德谟克利特（古希腊哲学家） “I don’t want to be the next Michael Jordan, I only want to be Kobe Bryant.”——Kobe Bryant 我不想成为下一个迈克尔 乔丹，我只想成为科比 布莱恩特——科比 布莱恩特 “If somebody says no to you, or if you get cut, Michael Jordan was cut his first year, but he came back and he was the best ever. That is what you have to have. The attitude that I’m going to show everybody, I’m going to work hard to get better and better.”——Magic Johnson 如果有人拒绝你，或者你遭受打击，迈克尔 乔丹在菜鸟赛季被人欺凌，但是他重返赛场并展现最好状态，这就是你必须要拥有的态度：向每个人表明我会更加努力，使之越来越好！——魔术师 约翰逊 When everything seems to be going against you, remember that the airplane takes off against the wind, not with it. ——Henry Ford 当看似一切都在和你作对时，记得飞机就是迎风起飞的，不必在意。 ——亨利 福特 My mission in life is not merely to survive, but to thrive; and to do so with some passion, some compassion, some humor, and some style——Maya Angelou 我的人生使命不只是生存，而是带有激情、同情、幽默和时尚的生活。——玛雅·安吉罗","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"爱句子","date":"2017-02-22T00:13:05.000Z","path":"2017/02/22/MyView/English/love-sentencns/","text":"How deep I love you, the moon represents my heart.你问我爱你有多深，月亮代表我的心。 Your present circumstances don’t determine where you can go; they merely determine where you start.你目前的处境并不决定你的未来，它只决定你的起点。 BBC英语教学 英国，不同地区的人们会用和动物有关的词汇来称呼他人。这些称呼十分有爱，也很友好。有些人认为这个称呼来源于 duke 公爵。 Feifei‘Hen’ is used in Glasgow – but only when talking to women. 在苏格兰格拉斯哥，人们会用 hen 来称呼女性。 NeilAlright, hen? And then we have ‘pet’… Feifei‘Pet’ is used in the North East of England. 在英格兰纽卡斯尔，人们会互相称呼 pet。 The happiness of life is made up of minute fractions – the little soon forgotten charities of a kiss, a smile, a kind look, a heartfelt compliment. 生活中的快乐是由一些小片断组成——很快被遗忘的亲吻、微笑、关爱的眼神、由衷的赞美等小善举。 词霸小编: 快乐似蒲公英的种子飘落在任意角落，你需要的只是一双发现它的眼睛……【词汇扩充】heartfelt adj. 衷心的，真诚的。如 heartfelt thanks 由衷的感谢。同义词为：sincere。 与老外见面的10大经典句lavaFOX看电影学英语 1.Welcome to China! Welcome to our city! 欢迎到中国来！欢迎到我们的城市来！ 2.I hope you’re enjoying your stay here. 希望你在这里过得愉快。 3.How long have you been in China? 你在中国多长时间了？ 4.Is this your first trip to China? 这是你第一次来中国吗？ 5.Are you here on business or for pleasure? 你来这里是出差还是游玩？ 6.There are many interesting places here. I’d like to show you around. 这儿有很多有趣的地方，我愿意带你去看一看。 7.Please let me know if you need any help. 如果需要帮助，请告诉我。 8.What’s your impression of China so far? 你对中国有印象如何？ 9.Are you used to the life here? Does the weather agree with you? 你习惯这里的生活吗？你适应这里的气候吗？ 10.How do you like Chinese food? Are you used to the food here? Does the food here agree with you? 你觉得中国菜如何？你习惯这里的食物吗？这里的食物合你口味吗？ 实用版家庭日常英语口语(1)Sleep and waking up(睡觉/起床) It’s time to go sleepy-bye.(到睡觉的时间了。) Sweat dreams.(做个好梦。) It’s time to go to bed./Time for bed.(该上床了。) It’s time to have a nap.(该午休了。) Wake up!(起床。) Did you sleep well?(睡好了吗？) Time to get up.(该起床了。) (2)Getting dressed(穿衣) It’s time to get dressed(该穿衣服了。) What do you want to wear today?(今天想穿什么？) This shirt doesn’t go with those pants.(这件上衣和裤子不搭配。) Stand still. / sit still.(站好/坐好。) Now put on your sweater.(现在穿上毛衣。) Take your clothes off./ Take off your clothes.(脱衣服。) Pick up your socks, please.(请把袜子捡起来。) Put on your trousers/shoes/coat/cap.穿上你的裤子/鞋子/外套/帽子。 (3)Meal time(吃饭) Come sit at the table。(过来坐在桌旁。) Stop playing with your food。(不要再玩食物了。) Don’t talk with your mouth full。(嘴里吃着不要说话。) Help Daddy do the dishes。(帮助爸爸收盘子。) Help Mommy to set the table。(帮助妈妈放桌子。) Help us clear off the table。(帮我们收拾桌子。) (4)Safty and injuries(安全和受伤) It’s bad for you!(这对你不好。) I have told you many times not to do that。(我已经告诉你好几遍了不要那样做。) Don’t sit too close to the TV。(不要坐的离电视太近。) It’s nothing. It’s just a little cut。(不要紧，只是小伤口) Don’t touch the electrical outlets。(不要碰电源插座) Don’t try to plug/put anything in the outlet。(不要试图拔或放任何东西在插座里。) Don’t touch anything on the stove。(不要碰炉子) The oven is very hot; you could burn yourself。(炉子很烫，你会烫着自己。) Those tools are too sharp; they’re only for grownups。(那些工具太锋利了，只有大人能用) Don’t use others cup; you could catch his cold/germs that way。(不要用别人的杯子，那样会传染病菌) Don’t play with fire; it’s dangerous。(不要玩火，危险) Wait for the green light before you cross the street。(等绿灯亮了再过马路) Always look both side before crossing the street. (过马路前一定看两边。) (5)Playing toys/games(玩玩具/游戏) Don’t leave toys on the floor where people will step on them。(不要把玩具放在地板上，别人会踩到它们) I’m going to count to ten。(我将数到十) Let’s pick up the toys and put them back。(咱们把玩具捡起来放回去。) Want to play hide and seek?(玩捉迷藏吗？) Ready or not, here I come。(准备好了吗？我来了) Please put the toys/books back on the shelf。(请把玩具/书放回架子上。) Want to play outside?(想出去玩吗？) (6)Bathroom talk(卫生间) Do you need to go potty?(你要去大/小便吗？) I need to go to the bathroom. (我要上厕所) Don’t unroll the toilet paper。(不要扯手纸。) Don’t use too much toilet paper。(不要浪费手纸。) Don’t pick your nose. / Don’t stick your fingers in your nose。(不要用手挖鼻子。) Wipe your bottom。(擦擦屁股。) (7)Washing up(清洁) Your hands are sticky。(你的手很脏。) Wash your hands immediately。(马上去洗手。) Look at the mess you’ve made。(看看你弄的。) You need to have a bath。(你得洗个澡了。) (8)Manners(礼貌) Don’t interrupt daddy/mommy。(不要打断妈/爸说话) Don’t bother me while I’m on the phone。(我打电话时不要捣乱。) Are you going to apologize?(你准备道歉吗？) You need to share your toys with your sister。(你应该与妹妹分享玩具。) He had that toy first。(他先拿到的玩具。) This toy doesn’t belong to you。(这个玩具不是你的。) (9)Finding out(发现问题) What’s happened?(发生什么事了？) What’s the matter?(怎么了？) Why are you crying?(为什么哭？) Don’t worry。(不要担心。) Everything’s fine。(一切都会好的。) There’s nothing to be scared of。(没什么可怕的。) Are you feeling better now?(你现在感觉好些吗？) We’re right in the next room。(我们就在旁边的屋子) (10)Discipline(纪律) Stop doing that。(停下) We need to discuss this。(我们需要检讨一下。) Good girls/boys don’t do/say things like that。(好孩子不那样做(说)。) You’re part of a family, and you can’t think only about yourself。(你是家庭的一员，你不能只想到自己。) Don’t argue me about this。(不要再和我争论了。) I’m going to count to three, and if you don’t have the toys picked up by then …(数到三你不收玩具，我就。。。) No more discussion, you’re going to bed now。(没有商量的余地，你必须现在上床。) Don’t raise your voice at me!(不要对我提高嗓门！) That’s a rude way to speak。(那样说话不礼貌/粗鲁。) (11)Compliments, encouragement(鼓励，夸奖) Great job!(太棒了！) I’m so proud of you。(我真为你骄傲！) Well done!(干得好！) You were so brave/great/good!(你真勇敢/棒！) (12)Restaurants, shopping(饭店，购物) We can’t eat the food until we pay for it。(这食物在付款之前我们不能吃。) Don’t run around here; we’re not at home。(不要在这乱跑，我们不是在家里。) Please don’t knock down all those cans。(请不要把那些罐子碰倒。) Don’t touch anything here. These things aren’t ours。(不要碰任何东西，这不是我们的。) You promised me you wouldn’t ask me to buy anything。(你答应我的不买任何东西。)","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"爱单词","date":"2017-02-21T23:44:05.000Z","path":"2017/02/22/MyView/English/love-words/","text":"图文来源：微信号 我爱背单词 predator英 [‘predətə] 美 [‘prɛdətɚ]n. [动] 捕食者；[动] 食肉动物；掠夺者 词根词根： predatoradj.predatory 掠夺的，掠夺成性的；食肉的；捕食生物的n.predation 捕食；掠夺 同近义词n. [动]捕食者；食肉动物；掠夺者carnivore , reiver 短语Predator Missile 掠食者导弹 ; 掠夺者导弹 ; 者导弹 ; 捕食者导弹Predator Hunt 终极战士狩猎 ; 终极战士猎杀模式UAV Predator 无人机predator model 掠夺者模式 ; 捕食模型Predator B 捕食者B ; 者B型 ; MQ-9 收割者侦察机Kavu Predator 掠食卡甫 ; 掠食卡普PREDATOR CROUCHLEAP 铁血战士的蹲跳UFO Predator 飞碟掠夺者Predator Chain 捕食食物链 ; 捕食链 双语例句Insane pumpkin carving of the Predator.疯狂的南瓜雕刻——食肉动物。 Some residents and experts said the predator may be a bear, a wayward panther or cougar, or even a wolf because 3-inch paw tracks were found at the scene.一些居民和专家认为这种食肉动物可能是一只熊，一头任性的豹子或狮子，抑或是一头狼，因为在现场发现了3英寸长的爪迹。 But just like Dutch in Predator before the final battle, you have to be able to answer only one question about your target before you start: where they are.但就像一战之前的荷兰掠夺者一样，在开始工作之前你必须能够回答实现目标的唯一问题：他们在哪里？ deprecated英 [ˈdeprəkeɪtɪd] 美 [‘dɛprə,ketɪd]v. 不赞成；弃用；不宜用（deprecate的过去式及过去分词形式） decor英 [‘deɪkɔː; ‘de-] 美 [de’kɔr]n. 装饰，布置 solver英 [‘sɒlvə] 美 [‘sɑlvɚ]n. 解决者；[计] 解算机；[数] 求解程序 resolver英 [riː’zɒlvə] 美n. 溶剂；[电子] 分解器；下决心者 asset英 [‘æset] 美 [‘æsɛt]n. 资产；优点；有用的东西；有利条件；财产；有价值的人或物n. （法）阿塞（人名） extensible英 [ek’stensɪbl; ɪk’stensɪb(ə)l] 美 [ɪk’stɛnsəbl]adj. 可延长的；可扩张的 digester英 [dɪ’dʒestə] 美 [daɪ’dʒɛstɚ]n. 做摘要者；助消化食品；汇编者；蒸炼器 density英 [‘densɪtɪ] 美 [‘dɛnsəti]n. 密度[ 复数 densities ] 词根denseadj.dense 稠密的；浓厚的；愚钝的adv.densely 浓密地；密集地n.denseness 密集；稠密；浓厚densitometer 比重计，浓度计；光密度计densitometry 测（光）密度术；显微测密术 短语energy density 能量密度 ; 能量密度 ; 能量密度 ; 能population density 人口密度 ; 种群密度 ; 群体密度 ; 虫口密度Linear density 线密度 ; 线形密度 ; 线密度 ; 纤维线密度Column density 柱密度 ; 柱密度 ; 柱数密度flux density 通量密度 ; 磁通密度 ; 磁感应强度 ; 流量密度optical density 光学密度 ; 光密度 ; 光学深度 ; 表示光学玻璃或器材对蓝HIGH DENSITY 高密度 ; 高密 ; 厚版胶印 ; 超薄高密面料系列probability density 概率密度 ; 几率密度 ; 机率密度 ; 机率密度density current 密度流 ; 异重流 ; 重流 ; 密度差流动 双语例句Mercury has a much greater density than water.水银的密度比水大得多。 The population density of that country is 685 per square mile.那个国家的人口密度为每平方英里685人。 The increasing population density will even further congeal traffic.日益增加的人口密度将使交通更加瘫痪。 manifest英 [‘mænɪfest] 美 [‘mænɪfɛst]vt. 证明，表明；显示vi. 显示，出现n. 载货单，货单；旅客名单adj. 显然的，明显的；明白的 词根manifestadv.manifestly 显然地；明白地n.manifestation 表现；显示；示威运动 短语Manifest Destiny 昭昭天命 ; 昭昭天命 ; 天定命运 ; 宿命cargo manifest 载货清单 ; 货物舱单 ; 货物清单 ; 载货详细登记单transhipment manifest 转运仓单 ; 转运仓单Manifest information 舱单信息Manifest Discrepancy 舱单数据不符 ; 舱复数据不符manifest freight 快运货物manifest content 显性内容 ; 显性梦境 ; 外显内容 ; 梦境OUTWARD MANIFEST 出口舱单 ; 出口货物舱单 ; 出口货物清单 ; 出口舱单manifest dream 显性梦 ; 梦现 双语例句Fear was manifest on her face.她脸上显露出惧怕的神情。《新英汉大辞典》So, all of those dependencies have to appear on one line in the manifest file.因此，所有这些依赖项在清单文件中必须出现在一行。www.ibm.comIf anything fails, then you might have left out some files in the cache manifest.如果出现任何失败，那么您可能在缓存清单中遗漏了一些文件。 magnificentWhat a magnificent future!我们来看一下 magnificent 这个单词地道的英文解释：If you say that something or someone is magnificent, you mean that you think they are extremely good, beautiful, or impressive. mandatory英 [‘mændət(ə)rɪ] 美 [‘mændətɔri]adj. 强制的；托管的；命令的n. 受托者（等于mandatary） 词根mandaten.mandate 授权；命令，指令；委托管理；受命进行的工作mandatary 受托者；代理人mandator 命令者；委托人，托管人mandamus 命令书；书面训令vt.mandate 授权；托管mandamus 发训令（过去式mandamused，过去分词mandamused，现在分词mandamusing，第三人称单数mandamuses） 短语mandatory plan 指令性计划 ; 强制性计划 ; 指令性打算 ; 指令性mandatory offer 强制要约 ; 强制性要约 ; 强制性收购建议 ; 强制性收购Mandatory Lock 强制锁 ; 强制性锁 ; 强制性的锁mandatory retention 必须保持 ; 强制保持mandatory rule 法定规范 ; 强制性规则 ; 强制规定 ; 强制性规范MANDATORY FIELD 必选项目 ; 必填字段 ; 必须填写Mandatory insurance 强制保险 ; 政策性保险 ; 法定保险 ; 强制保险Mandatory Prewash 强制预洗mandatory legislation 强迫性法规 ; 强制性法律 双语例句Not all these interfaces are mandatory.并非所有这些接口都是强制的。 constraint英 [kən’streɪnt] 美 [kən’strent]n. [数] 约束；局促，态度不自然；强制 词根 constrainadj.constrained 拘泥的；被强迫的；不舒服的adv.constrainedly 勉强地；强迫地；不自然地v.constrained 驱使；强迫；勉强（constrain的过去分词）vt.constrain 驱使；强迫；束缚 短语Constraint programming 约束编程 ; 约束编程 ; 约束规划 ; 限制规划Path Constraint 路径约束 ; 路径限制 ; 指定物体沿着或在样条线间运动 ; 同前constraint condition 约束条件 ; 束缚前提 ; 约束前提 ; 束缚条件Orientation Constraint 方位约束 ; 方向约束 ; 方向限制 ; 指定物体的方位与另一物体的方位一致site constraint 地盘限制 ; 工地限制 ; 地盘限制;工地限制contact constraint 接触约束 ; 接触束缚 ; 相接拘束active constraint 有效约束 ; 活动约束 ; 起作用的约束 ; 主动约束internal constraint 内部约束 ; 内约束nonholonomic constraint 不完全约束 ; 非完整约束 双语例句The boy felt constraint in her presence.那男孩在她面前感到局促不安。 In this activity, you add documentation to every element in the model, including every column, every table, every constraint, and every trigger.在这种情况中，你把文档添加到模型的每一个元素中，包括每个列，每个表，每个约束和每个触发器。 If you must make a change that would be incompatible with a released version, for whatever reason, then there is a back door of temporarily disabling this constraint.如果您必须做出一个变更 ，使它与发布版本不相兼容，不管是什么原因，那么就会有一个临时后门丧失这个约束的能力。 methodology英 [meθə’dɒlədʒɪ] 美 [,mɛθə’dɑlədʒi]n. 方法学，方法论[ 复数 methodologies ] 词根 methodadj.method 使用体验派表演方法的methodical 有系统的；有方法的methodological 方法的，方法论的adv.methodically 有方法地；有系统地n.method 方法；条理；类函数 短语Survey methodology 社会统计调查 ; 测量方法学 ; 调查方法 ; 进行调研方法Sociological Methodology 社会学方法论 (学术期刊) ; 社会学方法论 ; 社会学方法 ; 社会方法论Research Methodology 研究方法 ; 研究方法论 ; 研究方法学 ; 查找资料方法Political Methodology 政治学方法论 ; 政治方法学 ; 国际政治学 ; 政治方法论simulation methodology 仿真方法学 ; 仿真方法论 ; 模拟方法学 ; 仿真理论方法Qualitative methodology 定性方法论 ; 与质化 ; 质性方法论 ; 定性方法Sales Methodology 销售原则 ; 售准绳 ; 销售方法论instructional methodology 教育方法学 ; 教学方法论体系compaction methodology 充填法 双语例句It is not an either / or methodology.它不仅仅是一个可有可无的方法论。 We turn from methodology and science to politics.我们从方法论和科学转变到政治。 This will help them understand the methodology and decide what portions of it to adopt, in what order, and how quickly.这将帮助他们理解方法论并决定接受新方法的哪一部分，以什么样的顺序，速度多快。 primer英 [‘praɪmə] 美 [‘praɪmɚ]n. 初级读本；识字课本；原始物 词根词根： primadj.primary 主要的；初级的；基本的prime 主要的；最好的；基本的primitive 原始的，远古的；简单的，粗糙的primeval 原始的；初期的（等于primaeval）prim 拘谨的；整洁的；呆板的primal 原始的；主要的；最初的adv.prime 极好地n.primary 原色；最主要者prime 初期；青年；精华；全盛时期primitive 原始人primal 被压抑童年情绪的释放priming 底漆；装雷管；起爆剂；装点火药；装填物primality 原始；首要；根本；素性primitivism 原始主义；尚古主义；原始的风格primness 呆滞；拘谨；一本正经vi.prime 作准备prim 显得一本正经vt.prime 使准备好；填装prim 使显得一本正经；把…打扮得整整齐齐primal 释放（被压抑的童年情绪） 短语Factory primer 工厂底漆 ; 工厂 ; 工厂底漆，工厂防锈漆Epoxy primer 环氧底漆 ; 环氧树脂底漆 ; 环氧底漆shop primer 临时防锈底漆 ; 车间底漆 ; 预涂底漆 ; 防底漆primer lever 起动给油杆 ; 燃油泵上体 ; 起动注油器杆 ; 启动杆forward primer 正向引物 ; 前置引子 ; 计上游引物Foundation Primer 焕颜凝露 ; 妆前霜 ; 妆前乳 ; 经典款Primer Extension 引物延伸 ; 引物延伸法 ; 的有引物延伸法 ; 引物延伸反应metal primer 金属底漆 ; 金属用底补土 ; 金属打底剂finish primer 末道底漆 ; 硝基底漆 双语例句For low-risk pregnancies, sex is considered safe, advises a primer for doctors published this week in the Canadian Medical Association Journal.在这周加拿大医学协会期刊中发布的医生初级读本中建议，低风妊娠中的性生活是安全的。 But Gregory has wisely chosen to reach out to a broader audience by providing a highly accessible primer on the deadly workings of the state that proclaimed itself the workers’ paradise.但格里高利明智地选择面向更广泛的读者，以一部极为通俗易懂的初级读本，来书写这个自称劳动者乐土的国家所行的暴政。 A primer data model with default submission settings could be sent with the form and then edited at each site.可以发送包含默认提交设置的基本数据模型然后在每个站点上进行编辑。 portrait英 [‘pɔːtrɪt] 美 [‘pɔrtrɪt]n. 肖像；描写；半身雕塑像n. (Portrait)人名；(法)波特雷 词根portraitn.portrayal 描绘；画像，肖像portraiture 肖像画；肖像绘制；人像摄影portraitist 肖像画家；人像摄影师portrayer 记述者；描画者；肖像画家 Family Portrait 太阳系全家福 ; 全家福 ; 太阳系全家福 ; 四十不惑Self Portrait Self-Portrait ; 自画像 ; 私相簿 ; 白石草衣图Group portrait 群像portrait mode 纵向模式 ; 肖像模式 ; 画像模式 ; 当使用直向显示PORTRAIT PHOTOS 商业拍摄作品 ; 肖像摄影 ; 人像写真作品 ; 写真照portrait management 纵向管理Head portrait 头像 ; 头像表情 ; 头像embroidered portrait 刺绣肖像 ; 绣像portrait lens 人像镜头 ; 像镜头 双语例句Hang the portrait straight.把画像挂端正。 The portrait of some woman.一些女人的肖像。 The artist has reproduced your features very well in this portrait.这位艺术家在这幅画像中把你的容貌重现得维妙维肖。 landscape英 [‘læn(d)skeɪp] 美 [‘lænd’skep]n. 风景；风景画；景色；山水画；乡村风景画；地形；（文件的）横向打印格式vt. 对…做景观美化，给…做园林美化；从事庭园设计vi. 美化（环境等），使景色宜人；从事景观美化工作，做庭园设计师 词根 landscapen.landscaping 景观美化landscaper 庭园设计家landscapist 风景画家 短语Landscape Design 景观设计 ; 园林设计 ; 风景设计 ; 亚太景观设计cultural landscape 文化景观 ; 人文景观 ; 文化地景 ; 人为景观urban landscape 城市景观 ; 都市景观 ; 城市园林 ; 城市园林绿化landscape plant 园林植物 ; 景观植物 ; 园林植物景观 ; 景观植物landscape lighting 景观照明 ; 景不雅照明 ; 景观灯光 ; 景观亮化Landscape Urbanism 景观都市主义 ; 景观城市主义 ; 城市景观规划 ; 地景都市主义geological landscape 地质景观 ; 广东地质山水酒店 ; 地质地貌hard landscape 硬质景观 ; 设施景观Floating Landscape 恋之风景 ; 恋之风景未剪切版 双语例句Mist often blurs the landscape.薄雾常常使风景暗淡。 The boy painted a landscape on paper.这个男孩子在纸上画了一张风景画。 He thumbtacked the picture of landscape to the wall.他用图钉把那张风景画钉在墙上。 firework英 [‘faɪəwɜːk] 美 [‘faɪɚwɝk]n. 烟火；激烈情绪 forbid英 [fə’bɪd] 美 [fɚ’bɪd]vt. 禁止；不准；不允许；〈正式〉严禁[ 过去式 forbade 过去分词 forbidden 现在分词 forbidding ] prohibit英 [prə(ʊ)’hɪbɪt] 美 [prə’hɪbɪt]vt. 阻止，禁止 ban英 [bæn] 美 [bæn]vt. 禁止，取缔n. 禁令，禁忌 discharge英 [dɪs’tʃɑːdʒ] 美 [dɪs’tʃɑrdʒ]vt. 解雇；卸下；放出；免除vi. 排放；卸货；流出n. 排放；卸货；解雇 kindle英 [‘kɪnd(ə)l] 美 [‘kɪndl]vt. 点燃；激起；照亮vi. 发亮；着火；激动起来 admit英 [əd’mɪt] 美 [əd’mɪt]vt. 承认；准许进入；可容纳vi. 承认；容许 shack英 [ʃæk] 美 [ʃæk]n. 棚屋；小室vi. 居住 emergency英 [ɪ’mɜːdʒ(ə)nsɪ] 美 [ɪ’mɝdʒənsi]n. 紧急情况；突发事件；非常时刻adj. 紧急的；备用的 Emergency department 急症室 ; 急诊室 ; 急诊科 ; 急症室EMERGENCY STOP 紧急停止 ; 异常停止 ; 紧急停机 ; 紧急停车emergency switch 紧急开关 ; 应急开关 ; 紧急保险开关 ; 焚急开关Emergency Alarm 紧急报警 ; 紧急呼救设施 ; 急报警 ; 警报装置emergency case 急诊病人 ; 急救盒 ; 急诊病例 ; 急症emergency goods 急需品 ; 紧急用品 ; 救济品 ; 急用品emergency preparedness 应急准备 ; 紧急状况的准备工作 ; 应急准备状态 ; 应急预案Emergency Ladder 逃生梯 ; 紧急避难梯 ; 应急梯Emergency Phone 紧急呼救电话 ; 紧急电话 ; 急救电话 ; 紧急救护电话 accelerate英 [ək’seləreɪt] 美 [əkˈsɛləˌret]vt. 使……加快；使……增速vi. 加速；促进；增加[ 过去式 accelerated 过去分词 accelerated 现在分词 accelerating ] 词根 accelerateadj.accelerated 加速的；加快的accelerating 促进的，[物] 加速的；催化的accelerative 加速的；促进的；催促的acceleratory 加速的；催促的（等于accelerative）n.acceleration 加速，促进；[物] 加速度accelerator 油门；催化剂；[机] 加速装置accelerometer [航][物] 加速计v.accelerated 加速；促进（accelerate的变形） 同近义词vi. 加速；促进；增加improve , increase speed 短语accelerate increase 加速 ; 加大PC Accelerate 系统加速器Accelerate measures 加快措施accelerate math 渐进数学里accelerate time 加速时间 ; 加速时间Accelerate Events 加速事件table accelerate 工作台导槽accelerate to 加速accelerate card 加速卡 双语例句How do you plan to accelerate the development of these technologies?目前您打算如何加快这方面的技术研发？ At that point, post 2012, the social software market growth will accelerate as will the overall impact of social media on business and society.在这一点上，社区软件市场在2012年以后将加速增长，使得社区媒体对企业和社会产生全面的冲击。 Or you can choose to accelerate your growth and intentionally devour life and all it offers.又或许你可以选择加速自己的成长，故意地挥霍生活及其提供的一切。 anatomy英 [ə’nætəmɪ] 美 [ə’nætəmi]n. 解剖；解剖学；剖析；骨骼[ 复数 anatomies ] 词根词根： anatomyadj.anatomical 解剖的；解剖学的；结构上的anatomic 组织的；解剖学上的；结构上的adv.anatomically 结构上；解剖学上n.anatomist 解剖学家；剖析者vt.anatomise 解剖；解析anatomize 解剖；仔细分析 同近义词n. [解剖]解剖；解剖学；剖析；骨骼cadre , dissection 短语Human Anatomy 人体解剖学 ; 人体解剖学 ; 人体解剖高尺寸图片 ; 解剖学plant anatomy 植物解剖学 ; 植物形态解剖学 ; 植物解剖Regional Anatomy 局部解剖学 ; 局部解剖 ; 人体解剖学 ; 解剖学Greys Anatomy 实习医生格蕾 ; 实习女医生葛蕾斯 ; 外科女实习生 ; 实习医生sectional anatomy 断层解剖学 ; 断面解剖 ; 断层解剖 ; 断面解剖学topographic anatomy 局部解剖学 ; 外部解剖学 ; 局部解剖学;局部解剖学System Anatomy 系统分析 ; 系统解剖学 ; 系统剖析 ; 解剖Medical Anatomy 医学解剖 ; 医用解剖学 ; 医学解剖学 ; 医学解剖学imaging anatomy 影像解剖 ; 影像解剖学 ; 影象解剖学 ; 影像解剖学 双语例句A knowledge of anatomy adds to the appreciation of works of art.解剖学知识有助于提高对艺术作品的鉴赏力。 Now that you have seen the anatomy of each component, you can deploy them.您已经了解了对每个组件的剖析，现在可以部署它们了。 I don’t aim to be comprehensive, but to convey something of what continues to fascinate me about the wonderful subject of human anatomy.我的目的不在于广泛全面的介绍身体各部位，而是传达一些一直吸引着我的关于人体解剖学的东西。 Reinvent英 [ˌri:ɪnˈvent] 美 [ˌriɪnˈvɛnt]vt. 重新使用；彻底改造；重复发明（在不知他人已发明的情况下） 词根invent 同近义词vt. 重新使用；彻底改造；重复发明（在不知他人已发明的情况下）reemploy 短语REINVENT CONTINUOUSLY 不断创新function reinvent 职能重塑Reinvent Payphones 重塑电话亭reinvent HP 再造惠普Reinvent themselves 重塑自我Reinvent Yourself 重塑自我reinvent oneself 改过自新reinvent government 彻底改造To Reinvent An Industry 产业模式创新 双语例句In short, we need to reinvent the toilet.简而言之，我们需要彻底改造马桶。 I will try my best to reinvent my own life.我愿尽力彻底改造自己的生活。 We need not reinvent ourselves, but only remember who we are when we are at our best.我们无须彻底改变自己，只是在我们到达巅峰时不要忘了我们是谁。 sustainable英 [sə’steɪnəb(ə)l] 美 [sə’stenəbl]adj. 可以忍受的；足可支撑的；养得起的；可持续的 词根词根： sustainadj.sustained 持续的；持久的；持久不变的sustentacular 支撑的；支持的n.sustainability 持续性；永续性；能维持性sustainer 支持者，维持者；主发动机；支撑的人物sustentation 支撑，维持；食物v.sustained 维持（sustain的过去式和过去分词）；承受vt.sustain 维持；支撑，承担；忍受；供养；证实 短语Sustainable Agriculture 可持续农业 ; 永续农业 ; 持续农业 ; 持久农业sustainable tourism 可持续旅游 ; 永续旅游 ; 永续观光 ; 第十单元Sustainable Construction 可持续建筑 ; 可持续建设 ; 可持续性建筑管理 ; 永续建筑commercially sustainable 商业化可持续Sustainable Luxury 可持续性奢侈 ; 性奢侈 ; 可继续性朴素Sustainable innovation 持续创新 ; 可持续创新 ; 永续创新 ; 可持续创新Sustainable Urbanization 可持续城市化 ; 可持续城镇化 ; 可持续城市化 ; 可持续的城市化Sustainable Financing 可持续性融资 ; 可持续融资 ; 可持续金融 ; 可持续融资Sustainable Transportation 永续运输 ; 可持续交通 ; 绿色技术 ; 可持续交通运输 双语例句“There is nothing sustainable about it, “ she said.“这里没有什么是可持续的，”她说。 “To make our agriculture sustainable, we have to do this,” he said.”Ninety percent of the country is like this, all hills.“要让我们的农业可持续地发展，我们只能这样做，”他说，“我们的土地百分之九十都是这样，满目皆山。 Working together to provide fresh, sustainable food for the community is one of the hot trends in some community organizations.一起工作，为社区提供新鲜的，可持续的食物，这是一些社区组织热门趋势之一。 supplesupple英 [‘sʌp(ə)l] 美 [‘sʌpl]adj. 柔软的；灵活的；顺从的；易弯曲的；逢迎的vt. 使柔软；使顺从vi. 变柔顺；变柔软n. (Supple)人名；(意、西)苏普莱[ 比较级 suppler 最高级 supplest 过去式 suppled 过去分词 suppled 现在分词 suppling ] 词根词根： supplen.suppleness 柔软；易弯曲；顺从 同近义词adj. 柔软的；灵活的；顺从的；易弯曲的；逢迎的flexible , soft , elastic , tender , ductilevt. 使柔软；使顺从reconcile , conformvi. 变柔顺；变柔软tender , limber up 短语Supple leather 软革 ; 软革SUPPLE BEAR 绵尾熊Supple Round 柔顺圆润supple suede 软山羊皮supple mdinedriing 活性资料SUPPLE MIST 防锈剂Supple Skin 柔软皮肤supple nature 容易适应的本性Ultra supple 超柔 双语例句Cultivating a humorous mindset helps you see yourself and any situation with a more supple mind so that you are not locked into a negative view.培养幽默的心态有助于你了解自己，而且无论在什么状况下都能有一个灵活的头脑，这样就不会局限在消极的观点中无法自拔。 I often do yoga, so I’m quite supple.我常常做瑜伽，所以我的身体很柔软。 Moisturizer is the key to soft, supple skin in winter.在冬季，润肤霜是保持皮肤柔软细滑的密钥。 vigor英 美 [‘vɪgɚ]n. [生物] 活力，精力n. (Vigor)人名；(英、法)维戈尔 词根词根： vigoradj.vigorous 有力的；精力充沛的adv.vigorously 精神旺盛地，活泼地n.vigour 活力；气势 同近义词n. [生物]活力，精力energy , vitality , spring , steam , razzamatazz 短语Vigor Bovolenta 博沃伦塔Vigor index 活力指数 ; 活力指数 ; 活力指标Vigor Board 活力板 ; 活力板germination vigor 发芽势 ; 发芽活力 ; 萌发势Hotel Vigor 活力酒店vigor become 成为活力 ; 活力成为Totemic Vigor 图腾活力tree vigor 树势 ; 树木长势lacking vigor 虚弱的 双语例句If you want to retain youthful vigor,you have to take regular exercise.如果你想保持青春活力，你就得经常锻炼。 In fact, the huge inheritance does not do him any good, but tends to undermine his vigor and passion for life.实际上，这么大笔的遗产对他不仅没有什么好处，反而会损害他的活力和对生活的激情。 They would be lying there in the tree like, ‘Oh, just let me just die up here, ‘ because they lacked any kind of vigor.因为它们一点活力都没有, 他们会整天在树下躺着，一付‘噢，实在活不起了，让我死在这里好了’的样子。 temperamental英 [,temp(ə)rə’ment(ə)l] 美 [‘tɛmprə’mɛntl]adj. 喜怒无常的；性情的；易兴奋的[ 比较级 more temperamental 最高级 most temperamental ] 词根词根： temperadv.temperamentally 气质地n.temper 脾气；（钢等）回火；性情；倾向temperament 气质，性情，性格；急躁vi.temper 回火；调和vt.temper 使回火；锻炼；调和；使缓和 同近义词adj. 喜怒无常的；性情的；易兴奋的moody , twittery 短语Temperamental Side 气质一面temperamental life 气性生命temperamental weather 变幻无常的天气temperamental characteristics 性格特点temperamental trait 气质特性 ; 以气质特质temperamental fit 性情相投Amante Temperamental 德国摇滚temperamental character 性格特征Temperamental behaviour 情绪起伏大 双语例句What makes them laugh and cry, why are they temperamental, why are they so difficult to get along with, what do they really want?是什么让他们欢笑和哭泣，为什么他们喜怒无常，为什么他们这么难相处，他们到底想要什么？ Stress, such as that found in disrupted families, seems to impair the ability of temperamental children to adapt to their surroundings, the greater the amount of stress, the less well they adapt.压力，比如在破裂家庭中产生的压力，似乎削弱了这些喜怒无常的孩子们适应环境的能力，压力越大，他们适应环境的能力越弱。 Companionshipcompanionship英 [kəm’pænjənʃɪp] 美 [kəm’pænjən’ʃɪp]n. 友谊；陪伴；交谊 词根词根： companyadj.companionable 好交往的；友善的；适于做朋友的n.company 公司；陪伴，同伴；连队companion 同伴；朋友；指南；手册vi.company 交往vt.company 陪伴companion 陪伴 同近义词n. 友谊；陪伴；交谊friendship , fellowship 短语companionship family 友爱家庭Genuine Companionship 真正友谊And Companionship 和陪伴Peer Companionship 同伴陪同Quiet Companionship 安静相伴Social companionship 社会成员身份Some Companionship 有人陪伴Your Companionship 您一路陪同companionship therapy 友谊疗法 ; 友谊心理治疗 双语例句Don’t ask your friends for advice; ask for companionship and encouragement.不要向你的朋友咨询建议；而是寻求友谊和鼓励。 But people who watched for companionship were most distressed by the loss of their shows.但是那些寻求友谊的人们会因为失去喜欢的电视节目而非常痛苦。 Also, treatment should be voluntary as far as possible, while service users should have plenty of contact and companionship with other service users.另外，应当尽可能做到自愿接受治疗，而且服务使用者应当与使用服务的其他人有广泛的联系和友谊。 conservative英 [kən’sɜːvətɪv] 美 [kən’sɝvətɪv]adj. 保守的n. 保守派，守旧者[ 比较级 more conservative 最高级 most conservative ] 词根： conservedadj.conserved 保守的adv.conservatively 谨慎地；保存地；适当地n.conservation 保存，保持；保护conservatism 保守主义；守旧性conservationist 自然资源保护论者v.conserved 保存；保全（conserve的过去式） 同近义词adj. 保守的standpat , backward-lookingn. 保守派，守旧者old guard , pontificator 短语Conservative liberalism 保守自由主义 ; 保守自由主义Force conservative 保守力conservative treatment 保守治疗 ; 保守疗法 ; 非手术治疗 ; 保守性治疗conservative recombination 保守重组 ; 保守性重组conservative property 守恒性质 ; 保守性 ; 保守性质conservative replacement 保守替换 ; 保守(性)替换，保存性置换conservative field 保守场 ; 保守力场 ; 守恒场 ; 保守向量场conservative prediction 保守预测 ; 保守预测值Conservative transposition 保守型转座 ; 保守性转座 ; 保守转座 ; 保存型转位 双语例句He listed himself as a conservative.他自称是一个保守主义者。《21世纪大英汉词典》The more conservative politicians were trying to deradicalize the liberation movement.较保守的政治家正试图使解放运动放弃偏激的立场。《21世纪大英汉词典》The young people are the most eager to learn and the least conservative in their thinking.青年人最肯学习，最少保守思想。《新英汉大辞典》","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"Beautiful articles of English","date":"2017-02-21T12:25:05.000Z","path":"2017/02/21/MyView/English/beautiful-article-of-english/","text":"Youth 001 青春http://down010702.tingclass.net/lesson/shi0529/0001/1613/01-youth.mp3 Youth is not a time of life; it is a state of mind; it is not a matter of rosy cheeks, red lips and supple knees; it is a matter of the will, a quality of the imagination, a vigor of the emotions; it is the freshness of the deep springs of life. 青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志，恢宏的想象，炙热的恋情；青春是生命的深泉在涌流。 Youth means a temperamental predominance of courage over timidity, of the appetite for adventure over the love of ease. This often exists in a man of 60 more than a boy of 20. Nobody grows old merely by a number of years. We grow old by deserting our ideals. 青春气贯长虹，勇锐盖过怯弱，进取压倒苟安。如此锐气，二十后生而有之，六旬男子则更多见。年岁有加，并非垂老，理想丢弃，方堕暮年。 Years may wrinkle the skin, but to give up enthusiasm wrinkles the soul. Worry, fear, self-distrust bows the heart and turns the spirit back to dust. 岁月悠悠，衰微只及肌肤；热忱抛却，颓废必致灵魂忧烦，惶恐，丧失自信，定使心灵扭曲，意气如灰。 Whether 60 or 16, there is in every human being’s heart the lure of wonders, the unfailing child appetite for what’s next and the joy of the game of living. In the center of your heart and my heart, there is a wireless station; so long as it receives messages of beauty, hope, cheer, courage and power from man and from the infinite, so long as you are young. 无论年届花甲，拟或二八芳龄，心中皆有生命之欢乐，奇迹之诱惑，孩童般天真久盛不衰。人人心中皆有一台天线，只要你从天上人间接受美好、希望、欢乐、勇气和力量的信号，你就青春永驻，风华常存。 When your aerials are down, and your spirit is covered with snows of cynicism and the ice of pessimism, then you’ve grown old, even at 20; but as long as your aerials are up, to catch waves of optimism, there’s hope you may die young at 80. 一旦天线下降，锐气便被冰雪覆盖，玩世不恭、自暴自弃油然而生，即使年方二十，实已垂垂老矣；然则只要树起天线，捕捉乐观信号，你就有望在八十高龄告别尘寰时仍觉年轻。 002 Three Days to See(Excerpts)假如给我三天光明(节选) Three Days to Seehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/02-three_days_to_see.mp3 All of us have read thrilling stories in which the hero had only a limited and specified time to live. Sometimes it was as long as a year, sometimes as short as 24 hours. But always we were interested in discovering just how the doomed hero chose to spend his last days or his last hours. I speak, of course, of free men who have a choice, not condemned criminals whose sphere of activities is strictly delimited. 我们都读过震撼人心的故事，故事中的主人公只能再活一段很有限的时光，有时长达一年，有时却短至一日。但我们总是想要知道，注定要离世人的会选择如何度过自己最后的时光。当然，我说的是那些有选择权利的自由人，而不是那些活动范围受到严格限定的死囚。 Such stories set us thinking, wondering what we should do under similar circumstances. What events, what experiences, what associations should we crowd into those last hours as mortal beings, What happiness should we find in reviewing the past? What regrets? 这样的故事让我们思考，在类似的处境下，我们该做些什么?作为终有一死的人，在临终前的几个小时内我们应该做什么事，经历些什么或做哪些联想?回忆往昔，什么使我们开心快乐?什么又使我们悔恨不已? Sometimes I have thought it would be an excellent rule to live each day as if we should die tomorrow. Such an attitude would emphasize sharply the values of life. We should live each day with gentleness, vigor and a keenness of appreciation which are often lost when time stretches before us in the constant panorama of more days and months and years to come. There are those, of course, who would adopt the Epicurean motto of “Eat, drink, and be merry”. But most people would be chastened by the certainty of impending death. 有时我想，把每天都当作生命中的最后一天来边，也不失为一个极好的生活法则。这种态度会使人格外重视生命的价值。我们每天都应该以优雅的姿态，充沛的精力，抱着感恩之心来生活。但当时间以无休止的日，月和年在我们面前流逝时，我们却常常没有了这种子感觉。当然，也有人奉行“吃，喝，享受”的享乐主义信条，但绝大多数人还是会受到即将到来的死亡的惩罚。 In stories the doomed hero is usually saved at the last minute by some stroke of fortune, but almost always his sense of values is changed. He becomes more appreciative of the meaning of life and its permanent spiritual values. It has often been noted that those who live, or have lived, in the shadow of death bring a mellow sweetness to everything they do. 在故事中，将死的主人公通常都在最后一刻因突降的幸运而获救，但他的价值观通常都会改变，他变得更加理解生命的意义及其永恒的精神价值。我们常常注意到，那些生活在或曾经生活在死亡阴影下的人无论做什么都会感到幸福。 Most of us, however, take life for granted. We know that one day we must die, but usually we picture that day as far in the future. When we are in buoyant health, death is all but unimaginable. We seldom think of it. The days stretch out in an endless vista. So we go about our petty tasks, hardly aware of our listless attitude toward life. 然而，我们中的大多数人都把生命看成是理所当然的。我们知道有一天我们必将面对死亡，但总认为那一天还在遥远的将来。当我们身强体健之时，死亡简直不可想象，我们很少考虑到它。日子多得好像没有尽头。因此我们一味忙于琐事，几乎意识不到我们对待生活的冷漠态度。 The same lethargy, I am afraid, characterizes the use of all our faculties and senses. Only the deaf appreciate hearing, only the blind realize the manifold blessings that lie in sight. Particularly does this observation apply to those who have lost sight and hearing in adult life. But those who have never suffered impairment of sight or hearing seldom make the fullest use of these blessed faculties. Their eyes and ears take in all sights and sounds hazily, without concentration and with little appreciation. It is the same old story of not being grateful for what we have until we lose it, of not being conscious of health until we are ill. 我担心同样的冷漠也存在于我们对自己官能和意识的运用上。只有聋子才理解听力的重要，只有盲人才明白视觉的可贵，这尤其适用于那些成年后才失去视力或听力之苦的人很少充分利用这些宝贵的能力。他们的眼睛和耳朵模糊地感受着周围的景物与声音，心不在焉，也无所感激。这正好我们只有在失去后才懂得珍惜一样，我们只有在生病后才意识到健康的可贵。 I have often thought it would be a blessing if each human being were stricken blind and deaf for a few days at some time during his early adult life. Darkness would make him more appreciative of sight; silence would teach him the joys of sound. 我经常想，如果每个人在年轻的时候都有几天失时失聪，也不失为一件幸事。黑暗将使他更加感激光明，寂静将告诉他声音的美妙。 003 Companionship of Books 以书为伴 Companionship of Bookshttp://down010702.tingclass.net/lesson/shi0529/0001/1613/03-companionship_of_books.mp3 A man may usually be known by the books he reads as well as by the company he keeps; for there is a companionship of books as well as of men; and one should always live in the best company, whether it be of books or of men. 通常看一个读些什么书就可知道他的为人，就像看他同什么人交往就可知道他的为人一样，因为有人以人为伴，也有人以书为伴。无论是书友还是朋友，我们都应该以最好的为伴。 A good book may be among the best of friends.It is the same today that it always was, and it will never change. It is the most patient and cheerful of companions. It does not turn its back upon us in times of adversity or distress. It always receives us with the same kindness; amusing and instructing us in youth, and comforting and consoling us in age. 好书就像是你最好的朋友。它始终不渝，过去如此，现在如此，将来也永远不变。它是最有耐心，最令人愉悦的伴侣。在我们穷愁潦倒，临危遭难时，它也不会抛弃我们，对我们总是一如既往地亲切。在我们年轻时，好书陶冶我们的性情，增长我们的知识；到我们年老时，它又给我们以慰藉和勉励。 Men often discover their affinity to each other by the mutual love they have for a book just as two persons sometimes discover a friend by the admiration which both entertain for a third. There is an old proverb, ‘Love me, love my dog.” But there is more wisdom in this:” Love me, love my book.” The book is a truer and higher bond of union. Men can think, feel, and sympathize with each other through their favorite author. They live in him together, and he in them. 人们常常因为喜欢同一本书而结为知已，就像有时两个人因为敬慕同一个人而成为朋友一样。有句古谚说道：“爱屋及屋。”其实“爱我及书”这句话蕴涵更多的哲理。书是更为真诚而高尚的情谊纽带。人们可以通过共同喜爱的作家沟通思想，交流感情，彼此息息相通，并与自己喜欢的作家思想相通，情感相融。 A good book is often the best urn of a life enshrining the best that life could think out; for the world of a man’s life is, for the most part, but the world of his thoughts. Thus the best books are treasuries of good words, the golden thoughts, which, remembered and cherished, become our constant companions and comforters. 好书常如最精美的宝器，珍藏着人生的思想的精华，因为人生的境界主要就在于其思想的境界。因此，最好的书是金玉良言和崇高思想的宝库，这些良言和思想若铭记于心并多加珍视，就会成为我们忠实的伴侣和永恒的慰藉。 Books possess an essence of immortality. They are by far the most lasting products of human effort. Temples and statues decay, but books survive. Time is of no account with great thoughts, which are as fresh today as when they first passed through their author’s minds, ages ago. What was then said and thought still speaks to us as vividly as ever from the printed page. The only effect of time have been to sift out the bad products; for nothing in literature can long survive e but what is really good. 书籍具有不朽的本质，是为人类努力创造的最为持久的成果。寺庙会倒坍，神像会朽烂，而书却经久长存。对于伟大的思想来说，时间是无关紧要的。多年前初次闪现于作者脑海的伟大思想今日依然清新如故。时间惟一的作用是淘汰不好的作品，因为只有真正的佳作才能经世长存。 Books introduce us into the best society; they bring us into the presence of the greatest minds that have ever lived. We hear what they said and did; we see the as if they were really alive; we sympathize with them, enjoy with them, grieve with them; their experience becomes ours, and we feel as if we were in a measure actors with them in the scenes which they describe. 书籍介绍我们与最优秀的人为伍，使我们置身于历代伟人巨匠之间，如闻其声，如观其行，如见其人，同他们情感交融，悲喜与共，感同身受。我们觉得自己仿佛在作者所描绘的舞台上和他们一起粉墨登场。 The great and good do not die, even in this world. Embalmed in books, their spirits walk abroad. The book is a living voice. It is an intellect to which on still listens. 即使在人世间，伟大杰出的人物也永生不来。他们的精神被载入书册，传于四海。书是人生至今仍在聆听的智慧之声，永远充满着活力。 004 If I Rest,I Rust 如果我休息，我就会生锈 If I Rest, I Rusthttp://down010702.tingclass.net/lesson/shi0529/0001/1613/04-if_i_rest,i_rust.mp3 The significant inscription found on an old key—“If I rest, I rust”—would be an excellent motto for those who are afflicted with the slightest bit of idleness. Even the most industrious person might adopt it with advantage to serve as a reminder that, if one allows his faculties to rest, like the iron in the unused key, they will soon show signs of rust and, ultimately, cannot do the work required of them. 在一把旧钥匙上发现了一则意义深远的铭文——如果我休息，我就会生锈。对于那些懒散而烦恼的人来说，这将是至理名言。甚至最为勤勉的人也以此作为警示：如果一个人有才能而不用，就像废弃钥匙上的铁一样，这些才能就会很快生锈，并最终无法完成安排给自己的工作。 Those who would attain the heights reached and kept by great men must keep their faculties polished by constant use, so that they may unlock the doors of knowledge, the gate that guard the entrances to the professions, to science, art, literature, agriculture—every department of human endeavor. 有些人想取得伟人所获得并保持的成就，他们就必须不断运用自身才能，以便开启知识的大门，即那些通往人类努力探求的各个领域的大门，这些领域包括各种职业：科学，艺术，文学，农业等。 Industry keeps bright the key that opens the treasury of achievement. If Hugh Miller, after toiling all day in a quarry, had devoted his evenings to rest and recreation, he would never have become a famous geologist. The celebrated mathematician, Edmund Stone, would never have published a mathematical dictionary, never have found the key to science of mathematics, if he had given his spare moments to idleness, had the little Scotch lad, Ferguson, allowed the busy brain to go to sleep while he tended sheep on the hillside instead of calculating the position of the stars by a string of beads, he would never have become a famous astronomer. 勤奋使开启成功宝库的钥匙保持光亮。如果休·米勒在采石场劳作一天后，晚上的时光用来休息消遣的话，他就不会成为名垂青史的地质学家。著名数学家爱德蒙·斯通如果闲暇时无所事事，就不会出版数学词典，也不会发现开启数学之门的钥匙。如果苏格兰青年弗格森在山坡上放羊时，让他那思维活跃的大脑处于休息状态，而不是借助一串珠子计算星星的位置，他就不会成为著名的天文学家。 Labor vanquishes all—not inconstant, spasmodic, or ill-directed labor; but faithful, unremitting, daily effort toward a well-directed purpose. Just as truly as eternal vigilance is the price of liberty, so is eternal industry the price of noble and enduring success. 劳动征服一切。这里所指的劳动不是断断续续的，间歇性的或方向偏差的劳动，而是坚定的，不懈的，方向正确的每日劳动。正如要想拥有自由就要时刻保持警惕一样，要想取得伟大的，持久的成功，就必须坚持不懈地努力。 005 Ambition 抱负 Ambitionhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/05-ambition.mp3 It is not difficult to imagine a world short of ambition. It would probably be a kinder world: with out demands, without abrasions, without disappointments. People would have time for reflection. Such work as they did would not be for themselves but for the collectivity. Competition would never enter in. conflict would be eliminated, tension become a thing of the past. The stress of creation would be at an end. Art would no longer be troubling, but purely celebratory in its functions. Longevity would be increased, for fewer people would die of heart attack or stroke caused by tumultuous endeavor. Anxiety would be extinct. Time would stretch on and on, with ambition long departed from the human heart. 一个缺乏抱负的世界将会怎样，这不难想象。或许，这将是一个更为友善的世界：没有渴求，没有磨擦，没有失望。人们将有时间进行反思。他们所从事的工作将不是为了他们自身，而是为了整个集体。竞争永远不会介入；冲突将被消除。人们的紧张关系将成为过往云烟。创造的重压将得以终结。艺术将不再惹人费神，其功能将纯粹为了庆典。人的寿命将会更长，因为由激烈拼争引起的心脏病和中风所导致的死亡将越来越少。焦虑将会消失。时光流逝，抱负却早已远离人心。 Ah, how unrelieved boring life would be! 啊，长此以往人生将变得多么乏味无聊！ There is a strong view that holds that success is a myth, and ambition therefore a sham. Does this mean that success does not really exist? That achievement is at bottom empty? That the efforts of men and women are of no significance alongside the force of movements and events now not all success, obviously, is worth esteeming, nor all ambition worth cultivating. Which are and which are not is something one soon enough learns on one’s own. But even the most cynical secretly admit that success exists; that achievement counts for a great deal; and that the true myth is that the actions of men and women are useless. To believe otherwise is to take on a point of view that is likely to be deranging. It is, in its implications, to remove all motives for competence, interest in attainment, and regard for posterity. 有一种盛行的观点认为，成功是一种神话，因此抱负亦属虚幻。这是不是说实际上并不丰在成功？成就本身就是一场空？与诸多运动和事件的力量相比，男男女女的努力显得微不足？显然，并非所有的成功都值得景仰，也并非所有的抱负都值得追求。对值得和不值得的选择，一个人自然而然很快就能学会。但即使是最为愤世嫉俗的人暗地里也承认，成功确实存在，成就的意义举足轻重，而把世上男男女女的所作所为说成是徒劳无功才是真正的无稽之谈。认为成功不存在的观点很可能造成混乱。这种观点的本意是一笔勾销所有提高能力的动机，求取业绩的兴趣和对子孙后代的关注。 We do not choose to be born. We do not choose our parents. We do not choose our historical epoch, the country of our birth, or the immediate circumstances of our upbringing. We do not, most of us, choose to die; nor do we choose the time or conditions of our death. But within all this realm of choicelessness, we do choose how we shall live: courageously or in cowardice, honorably or dishonorably, with purpose or in drift. We decide what is important and what is trivial in life. We decide that what makes us significant is either what we do or what we refuse to do. But no matter how indifferent the universe may be to our choices and decisions, these choices and decisions are ours to make. We decide. We choose. And as we decide and choose, so are our lives formed. In the end, forming our own destiny is what ambition is about. 我们无法选择出生，无法选择父母，无法选择出生的历史时期与国家，或是成长的周遭环境。我们大多数人都无法选择死亡，无法选择死亡的时间或条件。但是在这些无法选择之中，我们的确可以选择自己的生活方式：是勇敢无畏还是胆小怯懦，是光明磊落还是厚颜无耻，是目标坚定还是随波逐流。我们决定生活中哪些至关重要，哪些微不足道。我们决定，用以显示我们自身重要性的，不是我们做了什么，就是我们拒绝做些什么。但是不论世界对我们所做的选择和决定有多么漠不关心，这些选择和决定终究是我们自己做出的。我们决定，我们选择。而当我们决定和选择时，我们的生活便得以形成。最终构筑我们命运的就是抱负之所在。 006 What I have Lived for 我为何而生 What I Have Lived For http://down010702.tingclass.net/lesson/shi0529/0001/1613/06-what_i_have_lived_for.mp3 Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. These passions, like great winds, have blown me hither and thither, in a wayward course, over a deep ocean of anguish, reaching to the very verge of despair. 我的一生被三种简单却又无比强烈的激情所控制：对爱的渴望，对知识的探索和对人类苦难难以抑制的怜悯。这些激情像狂风，把我恣情吹向四方，掠过苦痛的大海，迫使我濒临绝望的边缘。 I have sought love, first, because it brings ecstasy—ecstasy so great that I would often have sacrificed all the rest of my life for a few hours for this joy. I have sought it, next, because it relieves loneliness—that terrible loneliness in which one shivering consciousness looks over the rim of the world into the cold unfathomable lifeless abyss. I have sought it, finally, because in the union of love I have seen, in a mystic miniature, the prefiguring vision of the heaven that saints and poets have imagined. This is what I sought, and though it might seem too good for human life, this is what—at last—I have found. 我寻求爱，首先因为它使我心为之着迷，这种难以名状的美妙迷醉使我愿意用所有的余生去换取哪怕几个小时这样的幸福。我寻求爱，还因为它能缓解我心理上的孤独中，我感觉心灵的战栗，仿如站在世界的边缘而面前是冰冷，无底的死亡深渊。我寻求爱，因为在我所目睹的结合中，我仿佛看到了圣贤与诗人们所向往的天堂之景。这就是我所寻找的，虽然对人的一生而言似乎有些遥不可及，但至少是我用尽一生所领悟到的。 With equal passion I have sought knowledge. I have wished to understand the hearts of men. I have wished to know why the stars shine. And I have tried to apprehend the Pythagorean power by which number holds sway above the flux. A little of this, but not much, I have achieved. 我用同样的激情去寻求知识。我希望能理解人类的心灵，希望能够知道群星闪烁的缘由。我试图领悟毕达哥拉斯所景仰的“数即万物”的思想。我已经悟出了其中的一点点道理，尽管并不是很多。 Love and knowledge, so far as they were possible, led upward toward the heavens. But always it brought me back to earth. Echoes of cries of pain reverberate in my heart. Children in famine, victims tortured by oppressors, helpless old people a hated burden to their sons, and the whole world of loneliness, poverty, and pain make a mockery of what human life should be. I long to alleviate the evil, but I cannot, and I too suffer. 爱和知识，用它们的力量把人引向天堂。但是同情却总把人又拽回到尘世中来。痛苦的呼喊声回荡在我的内心。饥饿的孩子，受压迫的难民，贫穷和痛苦的世界，都是对人类所憧憬的美好生活的无情嘲弄。我渴望能够减少邪恶，但是我无能为力，我也难逃其折磨。 This has been my life. I have found it worth living, and would gladly live it again if the chance were offered me. 这就是我的一生。我已经找到它的价值。而且如果有机会，我很愿意能再活它一次。 007 When Love Beckons You 爱的召唤 When Love Beckons Youhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/07-when_love_beckons_you.mp3 When love beckons to you, follow him, though his ways are hard and steep. And when his wings enfold you, yield to him, though the sword hidden among his pinions may wound you. And when he speaks to you, believe in him, though his voice may shatter your dreams as the north wind lays waste the garden. 当爱召唤你时，请追随她，尽管爱的道路艰难险峻。当爱的羽翼拥抱你时，请顺从她，尽管隐藏在其羽翼之下的剑可能会伤到你。当爱向你诉说时，请相信她，尽管她的声音可能打破你的梦想，就如同北风吹落花园里所有的花瓣。 For even as love crowns you so shall he crucify you. Even as he is for your growth so is he for your pruning. Even as he ascends to your height and caresses your tenderest branches that quiver in the sun, so shall he descend to our roots and shake them in their clinging to the earth. 爱会给你戴上桂冠，也会折磨你。爱会助你成长，也会给你修枝。爱会上升到枝头，抚爱你在阳光下颤动力的嫩枝，也会下潜至根部，撼动力你紧抓泥土的根基。 But if, in your fear, you would seek only love’s peace and love’s pleasure, then it is better for you that you cover your nakedness and pass out of love’s threshing-floor, into the seasonless world where you shall laugh, but not all of your laughter, and weep, but not all of your tears. Love gives naught but it self and takes naught but from itself. Love possesses not, nor would it be possessed, for love is sufficient unto love. 但是，如果你在恐惧之中只想寻求爱的平和与快乐，那你就最好掩盖真实的自我，避开爱的考验，进入不分季节的世界，在那里你将欢笑，但并非开怀大笑，你将哭泣，但并非尽情地哭。爱只将自己付出，也只得到自己。爱一无所有，也不会为谁所有，因为爱本身就已自足。 Love has no other desire but to fulfill itself. But if you love and must have desires, let these be your desires: 爱除了实现自我别无他求。但是如果你爱而又不得不有所求，那就请期望： To melt and be like a running brook that sings its melody to the night. 将自己融化并像奔流的溪水一般向夜晚吟唱自己优美的曲调。 To know the pain of too much tenderness. 明了过多的温柔所带来的苦痛。 To be wounded by your own understanding of love; 被自己对爱的理解所伤害； And to bleed willingly and joyfully. 并情愿快乐地悲伤。 To wake at dawn with a winged heart and give thanks for another day of loving; 在黎明带着轻快的心醒来并感谢又一个有家的日子； To rest at the noon hour and meditate love’s ecstasy; 在中午的小憩时间思考爱的美妙； To return home at eventide with gratitude; 在黄昏怀着感恩之心回家； And then to sleep with a payer for the beloved in your heart and a song of praise upon your lips. 然后为内心所爱之人祈祷，吟唱赞美之歌，并带着祷告和歌声入眠。 008 The Road to Success 成功之道 The Road to Successhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/08-the_road_to_success.mp3 It is well that young men should begin at the beginning and occupy the most subordinate positions. Many of the leading businessmen of Pittsburgh had a serious responsibility thrust upon them at the very threshold of their career. They were introduced to the broom, and spent the first hours of their business lives sweeping out the office. I notice we have janitors and janitresses now in offices, and our young men unfortunately miss that salutary branch of business education. But if by chance the professional sweeper is absent any morning, the boy who has the genius of the future partner in him will not hesitate to try his hand at the broom. It does not hurt the newest comer to sweep out the office if necessary. I was one of those sweepers myself. 年轻人创业之初，应该从最底层干起，这是件好事。匹兹保有很多商业巨头，在他们创业之初，都肩负过“重任”：他们以扫帚相伴，以打扫办公室的方式度过了他们商业生涯中最初的时光。我注意到我们现在办公室里都有工友，于是年轻人就不幸错过了商业教育中这个有益的环节。如果碰巧哪天上午专职扫地的工友没有来，某个具有未来合伙人气质的年轻人会毫不犹豫地试着拿起扫帚。在必要时新来的员工扫扫地也无妨，不会因为而有什么损失。我自己就曾经扫过地。 Assuming that you have all obtained employment and are fairly started, my advice to you is “aim high”. I would not give a fig for the young man who does not already see himself the partner or the head of an important firm. Do not rest content for a moment in your thoughts as head clerk, or foreman, or general manager in any concern, no matter how extensive. Say to yourself, “My place is at the top.” Be king in your dreams. 假如你已经被录用，并且有了一个良好的开端，我对你的建议是：要志存高远。一个年轻人，如果不把自己想象成一家大公司未来的老板或者是合伙人，那我会对他不屑一顾。不论职位有多高，你的内心都不要满足于做一个总管，领班或者总经理。要对自己说：我要迈向顶尖！要做就做你梦想中的国王！ And here is the prime condition of success, the great secret: concentrate your energy, thought, and capital exclusively upon the business in which you are engaged. Having begun in one line, resolve to fight it out on that line, to lead in it, adopt every improvement, have the best machinery, and know the most about it. 成功的首要条件和最大秘诀就是：把你的精力，思想和资本全都集中在你正从事的事业上。一旦开始从事某种职业，就要下定决心在那一领域闯出一片天地来；做这一行的领导人物，采纳每一点改进之心，采用最优良的设备，对专业知识熟稔于心。 The concerns which fail are those which have scattered their capital, which means that they have scattered their brains also. They have investments in this, or that, or the other, here there, and everywhere. “Don’t put all your eggs in one basket.” is all wrong. I tell you to “put all your eggs in one basket, and then watch that basket.” Look round you and take notice, men who do that not often fail. It is easy to watch and carry the one basket. It is trying to carry too many baskets that breaks most eggs in this country. He who carries three baskets must put one on his head, which is apt to tumble and trip him up. One fault of the American businessman is lack of concentration. 一些公司的失败就在于他们分散了资金，因为这就意味着分散了他们的精力。他们向这方面投资，又向那方面投资；在这里投资，在那里投资，到处都投资。“不要把所有的鸡蛋放在一个篮子里”的说法大错特错。我要对你说：“把所有的鸡蛋都放在一个篮子里，然后小心地看好那个篮子。”看看你周围，你会注意到：这么做的人其实很少失败。看管和携带一个篮子并不太难。人们总是试图提很多篮子，所以才打破这个国家的大部分鸡蛋。提三个篮子的人，必须把一个顶在头上，而这个篮子很可能倒下来，把他自己绊倒。美国商人的一个缺点就是不够专注。 To summarize what I have said: aim for the highest; never enter a bar room; do not touch liquor, or if at all only at meals; never speculate; never indorse beyond your surplus cash fund; make the firm’s interest yours; break orders always to save owners; concentrate; put all your eggs in one basket, and watch that basket; expenditure always within revenue; lastly, be not impatient, for as Emerson says, “no one can cheat you out of ultimate success but yourselves.” 把我的话归纳一下：要志存高远；不要出入酒吧；要滴酒不沾，或要喝也只在用餐时喝少许；不要做投机买卖；不要寅吃卯粮；要把公司的利益当作自己的利益；取消订货的目的永远是为了挽救货主；要专注；要把所有的鸡蛋放在一个篮子里，然后小心地看好它；要量入为出；最后，要有耐心，正如爱默生所言，“谁都无法阻止你最终成功，除非你自己承认自己失败。” 009 On Meeting the Celebrated 论见名人 On Meeting the Celebratedhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/09-on_meeting_the_celebrated.mp3 I have always wondered at the passion many people have to meet the celebrated. The prestige you acquire by being able to tell your friends that you know famous men proves only that you are yourself of small account. The celebrated develop a technique to deal with the persons they come across. They show the world a mask, often an impressive on, but take care to conceal their real selves. They play the part that is expected from them, and with practice learn to play it very well, but you are stupid if you think that this public performance of theirs corresponds with the man within. 许多人热衷于见名人，我始终不得其解。在朋友面前吹嘘自己认识某某名人，同此而来的声望只能证明自己的微不足道。名人个个练就了一套处世高招，无论遇上谁，都能应付自如。他们给世人展现的是一副面具，常常是美好难忘的面具，但他们会小心翼翼地掩盖自己的真相。他们扮演的是大家期待的角色，演得多了，最后都能演得惟妙惟肖。如果你还以为他们在公众面前的表演就是他们的真实自我，那就你傻了。 I have been attached, deeply attached, to a few people; but I have been interested in men in general not for their own sakes, but for the sake of my work. I have not, as Kant enjoined, regarded each man as an end in himself, but as material that might be useful to me as a writer. I have been more concerned with the obscure than with the famous. They are more often themselves. They have had no need to create a figure to protect themselves from the world or to impress it. Their idiosyncrasies have had more chance to develop in the limited circle of their activity, and since they have never been in the public eye it has never occurred to them that they have anything to conceal. They display their oddities because it has never struck them that they are odd. And after all it is with the common run of men that we writers have to deal; kings, dictators, commercial magnates are from our point of view very unsatisfactory. To write about them is a venture that has often tempted writers, but the failure that has attended their efforts shows that such beings are too exceptional to form a proper ground for a work of art. They cannot be made real. The ordinary is the writer’s richer field. Its unexpectedness, its singularity, its infinite variety afford unending material. The great man is too often all of a piece; it is the little man that is a bundle of contradictory elements. He is inexhaustible. You never come to the end of the surprises he has in store for you. For my part I would much sooner spend a month on a desert island with a veterinary surgeon than with a prime minister. 我自己就喜欢一些人，非常喜欢他们。但我对人感兴趣一般不是因为他们自身的缘故，而是出于我工作需求。正如康德劝告的那样，我从来没有把认识某人作为目的，而是将其当作对一个作家有用的创作素材。比之名流显士，我更加关注无名小卒。他们常常显得较为自然真实，他们无须再创造另一个人物形象，用他来保护自己不受世人干扰，或者用他来感动世人。他们的社交圈子有限，自己的种种癖性也就越有可能得到滋长。因为他们从来没有引起公众的关注，也就从来没有想到过要隐瞒什么。他们会表露他们古怪的一面，因为他们从来就没有觉得有何古怪。总之，作家要写的是普通人。在我们看来，国王，独裁者和商界大亨等都是不符合条件的。去撰写这些人物经常是作家们难以抗拒的冒险之举，可为此付出的努力不免以失败告终，这说明这些人物都过于特殊，无法成为一件艺术作品的创作根基，作家也不可能把他们写得真真切切。老百姓才是作家的创作沃土，他们或变幻无常，或难觅其二，各式人物应有尽有，这些都给作家提供了无限的创作素材。大人物经常是千人一面，小人物身上才有一组组矛盾元素，是取之不尽的创作源泉，让你惊喜不断。就我而言，如果在孤岛上度过一个月，我宁愿和一名兽医相守，也不愿同一位首相做伴。 010 The 50-Percent Theory of Life 生活理论半对半 The 50-Percent Theory of Lifehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/10-the_50-percent_theory_of_life.mp3 I believe in the 50-percent theory. Half the time things are better than normal; the other half, they re worse. I believe life is a pendulum swing. It takes time and experience to understand what normal is, and that gives me the perspective to deal with the surprises of the future. 我信奉对半理论。生活时而无比顺畅，时而倒霉透顶。我觉得生活就像来回摆的钟摆。读懂生活的常态需要时间和阅历，而读懂它也练就了我面对未来的生活态度。 Let’s benchmark the parameters: yes, I will die. I’ve dealt with the deaths of both parents, a best friend, a beloved boss and cherished pets. Some of these deaths have been violent, before my eyes, or slow and agonizing. Bad stuff, and it belongs at the bottom of the scale. 让我们确定一下好坏的标准：是的，我注定会死去。我已经经历了双亲，一位好友，一位敬爱的老板和心爱宠物的死亡。有些突如其来，近在眼前，有些却缓慢痛苦。这些都是糟糕的事情，它们属于最坏的部分。 Then there are those high points: romance and marriage to the right person; having a child and doing those Dad things like coaching my son’s baseball team, paddling around the creek in the boat while he’s swimming with the dogs, discovering his compassion so deep it manifests even in his kindness to snails, his imagination so vivid he builds a spaceship from a scattered pile of Legos. 生活中也不乏高潮：坠入爱河缔结良缘；身为人父养育幼子，诸如训练指导儿子的棒球队，当他和狗在小河中嬉戏时摇桨划船，感受他如此强烈的同情心-即使对蜗牛也善待有加，发现他如此丰富的想象力-即使用零散的乐高玩具积木也能堆出太空飞船。 But there is a vast meadow of life in the middle, where the bad and the good flip-flop acrobatically. This is what convinces me to believe in the 50-percent theory. 但在生活最好与最坏部分之间有一片巨大的中间地带，其间各种好事坏事像耍杂技一样上下翻滚，轮番出现。这就是让我信服对半理论的原因。 One spring I planted corn too early in a bottomland so flood-prone that neighbors laughed. I felt chagrined at the wasted effort. Summer turned brutal—the worst heat wave and drought in my lifetime. The air-conditioned died; the well went dry; the marriage ended; the job lost; the money gone. I was living lyrics from a country tune—music I loathed. Only a surging Kansas City Royals team buoyed my spirits. 有一年春天，我在一块洼地上过早地种上了玉米。那块地极易遭到水淹，所以邻居们都嘲笑我。我为浪费了精力而感到懊恼。没想到夏天更为残酷-我经历了最糟糕的热浪和干旱。空调坏了，进干了，婚姻破裂了，工作丢了，钱也没有。我正经历着某首乡村歌曲中描绘的情节，我讨厌这种音乐，只有刚出道不久的堪萨斯皇家棒球队能鼓舞我的精神。 Looking back on that horrible summer, I soon understood that all succeeding good things merely offset the bad. Worse than normal wouldn’t last long. I am owed and savor the halcyon times. The reinvigorate me for the next nasty surprise and offer assurance that can thrive. The 50-percent theory even helps me see hope beyond my Royals’ recent slump, a field of struggling rookies sown so that some year soon we can reap an October harvest. 回首那个糟糕的夏天，我很快就明白了，所有后来出现的好事只不过与坏事相互抵消。比一般情况糟糕的境遇不会延宕过久；而太平时光是我应得的，我要尽情享受，它们为我注入活力以应对下一个险情，并确保我可以兴旺发达。对半理论甚至帮助我在堪萨斯皇家棒球队最近的低潮中看到希望-这是一快艰难行进的新手们耕耘的土地，只要播种了，假以时日我们就可以收获十月的金秋。 For that on blistering summer, the ground moisture was just right, planting early allowed pollination before heat withered the tops, and the lack of rain spared the standing corn from floods. That winter my crib overflowed with corn—fat, healthy three-to-a-stalk ears filled with kernels from heel to tip—while my neighbors’ fields yielded only brown, empty husks. 那个夏天天气酷热，地而湿度适宜，提早播种就可以在热浪打蔫植尖之前完成授粉，同于干旱更没有爆发洪水，产在田里的玉米得以保存。因此那个冬天我的粮仓堆满了玉米-丰满，健康，一颗三穗且从头到脚都是饱满的玉米粒的玉米穗-而我的邻居们收获的只是晒黑的空壳。 Although plantings past may have fallen below the 50-percent expectation, and they probably will again in the future, I am still sustained by the crop that flourishes during the drought. 尽管过去的播种可能没有达到50%的收获期望，而且将来也可能是这样，但我仍然能靠着在旱季繁茂生长的庄稼而生存下去。 011 What is Your Recovery Rate? 你的恢复速率是多少？ What is Your Recovery Rate?http://down010702.tingclass.net/lesson/shi0529/0001/1613/11-what_is_your_recovery_rate.mp3 What is your recovery rate? How long does it take you to recover from actions and behaviors that upset you? Minutes? Hours? Days? Weeks? The longer it takes you to recover, the more influence that incident has on your actions, and the less able you are to perform to your personal best. In a nutshell, the longer it takes you to recover, the weaker you are and the poorer your performance. 你的恢复速率是多少？你需要多长时间才能从让你烦恼的行为中恢复？几分钟？几小时？几天？几星期？你需要的恢复时间越长，那个事件对你的影响越大，你也就越不能做到最好。简言之，你的恢复时间越长，你就越软弱，你的表现也就越差劲。 You are well aware that you need to exercise to keep the body fit and, no doubt, accept that a reasonable measure of health is the speed in which your heart and respiratory system recovers after exercise. Likewise the faster you let go of an issue that upsets you, the faster you return to an equilibrium, the healthier you will be. The best example of this behavior is found with professional sportspeople. They know that the faster they can forget an incident or missd opportunity and get on with the game, the better their performance. In fact, most measure the time it takes them to overcome and forget an incident in a game and most reckon a recovery rate of 30 seconds is too long! 你充分意识到，要保持身体健康你需要锻炼，并且你无疑会接受，你的心脏和呼吸系统在锻炼后的恢复速度是衡量健康的一个合理尺度。同样，你越快摆脱使你烦恼的问题，越快恢复平静，你就越健康。此类行为的最好典范是专业运动员。他们知道，越快忘记一件事或失去的机会而好好比赛，他们的发挥就越好。实际上，大多数运动员会佰自己克服并忘记比赛中一个事件所需的时间，而且大多数人都认为30秒的恢复时间太长了！ Imagine yourself to be an actor in a play on the stage. Your aim is to play your part to the best of your ability. You have been given a script and at the end of each sentence is a ful stop. Each time you get to the end of the sentence you start a new one and although the next sentence is related to the last it is not affected by it. Your job is to deliver each sentence to the best of your ability. 想象自己是一位站在舞台上的戏剧赏。你的目标是尽全力扮演好你的角色。你已经拿到了剧本，而剧本中的每句话都以句号结尾。每次你念到一个句子的末尾，你就会开始一个新的句子。尽管下一句和上一句有关联，但并不受它的影响。你的工作是尽力说好每句台词。 Don’t live your life in the past! Learn to live in the present, to overcome the past. Stop the past from influencing your daily life. Don’t allow thoughts of the past to reduce your personal best. Stop the past from interfering with your life. Learn to recover quickly. 不要生活在过去！要学会生活在现在，学会克服过去；不要让过去影响你的日常生活；不要让过去的思想妨碍你做到最好；不要让过去干扰你的生活；学会快速恢复。 Remember: Rome wasn’t built in a day. Reflect on your recovery rate each day. Every day before you go to bed, look at your progress. Don’t lie in bed saying to you, “I did that wrong.” “I should have done better there.” No. look at your day and note when you made an effort to place a full stop after an incident. This is a success. You are taking control of your life. Remember this is a step by step process. This is not a make-over. You are undertaking real change here. Your aim: reduce the time spent in recovery. 记住，罗马不是一日建成的。每天都反思自己的恢复速率；每天上床睡觉前，都看看自己的进步；不要躺在床上对自己说：“我那个做错了。”“我应该做到更好。”不要那样做；回想自己的一天，并注意努力给某个事件画上句号的时刻。这就是一个成功，你在控制自己的生活。记住这是一个循序渐进的过程。这不是简单的修修补补。你正在进行的是真正的改变，你的目标是减少用在恢复上的时间。 The way forward? 将来该怎么做呢？ Live in the present. Not in the precedent. 生活在现在，而不是从前。 012 Clear Your Mental Space 清理心灵的空间 Clear Your Mental Space http://down010702.tingclass.net/lesson/shi0529/0001/1613/12-clear_your_mental_space.mp3 Think about the last time you felt a negative emotion—like stress, anger, or frustration. What was going through your mind as you were going through that negativity? Was your mind cluttered with thoughts? Or was it paralyzed, unable to think? 想下你最近一次感受到的消极情绪，例如压力，愤怒或挫折。当你处于那种消极情绪时你在想些什么？是充满了混乱的思绪？还是陷于麻木，无法思考？ The next time you find yourself in the middle of a very stressful time, or you feel angry or frustrated, stop. Yes, that’s right, stop. Whatever you’re doing, stop and sit for one minute. While you’re sitting there, completely immerse yourself in the negative emotion. 下次当你发现自己处于非常紧张的状态时，或是你感到气愤或受挫时，停下来。是的，对，停下来。不管你在做什么，停下来坐上一分钟。坐着的时候，让自己完全沉浸在那种消极情绪之中。 Allow that emotion to consume you. Allow yourself one minute to truly feel that emotion. Don’t cheat yourself here. Take the entire minute—but only one minute—to do nothing else but feel that emotion. 让那种消极情绪吞噬你，给自己一分钟的时间去真切地体会那种情绪，不要欺骗自己。花整整一分钟的时间 – 但只有一分钟 – 去体会那种情绪，别的什么也不要做。 When the minute is over, ask yourself, “Am I wiling to keep holding on to this negative emotion as I go through the rest of the day?” 当一分钟结束时，问自己：“我是否想在今天余下的时间里继续保持这种消极情绪？” Once you’ve allowed yourself to be totally immersed in the emotion and really fell it, you will be surprised to find that the emotion clears rather quickly. 一旦你允许自己完全沉浸在那种情绪当中并真切体会到它，你就会惊奇地发现那种情绪很快就消失了。 If you feel you need to hold on to the emotion for a little longer, that is OK. Allow yourself another minute to feel the emotion. 如果你觉得还需要点时间来保持那种情绪，没关系，再给自己一分钟的时间去体会它。 When you feel you’ve had enough of the emotion, ask yourself if you’re willing to carry that negativity with you for the rest of the day. If not, take a deep breath. As you exhale, release all that negativity with your breath. 如果你觉得自己已经充分体会了那种情绪，那就问自己是否愿意在今天余下的时间里继续保持这种消极情绪。如果不愿意，那就深呼吸。呼气的时候，把所有的消极情绪都释放出去。 This exercise seems simple—almost too simple. But, it is very effective. By allowing that negative emotion the space to be truly felt, you are dealing with the emotion rather than stuffing it down and trying not to feel it. You are actually taking away the power of the emotion by giving it the space and attention it needs. When you immerse yourself in the emotion, and realize that it is only emotion, it loses its control. You can clear your head and proceed with your task. 这个方法似乎很简单 – 几乎是太过简单了，但却非常有效。通过给自己空间真正体会消极情绪，你是在处理这种情绪，而不是将其压制下去然后尽量不加理会。通过给予消极情绪所需的空间和关注，你实际上是在消解其力量。当你沉浸在那种情绪之中，并且明白它只是一种情绪时，你就摆脱了它的控制。你可以清理头脑并继续做事。 Try it. Next time you’re in the middle of a negative emotion, give yourself the space to feel the emotion and see what happens. Keep a piece of paper with you that says the following: 你下次笼罩消极情绪时，试一下这种做法，给自己一点空间来体会那种情绪并看看会发生什么。随身带一张写着如下字句的纸条： Stop. Immerse for one minute. Do I want to keep this negativity? Breath deep, exhale, release. Move on! 停下来。沉浸一分钟。我想保持这种消极情绪吗？深吸气，呼气，放松。继续做事！ This will remind you of the steps to the process. Remember; take the time you need to really immerse yourself in the emotion. Then, when you feel you’ve felt it enough, release it—really let go of it. You will be surprised at how quickly you can move on from a negative situation and get to what you really want to do! 这会提醒你该怎样去做。记住，要花你所需要的时间去真正沉浸于那种情绪之中。然后，当你感到自己已经充分体会到了它。你会惊奇地发现，你很快就能摆脱消极情绪，并开始做你真正想做的事情！ 013 Be Happy 快乐 Be Happy!http://down010702.tingclass.net/lesson/shi0529/0001/1613/13-be_happy.mp3 “The days that make us happy make us wise.”—-John Masefield “快乐的日子使人睿智。” — 约翰·梅斯菲尔德 when I first read this line by England’s Poet Laureate, it startled me. What did Masefield mean? Without thinking about it much, I had always assumed that the opposite was true. But his sober assurance was arresting. I could not forget it. 第一次读到英国桂冠诗人梅斯菲尔德的这行诗时，我感到十分震惊。他想表达什么意思？我以前从未对此仔细考虑，总是认定这行诗反过来才正确。但他冷静而又胸有成竹的表达引起了我的注意，令我无法忘怀。 Finally, I seemed to grasp his meaning and realized that here was a profound observation.The wisdom that happiness makes possible lies in clear perception, not fogged by anxiety nor dimmed by despair and boredom, and without the blind spots caused by fear. 终于，我似乎领会了他的意思，并意识到这行诗意义深远。快乐带来的睿智存在于敏锐的洞察力之间，不会因忧虑而含混迷惑，也不会因绝望和厌倦而黯然模糊，更不会因恐惧而造成盲点。 Active happiness—not mere satisfaction or contentment —often comes suddenly, like an April shower or the unfolding of a bud. Then you discover what kind of wisdom has accompanied it. The grass is greener; bird songs are sweeter; the shortcomings of your friends are more understandable and more forgivable. Happiness is like a pair of eyeglasses correcting your spiritual vision. 积极的快乐 – 并非单纯的满意或知足 – 通常不期而至，就像四月里突然下起的春雨，或是花蕾的突然绽放。然后，你就会发觉与快乐结伴而来的究竟是何种智慧。草地更为青翠，鸟吟更为甜美，朋友的缺点也变得更能让人理解，宽容。快乐就像是一副眼镜，可以矫正你的精神视力。 Nor are the insights of happiness limited to what is near around you. Unhappy, with your thoughts turned in upon your emotional woes, your vision is cut short as though by a wall. Happy, the wall crumbles. 快乐的视野并不仅限于你周围的事物。当你不快乐时，你的思维陷入情感上的悲哀，你的眼界就像是被一道墙给阻隔了，而当你快乐时，这道墙就会砰然倒塌。 The long vista is there for the seeing. The ground at your feet, the world about you—-people, thoughts, emotions, pressures—are now fitted into the larger scene. Everything assumes a fairer proportion. And here is the beginning of wisdom. 你的眼界变得更为宽广。你脚下的大地，你身边的世界，包括人，思想，情感和压力，现在都融入了更为广阔的景象之中，其间每件事物 的比例都更加合理。而这就是睿智的起始。 014 The Goodness of life 生命的美好 The Goodness of Lifehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/14-the_goodness_of_life.mp3 Though there is much to be concerned about, there is far, far more for which to be thankful. Though life’s goodness can at times be overshadowed, it is never outweighed. 尽管有很多事让人忧虑，但相比而言，值得感激的事要多得多。尽管生命的美好有时被蒙上阴影，但它却永远不会被埋没。 For every single act that is senselessly destructive, there are thousands more small, quiet acts of love, kindness and compassion. For every person who seeks to hurt, there are many, many more who devote their lives to helping and to healing. 相对于每一个无谓的破坏行为而言，都有更多数以千计更为微小的，包含着爱，友善和同情的举动静静地上演着。相对于每一个试图伤害他人的人而言，都有更多的人致力于帮助他人，治愈他人的创伤。 There is goodness to life that cannot be denied. 生命的美好不能否认。 In the most magnificent vistas and in the smallest details, look closely, for that goodness always comes shining through. 在最为壮观的前景和最为琐碎的细节中，请仔细观察，因为美好的事物总是散发着耀眼的光芒闪亮登场。 There si no limit to the goodness of life. It grows more abundant with each new encounter. The more you experience and appreciate the goodness of life, the more there is to be lived. 生命的美好没有界限。每一次相遇都会使这美好变得越发丰富。你经历得越多，越能欣赏生命的美好，生命中的美好就会变得越多。 Even when the cold winds blow and the world seems to be cov ered in foggy shadows, the goodness of life lives on. Open your eyes, open your heart, and you will see that goodness is everywhere. 即使当寒风袭来，整个世界似乎被雾气掩盖之时，生命的美好仍会存在。睁开双眼，打开心扉，你就会发现这美好无处不在。 Though the goodness of life seems at times to suffer setbacks, it always endures. For in the darkest moment it becomes vividly clear that life is a priceless treasure. And so the goodness of life is made even stronger by the very things that would oppose it. 尽管生命的美好有时似乎遭受挫折，但它总会挺过来。因为，在最黑暗的时刻，有一点变得格外清楚，那就是，生命是无价的财富。因此，正是与生命的美好相对立的事物使其越发强大。 Time and time again when you feared it was gone forever you found that the goodness of life was really only a moment away. Around the next corner, inside every moment, the goodness of life is there to surprise and delight you. 无数次地，当你担心这美好已经远离之时，你会发现生命的美好其实只与你相隔须臾。它就在下一角落，存在于每个时刻之间，等着给你惊喜。 Take a moment to let the goodness of life touch your spirit and calm your thoughts. Then, share your good fortune with another. For the goodness of life grows more and more magnificent each time it is given away. 花些时间让生命的美好感动自己的灵魂，放松自己的思绪。然后，把你的幸运与他人分享。因为生命的美好会在每次给予之间变得越来越壮观。 Though the problems constantly scream for attention and the conflicts appear to rage ever stronger, the goodness of life grows stronger still, quietly, peacefully, with more purpose and meaning than ever before. 尽管总是有问题让你去关注，冲突也似乎愈演愈烈，但生命的美好却总是静静地，平和地，带着比以往更强的意志和更多的价值变得更加强大。 015 Facing the Enemies Within 直面内在的敌人 Facing the Enemies Withinhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/15-facing_the_enemies_within.mp3 We are not born with courage, but neither are we born with fear. Maybe some of our fears are brought on by your own experiences, by what someone has told you, by what you’ve read in the papers. Some fears are valid, like walking alone in a bad part of town at two o’clock in the morning. But once you learn to avoid that situation, you won’t need to live in fear of it. 我们的勇气并不是与生俱来的，我们的恐惧也不是。也许有些恐惧来自你的亲身经历，别人告诉你的故事，或你在报纸上读到的东西。有些恐惧可以理解，例如在凌晨两点独自走在城里不安全的地段。但是一旦你学会避免那种情况，你就不必生活在恐惧之中。 Fears, even the most basic ones, can totally destroy our ambitions. Fear can destroy fortunes. Fear can destroy relationships. Fear, if left unchecked, can destroy our lives. Fear is one of the many enemies lurking inside us. 恐惧，哪怕是最基本的恐惧，也可能彻底粉碎我们的抱负。恐惧可能摧毁财富，也可能摧毁一段感情。如果不加以控制，恐惧还可能摧毁我们的生活。恐惧是潜伏于我们内心的众多敌人之一。 Let me tell you about five of the other enemies we face from within. 让我来告诉你我们面临的其他五个内在敌人。 The first enemy that you’ve got to destroy before it destroys you is indifference. What a tragic disease this is! “Ho-hum, let it slide. I’ll just drift along.” Here’s one problem with drifting: you can’t drift your way to the to of the mountain. 第一个你要在它袭击你之前将其击败的敌人是冷漠。打着哈欠说：“随它去吧，我就随波逐流吧。”这是多么可悲的疾病啊！随波逐流的问题是：你不可能漂流到山顶去。 The second enemy we face is indecision. Indecision is the thief of opportunity and enterprise. It will steal your chances for a better future. Take a sword to this enemy. 我们面临的第二个敌人是优柔寡断。它是窃取机会和事业的贼，它还会偷去你实现更美好未来的机会。向这个敌人出剑吧！ The third enemy inside is doubt. Sure, there’s room for healthy skepticism. You can’t believe everything. But you also can’t let doubt take over. Many people doubt the past, doubt the future, doubt each other, doubt the government, doubt the possibilities nad doubt the opportunities. Worse of all, they doubt themselves. I’m telling you, doubt will destroy your life and your chances of success. It will empty both your bank account and your heart. Doubt is an enemy. Go after it. Get rid of it. 第三个内在的敌人是怀疑。当然，正常的怀疑还是有一席之地的，你不能相信一切。但是你也不能让怀疑掌管一切。许多人怀疑过去，怀疑未来，怀疑彼此，怀疑政府，怀疑可能性，并怀疑机会。最糟糕的是，他们怀疑自己。我告诉你，怀疑会毁掉你的生活和你成功的机会，它会耗尽你的存款，留给你干涸的心灵。怀疑是敌人，追赶它，消灭它。 The fourth enemy within is worry. We’ve all got to worry some. Just don’t let conquer you. Instead, let it alarm you. Worry can be useful. If you step off the curb in New York City and a taxi is coming, you’ve got to worry. But you can’t let worry loose like a mad dog that drives you into a small corner. Here’s what you’ve got to do with your worries: drive them into a small corner. Whatever is out to get you, you’ve got to get it. Whatever is pushing on you, you’ve got to push back. 第四个内在的敌人是担忧。我们都会有些担忧，不过千万不要让担忧征服你。相反，让它来警醒你。担忧也许能派上用场。当你在纽约走上人行道时有一辆出租车向你驶来，你就得担忧。但你不能让担忧像疯狗一样失控，将你逼至死角。你应该这样对付自己的担忧：把担忧驱至死角。不管是什么来打击你，你都要打击它。不管什么攻击你，你都要反击。 The fifth interior enemy is overcaution. It is the timid approach to life. Timidity is not a virtue; it’s an illness. If you let it go, it’ll conquer you. Timid people don’t get promoted. They don’t advance and grow and become powerful in the marketplace. You’ve got to avoid overcaution. 第五个内在的敌人是过分谨慎。那是胆小的生活方式。胆怯不是美德，而是一种疾病。如果你不理会它，它就会将你征服。胆怯的人不会得到提拔，他们在市场中不会前进，不会成长，不会变得强大。你要避免过分谨慎。 Do battle with the enemy. Do battle with your fears. Build your courage to fight what’s holding ou back, what’s keeping you from your goals and dreams. Be courageous in your life and in your pursuit of the things you want and the person you want to become. 一定要向这引起敌人开战。一定要向恐惧开战。鼓起勇气抗击阻挡你的事物，与阻止你实现目标和梦想的事物作斗争。要勇敢地生活，勇敢地追求你想要的事物并勇敢地成为你想成为的人。 016 Abundance is a Life Style 富足的生活方式 Abundance is a Life Stylehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/16-abundance_is_a_life_style.mp3 Abundance is a life style, a way of living your life. It isn’t something you buy now and then or pull down from the cupboard, dust off and use once or twice, and then return to the cupboard. 富足是一种生活方式。它不是你偶尔买来，从架子上拿下来，抹去灰尘用上一两次然后又放回到架子上的东西。 Abundance is a philosophy; it appears in your physiology, your value system, and carries its own set of beliefs. You walk with it, sleep with it, bath with it, feel with it, and need to maintain and take care of it as well. 富足是一种哲学，它体现于你的生理机能和价值观之中，并带有自己的一套信仰。无论走路，睡觉，洗澡你都会感受到它，你还要维护并照顾它。 Abundance doesn’t always require money. Many people live with all that money can buy yet live empty inside. Abundance begins inside with some main self-ingredients, like love, care, kindness and gentleness, thoughtfulness and compassion. Abundance is a state of being. It radiates outward. It shines like the sun among the many moons in the world. 富足并不一定需要金钱。许多人拥有金钱所能买到的一切，但却内心空虚。富足源自内心，其中包含一些重要的自我成分，比如爱，关心，善良和温柔，体贴与同情。富足是一种存在状态，它向处发散，像处于众多星球之间的太阳那样发光发亮。 Being from the brightness of abundance doesn’t allow the darkness to appear or be in the path unless a choice to allow it to. The true state of abundance doesn’t have room for lies or games normally played. The space is too full of abundance. This may be a challenge because we still need to shine for other to see. 来自富足的光亮不允许黑暗的出现或存在，除非选择允许它存在。真正的富足不给谎言或通常玩的游戏留有空间，因为富足已经把空间填得太满了。这可能是一个挑战，因为我们仍然需要为了让别人看见而发光。 Abundance is seeing people for their gifts and not what they lack or could be. Seeing all things for their gifts and not what they lack. 富足是看到人们的天赋，而不是他的缺陷。所有的事物都要看其天赋而不是缺陷。 Start by knowing what your abundances are, fill that space with you, and be fully present from that state of being. Your profession of choice is telling you of knowing and possibilities. That is their gift. Consultants and customer service professionals have the ministrative assistants and virtual assistants have an abundance of coordination and time management. Abundance is all around you, and all within. See what it is; love yourself for what it is, not what you’re missing, or what that can be better, but for what it is at this present moment. 从知道自己的富足是什么时开始，填写满空间，全身心投入生活。你的选择已经告诉你。例如：教练能够了解队员并激发其潜力，那是他们的天赋；顾问和客服专业人士通常能够提供很多成功且很具实用性的案例；行政助理和虚拟助理熟识直辖市配合和时间管理的技巧。富足充盈于你的四周以及你的内心。明白富足的内容，爱本色的自己，不要为自己缺少的或是能变得更好的方面爱自己，而是为此时此刻的富足而爱自己。 Be in a state of abundance of what you already have. I guarantee they are there; it always is buried but there. Breathe them in as if they are the air you breathe because they are yours. Let go of anything that isn’t abundant for the time being. Name the shoe boxes in your closet with your gifts of abundance; pull from them every morning if needed. Know they are there. 要处于你已经拥有的事物的富足状态。我保证它们就在那儿，深藏不露却从未远离。将其看成空气，吸入体内，因为它们是你的。放开暂并不富足的东西。把你富足的所有天赋写在橱柜里的鞋盒子上，如果需要就每天早晨拉开橱柜，知道你的天赋都在那儿。 Learning to trust in your own abundance is required. When you begin to be within your own space of abundance, whatever you need will appear whenever you need it. That’s just the way the higher powers set this universe up to work. Trust the universal energy. The knowing of it all will humble you to its power yet let the brightness of you shine everywhere it needs to. Just by being from a state of abundance, it is being you. 你需要学会信任自己的富足。当你开始处在自己富足的空间之内时，你需要的东西都会在你需要的时刻出现。这就是更高的力量设置这个宇宙动转的方式。要相信宇宙的能量。知道这一点会让你在其力量面前保持谦卑，但也会让你的光亮闪耀在所有需要的地方。只要处于富足的状态，就是做你自己。 017 Human Life a Poem 人生如诗 Human Life a Poemhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/17-human_life_a_poem.mp3 I think that, from a biological standpoint, human life almost reads like a poem. It has its own rhythm and beat, its internal cycles of growth and decay. It begins with innocent childhood, followed by awkward adolescence trying awkwardly to adapt itself to mature society, with its young passions and follies, its ideals and ambitions; then it reaches a manhood of intense activities, profiting from experience and learning more about society and human nature; at middle age, there is a slight easing of tension, a mellowing of character like the ripening of fruit or the mellowing of good wine, and the gradual acquiring of a more tolerant, more cynical and at the same time a kindlier view of life; then In the sunset of our life, the endocrine glands decrease their activity, and if we have a true philosophy of old age and have ordered our life pattern according to it, it is for us the age of peace and security and leisure and contentment; finally, life flickers out and one goes into eternal sleep, never to wake up again. 我以为，从生物学角度看，人的一生恰如诗歌。人生自有其韵律和节奏，自有内在的生成与衰亡。人生始于无邪的童年，经过少年的青涩，带着激情与无知，理想与雄心，笨拙而努力地走向成熟；后来人到壮年，经历渐广，阅人渐多，涉世渐深，收益也渐大；及至中年，人生的紧张得以舒缓，人的性格日渐成熟，如芳馥之果实，如醇美之佳酿，更具容忍之心，处世虽更悲观，但对人生的态度趋于和善；再后来就是人生迟暮，内分泌系统活动减少，若此时吾辈已经悟得老年真谛，并据此安排残年，那生活将和平，宁静，安详而知足；终于，生命之烛摇曳而终熄灭，人开始永恒的长眠，不再醒来。 One should be able to sense the beauty of this rhythm of life, to appreciate, as we do in grand symphonies, its main theme, its strains of conflict and the final resolution. The movements of these cycles are very much the same in a normal life, but the music must be provided by the individual himself. 人们当学会感受生命韵律之美，像听交响乐一样，欣赏其主旋律、激昂的高潮和舒缓的尾声。这些反复的乐章对于我们的生命都大同小异，但个人的乐曲却要自己去谱写。 In some souls, the discordant note becomes harsher and harsher and finally overwhelms or submerges the main melody. Sometimes the discordant note gains so much power that the music can no longer go on, and the individual shoots himself with a pistol or jump into a river. But that is because his original leitmotif has been hopelessly over-showed through the lack of a good self-education. Otherwise the normal human life runs to its normal end in kind of dignified movement and procession. There are sometimes in many of us too many staccatos or impetuosos, and because the tempo is wrong, the music is not pleasing to the ear; we might have more of the grand rhythm and majestic tempo o the Ganges, flowing slowly and eternally into the sea. 在某些人心中，不和谐音会越来越刺耳，最终竟然能掩盖主曲；有时不和谐音会积蓄巨大的能量，令乐曲不能继续，这时人们或举枪自杀或投河自尽。 这是他最初的主题被无望地遮蔽，只因他缺少自我教育。否则，常人将以体面的运动和进程走向既定的终点。在我们多数人胸中常常会有太多的断奏或强音，那是因为节奏错了，生命的乐曲因此而不再悦耳。我们应该如恒河，学她气势恢弘而豪迈地缓缓流向大海。 No one can say that life with childhood, manhood and old age is not a beautiful arrangement; the day has its morning, noon and sunset, and the year has its seasons, and it is good that it is so. There is no good or bad in life, except what is good according to its own season. And if we take this biological view of life and try to live according to the seasons, no one but a conceited fool or an impossible idealist can deny that human life can be lived like a poem. Shakespeare has expressed this idea more graphically in his passage about the seven stages of life, and a good many Chinese writers have said about the same thing. It is curious that Shakespeare was never very religious, or very much concerned with religion. I think this was his greatness; he took human life largely as it was, and intruded himself as little upon the general scheme of things as he did upon the characters of his plays. Shakespeare was like Nature itself, and that is the greatest compliment we can pay to a writer or thinker. He merely lived, observed life and went away. 人生有童年、少年和老年，谁也不能否认这是一种美好的安排，一天要有清晨、正午和日落，一年要有四季之分，如此才好。人生本无好坏之分，只是各个季节有各自的好处。如若我们持此种生物学的观点，并循着季节去生活，除了狂妄自大的傻瓜和无可救药的理想主义者，谁能说人生不能像诗一般度过呢。莎翁在他的一段话中形象地阐述了人生分七个阶段的观点，很多中国作家也说过类似的话。奇怪的是，莎士比亚并不是虔诚的宗教徒，也不怎么关心宗教。我想这正是他的伟大之处，他对人生秉着顺其自然的态度，他对生活之事的干涉和改动很少，正如他对戏剧人物那样。莎翁就像自然一样，这是我们能给作家或思想家的最高褒奖。对人生，他只是一路经历着，观察着，离我们远去了。 018 Solitude 独处 Solitudehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/18-solitude.mp3 I find it wholesome to be alone the greater part of the time. To be in company, even with the best, is soon wearisome and dissipating. I love to be alone. I never found the companion that was so companionable as solitude. We are for the most part more lonely when we go abroad among men than when we stay in our chambers. A man thinking or working is always alone, let him be where he will. Solitude is not measured by the miles of space that intervene between a man and his fellows. The really diligent student in one of the crowded hives of Cambridge College is as solitary as a dervish in the desert. The farmer can work alone in the field or the woods all day, hoeing or chopping, and not feel lonesome, because he is employed; but when he comes home at night he cannot sit down in a room alone, at the mercy of his thoughts, but must be where he can :see the folks,:” and recreate, and, as he thinks, remunerate himself for his day’s solitude; and hence he wonders how the student can sit alone in the house all night and most of the day without ennui and :the blues:; but he does not realize that the student, though in the house, is still at work in his field, and chopping in his woods, as the farmer in his, and in turn seeks the same recreation and society that the latter does, though it may be a more condensed form of it. 我发现人若大部分时间用于独处，将有益身心。与人为伴，即使是挚友，也很快会有厌烦或虚度光阴的感觉。我爱独处，我发现没有比独处更好的伴侣了。出国，身在熙攘人群中，要比退守陋室更让人寂寞。心有所想，身有所系的人总是孤身一人，不论他身处何地。独处与否也不是由人与人之间的距离来确定。在剑桥苦读的学子虽身处蜂巢般拥挤的教室，实际上却和沙漠中的苦行僧一样，是在独处。家人终日耕于田间，伐于山野，此时他虽孤单但并不寂寞，因他专心于工作；但待到他日暮而息，却未必能忍受形影相吊，空有思绪做伴的时光，他必到“可以看见大伙儿”的去处去找乐子，如他所认为的那样以补偿白日里的孤独；因此他无法理解学子如何能竟夜终日独坐而不心生厌倦或倍感凄凉；然而他没意识到，学子虽身在学堂，但心系劳作，但是耕于心田，伐于学林，这正和农人一样，学子在寻求的无非是和他一样的快乐与陪伴，只是形式更简洁罢了。 Society is commonly too cheap. We meet at very short intervals, not having had time to acquire any new value for each other. We meet at meals three times a day, and give each other a new taste of that old musty cheese that we are. We have had to agree on a certain set of rules, called etiquette and politeness, to make this frequent meeting tolerable and that we need not come to open war. We meet at the post-office, and at the sociable, and about the fireside every night; we live thick and are in each other’s way, and stumble over one another, and I think that we thus lose some respect for one another. Certainly less frequency would suffice for all important and hearty communications. Consider the girls in a factory—never alone, hardly in their dreams. It would be better if there were but one inhabitant to a square mile, as where I live. The value of a man is not in his skin, that we should touch him. 与人交往通常都因唾手可得而毫无价值，在频繁的相处中，我们无暇从彼此获取新价值。我们每日三餐相聚，反复让彼此重新审视的也是依旧故我，并无新奇之处。为此我们要循规蹈矩，称其为懂礼仪，讲礼貌，以便在这些频繁的接触中相安无事，无须论战而有辱斯文。我们相遇在邮局，邂逅在社交场所，围坐在夜晚的炉火旁，交情甚笃，彼此干扰着，纠缠着；实际上我认为这样我们都或多或少失去了对彼此的尊重。对于所有重要的倾心交流，相见不必过频。想想工厂里的女孩，她们虽从不落单，但也少有梦想。像这样方圆一英里仅一人居住，那情况会更好。人的价值非在肌肤相亲，而在心有灵犀。 I have a great deal of company in my house; especially in the morning, when nobody calls. Let me suggest a few comparisons, that some one may convey an idea of my situation. I am no more lonely than the loon in the pond that laughs so loud, or than Walden Pond itself. What company has that lonely lake, I pray?And yet it has not the blue devils, but the blue angels in it, in the azure tint of its waters. The sun is alone, except in thick weather, when there sometimes appear to be two, but one is a mock sun. god is alone—but the devil, he is far from being alone; he sees a great deal of company; he is legion. I am no more lonely than a single mullein or dandelion in a pasture, or a bean leaf, or sorrel, or a horse-fly, or a bumblebee. I am no more lonely than the Millbrook, or a weathercock, or the north star, or the south wind, or an April shower, or a January thaw, or the first spider in a new house. 我的房子里有很多伙伴，尤其在无人造访的清晨。我把自己和周围事物对比一下，你或许能窥见我生活的一斑。比起那湖中长笑的潜鸟，还有那湖，我并不比它们孤独多少。你看：这孤单的湖又何以为伴呢？然而它那一湾天蓝的湖水里有的却是天使的纯净，而非魔鬼的忧郁。太阳是孤独的，虽然时而在阴郁的天气里会出现两个太阳，但其中之一为幻日；上帝是孤独的 – 魔鬼才从不孤单，他永远不乏伙伴，因从他都甚众。比起牧场上的一朵毛蕊花，一支蒲公英，一片豆叶，一束酢浆草，一只牛虻或大黄蜂来，我并不孤单多少；比想密尔溪，风标，北极星，南风，四月春雨，正月融雪，或者新房中的第一只蜘蛛，我也并不更加孤单。 019 Giving Life Meaning 给生命以意义 Giving Life Meaninghttp://down010702.tingclass.net/lesson/shi0529/0001/1613/19-giving_life_meaning.mp3 Have you thought about what you want people to say about you after you’re gone? Can you hear the voice saying, “He was a great man.” Or “She really will be missed.” What else do they say? 你有没有想过，你希望人们在你死后怎样评论你？你能否听到这样的说，“他是个伟大的人”或“人们的确会怀念她”，他们还会说些什么？ One of the strangest phenomena of life is to engage in a work that will last long after death. Isn’t that a lot like investing all your money so that future generations can bare interest on it? Perhaps, yet if you look deep in your own heart, you’ll find something drives you to make this kind of contribution—something drives every human being to find a purpose that lives on after death. 人生最奇异的现象之一就是，你从事的事业在你死后仍将长久存在。这和你用所的钱进行投资以便后人能从中获益不是如出一辙吗？也许，如果你审视自己的内心深处，你就会发现促使你做出这种贡献的驱动力-一种驱使每个人寻找在自己死后仍能继续存在的事业的驱动力。 Do you hope to memorialize your name? Have a name that is whispered with reverent awe? Do you hope to have your face carved upon 50 ft of granite rock? Is the answer really that simple? Is the purpose of lifetime contribution an ego-driven desire for a mortal being to have an immortal name or is it something more? 你希望自己的名字被人记住吗？你希望别人提起你的名字时心怀敬畏吗？你希望自己的面容被雕刻在50英尺高的花岗岩上吗？答案真的那么简单吗？贡献一生的目的难道终将一死之人想要获得不朽名声的自我鞭策的欲望？抑或是其他更伟大的事物？ A child alive today will die tomorrow. A baby that had the potential to be the next Einstein will die from complication is at birth. The circumstances of life are not set in stone. We are not all meant to live life through to old age. We’ve grown to perceive life3 as a full cycle with a certain number of years in between. If all of those years aren’t lived out, it’s a tragedy. A tragedy because a human’s potential was never realized. A tragedy because a spark was snuffed out before it ever became a flame. 今天活着的孩子明天就会死去。一个有可能成为下一个爱因斯坦的婴儿会死于出生并发症。生命的情形并不是固定不变的。我们并没有注定都要活到老年。我们已经认识到，生命是一个周期，其时间长度是特定的。如果这些时间没有被充分利用，那就是个悲剧，因为人的潜能还未实现，因为火花还没形成火焰就被补灭。 By virtue of inhabiting a body we accept these risks. We expose our mortal flesh to the laws of the physical environment around us. The trade off isn’t so bad when you think about it. The problem comes when we construct mortal fantasies of what life should be like. When life doesn’t conform to our fantasy we grow upset, frustrated, or depressed. 由于存在于肉体之中，所以我们接受这些风险。我们使易朽的肉体服从周围物理环境的法则。你仔细想一想就会发现，这种交易并不是那么糟糕。当我们幻想生命应该如何时，问题就来了。当生命和我们的幻想不一致时，我们就变得烦恼，无奈或沮丧。 We are alive; let us live. We have the ability to experience; let us experience. We have the ability to learn; let us learn. The meaning of life can be grasped in a moment. A moment so brief it often evades our perception. 我们活着，那我们就要活得精彩；我们有能力体验，那我们就要体验人生甘苦；我们有能力学习，那我们就要在学海徜徉。生命的意义可以在一瞬间抓住-一个经常被我们忽略的短暂瞬间。 What meaning stands behind the dramatic unfolding of life? What single truth can we grasp and hang onto for dear life when all other truths around us seem to fade with time? 当生命戏剧般地一幕幕拉开时，其中隐含的意义是什么？当我们周围所有其他都似乎随着时间而消逝时，我们能够掌握哪个真理并依靠它来生活呢？ These moments are strung together in a series we call events. These events are strung together in a series we call life.When we seize the moment and bend it according to our will, a will driven by the spirit deep inside us, then we have discovered the meaning of life, a meaning for us that shall go on long after we depart this Earth. 这些瞬间串联在一起，我们称之为事件。这些事件串联系在一起， 我们称之为生活。当我们抓住那个瞬间并按照我们的意志来改变它-这意志受到我们内心深处的精神的驱使，我们就发现了生命的意义-这意义将在我们离开地球之后长久存在。 020 Relish the Moment 品位现在 Relish the Momenthttp://down010702.tingclass.net/lesson/shi0529/0001/1613/20-relish_the_moment.mp3 Tucked away in our subconsciousness is an idyllic vision. We see ourselves on a long trip that spans the moment. We are traveling by train. Out the windows, we drink in the passing scene of cars on nearby highways, of children waving at a crossing, of cattle grazing on a distant hillside, of smoke pouring from a power plant, of row upon row of corn ad wheat, of flatlands and valleys, of mountains and rolling hillsides, of city skylines and village halls. 我们的潜意识里藏着一派田园诗般的风光! 我们仿佛身处一次横贯大陆的漫漫旅程之中! 乘着火车, 我们领略着窗外流动的景色：附近高速公路上奔驰的汽车、十字路口处招手的孩童、远山上吃草的牛群、源源不断地从电厂排放出的烟尘、一片片的玉米和小麦、平原与山谷、群山与绵延的丘陵、天空映衬下城市的轮廓, 以及乡间的庄园宅第! But uppermost in our minds is the final destination. On a certain day at a certain hour, we will pull into the station. Bands will be playing and flags waving. Once we get there, so many wonderful dreams will come true and the pieces of our lives will fit together like a completed jigsaw puzzle. How restlessly we pace the aisles, damning the minutes for loitering—waiting, waiting, waiting for the station. 然而我们心里想得最多的却是最终的目的地! 在某一天的某一时刻, 我们将会抵达进站! 迎接我们的将是乐队和飘舞的彩旗! 一旦到了那儿, 多少美梦将成为现实, 我们的生活也将变得完整, 如同一块理好了的拼图! 可是我们现在在过道里不耐烦地踱来踱去, 咒骂火车的拖拖拉拉! 我们期待着, 期待着, 期待着火车进站的那一刻! “When we reach the station, that will be it!” we cry. “When I’m 18.” “When I buy a new 450SL Mercedes Benz!” “When I put the last kid through college.” “When I have paid off the mortgage!” “When I get a promotion.” “When I reach the age of retirement, I shall live happily ever after!” “当我们到站的时候, 一切就都好了! “我们呼喊着! “当我18岁的时候! “”当我有了一辆新450SL奔驰的时候! “”当我供最小的孩子念完大学的时候! “”当我偿清贷款的时候! “”当我官升高任的时候! “”当我到了退休的时候, 就可以从此过上幸福的生活啦! “ Sooner or later, we must realize there is no station, no one place to arrive at once and for all. The true joy of life is the trip. The station is only a dream. It constantly outdistances us. 可是我们终究会认识到人生的旅途中并没有车站, 也没有能够”一到永逸”的地方!生活的真正乐趣在于旅行的过程, 而车站不过是个梦, 它始终遥遥领先于我们! It isn’t the burdens of today that drive men mad. It is the regrets over yesterday and the fear of tomorrow. Regret and fear are twin thieves who rob us of today. 真正令人发疯的不是今日的负担, 而是对昨日的悔恨及对明日的恐惧! 悔恨与恐惧是一对孪生窃贼, 将今天从你我身边偷走! So stop pacing the aisles and counting the miles. Instead, climb more mountains, eat more ice cream, go barefoot more often, swim more rivers, watch more sunsets, laugh more, cry less. Life must be lived as we go along. The station will come soon enough. 那么就不要在过道里徘徊吧, 别老惦记着你离车站还有多远! 何不换一种活法, 将更多的高山攀爬, 多吃点儿冰淇淋甜甜嘴巴, 经常光着脚板儿溜达, 在更多的河流里畅游, 多看看夕阳西下, 多点欢笑哈哈, 少让泪水滴答! 生活得一边过一边瞧! 车站就会很快到达! 021 The Love of Beauty 爱美 The Love of Beautyhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/21-the_love_of_beauty.mp3 The love of beauty is an essential part of all healthy human nature. It is a moral quality. The absence of it is not an assured ground of condemnation, but the presence of it is an invariable sign of goodness of heart. In proportion to the degree in which it is felt will probably be the degree in which nobleness and beauty of character will be attained. 爱美及是整个健全人性不可或缺之一部分。它是一种道德品质。缺乏这种品质并不能作为受到责难的充分理由，但是拥有这种品质则是心灵美好的永恒标志。品德的高尚与美好所达到的程度可能与对美的感受程度成正比。 Natural beauty is an all-pervading presence. The universe is its temple. It unfolds into the numberless flowers of spring. It waves in the branches of trees and the green blades of grass. It haunts the depths of the earth and the sea. It gleams from the hues of the shell and the precious stone. And not only these minute objects but the oceans, the mountains, the clouds, the stars, the rising and the setting sun—all overflow with beauty. This beauty is so precious, and so congenial to our tenderest and noblest feelings, that it is painful to think of the multitude of people living in the midst of it and yet remaining almost blind to it. 大自然的美无处不在，整个宇宙就是美的殿堂。美，在春日百花中绽放；美，在绿叶嫩枝间摇曳；美，在深海幽谷里游弋；美，在奇石与贝壳的缤纷色彩中闪烁。不只是这些细微之物，还有海洋，山川，云彩，繁星，日升日落 – 一切都是洋溢着美。这样的美是如此珍贵，与我们最温柔，最高尚的情愫是如此相宜。然而，想到很多人置身于美之中，却几乎对它熟视无睹，真是令人痛心不已。 All persons should seek to become acquainted with the beauty in nature. There is not a worm we tread upon, nor a leaf that dances merrily as it falls before the autumn winds, but calls for our study and admiration. The power to appreciated beauty not merely increases our sources of happiness—it enlarges our moral nature, too. Beauty calms our restlessness and dispels our cares. Go into the fields or the woods, spend a summer day by the sea or the mountains, and all your little perplexities and anxieties will vanish. Listen to sweet music, and your foolish fears and petty jealousies will pass away. The beauty of the world helps us to seek and find the beauty of goodness. 所有的人都应该去认识大自然之美。没有一条我们踩过的小虫，没有一片在秋风拂掠之际飞舞的树叶不值得我们研究与赞赏。欣赏美的能力不仅增加了我们快乐的来源，也加强了我们德性的修养。美使我们不安的心平静下来，也驱散了我们的忧虑。到田野或森林去，在夏日的海边或山上呆上一天，那么你所有微不足道的困惑与焦虑都会烟消云散。倾听悦耳的音乐，你那愚蠢的恐惧与狭隘的嫉妒都会过去。世界之美将有助于我们找到为善之美。 022 The Happy Door 快乐之门 The Happy doorhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/22-the_happy_door.mp3 Happiness is like a pebble dropped into a pool to set in motion an ever-widening circle of ripples. As Stevenson has said, being happy is a duty. 快乐就像一块为了激起阵阵涟漪而丢进池塘的小石头。正好史蒂文森所说，快乐是一种责任。 There is no exact definition of the word happiness. Happy people are happy for all sorts of reasons. The key is not wealth or physical well-being, since we find beggars, invalids and so-called failures, who are extremely happy. 快乐这个词并没有确切的定义，快乐的人快乐的理由多种多样。快乐的关键并不是财富或身体健康，因为我们发现有些乞丐，残疾人和所谓的失败者也都非常快乐。 Being happy is a sort of unexpected dividend. But staying happy is an accomplishment, a triumph of soul and character. It is not selfish to strive for it. It is, indeed, a duty to ourselves and others. 快乐是一种意外的收获，但保持快乐却是一种成就，一种灵性的胜利。努力追寻快乐并不自私，实际上，这是我们对自己和他人应尽的责任。 Being unhappy is like an infectious disease. It causes people to shrink away from the sufferer. He soon finds himself alone, miserable and embittered. There is, however, a cure so simple as to seem, at first glance, ridiculous; if you don’t feel happy, pretend to be! 不快乐就像传染病，它使得人们都躲避不快乐的人。不快乐的人很快就会发现自己处于孤独，悲惨，痛苦的境地。然而，有一种简单得看似荒谬的治病良方：如果你不快乐，就假装你很快乐！ It works. Before long you will find that instead of repelling people, you attract them. You discover how deeply rewarding it is to be the center of wider and wider circles of good will. 这很有效。不久你就会发现，别人不再躲着你了，相反，你开始吸引别人了。你会发觉，做一块能激起好意涟漪的小石头有多么值得。 Then the make-believe becomes a reality. You possess the secret of peace of mind, and can forget yourself in being of service to others. 然后假装就变成了现实。你拥有了使心灵平静的秘密，会因帮助他人而忘我。 Being happy, once it is realized as a duty and established as a habit, opens doors into unimaginable gardens thronged with grateful friends. 一旦你认识到快乐是一种责任并使快乐成为习惯，通向不可思议的乐园的大门就会向你敞开，那里满是感激你的朋友。 023 Born to Win 生而为赢 Born to Winhttp://down010702.tingclass.net/lesson/shi0529/0001/1613/23-born_to_win.mp3 Each human being is born as something new, something that never existed before. Each is born with the capacity to win at life. Each person has a unique way of seeing, hearing, touching, tasting and thinking. Each has his or her own unique potentials—capabilities and limitations. Each can be a significant, thinking, aware, and creative being—a productive person, a winner. 人皆生而为新，为前所未有之所存在；人皆生而能赢。人皆有其特立独行之方式去审视，聆听，触摸，品味及思考，因而都具备独特潜质-能力和局限。人皆能举足轻重，思虑明达，洞察秋毫，富有创意，成就功业。 The word “winner” and “loser” have many meanings. When we refer to a person as a winner, we do not mean one who makes someone else lose. To us, a winner is one who responds authentically by being credible, trustworthy, responsive, and genuine, both as an individual and as a member of a society. “成者”与“败者”含义颇多。谈及成者我们并非指令他人失意之人。对我们而言，成者必为人守信，值得信赖，有求必应，态度诚恳，或为个人，或为社会一员皆能以真诚回应他人。 Winners do not dedicated their lives to a concept of what they imagine they should be; rather, they are themselves and as such do not use their energy putting on a performance, maintaining pretence and manipulating others. They are aware that there is a difference between being loving and acting loving, between being stupid and acting stupid, between being knowledgeable and acting knowledgeable. Winners do not need to hide behind a mask. 成者行事并不拘泥于某种信条，即便是他们认为应为其奉献一生的理念；而是本色行事，所以并不把精力用来表演，保持伪装或操控他人。他们明了爱与装爱，愚蠢与装傻，博学与卖弄之间迥然有别。成者无须藏于面具之后。 Winners are not afraid to do their own thinking and to use their own knowledge. They can separate facts from opinions and don’t pretend to have all the answers. They listen to others, evaluate what they say, but come to their own conclusions. Although winners can admire and respect other people, they are not totally defined, demolished, bound, or awed by them. 成者敢于利用所学，独立思考，区分事实与观点，且并不佯装通晓所有答案。他们倾听，权衡他人意见，但能得出自己的结论。尽管他们尊重，敬佩他们，但并不为他们所局限，所推翻，所束缚，也不对他人敬若神灵。 Winners do not play “helpless”, nor do they play the blaming game. Instead, they assume responsibility for their own lives. They don’t give others a false authority over them. Winners are their own bosses and know it. 成者既不佯装“无助”，亦不抱怨他人。相反，他们对人生总是独担责任，也不以权威姿态凌驾他人之上。他们主宰自己，而且能意识到这点。 A winner’s timing is right. Winners respond appropriately to the situation. Their responses are related to the message sent and preserve the significance, worth, well-being, and dignity of the people involved. Winners know that for everything there is a season and for every activity a time. 成者善于审时度势，随机应变。他们对所接受的信息做出回应，维护当事人的利益，康乐和尊严。成者深知成一事要看好时节，行一事要把握时机。 Although winners can freely enjoy themselves, they can also postpone enjoyment, can discipline themselves in the present to enhance their enjoyment in the future. Winners are not afraid to go after what he wants, but they do so in proper ways. Winners do not get their security by controlling others. They do not set themselves up to lose. 尽管成者可以自由享乐，但他更知如何推迟享乐，适时自律，以期将来乐趣更盛。成者并不忌惮追求所想，但取之有道，也并不靠控制他们而获取安然之感。他们总是使自己立于不败。 A winner cares about the world and its peoples. A winner is not isolated from the general problems of society, but is concerned, compassionate, and committed to improving the quality of life. Even in the face of national and international adversity, a winner’s self-image is not one of a powerless individual. A winner works to make the world a better place. 成者心忧天下，并不孤立尘世弊病之外，而是置身事内，满腔热情，致力于改善民生。即使面对民族，国家之危亡，成者亦非无力回天之个体。他总是努力令世界更好。 024 Work and Pleasure 工作和娱乐 Work and Pleasurehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/24-work_and_pleasure.mp3 To be really happy and really safe, one ought to have at least two or three hobbies, and they must all be real. It is no use starting late in life to say: “I will take an interest in this or that.” Such an attempt only aggravates the strain of mental effort. A man may acquire great knowledge of topics unconnected with his daily work, and yet hardly get any benefit or relief. It is no use doing what you like; you have got to like what you do. Broadly speaking, human being may be divided into three classes: those who are toiled to death, those who are worried to death, and those who are bored to death. It is no use offering the manual laborer, tired out with a hard week’s sweat and effort, the chance of playing a game of football or baseball on Saturday afternoon. It is no use inviting the politician or the professional or business man, who has been working or worrying about serious things for six days, to work or worry about trifling things at the weekend. 要想真正生活得幸福和平安，一个人至少应该有两三种业余爱好，而且必须是真正的爱好。到了晚年才开始说“我要培养这个或那个兴趣”是毫无用处的，种这种尝试只会增加精神上的负担。在与自己日常工作无关的领域中，一个人可以获得渊博的知识，但却很难有所收益或得到放松。做自己喜欢的事是无益的，你得喜欢自己所做的事。广言之，人可以分为三个类别：劳累而死的人，忧虑而死的人和无聊而死的人。对于那些体力劳动者来说，一周辛苦的工作使他们精疾力竭，因此在周六下午给他们提供踢足球或者打棒球的机会是没有意义的。对于政界人士，专业人士或者商人来说，他们已经为棘手的事务操劳或者烦恼了六天，因此在周末请他们为琐事劳神同样毫无意义。 It may also be said that rational, industrious, useful human beings are divided into two classes: first, those whose work is work and whose pleasure is pleasure; and secondly, those whose work and pleasure are one. Of these the former are the majority. They have their compensations. The long hours in the office or the factory bring with them as their reward, not only the means of sustenance, but a keen appetite for pleasure even in its simplest and most modest forms. But Fortune’s favored children belong to the second class. Their life is a natural harmony. For them the working hours are never long enough. Each day is a holiday, and ordinary holidays when they come are grudged as enforced interruptions in an absorbing vacation. Yet to both classes the need of an alternative outlook, of a change of atmosphere, of a diversion of effort, is essential. Indeed, it may well be that those whose work is their pleasure are those who most need the means of banishing it at intervals from their minds. 或者可以这么说，理智的，勤奋的，有用的人可以分为两类：对第一类人而言，工作就是工作，娱乐就是娱乐；对于第二类人而言，工作和娱乐是合二为一的。很大一部分人属于前者。他们可以得到相应的补偿。在办公室或工厂里长时间的工作，不仅带给他们维持生计的金钱，还带给他们一种渴求娱乐的强烈欲望，哪怕这种娱乐消遣是以最简单，最淳朴的方式进行的。而第二类人则是命运的宠儿。他们的生活自然而和谐。在他们看来，工作时间永远不够多，每天都是假期；而当正常的假日到来时，他们总会抱怨自己有趣的休假被强行中断。然而，有一些东西对于这两类人来说都十分必要，那就是变换一下视角，改变一下氛围，尝试做点不同的事情。事实上，那些把工作看作娱乐的人可能是需要以某种方式将工作不时地驱赶出自己的大脑。 025 Mirror, Mirror–What do I see镜子,镜子,告诉我 Mirror, Mirror—What do I See?http://down010702.tingclass.net/lesson/shi0529/0001/1613/25-mirror_mirror__what_do_i_see.mp3 A loving person lives in a loving world. A hostile person lives in a hostile world. Everyone you meet is your mirror. 充满爱意人的生活在充满爱意的世界里，充满敌意的人则生活在充满敌意的世界里。你所遇到的每一个人都是你的镜子。 Mirrors have a very particular function. They reflect the image in front of them. Just as a physical mirror serves as the vehicle to reflection, so do all of the people in our lives. 镜子里有一个非常独特的功能，那就是映射出在其前面的影像。就像真正的镜子具有反射功能一样，我们生活中的所有人也都能映射出他人的影子。 When we see something beautiful such as a flower garden, that garden serves as a reflection. In order to see the beauty in front of us, we must be able to see the beauty inside of ourselves. When we love someone, it’s a reflection of loving ourselves. When we love someone, it’s a reflection of loving ourselves. We have often heard things like “I love how I am when I’m with that person.” That simply translates into “I’m able to love me when I love that other person.” Oftentimes, when we meet someone new, we feel as though we “click”. Sometimes it’s as if we’ve known each other for a long time. That feeling can come from sharing similarities. 当我们看到美丽的事物时，例如一座花园，那这花园就起到了反射作用。为了发现我们面前美好的事物，我们必须能发现在自己内在的美。我们爱某个人，也正是我们爱自己的表现。我们经常听到这样的话：“当我和那个人在一起的时候，我爱那时的自己。”这句话也可以简单地说成：“在我爱那个人的同时，我也能爱我自己。”有时，我们遇见一个陌生人，感觉仿佛是一见如故，就好像我们已经相识甚久。这种熟悉感可能来自于彼此身上的共同点。 Just as the “mirror” or other person can be a positive reflection, it is more likely that we’ll notice it when it has a negative connotation. For example, it’s easy to remember times when we have met someone we’re not particularly crazy about. We may have some criticism in our mind about the person. This is especially true when we get to know someone with whom we would rather spend less time. 就像“镜子”或他人能映射出我们积极的一面一样，我们更有可能注意到映射出自己消极方面的“镜子”。例如，我们很容易就能记住我们碰到自己不太喜欢的人的时刻。我们可能在心里对那个人有些反感。当我们认识自己不喜欢与之相处的人时，这种情况就更为明显。 Frequently, when we dislike qualities in other people, ironically, it’s usually the mirror that’s speaking to us. 具有讽刺意味着的是，通常当我们讨厌别人身上的某些特质时，那就说明你其实讨厌自己身上相类似的特质。 I began questioning myself further each time I encountered someone that I didn’t particularly like. Each time, I asked myself, “What is it about that person that I don’t like?” and then “Is there something similar in me?” in every instance, I could see a piece of that quality in me, and sometimes I had to really get very introspective. So what did that mean? 每次，当我遇到不太喜欢的人时，我就开始进一步质问自己。我会扪心自问：“我不喜欢那个人的哪些方面？”然后还会问：“我是不是有和他相似的地方？”每次，我都能在自己身上看到一些令我厌恶的特质。我有时不得不深刻地反省自己。那这意味着什么呢？ It means that just as I can get annoyed or disturbed when I notice that aspect in someone else, I better reexamine my qualities and consider making some changes. Even if I’m not willing to make a drastic change, at least I consider how I might modify some of the things that I’m doing. 这意味着，就像我会对其他人身上令我厌恶的特质感到恼怒或不安一样，我应该更好地重新审视自己的特质，并考虑做一些改变。即使我不想做大的改变，至少我会考虑该如何修正自己正在做的一些事情。 At times we meet someone new and feel distant, disconnected, or disgusted. Although we don’t want to believe it, and it’s not easy or desirable to look further, it can be a great learning lesson to figure out what part of the person is being reflected in you. It’s simply just another way to create more self-awareness. 我们时常会遇到陌生人，并感到疏远或厌恶。尽管我们不想去相信，不容易也不想去深究，但是弄清楚别人的哪些特质在自己身上有所体现是非常有意义的一课，这也正是增强自我意识的另一个途径。 026 On Motes and Beams 微尘与栋梁 On Motes and Beamshttp://down010702.tingclass.net/lesson/shi0529/0001/1613/26-on_motes_and_beams.mp3 It is curious that our own offenses should seem so much less heinous than the offenses of others. I suppose the reason is that we know all the circumstances that have occasioned them and so manage to excuse in ourselves what we cannot excuse in others. We turn our attention away from our own defects, and when we are forced by untoward events to consider them, find it easy to condone them. For all I know we are right to do this; they are part of us and we must accept the good and bad in ourselves together. 让人奇怪的是，和别人的过错比起来，我们自身的过错往往不是那样的可恶。我想，其原因应该是我们知晓一切导致自己犯错的情况，因此能够设法谅解自己的错误，而别人的错误却不能谅解。我们对自己的缺点不甚关注，即便是深陷困境而不得不正视它们的时候，我们也会很容易就宽恕自己。据我所知，我们这样做是正确的。缺点是我们自身的一部分，我们必须接纳自己的好和坏。 But when we come to judge others, it is not by ourselves as we really are that we judge them, but by an image that we have formed of ourselves fro which we have left out everything that offends our vanity or would discredit us in the eyes of the world. To take a trivial instance: how scornful we are when we catch someone out telling a lie; but who can say that he has never told not one, but a hundred? 但是当我们评判别人的时候，情况就不同了。我们不是通过真实的自我来评判别人，而是用一种自我形象来评判，这种自我形象完全摒弃了在任何世人眼中会伤害到自己的虚荣或者体面的东西。举一个小例子来说：当觉察到别人说谎时，我们是多么地蔑视他啊！但是，谁能够说自从未说过谎？可能还不止一百次呢。 There is not much to choose between men. They are all a hotchpotch of greatness and littleness, of virtue and vice, of nobility and baseness. Some have more strength of character, or more opportunity, and so in one direction or another give their instincts freer play, but potentially they are the same. For my part, I do not think I am any better or any worse than most people, but I know that if I set down every action in my life and every thought that has crossed my mind, the world would consider me a monster of depravity. The knowledge that these reveries are common to all men should inspire one with tolerance to oneself as well as to others. It is well also if they enable us to look upon our fellows, even the most eminent and respectable, with humor, and if they lead us to take ourselves not too seriously. 人和人之间没什么大的差别。他们皆是伟大与渺小，善良与邪恶，高尚与低俗的混合体。有的人性格比较坚毅，机会也比较多，因而达个或那个方面，能够更自由地发挥自己的禀赋，但是人类的潜能却都是相同的。至于我自己，我认为自己并不比大多数人更好或者更差，但是我知道，假如我记下我生命中每一次举动和每一个掠过我脑海的想法的话，世界就会将我视为一个邪恶的怪物。每个人都会有这样的怪念头，这样的认识应当能够启发我们宽容自己，也宽容他人。同时，假如因此我们得以用幽默的态度看待他人，即使是天下最优秀最令人尊敬的人，而且假如我们也因此不把自己看得过于重要，那是很有裨益的。 027 An October Sunrise 十月的日出 An October Sunrisehttp://down010702.tingclass.net/lesson/shi0529/0001/1613/27-an_october_sunrise.mp3 I was up the next morning be fore the October sunrise, and away through the wild and the woodland. The rising of the sun was noble in the cold and warmth of it peeping down the spread of light, he raised his shoulder heavily over the edge of grey mountain and wavering length of upland. Beneath his gaze the dew-fogs dipped, and crept to crept to the hollow places; then stole away in line and column, holding skirts, and clinging subtly at the sheltering corners where rock hung over grassland, while the brave lines of the hills came forth, one beyond other gliding. 第二天凌晨，在十月的太阳升起之前，我已经起身并穿过了旷野和丛林。十月的清晨乍寒还暖，日出的景象非常壮观。透过一片晨曦，朝日从朦胧的山冈和起伏连绵的高地过际，沉重地抬起肩头。在它的逼视下，蒙蒙的雾气向下沉降，落到洼地里去，接着一丝丝一缕缕地悄悄飘散，而在草地之上悬岩之下的那些隐秘角落里，雾气却还不愿散去，同时群山的雄姿接二连三地显现出来。 The woods arose in folds, like drapery of awakened mountains, stately with a depth of awe, and memory of the tempests. Autumn’s mellow hand was upon them, as they owned already, touched with gold and red and olive, and their joy towards the sun was less to a bridegroom than a father. 森林也层层叠叠地显现，宛若刚刚苏醒的山峦的斗篷，端庄威严，并带着狂风暴雨的回忆。秋天成熟的手已经在抚摸这些山林，因为它们的颜色已经改变，染上了金黄，丹红和橄榄绿。它们对朝日所怀的一片喜悦，像是要奉献给一个新郎，更像是要奉献给一位父亲。 Yet before the floating impress of the woods could clear it self, suddenly the gladsome light leaped over hill and valley, casting amber, blue, and purple, and a tint of rich red rose; according to the scene they lit on, and the curtain flung around; yet all alike dispelling fear and the cloven hoof of darkness, all on the wings of hope advancing, and proclaiming, “God is here!” then life and joy sprang reassured from every crouching hollow; every flower, and bud and bird had a fluttering sense of them; and all the flashing of God’s gaze merged into soft beneficence. 然而，在树林那流动的景色逝去之前，欢悦的晨光突然跃出了峰峦和山谷，光线所及，把照到的地方和周围的森林分别染成青色，紫色，琥珀色和富丽的红玫瑰色。光线照到哪里，那里就如同一幅幕布被掀开。而所有的一切都同样在驱散恐惧和黑暗的魔影；所有的一切都展开希望的翅膀，向前习翔，并大声宣告：“上帝在这里！”于是生命和欢乐从每一个蜷伏的洞穴里信心十足地欣然跃出；一切花朵，蓓蕾和鸟雀都感到了生命和欢乐而抖动起来；上帝的凝视汇合成温柔的恩泽。 So, perhaps, shall break upon us that eternal morning, when crag and chasm shall be no more, neither hill and valley, nor great unvintaged ocean; but all things shall arise, and shine in the light of the Father’s countenance, because itself is risen. 也许，那永恒的晨光就会这样降临人间，那时不再有险崖沟壑，不再有峰峦山谷，也不再有浩瀚无际的海洋；万物都将踊跃升腾，在造物主慈爱的光芒中生辉，因为太阳已经升起。 028 To Be or Not to Be 生存还是毁灭 To be or not to behttp://down010702.tingclass.net/lesson/shi0529/0001/1613/28-to_be_or_not_to_be.mp3 Outside the Bible, these six words are the most famous in all the literature of the world. They were spoken by Hamlet when he was thinking aloud, and they are the most famous words in Shakespeare because Hamlet was speaking not only for himself but also for every thinking man and woman. To be or not to be, to live or not to live, to live richly and abundantly and eagerly, or to live dully and meanly and scarcely. A philosopher once wanted to know whether he was alive or not, which is a good question for everyone to put to himself occasionally. He answered it by saying: “I think, therefore am.” “生存还是毁灭。”如果把《圣经》除外，这六个字便是整个世界文学中最有名的六个字了。这六个字是哈姆雷特一次喃喃自语时说的，而这六个字也就成了莎士比亚作品中最有名的几个字了，因为这里哈姆雷特不仅道出了他自己的心声，同时也代表了一切有思想的男男女女。是活还是不活——是要生活还是不要生活，是要生活得丰满充实，兴致勃勃，还是只是活得枯燥委琐，贫乏无味。一位哲人一次曾想弄清他自己是否是在活着，这个问题我们每个人也大可不时地问问我们自己。这位哲学家对此的答案是： “我思故我在。” But the best definition of existence ever saw did another philosopher who said: “To be is to be in relations.“ If this true, then the more relations a living thing has, the more it is alive. To live abundantly means simply to increase the range and intensity of our relations. Unfortunately we are so constituted that we get to love our routine. But apart from our regular occupation how much are we alive? If you are interest-ed only in your regular occupation, you are alive only to that extent. So far as other things are concerned–poetry and prose, music, pictures, sports, unselfish friendships, politics, international affairs–you are dead. 但是关于生存我所见过的一条最好的定义却是另一位哲学家下的：“生活即是联系。”如果这话不假的话，那么一个有生命者的联系越多，它也就越有生气。所谓要活得丰富充实也即是要扩大和加强我们的各种联系。不幸的是，我们往往会因为天性不够丰厚而容易陷入自己的陈规旧套。试问除去我们的日常工作，我们的真正生活又有多少?如果你只是对你的日常工作才有兴趣，那你的生趣也就很有限了。至于在其它事物方面，比如诗歌、散文、音乐、美术、体育、无私的友谊、政治与国际事务，等等——你只是死人一个。 Contrariwise, it is true that every time you acquire a new interest–even more, a new accomplishment–you increase your power of life. No one who is deeply interested in a large variety of subjects can remain unhappy; the real pessimist is the person who has lost interest. 但反过来说，每当你获得一种新的兴趣——甚至一项新的造诣——你就增长了你的生活本领。一个能对许许多多事物都深感兴趣的人是不可能总不愉快的，真正的悲观者只能是那些丧失兴趣的人。 Bacon said that a man dies as often as he loses a friend. But we gain new life by contacts, new friends. What is supremely true of living objects is only less true of ideas, which are also alive. Where your thoughts are, there will your live be also. If your thoughts are confined only to your business, only to your physical welfare, only to the narrow circle of the town in which you live, then you live in a narrow cir-conscribed life. But if you are interested in what is going on in China, then you are living in China~ if you’re interested in the characters of a good novel, then you are living with those highly interesting people, if you listen intently to fine music, you are away from your immediate surroundings and living in a world of passion and imagination. 培根曾讲过，一个人失去朋友即是死亡。但是凭着交往，凭着新朋，我们就能获得再生。这条对于活人可谓千真万确的道理在一定程度上也完全适用于人的思想，它们也都是活的。你的思想所在，你的生命便也在那里。如果你的思想不出你的业务范围，不出你的物质利益，不出你所在城镇的狭隘圈子，那么你的一生便也只是多方受着局限的狭隘的一生。但是如果你对当前中国那里所发生的种种感到兴趣，那么你便可说也活在中国；如果你对一本佳妙小说中的人物感到兴趣，你便是活在一批极有趣的人们中间；如果你能全神贯注地听点好的音乐，你就会超脱出你的周围环境而活在一个充满激情与想象的神奇世界之中。 To be or not to be–to live intensely and richly, merely to exist, that depends on ourselves. Let widen and intensify our relations. While we live, let live! 生存还是毁灭——活得热烈活得丰富，还是只是简单存在，这就全在我们自己。但愿我们都能不断扩展和增强我们的各种联系。只要一天我们活着，就要一天是在活着。 029 Gettysburg Address 葛底斯堡演说 Gettysburg Addresshttp://down010702.tingclass.net/lesson/shi0529/0001/1613/29-gettysburg_address.mp3 Fourscore and seven years ago, our fathers brought forth upon this continent a new nation, conceived in liberty and dedicated to the proposition that all men are created equal. 87年前，我们的先辈们在这个大陆上创立了一个新国家，它孕育于自由之中，奉行一切人生来平等的原则。 Now, we are engaged in a great civil war, testing whether that nation or any nation so conceived and so dedicated, can long endure. We are met on a great battlefield of that war. We have come to dedicate a portion of that field as a final resting-place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. 现在我们正从事一场伟大的内战，以考验这个国家，或者任何一个孕育于自由和奉行上述原则的国家是否能够长久存在下去。我们在这场战争中的一个伟大战场上集会。烈士们为使这个国家能够生存下去而献出了自己的生命，我们来到这里，是要把这个战场的一部分奉献给他们作为最后安息之所。我们这样做是完全应该而且是非常恰当的。 But, in a larger sense, we cannot dedicate, we cannot consecrate, we cannot hallow this ground. The brave men, living and dead, who struggled here, have consecrated it far above our poor power to add or detract. The world will little note nor long remember what we say here, but it can never forget what they did here. It is for us, the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion; that we here highly resolve that these dead shall not have died in vain; that this nation, under God, shall have a new birth of freedom; and that government of the people, by the people, and for the people, shall not perish from the earth. 但是，从更广泛的意义上来说，这块土地我们不能够奉献，不能够圣化，不能够神化。那些曾在这里战斗过的勇士们，活着的和去世的，已经把这块土地圣化了，这远不是我们微薄的力量所能增减的。我们今天在这里所说的话，全世界不大会注意，也不会长久地记住，但勇士们在这里所做过的事，全世界却永远不会忘记。毋宁说，倒是我们这些还活着的人，应该在这里把自己奉献于勇士们已经如此崇高地向前推进但尚未完成的事业。倒是我们应该在这里把自己奉献于仍然留在我们面前的伟大任务——我们要从这些光荣的死者身上汲取更多的献身精神，来完成他们已经完全彻底为之献身的事业；我们要在这里下定最大的决心，不让这些死者白白牺牲；我们要使国家在上帝福佑下得到自由的新生，要使这个民有、民治、民享的政府永世长存。 030 First Inaugural Address就职演讲(节选) http://down010702.tingclass.net/lesson/shi0529/0001/1613/30-first_inaugural_address_.mp3 We observe today not a victory of party, but a celebration of freedom, symbolizing an end, as well as a beginning; signifying renewal, as well as change. For I have sworn before you and Almighty God the same solemn oath our forebears prescribed nearly a century and three quarters ago. 今天我们庆祝的不是政党的胜利，而是自由的胜利。这象征着一个结束，也象征着一个开端;意味着延续也意味看变革。因为我已在你们和全能的上帝面前，宣读了我们的先辈在170多年前拟定的庄严誓言。 In your hands, my fellow citizens, more than in mine, will rest the final success or failure of our course. Since this country was founded, each generation of Americans has been summoned to give testimony to its national loyalty. The graves of young Americans who answered the call to service surround the globe. 公民们，我们方针的最终成败与其说掌握在我手中，不如说掌握在你们手中。自从合众国建立以来，每一代美国人都曾受到召唤去证明他们对国家的忠诚。响应召唤而献身的美国青年的坟墓遍及全球。 Now the trumpet summons us again, not as a call to bear arms, though arms we need; not as a call to battle, though embattled we are; but a call to bear the burden of a long twilight struggle, year in and year out, “rejoicing in hope; patient in tribulation”, a struggle against the common enemies of man: tyranny, poverty, disease, and war itself. 现在，号角已再次吹响—不是召唤我们拿起武器，虽然我们需要武器;不是召唤我们去作战，虽然我们严阵以待。它召唤我们为迎接黎明而肩负起漫长斗争的重任，年复一年，从希望中得到欢乐，在磨难中保持耐性，对付人类共同的敌人—专制、社团、疾病和战争本身。 Can we forge against these enemies a grand and global alliance, North and South, East and West, that can assure a more fruitful life for all mankind? Will you join in that historic effort? 为反对这些敌人，确保人类更为丰裕的生活，我们能够组成一个包括东西南北各方的全球大联盟吗?你们愿意参加这一历史性的努力吗? In the long history of the world, only a few generations have been granted the role of defending freedom in its hour of maximum danger. I do not shrink from this responsibility. I welcome it. I do not believe that any of us would exchange places with any other people or any other generation. The energy, the faith, the devotion which we bring to this endeavor will light our country and all who serve it. And the glow from that fire can truly light the world. 在漫长的世界历史中，只有少数几代人在自由处于最危急的时刻被赋予保卫自由的责任。我不会推卸这一责任，我欢迎这一责任。我不相信我们中间有人想同其他人或其他时代的人交换位置。我们为这一努力所奉献的精力、信念和忠诚，将照亮我们的国家和所有为国效劳的人，而这火焰发出的光芒定能照亮全世界。 And so, my fellow Americans, ask not what your country can do for you, ask what you can do for your country. 因此，美国同胞们，不要问国家能为你们做些什么、而要问你们能为国家做些什么。 My fellow citizens of the world, ask not what America will do for you, but what together we can do for the freedom of man. 全世界的公民们，不要问美国将为你们做些计人，而要问我们共同能为人类的自由做些什么。 Finally, whether you are citizens of America or citizens of the world, ask of us here the same high standards of strength and sacrifice which we ask of you. With a good conscience our only sure reward, with history the final judge of our deeds, let us go forth to lead the land we love, asking His blessing and His help, but knowing that here on earth, God’s work must truly be our own. 最后，不论你们是美国公民还是其他国家的公民，你们应要求我们献出我们同样要求于你们的高度力量和牺牲。问心无愧是我们唯一可靠的奖赏，历史是我们行动的最终裁判，让我们走向前去，引导我们所热爱的国家。我们祈求上帝的福佑和帮助，但我们知道，确切地说，上帝在尘世的工作必定是我们自己的工作。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"VirtualAPK 滴滴 Android 插件化的实践之路","date":"2017-02-20T12:06:06.000Z","path":"2017/02/20/Program/Android/virtual-apk/","text":"作者：singwhatiwanna DDApp 前言在Android插件化技术日新月异的今天，开发并落地一款插件化框架到底是简单还是困难，这个问题不同人会有不同的答案。但是我相信，完成一个插件化框架的demo并不是多难的事，但是要开发一款完善的插件化框架却不是一件容易的事，尤其在国内，各大Rom厂商都对Android系统做了一定程度的定制，这进一步加剧了Android本身的碎片化问题。 滴滴出行在插件化上的探索起步较晚，由于滴滴业务发展较快，业务迭代占据了大量的时间，这使得我们在2016年才开始研究这方面的技术。经过半年的开发、测试、适配和线上验证，目前我们推出了一款比较完善的插件化框架：VirtualAPK。之所以现在推出来，是因为VirtualAPK在我们内部已经得到了很好的验证，我们在迭代过程中不断地做机型适配和细节特性的支持，目前已经达到一个非常稳定的状况，足以支撑滴滴部分乃至全部业务的动态发版需求。目前滴滴出行最新版本（v5.0.4）上面，小巴和接送机业务均为插件，大家可以去体验。 插件化的现状到目前为止，业界已经有很多优秀的开源项目，比如早期的基于静态代理思想的DynamicLoadApk，随后的基于占坑思想的DynamicApk、Small，还有360手机助手的DroidPlugin。他们都是优秀的开源项目，他们很大程度上促进了国内插件化技术的发展。 尽管有如此多的优秀框架存在，但是兼容性问题仍然是制约插件化发展的一个难题。一款插件化框架，也许可以在一款手机上完美运行，但是在数以千万的设备上却总是容易存在这样那样的兼容性问题。我相信上线过插件化的工程师应该深有体会。滴滴为什么还要自研一款新的插件化框架？因为我们需要一款功能完备的、兼容性优秀的、适用于滴滴业务的插件化框架，目前市面上的开源不能满足我们的需求，所以我们必须重新造轮子，于是VirtualAPK诞生了。 VirtualAPK的诞生VirtualAPK是滴滴出行自研的一款优秀的插件化框架，主要有如下几个特性。 功能完备 支持几乎所有的Android特性；四大组件方面四大组件均不需要在宿主manifest中预注册，每个组件都有完整的生命周期。Activity：支持显示和隐式调用，支持Activity的theme和LaunchMode，支持透明主题；Service：支持显示和隐式调用，支持Service的start、stop、bind和unbind，并支持跨进程bind插件中的Service；Receiver：支持静态注册和动态注册的Receiver；ContentProvider：支持provider的所有操作，包括CRUD和call方法等，支持跨进程访问插件中的Provider。自定义View：支持自定义View，支持自定义属性和style，支持动画；PendingIntent：支持PendingIntent以及和其相关的Alarm、Notification和AppWidget；支持插件Application以及插件manifest中的meta-data；支持插件中的so。优秀的兼容性 兼容市面上几乎所有的Android手机，这一点已经在滴滴出行客户端中得到验证；资源方面适配小米、Vivo、Nubia等，对未知机型采用自适应适配方案；极少的Binder Hook，目前仅仅hook了两个Binder：AMS和IContentProvider，Hook过程做了充分的兼容性适配；插件运行逻辑和宿主隔离，确保框架的任何问题都不会影响宿主的正常运行。入侵性极低 插件开发等同于原生开发，四大组件无需继承特定的基类；精简的插件包，插件可以依赖宿主中的代码和资源，也可以不依赖；插件的构建过程简单，通过Gradle插件来完成插件的构建，整个过程对开发者透明。 VirtualAPK的工作过程VirtualAPK对插件没有额外的约束，原生的apk即可作为插件。插件工程编译生成apk后，即可通过宿主App加载，每个插件apk被加载后，都会在宿主中创建一个单独的LoadedPlugin对象。如下图所示，通过这些LoadedPlugin对象，VirtualAPK就可以管理插件并赋予插件新的意义，使其可以像手机中安装过的App一样运行。 VirtualAPK的运行形态 我们计划赋予VirtualAPK两种工作形态，耦合形态和独立形态。目前VirtualAPK对耦合形态已经有了很好的支持，我们接下来将计划支持独立形态。耦合形态插件对宿主可以有代码或者资源的依赖，也可以没有依赖。这种模式下，插件中的类不能和宿主重复，资源id也不能和宿主冲突。这是VirtualAPK的默认形态，也是适用于大多数业务的形态。独立形态插件对宿主没有代码或者资源的依赖。这种模式下，插件和宿主没有任何关系，所以插件中的类和资源均可以和宿主重复。这种形态的主要作用是用于运行一些第三方apk。 如何使用 第一步： 初始化插件引擎 第二步：加载插件 我们对上述加载过程进行了一些封装，通过如下方式即可异步地去加载一个插件。 当插件入口被调用后，插件的后续逻辑均不需要宿主干预，均走原生的Android流程。比如，在插件内部，如下代码将正确执行： 探究原理基本原理 合并宿主和插件的ClassLoader需要注意的是，插件中的类不可以和宿主重复合并插件和宿主的资源重设插件资源的packageId，将插件资源和宿主资源合并去除插件包对宿主的引用构建时通过Gradle插件去除插件对宿主的代码以及资源的引用 四大组件的实现原理 Activity采用宿主manifest中占坑的方式来绕过系统校验，然后再加载真正的activity；Service动态代理AMS，拦截service相关的请求，将其中转给一个虚拟空间（Matrix）去处理，Matrix会接管系统的所有操作；Receiver将插件中静态注册的receiver重新注册一遍；ContentProvider动态代理IContentProvider，拦截provider相关的请求，将其中转给一个虚拟空间（Matrix）去处理，Matrix会接管系统的所有操作。 如下是VirtualAPK的整体结构图。 填坑之路在实践中我们遇到了很多很多的问题，比如机型适配、API版本适配、Binder hook的稳定性保证等问题，这里拿一个典型的资源适配问题来说明。 其实这是一个很无奈的问题，由于国内各大Rom厂商喜欢深度定制Android系统，所以就出现了这种适配问题。正常情况下我们通过如下代码去创建插件的Resources对象： 然后在Vivo手机上，竟然出现了如下的类型转换错误，看起来是Vivo自己派生了Resources的子类。 于是反编译了下Vivo的framework代码，果不其然，在如下代码中进行了类型转换，所以在加载插件资源的时候就报错了。 为了解决这个问题，我们分析了VivoResources的代码实现，然后在创建插件资源的时候，采用了如下的代码。 除了Vivo以外，有类似问题的还有MiUI、Nubia以及其它不知名的机型。而且在Vivo手机上，除了类型转换错误的问题，还有其他很坑的问题。 事实上我们还处理了很多其他的坑，这里无法一一说明，所以说如何保证插件化的稳定性是一件很有技术挑战的事情。 一些暂时不支持的特性 由于种种原因，VirtualAPK目前未能支持所有的Android的特性，如下是已知的几点。 不支持Activity的部分属性，比如process、configChanges等；暂不支持overridePendingTransition(int enterAnim, int exitAnim)这种形式的转场动画；插件中弹通知，不能使用插件中的资源，比如图片。开源计划 我们的目标是打造一款功能完备的插件化框架，使得各个业务线都能以插件的形式集成，从而实现Android App的热更新能力。 目前VirtualAPK还有一些特性需要进一步完善，待完善后，将会有开源计划。我们期望VirtualAPK开源后，可以让其他App能够无缝集成，无需考虑细节实现和兼容性问题即可轻松拥有热更新能力。 请关注滴滴 App 开发技术微信公众号 DDApp，我们会在上面发布 VirtualAPK的最新进展，也将会把滴滴 iOS 和 Android 开发的干货技术文章分享给大家：","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"VirtualAPK","slug":"VirtualAPK","permalink":"http://ipcreator.me/tags/VirtualAPK/"}]},{"title":"Coding心得","date":"2017-02-20T03:28:06.000Z","path":"2017/02/20/Program/my-views-of-learning-program/","text":"作者：IPCreator Skill is acquired through correct and repetitive practice, and practice makes perfect. 不放过任何一个err，每成功解决一个error就意味着自己的经验库又append一个案例； 理不顺想不通的时候，成长的时刻到了，坚持、坚持再坚持，成就感与困难度成正比； 官网+stackflow+github+google还解决不了的时候，暂时放一放，持续关注思考，直至惊喜发生； 换位常识思考，如果你是设计者，你会怎么设计，为什么这样设计？ 尽量不要复制粘贴，要逐字阅读，逐个输入，对开发而言，thinking与coding相辅相成，缺一不可； 知其然还要知其所以然，不要浮于表面，浅尝则止，运行/部署成功不等于你掌握了每个环节的原理； 慢工出细活，慢就是快，防火胜于救火，先打好基础（概念、框架、原理等），高手都重视内功； 专而精，精而深，通过一个突破口（语言、框架、平台），抓住本质量（通俗易懂，能重建和迁移），再融会贯通，一通百通； coding只是解决问题的一种方式，不要重复发明轮子，要open和share，不要敝扫自珍，因为每个人都能掌握相应的技能，只是时间早晚而已； 创新整合也是一种行之有效的商业途径，不要为了技术而技术，为了创新而创新，商业思维很重要； 从战略上来说，我们大部分都只是用别人开发出来的工具（类似于厨具）开发产品（类似于菜品）而已； 阅读代码（类似于品尝他人菜品）、模仿创新（借鉴改造）、原创分享（晋级高级厨师）； 道理都懂，为什么难以坚持？没有尝到甜头或者没有吃到苦头，又或者只是懒惰； 35岁以后能否再编程？取决于：以前的编程模式是否健康可持续？是否为自己实现创新产品和服务(而不只是为了挣钱)； 程序员人生的梦想和快乐简单易实现，成为其中一员才能真正感同身受… 有劲、有趣和有用，正常可持续，Kick-off &amp; Keep-going Dreams cann’t measured by S/A/B/C/D degree、money and position.Great mind thinks alike.RTFC Read the fucking code.RTFM Read the fucking manual.STFW Search the fucking Web.Read the article word by word.Code can talk, let the code talk.A good name tells the truth.Keep code simple and reusable.Keep hungry, Keep foolish.Keep healthy and sustainable.Less is more, slow is quick.Don’t Reinvent the Wheel.Use is the best way of learning English , so is programming.Master the essence of things, including languages (English/C/C++/JAVA/PYTHON/JS…)，platforms(Arena/Android/Tensor…)，tools(gcc/make/gradle/git…),etcWe make good habits first, then habits make us.Success is a habit, so is happiness. Hello World Program in Java 1234567class HelloWorld&#123; public static void main(String args[]) &#123; System.out.println(“Hello World”); &#125;&#125; Hello World Program in C123456#include&lt;stdio.h&gt;main()&#123; printf(“Hello World”);&#125; Hello World Program in C++123456#include &lt;iostream&gt;int main()&#123; std::cout &lt;&lt; “Hello, world”;&#125; Hello World Program in Javascript1234567&lt;script&gt;window.onload = function()&#123; document.getElementById(‘result’).innerHTML = “Hello World”;&#125;&lt;/script&gt;&lt;div id=”result&gt;&lt;/div&gt; Hello World Program in HTML&lt;p&gt;Hello World&lt;/p&gt; Hello World Program in Pythonprint “Hello World Hello World Program in Perlprint “Hello World Hello World Program in Rubyputs “Hello World Source: http://blog.learntoprogram.tv/hello-world-eight-languages/ 太用力的人跑不远写在前面有阶段的自己，会用蛮力去学习一些东西，就是这东西不管是否适合目前自己的知识体系， 觉得学了之后会更牛逼就去学，但是这样的东西往往学了记不住。 学习的过程越用力反而显得越吃力， 太吃力的事情，自然就无法有恒心， 这就是很多人会觉得自己做事总是无法持之以恒的原因。 努力不应该是某种需要被时常觉知的东西，意志力是短期内会用完的精神能量。真正坚持到最后的人靠的不是激情，而是恰到好处的喜欢和投入。 太用力的人更容易产生期望落差，更不愿接受自己找错了方向的事实——没有什么比这样的“失落”更能让人心寒的了，太用力的人大多都因心累而倒在了半途中。 精神上的用力并不会让你跑得更快，但是精神上的疲惫却可以让你停下。 人越用力，就会越想要得到及时的良好刺激。越用力的人对于正刺激的需求就越高，越不能忍受暂时的负反馈。遗憾的是，人生常常是没有下文的考卷，这种刺激来得太慢、太不稳定。 真正的坚持归于平静，靠的是温和的发力，而不是时时刻刻的刺激。 太用力的人增加了执行的功耗。纠结，是太用力的一种表现，造成内部的运转处于空转的状态——意识与行动的主观脱节；从心所欲，就是把运转效率最大化后的结果——所想即所为。执行阶段最大的敌人，是纠结，是埋怨，是内心的冲突——太用力，就是心理额外动作太多。想好之后就只管去做。 我一直告诫自己不要用力过猛，以保持自己对困难的顿感和不顺的接受程度。短期的过度用力极容易造成身体和心理上的挫伤。哪怕你在做的事情非常重要，也要保证基本的休息和放松。 不论是以后的工作还是将来的创业，都要保持一颗平常心。你需要更多的“寸劲”而不是“用力感”。在找到受力点“all in”之前，一切都要顺势而行，自然随和。 人在学习的过程会经历一系列的过程，先是笨拙期，再是熟练期——这两个过程他虽然能运用出技能，但是头脑中仍然能感受到使用时的提取感。这两个阶段都需要用力，但是用力的程度却大幅度减小。 技能掌握的最后阶段是运用自如期，就是张三丰把太极拳的形态全部都忘了的阶段。这个时候头脑中已经能下意识地去进行活动，达到了能耗最低的理想阶段。 从用力感，到毫无感觉，是一种技能掌握上的纯熟。年轻的时候太认真是件好事，或许只有用力过了，才能体会从心所欲、顺其自然的难得。 IT人员怎么用力总有在校的学生问我现在 X,Y,Z… 技术很火热，应该学哪个？ 我看他列出的那些准备学习的选项中，其实前景和热门程度都差不多。 这让他陷入了选择焦虑症，不管做什么决定都怕「一失足成千古恨」。 对技术发展趋势关心是好事，就像之前那篇「不要总是选择困难模式」里面说的那样。 但是其实在「不要总是选择困难模式」里面忽略了很重要的一点，就是你个人的兴趣。 比如有的人对苹果的东西有天生的热爱，所以选择「iOS开发」对他来说就更容易做好。 尽可能选择会让自己 Enjoy 的技术方向，路还很长，不享受过程的话容易半途而废。 太用力的人跑不远记得之前本科的时候喜欢和舍友一起打Dota，打Dota开局之前一般要等人齐， 等人的这段时间我有时候会切出来写写代码，叫舍友开局了告诉我一声。 然后别人看到我在打Dota间隙都在写代码，就觉得我有多努力多努力，给人了一种非常「刻苦」的印象。 以至于上次和一个本科同学吃饭他还说起这个事情，觉得我能做到这样非常「牛逼」。 但是其实这样的事情，如果对于真的对写代码有经历过热爱的人，是不会觉得有多么刻苦的事情。 这是自然而然的事情，甚至其实有些代码，那种满足好奇心的快感，是比打游戏有意思的多， 是件很Enjoy的事情，而不是所谓的「刻苦」。 就像跑步，「太用力的人跑不远」。不要用蛮力去学编程 记得当年初学 C++ 的同学，听别人说 C++ 很基础也很重要的一个知识点就是STL， 然后听说要学好 STL 就应该去看看侯捷的「STL源码剖析」。 然后就买了书硬啃，然后没啃几天就放弃了，觉得太讳莫如深了没法理解。 但是如果换个学习的方式， 先假设现在没有STL这个标准库， 让你用已有的C++语法知识去自己写一个仿造STL标准库的功能， 哪怕是最最简单的 vector 。 你在编写的时候就会自然而然得体会到内存动态扩展的一些缺点和潜在的坑。 会知道为什么适当使用 reserve 和 swap 能非常明显的提高性能。 然后在自己思考的过程中会提出很多相关的疑惑， 带着疑惑再去翻看「STL源码剖析」， 就会让你对一个个数据结构恍然大悟知根知底。 自然而然你的看书体验会非常的 Enjoy， 而不是觉得苦涩难咽。 编程和求知本身是一件愉悦身心的事情， 如果只是为了高薪，而用蛮力去写代码，只会让自己疲惫不堪。 最后希望对在学习编程的路上很挣扎的朋友有所帮助。 毕竟工作是生活的很大一部分， 如果工作不开心，生活怎么办。 不是人人都懂的学习要点学习是一种基础性的能力。然而，“吾生也有涯，而知也无涯。”，如果学习不注意方法，则会“以有涯随无涯，殆矣”。 一．学习也是一种能力看到这个标题，有人会说：“学习，谁不会？”的确，学习就像吃饭睡觉一样，是人的一种本能，人人都有学习的能力。我们在刚出生的时候，什么也不知道，是一张真正的白纸，我们靠学习的本能，学会了走路、说话、穿衣服…后来，我们上学了，老师把书本上的知识一点一点灌输到我们的脑子里，我们掌握的知识越来越多，与此同时，我们学习能力却好像越来越差了，习惯了被别人喂饱，似乎忘记了怎么来喂自己了。 学习本来只是一种本能，算不上什么能力，然而，经过二十多年的不断学习，学习反而成为了一种真正的能力，因为我们慢慢失去了它，它就更显得珍贵。 在学校里我们基本上被动式学习，然而走出了象牙塔之后，不会再有人对你负责，不会有人主动教你，我们需要主动的学习。所谓的学习能力，其实就是自主学习的能力。 几年前，曾有一本风靡管理界的书，叫《第五项修炼》，这本书倡导建立学习型组织，因为从长远来看，一个组织唯一可持续的竞争优秀，就是比竞争对手更快更好的学习能力。 一个公司如此，一个人又何尝不是如此？众所周知现在是一个知识爆炸的时候代，知识更新非常快。据说，一个大学毕业生所学习到的知识，在毕业之后的2年内，有效的不过剩下5%，更何况我们的学校与社会需要严重脱轨。我们赖以立足的，不在于我们现在掌握了多少知识，而是我们有多强的学习能力！ 学习不但是一种能力，而且是一种至关重要的能力，而这种能力的核心，就是学习的方法和心态。 二．买书是最划算的投资古人云：“书中自有黄金屋，书中自有颜如玉。”这说明先贤们早就认识到，买书是最划算的投资了。 当我刚出道的时候，拿着非常微薄的工资，有一次我向主管抱怨道：“现在的书真贵啊，这点工资连饭都吃不起，更别说买书了！”主管对我说：“不要吝惜买书的钱，宁可忍着不吃饭，也不要忍着不买书，因为买书是回报率的最高的投资了。” 主管的话让我非常震动。后来，我看到喜欢的书时，再有没有手软过。我不断的学习，开发能力也不断的提高，工资水平也获得了大幅度的提高。一年后，我一个月工资的涨幅，就足够买两年的书了。你说，还有比这更划算的投资吗? 一本书，哪怕只有一页纸是有用的，它将所产生的潜在价值，也会远远超过书本身的价格。当然，书不在多，能踏踏实实消化掉一本好书，可能比泛泛而读10本普通书，要更有价值得多。 三．多读经典书十年前，我刚进入IT行业的时候，真是求知渴，每星期都要往购书中心跑，可惜的是，那时给程序员看的书不像现在这么多，高质量的书就更少了。当时我印象中比较经典的书籍就是《Windows程序设计》、《COM本质论》、《Java编程思想》，还有就是谭浩强的《C语言程序设计》。其它充斥书架的，就是类似于《21天精通XXX》、《XXX从入门到精通》、《XX宝典》这样的书籍。 回首往昔，令我比较郁闷的一件事就是在我最有学习动力的时候，看的高质量的书籍太少，就好像是在长身体的时候，天天吃的是没营养的泡面。当然，这跟没有人指导也有很大的关系，独自一个人学习，让我走了很多的弯路。 软件开发方面的书籍，我大致将其分为三类： （1）浅显的入门类书籍。 这类书的标题往往是《XX天精通XXX》、《XXX从入门到精通》、《XX开发实战》等，这类书往往从软件的安装讲起，喜欢翻译帮助文件。有人批评这类书为烂书、毫无价值，这并不公平。至少我本人，也曾从这些书中学到一些东西。即使是21天系列书，也有适合看的人群，只不过，它一般也就只能看21天而已，过后就可以扔到垃圾堆。这类书只适于还没有入门的初学者，从中学到一些入门的招式。这种书在刚起步的时候一般买上一本就可以了。如果你善于使用搜索引擎，这一本书也可以省了。 （2）国内外高手写的实战类书籍。 这类书实战性很强，把技术及原理讲得很透彻。比如《windows环境下32位汇编语言程序设计》、《深入解析MFC》、《Delphi深度探索》、《深入浅出WPF》、《深入剖析Asp.NET组件设计》等。以前这类书都是从国外翻译或从台湾引进，现在国内高手越来越多，出自国内作者的也越来越多。这类书如果在你学习的每个方向看个两三本，并且通过实践消化掉，那么毫无疑问，你会成为一个优秀的程序员。 （3）国外大牛写的、揭露本质、有丰富思想的书。 这类书就是所谓的经典书了，例如《代码大全》、《编程珠玑》、《设计模式》、《重构》、《代码整洁之道》等。经典书就像一个有深度、有思想的朋友，他会给你启发、每次阅读都会有新的收获，这类书具有真正的收藏价值。看经典书永远是正确的选择，它绝不会浪费你的时间，因为经典书是无数人沙里淘金、帮你挑选过的结果。 然而，阅读这类书并不是一件容易的事情，读者需要有丰富的开发经验，才能与作者产生共鸣。真正能消化经典书的人其实不多，这就好像饮酒，一个新手无论如何也品不出葡萄美酒的醇香。在酒桌上，人人都把杯中酒一饮而尽，当有人点评“这个酒不错”的时候，我只能无奈的苦笑一番，真的是甘苦自知。 如果一本经典书你看得很辛苦，很有可能就是因为你功力未够，这种情况下不要着急，慢点来，不妨先将其先束之高阁，多看看第二类实战型书籍，过一段时间再回头来看，也许你会有新的惊喜。 四．不要在上班时间看书一个善于学习的人，首先要善于利用一切时间来学习。不知是伟大的雷锋叔叔还是鲁迅爷爷曾经说过：“时间就像海绵里的水，只要愿挤，总还是有的。”然而，当我们从上班时间中挤时间学习时，就千万要注意了，不要在上班时间看书！ 上班时间看书不但是一件很敏感的事情，而且非常吸引眼球，很快就会引起周遭的不爽。首先老板心里不爽，他想：“我给你钱是让你来工作的，不是来学习的！”；其次同事们也不爽：“我们工作都做不完，瞧，这小子真闲哪！”用不了多久，你就会成为被众人排斥的异类。 当然，你可能会说，“我工作已经做完了，经理没有安排，当然可以学习了”，其实不然。你完成了一件事情，不等于所有的事情都完成了。一个优秀的员工，应该是主动要工作，而不是被动的等工作。工作完成以后，你至少还可以： （1）主动汇报给你的经理，请他来检查你的成果，并安排新的任务；（2）如果公司这一段时间确实比较闲，没有什么具体的任务，可以进行代码重构、优化；（3）你还可以主动请缨，承担额外的工作或更艰巨的任务。（4）如果一定要学习，也只能对着电脑屏幕来学习，纸质书最多只能拿来翻阅一下，而不能一直捧着，以免影响到其他人的情绪。 五、只学习与工作相关的东西我曾发现不少程序员在学习方面找不到方向，一会学学C#，一会学学Java，看了最新的编程语言排行榜，又觉得该学C++。这样左抓抓，右挠挠，只会让你觉得更痒。 学习最忌三心二意。俗话说：“伤其十指不如断其一指”，每门都学一点，还不如专心学好一个方向。这个道理谁都懂，可是又该学哪个方向呢？难道只能跟着感觉走吗？ 不！最实际的方向，应该跟着工作走，工作需要什么，我们就学什么，把工作需要的技能熟练掌握。我们为什么要学习和工作弱相关的东西呢？是为了转行或跳槽吗？可是，如果我们连现在本职工作都不能做好，又怎么能保证到新的岗位、用新学的技能就可以做得更好呢？ 学习与工作需要的的东西，有很多好处： 首先，可以集中精力，在某一方面钻研得更加深入。所谓“百招会不如一招绝”，有了绝招，你还怕不能在“武林”立足吗？《天龙八部》中的慕容复武功博学无比，最后还不是被只会一招六脉神剑的段誉打得落花流水？ 其次，可以学得更快、更深入，因为学习更具有针对性，而且可以立即在工作中运用，可以马上检验出学习的效果，对存在的问题可以进行深入的研究，因此掌握的知识也会更加的牢固。 第三，学习与工作结合在一起，工作时间也就成了学习时间，这样突破了三个8小时的限制。有人说，我们每天所有拥有的时间可以分为三个8小时，工作8小时，睡觉8小时，另外还有8小时自己可以自由支配的时间。工作和睡觉的两个8小时大家都一样，决定人生高度的是另外这个8小时。当我们把学习的焦点放到与工作相关的知识上时，工作时间中的很大一部分，同时也就成了宝贵的学习时间，这真是一举两得的美事啊。 六．织网式的学习知识的广度和深度都很重要。作为一个程序员，深入把握技术细节，是写出优质代码的保证。但对于一个项目经理而言，知识的广度更显重要。项目中碰到的问题往往是综合性的，只有具有广博的知识，才能快速的对问题进行分析和定位。在程序员通往项目经理的道路上，我们必须有意识的扩大自己的知识面，形成更完善的知识体系。 每个人的知识体系就好比是一张网，我们学习其实就是要织这样一张网。 我曾看过渔网的编织过程，渔网虽大，也是一个结点起步，一个点一个点的编出来的，编织的过程中，始终只有一根主线。 学习又何尝不是这样，知识体系的大网也是由许多小的结点组成，要结这样一张网，只能由一个点起步。牵住一条主线，织出一个个的点，由点带出面，最后才能形成这张大网。 我曾经编写过一个网络信息采集软件，这个软件可以从具有列表页网站中按字段设置采集信息，支持自定义字段、页面多级关联、下载附件、支持多种数据库、可视化定义等特性。刚开始时，觉得这个软件也是一个比较大的功能点而已，后来发现这个不起眼的功能关联着大量的知识点，在开发过程中， 我顺藤摸瓜，各个击破，对很多知识点进行了细致的学习研究，软件开发完成后，个人的知识体系网也进一步得到了补充和完善。 图1 由知识点形成知识网 七．问题是最好的学习机会日本经营之神松下幸之助曾经说过：“工作就是不断发现问题、分析问题、最终解决问题的一个过程，晋升之门将永远为那些随时解决问题的人敞开着。”可见，工作过程中有问题是正常，没有问题那才是真正的问题。在发生问题能时，能勇于面对问题、解决问题的人，才是公司真正的核心骨干。 现实中，很多人总是千方百计回避问题，当上司安排一项艰巨的任务时，也是想尽办法推托。殊不知，对于个人而言，其实问题是最好的学习机会。往往那些愿意接受困难工作的人，能力会变得越来越强，那就是因为他们在克服困难的过程中取得了巨大的进步。 有一次，一位项目经理对我说：“有一个问题，客户有一台HP服务器要装磁盘阵列，没人会做，怎么办啊？” “可以学啊，没有人愿意去吗？” “我都问了，没人想去。” “哦，正好明天我有时间，我也没装过磁盘阵列，那我明天去学着弄一下。”我说的是真心话。 第二天早上，当我准备出发时，项目经理告诉我不用我去了，因为项目组好几个同事都想去“学着弄一下”。 结果服务器很快就装好了，远远没有之前大家想像的那么困难嘛。更重要的是，在解决这个问题的过程中，大家都学会了怎么装磁盘阵列。 碰到困难时，迎难而上吧，千万不要拒绝这个最好的学习机会！ 八．经常思考总结子曰：“学而不思则罔”。只学习不思考，就会迷惑，难以把握事情的本质。这就好比一个学武之人，只习得其形，而未得其神，难以成为真正的高手。 一个程序员从入门，到成为高手的过程中，往往要经过几次顿悟。顿悟会让你跳出知识的丛林，一切豁然开朗，仿佛打通了全身的奇经八脉一般奇妙。记得我有一次，顿悟到了一个很简单的结论：“原来高级编程语言中的类库是封装了Windows API来实现的。”后来碰到一些自带类库无法实现的功能时，我就会想到，其实可以通过调用Windows API来实现。利用这个思路，我解决了一些看起来很难的问题，得到老板的赏识，从而很快获得提升。 顿悟非常可贵，然而它不是随便发生的，而是经过一次次苦苦思索之后、灵光闪现的结果。思考的过程，其实就是将外在的知识内化为自己的知识的过程，而顿悟，则是批量的实现这种内化，将无数个知识点连接在一起，达到融会贯通的境界。 九、克服“高原现象”爱学习的人都会有这样的经历，学习持续了一段时间之后，往往会有一个瓶颈期，长时间似乎很久没有什么进步，于是内心非常着急。 这种情况实际上这是由人的学习规律决定的一种“高原现象”。据研究，学习者在刚开始进步快，随后有一个明显的或长或短的进步停顿期，后期进步慢，中间的停顿期叫高原期。 图2 技能学习练习曲线 在我看来，高原期实质是一个消化期，由于前期的学习积累了太多的知识点，这些知识点在大脑中乱作一团，还没有形成一个知识体系。这时需要一定的时间来消化它，将它融会贯通，经常思考总结可以快速帮你跨过高原期。 在处于高原期的时候，还可以换一个相关的方向来学习，例如编程语言学不下去了，你可以学习一下设计模式，设计模式也学不下去了，再换成数据库。通过学习这些相关的知识，不但补齐了知识体系中的短板，而且各个知识点之间可以互相启发，帮助你实现顿悟，跨过高原期。 十、学习要有好心态（1）学习要静心 急于求成是学习过程中普遍存在的一种心态。这可以理解，毕竟作为一个程序员，要学的东西实在太多了，而社会又是那样的浮躁，让人觉得一切都是那样的不安全、不确定，似乎只有学得快一点，才能跟上社会的脚步。 可是“欲速则不达”，想快快的学，往往会形成东一榔头、西一棒槌的学习方式，每一个点都没有吃透。心沉不下去，知识也会沉不下去。要想成为真正的高手，只能静下心来，一步一个脚印的攀登。 （2）学习是一个持续一生的过程 人生的过程，就是一个自我完善过程。 孔子曾经说：“吾十有五而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲，不逾矩。”可见孔子也不是天生的圣人，也在不停的学习、进步，从“志于学”到最后“从心所欲，不逾矩”，孔子一共花了55年的时间。 作为一个程序员，更是需要不断更新自己的知识。我们所知道的东西，就像一个白色的圆圈，圈外则是黑暗的未知的世界。当圆圈越大，所接触到的黑暗部分就越多。我们只有不停的学习，打破更多的黑暗，找到更多光明。 （3）保持饥饿，保持愚蠢 看了《乔布斯传》之后，我最喜欢的一句话是“求知若饥，虚心若愚”（Stay Hungry,Stay Foolish），其实我更喜欢它更原生态的翻译“保持饥饿，保持愚蠢”。我们只有认识到自己还很饥饿和愚蠢，才会像没吃饱一样，由衷的需要学习、爱上学习。 当然，知易行难，知行合一才是学习的最高境界。我也始终是一个学习者，一直在路上。 关于App程序员泡沫前言 做开发快七年了，对于程序员，外行人总有着数不完的讽刺和误解，但是我都懒得去解释，代码搬运工人也好，民工也罢，随他们去说吧。但是网上最近流传的程序员泡沫,尤其是APP程序员泡沫的文章导致很多我们的年轻的同行产生了疑惑,所以我这个隐藏了很久的能言善辩的老程序员出山来聊一聊这个APP程序员泡沫的话题。 笔者是2010年从事安卓开发，此前做J2ee,对于安卓我有很深的感情，此前也是有意学了iOS，但是还是决定在安卓这条路上一直走到黑，在2010年一个好的安卓开发苗子工资可以过万，工作经验也就1年那样子，基本上你会点安卓都可以接近1W。想想最近某些文章中提到现在安卓开发新手动不动就要过万的工资相比，我觉得现在的新手做法并不为过：第一，以现在的北京物价房价对比2010年来说，开发的工资其实并没有涨反倒是跌了。第二，现在的开发比2010年的新手安卓开发要厉害一些，那个时候网上资料很少，书也很少，大多数安卓开发自学起来很痛苦。现在网上资料多，也有很多高水品的技术书，也有很完善的培训机制。 当然现在很多APP开发存在漫天要价的现象，但是作为企业的HR,技术经理甚至老板你可以选择不要他啊。这篇文章只讨论一般的APP开发，脑残的APP开发不在此文范畴。 1.大环境 首先我们说说大环境，现在是互联网时代，你别跟我说什么资本寒冬，在2008年经济危机时，也没见哪个程序员饿死了。资本寒冬只是暂时的，从2010年到现在死的互联网公司多了去了，又会有无数的互联网公司站起来。人们已经离不开互联网和手机了，做为必需品你觉得会破灭吗？就如同北上广的房子一样，08年说泡沫，现在这么多年过去了，谁还会相信这是泡沫呢？ 2.App开发 接下来我们说一说安卓开发和iOS开发，windowsphone我们暂且不谈，这家伙10年就说要干掉安卓，也就过过嘴瘾。 我现在引用一篇文章的看法:”泡沫，毕竟是泡沫，终有爆破的那一天。这个时间不会很长，3到5年。随着新技术慢慢变旧（当Android和iOS变成和C语言一样老），随着大批量的人才涌入和一些公司退出（十万开发者面对一千岗位），随着很多老板慢慢发现原理和真相（APP真的只是个终端）。” 一看就外行人写的，还说当Android和iOS变成和C语言一样老，现在写C，C++赚的不比App少，Java老不老呢？2010年做Javaweb的优秀开发月薪2W+，再说Android和iOS不是语言不能和C语言比较，我牙都笑掉了。在此我们只能看到这是外行人眼红App开发工资比他高，他又转不了开发罢了，和windowsphone一样也就过过嘴瘾。 3.安卓和ios灭亡 有不少眼红的人希望Android和iOS灭亡，就像塞班一样，看Android和iOS灭亡了你们怎么办？笔者的同学以前做塞班的，塞班灭亡了他转做iOS，现在一样很牛逼，因为人家C++强，转iOS有优势。同样如果安卓灭亡了，安卓开发可以转Java，iOS。其实年轻的App开发不用担心这些，当你的技术达到一定层次，语言已经不是阻碍我们的脚步了，笔者1周就学会obj-c,写iOS代码了。同时也给年轻的App开发建议就是要注重基础，安卓和iOS只是武学招式，真正使他们发挥威力是你的内功，也就是你的基础。 4.互联网职位稀缺性 一个优秀的程序员是十分难求，他不是去熬年头就能得到的，他需要付出很多，阅读很多书籍，看过很多技术文章，敲过很多高质量的代码，无数个Bug折磨过的，一步步才培养起来的，反观其他的互联网职业我就不便多说什么了，优秀的是有，但更多的是熬年头拼学历，他们所付出的努力远远没有优秀程序员付出的多，他们所创造的价值也未必有他们想象的大。现在有产品思维能言善辩的App开发越来越多，他们可以去抢产品经理的饭碗，但产品经理很难抢程序员的饭碗，这也说明了优秀App程序员的稀缺性。现在我在招聘网上找一个3年以上经验的安卓开发都很难，就算找到了也很容易被别的公司抢走。现在市场上最多的是1到2年的App开发，还有一些从别的行业转过来的App开发，靠谱的很少。 5.提升自己让别人去喷吧 我们中国人的一大劣根性就是见不得人好，这是正常现象，那么怎么提高自己使得自己更强，让别人更眼红呢？ 看清自己并尽早规划职业生涯 早看清自己的人早确定方向，看到自己的优点避开缺点，如果你热爱开发你就继续干开发成为App架构师。如果你能言善辩，组织能力强又敲的一手好代码，那就去做技术经理。如果你只是为了钱而不喜欢代码，那你得想办法尽快脱离这个行业。 如果闷头去敲代码这显然是大部分程序员都能做到的，但是你有没有想过程序员这个职业可以做一辈子嘛，早做打算并且要对自己的职业生涯负责，找到自己的本性和擅长并发掘自己的潜力，从而决定自己是做个技术经理、架构师还是个什么其他相关的职业，工作多年如果还是和刚入行的干一样的活这显然不会提升自身的价值也迟早会被这个行当所淘汰。 做有产品思维的程序员 平常多看看其他的App是怎样的，和自己的对比下，每做一个需求要考虑它是否是必须的，能为用户带来什么，而不是产品经理让做什么就做什么想都不想。 业余多看书，多写代码，写技术博客，找到适合自己的学习方法 想要脱颖而出你不付出努力又怎么能行，平常可以写一些自己想写的代码，把他写到博客上或者建立自己的代码库，写博客可以提高自己的写作能力同时也检验你的技术的掌握程度，你会发现你为了写一篇技术文章会查很多资料看很多书，遇到很多的坑，这是你去看别人的技术文章所得不到的。技术首先要做到先精，再做到广，什么叫做精，至少我现在的也不敢说精通Android，不会的实在是太多了。而我现在看到的就是很多开发什么都想搞，结果什么都搞不明白，今天学了Android，明天看看iOS，后天H5和RN火了又都去学，结果什么都不专什么都不精，知道慕容复嘛，会的再多也打不过专精一门武学的乔峰吧。只有你先精一门的前提下再去深入的研究其他的技术这才是对的。不要跟我说什么全栈工程师才是未来的大势所趋，才是王道，跟我说这个首先要明确什么是全栈工程师？全栈工程师至少要精通一门，会一堆技术结果全是半吊子也好意思说自己是全栈？作为Android开发多看看底层的源码，Java的基础，设计模式和算法以及iOS的基本知识。更重要的是在学习的过程中找到适合自己的学习方法，比如我就是多看书，然后敲一敲自己喜欢的代码，写博客总结归纳。关于书，我建议大家还是多多宜善，不仅仅限于专业的。古时文人为了一本书可以受饿攒钱去买，但现在的大多数人，在吃穿玩上花了很多的钱，唯独在书上却斤斤计较，希望大家都能养成爱读书、读好书的好习惯。 提高自身形象，培养软实力 App程序员同时也需要跟别人打交道，至少要穿的得体干净，别自己舒服却让别人不舒服。多培养自己沟通的能力，多想想其他人是怎么想的，培养自己的同理心，管理好自己的情绪，学会什么时候该发火，什么时候该淡然一笑，学会对着那些令人无比生厌的小人报以自然的微笑。网上讨论什么牛逼的人应该脾气好，但我不这么认为，该霸气时就应该霸气。如果我们程序员能言善辩，精通业务，人际关系好，人脉广，并且还能敲的一手好代码，这绝对非常恐怖。 保持良好的技术敏锐度和前瞻性 作为一个开发，技术的敏锐度和前瞻性是极其重要的。做技术难免会遇到技术的更新和新技术的出现，如何去选择变得极为重要，因为人的精力有限，这一点选择远远要比努力重要。首先要选择自己擅长的那门技术相关的新技术来进行学习，接下来再考虑其他的新技术。说到其他”新”技术，不得不提到H5和RN，作为一个移动开发者和一个手机用户，并不看好这两门”新”技术。从用户的角度来看，我们更追求高品质和最好的体验，显然H5和RN都无法达到这一点，另外想想PC端也出现了很多web应用，但至今都不温不火的，因为体验太屎了，我宁可下个客户端也不会在web应用上做操作。总结一句，就是H5难成大器。作为一个开发者，H5只适合一些商城或者广告类的界面，它只是一种解决方案，想要拿它做App那太扯了。有人在2011年就说H5是趋势是潮流，过了5年还在说，是不是等我退休了你们还在说H8是趋势呢。至于RN，可能未来会有一些进展，国人太喜欢炒作也太浮躁，Android和iOS都有自己的成熟的开发框架，非要在此之上罩上一层去写js，感觉就像是不脱裤子拉屎一样（我实在找不到很好的形容）。用你们的脑子想想，未来人们追求的是什么，是极致和高品质，为了所谓的商业模式来应付用户群体必定走不远，当然想捞一票就跑的可以忽略极致和高品质这个问题，用户不会关心你用了什么技术，他们只关心好不好用。不好用的直接扔垃圾箱里，好用的就算时常让他们下载新版本也会有人用。总结一句，RN可能就是一个搅屎棍，它的出现可能会让很多人趟浑水并且浪费很多时间。对于RN现在我也是持观望态度，因为我发现真正重要，能让我走的更远的是基础和深度，而不是这些前途不明的潮流框架。总之，对于新技术要有自己的判断，不要听风就是雨。 选择好平台，不要计较一时得失 在好的平台才能得到最大的利益，才会发挥自己最大的能力，相反在差的平台以及不适合自己的岗位上就算再努力也白费，除了你手里那点钱什么都得不到，还会赔上最有价值的青春。有时要学会放弃，面对不好的平台、不适合自己的岗位当断则断，计较一时的金钱得失可能会葬送自己整个人生。就好比金子扔进茅坑它永远不会发光，一个铝片放在舞台上却能够闪光，不管我们是金子还是铝片一定要区分茅坑和舞台。既要活在当下同时眼光也要放远。 去做去行动 大道理很多人都懂，为何脱颖而出的就那么几个人，因为他们不只懂而且也去做了","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Programming","slug":"Programming","permalink":"http://ipcreator.me/tags/Programming/"}]},{"title":"JavaScript教程","date":"2017-02-19T22:53:06.000Z","path":"2017/02/20/Program/Concepts/learn-journey-of-javascript/","text":"作者：廖雪峰 这是小白的零基础JavaScript全栈教程。 JavaScript是世界上最流行的脚本语言，因为你在电脑、手机、平板上浏览的所有的网页，以及无数基于HTML5的手机App，交互逻辑都是由JavaScript驱动的。 简单地说，JavaScript是一种运行在浏览器中的解释型的编程语言。 那么问题来了，为什么我们要学JavaScript？尤其是当你已经掌握了某些其他编程语言如Java、C++的情况下。 简单粗暴的回答就是：因为你没有选择。在Web世界里，只有JavaScript能跨平台、跨浏览器驱动网页，与用户交互。 Flash背后的ActionScript曾经流行过一阵子，不过随着移动应用的兴起，没有人用Flash开发手机App，所以它目前已经边缘化了。相反，随着HTML5在PC和移动端越来越流行，JavaScript变得更加重要了。并且，新兴的Node.js把JavaScript引入到了服务器端，JavaScript已经变成了全能型选手。 JavaScript一度被认为是一种玩具编程语言，它有很多缺陷，所以不被大多数后端开发人员所重视。很多人认为，写JavaScript代码很简单，并且JavaScript只是为了在网页上添加一点交互和动画效果。 但这是完全错误的理解。JavaScript确实很容易上手，但其精髓却不为大多数开发人员所熟知。编写高质量的JavaScript代码更是难上加难。 一个合格的开发人员应该精通JavaScript和其他编程语言。如果你已经掌握了其他编程语言，或者你还什么都不会，请立刻开始学习JavaScript，不要被Web时代所淘汰。 等等，你会问道，现在有这么多在线JavaScript教程和各种从入门到精通的JavaScript书籍，为什么我要选择这个教程？ 原因是，这个教程： 是JavaScript全栈教程！ 可以在线免费学习！ 可以在线编写JavaScript代码并直接运行！ 不要再犹豫了，立刻从现在开始，零基础迈向全栈开发工程师！ 关于作者 廖雪峰，十年软件开发经验，业余产品经理，精通Java/Python/Ruby/Visual Basic/Objective C等，对开源框架有深入研究，著有《Spring 2.0核心技术与最佳实践》一书，多个业余开源项目托管在GitHub，欢迎微博交流：","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Java Script","slug":"Java-Script","permalink":"http://ipcreator.me/tags/Java-Script/"}]},{"title":"人工智能的黄金时代","date":"2017-02-19T15:59:59.000Z","path":"2017/02/19/BusinessAI/golden-age-of-artificial-intelligence/","text":"“人工智能时代，将是一个比移动互联时代大十倍的市场 —-李开复” 10年后，人工智能能将取代世界上90%的翻译/记者/助理/保安/司机/销售/客服/交易员/会计/保姆。 人工智能也就是这样几个事情，感知、决策、反馈。 人工智能发展的主要里程碑。 近年最大的突破：深度学习深度学习是什么？你丢一大堆数据给它，然后问它，我应该买什么股票？这个人的保险该付多少钱？这个想贷款的该不该贷？这个信用卡的交易是否有欺诈的嫌疑？你还可以问他，这么多的男人你应该找哪一个为对象？你也可以问他，今天晚上这么多好吃的，我应该吃哪些？它都会告诉你一个答案。 深度学习之后还有更新的技术 什么领域适合人工智能海量的数据，清晰领域界限，顶尖的AI科学家，还有自动标注数据，以及超大的计算量。科学家的创业时代来临了，而不是三个小朋友的创业时代。 机器学习在很多领域超越人类、创造巨大价值左上角代表的是在图像识别领域机器超越人类，左下角是语音识别领域机器的错误率低于人类。当人脸识别超越了人类，我们还需要保安吗？当语音识别超越了人类，我们还需要客服吗？还需要打电话推销吗？当自动驾驶超越人类，我们还需要司机吗？当传内容，写新闻，金融稿件的能力超越了人类我们还需要金融界记者吗？90%的金融领域的报道都是传出来的，这些报道以后绝对不是人写的，人写是会犯错的，机器不会犯错，只有深度的报道才需要人写。那到底哪些领域可以做人工智能，可以挣钱呢？实在太多了，这里随便列了三十多个领域，在任何一个领域就是一个商业计划书，如果你能找到一个该领域的超级的商业专家，销售专家，再搭配一个人工智能的科学家，那就是一个黄金创业团队。 简单来说，谁能做人工智能的创业 第一种，谁手中拥有互联网数据的这个是最了不起的，也就是BAT、滴滴、美图等等，他们手中有数据，而且已经标注，只要有科学家就可以产生价值。 第二种是传统企业，比如说股票的数据，比如说保险业、银行业，各种金融的。我觉得数据非常的丰富，而且是非常的狭窄领域，不用跨领域的理解，而且可以快速产生商业价值。再往下医学，如何看片子，看MRI，看CT，看各种人的健康记录一定是超过医生的，现在至少有3种重要的病症人工智能已经超越了医生的平均水平，而且你像这个是要花多少临床的时间，现在三种可能再过5年就是300种，再过10年可能就是3000种。然后90%的医生就都不需要了，至少被机器取代。那这些医生就要做更高等的工作，更深入的工作，去发掘新的医药的工作，或者是做更心理医疗的工作。面对病人，机器还是冷冰冰的，可能还需要一个人脸对着病人，但是90%的医生，在10年以后应该都打不过我们机器的诊断能力了。这对人类是有很大意义的，教育的数据也是很多的，就不多细讲。 最右边是无人驾驶。这是我们特别看好的领域，它是最大颠覆量的，以后都不需要人开车了。再加上电动车和共享经济，以后我们出门的时候，一辆坐一人的车就会出现在我们面前，它带我们去要去的地方，节能低碳，减少雾霾，而且这还会影响整个经济。如果大家谁有投资停车场的，十年以后就没有停车场了。所以，这些都有巨大的颠覆性。如果你们觉得听起来像是天方夜谭，像是科幻小说，那么你们也可以想一想，2009年当我告诉所有人移动互联网时代来临的时候，大部分人也是这样想的。甚至当时的BAT听了移动互联网的预测之后，他们总是认为没有PC大，没有PC赚钱，成长的会很慢。但现在你看他们一个个也都追上来了。所以人工智能是一个特别巨大的领域和机会。 我们到底该和谁学人工智能呢？ 世界上最懂人工智能的绝对是谷歌这个公司了。在一年前他就宣布了要做Alphabet这个母公司。什么是Alphabet呢？其实它就是把谷歌里面做搜索提炼出来的人工智能做成谷歌大脑，然后把它用到各种领域。用在围棋就成了AlphaGo，我们已经看到它的威力有多大了，用在汽车就是Google car，用在健康就是Google house用在基因检测就是Google genetics，所以在Alphabet上面，谷歌的野心就是要把一个谷歌的成功变成26个，这是一个特别有野心的人工智能的公司。 谷歌公司内部也是在用刚才所说的深度学习。这个图是来自谷歌的一个科学家，他对外演讲用的我们可以看到也是在这4年，他们才领悟了人工智能的价值和谷歌大脑的价值，收购了Deep Mind这样的公司。所以很明确的就是，谷歌的Alphabet这样的一个动作，绝对是它看到了机器学习可以进入各种领域的机会，这也是它所进行的一个很有野心的探索。 到底人工智能如何克服挑战产生竞争壁垒呢？ 第一，就是要寻找行业里面有特别大的大数据，然后是垄断性和闭环的。第二是买很多机器，尤其是CPU＋GPU。第三是有很厉害的深度学习的科学家。第四，虽然这些顶尖科学家很有价值，同样的小朋友也有价值。不过小朋友还不能创业，需要培训。人工智能很大的一个特色是速成，他不像是你去找一个化学科学家，或者说生物科技或者甚至是计算机领域的这个Networking 、Database之类的，非常难学。人工智能不一样，它很好学，前提是你一定要是一个数学天才。 怎么样让人工智能快速商业化 第一是做助手，而非取代人。第二是界面要用好，给很多结果，而不只是一个结果。第三草船借箭，要用户提供数据，如果你的数据不够。第四局限你的领域，不要做一个特别伟大的超级的技术。 中国的独特人工智能机会 中国在人工智能领域比移动互联网领域还适合创造世界顶尖的公司。第一个理由就是，中国人很适合做人工智能。第二，训练小朋友非常快速第三，传统企业的人工智能技术非常的弱第四个理由，因为中国市场大，互联网公司多，很多非AI的公司到了一定的规模，就开始需要AI。第五点，美国人工智能现在是绝对领先中国的，但是他们进不了中国，中国上面有各种理由。最后一点是中国对人工智能各方面的约束较少。 创新工场对人工智能有一个很完整的投资蓝图 第一个重点是大数据的机会第二个是语言方面第三呢，是传感器的降价非常的重要。最后是自动驾驶 创新工场在人工智能领域在做什么呢？ wonder workshop，它是一个人工智能的玩具。它可以跟着小朋友，就像现在的这个大疆新的机型，可以让它跟着你一样。甚至两个机器可以在一块玩等等，很有趣的。它是一个没有眼睛、耳朵、手与脚只是几个小轮子做的这样的一个机器人，我们认为这个领域也像Echo音响一样是有机会的。 找一批专家带一批学生，买大量的数据，数据也包括了金融交易的数据。AI时代的创业呢，都是科学家。 如何去做早期公司的投资 第一个怎么投资公司。刚才我已经说过了，要衡量它有没有大数据，然后有没有独特的大数据，不是买来的大数据，有没有科学家，有没有闭环，有没有很多机器。然后他做的这个领域，是不是可以产生商业价值的领域，还是一批科学家在瞎搞。这是第一个。看这些项目要小心，还有看机器人的项目，有眼睛耳朵手与脚的就千万不要再听了，虽然听起来很酷。无人驾驶可以去想想怎么去参与。 这是投公司的，投基金呢？投创新工场和真格基金就可以了。 至于买股票呢？我是美图的董事，可能下面不适合说，但是你应该知道我要说什么，我们看好美图，认可美图。 刚才也分享了，量化AI在国内的投资应该机会特别大，这不是一个人工智能投资，这是一个真的二级市场的投资，当然要避免一些法律所不允许的事情，但是机会还是很多。那么我们现在也在专门看这个量化AI投资，对于这些呢，如果有兴趣的我们也可以一起以后在别的机会一起探索。 我也给大家说了，过去两年，我所有的资产基本都是在创新工场里，除了一栋房子，创新工场，我所有的资产基本上都是交给机器人管理，都是用AI量化来管理。这个也就是告诉你我对这个领域是多么看好和认可。当然三年后这个领域可能就是红海了，只是说现在的机会是非常好的。当然我还有一支股票是例外的，是我孩子决定要投资的。就像如果说在移动互联网时代，二级市场最好的投资标的是ARM，人工智能的时代是什么？大家确实可以看一看NVIDIA。 报告称：被机器人取代的不止低端行业 中产阶级也有风险 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 【网易智能讯 2月7日消息】 该研究分析了在技术发展情况下高薪工作被自动化设备取代的风险。 研究指出，房地产经纪人和信贷分析师 等中产阶级职业被自动化设备取代的风险高达97%，而包括侦探、法官和治安官被取代的风险偏向中等，包括牙医、医生和消防员等职业被自动化取代的风险较低。 总体来说，技术的进步很快就会使几十个中产阶级工作岗位变得岌岌可危。 该研究的作者Carl Frey是牛津大学的一名校长，他之前曾发表过一份研究报告，认为英国有35%的工作处于被机器人取代的危险之中。其主要工作是分析今后哪些收入更高的工作可能会消失。 通过对诸多年薪超过4万美元的工作进行深入调查分析，Frey编制了一份风险清单，显示了哪些工作最容易被自动化所替代，同时哪些工作最有可能存续下去。 研究指出，由于计算机技术的不断发展，保险公司和房地产中介等高收入中产阶级正在面临被取代的风险。该类工作有97%的概率将会被计算机所替代，也会引发相关中产阶级的担忧。 Frey告诉《时代周刊》，“在未来几十年内，对专业技能要求较低的工作岗位自动化程度会越来越高，但中等收入的工作岗位同样面临会面临着被自动化取代的风险。” 信用分析师也被归于Frey的高风险列表，其职位有97%的概率会被机器人所取代。邮政服务工作者岗位被取代的概率是95%，而实验室技术人员的风险为89%。 此外，研究指出，地铁或有轨电车的工作人员有93%的概率被自动化。 这些数据表明了一项客观的评估，即科技如何取代人类完成工作和任务的交互，并不是说在不久的将来人类工作将变得多余。另一方面，这项研究也表明各类工作有被自动化的风险。 研究人员称，消防员、牙医和医生等专业岗位被自动化的概率不到1%。这项研究也表明，长期来看此类工作相对安全。其中包括诸如牙医、精神病医生和营养师等医疗保健岗位。总体来看，整个医疗保健行业的岗位普遍“低风险”。此外还包括营养师、营养学家、精神病医生、足疗医生和药剂师等职位。 根据这项研究，包括侦探、法官和地方官员等岗位属于中期内安全职业——这或许表明，虽然理论上这些工作可以自动化，但技术的复杂性还无法满足现实需求。 长期以来，人们认为传统的低技能工作将逐渐被淘汰，因为随着经济的发展计算机技术的应用更加具备成本效益，技术的发展将使那些看似脆弱的工作岗位变得更加脆弱。 尽管这项研究分析的是美国岗位，但Frey指出，由于行业相似，发展阶段相同，这项研究也适用于英国。 （英文来源：每日邮报编译：机器小易 校对：晗冰）。 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 停车库、浏览器、提款机、十字路口与办公室，都将由AI控制 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月6日消息，如果人工智能（AI）真的在改变我们的日常生活，它会如何改变?仔细想想，你就会发现，像人类这样处理信息的技术依然处于早期阶段，但它已经出现在聊天机器人和像亚马逊Echo这样的扬声器上。然而，我们每天使用的许多服务仍未获得AI支持，这是多么糟糕！ 1.AI停车库 目前正在进行的许多尝试，都希望让泊车变得更容易，其中包括福特的汽车，你可以使用应用来预订停车位，并支付停车费。但我希望的是更先进的方案。 当你驾车到来时，由AI支持的停车库可以识别出你的车，然后查阅你的账户。当它发现你是老顾客时，头顶的扬声器系统就会与你聊天，并引导你到空旷的地方，向你展示你的奥迪的“夜生活”，然后让你自动付款。当你离开时，如果有任何问题，都可以在出口处跟机器人协商处理。 2.网络浏览器 网络浏览器如何能从人工智能中获益呢?这听起来似乎显得有些牵强，但当你在网页上搜索特定主题，比如新的打印机时，AI助理会注意到，并提供最佳选择的链接。它会帮你记住这些网站——不仅仅是把它们放在书签或收藏在浏览历史中，还可以把它们保存在知识库中。 你不需要搜索那个档案——AI可以提醒你这些事实和链接。它可能会关注你在社交媒体上发布的信息，甚至建议你不要和一个在Twitter上攻击别人的人打交道。而且，它可能还可帮助我们进行标签管理，调整我们正在使用的标签宽度，或者提供我们昨天就没有触碰过的标签。 3.自动提款机 这些愚蠢的终端可能会变得更聪明。当然，我们主要需要它们进行存款和提取现金。有些最受欢迎的银行ATM可以记住你通常使用的选项，比如最喜欢的账户。人工智能会更了解你，提醒你(如果你启用了这个功能)关于到期的账单等。 最重要的是，它会使用生物识别技术来识别你，知道你总是在特定的日期存取款。它还可了解你的其他习惯，以使这个过程变得更快、更容易。 4.道路交叉路口 我知道现在正努力让公路变得更加智能化——在不久的将来，我们的汽车将会知道什么时候交通灯会变绿。然而，人工智能将能够随时识别汽车和卡车的确切位置。它可以与信号灯进行交流，以调整交通流量。 如果人工智能可以进行干预(如果我们允许的话)，汽车本身知道如何避免在十字路口发生碰撞，并调整两辆车的方向盘和刹车，其中包括由傻瓜驾驶的汽车。 5.办公桌椅 这看起来可能有些奇怪，但它的确能从AI中受益。假设你的办公器具都有AI支持。你的椅子可以调整，以便符合你的骨骼结构或任何医疗条件。 你的站立式办公桌可以根据你的身高和体重(以及打字风格)来调整，以符合最佳的人体工程学。当你坐得太久时，桌子可能会建议你站立15分钟。如果你没精打采地坐着，椅子可能会轻轻地推你一把。 （英文来源/venturebeat，编译/机器小易，校对/小小 ） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"}]},{"title":"猎豹CEO傅盛：关于深度学习的五个思考","date":"2017-02-19T15:59:59.000Z","path":"2017/02/19/BusinessAI/some-thoughts-of-fusheng/","text":"来源：36大数据 作者：傅盛 任何一场革命，绝不是以敲锣打鼓的方式，来到你的身边。等到某一天，你忽然发现快要天翻地覆时，再去看，发现自己已被别人抛弃了。过去以端为中心的技术革命，不能说结束了，但已不再是时代的风口。 技术，进入了一场以数据为驱动的革命。互联网不再只是一张虚拟的网，而更像是一个大数据库。大量的数据，沉甸甸，就在那里。没有人知道，怎么把这些数据，更加完整清晰的表达出来。我们需要重新思考技术的致胜点。 怎么思考呢?我讲几个关键点。 1、数据和运算能力，变得越来越重要。孔子说过一句话：“学而不思则罔，思而不学则殆”。 先说，学而不思则罔。你拿了很多知识，不深度学习，不行。如果你没有运算能力，有了一堆数据，算不出来，没用。不是深度越深，效果越好。这是个复杂的问题。需要不停算，不停实验。 今天，整个深度学习的理论，还不够成熟，依然落后于实践。更多时候，只能靠试。此时，运算能力，就变得非常关键。 假如，别人做一次运算，要两个礼拜，而你只需要一天或2个小时。同样时间内，你可以做更多实验，积累更多宝贵经验，迭代速度也更快。 这就好像，两个人起点一样，但由于迭代速度不同，导致了最后成就的千差万别。每一次迭代，相当于你的一次翻版。你是一天迭代一次，还是一年迭代一次。你对自己翻版本的速度有多快，决定你最后以多大的成果超过对手。 思而不学则殆呢?简单说，如果你没有数据，一点用都没有。 这个时代越来越需要海量数据。数据量越大越好。甚至于，我们以前被认为不是很关键的数据，都有可能灌进去，再看效果。 这才有了一句流行语——Welcome to the GPU world. GPU最早为快速满足增长的图形计算需求而设计。它不同于CPU，在多核多线程处理上浮点性能更佳，使得它在图形界的并行运算，变得超强。 早期，谷歌发表了一篇论文说——深度学习的结果，要跑在英伟达的GPU上。很快，做芯片起家的英伟达，其公司股价开始蹭蹭蹭一路上涨，涨了好几十块。 然而，如果今天，你还以为英伟达是个显卡公司，那就大错特错了。如今汽车的防撞系统，警告系统，以及无人驾驶采用的双目视觉图像处理，英伟达是第一大提供商。它其实变成了一家人工智能公司。 说到这，大家可能也会奇怪——今天关于无人驾驶，辅助驾驶的新闻越来越多，也有越来越多的公司在做，为啥呢? 核心就在于，深度学习极大降低了这一门槛。只要你能拿到足够数据，就可能实现对物体的各种判断。 本质也带来了一个技术上弯道超车的好机会。很多公司辛苦积累的软件技术直接作废了。包括IBM做了语音输入好多年，上来就被深度学习超越了。尤其当谷歌进入语音输入时，一下就超越了IBM多年的技术积累。与此同时，谷歌还有足够多的数据，以及足够多的语音样本，不停输入。 算法为核心的竞争力，正转换成数据为核心竞争力。 我个人觉得，甚至有些算法会消失掉。但，并不是说算法不重要。只是神经网络的核心算法，提升起来太难。 现在大家都把专注度放在了数据和运算。尤其在深度学习里，获取足够多的数据，就有机会产生更好的结果。神经网络本身差异不会很大，关键比的是——谁能把这些数据用好，并快速计算。 数据变得越来越重要。尤其在深度学习里，获取足够多的数据，就有机会产生更好的结果。神经网络本身差异不会很大，关键比的是——谁能把这些数据用好，并快速计算。 2、公司研发结构会发生很多改变，数据获取和数据标注会变得非常重要。中国在这场竞争中，还是有很大机会。能够轻易获取的互联网数据，以及低成本的众包劳动，将为中国公司带来训练所需的计算和人力资源。 第一，数据获取的量级。尽管美国整个技术的前沿性很好，问题在于——硅谷一家小公司拿到的数据，和一家中国高速发展的互联网公司拿到的数据，不可同日而语。 第二，数据标注的成本。在美国，要搞数据标注，肯定很累，多贵啊!但在中国，到珠海或成都随便找300个人，去帮你标注，成本很低。ImageNet图像分类大赛，中国人取得的成绩明显突出。国外，微软或谷歌参赛，都是几个人去做图像标注和算法验证。而中国可以组织足够多的人去做标注。我认为，ImageNet大赛，未来的世界冠军都会来自中国。 3、并行异构计算的人才，变成核心竞争力。过去计算领域都是以CPU为中心的计算模式。深度学习要将CPU和GPU两个加起来。这是两个技术的计算模型，是异构的模型。 为什么要异构? 因为GPU是并行的。它需要用来显示。为了让你的屏幕刷新保持更快更流畅，就要把GPU分成很多个小的运算单元。每一个运算单元，负责屏幕某一块具体区域的刷新。而大量这样的运算单元都包含在一个GPU当中。要想跑得快，就得把计算逻辑放在CPU中，同时再把你准备好的数据拷贝到GPU中。然后呢?GPU再用并行的方式，计算准备好的这些数据。这就是异构的模型。 这个模型，是计算体系，也是硬件体系的一次革命，是真正的技术革命。 举个例子。现在要完成一个复杂的大型任务，需分割在100台机器，让它们分开跑，又同时共同执行同一个全局任务，需要一个数学上严格的方法来完成。这意味着，每一次计算更新的时候，都要把大数据刷一遍，刷几千遍是何其难的事情。几十亿个参数的深度学习模型，每一次迭代都要把参数刷一遍。尤其数据量足够大时，这是很难的。 因此，能否调动大量的运算资源，就会成为核心竞争力。我的判断是，未来整个研发结构——重数据，重运算，这两点，必然出现。 4、语音和视觉，将成为下一代交互模式。可能大家没有注意一个数据，谷歌已经有20%的搜索来自语音。这是很可怕的一个趋势。我认为，语音和视觉会是下一代的交互模式。过去我们从PC时代的十指模式(电脑键盘)，走到今天的拇指模式(手机)，未来一定是自然模式(语音和视觉)。因为，太多的交互都会变得很简单。有多简单呢?只会用接触的方式去完成。今天之所以还没有大规模到来，其实是技术不够成熟。亚马逊发布Echo时，为什么谷歌那么在意?我觉得很重要的一点，就是它通过300万台的设备，不停地拿数据——用户的每一次说话，都是一次新的数据。这个数据足够多，又反过来加深它的语音能力。交互模式的变化，不仅改变了产品，也影响了数据方式。 5、深度学习在各个领域产生的变革才刚刚开始。无论是现阶段的内容个性化推荐，还是未来输入方式的改变，还有太多地方，可以被深度学习改变。比如人脸识别。今天你用支付宝，或招商银行客户端，都会让你扫一扫，准确率已经相当高了。高到什么程度呢?有一家公司专门为海关提供人脸识别服务。以前用人工查看，看两个小时后就会出错，加上深度学习算法的系统，极大降低了人脸识别的出错率。 我认为，只要需求越多，它就会越来越准。 比如小米手机出了面孔功能。根据人脸识别进行照片分类。已经可以达到92%的准确率了。包括猎豹。我们在全球有6亿月度活跃用户，一旦建立起深度学习的核心技术能力，猎豹向很多领域的扩展和应用结合就会变成可能。 如果你把深度学习看成一种“工具”，就会发现——它有很多和其它领域，包括传统行业相互结合的机会。 漫漫长路，才刚刚开始。End.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"},{"name":"Business","slug":"Business","permalink":"http://ipcreator.me/tags/Business/"}]},{"title":"李开复：AI 创业的十个真相","date":"2017-02-19T15:59:58.000Z","path":"2017/02/19/BusinessAI/ten-truths-of-ai-star-up-firm/","text":"作者：史中 “重仓”人工智能，是李开复和创新工场未来几年的方向。但是，他面临一个很重要的问题：现在的 AI 创业，核心是 AI 科学家，而“文能起笔安天下，武能上马定乾坤”的 AI 科学家凤毛麟角，用他的话说“该创业的都创业了”。 这时，产业在面临一步棋。那就是：如何把一个普通的 AI 科学家变成“创业英雄”。 作为三十年前就开始研究人工智能的李开复，觉得自己“技术范儿”的创新工场有能力推动这步棋，并且在这一步棋中获得稳固的战略优势。 李开复告诉雷锋网(公众号：雷锋网)，AI 创业现在是科学家的天下，之后是数学家的天下，将来是普通人的天下。 以下是李开复在《创新工场人工智能战略白皮书》发布会上的闭门分享，雷锋网将其整理成为《李开复：AI 创业的十个真相》，呈现给读者。 AI 科学家都是超级宅男创新工场本身主营的机构是投资和投后的机构，我们当然是看项目，看创始人，他们有 idea、方向，我们就会用基金投资它。 过去的互联网创业模式，已经非常经典地被《精益创业》描述： 几个小朋友随便做个产品上去，能融资就融资，不能融资就拉倒。怎么样去惠及用户，迭代产品，之后变现，成为经典的模式。这个创业的模式，它的红利时代已经过去了。当然以后还会有，但是不会像以前那么多。创业的门槛大大提高了，因为人工智能是下一批创业方向，而人工智能创业里面很核心的人物其实是 AI 科学家， AI 的公司没有 AI 科学家是没戏的。 但是AI科学家往往都是超级宅男，自己宅在房间里面，整天做实验，突然你把他丢到一个残酷野蛮可怕的世界里，他自己创业成功率不是很高。 很多 AI 科学家一般这辈子从来没想过创业，现在突然想创业了，然后发现自己长板特别长，短板特别短： 他也许技术很牛，但是也许执行不够；也许他的产品演示起来很好，但是一做起来都是Bug；也可能他产品做得很不错，但是不懂市场；或者懂市场但是不知道怎么去卖。尤其 AI 本身又是一个 ToB 的业务，所以不是那么容易自己攒一个局。所以 AI 科学家需要懂商业的人，懂 ToB 的人，他需要工程师。 AI 创业“不美好”我们平时都会把 AI 创业讲得很美好，今天我就跟大家讲讲 AI 不美好的地方。 第一个就是：AI 科学家有短板。这一点刚才已经说了，我们要想怎么帮“宅男”补足短板。 第二个就是：AI 创业很贵。刚才讲的“精益创业”很便宜，因为几个小朋友不拿薪水，用零元就可以把第一个 App 推出去。我们刚投资一家公司，投了一个月以后钱就用完了。我说你们不就八个人怎么钱就用完了，给了你好几百万。但他们说，光买机器就用了三百万。 第三个就是：AI 需要数据。识别一张图片，最少需要几十万张样本数据，甚至几百上千万。谁给你弄数据？所以做人工智能投资有一个非常头大的地方：一下顶尖的人就投完了。 过去这两年我们就到处去扫，从最厉害的团队出来的无人驾驶公司投了两个，没投两个。然后就再也找不到团队了，因为有资格的人就那么多。 我们做互联网金融，扫完了以后大概投了三个，然后可能有一两个错过了机会，一两个没投，然后就没有了。 因为AI科学家就那么多，能够创业把事情打造到一个地步的就那么多。 AI 的现状是“僧多粥少”。大家都去抢那几棵树，已经把树拱到天价了。我觉得 AI 这片土地需要“施肥”，而不是抢那些非常少的农作物。 所以我们成立了“人工智能工程院”。我们可能花几千万把机器搞定，然后帮助十家二十家创业公司；我们从各种渠道拿到数据，AI 科学家可以做试验；我们试着让更多有潜力的 AI 科学家，能够考虑来创业这条路，帮他们把可能 95% 的失败率降低到 40%，这样的话我们就能够产生自己的价值。 当然，投靠创新工场，我们帮你解决所有问题，也要求自己的回报。本来可能五百万占股 10%，现在也许给我们 15%，我们觉得这样的话也就足够了。以后如果可以打造出独角兽，我们是有很多回报的。 这个工程院在得到金钱回报的话，至少得花掉两亿元人民币。但如果是我们施肥的，想必相比那些“农作物”会喜欢我们。 两三年之后，AI 会像 Android 一样普及长期来说，真的是永远只能由 AI 科学家来创业吗？其实不一定。 任何技术都有一条发展路径，一个很好的例子就是 Android。当年我们跟 CSDN 的蒋涛一起做移动开发者的大会。第一次大会的时候，我问现场观众：有多少人看好Android？大概有5个手。我问有多少人看好 Symbian？五百个手举起来。 但当时我们坚决相信 Android 才是未来的道路。只是因为平台不够。现在大学里面的 Android、 iOS 培训课程非常普及。你如果是一个计算机的学生，你自己自学也好，去做培训课也好，几个月之内你就可以开始做 Android 了。 AI 也是这样的状态。 要多久时间呢？我们大胆的假设两三年吧。这两三年里，我们工程院孵化科学家会是一个非常独特而有价值的方法。三年以后平台出来了，很多聪明的大学生可以自学。平台、工具越来越多，AI 会变得越来越容易用了。 以后年轻人来创业，我觉得可能比现在的科学家创业更能成功。因为 创业需要有动机，有狼性，愿意拼命。本来就要把自己名声，身家全部赌进去的。 有资格的人六个月就能成为 AI 工程师，有资格的人是指：数学天才 一位老教授，用三十年的功力弄出来一个新算法。这种可能性是存在的。但真正能发力的其实还是年轻人。很多年轻人只是苦于没有一个平台。我告诉大家一个秘密。 如果你是一个有资格的年轻人，我们只需要六个月就可以把你培训成为一个 AI 工程师。绝对不是你想象的二十年，三十年。这不像一个材料科学家、火箭专家——这种专家真的是需要三十年的功力。 那么，什么是有资格呢？ 很不幸，不是所有的人。“有资格”简单来说就是：数学天才。 当然，这其中也涵盖了 统计、自动化、计算机。中国人口这么多，光是数学天才我们应该一年都要产生个几十万了。 假设有十万个数学小天才，那里面对AI有兴趣的可能就会有五万。（因为中国学生是特别愿意去追最热门的东西，最热门的定义是什么呢？很酷，能赚很多钱的。）里面有两万个接触到了一些培训平台，花了六个月去做，这两万人里可能又有两千个是适合的领军人物。比如说他是AI领域的雷军、傅盛等等这些人。这两千人最终才是我们最好的投资对象。我们的工作就是让这些人出现。所以短期我们是抓着科学家来，再过三四年我们要把这些年轻人都培训出来。让他们认知这是创业最好的时机。所以这秘密就是：我们要挖掘中国所有的数学小天才，然后引导他们进入AI创业。 AI 接管人类？我们的问题是科幻小说看多了 我们应该怎样看待 AI 呢？ 有人看到阿法狗战胜了李世石，瞬间就联想到了 AI 要接管人类。实际上，这其中还差十万八千里。 AI里最难的问题之一，是跨领域的自然语言理解。要做到这一点，需要上下文的理解，需要跨领域的知识，还需要人类的“Common Sense”。 例如我突然和你说：“中午还好没吃汉堡，麦当劳不好吃。”这句话所有人都明白什么意思，但是机器很难读懂。它可以把每一个字都识别正确，但仍然无法“理解”。 再例如：熨斗打开的不能去摸，沾了水的手不能碰电。这些东西不用讲我们都知道。但是计算机怎么会知道这些事情呢？你怎么去教一个计算机跨领域的知识？你怎么教会它七情六欲？你怎么教会它什么是美？什么是爱？什么是宗教？什么是信仰？这些东西差得还非常远。 揣测可能发生的事情跟确信一定会发生的事情，这两个还是要分辨得很清楚的。任何刚才讲的 AI 不能做的事情，我们都无法揣测多久会被突破。有人说五年，有人说五十年，也有人说永远不会。 我觉得我们真正应该讨论的事情是 怎么用AI来创造价值，怎么让人类能够没有饥饿和寒冷，让每一个人都能有尊严的活着。 例如，未来很多蓝领和白领的工作都会被取代，也包括了记者。当然有些深度文章机器可能五十年也写的出来。但是如果你从网上攒一些资料，例如科大讯飞发布财报，产品多了30%，分析师说股票怎么样，未来人工智能被看好什么的，这种东西机器已经在写了。 当机器能够把简单的工作取代的时候，当经过五秒以内思考的事情人都不用做的时候，当这么多人将可能失业的时候，这些失业者应该怎么做？我们如何去重新训练他们？孩子的教育是什么样的？怎么让人类继续的去寻找应该做的事情？也许造物者是不希望我们做这种无聊的工作，让我们都做有意义的事情，所以才用机器取代了我们。 刚才讲的这些事情都是十年内会发生的。 当然未来也可能是 AI 养活了全世界，我们也许都成为 AI 的宠物，在家里戴着 VR 头盔玩游戏。机器会不会有自我意识，会不会取代人，会不会成为物种，虽然未必不可能，但这些是未知的。 很不幸的是：我们科幻小说看多了。 “AI 新物种”“取代”“奴役”，这些当然可以被想象，但有更多必然的有意思的问题，更值得我们去思考。 AI “低处的果实”还没摘完 人工智能有很多学派。符号学派、连接学派等等。但是除了深度学习以外的方法，经过多年被验证，是不太有发展的。 模拟人的分析方法，希望把它变成一个规律和专家系统，过去五十年已经证明了这个思路是不行的。当然也许某一天会有一个突破，但是直到那一天为止应该是不行的。 就我自己的背景来说。在1988年，我就开始做语音识别。当年第一套系统就是用完全机器学习的方法来做的非特定人的语音识别。 现在看起来这是一个特别小的方法：世界上有一个人能够从纸上读出语音，我的导师就要把这套方法变成一套专家系统。当年就让我很坚定地认为：机器的构造跟人脑，跟人的思维方式其实是不一样的。我们硬要把A放到B其实是很困难的，就像我们不能逼自己去变成一个深度学习者，去分析事情——我们脑子思维就不是那样的，是不自然的。 用脑科学的方法制造人工智能，是一个未知的领域。未知的东西有它的魅力，你要做研究就要做未知，你要有了突破那就是创新。在学术领域你做每一件事情的衡量标准是：我要做别人从来没做过的东西。我们可以假设脑科学跟未来的 AI 是相关的，我们可以去证明这是或不是。但是从投资的角度来讲，押注的风险就太大了。 当年深度学习也是因为数据的不足，碰到了一些瓶颈。但近年我们看到有好几个特别大的变化： 第一个就是特别大量的数据在某些领域开始产生，而且我觉得我们目前还没有被用完。第二个就是 GPU 的使用让我们能够更高效地、非常快速地做深度学习。现在我觉得，所谓的深度学习的果实还远远没有被摘完。人工智能的应用来说百花齐放，一个一个大果实就在你面前。在这种情况下，你还要去种花，何必呢？ 我们把 GPU 和海量数据在全世界扫一遍，应该还够我们 VC 界吃个五年，所以从投资的角度这是非常清晰的事情。 再往下走，我觉得我们 AI 肯定不可以是只有深度学习。例如现在还有增强学习的方法，也在被探索。AlphaGo 里面也不是只存在一个方法。所以我觉得学术界其实应该开始帮助和探索更多的可能性，当我们把这两年的粮食吃完之后也许还有更好的机会。 我没有 AI 宗教信仰 当然未来 AI 也可能没有进一步的突破了。 如果没有的话，那就说明 AI 的黄金时代过去了。下面就是物联网或者其他什么的。作为投资机构，我们并没有一种 AI 宗教信仰，我们还是要把控灵活度。 就像移动互联网时代，当时我们应该是在业界最高调的移动互联网 VC。但是随后我们根据情况做了调整。 如果学术界跟产业界有一个合理的分工，我对未来五年投资界和产生价值非常乐观，对于所谓AI的泡沫我认为不会发生。当然有个别的案例会有泡沫，但是我认为能吃的粮食实在是太多了。 学术跟产业它的分工大概是这样： 一方面是一个很天然有机的分工；另外一方面又是有一点羡慕嫉妒恨在里面。一般来说学术界是看不起工业界的，但是在某一个时刻突然工业界的一个技术成熟了，在这个技术上学术界就做不到工业界的成就了。于是学术界就被逼的去做新的东西。例如：现在再去做人脸识别，学术界就已经打不过工业界了。所以在人工智能领域，很少见到一个老教授一生只研究一个命题。 AlphaGo 本身没有商业价值 AI 会带给我们什么价值呢？ 我想先说说 AlphaGo。之所以 AlphaGo 如此引人注目，很大程度上是因为我们这样的专家把它讲得太悬。 之前我觉得围棋比国际象棋至少难十年或十五年，但后来结果证明我是过于悲观了。我过于悲观其实有很多理由。我当时认为围棋要比国际象棋难了一个天文数字，但天文数字也是数字。 在AlphaGo之前最好的人工智能棋手达到了业余五段。而 AlphaGo 最新的 Master 和职业九段之间的差距，大致相当于职业九段和业余九段的差距。这确实是很大的跳跃。 那为什么会有这样的现象呢？也就是说，为什么下围棋的人工智能进步幅度这么大呢？ 其实有一个非常现实的理由，就是想挣钱的人不会去做围棋。你看 AlphaGo 的专家队伍也没那么了不起，就是二十个很厉害的机器学习专家。在谷歌里面可能有两千个这样的人，在微软里有一千个这样的人。原因在于微软和谷歌过去没有想拿两千个专家的力量打败围棋手，他们的更多时间都在做语音识别、人脸识别这些有价值的事情。 在这个没有价值的事情上 ，能用二十个专家就不错了。 金融、医疗是有商业价值的 AI有商业价值的 AI，影响就巨大了。 AI 在数据量大的领域最易应用。这些数据最好被准确标注，自动化标注。 AI 在无摩擦的领域最容易应用。一个领域里面如果有制造、测试、物流这类摩擦，那就麻烦了。无摩擦的领域是什么？医疗是无摩擦，金融是无摩擦。 AI 在挣钱最多的领域容易应用。毫无疑问，最挣钱的又是金融。所以 金融毫无疑问会是AI最快征服的领域。因为你的算法可以很快就变成钱。 医疗也是一个特别巨大的领域。而且医疗相对传统，能产生增值的机会很大。而且它不是基于大数据的。最好的医生是什么，就是他自己是一个深度学习的机器，根据他的经验做了好多好多次。 假设他判断了五千个病人，判对了很多，判错了一些，下面他的判断就会非常精准了。但一个好医生可能最多也就判断过五千个病人，但我们的数据是五千万的病人的级别。所以 医疗超越医生应该是一个非常必然的，全球性的趋势。 但是AI 医疗需要突破一些隐私问题，可能会有一些挑战。 机器人世界的大门，要靠智能驾驶来敲开 除了大数据应用之外，还有就是科幻型的应用了。包括机器人，无人驾驶这类领域。 目前看得非常清晰，而且全球达到共识就是无人驾驶。有时候你要做一个科幻型的东西，需要万事俱备，天时地利人和才能推动。但是一旦开始动它就不得了。就像以前我们的移动互联网改造了整个产业链，以前的 SP、诺基亚之类。这样的产业变革来临，基本旧的企业全部会死掉，换成一批新的。 出行就会是下一个产业。我们非常幸运，目前有了共享经济，还有电动车。这两个领域已经在推动了，可推动的过程中遇到了一些阻力。 现在无人驾驶一来，就会改变世界的经济格局。我相信，世界经济10%是和出行和运输相关的。虽然真正的无人驾驶到来可能还要十年，但是有些其他的事情可以更快地被做好。 比如景区游览车，比如运输卡车。你可能会问，如果自动驾驶技术暂时还不成熟，卡车下了高速公路怎么办？没问题，我们把仓库全停在高速公路旁边不就是了。 万一卡车看错路怎么办？那我们就重新修路，在路上放很多标志和传感器，这也不是很困难。 所以我们未来三五年我们就可以打很多补丁，让无人驾驶能够在很多有限的环境之下被使用，所以千万不要认为自动驾驶还有十年才来，现在跟我们无关。 我们很少看到有一个产业从头到尾全部都“投降”了。 哪一家汽车公司还敢不说无人驾驶？每一家都在拼命想办法去解决，整个产业力量都进来了。资本的力量在全球都在投资无人驾驶的公司。最新最酷的创业者，很多都在无人驾驶领域创业。这是一个不可逆的必然趋势，会对各个行业做全新的布局。 例如，所有的司机该怎么办？没有车会停下来，停车场该怎么办？以后的汽车该什么样子？道路要提供什么传感器？哪些领域是最快能够赚最多钱的？ 这些我们其实都不必太担心，因为那些最有商业嗅觉的人和最有科技能力的人已经在每天在推敲这个事情。他们，或者说我们一定会找到解决方案。 当一辆无人驾驶汽车可以在路上运行的时候，汽车之间就可以对话了。例如前面发生了车祸，我的车要做出避让。今天我的主人着急上班，你给我让路，我给你两毛钱行不行？ 在这种情况下机器人就变得可行了。与其期待家里的机器人用陪小孩玩的方式进化，还不如期待无人驾驶汽车促进机器人的进化。 更多人工智能相关内容，请关注雷锋网。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Business","slug":"Business","permalink":"http://ipcreator.me/tags/Business/"}]},{"title":"谷歌发布全新轻型机器学习架构：可直接载于设备端的AI系统","date":"2017-02-19T15:59:56.000Z","path":"2017/02/19/BusinessAI/ai-on-terminal-of-google/","text":"作者：雷锋网 亚萌 雷锋网(公众号：雷锋网)消息，谷歌近日发布了全新应用于可穿戴设备的Android Wear 2.0系统和相关设备，而这一批系统和设备，将具有一项新技能：运行谷歌全新的“设备端”机器学习技术。下面是对该项技术的介绍，原文载于Googleblog，由雷锋网编译整理。 设备端的机器智能为了打造会话理解和图像识别领域领先的技术，我们通常将多种先进的机器学习技术（比如深度神经网络和基于图的机器学习）结合起来使用。然而，以上提到的机器学习系统往往需要大量的计算能力和存储空间。可是，如果想 要在不论是否连接到的云端的情况下，个人手机、智能手表和IoT设备都能运行机器智能，又要怎么办呢？ 昨天，我们发布了Android Wear 2.0系统和全新的可穿戴设备，这些设备将会运行 谷歌首个完全“设备端”（on-device）的机器学习技术，首先用于“智能回复”（Smart Reply）这一功能上。这个“设备端”机器学习系统由谷歌Expander研发团队开发，在不需要接入云端的情况下，将“智能回复”功能应用于各第三方的讯息App上。所以现在，你若在手表上收到了一条信息，轻敲回复选项就可以了。 这个系统的研发从去年开始，当时我们的团队正在为Allo和Inbox里的会话理解开发相应的机器学习系统。 Android Wear团队找到我们，并询问将“智能回复”直接应用在智能设备上的可能性。因为智能设备的计算和存储量都是有限的，我们很快就判断这种移植根本不可能。 但我们的产品经理Patrick McGregor意识到这对于Expander团队来说是个独特的挑战和机会，可以从头开始 设计一个全新的、轻型机器学习架构，这不仅让“智能回复”应用于Android Wear系统，还应用于其它众多设备端的移动应用程序。于是，我们与Android Wear团队的Tom Rudick、Nathan Beach等同事一起，开始着手建立这个全新的系统。 与“投影”一起进行学习建立轻型会话理解模型的一个简单策略，就是在设备上 创建一个小型的包含一般规则的字典（输入—&gt;回复映射），并且在推理阶段，使用一个朴素的查找策略。 这个可以执行简单的预测任务，包括使用一些特征进行分类 （比如对文本里的情感进行二元分类，例如“我爱这部电影”传递出一种积极的情感，而“演员的表演很糟糕”则传达一种消极情感）。但是，它的规模并没有大到去执行包含丰富词汇和语言变化的复杂自然语言任务。 另一方面，机器学习模型，比如RNN（如LSTM），结合图学习（graph learning），已经被证明是用于自然语言理解的复杂序列学习里极强悍的工具，包括“智能回复”。 然而，为了适应设备存储空间而将这么丰富的模型进行压缩，并在低计算成本的情况下产生鲁棒的预测（快速按需），这是非常具有挑战性的。在我们的早期实验里，受到限制的模型仅仅预测一小批回复语句，我们还使用其他包括量化（quantization）、字母级别模型等技术，并不能产生有用的结果。 所以，我们为设备端机器学习系统建立了一种不同的解决方法，我们一开始使用了一个快速、有效的机制，将相似的传入讯息聚集起来，并将他们投影到相似的（附近的）位向量表征里。虽然执行这个投影步骤有几种方法，比如使用单词嵌入（word embeddings）或者编码网络（encoder networks），我们应用了局部敏感哈希算法（locality sensitive hashing ，LSH) 的修改版本来降低维度，把数百万个独特的单词转换为短小的、固定长度的位序列。 这允许我们为一条传入讯息的投影进行非常 快速、即时（on-the-fly） 的计算，占用很少的内存，由于我们并不需要存储传入讯息、单词嵌入甚至是用来训练的整个模型。 投影步骤：相似讯息组合在一起，投射到邻近向量里。比如，“hey, how’s it going?”与 “How’s it going buddy?” 这两条讯息内容是相似的，或许会投射到同样的向量 11100011。另一条相似的讯息“Howdy, everything going well?”被映射到一个附近的向量11100110，与前两条相差2位。 接下来，使用我们的 半监督图学习框架 ，我们的系统把传入讯息和投影结合在一起，共同训练一个“讯息投入模型”，学习预测可能的回复语句。图学习框架能够训练一个鲁棒的模型，通过从各种资源里找出的语义关系——讯息/回复互动、单词/短语相似性、语义集群信息——学习有用的投影操作，来映射良好的回复语句预测。 学习步骤：（顶部）的讯息、投射和相应回复语句一起，在一个机器学习框架里，同步学习一个“讯息投射模型”。（底部）讯息投射模型学习，将回复语句与相应传入讯息的投射联系在一起。比如，模型投射两种不同的讯息“Howdy, everything going well?”和“How’s it going buddy?”投射到附近的位向量里，并且学习着将其映射成相关的回复语句（底部左图）。 值得注意的是，就像我们前面提到的，尽管“讯息投影模型”用复杂的机器学习架构和云计算进行训练，但是模型本身在设备上存在和运行。 设备上的App可以传递用户的传入讯息，并从设备端模型上接受回复语句预测选项，而不需要离开设备去获得数据。这个模型也可以适应用户书写风格和个人偏好，从而提供一种个性化的体验。 推理步骤：模型将学习好的映射应用于一条传入讯息（或讯息序列）里，并且推荐相关的多条回复语句。推理过程在设备上运行，使得模型适应用户数据和个性化书写风格。 为了得到开箱即用的设备端系统，我们必须要进行一些额外的改进，比如优化设备上的计算速度、从模型中生成丰富多样的回复语句等等。不久之后，我们将进行一些科学发表，介绍更多设备端机器学习系统工作的细节。 与你的手腕交谈 当我们踏上从无到有打造这项技术的旅程时，一开始我们并不确定，这些模型的预测结果质量是否合格。我们非常惊讶地发现，它能在非常有限的计算能力和存储资源的情况下，在安卓的可穿戴设备上工作良好，对此我们非常兴奋。我们期待继续改善模型，为用户提供共更加愉悦的会话体验，我们将会提升这个设备端的机器学习平台，接下来的几个月里将其应用于新的领域。 现在，你可以在你的Google手表或任何运行Android Wear 2.0系统的手表上使用这一功能。这一功能已经可以在Google Hangouts、Google Messenger和众多第三方App上使用。我们也 会为第三方穿戴设备App的开发者提供API接口。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"}]},{"title":"智能手机 + 机器学习 = 个人终端的未来","date":"2017-02-19T15:58:06.000Z","path":"2017/02/19/BusinessAI/the-future-of-personal-terminal/","text":"作者：陈杨英杰 今天是 iPhone 7 发布的日子，无论你是不是果粉，无论是主动关注还是被动接受，所有人的信息焦点只有一个，那就是苹果。作为技术创新的长期领导者，苹果已经一次又一次给我们带来各种意想不到的新体验，今天的 iPhone 7 更是如此。那么，就让我们从小小的智能手机开始聊一聊机器学习将如何改变个人终端的未来。 尽管新的产品、新的功能层出不穷，但人们不禁好奇，究竟是什么因素在将不可能变为可能。 答案大概可以归结为四个字：“机器学习”。 iPhone 7 发布会 无论我们是否真的意识到，机器学习已经在我们的日常生活中应用很长时间了。事实上，我们没有注意到它的存在反而意味着这个技术非常有效，因为每天当着用户面处理学习如此大量的实时数据却不被察觉，显然这种方式是可以令人接受的。然而，最近这个词频频出现在各种商业和大众媒体上，在人工智能的专业技术人员和消费者中间引发了大量深入的讨论。 苹果公司早就在人工智能领域奠定了坚实的基础。在史蒂文·李维（Steven Levi）发表在 iBrain 上的文章中，其深入剖析了苹果错综复杂的机器学习技术。尽管很大程度上 Siri 只是苹果在机器学习方面的“门面”，但毋庸置疑的是，苹果在这方面的研发并不止于此，机器学习技术已经被应用到苹果的各类设备和应用中。例如，滑动屏幕会出现你想要打开的应用名单，或是指出你预订的酒店在地图的位置。 这个直接面向消费者的人工智能应用，在科技行业树立了一个标杆，不仅成功提升了品牌价值，也让消费者对数字体验有了更高的期待。 Siri 尽管 Siri 是一个非常受欢迎的人工智能应用，但她也不是没有竞争对手。虚拟助手 Cortana（微软小娜）的出现加剧了科技公司之间的竞争，现在鹿死谁手还未可知。这给苹果带来了巨大的压力，苹果很快意识到了问题，并开始不断采取措施加强他们的机器学习部门，目的就是为了在这一领域保持一个领先地位，尤其是要赶在新产品发布之前。最近的例子就是苹果收购了专注于机器学习的人工智能公司 Turi 。此外，苹果公司还宣布，除了已经搭载了 Siri 功能的苹果手机，他们还准备将 Siri 背后的深度学习技术集成到苹果的笔记本电脑、手表和电视上。 iWatch 更深远的影响在于，这些努力是为了把机器学习运用到苹果的整个产品链中，此举标志着苹果的品牌和零售将开始一种全方位的个性化体验服务。用户已经开始期待基于深度学习其实时行为反应的高级定制化内容。苹果公司已经意识了只有机器学习才能满足如此大规模的用户需求。苹果通过增强型机器学习算法提高内容准确性和时效性，为用户提供了一对一的个性化体验服务，这些最终将转化为公司的品牌忠诚度，并为公司增加营收。 消费者对个性化体验服务的期望只会不断增加，而苹果公司已经明确表示他们正在想方设法满足这些需求。这也意味着面对竞争，需要不断努力加强自身的深度学习技术，才能跟上发展。这不仅适用于苹果的竞争对手，也对其合作伙伴提出了更高要求。 通过把机器学习集成到苹果的产品中，品牌和零售商就能轻松地为消费者提供他们一直期待的购物体验。 那些不敢冒险的人终将会被时代所淘汰。 GPU 芯片 具体来说，对于计算机中的神经网络和机器学习中的其他方法的研究自 70 年代就开始了。深度学习是机器学习的一部分，通过算法对数据进行关联和分类。深度学习系统通常需要使用复杂的神经网络和大量的计算资源。GPU芯片是一种专门用于图像计算的芯片，在带有屏幕的个人终端设备上十分常见，神经网络大都在GPU上运行。 麻省理工学院的研究团队研发出了一款名为 Eyeriss 的芯片，将能耗减少到了 GPU 平均水平的 1/10。因此，这为智能手机上的应用打开了新的可能性，可以直接在移动设备上执行强大的人工智能算法，而不需要将数据上传到互联网进行云计算。 这款专为深度学习而优化的计算机芯片，能够让人工智能变得更为流行。 MIT 研发的这款168核的芯片能够识别人脸、其他物体，甚至是声音。该芯片可适用于智能手机、自动驾驶汽车、机器人、无人机和其他设备。普通 GPU 芯片一般是很多处理单元共享一个内存条，而Eyeriss芯片每个处理单元都有自己的内存，而且它可以在向处理单元发送数据前对数据进行压缩。Eyeriss的每个处理单元都可以直接与相邻的处理单元进行交流，如果需要共享数据，不需要将数据传送到主内存。 配备这种新芯片后，未来的智能手机不仅能够更好地执行日常任务，还可以进行原本需要外部资源投入的人工智能和深度学习任务。而 一个内置 Eyeriss 芯片的智能手机可以执行更多的基本任务，诸如追踪用户的偏好、时间表和使用模式，能更好地优化移动体验，这意味着一种截然不同的绝佳用户体验。 AI助理（配图：《钢铁侠》） 我们对普通用户每天的 应用场景进行归类 后，搭载了 AI 助理的智能手机可以 清楚的判断用户的各种使用情况，是在应用商店下载了游戏，还是对已安装的应用进行更新，都一目了然。芯片会查看一些手机信息，比如应用程序的大小，代码特点，用户使用量的统计数据，线上意见等，并向用户 推荐一些可能感兴趣的内容。例如，某个用户在市中心闲逛时突然想找去酒吧玩儿，他们也许对机载 AI 助理说：“推荐一个我没去过的好酒吧。”此时，AI 就会开始查询银行对账单，判断用户多长时间去一次酒吧，每次平均花费多少钱，然后找到评论这些酒吧的关键词，诸如“氛围好”或这“啤酒好”等，最后找到一个附近的新酒吧推荐给用户。目前，所有这些计算都是由异地的服务器统一处理后传回用户的手机，很难将其他数据和应用整合到设备上，并有效管理用户数据。 机载 AI 助理将彻底改变个人终端计算设备的发展，首当其冲的就是智能手机。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Smart Phone","slug":"Smart-Phone","permalink":"http://ipcreator.me/tags/Smart-Phone/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"深度学习框架太抽象？其实不外乎这五大核心组件","date":"2017-02-19T15:57:20.000Z","path":"2017/02/19/Program/TensorFlow/core-components-from-deep-learning-framework/","text":"本文作者：恒亮 许多初学者觉得深度学习框架抽象，虽然调用了几个函数/方法，计算了几个数学难题，但始终不能理解这些框架的全貌。为了更好地认识深度学习框架，也为了给一些想要自己亲手搭建深度学习框架的朋友提供一些基础性的指导，日前来自苏黎世联邦理工学院计算机科学系的硕士研究生Gokula Krishnan Santhanam在博客上撰文，概括了大部分深度学习框架都会包含的五大核心组件，为我们详细剖析了深度学习框架一般性的内部组织结构。以下由雷锋网(公众号：雷锋网)编译。 Gokula Krishnan Santhanam认为，大部分深度学习框架都包含以下五个核心组件：&gt; 张量（Tensor） 基于张量的各种操作 计算图（Computation Graph） 自动微分（Automatic Differentiation）工具 BLAS、cuBLAS、cuDNN等拓展包 1. 张量（Tensor） 张量是所有深度学习框架中最核心的组件，因为后续的所有运算和优化算法都是基于张量进行的。几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将 标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。 举例来说，我们可以将任意一张RGB彩色图片表示成一个三阶张量（三个维度分别是图片的高度、宽度和色彩数据）。如下图所示是一张普通的水果图片，按照RGB三原色表示，其可以拆分为三张红色、绿色和蓝色的灰度图片，如果将这种表示方法用张量的形式写出来，就是图中最下方的那张表格。 图中只显示了前5行、320列的数据，每个方格代表一个像素点，其中的数据[1.0, 1.0, 1.0]即为颜色。假设用[1.0, 0, 0]表示红色，[0, 1.0, 0]表示绿色，[0, 0, 1.0]表示蓝色，那么如图所示，前面5行的数据则全是白色。 将这一定义进行扩展，我们也可以用四阶张量表示一个包含多张图片的数据集，其中的四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。 将各种各样的数据抽象成张量表示，然后再输入神经网络模型进行后续处理是一种非常必要且高效的策略。因为如果没有这一步骤，我们就需要根据各种不同类型的数据组织形式定义各种不同类型的数据操作，这会浪费大量的开发者精力。更关键的是，当数据处理完成后，我们还可以方便地将张量再转换回想要的格式。例如Python NumPy包中numpy.imread和numpy.imsave两个方法，分别用来将图片转换成张量对象（即代码中的Tensor对象），和将张量再转换成图片保存起来。 2. 基于张量的各种操作 有了张量对象之后，下面一步就是一系列针对这一对象的数学运算和处理过程。 其实，整个神经网络都可以简单视为为了达到某种目的，针对输入张量进行的一系列操作过程。而所谓的“学习”就是不断纠正神经网络的实际输出结果和预期结果之间误差的过程。这里的一系列操作包含的范围很宽，可以是简单的矩阵乘法，也可以是卷积、池化和LSTM等稍复杂的运算。而且各框架支持的张量操作通常也不尽相同，详细情况可以查看其官方文档（如下为NumPy、Theano和TensorFlow的说明文档）。 NumPy：http://www.scipy-lectures.org/intro/numpy/operations.html Theano：http://deeplearning.net/software/theano/library/tensor/basic.html TensorFlow：https://www.tensorflow.org/api_docs/python/math_ops/ 需要指出的是，大部分的张量操作都是基于类实现的（而且是抽象类），而并不是函数（这一点可能要归功于 大部分的深度学习框架都是用面向对象的编程语言实现的）。这种实现思路一方面允许开发者将各种类似的操作汇总在一起，方便组织管理。另一方面也保证了整个代码的复用性、扩展性和对外接口的统一。总体上让整个框架更灵活和易于扩展，为将来的发展预留了空间。 3. 计算图（Computation Graph） 有了张量和基于张量的各种操作之后，下一步就是将各种操作整合起来，输出我们需要的结果。 但不幸的是，随着操作种类和数量的增多，有可能引发各种意想不到的问题，包括多个操作之间应该并行还是顺次执行，如何协同各种不同的底层设备，以及如何避免各种类型的冗余操作等等。这些问题有可能拉低整个深度学习网络的运行效率或者引入不必要的Bug，而计算图正是为解决这一问题产生的。 据雷锋网了解，计算图首次被引入人工智能领域是在2009年的论文《Learning Deep Architectures for AI》。当时的图片如下所示，作者用不同的占位符（*，+，sin）构成操作结点，以字母x、a、b构成变量结点，再以有向线段将这些结点连接起来，组成一个表征运算逻辑关系的清晰明了的“图”型数据结构，这就是最初的计算图。 后来随着技术的不断演进，加上脚本语言和低级语言各自不同的特点（概括地说，脚本语言建模方便但执行缓慢，低级语言则正好相反），因此业界逐渐形成了这样的一种开发框架： 前端用Python等脚本语言建模，后端用C++等低级语言执行（这里低级是就应用层而言），以此综合了两者的优点。 可以看到，这种开发框架大大降低了传统框架做跨设备计算时的代码耦合度，也避免了每次后端变动都需要修改前端的维护开销。而这里，在前端和后端之间起到关键耦合作用的就是计算图。 将计算图作为前后端之间的中间表示（Intermediate Representations）可以带来良好的交互性，开发者可以将Tensor对象作为数据结构，函数/方法作为操作类型，将特定的操作类型应用于特定的数据结构，从而定义出类似MATLAB的强大建模语言。 需要注意的是，通常情况下开发者不会将用于中间表示得到的计算图直接用于模型构造，因为这样的计算图通常包含了大量的冗余求解目标，也没有提取共享变量，因而通常都会经过依赖性剪枝、符号融合、内存共享等方法对计算图进行优化。 目前，各个框架对于计算图的实现机制和侧重点各不相同。例如Theano和MXNet都是以隐式处理的方式在编译中由表达式向计算图过渡。而Caffe则比较直接，可以创建一个Graph对象，然后以类似Graph.Operator(xxx)的方式显示调用。 因为计算图的引入，开发者得以从宏观上俯瞰整个神经网络的内部结构，就好像编译器可以从整个代码的角度决定如何分配寄存器那样，计算图也可以从宏观上决定代码运行时的GPU内存分配，以及分布式环境中不同底层设备间的相互协作方式。 除此之外，现在也有许多深度学习框架将计算图应用于模型调试，可以实时输出当前某一操作类型的文本描述。 4. 自动微分（Automatic Differentiation）工具 计算图带来的另一个好处是让模型训练阶段的梯度计算变得模块化且更为便捷，也就是自动微分法。 正如前面提到的，因为我们可以将神经网络视为由许多非线性过程组成的一个复杂的函数体，而计算图则以模块化的方式完整表征了这一函数体的内部逻辑关系，因此微分这一复杂函数体，即求取模型梯度的方法就变成了在计算图中简单地从输入到输出进行一次完整遍历的过程。与自动微分对应，业内更传统的做法是符号微分。 符号微分即常见的求导分析。针对一些非线性过程（如修正线性单元ReLU）或者大规模的问题，使用符号微分法的成本往往非常高昂，有时甚至不可行（即不可微）。因此，以上述迭代式的自动微分法求解模型梯度已经被广泛采用。并且由于自动微分可以成功应对一些符号微分不适用的场景，目前许多计算图程序包（例如Computation Graph Toolkit）都已经预先实现了自动微分。 另外，由于每个节点处的导数只能相对于其相邻节点计算，因此实现了自动微分的模块一般都可以直接加入任意的操作类中，当然也可以被上层的微分大模块直接调用。 5. BLAS、cuBLAS、cuDNN等拓展包 现在，通过上述所有模块，我们已经可以搭建一个全功能的深度学习框架：将待处理数据转换为张量，针对张量施加各种需要的操作，通过自动微分对模型展开训练，然后得到输出结果开始测试。这时还缺什么呢？答案是运算效率。 由于此前的大部分实现都是基于高级语言的（如Java、Python、Lua等），而即使是执行最简单的操作，高级语言也会比低级语言消耗更多的CPU周期，更何况是结构复杂的深度神经网络，因此运算缓慢就成了高级语言的一个天然的缺陷。 目前针对这一问题有两种解决方案。 第一种方法是模拟传统的编译器。就好像传统编译器会把高级语言编译成特定平台的汇编语言实现高效运行一样，这种方法将高级语言转换为C语言，然后在C语言基础上编译、执行。为了实现这种转换，每一种张量操作的实现代码都会预先加入C语言的转换部分，然后由编译器在编译阶段将这些由C语言实现的张量操作综合在一起。目前pyCUDA和Cython等编译器都已经实现了这一功能。 第二种方法就是前文提到的，利用脚本语言实现前端建模，用低级语言如C++实现后端运行，这意味着高级语言和低级语言之间的交互都发生在框架内部，因此每次的后端变动都不需要修改前端，也不需要完整编译（只需要通过修改编译参数进行部分编译），因此整体速度也就更快。 除此之外，由于低级语言的最优化编程难度很高，而且大部分的基础操作其实也都有公开的最优解决方案，因此另一个显著的加速手段就是利用现成的扩展包。例如最初用Fortran实现的BLAS（基础线性代数子程序），就是一个非常优秀的基本矩阵（张量）运算库，此外还有英特尔的MKL（Math Kernel Library）等，开发者可以根据个人喜好灵活选择。 值得一提的是，一般的BLAS库只是针对普通的CPU场景进行了优化，但目前大部分的深度学习模型都已经开始采用并行GPU的运算模式，因此 利用诸如NVIDIA推出的针对GPU优化的cuBLAS和cuDNN等更据针对性的库可能是更好的选择。 运算速度对于深度学习框架来说至关重要，例如同样训练一个神经网络，不加速需要4天的时间，加速的话可能只要4小时。在快速发展的人工智能领域，特别是对那些成立不久的人工智能初创公司而言，这种差别可能就会决定谁是先驱者，而谁是追随者。 总结 原文作者在文末指出：为了向开发者提供尽量简单的接口，大部分深度学习框架通常都会将普通的概念抽象化，这可能是造成许多用户感知不到上述五点核心组件的重要原因。 而这也正是作者写本文的初衷：他希望开发者能够通过了解不同框架之间的一些相似特性，更好地认识和使用一个深度学习框架。另一方面，对于那些不仅对学会使用深度学习框架感兴趣，还打算亲手搭建一个深度框架的朋友，作者认为了解各框架的内部组成和一些共性的特征也是迈向成功的重要一步。他真诚地相信，一个优秀的工程师不仅应该“知其然”，更应该“知其所以然”。 来源：medium，雷锋网编译 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"机器学习年度 20 大开源项目花落谁家？（Python 版）","date":"2017-02-19T15:57:06.000Z","path":"2017/02/19/Program/TensorFlow/20-open-source-projects-of-machine-learning/","text":"作者：雷锋网 小东 如今，开源已经成为创新与技术发展的核心。在本文中，雷锋网(公众号：雷锋网)将介绍 2016 Python 前20大机器学习开源项目。 去年 KDnuggets 评选了前 20 大机器学习开源项目（Python版），今年的评选结果与去年相比，名单中出现了一些新的面孔，有13个新开源项目入围了这个名单。作者 Prasad Pore 将具体介绍这些开源项目，雷锋网编译，未经许可不得转载。 第一名：Scikit-learn Scikit-learn可以说是一款简单而高效的数据挖掘与分析工具，大家可以免费下载安装，使用它处理各种数据，使用时需引入 NumPy, SciPy, and matplotlib这些第三方开源模块。 提交: 21486 贡献: 736 Github URL: Scikit-learn 第二名：Tensorflow Tensorflow是由谷歌大脑与谷歌人工智能实验室的科研人员研发而成的，这个系统用于机器学习的研究，可以简单、快速的实现研究人员的想法。前段时间恰逢Tensorflow一周年，雷锋网也做过报道和回顾。 提交: 10466 贡献: 493 Github URL: Tensorflow 第三名：Theano Theano可以对那些高维数组数学表达式进行定义、优化与评估。 提交: 24108 贡献: 263 Github URL: Theano 第四名：Caffe Caffe是一款具有表达、加速、模块化思想的深度学习框架，由 Berkeley Vision and Learning Center (BVLC)于社区志愿者共同开发维护。 提交: 3801 贡献: 215 Github URL: Caffe 第五名：Gensim Gensim是一个免费的Python库，这个库可以实现文本的情感倾向判断，相似文本检索等功能。 提交: 2702 贡献: 145 Github URL: Gensim 第六名：Pylearn2 Pylearn2 也是一个机器学习的开源库，但它是一个基于Theano的库，所以它有一些Theano的特点，你可以使用数学表达式来写Pylearn2插件，Theano会自动对你写的表达式进行优化，按照你的选择（用CPU或GPU）对这些表达式进行编译。 提交: 7100 贡献: 115 Github URL: Pylearn2 第七名：Statsmodels Statsmodels是一款Python开源工具，可以实现数据探究、统计模型评价、性能测试等功能，扩展性能良好，可对各种类型的数据进行各种处理，例如描述统计、统计测试、绘图、结果统计等等。 提交: 8664 贡献: 108 Github URL: Statsmodels 第八名：Shogun Shogun是一款机器学习工具，其包含了各种机器学习方法。它可以简单的实现多种数据表示、多种算法的无缝融合。 提交: 15172 贡献: 105 Github URL: Shogun 第九名：Chainer Chainer是一个基于Python的开源深度学习框架，它可以让你以一种灵活、简单、快速的方式实现多种深度学习模型，包括RNN与各种自编码。 提交: 6298 贡献: 84 Github URL: Chainer 第十名：NuPIC NuPIC是一个基于Hierarchical Temporal Memory理论的开源项目，目前Hierarchical Temporal Memory这个理论中的部分功能已经实现，并进行了测试与应用，其它部分正在完善中。 提交: 6088 贡献: 76 Github URL: NuPIC 第十一名：Neon Neon是一款深度学习第三方库，在进行高性能计算时它具有简单易用的特点。 提交: 875 贡献: 47 Github URL: Neon 第十二名：NiLearn NiLearn主要用于处理医学图像数据，具有简单、快速的特点。它通过调用scikit-learn进行多元统计分析（例如：预测模型、分类、解码、关联分析）。 提交: 5254 贡献: 46 Github URL: NiLearn 第十三名：Orange3 Orange3是一款机器学习与数据可视化开源工具，可以对数据进行各种交互分析。 提交: 6356 贡献: 40 Github URL: Orange3 第十四名：Pymc Pymc是一个贝叶斯统计模型（包括马尔科夫链）库，具有灵活、扩展性能好的特点。 提交: 2701 贡献: 37 Github URL: Pymc 第十五名：PyBrain： PyBrain是一个机器学习库，它的目标是让算法的实现变的简单、灵活、高效。同时使得在特定环境下对算法的测试与比较也变的简单、灵活、高效。 提交: 984 贡献: 31 Github URL: PyBrain 第十六名：Fuel Fuel主要用于算法与输入数据之间的衔接。它将被Blocks and Pylearn2这两个Python库使用。 提交: 1053 贡献: 29 Github URL: Fuel 第十七名： PyMVPA PyMVPA 适用于大规模的数据集，具有扩展性能好优点，提供多种算法（分类、回归、特征选择、数据导入、数据导出等）接口。 提交: 9258 贡献: 26 Github URL: PyMVPA 第十八名：Annoy Annoy是一个Python可调用的C++库，主要用来对给定数据进行搜索。它可以生成大量的基于文档的可读数据结构，这种数据结构与内存相对应，从而使数据被共享。 提交: 365 贡献: 24 Github URL: Annoy 第十九名：Deap Deap是一款新的计算框架，它使得算法实现与数据结构变得简单明了。它采用的是并行处理机制。 提交: 1854 贡献: 21 Github URL: Deap 第二十名：Pattern Pattern是一款web信息挖掘工具，它集成了各种工具。这些工具可以用来进行数据挖掘、自然语言处理、机器学习、网络分析。 提交: 943 贡献: 20 Github URL: Pattern 如下图所示，PyMVPA的社区贡献率最高，而排名第一的Scikit-learn社区贡献率却很低，究其原因是PyMVPA是还是一个比较新的开源项目，还有一些地方需要完善、修复。而Scikit-learn则是一个相对来说比较成熟的项目，需要修改、完善的地方比较少。 当我们对2015与2016的结果进行对比（下图），我们发现Pattern, PyBrain and Pylearn2这三个项目的贡献人数与提交数均没有变化。贡献的人增加了，提交的次数也才跟着增加，这就是开源社区的神奇所在。这些新增的贡献者与其提交内容导致了新的思想、新的软件的产生。 基于2016年20大机器学习开源项目的贡献人数与提交数，以上是雷锋网整理的简单分析。不知道到明年的评选上，又有怎样的开源平台会登上这个榜单呢？ via Top 20 Python Machine Learning Open Source Project 五个鲜为人知，但又不可不知的机器学习开源项目 本文作者：恒亮 2017-02-09 14:14 导语：本文将介绍的这五个小众项目来自不同的生态系统和编程语言，并且版本更新活跃，具有一定的学习价值。 五个鲜为人知，但又不可不知的机器学习开源项目 借着人工智能的热潮，各种机器学习项目也迎来了一个爆发期。其中有一些因为背后的巨头支持或者稳定可靠的性能而广为人知，例如Tensorflow、Caffe和Theano等。但实际上，有为数更多的项目却并不为人所知。在这些相对小众的项目中，是否隐藏着一些版本迭代积极，且具有一定参考价值的项目？答案显然是肯定的。 本文将介绍的这五个小众项目来自不同的生态系统和编程语言，并且版本更新活跃，具有一定的参考价值。或许你会觉得了解这些小众的项目并没有太多实际意义，但本文的原作者Matthew Mayo，一位资深的数据科学家和无监督学习领域的大牛认为，仔细学习这些项目的实现细节和编码方式，将帮助开发者对他们自己的项目产生一些具有积极意义的想法，因此仍然是大有裨益的。 原文来自KDnuggets，以下项目排名不分先后，雷锋网(公众号：雷锋网)编译。 Hyperopt-sklearn Hyperopt-sklearn是基于scikit-learn项目的一个子集，其全称是：Hyper-parameter optimization for scikit-learn，即针对scikit-learn项目的超级参数优化工具。由于scikit-learn是基于Python的机器学习开源框架，因此Hyperopt-sklearn也基于Python语言。 Hyperopt-sklearn的文档称：对于开发者而言，针对不同的训练数据挑选一个合适的分类器（classifier）通常是困难的。而且即使选好了分类器，后面的参数调试过程也相当乏味和耗时。更严重的是，还有许多情况是开发者好不容易调试好了选定的分类器，却发现一开始的选择本身就是错误的，这本身就浪费了大量的精力和时间。针对该问题，Hyperopt-sklearn提供了一种解决方案。 Hyperopt-sklearn支持各种不同的搜索算法（包括随机搜索、Tree of Parzen Estimators、Annealing等），可以搜索所有支持的分类器（KNeightborsClassifier、KNeightborsClassifier、SGDClassifier等）或者在给定的分类器下搜索所有可能的参数配置，并评估最优选择。并且Hyperopt-sklearn还支持多种预处理流程，包括TfidfVectorizer，Normalzier和OneHotEncoder等。 那么Hyperopt-sklearn的实际效果究竟如何？下表分别展示了使用scikit-learn默认参数和Hyperopt-sklearn优化参数运行的分类器的F-score分数，数据源来自20个不同的新闻组稿件。可以看到，经过优化的分类器的平均得分都要高于默认参数的情况。 另外，Hyperopt-sklearn的编码量也很小，并且维护团队还提供了丰富的参考样例。 主页：http://hyperopt.github.io/hyperopt-sklearn/ Dlib Dlib的目标用户并没有Hyperopt-sklearn细分，它是一个基于C++语言的通用的机器学习和数据分析库。值得一提的是，虽然Dlib的确是由C++实现的，但它却提供了针对Python语言的API。 Dlib的官网称：Dlib是一个现代的C++工具包，实现了大量机器学习的相关算法和工具，可用于在C++环境下创建复杂的软件来解决现实问题。目前，Dlib在工业界和学术界都得到了广泛的应用，包括机器人，嵌入式设备，移动电话和大规模的高性能计算环境等。 Dlib的帮助文档非常规范，针对每个API接口的解释也相当全面，而且Dlib还提供了非常详细的入门参考。更为难能可贵的是，Dlib的博客更新也非常频繁，官方人员经常通过博客分享基于Dlib实现的有趣的应用项目。实际上，Dlib也并非随着近两年的人工智能热潮才发起的项目，相对而言，它的历史非常悠久，早在2002年，Dlib的维护团队就已经开始着手开发了。 鉴于Dlib包含了为数众多的算法实现，因此原文作者认为Dlib的运行效率应该与scikit-learn接近，甚至有可能超越后者。 主页：http://dlib.net/ N++ N++同样基于C++环境，相对其他项目而言，它是一个非常小巧易用的神经网络实现库。这一点主要体现在，N++并不需要复杂的安装过程，使用时只需要在C++代码中通过#include语句对所需的库文件做一个声明就可以了。 其官网称：N++是一个简短、自包含（self-contained）、易于使用的基于C++环境的神经网络工具包。它实现了包括神经网络和基本线性代数运算在内的一些矩阵类。该项目的主要目的是为了相互学习和交流，但基于MNIST数据库的一些初步测试结果却表明N++在某些实际应用项目中的表现同样出色。 N++的配套文档并不多，但它却对矩阵类的相关用法进行了详细解释。另外，N++官方还公布了一些对神经网络进行设置和查询的代码片段，而且由于这些代码相对其他实现都非常简短，因此N++特别适合于那些想要了解简单的神经网络实现或者刚从其他编程语言转到C++环境的开发者。 主页：https://github.com/stagadish/NNplusplus LightGBM LightGBM是基于微软DMTK（Microsoft Distributed Machine Learning Toolkit）开源项目的一个子集，它的全称是：Light Gradient Boosting Machine，专注于各种梯度提升（Gradient Boosting）算法的实现，包括GBDT，GBRT，GBM和MART等。 官网描述称：基于公开数据集的测试结果表明，LightGBM无论在模型训练的速度、准确性还是内存消耗等各方面都要优于其他的梯度提升算法实现。此外，LightGBM还可以通过在特定设置中使用多台机器进行并行训练的方式来实现线性加速（linear speed-up）。 LightGBM本身由C++和Python两种语言实现，微软为开发者提供了完整的帮助文档和入门参考。背靠科技巨头微软的鼎力支持，LightGBM自然也是一个非常值得关注的项目。 主页：https://github.com/Microsoft/LightGBM Sklearn-pandas 与前面的几个项目不同，Sklearn-pandas既可以视为一个通用型的机器学习工具包，也可是视为一些特定算法的实现。它在具体的机器学习任务中主要充当支持者的角色。 这里所谓支持者的角色，按照其官网的解释即是说：Sklearn-pandas在Scikit-Learn和pandas之间提供了一个互通的桥梁（这一点从项目的名称也能看出）。Scikit-Learn上文已经提过，这里pandas是指一个开源的基于Python实现的数据分析工具。 具体的说，Sklearn-pandas的桥梁作用主要体现在以下两个方面： 1) 提供将DataFrame列映射到transformations的方法，这些列此后还可以重新组合成特征（features）； 2) 以pandas DataFrame为输入，为scikit-learn旧版本的管道交叉验证（cross-validate a pipeline）提供兼容性支持。 Sklearn-pandas的版本更新活跃，也是一个非常值得关注的开源项目。 主页：https://github.com/paulgb/sklearn-pandas 来源：kdnuggets，雷锋网编译","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"技术大牛带你走向机器学习“正道”","date":"2017-02-19T15:57:06.000Z","path":"2017/02/19/Program/Concepts/right-way-of-master-machine-learning/","text":"作者：雷锋网 亚峰 导语：现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉。 雷锋网按：“算法”这两字在人工智能圈已然成为“高大上”的代名词，由于不少在校生和职场新人对它的过度迷恋，多名 AI 资深人士均对这一现象表示担忧。李开复曾这样说到： 现在的 AI 科学家大部分是在科研环境中培养出来的，不但欠缺工程化、产品化的经验，而且对于错综复杂的商业环境也并不熟悉，更缺乏解决实际问题所必须的数据资源。随着开源框架层出不穷，人工智能产品化和商业化进程不断加速，使得算法的门槛逐渐降低，但对工程的要求不断在提高。这种情况下，实际应用和工程能力基础扎实的技术人才变得异常抢手。 其实 AI 新人们在进入职场后也愈发意识到这个问题，那他们该如何提升自己的实战能力？ 雷锋网特邀王刚为大家讲述机器学习的实战与应用，王刚根据工程、产品、业务等多个维度帮大家梳理如何系统地去学习机器学习。 嘉宾介绍： 王刚，前乐视大数据总监，现任某电商平台大数据总监。10 年大数据领域工作经验，具有 Hadoop 和 Spark 生态相关技术的实际应用经验。目前专注于机器学习，搜索和推荐系统的设计和开发。 以下为王刚所撰写的正文： 机器学习对很多初学者来说，最大的学习困难和障碍就是模型、算法、“眼花缭乱”的数学公式所带来的抽象感，无法有效的建立起直觉上的理解。所以本文的目的是尝试给初学者具体的学习方式建议，以帮助初学者打通机器学习的任督二脉，然后通过不断的学习和实践，使得自己在机器学习领域的专业能力持续提升。 机器学习与人工智能、深度学习之间的关系 当前被提及的高频词语是“AI人工智能”、“机器学习”、“深度学习”。那这些词语背后所代表的技术之间到底是什么关系呢？充分的理解这个关系，有利于建立起更加系统的专业学习框架。 首先，我们要搞明白机器学习到底学习的是什么，答案是模型“参数”，比如Y=AX+B是个机器学习的模型，通过样本数据，可以学习出参数A和B的确定值。然后基于这两个参数，对模型进行泛化，即对给定的X对Y进行预测。明白了机器学习到底是学习什么之后，我们一起看看下图来搞清楚机器学习与人工智能和深度学习之间的关系。 技术大牛带你走向机器学习“正道”：小朋友才迷信算法，大人们更重视工程实践 如上图所示，人工智能是最大的一个范畴，人工智能的实现目前看主要有两种途径：一种是基于脑科学的方式来实现智能。另一种是基于机器学习的方式来实现智能，这种方式的假设是当学习的数据足够充分，就可以大概率的逼近事实。 再回到公式Y=AX+B，我们可以看到机器学习是通过X和Y来学习出参数A和B，而在机器学习中，X是人工构造的特征，Y是人工进行标注的标签。一句话，机器学习就是通过构造X和Y来学习参数A和B。但通常情况下，构造X和标注Y需要耗用大量的人力和时间。所以，对于如何更智能的构造X和标注Y是机器学习很重要的研究方向。深度学习的一个重要作用就是能够更智能的构造X，即进行更好的特征表示。所以深度学习是机器学习的一个子集。那如何更好的标注Y呢，当前流行的对抗生成网络（GAN）就是一种解决方案。 机器学习需要的基础知识体系 机器学习的三个关键要素是模型、策略、算法。模型指的是具体的机器学习模型，比如决策树、SVM、神经网络、LDA等具体模型。策略指的是最小化模型结构性风险的手段，即避免模型欠拟合和过拟合的应对策略，在这里专指正则化（Regularization）。算法指的是建立好模型之后，如何对模型中的参数进行学习。也即最优化的方法。所以，初学者需要掌握的基础知识为： 1.导数与微积分，以及还需要对泰勒展开式、拉格朗日等定理和公式有充分的掌握。这是进行算法推导的基础中的基础。 2.线性代数，矩阵运算等要做到熟练掌握，因为机器学习的最优化算法中涉及到的复杂计算需要线性代数好矩阵运算的内容。 3.概率论，概率论的基础知识是理解像极大似然、最大熵、EM算法、贝叶斯网络、概率图模型的基础。 4.最优化，机器学习中的模型训练是通过对模型中参数的学习来进行泛化推广。如何对模型中的参数进行学习是最优化要解决的问题。比如线性优化、非线性优化的各种主要方法（比如梯度下降法、牛顿和拟牛顿法等）要有充分的理解。 5.机器学习模型的思想和具体实现方式要理解透彻。 机器学习的应用实践 特征工程，如上面所说就是造X，机器学习实践中大部分的实践都在处理特征工程上。所以真正有机器学习实践经验的人都知道机器学习更多的时间不是高大上的算法，而是苦逼特征工程。工程师每天更多的是基于对业务的深刻理解，通过构建“更好”的特征，持续提升模型的准确度。 推荐系统与搜索系统 当推荐和搜索这些字眼出现在网页中，专业书籍中，或是大部分的培训课程中，更多的是与机器学习和算法关联起来。这种情况的原因可能是为了迎合机器学习在大部分人认知中的“高大上”吧。 在实际的产品设计和开发中，推荐系统和搜索系统是有着一个更大概念的系统架构，绝非仅仅是只有机器学习和算法。其中UI/UE的重要性占比为40%，业务理解重要性占比为30%，数据重要性占比为20%，模型重要性占比为10%。 以推荐系统举例，整个推荐系统的框架应当如下图所示： 下图是电商平台上推荐系统的框架 所以，建议的推荐系统知识学习体系为： 一、推荐系统之整体架构 1.推荐系统的本质、目标及价值 2.一个好的推荐系统的相貌 3.线下零售的促销员与电商平台的推荐系统的关系 3.推荐系统与搜索的关系 4.主流电商平台上的推荐系统学习 5.推荐系统的整体架构图以及如何学习推荐系统 二、推荐系统之策略及模型 基于规则的推荐算法 基于内容(Content-Based)的推荐算法 基于协同过滤（CF)的推荐算法 基于隐因子（SVD/SVD++/MF/FM/FFM/PLSA/LDA）的推荐算法 推荐结果的排序模型（GBDT+LR，LTR） 数学基础及典型最优化算法 7.不同场景下的推荐策略（如在电商平台上，首页、详情页、购物车页、搜索结果页等不同场景下的推荐策略） 8.推荐系统评估 如何评估线下模型，如何评估线上效果 三、推荐系统之特征工程 1.用户画像如何构建 2.特征工程如何构建，以及如何进行特征分析 四、推荐系统之交互体验 如何向用户展示推荐系统的权威性、取得用户的信任、如何帮助用户决策、如何获取用户反馈。 如何开始机器学习 对于大多数人来说，如果以抽象的方式开始学习一项内容肯定不是最好的方式。相反，先建立起直觉，然后建立具体到抽象的映射，再深入学习抽象部分完成对细节部分的掌握，最后循环到具体的应用是适合大多数人的学习方式。所以对于机器学习初学者建议的学习路径为： 步骤一：先选择一门实战性非常强的机器学习及其应用课程进行学习。目标是通过足够多具体的应用，能够深刻理解机器学习的实际使用方式，从而建立起直觉。 步骤二：学习机器学习的理论课程，包括具体的模型算法，最优化方法，以及相关的公式推导。过了这一关，就完成了对机器学习细节的更好掌控。 步骤三：如果能够立刻参与到机器学习的实际项目中是最好不过了。如果不能，可以去完成Kaggle中的一些比赛项目。 最后，也是最最重要的建议，如果要想“更快速”“更高效”的掌握机器学习，找到合适的培训课程进行学习是最合适的方式。用钱买时间，买别人的经验，以更高效的方式掌握机器学习后，这些付出的费用可能仅仅是你工作之后月薪的很小的一部分。 在任督二脉打通之后，可以适当的对分布式存储和计算相关体系的内容进行学习。即靠的是个人的持续修行，在理论与实践循环提升中，成长为真正的专家。 PS：为了推动 AI 人才全面化，雷锋网将为大家提供一个业界顶级的专业 AI 技术培训平台：1024MOOC 。其中王刚老师也会在1024MOOC 开展系统的机器学习实战培训课程，具体开课时间在年后一周左右，请大家持续关注雷锋网(公众号：雷锋网)信息。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"28款 GitHub 最流行的开源机器学习项目：TensorFlow 排榜首","date":"2017-02-19T15:57:05.000Z","path":"2017/02/19/Program/TensorFlow/28-open-source-projects-of-machine-learning/","text":"作者：云栖社区 readygo 现在机器学习逐渐成为行业热门，经过二十几年的发展，机器学习得到了十分广泛的应用，如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、DNA序列测序、战略游戏和机器人等方面。 云栖社区特意翻译整理了目前GitHub上最受欢迎的28款开源的机器学习项目，以供开参考使用。 1. TensorFlowTensorFlow 是谷歌发布的第二代机器学习系统。据谷歌宣称，在部分基准测试中，TensorFlow的处理速度比第一代的DistBelief加快了2倍之多。具体的讲，TensorFlow是一个利用数据流图（Data Flow Graphs）进行数值计算的开源软件库：图中的节点（ Nodes）代表数学运算操作，同时图中的边（Edges）表示节点之间相互流通的多维数组，即张量（Tensors）。 这种灵活的架构可以让使用者在多样化的将计算部署在台式机、服务器或者移动设备的一个或多个CPU上，而且无需重写代码；同时任一基于梯度的机器学习算法均可够借鉴TensorFlow的自动分化（Auto-differentiation）；此外通过灵活的Python接口，要在TensorFlow中表达想法也变得更为简单。 TensorFlow最初由Google Brain小组（该小组隶属于Google’s Machine Intelligence研究机构）的研究员和工程师开发出来的，开发目的是用于进行机器学习和深度神经网络的研究。但该系统的通用性足以使其广泛用于其他计算领域。 目前Google 内部已在大量使用 AI 技术，包括 Google App 的语音识别、Gmail 的自动回复功能、Google Photos 的图片搜索等都在使用 TensorFlow 。 开发语言：C++许可协议：Apache License 2.0GitHub项目地址：https://github.com/tensorflow/tensorflow 2. Scikit-LearnScikit-Learn是用于机器学习的Python 模块，它建立在SciPy之上。该项目由David Cournapeau 于2007年创立，当时项目名为Google Summer of Code，自此之后，众多志愿者都为此做出了贡献。 主要特点：操作简单、高效的数据挖掘和数据分析无访问限制，在任何情况下可重新使用建立在NumPy、SciPy 和 matplotlib基础上 Scikit-Learn的基本功能主要被分为六个部分：分类、回归、聚类、数据降维、模型选择、数据预处理，具体可以参考官方网站上的文档。经过测试，Scikit-Learn可在 Python 2.6、Python 2.7 和 Python 3.5上运行。除此之外，它也应该可在Python 3.3和Python 3.4上运行。注：Scikit-Learn以前被称为Scikits.Learn。 开发语言：Python许可协议:3-Clause BSD licenseGitHub项目地址: https://github.com/scikit-learn/scikit-learn 3.CaffeCaffe 是由神经网络中的表达式、速度、及模块化产生的深度学习框架。后来它通过伯克利视觉与学习中心（(BVLC）和社区参与者的贡献，得以发展形成了以一个伯克利主导，然后加之Github和Caffe-users邮件所组成的一个比较松散和自由的社区。 Caffe是一个基于C++/CUDA架构框架，开发者能够利用它自由的组织网络，目前支持卷积神经网络和全连接神经网络（人工神经网络）。在Linux上，C++可以通过命令行来操作接口，对于MATLAB、Python也有专门的接口，运算上支持CPU和GPU直接无缝切换。 Caffe的特点 易用性：Caffe的模型与相应优化都是以文本形式而非代码形式给出， Caffe给出了模型的定义、最优化设置以及预训练的权重，方便快速使用；速度快：能够运行最棒的模型与海量的数据；Caffe可与cuDNN结合使用，可用于测试AlexNet模型，在K40上处理一张图片只需要1.17ms；模块化：便于扩展到新的任务和设置上；使用者可通过Caffe提供的各层类型来定义自己的模型；目前Caffe应用实践主要有数据整理、设计网络结构、训练结果、基于现有训练模型，使用Caffe直接识别。 开发语言：C++许可协议： BSD 2-Clause licenseGitHub项目地址: https://github.com/BVLC/caffe 4. PredictionIOPredictionIO 是面向开发人员和数据科学家的开源机器学习服务器。它支持事件采集、算法调度、评估，以及经由REST APIs的预测结果查询。使用者可以通过PredictionIO做一些预测，比如个性化推荐、发现内容等。PredictionIO 提供20个预设算法，开发者可以直接将它们运行于自己的数据上。几乎任何应用与PredictionIO集成都可以变得更“聪明”。其主要特点如下所示： 基于已有数据可预测用户行为；使用者可选择你自己的机器学习算法；无需担心可扩展性，扩展性好。PredictionIO 基于 REST API（应用程序接口）标准，不过它还包含 Ruby、Python、Scala、Java 等编程语言的 SDK（软件开发工具包）。其开发语言是Scala语言，数据库方面使用的是MongoDB数据库，计算系统采用Hadoop系统架构。 开发语言：Scala许可协议： Apache License 2.0GitHub项目地址: https://github.com/PredictionIO/PredictionIO 5. BrainBrain是 JavaScript 中的 神经网络库。以下例子说明使用Brain来近似 XOR 功能： 1234567891011var net = new brain.NeuralNetwork();net.train([&#123;input: [0, 0], output: [0]&#125;, &#123;input: [0, 1], output: [1]&#125;, &#123;input: [1, 0], output: [1]&#125;, &#123;input: [1, 1], output: [0]&#125;]);var output = net.run([1, 0]); // [0.987] 当 brain 用于节点中，可使用npm安装：npm install brain当 brain 用于浏览器，下载最新的 brain.js 文件。训练计算代价比较昂贵，所以应该离线训练网络（或者在 Worker 上），并使用 toFunction() 或者 toJSON()选项，以便将预训练网络插入到网站中。 开发语言：JavaScriptGitHub项目地址: https://github.com/harthur/brain 6. KerasKeras是极其精简并高度模块化的神经网络库，在TensorFlow 或 Theano 上都能够运行，是一个高度模块化的神经网络库，支持GPU和CPU运算。Keras可以说是Python版的Torch7，对于快速构建CNN模型非常方便，同时也包含了一些最新文献的算法，比如Batch Noramlize，文档教程也很全，在官网上作者都是直接给例子浅显易懂。Keras也支持保存训练好的参数，然后加载已经训练好的参数，进行继续训练。 Keras侧重于开发快速实验，用可能最少延迟实现从理念到结果的转变，即为做好一项研究的关键。当需要如下要求的深度学习的库时，就可以考虑使用Keras： 考虑到简单快速的原型法（通过总体模块性、精简性以及可扩展性）；同时支持卷积网络和递归网络，以及两者之间的组合；支持任意连接方案（包括多输入多输出训练）；可在CPU 和 GPU 上无缝运行。Keras目前支持 Python 2.7-3.5。 开发语言：PythonGitHub项目地址:https://github.com/fchollet/keras 7. CNTKCNTK（Computational Network Toolkit ）是一个统一的深度学习工具包，该工具包通过一个有向图将神经网络描述为一系列计算步骤。在有向图中，叶节点表示输入值或网络参数，其他节点表示该节点输入之上的矩阵运算。 CNTK 使得实现和组合如前馈型神经网络DNN、卷积神经网络（CNN）和循环神经网络(RNNs/LSTMs)等流行模式变得非常容易。同时它实现了跨多GPU 和服务器自动分化和并行化的随机梯度下降（SGD，误差反向传播）学习。 下图将CNTK的处理速度（每秒处理的帧数）和其他四个知名的工具包做了比较了。配置采用的是四层全连接的神经网络（参见基准测试脚本）和一个大小是8192 的高效mini batch。在相同的硬件和相应的最新公共软件版本（2015.12.3前的版本）的基础上得到如下结果： CNTK自2015年四月就已开源。 开发语言：C++GitHub项目地址:https://github.com/Microsoft/CNTK 8. ConvnetjsConvNetJS是利用Javascript实现的神经网络，同时还具有非常不错的基于浏览器的Demo。它最重要的用途是帮助深度学习初学者更快、更直观的理解算法。 它目前支持：常见的神经网络模块（全连接层，非线性）；分类（SVM/ SOFTMAX）和回归（L2）的成本函数；指定和训练图像处理的卷积网络；基于Deep Q Learning的实验强化学习模型。 一些在线示例：Convolutional Neural Network on MNIST digitsConvolutional Neural Network on CIFAR-10Toy 2D dataToy 1D regressionTraining an Autoencoder on MNIST digitsDeep Q Learning Reinforcement Learning demo +Image Regression (“Painting”) +Comparison of SGD/Adagrad/Adadelta on MNIST 开发语言：Javascript许可协议：MIT LicenseGitHub项目地址:https://github.com/karpathy/convnetjs 9. Pattern Pattern是Python的一个Web挖掘模块。拥有以下工具：数据挖掘：网络服务（Google、Twitter、Wikipedia）、网络爬虫、HTML DOM解析；自然语言处理：词性标注工具(Part-Of-Speech Tagger)、N元搜索(n-gram search)、情感分析(sentiment analysis)、WordNet；机器学习：向量空间模型、聚类、分类（KNN、SVM、 Perceptron）；网络分析：图形中心性和可视化。其文档完善，目前拥有50多个案例和350多个单元测试。 Pattern目前只支持Python 2.5+（尚不支持Python 3），该模块除了在Pattern.vector模块中使用LSA外没有其他任何外部要求，因此只需安装 NumPy （仅在Mac OS X上默认安装）。 开发语言：Python许可协议：BSD licenseGitHub项目地址:https://github.com/clips/pattern 10. NuPIC NuPIC是一个实现了HTM学习算法的机器智能平台。HTM是一个关于新（大脑）皮质（Neocortex）的详细人工智能算法。HTM的核心是基于时间的连续学习算法，该算法可以存储和调用时间和空间两种模式。NuPIC可以适用于解决各类问题，尤其是异常检测和流数据源预测方面。NuPIC Binaries文件目前可用于：Linux x86 64bitOS X 10.9OS X 10.10Windows 64bitNuPIC 有自己的独特之处。许多机器学习算法无法适应新模式，而NuPIC的运作接近于人脑，当模式变化的时候，它会忘掉旧模式，记忆新模式。 开发语言：PythonGitHub项目地址：https://github.com/numenta/nupic Theano Theano是一个Python库，它允许使用者有效地定义、优化和评估涉及多维数组的数学表达式，同时支持GPUs和高效符号分化操作。Theano具有以下特点：与NumPy紧密相关–在Theano的编译功能中使用了Numpy.ndarray ；透明地使用GPU–执行数据密集型计算比CPU快了140多倍（针对Float32）；高效符号分化–Theano将函数的导数分为一个或多个不同的输入；速度和稳定性的优化–即使输入的x非常小也可以得到log(1+x)正确结果；动态生成 C代码–表达式计算更快；广泛的单元测试和自我验证–多种错误类型的检测和判定。自2007年起，Theano一直致力于大型密集型科学计算研究，但它目前也很被广泛应用在课堂之上（ 如Montreal大学的深度学习/机器学习课程）。 开发语言：PythonGitHub项目地址：https://github.com/Theano/Theano 12. MXNet MXNet是一个兼具效率和灵活性的深度学习框架。它允许使用者将符号编程和命令式编程相结合，以追求效率和生产力的最大化。其核心是动态依赖调度程序，该程序可以动态自动进行并行化符号和命令的操作。其中部署的图形优化层使得符号操作更快和内存利用率更高。该库轻量且便携带，并且可扩展到多个GPU和多台主机上。 主要特点：其设计说明提供了有用的见解，可以被重新应用到其他DL项目中；任意计算图的灵活配置；整合了各种编程方法的优势最大限度地提高灵活性和效率；轻量、高效的内存以及支持便携式的智能设备；多GPU扩展和分布式的自动并行化设置；支持Python、R、C++和 Julia；对“云计算”友好，直接兼容S3、HDFS和Azure。MXNet不仅仅是一个深度学习项目，它更是一个建立深度学习系统的蓝图、指导方针以及黑客们对深度学习系统独特见解的结合体。 开发语言：Jupyter Notebook开源许可：Apache-2.0 licenseGitHub项目地址：https://github.com/dmlc/mxnet 13. Vowpal WabbitVowpal Wabbit是一个机器学习系统，该系统推动了如在线、散列、Allreduce、Learning2search、等方面机器学习前沿技术的发展。 其训练速度很快，在20亿条训练样本，每个训练样本大概100个非零特征的情况下：如果特征的总位数为一万时，训练时间为20分钟；特征总位数为1000万时，训练时间为2个小时。Vowpal Wabbit支持分类、 回归、矩阵分解和LDA。 当在Hadoop上运行Vowpal Wabbit时，有以下优化机制：懒惰初始化：在进行All Reduce之前，可将全部数据加载到内存中并进行缓存。即使某一节点出现了错误，也可以通过在另外一个节点上使用错误节点的数据（通过缓存来获取）来继续训练。Speculative Execution：在大规模集群当中，一两个很慢的Mapper会影响整个Job的性能。Speculative Execution的思想是当大部分节点的任务完成时，Hadoop可以将剩余节点上的任务拷贝到其他节点完成。 开发语言：C++GitHub项目地址：https://github.com/JohnLangford/vowpal_wabbit 14. Ruby Warrior通过设计了一个游戏使得Ruby语言和人工智能学习更加有乐趣和互动起来。使用者扮演了一个勇士通过爬上一座高塔，到达顶层获取珍贵的红宝石（Ruby）。在每一层，需要写一个Ruby脚本指导战士打败敌人、营救俘虏、到达楼梯。使用者对每一层都有一些认识，但是你永远都不知道每层具体会发生什么情况。你必须给战士足够的人工智能，以便让其自行寻找应对的方式。 勇士的动作相关API：Warrior.walk： 用来控制勇士的移动，默认方向是往前；warrior.feel：使用勇士来感知前方的情况，比如是空格，还是有怪物；Warrior.attack：让勇士对怪物进行攻击；Warrior.health：获取勇士当前的生命值；Warrior.rest：让勇士休息一回合，恢复最大生命值的10%。 勇士的感知API:Space.empty：感知前方是否是空格；Space.stairs：感知前方是否是楼梯；Space.enemy： 感知前方是否有怪物；Space.captive：感知前方是否有俘虏；Space.wall：感知前方是否是墙壁。 开发语言：RubyGitHub项目地址：https://github.com/ryanb/ruby-warrior 15. XGBoostXGBoot是设计为高效、灵活、可移植的优化分布式梯度 Boosting库。它实现了 Gradient Boosting 框架下的机器学习算法。XGBoost通过提供并行树Boosting（也被称为GBDT、GBM），以一种快速且准确的方式解决了许多数据科学问题。相同的代码可以运行在大型分布式环境如Hadoop、SGE、MP上。它类似于梯度上升框架，但是更加高效。它兼具线性模型求解器和树学习算法。 XGBoot至少比现有的梯度上升实现有至少10倍的提升，同时还提供了多种目标函数，包括回归、分类和排序。由于它在预测性能上的强大，XGBoot成为很多比赛的理想选择，其还具有做交叉验证和发现关键变量的额外功能。 值得注意的是：XGBoost仅适用于数值型向量，因此在使用时需要将所有其他形式的数据转换为数值型向量；在优化模型时，这个算法还有非常多的参数需要调整。 开发语言：C++开源许可：Apache-2.0 licenseGitHub项目地址：https://github.com/dmlc/xgboost 16. GoLearnGoLearn 是Go 语言中“功能齐全”的机器学习库，简单性及自定义性是其开发目标。 在安装 GoLearn 时，数据作为实例被加载，然后可以在其上操作矩阵，并将操作值传递给估计值。GoLearn 实现了Fit/Predict的Scikit-Learn界面，因此用户可轻松地通过反复试验置换出估计值。此外，GoLearn还包括用于数据的辅助功能，例如交叉验证、训练以及爆裂测试。 开发语言：GoGitHub项目地址: https://github.com/sjwhitworth/golearn 17. ML_for_HackersML_for_Hackers 是针对黑客机器学习的代码库，该库包含了所有针对黑客的机器学习的代码示例（2012）。该代码可能和文中出现的并不完全相同，因为自出版以来，可能又添加了附加的注释和修改部分。所有代码均为R语言，依靠众多的R程序包，涉及主题包括分类(Classification)、排行(Ranking)、以及回归(Regression)的所有常见的任务和主成分分析(PCA)和多维尺度(Multi-dimenstional Scaling)等统计方法。 开发语言：R开源许可：Simplified BSD LicenseGitHub项目地址: https://github.com/johnmyleswhite/ML_for_Hackers 18. H2O-2H2O使得Hadoop能够做数学运算！它可以通过大数据衡量统计数据、机器学习和数学。H2O是可扩展的，用户可以在核心区域使用简单的数学模型构建模块。H2O保留着与R、Excel 和JSON等相类似的熟悉的界面，使得大数据爱好者及专家们可通过使用一系列由简单到高级的算法来对数据集进行探索、变换、建模及评分。采集数据很简单，但判决难度却很大，而H2O却通过更快捷、更优化的预测模型，能够更加简单迅速地从数据中获得深刻见解。0xdata H2O的算法是面向业务流程——欺诈或趋势预测。Hadoop专家可以使用Java与H2O相互作用，但框架还提供了对Python、R以及Scala的捆绑。 开发语言：JavaGitHub项目地址: https://github.com/h2oai/h2o-2 19. neonneon 是 Nervana 基于 Python 语言的深度学习框架，在诸多常见的深层神经网络中都能够获得较高的性能，比如AlexNet、VGG 或者GoogLeNet。在设计 neon 时，开发者充分考虑了如下功能： 支持常用的模型及实例，例如 Convnets、 MLPs、 RNNs、LSTMs、Autoencoders 等，其中许多预训练的实现都可以在模型库中发现；与麦克斯韦GPU中fp16 和 fp32(基准) 的nervanagpu 内核紧密集成；在Titan X（1 GPU ~ 32 hrs上可完整运行）的AlexNet上为3s/macrobatch（3072图像）；快速影像字幕模型（速度比基于 NeuralTalk 的CPU 快200倍）。支持基本自动微分；框架可视化；可交换式硬盘后端：一次编写代码，然后配置到 CPU、GPU、或者 Nervana 硬盘。在 Nervana中，neon被用来解决客户在多个域间存在的各种问题。 开发语言：Python开源许可：Apache-2.0 licenseGitHub项目地址: https://github.com/NervanaSystems/neon 20. Oryx 2开源项目Oryx提供了简单且实时的大规模机器学习、预测分析的基础设施。它可实现一些常用于商业应用的算法类：协作式过滤/推荐、分类/回归、集群等。 此外，Oryx 可利用 Apache Hadoop 在大规模数据流中建立模型，还可以通过HTTP REST API 为这些模型提供实时查询，同时随着新的数据不断流入，可以近似地自动更新模型。这种包括了计算层和服务层的双重设计，能够分别实现一个Lambda 架构。模型在PMML格式交换。 Oryx本质上只做两件事：建模和为模型服务，这就是计算层和服务层两个独立的部分各自的职责。计算层是离线、批量的过程，可从输入数据中建立机器学习模型，它的经营收益在于“代”，即可利用某一点处输入值的快照建模，结果就是随着连续输入的累加，随时间生成一系列输出；服务层也是一个基于Java长期运行的服务器进程，它公开了REST API。使用者可从浏览器中访问，也可利用任何能够发送HTTP请求的语言或工具进行访问。 Oryx的定位不是机器学习算法的程序库，Owen关注的重点有四个：回归、分类、集群和协作式过滤（也就是推荐）。 其中推荐系统非常热门，Owen正在与几个Cloudera的客户合作，帮他们使用Oryx部署推荐系统。 开发语言：JavaGitHub项目地址: https://github.com/cloudera/oryx 21. ShogunShogun是一个机器学习工具箱，由Soeren Sonnenburg 和Gunnar Raetsch（创建，其重点是大尺度上的内核学习方法，特别是支持向量机（SVM，Support Vector Machines）的学习工具箱。它提供了一个通用的连接到几个不同的SVM实现方式中的SVM对象接口，目前发展最先进的LIBSVM和SVMlight 也位于其中，每个SVM都可以与各种内核相结合。工具箱不仅为常用的内核程序（如线性、多项式、高斯和S型核函数）提供了高效的实现途径，还自带了一些近期的字符串内核函数，例如局部性的改进、Fischer、TOP、Spectrum、加权度内核与移位，后来有效的LINADD优化内核函数也已经实现。 此外，Shogun还提供了使用自定义预计算内核工作的自由，其中一个重要特征就是可以通过多个子内核的加权线性组合来构造的组合核，每个子内核无需工作在同一个域中。通过使用多内核学习可知最优子内核的加权。 目前Shogun可以解决SVM 2类的分类和回归问题。此外Shogun也添加了了像线性判别分析（LDA）、线性规划（LPM）、（内核）感知等大量线性方法和一些用于训练隐马尔可夫模型的算法。 开发语言：C/C++、Python许可协议：GPLv3GitHub项目地址: https://github.com/shogun-toolbox/shogun 22. HLearnHLearn是由Haskell语言编写的高性能机器学习库，目前它对任意维度空间有着最快最近邻的实现算法。 HLearn同样也是一个研究型项目。该项目的研究目标是为机器学习发掘“最佳可能”的接口。这就涉及到了两个相互冲突的要求：该库应该像由C/C++/Fortran/Assembly开发的底层库那样运行快速；同时也应该像由Python/R/Matlab开发的高级库那样灵活多变。Julia在这个方向上取得了惊人的进步，但是 HLearn“野心”更大。更值得注意的是，HLearn的目标是比低级语言速度更快，比高级语言更加灵活。 为了实现这一目标，HLearn采用了与标准学习库完全不同的接口。在HLearn中H代表着三个不同的概念，这三个概念也是HLearn设计的基本要求：H代表Haskell。机器学习是从数据中预测函数，所以功能性编程语言适应机器学习是完全说的通的。但功能性编程语言并没广泛应用于机器学习，这是因为它们固来缺乏支持学习算法的快速数值计算能力。HLearn通过采用Haskell中的SubHask库获得了快速数值计算能力； H同时代表着Homomorphisms。Homomorphisms是抽象代数的基本概念，HLearn将该代数结构用于学习系统中； H还代表着History monad。在开发新的学习算法过程中，最为困难的任务之一就是调试优化过程。在此之前，是没有办法减轻调试过程的工作量的，但History monad正在试图解决该问题。它可以让你在整个线程优化代码的过程中无需修改原代码。此外，使用该技术时没有增加其他的运行开销。 开发语言：HaskellGitHub项目地址:https://github.com/mikeizbicki/HLearn 23. MLPNeuralNetMLPNeuralNet是一个针对iOS和Mac OS系统的快速多层感知神经网络库，可通过已训练的神经网络预测新实例。它利用了向量运算和硬盘加速功能（如果可用），其建立在苹果公司的加速框架之上。 若你已经用Matlab（Python或R）设计了一个预测模型，并希望在iOS应用程序加以应用。在这种情况下，正好需要MLP NeuralNet，而MLP NeuralNet只能加载和运行前向传播方式的模型。MLP NeuralNet 有如下几个特点： 分类、多类分类以及回归输出；向量化实现形式；双精度；多重隐含层数或空（此时相当于逻辑学/线性回归）。 开发语言：Objective-C许可协议：BSD licenseGitHub项目地址: https://github.com/nikolaypavlov/MLPNeuralNet 24. Apache MahoutMahout 是Apache Software Foundation（ASF） 旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。Apache Mahout项目的目标是建立一个能够快速创建可扩展、高性能机器学习应用的环境。 虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：Taste CF，Taste是Sean Owen在SourceForge上发起的一个针对CF的开源项目，并在2008年被赠予Mahout；一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift；Distributed Naive Bayes 和 Complementary Naive Bayes 分类实现；针对进化编程的分布式适用性功能；Matrix 和矢量库。使用 Mahout 还可实现内容分类。Mahout 目前支持两种根据贝氏统计来实现内容分类的方法：第一种方法是使用简单的支持 Map-Reduce 的 Naive Bayes 分类器；第二种方法是 Complementary Naive Bayes，它会尝试纠正Naive Bayes方法中的一些问题，同时仍然能够维持简单性和速度。 开发语言：Java许可协议：ApacheGitHub项目地址: https://github.com/apache/mahout 25. Seldon ServerSeldon是一个开放式的预测平台，提供内容建议和一般的功能性预测。它在Kubernetes集群内运行，因此可以调配到Kubernetes范围内的任一地址：内部部署或云部署（例如，AWS、谷歌云平台、Azure）。另外，它还可以衡量大型企业安装的需求。 开发语言：JavaGitHub项目地址: https://github.com/SeldonIO/seldon-server 26. Datumbox - FrameworkDatumbox机器学习框架是用Java编写的一个开源框架，该框架的涵盖大量的机器学习算法和统计方法，并能够处理大尺寸的数据集。 Datumbox API提供了海量的分类器和自然语言处理服务，能够被应用在很多领域的应用，包括了情感分析、话题分类、语言检测、主观分析、垃圾邮件检测、阅读评估、关键词和文本提取等等。目前，Datumbox所有的机器学习服务都能够通过API获取，该框架能够让用户迅速地开发自己的智能应用。目前，基于GPL3.0的Datumbox机器学习框架已经开源并且可以从GitHub上进行下载。 Datumbox的机器学习平台很大程度上已经能够取代普通的智能应用。它具有如下几个显著的优点： 强大并且开源。Datumbox API使用了强大的开源机器学习框架Datumbox，使用其高度精确的算法能够迅速地构建创新的应用；易于使用。平台API十分易于使用，它使用了REST&amp;JSON的技术，对于所有的分类器；迅速使用。Datumbox去掉了那些很花时间的复杂机器学习训练模型。用户能够通过平台直接使用分类器。 Datumbox主要可以应用在四个方面：一个是社交媒体的监视，评估用户观点能够通过机器学习解决，Datumbox能够帮助用户构建自己的社交媒体监视工具；第二是搜索引擎优化，其中非常有效的方法就是文档中重要术语的定位和优化；第三点是质量评估，在在线通讯中，评估用户产生内容的质量对于去除垃圾邮件是非常重要的，Datumbox能够自动的评分并且审核这些内容；最后是文本分析，自然语言处理和文本分析工具推动了网上大量应用的产生，平台API能够很轻松地帮助用户进行这些分析。 开发语言：Java许可协议：Apache License 2.0GitHub项目地址: https://github.com/datumbox/datumbox-framework 27. JubatusJubatus库是一个运行在分布式环境中的在线机器学习框架，即面向大数据数据流的开源框架。它和Storm有些类似，但能够提供更多的功能，主要功能如下：在线机器学习库：包括分类、聚合和推荐；Fv_converter: 数据预处理（用自然语言）；在线机器学习框架，支持容错。 Jubatus认为未来的数据分析平台应该同时向三个方向展开：处理更大的数据，深层次的分析和实时处理。于是Jubatus将在线机器学习，分布式计算和随机算法等的优势结合在一起用于机器学习，并支持分类、回归、推荐等基本元素。根据其设计目的，Jubatus有如下的特点： 可扩展：支持可扩展的机器学习处理。在普通硬件集群上处理数据速度高达100000条/秒； ＋实时计算：实时分析数据和更新模型；深层次的数据分析：支持各种分析计算：分类、回归、统计、推荐等。如果有基于流数据的机器学习方面的需求，Jubatus值得关注。 开发语言：C/C++许可协议：LGPLGitHub项目地址: https://github.com/jubatus/jubatus 28. DeciderDecider 是另一个 Ruby 机器学习库，兼具灵活性和可扩展性。Decider内置了对纯文本和URI、填充词汇、停止词删除、字格等的支持，以上这些都可以很容易地在选项中组合。Decider 可支持Ruby中任何可用的存储机制。如果你喜欢，可以保存到数据库中，实现分布式分类。Decider有几个基准，也兼作集成测试。这些都是定期运行并用于查明CPU和RAM的瓶颈。Decider可以进行大量数学运算，计算相当密集，所以对速度的要求比较高。这是经常使用Ruby1.9和JRuby测试其计算速度。此外，用户的数据集应该完全在内存中，否则将会遇到麻烦。 开发语言：RubyGitHub项目地址: https://github.com/danielsdeleo/Decider 编译自：https://github.com/showcases/machine-learning译者：刘崇鑫 校对：王殿进","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"谷歌机器学习白皮书全解析43条黄金法则","date":"2017-02-19T15:57:00.000Z","path":"2017/02/19/Program/Concepts/white-paper-of-google-machine-learning/","text":"作者：雷锋网 谷歌白皮书原文地址：http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf 编者按：此白皮书为谷歌总结的机器学习（ML）最优实践方法，浓缩了其多年技术积累与经验，尤其是 Youtube、Google Play 和 Google+ 等平台背后的 ML 算法开发、维护经历。谷歌于白皮书中总结了四十三条 ML 黄金法则，旨在帮助已经掌握了基础知识的开发者少走弯路。鉴于其珍贵程度与技术性，雷锋网逐条做了严格尊重原文的翻译。若你已学习过机器学习课程，抑或有开发 ML 模型的经验，那么应当具备足够的背景知识理解这篇文章。 术语 以下是对文中反复出现的术语的解释。 实例（ Instance）：做预测的对象。比如说，实例可以是一个网页，你想要把它分类为“关于猫”或者“与猫不相关”。 标记（Label）：预测任务的答案。它既可以是机器学习系统生成的答案，也可以是训练数据中提供的正确答案（雷锋网注：比如监督学习中的人工标记）。举例来说，一个网页的标记可以是“关于猫”。 特征（Feature）：预测任务中实例的属性。比如说，某网页可能有“包含关键词‘猫’”的特征 特征栏 （Feature Column）:这是谷歌自创的术语，意为关联特征的集合。比如说，用户的所有可能居住国家的集合。一个样例的特征栏可以有一个或多个特征。特征栏可被看作是 VW 系统（微软、雅虎所用）中的命名空间，或者场（ field）。 样例（Example）：有标记的实例（具备特征）。 模型（Model）：对预测任务的统计表达。你用样例训练模型，然后用模型做预测。 指标（Metric）：你在意的数字。可被直接优化过，也可没有。 目标（Objective）：你的算法试图优化的指标。 流水线（Pipeline）：机器学习算法的基础设施；包括从前端收集数据，把它放入训练数据文档，训练一个或多个模型，以及把模型输出、产品化。 概览： 为了开发出好产品： 做机器学习这一行首先要摆正心态，你是一名（优秀的）工程师，不要拿专家的标准来要求自己。 事实上，你将要面对的大多数难题是工程问题（engineering problems）。即便是一个杰出的ML 专家，坐拥该级别才有的资源，其大多数收获也来自于特征而不是 ML 算法。所以，ML 开发的基本路线是： 保证可靠的端到端流水线 从制定合理的目标着手 用简单的方式，加入符合常识的特征 确保流水线始终可靠 该方法能帮你赚钱养家，并且让很多人满意。只有当无路可走、简单的技巧无法再起作用时，你才需要偏离该路线。但注意，提高复杂度会拖慢将来的产品发布。另外，当你穷尽了简单技巧，或许就到了登堂入室、探索 ML 最前沿技术的时候了。具体请看本文机器学习第三阶。 本文分为四个部分： 第一部分“1.0 做机器学习之前”，会帮你搞清楚，你创建机器学习系统的时机是否已经成熟。 第二部分“2.0 机器学习第一阶”是关于设置你的第一个流水线。 第三部分“3.0 机器学习第二阶”，关乎启动和重复，同时向流水线加入新特征。 最后一部分“4.0 机器学习第三阶”是关于达到瓶颈后怎么办。 43 条黄金法则列表： 对发布一个不含 ML 技术的产品，不要有顾虑 首先要设计和贯彻指标 在机器学习和复杂启发算法之间，选择前者 第一个模型要简单，把基础设施弄好 测试基础设施要与 ML 测试分开 复制流水线时当心数据遗落 把启发式（heuristics）变为特征，不然就对它们做外部处理 了解系统的时效性 在输出模型之前发现问题 于无声处听惊雷：注意没表现出来的故障 注意特征栏的维护者和文件 选择直接优化哪个目标时，不需要想太多 选择一个简单、可观察并且可归属（attributable）的指标来作为第一个目标 用可解释的模型开头，修补漏洞会更简单 用 policy layer（规则层）把垃圾信息过滤和质量排序分来 做好模型被推倒和重建的准备 直接以观察到的或报告的特征开始训练，而不是经过学习的特征 从不同的上下文环境中提取特征 尽量选择更具体的特征 以合理的方式组合、修改现有特征 通过线性模型学到的特征权重的数目，大致与数据量成正比 清理不需要的特征 你并不是一个典型的用户 版本之间存在对等差分（symmetric difference） 选择模型时，性能胜过预测能力 从误差中查找新模式、创建新特征 尝试量化观察到的异常行为 注意短期行为和长期行为的差别 确保训练和服务一样好的最直接办法是：保存服务时使用的特征，然后将这些特征导入日志，以便在训练中使用。 重视采样数据 注意表格中的数据可能改变 尽量在训练和服务流水线中复用代码 训练和测试的数据不能相同 在二进制分类过滤的应用场景中（例如垃圾邮件检测），不要为了纯净的数据做太大的性能牺牲 注意排序问题的固有偏差 避免具有位置特征的反馈回路 测量训练/服务偏差 如果目标之间不搭，并成为问题，就不要在新特征上浪费时间 模型发布决策是长期产品目标的代理 保证集成模型（ensemble）的简洁 当性能达到瓶颈，相比精炼现存信号，不如寻找新性质的信息源 不要期望多样性、个性化、相关性和受欢迎程度之间有紧密联系 不同产品中，你的朋友总是那一个，你的兴趣不会如此 1.0 做机器学习之前 对发布一个不含 ML 技术的产品，不要有顾虑 机器学习很酷，但要有数据。理论上，你可以把另一个相近课题的数据拿来用，调整下模型变成一个新产品。但这么做的实际效果，通常比简单的启发式算法（heuristics）还差。如果你认为机器学习能完成任务的 100%。那么启发式算法能帮你完成 50%。 比如说，若你为应用商店进行 app 排名，不妨直接利用下载率和装机量写个简单算法；若你在检测垃圾邮件，可以先把发送过垃圾邮件的地址过滤掉。也不要在人工编辑上有顾虑。如果机器学习对于你的产品不是必需的，那么在获得数据之前不要用它。 首先要设计和贯彻指标 在定义你的 ML 系统要做什么之前，要尽可能多得追踪你当前的系统。这出于以下原因： 在早期，获得系统用户的许可相对容易。 如果你认为有些东西在将来需要考虑，最好从现在起就收集历史数据。 如果你设计系统时考虑了指标的工具化（ metric instrumentation），会省下将来的许多力气。你绝对不想为了指标而查找日志字符串。 有些东西会改变，有些不会。比如说，假设你想要直接优化每日活跃用户。但是，在你对系统的早期操作中，你也许会发现用户体验的大幅变化并不会显著改变这个指标。 Google+ 团队会衡量每次阅读的扩展数（expands per read）、分享、点赞、评论，以及每用户评论数、分享等等。然后他们利用这些数据计算发布消息的质量。另外要注意，能通过试验把用户分组并整合数据的试验框架非常重要，参考第 12 条。 通过更灵活地收集指标，你能用更大的视角观察系统。发现一个问题？添加一个指标来追踪它！对上一个发布版本的量化变动很兴奋？添加指标来追踪! 在机器学习和复杂启发算法之间，选择前者 一个简单的启发算法能帮助产品走向市场，而复杂启发算法难以维护。一旦你有了数据以及需要实现的目标的蓝图，就可以转去开发 ML。在大多数软件工程任务中，开发者需要不停更新开发方式，不管是启发式算法还是 ML 模型。你会发现后者更加容易更新维护（参考第 16 条）。 2.0 机器学习第一阶2.1 你的第一条流水线 对于第一条流水线，关注你的系统基础设施。虽然，设想你将要做的种种 ML 应用很有趣；但如果你无法信任自己的流水线，你会很难搞清楚状况。 第一个模型要简单，把基础设施弄好 第一个模型为你的产品提供了最大的助力，所以它不需要花哨。而且你会遇到许多想象之外的基础设施问题。在你的新 ML 系统诞生之前，你需要决定： 如何获取学习算法的样例 对于你的系统，“好”、“坏”的定义是什么 如何把模型整合入应用。你可以实时应用模型，也可以在线下预计算模型，并把结果保存好。比如对网页预分类，然后在表格里保存结果。但有的任务可能需要对实时聊天信息进行分类。 选择简单的特征更容易保证： 这些特征正确应用于学习算法 模型学会合理的权重。 这些特征正确应用于服务器模型。 当你有了能可靠做到上述三点的系统，大部分的工作就已完成。简单模型提供给你基础的指标和行为，然后你可以用它们来测试更复杂的模型。有些团队把目标定为“中性”的首发——故意在首次发布不那么重视机器学习成果，以避免分心。 测试基础设施要与 ML 测试分开 要确保基础设施可测试，而且系统的学习部分都被包含在内，使得你能够测试所有相关物。特别是： 测试把数据导入算法。检查可填充的特征栏是不是空的。若条件允许，手工检查训练算法的输入。若可能，把流水线数据与其他地方作比较，比如 RASTA。 测试把数据导出训练算法。确保训练环境的模型与服务环境（serving environment）的模型产生同样的得分（详见第 37 条）。 ML 有不可预测的因素。所以一定要对生成训练、服务样例的代码进行测试；这样你可以在服务中载入、使用固定模型。另外，理解你的数据也十分重要。 复制流水线时当心数据遗落 我们经常复制现成的流水线来创建新流水线（例如 cargo cult 编程），但有时旧流水线遗落了新流水线需要的数据。举个例子， Google Plus What’s Hot（雷锋网按：社交软件 Google+ 的热门新闻版块） 的流水线会遗落旧帖子（因为它试图为新帖子排名）。我们复制该流水线，用于 Google Plus Stream（Google+ 流）。对于后者，旧帖子仍然有意义，但新流水线仍然会丢掉数据。 另一个常见的模式是只记录用户看过的数据。因此，当你需要对为什么用户没有看到某个信息进行建模，该数据完全没用——因为所有反例已经被丢掉了。Google Play 发生过一个类似的问题：当我们开发 Google Play 应用商城主页时，创建出的新流水线包含另外两个登录页面（Play Games Home and Play Home Home，游戏主页和家庭主页）的样例。但是，并没有能够对“样例来自于哪个主页”加以区分的特征。 把启发式（heuristics）变为特征，不然就对它们做外部处理 通常来讲，ML 试图解决的问题并不是什么新问题——一般有现成的排名、分类等各种系统。这意味着有一大堆规则和启发式算法可用。这些启发式能在你调整 ML 时起到帮助。你应该压榨出启发式算法的所有信息，这有两个原因：1. 到 ML 系统的过渡会更顺畅。2. 这些规则通常包含一大堆关于系统的直觉信息，你绝对不想把它们扔掉。有四种利用现成启发式算法的途径： 使用启发式算法预处理。如果该特征非常棒，那么这就是一个选择。举个垃圾邮件过滤器的例子，若发件人已经被加入黑名单，不要试图重新学习“加入黑名单”是啥意思。直接拦截该信息。该方法最适用于二分类任务。 创建特征。直接用启发式创建特征相当棒。比如说，如果你用启发式计算一个问题结果的相关度分值，你可以把该得分作为特征值。之后，你或许想用 ML 技术来操作数值（比如把数值转化为有限个独立值集合，或与其他特征合并），但却拿启发式生成的原始数值来开头。 挖掘启发式的原始输入。如果有面向 APP 的启发式把装机量、文字中字母数目和日期组合到一起，就得考虑把它们分开——把这些输入分开来学习。有些应用于整体的技巧可用在这里（详见第 40 条）。 修正标记。当你发现启发式抓取了标记中未包含的信息时，这是一个选择。举个例子，如果你试图最大化下载量，但却仍然想要高品质内容，那么或许最好的方案是把标记与 APP 的平均星星得分相乘。这里有很大的余地。请参考“2.3 你的第一个目标”部分。 请注意启发式为 ML 系统加入的复杂度。在新 ML 算法中加入旧启发式有助于平滑地过渡，但你需要考虑是否更简单的实现方式。 2.2 监测 总的来讲，养成处理警告（alerts）的好习惯，比如对每个提醒付诸行动，并且建立一个仪表页面（dashboard page）。 了解系统的时效性 当你的模型已经开发出来一天、一周、一季度了，它的效果分别会降低多少？该信息能帮助你理解维护任务的优先级。假设模型一天没更新，你就要损失 10% 的收入。那么你或许要考虑雇佣专人每天维护。许多广告服务系统每天都有需要处理的新广告，因此必须每日更新。再举一个例子，如果 Google Play 的搜索 ML 模型停止更新，一个月内就会造成很大的损失。Google+ What’s Hot（雷锋网注：热门推荐）的一些模型，并没有针对发布信息的身份确认机制，所以不需要频繁导出这些模型。但有身份确认机制的模型就需要非常频繁地更新。另外需注意，时效性会随时间而变化，尤其是为模型添加或移除特征栏的时候。 在输出模型之前发现问题 许多 ML 系统包含该步骤：输出模型到服务端。如果输出的模型有问题，会直接让用户们遇上。而这个环节之前的问题只是训练问题，不会影响用户体验。 在导出模型之前一定要检查，尤其要确保模型在给定数据上有合理的效果。另外，若你对数据有顾虑，不要输出该模型。许多开发团队会在模型输出前检查 ROC 曲线 (或 AUC) 下的区域。未输出的模型存在问题，可能只需要一封 email 提醒一下。但用户端模型出了问题，很可能需要你向上司、同事解释一整页。所以最好多花点时间，在影响到用户之前做到胸有成竹。 于无声处听惊雷：注意没表现出来的故障 这是一个多见于机器学习、而少见于其他系统的问题。设想一个不再更新的特定表格：机器学习系统会调整，其行为仍会有合理表现，但逐渐退化。有时候开发者会发现过期几个月的表格——这时，一个简单的更新所提高的性能，比该季度的所有发布新版本都要高。举个例子，对一个特征的取舍会因为执行情况的变化而变化：覆盖 90% 样例的特征栏可能突然降低到只覆盖 60%。Google Play 曾经就有一个过期了六个月的表格，单单更新那个表格就带来了 2% 的安装率提升。如果你对统计数据进行跟踪，并偶尔人工检查，就能减少这类失误。 注意特征栏的维护者和文件 如果系统很大、有许多特征栏，你需要知道谁创立、维护了每一个特征栏。如果你发现懂得特征栏的那个人要跳槽了，一定要确保团队里有还有人知道这些信息。虽然许多特征栏有描述名称，你仍然需要更详细的解释，知道它是什么、从哪里来、起什么作用。 2.3 你的第一个目标 你有许多关心的系统指标或度量，但 ML 算法通常只需要一个目标——算法试图优化的某个数字。这里，我要区别目标（objectives）和指标（metrics）：指标是系统报告的任何数字，或许重要，或许不重要。详见第二条。 选择直接优化哪个目标时，不需要想太多 你想要赚钱，让用户满意，并且让地球更美好。有许多你关心的指标，你应该全部都去测量（见第二条）。但在 ML 初期，你会注意到它们全都有提升，即便是那些没有直接优化的也是如此。举个例子，假设你关注点击数、浏览时间和每日活跃用户。如果你优化点击数，你会看到浏览时间也在上升。 所以简简单单就好。当你能轻易地提高所有指标，不需要在不同指标之间的平衡上想太多。但也不要误解这条建议：别把目标与系统最终的健康混为一谈（详见第 39 条）。另外，如果你增加了直接优化的指标，但决定不予发布，或许有必要重新修订目标。 选择一个简单、可观察并且可归属（attributable）的指标来作为第一个目标 很多情况下你不知道真正的目标是什么——你以为你知道。但当你仔细观察数据，以及对旧系统和新 ML 系统进行分析，你意识到自己其实想要对原定目标进行修改。团队不同成员也经常无法在真正的目标上取得一致意见。ML 目标应当易于测量，并可作为“真正”目标的代理。所以最好采用简单的 ML 目标训练，然后考虑在这之上设一个 “policy layer”（规则层），允许你加入额外的逻辑（但愿是简单的逻辑）来做最终排名。 最容易建模的是，能被直接观察到、并且可归属于系统中某个行动的用户行为： 这个排名链接被点击了吗? 这个排名对象被下载了吗？ 这个排名对象被 转发/回复/发 email 了吗？ 这个排名对象被打分了吗？ 这个显示的对象被标记为垃圾邮件/色情信息/侮辱性信息了吗？ 一开始要避免对间接作用建模： 用户在第二天访问了吗？ 用户的访问时间是多长？ 每日活跃用户都是谁？ 其实，间接作用是非常不错的指标，并且可在 A/B 测试和发布决定中使用。 最后，不要试图让 ML 搞懂： 用户对使用该产品满意吗? 用户对体验满意吗？ 产品提升了用户的福祉了吗？ 这如何影响公司的整体健康？ 这些都很重要，但是极度困难。你应该用代理来替代：如果用户感到开心，他们会在页面停留更长时间。如果用户满意，他明天会再次访问。目前，当涉及到福祉和公司健康状态，把 ML 目标与产品本质和商业计划之间做关联需要人的判断。 用可解释的模型开头，修补漏洞会更简单 线性回归、逻辑回归、泊松回归（Poisson regression）直接被概率模型驱动，每个预测都可作为概率或期望值解释。这使得相比使用了目标、直接优化分类精度或排序效果的模型（zero­one 损失、各种 hinge 损失等等），它们修补漏洞更加简单。如果通过对比或检查产品系统，发现训练里的概率偏离了预测概率，就可能存在问题。 比如说，在线性回归、逻辑回归、泊松回归之中，有的数据子集里平均预期和平均标签相等（1-­moment 校准，或者普通校准 ）。对于一个值要么是 0 要么是 1 的特征，三个特征值为 1 的样例集就会被校准。同样地，若某特征下所有样例的特征值都是 1，它们都会被校准。 对于简单的模型，处理反馈回路（ feedback loops ）更加容易。我们经常用这些概率预期来做决定：比如以期望值（点击概率/下载量等）为标准对发布消息进行降序排列。但要记住，当决定采用那个模型的时候，你的决定比给定模型数据的可能性（ the likelihood of the data given the model ）更加重要（参考第 21 条）。 用 policy layer（规则层）把垃圾信息过滤和质量排序分来 质量排序是一门高雅的艺术，而垃圾信息过滤是一场战争。对于使用你系统的人，你用来判断高质量消息的信号十分显而易见。然后，他们会据此调整他们的发布信息来获得这些属性。因此，你的质量排序应当专注于有信誉的内容——不应该让质量排序学习器退化到给垃圾信息高排名。同样的，重口味内容应当与质量排序分开。而垃圾信息过滤是另一回事了。你需要创建的特征会不断变化，对此要有心理准备。通常，你加入系统里的规则有些很显而易见（比如，若一个发布信息得到超过三个“垃圾信息”票数，不要恢复它）。任何学习到的模型需要至少每天更新。内容生产者的名誉会起到相当大的作用。 在某个层级，这两个系统的输出需要整合在一起。需要注意的是，在搜索结果里过滤垃圾信息，比过滤垃圾邮件要更加强力。 为了高质量的分类器而去除训练数据中的垃圾，已是行业标准。 3.0 机器学习第二阶段3.1 特征工程 在进行机器学习相关实践的第一阶段，你要关注的主要问题包括以下三个方面：一是将训练数据导入系统，二是确定系统的重点关注指标，三是保证底层基础设施的稳定可靠。当这三个问题都确认无误，即已经搭建了一个端到端的可稳定运行的系统，并且针对系统本身和其中的每个单元都经过了严格测试，这时就可以进入第二阶段了。 应该说，第二阶段将更容易取得成绩。这一阶段会有许多显著的特征（feature）被导入系统，因此，导入并以直观的方式组合这些特征，将是本阶段涉及的主要任务。另外，本阶段也更适合多位工程师协同工作，共同对此前导入的训练数据进行整合和处理，推动所有的指标（metric）在本阶段取得持续性的上升。 做好模型被推倒和重建的准备 不要指望从头到尾只使用一个模型，也不要指望着某一结点之后就不用重建模型了，模型的推倒和重建是机器学习过程中的必修课。另外，每加入一个新特性都必须考虑是否会拉低模型的运行效率。目前，许多团队每三个月或一年就会新建一个模型。这里我们总结了一般情况下引发模型重建的三大原因： 1) 增加新的特征 2) 打算重组旧的特征，或对旧模型正则化 3) 修订建模目标 无论如何，创建模型时多想想并没有什么坏处：例如检查训练数据是否有更合理的组织形式，考虑当前的建模方式是否便于特征的修改和重组，当前的机器学习流水线（pipeline）是否便于创建副本并检验其正确率，以及是否可以创建两到三个副本并行运行等等。最后需要指出的是，并不一定非要在一个机器学习流水线中覆盖所有特征，在下一个版本中实现也是可行的。 直接以观察到的或报告的特征开始训练，而不是经过学习的特征 这一点建议或许存在一些争议，但的确能避免许多潜在的问题。这里经过学习的特征（learned feature）是指由外部系统（例如无监督的聚类系统）或模型本身（例如通过深度学习和因子模型）产生的特征。这两种情况虽然的确可以使用，但并不适合系统的第一个模型。 首先，在使用外部系统创建特征时必须要格外小心。因为外部系统的目标可能与当前系统并不相符，而且从外部系统更新当前系统的特征，其特定的含义也可能改变。 另一方面，因子模型和深度模型的主要问题是它们是非凸的（non-convex），因此它们无法保证可以最终找到或近似找到最优解，它们在每次迭代中产生的局部最小值都可能变化，而且目前无法评估这种变化对系统的影响是有益的还是有害的。通过创建没有深度特征的模型，你就可以获得很好的基准性能。在实现这一基准性能之后，你可以尝试更高阶的方法。 从不同的上下文环境中提取特征 通常情况下，机器学习只占到一个大系统中的很小一部分，因此你必须要试着从不同角度审视一个用户行为。比如热门推荐这一场景，一般情况下论坛里“热门推荐”里的帖子都会有许多评论、分享和阅读量，如果利用这些统计数据对模型展开训练，然后对一个新帖子进行优化，就有可能使其成为热门帖子。另一方面，YouTube上自动播放的下一个视频也有许多选择，例如可以根据大部分用户的观看顺序推荐，或者根据用户评分推荐等。总之，如果你将一个用户行为用作模型的标记（label），那么在不同的上下文条件下审视这一行为，可能会得到更丰富的特征（feature），也就更利于模型的训练。需要注意的是这与个性化不同：个性化是确定用户是否在特定的上下文环境中喜欢某一内容，并发现哪些用户喜欢，喜欢的程度如何。 尽量选择更具体的特征 在海量数据的支持下，即使学习数百万个简单的特征也比仅仅学习几个复杂的特征要容易实现。由于被检索的文本标识与规范化的查询并不会提供太多的归一化信息，只会调整头部查询中的标记排序。因此你不必担心虽然整体的数据覆盖率高达90%以上，但针对每个特征组里的单一特征却没有多少训练数据可用的情况。另外，你也可以尝试正则化的方法来增加每个特征所对应的样例数。 以合理的方式组合、修改现有的特征 目前有多种方法组合、修改现有的特征，由于本文以Google工具为背景，因此在这里推荐两种TensorFlow框架已实现好的方法：“离散化”（discretizations）和“交叉”（crosses）。 离散化主要包含提取连续特征和从连续特征中创建离散特征两个部分。比如对于年龄这一连续的特征，你就可以创建这样的离散特征：当年龄小于18时结果为1，或者当年龄介于18-35之间时为1，等等。另外，不要过分考虑直方图中基本分位数的问题。 在TensorFlow的术语中，特征栏是一组相似的特征，比如{男性，女性}，{美国，加拿大，墨西哥}等。这里的交叉是指将两个或多个特征栏合并，例如{男性，女性}×{美国，加拿大，墨西哥}的结果就是一个交叉（a cross），也就构成了一个新的特征栏。假设你利用TensorFlow框架创建了这样一个交叉，其中也就包含了{男性，加拿大}的特征，因此这一特征也就会出现在男性加拿大人的样例中。需要注意的是，交叉方法中合并的特征栏越多，所需要的训练数据量就越大。 如果通过交叉法生成的特征栏特别庞大，那么就可能引起过拟合。例如，假设你正在进行某种搜索，并且在查询请求和文档中都具有一个包含关键字的特征栏。那么假如你选择用交叉法组合这两个特征栏，这样得到的新特征栏就会非常庞大，它内部包含了许多特征。当这种情况发生在文本搜索场景时，有两种可行的应对方法。最常用的是点乘法（dot produc），点乘法最常见的处理方式就是统计查询请求和文档中共同的所有特征词，然后对特征离散化。另一个方法是交集（intersection），比如当且仅当关键词同时出现在文档和查询结果中时，我们才能获取所需的特征。 通过线性模型学到的特征权重的数目，大致与数据量成正比 许多人都认为从一千个样例中并不能得到什么可靠的训练结果，或者由于选择了某种特定的模型，就必须获取一百万个样例，否则就没法展开模型训练。这里需要指出的是，数据量的大小是和需要训练的特征数是正相关的： 1) 假如你在处理一个搜索排名问题，文档和查询请求中包含了数百万个不同的关键词，并且有一千个被标记的样例，那么你应该用上文提到的点乘法处理这些特征。这样就能得到一千个样例，对应了十几个特征。 2) 如你有一百万个样例，那么通过正则化和特征选择的方式就可以交叉处理文档和查询请求中的特征栏，这可能会产生数百万的特征数，但再次使用正则化可以大大减少冗余特征。这样就可能得到一千万个样例，对应了十万个特征。 3) 如果你有数十亿或数百亿个样例，那同样可以通过特征选择或正则化的方法交叉处理文档和查询请求中的特征栏。这样就可能得到十亿个样例，对应了一千万个特征。 对特征数和样例来说，这些统计学上的结论并不能给出一个具体的比例关系，但却可以从数量级上给出一些指导。另外，这里推荐用户依照第28条建议来选择具体使用哪些特征。 清理不需要的特征 如果你发现有些特征并没有在使用，而且将其与其他特征相结合之后也无法使用的话，就应该清理这些特征。应该保持系统的清洁，这样才能尽快尝试那些最有希望出结果的特征。而且，如果有必要，被删除的特征也可以随时找人加回来。 在考虑增删一个特征时，应该仔细排查其覆盖范围。例如你有一些个性化的特征，但只有大约8%的用户使用了该特征，那么删掉或添加这个特征就不会有太大影响。 另一方面，增删特征时也要考虑其对应的数据量。例如你有一个只覆盖了1%数据的特征，但有90%的包含这一特征的样例都通过了训练，那么这就是一个很好的特征，应该添加。 3.2 对系统的人工分析 在进入机器学习实践的第三阶段之前，关注一些课堂上不曾教授的问题也同样至关重要，比如如何检查一个模型并改进它。要说这一点是一门科学，反而不如说它是一种艺术，这里我们介绍几点反面模式（anti-patterns）。 你并不是一个典型的用户 这可能是让一个团队陷入困境的最简单的方法。虽然fishfooding（只在团队内部使用原型）和dogfooding（只在公司内部使用原型）都有许多优点，但无论哪一种，开发者都应该首先确认这种方式是否符合性能要求。另一方面，应该尽量避免不好的变化，但任何看起来合理的产品策略都应该被进一步验证，例如通过非专业人士在众包平台上的问卷调查，或者请目标用户来实测。 走外部验证渠道的原因来自两个方面：一是作为开发者，你太熟悉代码。例如你可能正在分析数据的某一方面而非全局，或者投入了太多的个人感情色彩，从而引发一些偏见。二是几位工程师开一个小时的讨论会议得到的评估结果，可能远比不上直接交给众包平台来得简单和有效。 如果你真的想要获取用户反馈，那么应该采用用户体验法（user experience methodologies）。 在流程早期创建用户角色（详情见Bill Buxton的《Designing User Experiences》一书），然后进行可用性测试（详情见Steve Krug的《Do not Make Me Think》一书）。这里的用户角色涉及创建假想用户。例如，假设你的团队成员都是男性，现在要针对35岁女性用户研发一款产品，那么基于目标群体创建一个假想角色，肯定比几位25-40岁的男性开发者闭门造车的效果要好。当然，让用户实测产品并观察他们的反应也是很不错的方法。 版本之间存在对等差分（symmetric difference） 将产品交付至用户之前，有时候最简单有效的做法就是评估当前版本与交付版本的差异。例如面对排名问题，你可以在两个版本间利用同一组样例进行测试，然后对比其结果。如果差异很小，那么意味着这个版本没问题。如果差异很大，那么就需要确认进行了哪些修改，为什么进行这些修改。通过查看哪些测试样例造成了这一差异，也有助于定性了解修改具体是怎样的。总之，目标是确保不同版本的模型之间的对等差分做到最小。 选择模型时，性能胜过预测能力 你的模型可能会被用来预测点击率，但更关键问题是：这种预测是应用在什么场景的。如果你用它来排列文档，那么最终排名的质量显然比预测本身更重要。如果你用它来排查垃圾邮件，那么识别精度显然更重要。大多数情况下，这两类功能应该是一致的，如果他们存在不一致，则意味着系统可能存在某种小增益。因此，假如一个改进措施可以解决日志丢失的问题，但却造成了系统性能的下降，那就不要采用它。当这种情况频繁发生时，通常应该重新审视你的建模目标。 从误差中查找新模式、创建新特征 假设你的模型在某个样例中预测错误。在分类任务中，这可能是误报或漏报。在排名任务中，这可能是一个正向判断弱于逆向判断的组。但更重要的是，在这个样例中机器学习系统知道它错了，需要修正。如果你此时给模型一个允许它修复的特征，那么模型将尝试自行修复这个错误。 另一方面，如果你尝试基于未出错的样例创建特征，那么该特征将很可能被系统忽略。例如，假设在谷歌Play商店的应用搜索中，有人搜索“免费游戏”，但其中一个排名靠前的搜索结果却是一款其他App，所以你为其他App创建了一个特征。但如果你将其他App的安装数最大化，即人们在搜索免费游戏时安装了其他App，那么这个其他App的特征就不会产生其应有的效果。 所以，正确的做法是一旦出现样例错误，那么应该在当前的特征集之外寻找解决方案。例如，如果你的系统降低了内容较长的帖子的排名，那就应该普遍增加帖子的长度。而且也不要拘泥于太具体的细节。例如你要增加帖子的长度，就不要猜测长度的具体含义，而应该直接添加几个相关的特征，交给模型自行处理，这才是最简单有效的方法。 尝试量化观察到的异常行为 有时候团队成员会对一些没有被现有的损失函数覆盖的系统属性感到无能为力，但这时抱怨是没用的，而是应该尽一切努力将抱怨转换成实实在在的数字。例如，当有些开发者认为在谷歌Play商店的搜索结果中显示了过多的其他App，就可以选择人工识别的方法剔除这些App（这时是可以选择人工标记数据的，因为相对较小的App查询可能占了很大一部分流量）。首先要确认你的问题是可量化的，然后才可以根据这些问题创建新的特征（features）、目标（objectives）或者指标（metrics）。总之规则是：先量化，再优化。 注意短期行为和长期行为的差别 假设你有一个新系统，它可以查看每个doc_id和exact_query，然后根据每个文档的每次查询行为计算其点击率。你发现它的行为几乎与当前系统的并行和A/B测试结果完全相同，而且它很简单，于是你启动了这个系统。但却没有新的应用显示，为什么？由于你的系统只基于自己的历史查询记录显示文档，所以不知道应该显示一个新的文档。 要了解一个系统在长期行为中如何工作的唯一办法，就是让它只基于当前的模型数据展开训练。这一点非常困难。 3.3 训练服务的偏差（Training­-Serving Skew） 这里训练服务偏差是指系统在训练时的性能表现和服务中的性能表现出现差别。造成这种差别的原因可能有如下三个方面： 1) 在训练和服务中的数据处理流水线不同； 2) 在训练和服务中使用了不同的数据； 3) 模型和算法间的反馈回路引起。 我们注意到谷歌的机器学习系统也存在训练服务偏差，而且会对性能产生负面影响。这里需要说明的是：最好的解决办法就是明确地监视它，使系统和数据的改变不至于引发潜在的偏差。 确保训练和服务一样好的最直接办法是：保存服务时使用的特征，然后将这些特征导入日志，以便在训练中使用 即使你不能对每个样例都这样做，做一小部分也比什么也不做好，这样你就可以验证服务和训练之间的一致性（见规则37）。在谷歌采取了这项措施的团队有时候会对其效果感到惊讶。比如YouTube主页在服务时会切换到日志记录特征，这不仅大大提高了服务质量，而且减少了代码复杂度。目前有许多团队都已经在其基础设施上采用了这种策略。 重视采样数据 当数据太多时，有些团队可能会选择丢弃一部分以减轻负担。这是一个明显的错误：历史经验证明在训练过程中丢弃数据将引发一系列问题（详见规则6）。当然，有时候的确可以丢弃数据，比如那些从未向用户显示过的，但重要性加权却是更好的选择。重要性加权意味着，如果你决定以30%的概率对样例X进行抽样，则权重应该是3/10。值得一提的是，使用重要性加权并不影响规则14中讨论的校准属性。 注意表格中的数据可能改变 假设你通过包含文件特征的表格（表格中还可能包含评论或点击的次数）加入文件的ID信息，那么需要注意表格中的特征可能会在训练和服务的不同时间点发生一些变化，造成模型对同一文档的预测也跟着改变。避免此类问题的最简单方法是在服务时记录特征（请参阅规则32）。如果表格的变化足够缓慢的话，你可以每天或每小时都记录一次表格以获得非常接近的数据，但需要注意的是，这并不能完全解决问题。 尽量在训练和服务流水线中复用代码 首先需要明确的一点是：批处理与在线处理不同。在线处理中，你必须在每个请求到达时及时处理（例如必须为每个查询单独查找）；而在批处理中，你可以组合任务（例如建立联结）。类似的，可以将服务视为在线处理过程，而训练视为批处理过程，而其中有许多代码是可以复用的。比如说，你可以创建特定于系统的对象，其中的所有联结和查询结果都以人类可读的方式存储，错误也可以被简单地测试。然后，一旦在服务或训练期间收集了所有信息，你就可以通过一种通用方法在这个特定对象和机器学习系统需要的格式之间形成互通，训练和服务的偏差也得以消除。另外，由此推知：最好不要在训练和服务期间使用不同的编程语言（因为不同的语言间几乎无法复用）。 训练和测试的数据不能相同 一般来说，最好用不同的数据对模型进行训练和测试，例如你用1月5日之前的数据训练了一个模型，那么最好用1月6日之后的数据对模型展开测试。可能模型对新数据的性能表现不如训练数据，但也不会太糟。由于可能会产生每日效应（daily effects），因此你可能无法预测平均点击率或转化率，但曲线下方的面积（表示正面样例的分数高于反面样例的可能性）应该是接近的。 在二进制分类过滤的应用场景中（例如垃圾邮件检测），不要为了纯净的数据做太大的性能牺牲 一般在过滤应用场景中，反面样例并不会对用户展示。不过假如你的过滤器在服务过程中阻止了75%的反面样例，那么你可能需要从向用户显示的实例中提取额外的训练数据并展开训练。比如说，用户将系统认可的邮件标记为垃圾邮件，那么你可能就需要从中学习。 但这种方法同时也引入了采样偏差。如果改为在服务期间将所有流量的1%标记为“暂停”，并将所有这样的样例发送给用户，那你就能收集更纯净的数据。现在你的过滤器阻止了至少74％的反面样例，这些样例可以成为训练数据。 需要注意的是，如果你的过滤器阻止了95%或更多的反面样例，那这种方法可能就不太适用。不过即使如此，如果你想衡量服务的性能，可以选择做出更细致的采样（例如0.1%或0.001%），一万个例子足以准确地估计性能。 注意排序问题的固有偏差 当你彻底改变排序算法时，一方面会引起完全不同的排序结果，另一方面也可能在很大程度上改变算法未来可能要处理的数据。这会引入一些固有偏差，因此你必须事先充分认识到这一点。以下这些方法可以有效帮你优化训练数据。 1) 对涵盖更多查询的特征进行更高的正则化，而不是那些只覆盖单一查询的特征。这样，模型将偏好于那些基于一个或几个特定查询的特征，而不是所有的特征。这种方式可以有效防止那些最常见的查询结果泄漏到不相关的查询中。需要注意的是，这与一条更传统的建议相左：更多地正则化一些具有单一值的特征栏。 2) 只允许特征具有正向权重，这样一来就能保证任何好特征都会比未知特征合适。 3) 不要选择那些只处理文档数据的特征。例如，不管搜索请求是什么，即使一个给定的应用程序是当前的热门下载，你也不会想在所有地方都显示它。没有文档特征的话，这一点会很容易做到。 避免具有位置特征的反馈回路 内容的位置会显著影响用户与它交互的可能性。很明显，如果你把一个App置顶，那它一定会更频繁地被点击。处理这类问题的一个有效方法是加入位置特征，即关于页面中的内容的位置特征。假如你用正向特征来训练模型，那模型就会更偏向“1st-position”这类的特征。因而模型对其他因素的权重就会相应地减小，例如对“1st-position = true”这种样例。在服务的时候，你可以选择不提供任何位置特征的实例，或者为所有位置特征设置相同的初始值，因为在决定以怎样的顺序显示它们之前，你具有决策权。 需要注意的是，因为训练和测试的不对称性，所以最好在一些位置特征和模型之间保持一定的分离性，这一点很重要。让模型成为位置特征函数和其他特征函数的和，是理想的状态。比如说，最好不要交叉任何文档特征和位置特征。 测量训练/服务偏差 许多情况都会引起偏差，但它们大多可以分为如下三类： 1) 训练数据和测试数据的性能之间的差异。一般来说，这总是存在的，但并不会太严重。 2) 测试数据的性能与“第二天数据”（next-day data）之间的差异。同样，这也会一直存在。你可以不同程度地正则化以最大限度地提高第二天的性能（next-day performance）。然而，如果在测试数据和第二天数据之间存在很大的性能下降，这有可能意味着某些特征是时间敏感的，而且整个模型的性能也会跟着下降。 3) “第二天数据”和实时数据的性能之间的差异。如果你将模型应用于训练数据的样例，也应用于相同的服务样例，则它们应该给出完全相同的结果（详见规则5）。因此，这里的差异可能是指工程误差。 4.0 机器学习第三阶4.1 减慢的增速，精细优化和复杂模型 第二阶段将要结束的时候，一定会有些信号。首先，你每月的收益开始降低。你开始要在指标之间做牺牲：一些试验中有的上升有的下降。从此情况变得更有趣。由于更难产生效益，机器学习不得不变得更复杂。 警告：这部分有许多开放式的实践法则。我们亲眼看着很多团队走过第一阶段和第二阶段的幸福期——一旦到达第三阶段，开发团队就不得不找出他们自己的路。 如果目标之间不搭，并成为问题，就不要在新特征上浪费时间 当达到度量瓶颈，你的团队开始关注 ML 系统目标范围之外的问题。如同之前提到的，如果产品目标没有包括在算法目标之内，你就得修改其中一个。比如说，你也许优化的是点击数、点赞或者下载量，但发布决策部分依赖于人类评估者。 模型发布决策是长期产品目标的代理 （雷锋网注：谷歌工程师在这里举了个例子）Alice 有一个关于降低安装预测的逻辑损失的想法。她加入一个特征。逻辑损失下降。当她实时测试时，安装量上升了。但在公司的发布会议上，有人指出每日活跃用户数降低了 5%。团队决定不发布该模型。Alice 很失望，但意识到发布决策取决于多个标准，其中只有一部分能够被 ML 直接优化。 事实是，现实世界并不是网络游戏：没有“攻击值”和“血量”来衡量产品的健康。团队需要利用收集的数据，来试图预测将来系统的表现会怎样。他们需要操心用户黏性、每日活跃用户、每月活跃用户、收入和广告主的收益。这些 A/B 测试中的指标，实际上只是长期目标的代理：让用户满意、增加用户、让合作方满意还有利润；即便这时你还可以考虑高品质、有使用价值的产品的代理，以及五年后一个繁荣的企业的代理。 做出发布决策变得容易的唯一一种情况是：所有指标都变好了（起码没有变差的）。如果团队在复杂 ML 算法和简单启发式算法之间有的选择；如果简单的启发式算法在这些指标上做得更好；那么应当选择后者。另外，所有指标数值并没有明确的排序。更具体的，考虑以下两种情形： 谷歌机器学习白皮书全解析 43条黄金法则（四） 雷锋网注：标题栏（自左至右）为试验，每日活跃用户以及每日收入 如果现有系统是 A ，团队不会想要转移到 B。如果现有系统是 B，团队也不会想要转到 A。这看起来与理性决策相抵触：但是，对指标变化的预期情形或许会发生，或许不会。因此任意一种改变都有相当大的风险。每一个指标覆盖了一些团队所关注的风险。但没有指标能覆盖团队的首要关切——“我的产品在五年后会怎样？” 另一方面，个体倾向于选择能直接优化的目标。大多数 ML 工具喜欢这样的环境。这样的环境下，一个能快速创建新特征的工程师能稳定输出一系列产品发布。有一种叫“多目标学习”（multi­objective learning）的机器学习开始解决这一问题。比如说，可以制定一个在每个指标上有下限的约束满意度问题（constraint satisfaction problem），然后优化指标的一些线性组合。但即便那时，也不是所有指标都能轻易表达为 ML 目标：如果一个文件被点击，或者 APP 被安装，这是因为有内容被展示出来。但搞清楚用户为什么访问你的页面就更加难了。如何预测一个页面在将来是否成功，是一项 AI­-complete 问题（雷锋网注：意味着完成它的难度相当于解决 AI 问题），与计算机视觉和自然语言处理一样难。 保证集成模型（ensemble）的简洁 接收原始特征、直接对内容排序的统一模型，是最容易理解、最容易修补漏洞的模型。但是，一个集成模型（一个把其他模型得分组合在一起的“模型”）的效果会更好。为保持简洁，每个模型应该要么是一个只接收其他模型的输入的集成模型，要么是一个有多种特征的基础模型，但不能两者皆是。如果你有单独训练、基于其它模型的模型，把它们组合到一起会导致不好的行为。 只用简单模型来集成：那些只把基础模型的输入作为输出、进行接收的模型。你或许想要为这些集成模型强加上属性。比如，基础模型生成得分的提高，不应该降低集成模型的分数。另外，如果连入模型在语义上可解释（比如校准了的）会更好，这样其下层模型不会与集成模型混淆。再者，强行让下层分类器预测的概率升高，不会降低集成模型的预测概率。 当性能达到瓶颈，相比精炼现存信号，不如寻找新性质（qualitatively）的信息源 你已经加入了一些关于用户的人口统计信息，还有文件中的词语。你经历了模板探索，和正则化（regularization）调参。但连续几个季度的发布，你都没有看到核心指标有超过 1% 的提升。现在怎么办？ 你已经到了为不同寻常（雷锋网注：很不一样）的特征，创建基础设施的时候了。比如用户昨天、上周、去年检索的文档，或是另一种属性的数据。为你的公司使用维基数据（wikidata）实体或者一些内部的东西（比如谷歌的知识图，Google’s knowledge graph）。你或许需要使用深度学习。开始调整你对投资回报的期望，并作出相应努力。如同所有工程项目，你需要平衡新增加的特征与提高的复杂度。 不要期望多样性、个性化、相关性和受欢迎程度之间有紧密联系 一系列内容的多样性能意味着许多东西，内容来源的多样性最为普遍。个性化意味着每个用户得到属于他们自己的结果。相关性意味着一个特定检索的结果，对应它比对应其他检索更合适。因此，这三个属性的定义都有别于“标准”。 但标准更难被打败。 注意：如果你的系统在统计点击量、耗费时间、浏览数、点赞数、分享数等等，你事实上在衡量内容的受欢迎程度。有团队试图学习具备多样性的个性化模型。为个性化，他们加入允许系统进行个性化的特征（有的特征代表用户兴趣），或者加入多样性（表示该文档与其它返回文档有相同特征的特征，比如作者和内容），然后发现这些特征比他们预想的得到更低的权重（有时是不同的信号）。 这不意味着多样性、个性化和相关性就不重要。如同上个法则所指出的，你可以通过后处理来提高多样性或相关性。如果你看到长期目标的进步，那么你可以宣布在受欢迎程度之外，多样性和相关性是有价值的。你可以继续采用后处理，或者直接根据多样性或相关性修改目标。 不同产品中，你的朋友总是同一个，你的兴趣不会如此 谷歌的 ML 团队 常常把一个预测某产品联系紧密程度（the closeness of a connection in one product）的模型，应用在另一个产品上，然后发现效果很好。另一方面，我见过好几个在产品线的个性化特征上苦苦挣扎的团队。是的，之前看起来它应该能奏效。但现在看来它不会了。有时候起作用的是——用某属性的原始数据来预测另一个属性的行为。即便知道某用户存在另一个属性能凑效的历史，也要记住这一点。比如说，两个产品上用户活动的存在或许就自身说明了问题。 全文结束。感谢您对雷锋网(公众号：雷锋网)的支持。 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"Awesome Machine Learning","date":"2017-02-19T15:56:06.000Z","path":"2017/02/19/Program/TensorFlow/awesome-machine-learning/","text":"作者：Joseph Misiti/josephmisiti A curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by awesome-php. If you want to contribute to this list (please do), send me a pull request or contact me @josephmisitiAlso, a listed repository should be deprecated if: Repository’s owner explicitly say that “this library is not maintained”.Not committed for long time (2~3 years). For a list of free machine learning books available for download, go here. For a list of free-to-attend meetups and local events, go here. Table of Contents APLGeneral-Purpose Machine LearningCGeneral-Purpose Machine LearningComputer VisionC++Computer VisionGeneral-Purpose Machine LearningNatural Language ProcessingSequence AnalysisGesture RecognitionCommon LispGeneral-Purpose Machine LearningClojureNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationElixirGeneral-Purpose Machine LearningNatural Language ProcessingErlangGeneral-Purpose Machine LearningGoNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationHaskellGeneral-Purpose Machine LearningJavaNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationDeep LearningJavascriptNatural Language ProcessingData Analysis / Data VisualizationGeneral-Purpose Machine LearningMiscJuliaGeneral-Purpose Machine LearningNatural Language ProcessingData Analysis / Data VisualizationMisc Stuff / PresentationsLuaGeneral-Purpose Machine LearningDemos and ScriptsMatlabComputer VisionNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data Visualization.NETComputer VisionNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationObjective CGeneral-Purpose Machine LearningOCamlGeneral-Purpose Machine LearningPHPNatural Language ProcessingGeneral-Purpose Machine LearningPythonComputer VisionNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationMisc Scripts / iPython Notebooks / CodebasesKaggle Competition Source CodeNeural networksRubyNatural Language ProcessingGeneral-Purpose Machine LearningData Analysis / Data VisualizationMiscRustGeneral-Purpose Machine LearningRGeneral-Purpose Machine LearningData Analysis / Data VisualizationSASGeneral-Purpose Machine LearningData Analysis / Data VisualizationHigh Performance Machine Learning (MPP)Natural Language ProcessingDemos and ScriptsScalaNatural Language ProcessingData Analysis / Data VisualizationGeneral-Purpose Machine LearningSwiftGeneral-Purpose Machine LearningTensorFlowGeneral-Purpose Machine LearningCredits APL General-Purpose Machine Learning naive-apl - Naive Bayesian Classifier implementation in APL C General-Purpose Machine Learning Darknet - Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation. Recommender - A C library for product recommendations/suggestions using collaborative filtering (CF). Hybrid Recommender System - A hybrid recomender system based upon scikit-learn algorithms. Computer Vision CCV - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library VLFeat - VLFeat is an open and portable library of computer vision algorithms, which has Matlab toolbox Speech Recognition HTK -The Hidden Markov Model Toolkit (HTK) is a portable toolkit for building and manipulating hidden Markov models. C++ Computer Vision DLib - DLib has C++ and Python interfaces for face detection and training general object detectors. EBLearn - Eblearn is an object-oriented C++ library that implements various machine learning models OpenCV - OpenCV has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS. VIGRA - VIGRA is a generic cross-platform C++ computer vision and machine learning library for volumes of arbitrary dimensionality with Python bindings. General-Purpose Machine Learning BanditLib - A simple Multi-armed Bandit library. Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind. [DEEP LEARNING] CNTK - The Computational Network Toolkit (CNTK) by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph. CUDA - This is a fast C++/CUDA implementation of convolutional [DEEP LEARNING] CXXNET - Yet another deep learning framework with less than 1000 lines core code [DEEP LEARNING] DeepDetect - A machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications. Disrtibuted Machine learning Tool Kit (DMTK) - A distributed machine learning (parameter server) framework by Microsoft. Enables training models on large data sets across multiple machines. Current tools bundled with it include: LightLDA and Distributed (Multisense) Word Embedding. DLib - A suite of ML tools designed to be easy to imbed in other applications DSSTNE - A software library created by Amazon for training and deploying deep neural networks using GPUs which emphasizes speed and scale over experimental flexibility. DyNet - A dynamic neural network library working well with networks that have dynamic structures that change for every training instance. Written in C++ with bindings in Python. encog-cpp Fido - A highly-modular C++ machine learning library for embedded electronics and robotics. igraph - General purpose graph library Intel(R) DAAL - A high performance software library developed by Intel and optimized for Intel’s architectures. Library provides algorithmic building blocks for all stages of data analytics and allows to process data in batch, online and distributed modes. LightGBM - Microsoft’s fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks. MLDB - The Machine Learning Database is a database designed for machine learning. Send it commands over a RESTful API to store data, explore it using SQL, then train machine learning models and expose them as APIs. mlpack - A scalable C++ machine learning library Regularized Greedy Forest - Regularized greedy forest (RGF) tree ensemble learning method. ROOT - A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualization and storage. shark - A fast, modular, feature-rich open-source C++ machine learning library. Shogun - The Shogun Machine Learning Toolbox sofia-ml - Suite of fast incremental algorithms. Stan - A probabilistic programming language implementing full Bayesian statistical inference with Hamiltonian Monte Carlo sampling Timbl - A software package/C++ library implementing several memory-based learning algorithms, among which IB1-IG, an implementation of k-nearest neighbor classification, and IGTree, a decision-tree approximation of IB1-IG. Commonly used for NLP. Vowpal Wabbit (VW) - A fast out-of-core learning system. Warp-CTC - A fast parallel implementation of Connectionist Temporal Classification (CTC), on both CPU and GPU. XGBoost - A parallelized optimized general purpose gradient boosting library. Natural Language Processing BLLIP Parser - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser) colibri-core - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way. CRF++ - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data &amp; other Natural Language Processing tasks. CRFsuite - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. frog - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer. libfolia - C++ library for the FoLiA format MeTA - MeTA : ModErn Text Analysis is a C++ Data Sciences Toolkit that facilitates mining big text data. MIT Information Extraction Toolkit - C, C++, and Python tools for named entity recognition and relation extraction ucto - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format. Speech Recognition Kaldi - Kaldi is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers. Sequence Analysis ToPS - This is an objected-oriented framework that facilitates the integration of probabilistic models for sequences over a user defined alphabet. Gesture Detection grt - The Gesture Recognition Toolkit (GRT) is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition. Common Lisp General-Purpose Machine Learning mgl - Neural networks (boltzmann machines, feed-forward and recurrent nets), Gaussian Processes mgl-gpr - Evolutionary algorithms cl-libsvm - Wrapper for the libsvm support vector machine library Clojure Natural Language Processing Clojure-openNLP - Natural Language Processing in Clojure (opennlp) Infections-clj - Rails-like inflection library for Clojure and ClojureScript General-Purpose Machine Learning Touchstone - Clojure A/B testing library Clojush - The Push programming language and the PushGP genetic programming system implemented in Clojure Infer - Inference and machine learning in clojure Clj-ML - A machine learning library for Clojure built on top of Weka and friends Encog - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets) Fungp - A genetic programming library for Clojure Statistiker - Basic Machine Learning algorithms in Clojure. clortex - General Machine Learning library using Numenta’s Cortical Learning Algorithm comportex - Functionally composable Machine Learning library using Numenta’s Cortical Learning Algorithm cortex - Neural networks, regression and feature learning in Clojure. lambda-ml - Simple, concise implementations of machine learning techniques and utilities in Clojure. Data Analysis / Data Visualization Incanter - Incanter is a Clojure-based, R-like platform for statistical computing and graphics. PigPen - Map-Reduce for Clojure. Envision - Clojure Data Visualisation library, based on Statistiker and D3 Elixir General-Purpose Machine Learning Simple Bayes - A Simple Bayes / Naive Bayes implementation in Elixir. Natural Language Processing Stemmer - An English (Porter2) stemming implementation in Elixir. Erlang General-Purpose Machine Learning Disco - Map Reduce in Erlang Go Natural Language Processing go-porterstemmer - A native Go clean room implementation of the Porter Stemming algorithm. paicehusk - Golang implementation of the Paice/Husk Stemming Algorithm. snowball - Snowball Stemmer for Go. go-ngram - In-memory n-gram index with compression. General-Purpose Machine Learning gago - Multi-population, flexible, parallel genetic algorithm. Go Learn - Machine Learning for Go go-pr - Pattern recognition package in Go lang. go-ml - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution bayesian - Naive Bayesian Classification for Golang. go-galib - Genetic Algorithms library written in Go / golang Cloudforest - Ensembles of decision trees in go/golang. gobrain - Neural Networks written in go GoNN - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. go-mxnet-predictor - Go binding for MXNet c_predict_api to do inference with pre-trained model Data Analysis / Data Visualization go-graph - Graph library for Go/golang language. SVGo - The Go Language library for SVG generation RF - Random forests implementation in Go Haskell General-Purpose Machine Learning haskell-ml - Haskell implementations of various ML algorithms. HLearn - a suite of libraries for interpreting machine learning models according to their algebraic structure. hnn - Haskell Neural Network library. hopfield-networks - Hopfield Networks for unsupervised learning in Haskell. caffegraph - A DSL for deep neural networks LambdaNet - Configurable Neural Networks in Haskell Java Natural Language Processing Cortical.io - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc…) as quickly and intuitively as the brain. CoreNLP - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words Stanford Parser - A natural language parser is a program that works out the grammatical structure of sentences Stanford POS Tagger - A Part-Of-Speech Tagger (POS Tagger Stanford Name Entity Recognizer - Stanford NER is a Java implementation of a Named Entity Recognizer. Stanford Word Segmenter - Tokenization of raw text is a standard pre-processing step for many NLP tasks. Tregex, Tsurgeon and Semgrex - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for “tree regular expressions”). Stanford Phrasal: A Phrase-Based Translation System Stanford English Tokenizer - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java. Stanford Tokens Regex - A tokenizer divides text into a sequence of tokens, which roughly correspond to “words” Stanford Temporal Tagger - SUTime is a library for recognizing and normalizing time expressions. Stanford SPIED - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion Stanford Topic Modeling Toolbox - Topic modeling tools to social scientists and others who wish to perform analysis on datasets Twitter Text Java - A Java implementation of Twitter’s text processing library MALLET - A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text. OpenNLP - a machine learning based toolkit for the processing of natural language text. LingPipe - A tool kit for processing text using computational linguistics. ClearTK - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA. Apache cTAKES - Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text. ClearNLP - The ClearNLP project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. This project is under the Apache 2 license. CogcompNLP - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois’ Cognitive Computation Group, for example illinois-core-utilities which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, illinois-edison a library for feature extraction from illinois-core-utilities data structures and many other packages. General-Purpose Machine Learning aerosolve - A machine learning library by Airbnb designed from the ground up to be human friendly. Datumbox - Machine Learning framework for rapid development of Machine Learning and Statistical applications ELKI - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.) Encog - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks. FlinkML in Apache Flink - Distributed machine learning library in Flink H2O - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON. htm.java - General Machine Learning library using Numenta’s Cortical Learning Algorithm java-deeplearning - Distributed Deep Learning Platform for Java, Clojure,Scala Mahout - Distributed machine learning Meka - An open source implementation of methods for multi-label classification and evaluation (extension to Weka). MLlib in Apache Spark - Distributed machine learning library in Spark Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services. Neuroph - Neuroph is lightweight Java neural network framework ORYX - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning. Samoa SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms. RankLib - RankLib is a library of learning to rank algorithms rapaio - statistics, data mining and machine learning toolbox in Java RapidMiner - RapidMiner integration into Java code Stanford Classifier - A classifier is a machine learning tool that will take data items and place them into one of k classes. SmileMiner - Statistical Machine Intelligence &amp; Learning Engine SystemML - flexible, scalable machine learning (ML) language. WalnutiQ - object oriented model of the human brain Weka - Weka is a collection of machine learning algorithms for data mining tasks LBJava - Learning Based Java is a modeling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer’s application. Speech Recognition CMU Sphinx - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library. Data Analysis / Data Visualization Flink - Open source platform for distributed stream and batch data processing. Hadoop - Hadoop/HDFS Spark - Spark is a fast and general engine for large-scale data processing. Storm - Storm is a distributed realtime computation system. Impala - Real-time Query for Hadoop DataMelt - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization. Dr. Michael Thomas Flanagan’s Java Scientific Library Deep Learning Deeplearning4j - Scalable deep learning for industry with parallel GPUs Javascript Natural Language Processing Twitter-text - A JavaScript implementation of Twitter’s text processing library NLP.js - NLP utilities in javascript and coffeescript natural - General natural language facilities for node Knwl.js - A Natural Language Processor in JS Retext - Extensible system for analyzing and manipulating natural language TextProcessing - Sentiment analysis, stemming and lemmatization, part-of-speech tagging and chunking, phrase extraction and named entity recognition. NLP Compromise - Natural Language processing in the browser Data Analysis / Data Visualization D3.js High Charts NVD3.js dc.js chartjs dimple amCharts D3xter - Straight forward plotting built on D3 statkit - Statistics kit for JavaScript datakit - A lightweight framework for data analysis in JavaScript science.js - Scientific and statistical computing in JavaScript. Z3d - Easily make interactive 3d plots built on Three.js Sigma.js - JavaScript library dedicated to graph drawing. C3.js- customizable library based on D3.js for easy chart drawing. Datamaps- Customizable SVG map/geo visualizations using D3.js. ZingChart- library written on Vanilla JS for big data visualization. cheminfo - Platform for data visualization and analysis, using the visualizer project. General-Purpose Machine Learning Convnet.js - ConvNetJS is a Javascript library for training Deep Learning models[DEEP LEARNING] Clusterfck - Agglomerative hierarchical clustering implemented in Javascript for Node.js and the browser Clustering.js - Clustering algorithms implemented in Javascript for Node.js and the browser Decision Trees - NodeJS Implementation of Decision Tree using ID3 Algorithm DN2A - Digital Neural Networks Architecture figue - K-means, fuzzy c-means and agglomerative clustering Node-fann - FANN (Fast Artificial Neural Network Library) bindings for Node.js Kmeans.js - Simple Javascript implementation of the k-means algorithm, for node.js and the browser LDA.js - LDA topic modeling for node.js Learning.js - Javascript implementation of logistic regression/c4.5 decision tree Machine Learning - Machine learning library for Node.js machineJS - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file! mil-tokyo - List of several machine learning libraries Node-SVM - Support Vector Machine for nodejs Brain - Neural networks in JavaScript [Deprecated] Bayesian-Bandit - Bayesian bandit implementation for Node and the browser. Synaptic - Architecture-free neural network library for node.js and the browser kNear - JavaScript implementation of the k nearest neighbors algorithm for supervised learning NeuralN - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training. kalman - Kalman filter for Javascript. shaman - node.js library with support for both simple and multiple linear regression. ml.js - Machine learning and numerical analysis tools for Node.js and the Browser! Pavlov.js - Reinforcement learning using Markov Decision Processes MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. Misc sylvester - Vector and Matrix math for JavaScript. simple-statistics - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in node.js. regression-js - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data. Lyric - Linear Regression library. GreatCircle - Library for calculating great circle distance. Julia General-Purpose Machine Learning MachineLearning - Julia Machine Learning library MLBase - A set of functions to support the development of machine learning algorithms PGM - A Julia framework for probabilistic graphical models. DA - Julia package for Regularized Discriminant Analysis Regression - Algorithms for regression analysis (e.g. linear regression and logistic regression) Local Regression - Local regression, so smooooth! Naive Bayes - Simple Naive Bayes implementation in Julia Mixed Models - A Julia package for fitting (statistical) mixed-effects models Simple MCMC - basic mcmc sampler implemented in Julia Distance - Julia module for Distance evaluation Decision Tree - Decision Tree Classifier and Regressor Neural - A neural network in Julia MCMC - MCMC tools for Julia Mamba - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia GLM - Generalized linear models in Julia Online Learning GLMNet - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet Clustering - Basic functions for clustering data: k-means, dp-means, etc. SVM - SVM’s for Julia Kernal Density - Kernel density estimators for julia Dimensionality Reduction - Methods for dimensionality reduction NMF - A Julia package for non-negative matrix factorization ANN - Julia artificial neural networks Mocha - Deep Learning framework for Julia inspired by Caffe XGBoost - eXtreme Gradient Boosting Package in Julia ManifoldLearning - A Julia package for manifold learning and nonlinear dimensionality reduction MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. Merlin - Flexible Deep Learning Framework in Julia ROCAnalysis - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers GaussianMixtures - Large scale Gaussian Mixture Models ScikitLearn - Julia implementation of the scikit-learn API Knet - Koç University Deep Learning Framework Natural Language Processing Topic Models - TopicModels for Julia Text Analysis - Julia package for text analysis Data Analysis / Data Visualization Graph Layout - Graph layout algorithms in pure Julia Data Frames Meta - Metaprogramming tools for DataFrames Julia Data - library for working with tabular data in Julia Data Read - Read files from Stata, SAS, and SPSS Hypothesis Tests - Hypothesis tests for Julia Gadfly - Crafty statistical graphics for Julia. Stats - Statistical tests for Julia RDataSets - Julia package for loading many of the data sets available in R DataFrames - library for working with tabular data in Julia Distributions - A Julia package for probability distributions and associated functions. Data Arrays - Data structures that allow missing values Time Series - Time series toolkit for Julia Sampling - Basic sampling algorithms for Julia Misc Stuff / Presentations DSP - Digital Signal Processing (filtering, periodograms, spectrograms, window functions). JuliaCon Presentations - Presentations for JuliaCon SignalProcessing - Signal Processing tools for Julia Images - An image library for Julia Lua General-Purpose Machine Learning Torch7 cephes - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy.autograd - Autograd automatically differentiates native Torch code. Inspired by the original Python version.graph - Graph package for Torchrandomkit - Numpy’s randomkit, wrapped for Torchsignal - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stftnn - Neural Network package for Torchtorchnet - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programmingnngraph - This package provides graphical computation for nn library in Torch7.nnx - A completely unstable and experimental package that extends Torch’s builtin nn libraryrnn - A Recurrent Neural Network library that extends Torch’s nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.dpnn - Many useful features that aren’t part of the main nn package.dp - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns.optim - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.unsup - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, …), and self-contained algorithms (k-means, PCA).manifold - A package to manipulate manifoldssvm - Torch-SVM librarylbfgs - FFI Wrapper for liblbfgsvowpalwabbit - An old vowpalwabbit interface to torch.OpenGM - OpenGM is a C++ library for graphical modeling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM.sphagetti - Spaghetti (sparse linear) module for torch7 by @MichaelMathieuLuaSHKit - A lua wrapper around the Locality sensitive hashing library SHKitkernel smoothing - KNN, kernel-weighted average, local linear regression smootherscutorch - Torch CUDA Implementationcunn - Torch CUDA Neural Network Implementationimgraph - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images.videograph - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos.saliency - code and tools around integral images. A library for finding interest points based on fast integral histograms.stitch - allows us to use hugin to stitch images and apply same stitching to a video sequencesfm - A bundle adjustment/structure from motion packagefex - A package for feature extraction in Torch. Provides SIFT and dSIFT modules.OverFeat - A state-of-the-art generic dense feature extractorNumeric LuaLunatic PythonSciLuaLua - Numerical AlgorithmsLunum Demos and Scripts Core torch7 demos repository. linear-regression, logistic-regressionface detector (training and detection as separate demos)mst-based-segmentertrain-a-digit-classifiertrain-autoencoderoptical flow demotrain-on-housenumberstrain-on-cifartracking with deep netskinect demofilter-bank visualizationsaliency-networksTraining a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)Music Tagging - Music Tagging scripts for torch7torch-datasets - Scripts to load several popular datasets including:BSR 500CIFAR-10COILStreet View House NumbersMNISTNORBAtari2600 - Scripts to generate a dataset with static frames from the Arcade Learning Environment Matlab Computer Vision Contourlets - MATLAB source code that implements the contourlet transform and its utility functions. Shearlets - MATLAB code for shearlet transform Curvelets - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles. Bandlets - MATLAB code for bandlet transform mexopencv - Collection and a development kit of MATLAB mex functions for OpenCV library Natural Language Processing NLP - An NLP library for Matlab General-Purpose Machine Learning Training a deep autoencoder or a classifieron MNIST digits - Training a deep autoencoder or a classifieron MNIST digits[DEEP LEARNING] Convolutional-Recursive Deep Learning for 3D Object Classification - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING] t-Distributed Stochastic Neighbor Embedding - t-Distributed Stochastic Neighbor Embedding (t-SNE) is a (prize-winning) technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. Spider - The spider is intended to be a complete object orientated environment for machine learning in Matlab. LibSVM - A Library for Support Vector Machines LibLinear - A Library for Large Linear Classification Machine Learning Module - Class on machine w/ PDF,lectures,code Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind. Pattern Recognition Toolbox - A complete object-oriented environment for machine learning in Matlab. Pattern Recognition and Machine Learning - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop. Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB. Data Analysis / Data Visualization matlab_gbl - MatlabBGL is a Matlab package for working with graphs. gamic - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL’s mex functions. .NET Computer Vision OpenCVDotNet - A wrapper for the OpenCV project to be used with .NET applications. Emgu CV - Cross platform wrapper of OpenCV which can be compiled in Mono to e run on Windows, Linus, Mac OS X, iOS, and Android. AForge.NET - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub. Accord.NET - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android. Natural Language Processing Stanford.NLP for .NET - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package. General-Purpose Machine Learning Accord-Framework -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications. Accord.MachineLearning - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework. DiffSharp - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization. Vulpes - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase. Encog - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks. Neural Network Designer - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feed back. The chat bots can even scrape the internet for information to return in their output as well as to use for learning. Data Analysis / Data Visualization numl - numl is a machine learning library intended to ease the use of using standard modeling techniques for both prediction and clustering. Math.NET Numerics - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and every day use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin. Sho - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development. Objective C General-Purpose Machine Learning YCML - A Machine Learning framework for Objective-C and Swift (OS X / iOS). MLPNeuralNet - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural network. It is built on top of the Apple’s Accelerate Framework, using vectorized operations and hardware acceleration if available. MAChineLearning - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it’s 20 times faster than its Java equivalent. Includes sample code for use from Swift. BPN-NeuralNetwork - It implemented 3 layers neural network ( Input Layer, Hidden Layer and Output Layer ) and it named Back Propagation Neural Network (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis. Multi-Perceptron-NeuralNetwork - it implemented multi-perceptrons neural network (ニューラルネットワーク) based on Back Propagation Neural Network (BPN) and designed unlimited-hidden-layers. KRHebbian-Algorithm - It is a non-supervisor and self-learning algorithm (adjust the weights) in neural network of Machine Learning. KRKmeans-Algorithm - It implemented K-Means the clustering and classification algorithm. It could be used in data mining and image compression. KRFuzzyCMeans-Algorithm - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression. OCaml General-Purpose Machine Learning Oml - A general statistics and machine learning library. GPR - Efficient Gaussian Process Regression in OCaml. Libra-Tk - Algorithms for learning and inference with discrete probabilistic models. PHP Natural Language Processing jieba-php - Chinese Words Segmentation Utilities. General-Purpose Machine Learning PHP-ML - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library. PredictionBuilder - A library for machine learning that builds predictions using a linear regression. Python Computer Vision Scikit-Image - A collection of algorithms for image processing in Python. SimpleCV - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux. Vigranumpy - Python bindings for the VIGRA C++ computer vision library. OpenFace - Free and open source face recognition with deep neural networks. PCV - Open source Python module for computer vision Natural Language Processing NLTK - A leading platform for building Python programs to work with human language data. Pattern - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others. Quepy - A python framework to transform natural language questions to queries in a database query language TextBlob - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both. YAlign - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora. jieba - Chinese Words Segmentation Utilities. SnowNLP - A library for processing Chinese text. spammy - A library for email Spam filtering built on top of nltk loso - Another Chinese segmentation library. genius - A Chinese segment base on Conditional Random Field. KoNLPy - A Python package for Korean natural language processing. nut - Natural language Understanding Toolkit Rosetta - Text processing tools and wrappers (e.g. Vowpal Wabbit) BLLIP Parser - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser) PyNLPl - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for FoLiA, but also ARPA language models, Moses phrasetables, GIZA++ alignments. python-ucto - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages) python-frog - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER) python-zpar - Python bindings for ZPar, a statistical part-of-speech-tagger, constiuency parser, and dependency parser for English. colibri-core - Python binding to C++ library for extracting and working with with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way. spaCy - Industrial strength NLP with Python and Cython. PyStanfordDependencies - Python interface for converting Penn Treebank trees to Stanford Dependencies. Distance - Levenshtein and Hamming distance computation Fuzzy Wuzzy - Fuzzy String Matching in Python jellyfish - a python library for doing approximate and phonetic matching of strings. editdistance - fast implementation of edit distance textacy - higher-level NLP built on Spacy stanford-corenlp-python - Python wrapper for Stanford CoreNLP General-Purpose Machine Learning auto_ml - Automated machine learning pipelines for analytics and production. Handles some standard feature engineering, feature selection, model selection, model tuning, ensembling, and advanced scoring, in addition to logging output for analysts trying to understand their datasets. machine learning - automated build consisting of a web-interface, and set of programmatic-interface API, for support vector machines. Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore. XGBoost - Python bindings for eXtreme Gradient Boosting (Tree) Library Bayesian Methods for Hackers - Book/iPython notebooks on Probabilistic Programming in Python Featureforge A set of tools for creating and testing machine learning features, with a scikit-learn compatible API MLlib in Apache Spark - Distributed machine learning library in Spark Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services. scikit-learn - A Python module for machine learning built on top of SciPy. metric-learn - A Python module for metric learning. SimpleAI Python implementation of many of the artificial intelligence algorithms described on the book “Artificial Intelligence, a Modern Approach”. It focuses on providing an easy to use, well documented and tested library. astroML - Machine Learning and Data Mining for Astronomy. graphlab-create - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame. BigML - A library that contacts external servers. pattern - Web mining module for Python. NuPIC - Numenta Platform for Intelligent Computing. Pylearn2 - A Machine Learning library based on Theano. keras - Modular neural network library based on Theano. Lasagne - Lightweight library to build and train neural networks in Theano. hebel - GPU-Accelerated Deep Learning Library in Python. Chainer - Flexible neural network framework gensim - Topic Modelling for Humans. topik - Topic modelling toolkit PyBrain - Another Python Machine Learning Library. Brainstorm - Fast, flexible and fun neural networks. This is the successor of PyBrain. Crab - A ﬂexible, fast recommender engine. python-recsys - A Python library for implementing a Recommender System. thinking bayes - Book on Bayesian Analysis Restricted Boltzmann Machines -Restricted Boltzmann Machines in Python. [DEEP LEARNING] Bolt - Bolt Online Learning Toolbox CoverTree - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree nilearn - Machine learning for NeuroImaging in Python imbalanced-learn - Python module to perform under sampling and over sampling with various techniques. Shogun - The Shogun Machine Learning Toolbox Pyevolve - Genetic algorithm framework. Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind. breze - Theano based library for deep and recurrent neural networks pyhsmm - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations. mrjob - A library to let Python program run on Hadoop. SKLL - A wrapper around scikit-learn that makes it simpler to conduct experiments. neurolab - https://github.com/zueve/neurolab Spearmint - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012. Pebl - Python Environment for Bayesian Learning Theano - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python TensorFlow - Open source software library for numerical computation using data flow graphs yahmm - Hidden Markov Models for Python, implemented in Cython for speed and efficiency. python-timbl - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit. deap - Evolutionary algorithm framework. pydeep - Deep Learning In Python mlxtend - A library consisting of useful tools for data science and machine learning tasks. neon - Nervana’s high-performance Python-based Deep Learning framework [DEEP LEARNING] Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Neural Networks and Deep Learning - Code samples for my book “Neural Networks and Deep Learning” [DEEP LEARNING] Annoy - Approximate nearest neighbours implementation skflow - Simplified interface for TensorFlow, mimicking Scikit Learn. TPOT - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning. pgmpy A python library for working with Probabilistic Graphical Models. DIGITS - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models. Orange - Open source data visualization and data analysis for novices and experts. MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. milk - Machine learning toolkit focused on supervised classification. TFLearn - Deep learning library featuring a higher-level API for TensorFlow. REP - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience. rgf_python - Python bindings for Regularized Greedy Forest (Tree) Library. gym - OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms. skbayes - Python package for Bayesian Machine Learning with scikit-learn API Data Analysis / Data Visualization SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering. NumPy - A fundamental package for scientific computing with Python. Numba - Python JIT (just in time) complier to LLVM aimed at scientific Python by the developers of Cython and NumPy. NetworkX - A high-productivity software for complex networks. igraph - binding to igraph library - General purpose graph library Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools. Open Mining - Business Intelligence (BI) in Python (Pandas web interface) PyMC - Markov Chain Monte Carlo sampling toolkit. zipline - A Pythonic algorithmic trading library. PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib. SymPy - A Python library for symbolic mathematics. statsmodels - Statistical modeling and econometrics in Python. astropy - A community Python library for Astronomy. matplotlib - A Python 2D plotting library. bokeh - Interactive Web Plotting for Python. plotly - Collaborative web plotting for Python and matplotlib. vincent - A Python to Vega translator. d3py - A plotting library for Python, based on D3.js. PyDexter - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser. ggplot - Same API as ggplot2 for R. ggfortify - Unified interface to ggplot2 popular R packages. Kartograph.py - Rendering beautiful SVG maps in Python. pygal - A Python SVG Charts Creator. PyQtGraph - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy. pycascading Petrel - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python. Blaze - NumPy and Pandas interface to Big Data. emcee - The Python ensemble sampling toolkit for affine-invariant MCMC. windML - A Python Framework for Wind Energy Analysis and Prediction vispy - GPU-based high-performance interactive OpenGL 2D/3D data visualization library cerebro2 A web-based visualization and debugging platform for NuPIC. NuPIC Studio An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool! SparklingPandas Pandas on PySpark (POPS) Seaborn - A python visualization library based on matplotlib bqplot - An API for plotting in Jupyter (IPython) pastalog - Simple, realtime visualization of neural network training performance. caravel - A data exploration platform designed to be visual, intuitive, and interactive. Dora - Tools for exploratory data analysis in Python. Ruffus - Computation Pipeline library for python. SOMPY - Self Organizing Map written in Python (Uses neural networks for data analysis). somoclu Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API. HDBScan - implementation of the hdbscan algorithm in Python - used for clustering visualize_ML - A python package for data exploration and data analysis. Misc Scripts / iPython Notebooks / Codebases BioPy - Biologically-Inspired and Machine Learning Algorithms in Python. pattern_classification thinking stats 2 hyperopt numpic 2012-paper-diginorm A gallery of interesting IPython notebooks ipython-notebooks data-science-ipython-notebooks - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines. decision-weights Sarah Palin LDA - Topic Modeling the Sarah Palin emails. Diffusion Segmentation - A collection of image segmentation algorithms based on diffusion methods Scipy Tutorials - SciPy tutorials. This is outdated, check out scipy-lecture-notes Crab - A recommendation engine library for Python BayesPy - Bayesian Inference Tools in Python scikit-learn tutorials - Series of notebooks for learning scikit-learn sentiment-analyzer - Tweets Sentiment Analyzer sentiment_classifier - Sentiment classifier using word sense disambiguation. group-lasso - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model jProcessing - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary &amp; parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO–8859-1 configured) in Python. mne-python-notebooks - IPython notebooks for EEG/MEG data processing using mne-python Neon Course - IPython notebooks for a complete course around understanding Nervana’s Neon pandas cookbook - Recipes for using Python’s pandas library climin - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others Allen Downey’s Data Science Course - Code for Data Science at Olin College, Spring 2014. Allen Downey’s Think Bayes Code - Code repository for Think Bayes. Allen Downey’s Think Complexity Code - Code for Allen Downey’s book Think Complexity. Allen Downey’s Think OS Code - Text and supporting code for Think OS: A Brief Introduction to Operating Systems. Python Programming for the Humanities - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP. GreatCircle - Library for calculating great circle distance. Optunity examples - Examples demonstrating how to use Optunity in synergy with machine learning libraries. Dive into Machine Learning with Python Jupyter notebook and scikit-learn - “I learned Python by hacking first, and getting serious later. I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.” TDB - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow. Suiron - Machine Learning for RC Cars. Introduction to machine learning with scikit-learn - IPython notebooks from Data School’s video tutorials on scikit-learn. Practical XGBoost in Python - comprehensive online course about using XGBoost in Python Neural networks Neural networks - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences. Neuron - Neuron is simple class for time series predictions. It’s utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg–Marquardt algorithm. Data Driven Code - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments. Kaggle Competition Source Code wiki challenge - An implementation of Dell Zhang’s solution to Wikipedia’s Participation Challenge on Kaggle kaggle insults - Kaggle Submission for “Detecting Insults in Social Commentary” kaggle_acquire-valued-shoppers-challenge - Code for the Kaggle acquire valued shoppers challenge kaggle-cifar - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet kaggle-blackbox - Deep learning made easy kaggle-accelerometer - Code for Accelerometer Biometric Competition at Kaggle kaggle-advertised-salaries - Predicting job salaries from ads - a Kaggle competition kaggle amazon - Amazon access control challenge kaggle-bestbuy_big - Code for the Best Buy competition at Kaggle kaggle-bestbuy_small Kaggle Dogs vs. Cats - Code for Kaggle Dogs vs. Cats competition Kaggle Galaxy Challenge - Winning solution for the Galaxy Challenge on Kaggle Kaggle Gender - A Kaggle competition: discriminate gender based on handwriting Kaggle Merck - Merck challenge at Kaggle Kaggle Stackoverflow - Predicting closed questions on Stack Overflow kaggle_acquire-valued-shoppers-challenge - Code for the Kaggle acquire valued shoppers challenge wine-quality - Predicting wine quality Ruby Natural Language Processing Treat - Text REtrieval and Annotation Toolkit, definitely the most comprehensive toolkit I’ve encountered so far for Ruby Ruby Linguistics - Linguistics is a framework for building linguistic utilities for Ruby objects in any language. It includes a generic language-independent front end, a module for mapping language codes into language names, and a module which contains various English-language utilities. Stemmer - Expose libstemmer_c to Ruby Ruby Wordnet - This library is a Ruby interface to WordNet Raspel - raspell is an interface binding for ruby UEA Stemmer - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing Twitter-text-rb - A library that does auto linking and extraction of usernames, lists and hashtags in tweets General-Purpose Machine Learning Ruby Machine Learning - Some Machine Learning algorithms, implemented in Ruby Machine Learning Ruby jRuby Mahout - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby. CardMagic-Classifier - A general classifier module to allow Bayesian and other types of classifications. rb-libsvm - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines Data Analysis / Data Visualization rsruby - Ruby - R bridge data-visualization-ruby - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby ruby-plot - gnuplot wrapper for ruby, especially for plotting roc curves into svg files plot-rb - A plotting library in Ruby built on top of Vega and D3. scruffy - A beautiful graphing toolkit for Ruby SciRuby Glean - A data management tool for humans Bioruby Arel Misc Big Data For Chimps Listof - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, json or hash. Demo/Search for a list Rust General-Purpose Machine Learning deeplearn-rs - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license. rustlearn - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests. rusty-machine - a pure-rust machine learning library. leaf - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe. Available under the MIT license. [Deprecated] RustNN - RustNN is a feedforward neural network library. R General-Purpose Machine Learning ahaz - ahaz: Regularization for semiparametric additive hazards regression arules - arules: Mining Association Rules and Frequent Itemsets biglasso - biglasso: Extending Lasso Model Fitting to Big Data in R bigrf - bigrf: Big Random Forests: Classification and Regression Forests for Large Data Sets bigRR - bigRR: Generalized Ridge Regression (with special advantage for p &gt;&gt; n cases) bmrm - bmrm: Bundle Methods for Regularized Risk Minimization Package Boruta - Boruta: A wrapper algorithm for all-relevant feature selection bst - bst: Gradient Boosting C50 - C50: C5.0 Decision Trees and Rule-Based Models caret - Classification and Regression Training: Unified interface to ~150 ML algorithms in R. caretEnsemble - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models. Clever Algorithms For Machine Learning CORElearn - CORElearn: Classification, regression, feature evaluation and ordinal evaluation CoxBoost - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks Cubist - Cubist: Rule- and Instance-Based Regression Modeling e1071 - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien earth - earth: Multivariate Adaptive Regression Spline Models elasticnet - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA ElemStatLearn - ElemStatLearn: Data sets, functions and examples from the book: “The Elements of Statistical Learning, Data Mining, Inference, and Prediction” by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction” by Trevor Hastie, Robert Tibshirani and Jerome Friedman evtree - evtree: Evolutionary Learning of Globally Optimal Trees forecast - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models forecastHybrid - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the “forecast” package fpc - fpc: Flexible procedures for clustering frbs - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks GAMBoost - GAMBoost: Generalized linear and additive models by likelihood based boosting gamboostLSS - gamboostLSS: Boosting Methods for GAMLSS gbm - gbm: Generalized Boosted Regression Models glmnet - glmnet: Lasso and elastic-net regularized generalized linear models glmpath - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model GMMBoost - GMMBoost: Likelihood-based Boosting for Generalized mixed models grplasso - grplasso: Fitting user specified models with Group Lasso penalty grpreg - grpreg: Regularization paths for regression models with grouped covariates h2o - A framework for fast, parallel, and distributed machine learning algorithms at scale – Deeplearning, Random forests, GBM, KMeans, PCA, GLM hda - hda: Heteroscedastic Discriminant Analysis Introduction to Statistical Learning ipred - ipred: Improved Predictors kernlab - kernlab: Kernel-based Machine Learning Lab klaR - klaR: Classification and visualization lars - lars: Least Angle Regression, Lasso and Forward Stagewise lasso2 - lasso2: L1 constrained estimation aka ‘lasso’ LiblineaR - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library LogicReg - LogicReg: Logic Regression Machine Learning For Hackers maptree - maptree: Mapping, pruning, and graphing tree models mboost - mboost: Model-Based Boosting medley - medley: Blending regression models, using a greedy stepwise approach mlr - mlr: Machine Learning in R mvpart - mvpart: Multivariate partitioning ncvreg - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models nnet - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models oblique.tree - oblique.tree: Oblique Trees for Classification Data pamr - pamr: Pam: prediction analysis for microarrays party - party: A Laboratory for Recursive Partytioning partykit - partykit: A Toolkit for Recursive Partytioning penalized - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model penalizedLDA - penalizedLDA: Penalized classification using Fisher’s linear discriminant penalizedSVM - penalizedSVM: Feature Selection SVM using penalty functions quantregForest - quantregForest: Quantile Regression Forests randomForest - randomForest: Breiman and Cutler’s random forests for classification and regression randomForestSRC - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC) rattle - rattle: Graphical user interface for data mining in R rda - rda: Shrunken Centroids Regularized Discriminant Analysis rdetools - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces REEMtree - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data relaxo - relaxo: Relaxed Lasso rgenoud - rgenoud: R version of GENetic Optimization Using Derivatives rgp - rgp: R genetic programming framework Rmalschains - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R rminer - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression ROCR - ROCR: Visualizing the performance of scoring classifiers RoughSets - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories rpart - rpart: Recursive Partitioning and Regression Trees RPMM - RPMM: Recursively Partitioned Mixture Model RSNNS - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS) RWeka - RWeka: R/Weka interface RXshrink - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression sda - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection SDDA - SDDA: Stepwise Diagonal Discriminant Analysis SuperLearner and subsemble - Multi-algorithm ensemble learning packages. svmpath - svmpath: svmpath: the SVM Path algorithm tgp - tgp: Bayesian treed Gaussian process models tree - tree: Classification and regression trees varSelRF - varSelRF: Variable selection using random forests XGBoost.R - R binding for eXtreme Gradient Boosting (Tree) Library Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R. igraph - binding to igraph library - General purpose graph library MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more. TDSP-Utilities - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modeling and Reporting (AMR). Data Analysis / Data Visualization ggplot2 - A data visualization package based on the grammar of graphics. SAS General-Purpose Machine Learning Enterprise Miner - Data mining and machine learning that creates deployable models using a GUI or code. Factory Miner - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI. Data Analysis / Data Visualization SAS/STAT - For conducting advanced statistical analysis. University Edition - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses. High Performance Machine Learning High Performance Data Mining - Data mining and machine learning that creates deployable models using a GUI or code in an MPP environment, including Hadoop. High Performance Text Mining - Text mining using a GUI or code in an MPP environment, including Hadoop. Natural Language Processing Contextual Analysis - Add structure to unstructured text using a GUI. Sentiment Analysis - Extract sentiment from text using a GUI. Text Miner - Text mining using a GUI or code. Demos and Scripts ML_Tables - Concise cheat sheets containing machine learning best practices. enlighten-apply - Example code and materials that illustrate applications of SAS machine learning techniques. enlighten-integration - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R. enlighten-deep - Example code and materials that illustrate using neural networks with several hidden layers in SAS. dm-flow - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics. Scala Natural Language Processing ScalaNLP - ScalaNLP is a suite of machine learning and numerical computing libraries. Breeze - Breeze is a numerical processing library for Scala. Chalk - Chalk is a natural language processing library. FACTORIE - FACTORIE is a toolkit for deployable probabilistic modeling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference. Data Analysis / Data Visualization MLlib in Apache Spark - Distributed machine learning library in Spark Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services. Scalding - A Scala API for Cascading Summing Bird - Streaming MapReduce with Scalding and Storm Algebird - Abstract Algebra for Scala xerial - Data management utilities for Scala simmer - Reduce your data. A unix filter for algebird-powered aggregation. PredictionIO - PredictionIO, a machine learning server for software developers and data engineers. BIDMat - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis. Wolfe Declarative Machine Learning Flink - Open source platform for distributed stream and batch data processing. Spark Notebook - Interactive and Reactive Data Science using Scala and Spark. General-Purpose Machine Learning Conjecture - Scalable Machine Learning in Scalding brushfire - Distributed decision tree ensemble learning in Scala ganitha - scalding powered machine learning adam - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed. bioscala - Bioinformatics for the Scala programming language BIDMach - CPU and GPU-accelerated Machine Learning Library. Figaro - a Scala library for constructing probabilistic models. H2O Sparkling Water - H2O and Spark interoperability. FlinkML in Apache Flink - Distributed machine learning library in Flink DynaML - Scala Library/REPL for Machine Learning Research Saul - Flexible Declarative Learning-Based Programming. SwiftLearner - Simply written algorithms to help study ML or write your own implementations. Swift General-Purpose Machine Learning Swift AI - Highly optimized artificial intelligence and machine learning library written in Swift. BrainCore - The iOS and OS X neural network framework swix - A bare bones library thatincludes a general matrix language and wraps some OpenCV for iOS development. DeepLearningKit an Open Source Deep Learning Framework for Apple’s iOS, OS X and tvOS.It currently allows using deep convolutional neural network models trained in Caffe on Apple operating systems. AIToolbox - A toolbox framework of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians. MLKit - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression. Swift Brain - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc.. TensorFlow General-Purpose Machine Learning Awesome TensorFlow - A list of all things related to TensorFlow Credits Some of the python libraries were cut-and-pasted from vinta The few go reference I found where pulled from this page","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"Awesome Deep Learning","date":"2017-02-19T15:56:00.000Z","path":"2017/02/19/Program/TensorFlow/awesome-deep-learning/","text":"作者：Joseph Misiti/josephmisiti A curated list of awesome Deep Learning tutorials, projects and communities. Free Online Books Deep Learning by Yoshua Bengio, Ian Goodfellow and Aaron Courville (01/01/2015) Neural Networks and Deep Learning by Michael Nielsen (Dec 2014) Deep Learning by Microsoft Research (2013) Deep Learning Tutorial by LISA lab, University of Montreal (Jan 6 2015)Courses Machine Learning - Stanford by Andrew Ng in Coursera (2010-2014) Machine Learning - Caltech by Yaser Abu-Mostafa (2012-2014) Machine Learning - Carnegie Mellon by Tom Mitchell (Spring 2011) Neural Networks for Machine Learning by Geoffrey Hinton in Coursera (2012) Neural networks class by Hugo Larochelle from Université de Sherbrooke (2013) Deep Learning Course by CILVR lab @ NYU (2014) A.I - Berkeley by Dan Klein and Pieter Abbeel (2013) A.I - MIT by Patrick Henry Winston (2010) Vision and learning - computers and brains by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)Video and Lectures How To Create A Mind By Ray Kurzweil Deep Learning, Self-Taught Learning and Unsupervised Feature Learning By Andrew Ng Recent Developments in Deep Learning By Geoff Hinton The Unreasonable Effectiveness of Deep Learning by Yann LeCun Deep Learning of Representations by Yoshua bengio Principles of Hierarchical Temporal Memory by Jeff Hawkins Machine Learning Discussion Group - Deep Learning w/ Stanford AI Lab by Adam Coates Making Sense of the World with Deep Learning By Adam Coates Demystifying Unsupervised Feature Learning By Adam Coates Visual Perception with Deep Learning By Yann LeCun The Next Generation of Neural Networks By Geoffrey Hinton at GoogleTechTalks The wonderful and terrifying implications of computers that can learn By Jeremy Howard at TEDxBrusselsPapers ImageNet Classification with Deep Convolutional Neural Networks Using Very Deep Autoencoders for Content Based Image Retrieval Learning Deep Architectures for AI CMU’s list of papersTutorials UFLDL Tutorial 1 UFLDL Tutorial 2 Deep Learning for NLP (without Magic) A Deep Learning Tutorial: From Perceptrons to Deep Networks Deep Learning from the Bottom upWebSites deeplearning.net deeplearning.stanford.eduDatasets MNIST Handwritten digits Google House Numbers from street view CIFAR-10 and CIFAR-1004. IMAGENET Tiny Images 80 Million tiny images6. Flickr Data 100 Million Yahoo dataset Berkeley Segmentation Dataset 500Frameworks Caffe Torch7 Theano cuda-convnet Ccv NuPIC DeepLearning4J BrainMiscellaneous Google Plus - Deep Learning Community Caffe Webinar 100 Best Github Resources in Github for DL Word2Vec Caffe DockerFile TorontoDeepLEarning convnet Vision data sets Fantastic Torch Tutorial gfx.jsTorch7 Cheat sheetMisc from MIT’s ‘Advanced Natural Language Processing’ courseMisc from MIT’s ‘Machine Learning’ courseMisc from MIT’s ‘Networks for Learning: Regression and Classification’ courseMisc from MIT’s ‘Neural Coding and Perception of Sound’ courseImplementing a Distributed Deep Learning Network over SparkContributingHave anything in mind that you think is awesome and would fit in this list? Feel free to send a pull request.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"25个Java机器学习工具&库","date":"2017-02-19T15:50:06.000Z","path":"2017/02/19/Program/TensorFlow/25-open-source-projects-of-machine-learning-java/","text":"转自：CSDN 本列表总结了25个Java机器学习工具&amp;库 本列表总结了25个Java机器学习工具&amp;库：1.&nbsp;Weka集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。2.Massive&nbsp;Online&nbsp;Analysis（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。3.MEKA项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。4.&nbsp;Advanced&nbsp;Data&nbsp;mining&nbsp;And&nbsp;Machine&nbsp;learning&nbsp;System（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。5.&nbsp;Environment&nbsp;for&nbsp;Developing&nbsp;KDD-Applications&nbsp;Supported&nbsp;by&nbsp;Index-Structure（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。6.&nbsp;Mallet是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。7.&nbsp;Encog是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。8.&nbsp;Datumbox机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。9.&nbsp;Deeplearning4j是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。10.&nbsp;Mahout是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。11.Rapid&nbsp;Miner是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java&nbsp;API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。12.&nbsp;Apache&nbsp;SAMOA是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache&nbsp;Storm、Apache&nbsp;S4和Apache&nbsp;samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。13.&nbsp;Neuroph通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。14.&nbsp;Oryx&nbsp;2是一个建立在Apache&nbsp;Spark和Apache&nbsp;Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。15.&nbsp;Stanford&nbsp;Classifier是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。16.io是一个Retina&nbsp;API，有着快速精确的类&#20284;大脑的自然语言处理算法。17.JSAT是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。18.&nbsp;N-Dimensional&nbsp;Arrays&nbsp;for&nbsp;Java(ND4J)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。19.&nbsp;Java&nbsp;Machine&nbsp;Learning&nbsp;Library（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。20.&nbsp;Java-ML是一个使用Java编写的一系列机器学习算法的Java&nbsp;API。它只提供了一个标准的算法接口。21.&nbsp;MLlib&nbsp;(Spark)是Apache&nbsp;Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。22.&nbsp;H2O是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。23.&nbsp;WalnutiQ是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。24.&nbsp;RankLib是一个排名学习算法库。目前已经实现八种流行的算法。25.&nbsp;htm.java（基于Java的Hierarchical&nbsp;Temporal&nbsp;Memory算法实现）是一个面向智能计算的Numenta平台的Java接口","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"},{"name":"Java","slug":"Java","permalink":"http://ipcreator.me/tags/Java/"}]},{"title":"Python教程","date":"2017-02-19T06:14:06.000Z","path":"2017/02/19/Program/Concepts/learn-journey-of-python/","text":"作者：廖雪峰 这是小白的Python新手教程，具有如下特点： 中文，免费，零起点，完整示例，基于最新的Python 3版本。 Python是一种计算机程序设计语言。你可能已经听说过很多种流行的编程语言，比如非常难学的C语言，非常流行的Java语言，适合初学者的Basic语言，适合网页编程的JavaScript语言等等。 那Python是一种什么语言？ 首先，我们普及一下编程语言的基础知识。用任何编程语言来开发程序，都是为了让计算机干活，比如下载一个MP3，编写一个文档等等，而计算机干活的CPU只认识机器指令，所以，尽管不同的编程语言差异极大，最后都得“翻译”成CPU可以执行的机器指令。而不同的编程语言，干同一个活，编写的代码量，差距也很大。 比如，完成同一个任务，C语言要写1000行代码，Java只需要写100行，而Python可能只要20行。 所以Python是一种相当高级的语言。 你也许会问，代码少还不好？代码少的代价是运行速度慢，C程序运行1秒钟，Java程序可能需要2秒，而Python程序可能就需要10秒。 那是不是越低级的程序越难学，越高级的程序越简单？表面上来说，是的，但是，在非常高的抽象计算中，高级的Python程序设计也是非常难学的，所以，高级程序语言不等于简单。 但是，对于初学者和完成普通任务，Python语言是非常简单易用的。连Google都在大规模使用Python，你就不用担心学了会没用。 用Python可以做什么？可以做日常任务，比如自动备份你的MP3；可以做网站，很多著名的网站包括YouTube就是Python写的；可以做网络游戏的后台，很多在线游戏的后台都是Python开发的。总之就是能干很多很多事啦。 Python当然也有不能干的事情，比如写操作系统，这个只能用C语言写；写手机应用，只能用Swift/Objective-C（针对iPhone）和Java（针对Android）；写3D游戏，最好用C或C++。 如果你是小白用户，满足以下条件： 会使用电脑，但从来没写过程序；还记得初中数学学的方程式和一点点代数知识；想从编程小白变成专业的软件架构师；每天能抽出半个小时学习。不要再犹豫了，这个教程就是为你准备的！ 准备好了吗？ 关于作者 廖雪峰，十年软件开发经验，业余产品经理，精通Java/Python/Ruby/Visual Basic/Objective C等，对开源框架有深入研究，著有《Spring 2.0核心技术与最佳实践》一书，多个业余开源项目托管在GitHub，欢迎微博交流： Python是一种计算机编程语言。计算机编程语言和我们日常使用的自然语言有所不同，最大的区别就是，自然语言在不同的语境下有不同的理解，而计算机要根据编程语言执行任务，就必须保证编程语言写出的程序决不能有歧义，所以，任何一种编程语言都有自己的一套语法，编译器或者解释器就是负责把符合语法的程序代码转换成CPU能够执行的机器码，然后执行。Python也不例外。 Python的语法比较简单，采用缩进方式，写出来的代码就像下面的样子： 123456# print absolute value of an integer:a = 100if a &gt;= 0: print(a)else: print(-a) 以#开头的语句是注释，注释是给人看的，可以是任意内容，解释器会忽略掉注释。其他每一行都是一个语句，当语句以冒号:结尾时，缩进的语句视为代码块。 缩进有利有弊。好处是强迫你写出格式化的代码，但没有规定缩进是几个空格还是Tab。按照约定俗成的管理，应该始终坚持使用4个空格的缩进。 缩进的另一个好处是强迫你写出缩进较少的代码，你会倾向于把一段很长的代码拆分成若干函数，从而得到缩进较少的代码。 缩进的坏处就是“复制－粘贴”功能失效了，这是最坑爹的地方。当你重构代码时，粘贴过去的代码必须重新检查缩进是否正确。此外，IDE很难像格式化Java代码那样格式化Python代码。 最后，请务必注意，Python程序是大小写敏感的，如果写错了大小写，程序会报错。 在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，例如： 1234a = 123 # a是整数print(a)a = 'ABC' # a变为字符串print(a) 这种变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言。静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。Java是静态语言，和静态语言相比，动态语言更灵活，就是这个原因。 下面的代码：1234a = 'ABC'b = aa = 'XYZ'print(b) 执行a = ‘ABC’，解释器创建了字符串’ABC’和变量a，并把a指向’ABC’： 执行b = a，解释器创建了变量b，并把b指向a指向的字符串’ABC’： 执行a = ‘XYZ’，解释器创建了字符串’XYZ’，并把a的指向改为’XYZ’，但b并没有更改： Python支持多种数据类型，在计算机内部，可以把任何数据都看成一个“对象”，而变量就是在程序中用来指向这些数据对象的，对变量赋值就是把数据和变量给关联起来。 注意：Python的整数没有大小限制，而某些语言的整数根据其存储长度是有大小限制的，例如Java对32位整数的范围限制在-2147483648-2147483647。 Python的浮点数也没有大小限制，但是超出一定范围就直接表示为inf（无限大）。 字符编码我们已经讲过了，字符串也是一种数据类型，但是，字符串比较特殊的是还有一个编码问题。 因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），如果要表示更大的整数，就必须用更多的字节。比如两个字节可以表示的最大整数是65535，4个字节可以表示的最大整数是4294967295。 由于计算机是美国人发明的，因此，最早只有127个字母被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码，比如大写字母A的编码是65，小写字母z的编码是122。 但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。 你可以想得到的是，全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。 因此，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。 Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。 现在，捋一捋ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。 字母A用ASCII编码是十进制的65，二进制的01000001； 字符0用ASCII编码是十进制的48，二进制的00110000，注意字符’0’和整数0是不同的； 汉字中已经超出了ASCII编码的范围，用Unicode编码是十进制的20013，二进制的01001110 00101101。 你可以猜测，如果把ASCII编码的A用Unicode编码，只需要在前面补0就可以，因此，A的Unicode编码是00000000 01000001。 新的问题又出现了：如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。 所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间： 字符 ASCII Unicode UTF-8A 01000001 00000000 01000001 01000001中 x 01001110 00101101 11100100 10111000 10101101从上面的表格还可以发现，UTF-8编码有一个额外的好处，就是ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作。 搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式： 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。 用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件： 浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器： 所以你看到很多网页的源码上会有类似的信息，表示该网页正是用的UTF-8编码。 由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上这两行： 12#!/usr/bin/env python3# -*- coding: utf-8 -*- 第一行注释是为了告诉Linux/OS X系统，这是一个Python可执行程序，Windows系统会忽略这个注释； 第二行注释是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。 申明了UTF-8编码并不意味着你的.py文件就是UTF-8编码的，必须并且要确保文本编辑器正在使用UTF-8 without BOM编码： 如果.py文件本身使用UTF-8编码，并且也申明了# -- coding: utf-8 --，打开命令提示符测试就可以正常显示中文： 格式化在Python中，采用的格式化方式和C语言是一致的，用%实现 %运算符就是用来格式化字符串的。在字符串内部，%s表示用字符串替换，%d表示用整数替换，有几个%?占位符，后面就跟几个变量或者值，顺序要对应好。如果只有一个%?，括号可以省略。 常见的占位符有： %d 整数%f 浮点数%s 字符串%x 十六进制整数 有些时候，字符串里面的%是一个普通字符怎么办？这个时候就需要转义，用%%来表示一个% Python内置的一种数据类型是列表：list。list是一种有序的集合，可以随时添加和删除其中的元素。classmates = [‘Michael’, ‘Bob’, ‘Tracy’]另一种有序列表叫元组：tuple。tuple和list非常类似，但是tuple一旦初始化就不能修改，比如同样是列出同学的名字classmates = (‘Michael’, ‘Bob’, ‘Tracy’)不可变的tuple有什么意义？因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。只有1个元素的tuple定义时必须加一个逗号,，来消除歧义Python在显示只有1个元素的tuple时，也会加一个逗号,，以免你误解成数学计算意义上的括号。 最后来看一个“可变的”tuple： 12345&gt;&gt;&gt; t = ('a', 'b', ['A', 'B'])&gt;&gt;&gt; t[2][0] = 'X'&gt;&gt;&gt; t[2][1] = 'Y'&gt;&gt;&gt; t('a', 'b', ['X', 'Y']) 这个tuple定义的时候有3个元素，分别是’a’，’b’和一个list。不是说tuple一旦定义后就不可变了吗？怎么后来又变了？ 别急，我们先看看定义的时候tuple包含的3个元素： 当我们把list的元素’A’和’B’修改为’X’和’Y’后，tuple变为：表面上看，tuple的元素确实变了，但其实变的不是tuple的元素，而是list的元素。tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！ 理解了“指向不变”后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。 如果要计算1-100的整数之和，从1写到100有点困难，幸好Python提供一个range()函数，可以生成一个整数序列，再通过list()函数可以转换为list。比如range(5)生成的序列是从0开始小于5的整数：12&gt;&gt;&gt; list(range(5))[0, 1, 2, 3, 4] 循环是让计算机做重复任务的有效的方法。 break语句可以在循环过程中直接退出循环，而continue语句可以提前结束本轮循环，并直接开始下一轮循环。这两个语句通常都必须配合if语句使用。 要特别注意，不要滥用break和continue语句。break和continue会造成代码执行逻辑分叉过多，容易出错。大多数循环并不需要用到break和continue语句，上面的两个例子，都可以通过改写循环条件或者修改循环逻辑，去掉break和continue语句。 有些时候，如果代码写得有问题，会让程序陷入“死循环”，也就是永远循环下去。这时可以用Ctrl+C退出程序，或者强制结束Python进程。 使用dict和setPython内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。如果用dict实现，只需要一个“名字”-“成绩”的对照表，直接根据名字查找成绩，无论这个表有多大，查找速度都不会变慢。 用Python写一个dict如下：123&gt;&gt;&gt; d = &#123;'Michael': 95, 'Bob': 75, 'Tracy': 85&#125;&gt;&gt;&gt; d['Michael']95 为什么dict查找速度这么快？因为dict的实现原理和查字典是一样的。假设字典包含了1万个汉字，我们要查某一个字，一个办法是把字典从第一页往后翻，直到找到我们想要的字为止，这种方法就是在list中查找元素的方法，list越大，查找越慢。 第二种方法是先在字典的索引表里（比如部首表）查这个字对应的页码，然后直接翻到该页，找到这个字。无论找哪个字，这种查找速度都非常快，不会随着字典大小的增加而变慢。 dict就是第二种实现方式，给定一个名字，比如’Michael’，dict在内部就可以直接计算出Michael对应的存放成绩的“页码”，也就是95这个数字存放的内存地址，直接取出来，所以速度非常快。 你可以猜到，这种key-value存储方式，在放进去的时候，必须根据key算出value的存放位置，这样，取的时候才能根据key直接拿到value。请务必注意，dict内部存放的顺序和key放入的顺序是没有关系的。和list比较，dict有以下几个特点： 查找和插入的速度极快，不会随着key的增加而变慢； 需要占用大量的内存，内存浪费多。而list相反： 查找和插入的时间随着元素的增加而增加； 占用空间小，浪费内存很少。所以，dict是用空间来换取时间的一种方法。 dict可以用在需要高速查找的很多地方，在Python代码中几乎无处不在，正确使用dict非常重要，需要牢记的第一条就是dict的key必须是不可变对象。 这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这个 通过key计算位置的算法称为哈希算法（Hash）。 要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。 再议不可变对象str是不变对象，而list是可变对象。 对于可变对象，比如list，对list进行操作，list内部的内容是会变化的，比如：1234&gt;&gt;&gt; a = ['c', 'b', 'a']&gt;&gt;&gt; a.sort()&gt;&gt;&gt; a['a', 'b', 'c'] 而对于不可变对象，比如str，对str进行操作呢：12345&gt;&gt;&gt; a = 'abc'&gt;&gt;&gt; a.replace('a', 'A')'Abc'&gt;&gt;&gt; a'abc' 虽然字符串有个replace()方法，也确实变出了’Abc’，但变量a最后仍是’abc’，应该怎么理解呢？ 我们先把代码改成下面这样：123456&gt;&gt;&gt; a = 'abc'&gt;&gt;&gt; b = a.replace('a', 'A')&gt;&gt;&gt; b'Abc'&gt;&gt;&gt; a'abc' 要始终牢记的是，a是变量，而’abc’才是字符串对象！有些时候，我们经常说，对象a的内容是’abc’，但其实是指，a本身是一个变量，它指向的对象的内容才是’abc’： 当我们调用a.replace(‘a’, ‘A’)时，实际上调用方法replace是作用在字符串对象’abc’上的，而这个方法虽然名字叫replace，但却没有改变字符串’abc’的内容。相反，replace方法创建了一个新字符串’Abc’并返回，如果我们用变量b指向该新字符串，就容易理解了，变量a仍指向原有的字符串’abc’，但变量b却指向新字符串’Abc’了： 所以，对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。 函数基本上所有的高级语言都支持函数，Python也不例外。Python不但能非常灵活地定义函数，而且本身内置了很多有用的函数，可以直接调用。 抽象是数学中非常常见的概念。举个例子： 计算数列的和，比如：1 + 2 + 3 + … + 100，写起来十分不方便，于是数学家发明了求和符号∑，可以把1 + 2 + 3 + … + 100记作： 100 ∑n n=1 这种抽象记法非常强大，因为我们看到 ∑ 就可以理解成求和，而不是还原成低级的加法运算。 而且，这种抽象记法是可扩展的，比如： 100 ∑(n2+1) n=1 还原成加法运算就变成了： (1 x 1 + 1) + (2 x 2 + 1) + (3 x 3 + 1) + … + (100 x 100 + 1) 可见，借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。 写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。函数名其实就是指向一个函数对象的引用，完全可以把函数名赋给一个变量，相当于给这个函数起了一个“别名”123&gt;&gt;&gt; a = abs # 变量a指向abs函数&gt;&gt;&gt; a(-1) # 所以也可以通过a调用abs函数1 在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用return语句返回。我们以自定义一个求绝对值的my_abs函数为例：12345def my_abs(x): if x &gt;= 0: return x else: return -x 如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。 return None可以简写为return。 如果想定义一个什么事也不做的空函数，可以用pass语句：12def nop(): pass pass语句什么都不做，那有什么用？实际上pass可以用来作为占位符，比如现在还没想好怎么写函数的代码，就可以先放一个pass，让代码能运行起来。 pass还可以用在其他语句里，比如：12if age &gt;= 18: pass 缺少了pass，代码运行就会有语法错误。 Python的函数返回多值其实就是返回一个tuple，但写起来更方便。 定义函数时，需要确定函数名和参数个数；如果有必要，可以先对参数的数据类型做检查；函数体内部可以用return随时返回函数结果；函数执行完毕也没有return语句时，自动return None。函数可以同时返回多个值，但其实就是一个tuple。 函数的参数定义函数的时候，我们把参数的名字和位置确定下来，函数的接口定义就完成了。对于函数的调用者来说，只需要知道如何传递正确的参数，以及函数将返回什么样的值就够了，函数内部的复杂逻辑被封装起来，调用者无需了解。 Python的函数定义非常简单，但灵活度却非常大。除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，使得函数定义出来的接口，不但能处理复杂的参数，还可以简化调用者的代码。 位置参数 我们先写一个计算x2的函数： def power(x): return x * x对于power(x)函数，参数x就是一个位置参数。 当我们调用power函数时，必须传入有且仅有的一个参数x：1234&gt;&gt;&gt; power(5)25&gt;&gt;&gt; power(15)225 现在，如果我们要计算x3怎么办？可以再定义一个power3函数，但是如果要计算x4、x5……怎么办？我们不可能定义无限多个函数。 你也许想到了，可以把power(x)修改为power(x, n)，用来计算xn，说干就干：123456def power(x, n): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 对于这个修改后的power(x, n)函数，可以计算任意n次方：1234&gt;&gt;&gt; power(5, 2)25&gt;&gt;&gt; power(5, 3)125 修改后的power(x, n)函数有两个参数：x和n，这两个参数都是位置参数，调用函数时，传入的两个值按照位置顺序依次赋给参数x和n。 默认参数 新的power(x, n)函数定义没有问题，但是，旧的调用代码失败了，原因是我们增加了一个参数，导致旧的代码因为缺少一个参数而无法正常调用：1234&gt;&gt;&gt; power(5)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: power() missing 1 required positional argument: 'n' Python的错误信息很明确：调用函数power()缺少了一个位置参数n。 这个时候，默认参数就排上用场了。由于我们经常计算x2，所以，完全可以把第二个参数n的默认值设定为2：123456def power(x, n=2): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 这样，当我们调用power(5)时，相当于调用power(5, 2)：1234&gt;&gt;&gt; power(5)25&gt;&gt;&gt; power(5, 2)25 而对于n &gt; 2的其他情况，就必须明确地传入n，比如power(5, 3)。 从上面的例子可以看出，默认参数可以简化函数的调用。设置默认参数时，有几点要注意： 一是必选参数在前，默认参数在后，否则Python的解释器会报错（思考一下为什么默认参数不能放在必选参数前面）；二是如何设置默认参数。当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数。使用默认参数有什么好处？最大的好处是能降低调用函数的难度。定义默认参数要牢记一点：默认参数必须指向不变对象！ 在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。 可变参数 在Python函数中，还可以定义可变参数。顾名思义，可变参数就是传入的参数个数是可变的，可以是1个、2个到任意个，还可以是0个。 定义可变参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此，函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数。 Python允许你在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去123&gt;&gt;&gt; nums = [1, 2, 3]&gt;&gt;&gt; calc(*nums)14 *nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。 参数组合 在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 对于任意函数，都可以通过类似func(*args, kw)的形式调用它，无论它的参数是如何定义的。** 小结 Python的函数具有非常灵活的参数形态，既可以实现简单的调用，又可以传入非常复杂的参数。 默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！ 要注意定义可变参数和关键字参数的语法： *args是可变参数，args接收的是一个tuple； **kw是关键字参数，kw接收的是一个dict。 以及调用函数时如何传入可变参数和关键字参数的语法： 可变参数既可以直接传入：func(1, 2, 3)，又可以先组装list或tuple，再通过args传入：func((1, 2, 3))； 关键字参数既可以直接传入：func(a=1, b=2)，又可以先组装dict，再通过kw传入：func({‘a’: 1, ‘b’: 2})。 使用args和*kw是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。 命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。 定义命名的关键字参数在没有可变参数的情况下不要忘了写分隔符*，否则定义的将是位置参数。 递归函数 在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。递归函数的优点是定义简单，逻辑清晰。理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。解决递归调用栈溢出的方法是通过尾递归优化，事实上尾递归和循环的效果是一样的，所以，把循环看成是一种特殊的尾递归函数也是可以的。尾递归是指，在函数返回的时候，调用自身本身，并且，return语句不能包含表达式。这样，编译器或者解释器就可以把尾递归做优化，使递归本身无论调用多少次，都只占用一个栈帧，不会出现栈溢出的情况。 fact(n)用递归的方式写出来就是：1234def fact(n): if n==1: return 1 return n * fact(n - 1) 改成尾递归方式，需要多一点代码，主要是要把每一步的乘积传入到递归函数中：1234567def fact(n): return fact_iter(n, 1)def fact_iter(num, product): if num == 1: return product return fact_iter(num - 1, num * product) 可以看到，return fact_iter(num - 1, num product)仅返回递归函数本身，num - 1和num product在函数调用前就会被计算，不影响函数调用。 尾递归调用时，如果做了优化，栈不会增长，因此，无论多少次调用也不会导致栈溢出。遗憾的是，大多数编程语言没有针对尾递归做优化，Python解释器也没有做优化，所以，即使把上面的fact(n)函数改成尾递归方式，也会导致栈溢出。 小结 使用递归函数的优点是逻辑简单清晰，缺点是过深的调用会导致栈溢出。 针对尾递归优化的语言可以通过尾递归防止栈溢出。尾递归事实上和循环是等价的，没有循环语句的编程语言只能通过尾递归实现循环。 Python标准的解释器没有针对尾递归做优化，任何递归函数都存在栈溢出的问题。 高级特性在Python中，代码不是越多越好，而是越少越好。代码不是越复杂越好，而是越简单越好。1行代码能实现的功能，决不写5行代码。请始终牢记，代码越少，开发效率越高。 切片在很多编程语言中，针对字符串提供了很多各种截取函数（例如，substring），其实目的就是对字符串切片。Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。 有了切片操作，很多地方循环就不再需要了。Python的切片非常灵活，一行代码就可以实现很多行循环才能完成的操作。 迭代如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代（Iteration）。在Python中，迭代是通过for … in来完成的，而很多语言比如C或者Java，迭代list是通过下标完成的Python的for循环抽象程度要高于Java的for循环，因为Python的for循环不仅可以用在list或tuple上，还可以作用在其他可迭代对象上。list这种数据类型虽然有下标，但很多其他数据类型是没有下标的，但是，只要是可迭代对象，无论有无下标，都可以迭代，比如dict就可以迭代因为dict的存储不是按照list的方式顺序排列，所以，迭代出的结果顺序很可能不一样。默认情况下，dict迭代的是key。如果要迭代value，可以用for value in d.values()，如果要同时迭代key和value，可以用for k, v in d.items()。由于字符串也是可迭代对象，因此，也可以作用于for循环： 如何判断一个对象是可迭代对象呢？方法是通过collections模块的Iterable类型判断：1234567&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance('abc', Iterable) # str是否可迭代True&gt;&gt;&gt; isinstance([1,2,3], Iterable) # list是否可迭代True&gt;&gt;&gt; isinstance(123, Iterable) # 整数是否可迭代False 如果要对list实现类似Java那样的下标循环怎么办？Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身：123456&gt;&gt;&gt; for i, value in enumerate(['A', 'B', 'C']):... print(i, value)...0 A1 B2 C 上面的for循环里，同时引用了两个变量，在Python里是很常见的，比如下面的代码：123456&gt;&gt;&gt; for x, y in [(1, 1), (2, 4), (3, 9)]:... print(x, y)...1 12 43 9 小结 任何可迭代对象都可以作用于for循环，包括我们自定义的数据类型，只要符合迭代条件，就可以使用for循环。 列表生成式 写列表生成式时，把要生成的元素x * x放到前面，后面跟for循环，就可以把list创建出来，十分有用，多写几次，很快就可以熟悉这种语法。1&gt;&gt;&gt;[x * x for x in range(1, 11)] for循环后面还可以加上if判断，这样我们就可以筛选出仅偶数的平方：12&gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100] 还可以使用两层循环，可以生成全排列：12&gt;&gt;&gt; [m + n for m in 'ABC' for n in 'XYZ']['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] 运用列表生成式，可以写出非常简洁的代码。例如，列出当前目录下的所有文件和目录名，可以通过一行代码实现：123&gt;&gt;&gt; import os # 导入os模块，模块的概念后面讲到&gt;&gt;&gt; [d for d in os.listdir('.')] # os.listdir可以列出文件和目录['.emacs.d', '.ssh', '.Trash', 'Adlm', 'Applications', 'Desktop', 'Documents', 'Downloads', 'Library', 'Movies', 'Music', 'Pictures', 'Public', 'VirtualBox VMs', 'Workspace', 'XCode'] for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value：1234567&gt;&gt;&gt; d = &#123;'x': 'A', 'y': 'B', 'z': 'C' &#125;&gt;&gt;&gt; for k, v in d.items():... print(k, '=', v)...y = Bx = Az = C 因此，列表生成式也可以使用两个变量来生成list：123&gt;&gt;&gt; d = &#123;'x': 'A', 'y': 'B', 'z': 'C' &#125;&gt;&gt;&gt; [k + '=' + v for k, v in d.items()]['y=B', 'x=A', 'z=C'] 最后把一个list中所有的字符串变成小写：123&gt;&gt;&gt; L = ['Hello', 'World', 'IBM', 'Apple']&gt;&gt;&gt; [s.lower() for s in L]['hello', 'world', 'ibm', 'apple'] 运用列表生成式，可以快速生成list，可以通过一个list推导出另一个list，而代码却十分简洁。 生成器通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：123456&gt;&gt;&gt; L = [x * x for x in range(10)]&gt;&gt;&gt; L[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]&gt;&gt;&gt; g = (x * x for x in range(10))&gt;&gt;&gt; g&lt;generator object &lt;genexpr&gt; at 0x1022ef630&gt; 创建L和g的区别仅在于最外层的[]和()，L是一个list，而g是一个generator。 我们可以直接打印出list的每一个元素，但我们怎么打印出generator的每一个元素呢？ 如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值：generator保存的是算法，每次调用next(g)，就计算出g的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，并且不需要关心StopIteration的错误。 generator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。 如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。 小结 generator是非常强大的工具，在Python中，可以简单地把列表生成式改成generator，也可以通过函数实现复杂逻辑的generator。 要理解generator的工作原理，它是在for循环的过程中不断计算出下一个元素，并在适当的条件结束for循环。对于函数改成的generator来说，遇到return语句或者执行到函数体最后一行语句，就是结束generator的指令，for循环随之结束。 请注意区分普通函数和generator函数，普通函数调用直接返回结果：123&gt;&gt;&gt; r = abs(6)&gt;&gt;&gt; r6 generator函数的“调用”实际返回一个generator对象： 123&gt;&gt;&gt; g = fib(6)&gt;&gt;&gt; g&lt;generator object fib at 0x1022ef948&gt; 迭代器我们已经知道，可以直接作用于for循环的数据类型有以下几种： 一类是集合数据类型，如list、tuple、dict、set、str等； 一类是generator，包括生成器和带yield的generator function。 这些可以直接作用于for循环的对象统称为可迭代对象：Iterable。 可以使用isinstance()判断一个对象是否是Iterable对象：1234567891011&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance([], Iterable)True&gt;&gt;&gt; isinstance(&#123;&#125;, Iterable)True&gt;&gt;&gt; isinstance('abc', Iterable)True&gt;&gt;&gt; isinstance((x for x in range(10)), Iterable)True&gt;&gt;&gt; isinstance(100, Iterable)False 而生成器不但可以作用于for循环，还可以被next()函数不断调用并返回下一个值，直到最后抛出StopIteration错误表示无法继续返回下一个值了。 可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。 可以使用isinstance()判断一个对象是否是Iterator对象：123456789&gt;&gt;&gt; from collections import Iterator&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)True&gt;&gt;&gt; isinstance([], Iterator)False&gt;&gt;&gt; isinstance(&#123;&#125;, Iterator)False&gt;&gt;&gt; isinstance('abc', Iterator)False 生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。 把list、dict、str等Iterable变成Iterator可以使用iter()函数：1234&gt;&gt;&gt; isinstance(iter([]), Iterator)True&gt;&gt;&gt; isinstance(iter('abc'), Iterator)True 你可能会问，为什么list、dict、str等数据类型不是Iterator？ 这是因为Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。 Iterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list是永远不可能存储全体自然数的。 小结 凡是可作用于for循环的对象都是Iterable类型； 凡是可作用于next()函数的对象都是Iterator类型，它们表示一个惰性计算的序列； 集合数据类型如list、dict、str等是Iterable但不是Iterator，不过可以通过iter()函数获得一个Iterator对象。 Python的for循环本质上就是通过不断调用next()函数实现的，例如：1234567891011121314for x in [1, 2, 3, 4, 5]: pass实际上完全等价于：# 首先获得Iterator对象:it = iter([1, 2, 3, 4, 5])# 循环:while True: try: # 获得下一个值: x = next(it) except StopIteration: # 遇到StopIteration就退出循环 break 函数式编程函数是Python内建支持的一种封装，我们通过把大段代码拆成函数，通过一层一层的函数调用，就可以把复杂任务分解成简单的任务，这种分解可以称之为面向过程的程序设计。函数就是面向过程的程序设计的基本单元。 而函数式编程（请注意多了一个“式”字）——Functional Programming，虽然也可以归结到面向过程的程序设计，但其思想更接近数学计算。 我们首先要搞明白计算机（Computer）和计算（Compute）的概念。 在计算机的层次上，CPU执行的是加减乘除的指令代码，以及各种条件判断和跳转指令，所以，汇编语言是最贴近计算机的语言。 而计算则指数学意义上的计算，越是抽象的计算，离计算机硬件越远。 对应到编程语言，就是越低级的语言，越贴近计算机，抽象程度低，执行效率高，比如C语言；越高级的语言，越贴近计算，抽象程度高，执行效率低，比如Lisp语言。 函数式编程就是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量，因此，任意一个函数，只要输入是确定的，输出就是确定的，这种纯函数我们称之为没有副作用。而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，同样的输入，可能得到不同的输出，因此，这种函数是有副作用的。 函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数！ Python对函数式编程提供部分支持。由于Python允许使用变量，因此，Python不是纯函数式编程语言。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://ipcreator.me/tags/Python/"}]},{"title":"Git教程","date":"2017-02-19T06:09:06.000Z","path":"2017/02/19/Program/Concepts/learn-journey-of-git/","text":"作者：廖雪峰 史上最浅显易懂的Git教程！ 为什么要编写这个教程？因为我在学习Git的过程中，买过书，也在网上Google了一堆Git相关的文章和教程，但令人失望的是，这些教程不是难得令人发指，就是简单得一笔带过，或者，只支离破碎地介绍Git的某几个命令，还有直接从Git手册粘贴帮助文档的，总之，初学者很难找到一个由浅入深，学完后能立刻上手的Git教程。 既然号称史上最浅显易懂的Git教程，那这个教程有什么让你怦然心动的特点呢？ 首先，本教程绝对面向初学者，没有接触过版本控制概念的读者也可以轻松入门，不必担心起步难度； 其次，本教程实用性超强，边学边练，一点也不觉得枯燥。而且，你所学的Git命令是“充分且必要”的，掌握了这些东西，你就可以通过Git轻松地完成你的工作。 文字+图片还看不明白？有视频！！！ 本教程只会让你成为Git用户，不会让你成为Git专家。很多Git命令只有那些专家才明白（事实上我也不明白，因为我不是Git专家），但我保证这些命令可能你一辈子都不会用到。既然Git是一个工具，就没必要把时间浪费在那些“高级”但几乎永远不会用到的命令上。一旦你真的非用不可了，到时候再自行Google或者请教专家也未迟。 如果你是一个开发人员，想用上这个世界上目前最先进的分布式版本控制系统，那么，赶快开始学习吧！ 关于作者 廖雪峰，十年软件开发经验，业余产品经理，精通Java/Python/Ruby/Visual Basic/Objective C等，对开源框架有深入研究，著有《Spring 2.0核心技术与最佳实践》一书，多个业余开源项目托管在GitHub，欢迎微博交流： 读书笔记集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。 分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 通过git init命令把这个目录变成Git可以管理的仓库： $ git init 当前目录下多了一个.git的隐藏目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。 所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 使用Windows的童鞋要特别注意： 千万不要使用Windows自带的记事本编辑任何文本文件。原因是Microsoft开发记事本的团队使用了一个非常弱智的行为来保存UTF-8编码的文件，他们自作聪明地在每个文件开头添加了0xefbbbf（十六进制）的字符，你会遇到很多不可思议的问题，比如，网页第一行可能会显示一个“?”，明明正确的程序一编译就报语法错误，等等，都是由记事本的弱智行为带来的。建议你下载Notepad++代替记事本，不但功能强大，而且免费！记得把Notepad++的默认编码设置为UTF-8 without BOM即可： 用命令git add告诉Git，把文件添加到仓库： $ git add readme.txt 执行上面的命令，没有任何显示，这就对了，Unix的哲学是“没有消息就是好消息”，说明添加成功。 用命令git commit告诉Git，把文件提交到仓库： $ git commit -m “wrote a readme file” 为什么Git添加文件需要add，commit一共两步呢？因为commit可以一次提交很多文件，所以你可以多次add不同的文件，比如： $ git add file1.txt$ git add file2.txt file3.txt$ git commit -m “add 3 files.” git status命令可以让我们时刻掌握仓库当前的状态git diff顾名思义就是查看difference $ git diff readme.txt 每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为commit。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个commit恢复，然后继续工作 版本控制系统肯定有某个命令可以告诉我们历史记录，在Git中，我们用git log命令查看：如果嫌输出信息太多，看得眼花缭乱的，可以试试加上–pretty=oneline参数 $ git log –pretty=oneline 为什么commit id需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。 在Git中，用HEAD表示当前版本Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL：改为指向add distributed：然后顺便把工作区的文件更新了。所以你让HEAD指向哪个版本号，你就把当前版本定位在哪。Git提供了一个命令git reflog用来记录你的每一次命令： Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 我们把文件往Git版本库里添加的时候，是分两步执行的：第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。 Git会告诉你，git checkout – file可以丢弃工作区的修改就是让这个文件回到最近一次git commit或git add时的状态。一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 $ git checkout – readme.txt git checkout – file命令中的–很重要，没有–，就变成了“切换到另一个分支”的命令,git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 用命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区： $ git reset HEAD readme.txt git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。 确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit： $ git rm test.txt$ git commit -m “remove test.txt” 在本地的learngit仓库下运行命令： $ git remote add origin git@github.com:michaelliao/learngit.git 请千万注意，把上面的michaelliao替换成你自己的GitHub账户名，否则，你在本地关联的就是我的远程库，关联没有问题，但是你以后推送是推不上去的，因为你的SSH Key公钥不在我的账户列表中。 添加后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库。 下一步，就可以把本地库的所有内容推送到远程库上： $ git push -u origin master 把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 从现在起，只要本地作了提交，就可以通过命令： $ git push origin master 登陆GitHub，创建一个新的仓库，名字叫gitskills：我们勾选Initialize this repository with a README，这样GitHub会自动为我们创建一个README.md文件。创建完毕后，可以看到README.md文件：现在，远程库已经准备好了，下一步是用命令git clone克隆一个本地库： $ git clone git@github.com:michaelliao/gitskills.git GitHub给出的地址不止一个，还可以用https://github.com/michaelliao/gitskills.git这样的地址。实际上，Git支持多种协议，默认的git://使用ssh，但也可以使用https等其他协议。 使用https除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用ssh协议而只能用https。 每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点：每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长： 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： 你看，Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！ 不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 所以Git合并分支也很快！就改改指针，工作区内容也不变！ 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 创建dev分支，然后切换到dev分支： $ git checkout -b dev git checkout命令加上-b参数表示创建并切换，相当于以下两条命令： $ git branch dev$ git checkout dev 用git branch命令查看当前分支：git branch命令会列出所有分支，当前分支前面会标一个*号。 $ git branch dev分支的工作完成，我们就可以切换回master分支： $ git checkout master 切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变： 我们把dev分支的工作成果合并到master分支上：git merge命令用于合并指定分支到当前分支。 $ git merge dev 合并完成后，就可以放心地删除dev分支了： $ git branch -d dev 因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在master分支上工作效果是一样的，但过程更安全。 master分支和feature1分支各自都分别有新的提交，变成了这样： Git告诉我们，readme.txt文件存在冲突，必须手动解决冲突后再提交。git status也可以告诉我们冲突的文件：Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容 修改后保存，再提交： $ git add readme.txt$ git commit -m “conflict fixed”[master 59bc1cb] conflict fixed现在，master分支和feature1分支变成了下图所示： 用带参数的git log也可以看到分支的合并情况：$ git log –graph –pretty=oneline –abbrev-commit 合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 准备合并dev分支，请注意–no-ff参数，表示禁用Fast forward： $ git merge –no-ff -m “merge with no-ff” dev 不使用Fast forward模式，merge后就像这样： 分支策略 在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样： Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： $ git stash 刚才的工作现场存到哪去了？用git stash list命令看看： $ git stash list 一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除；另一种方式是用git stash pop，恢复的同时把stash内容也删了： $ git stash pop 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令： $ git stash apply stash@{0} 软件开发中，总有无穷无尽的新的功能要不断添加进来。 添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。 要查看远程库的信息，用git remote：或者，用git remote -v显示更详细的信息： $ git remote$ git remote -vorigin git@github.com:michaelliao/learngit.git (fetch)origin git@github.com:michaelliao/learngit.git (push) 上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。 推送分支 推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上： $ git push origin master如果要推送其他分支，比如dev，就改成： $ git push origin dev master分支是主分支，因此要时刻与远程同步；dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步；bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug；feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。 当你的小伙伴从远程库clone时，默认情况下，你的小伙伴只能看到本地的master分支。现在，你的小伙伴要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支： $ git checkout -b dev origin/dev现在，他就可以在dev上继续修改，然后，时不时地把dev分支push到远程： 你的小伙伴的最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送： git pull也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接： $ git branch –set-upstream dev origin/devBranch dev set up to track remote branch dev from origin. 再pull：$ git pull 多人协作的工作模式通常是这样： 首先，可以试图用git push origin branch-name推送自己的修改；如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并；如果合并有冲突，则解决冲突，并在本地提交；没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功！如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch –set-upstream branch-name origin/branch-name。 tag就是一个让人容易记住的有意义的名字，它跟某个commit绑在一起。 在Git中打标签非常简单，首先，切换到需要打标签的分支上： $ git branch 然后，敲命令git tag 就可以打一个新标签： $ git tag v1.0可以用命令git tag查看所有标签：标签不是按时间顺序列出，而是按字母排序的。可以用git show 查看标签信息, 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字：还可以通过-s用私钥签名一个标签：签名采用PGP签名，因此，必须首先安装gpg（GnuPG），如果没有找到gpg，或者没有gpg密钥对，就会报错, 如果报错，请参考GnuPG帮助文档配置Key。用命令git show 可以看到PGP签名信息,用PGP签名的标签是不可伪造的，因为可以验证PGP签名。 $ git tag -a v0.1 -m “version 0.1 released” 3628164 $ git tag 默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？ 方法是找到历史提交的commit id，然后打上就可以了： $ git log –pretty=oneline –abbrev-commit 比方说要对add merge这次提交打标签，它对应的commit id是6224937，敲入命令： $ git tag v0.9 6224937 如果标签打错了，也可以删除： $ git tag -d v0.1 如果要推送某个标签到远程，使用命令git push origin ： $ git push origin v1.0 一次性推送全部尚未推送到远程的本地标签： $ git push origin –tags 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： $ git tag -d v0.9 然后，从远程删除。删除命令也是push，但是格式如下： $ git push origin :refs/tags/v0.9 如何参与一个开源项目呢？比如人气极高的bootstrap项目，这是一个非常强大的CSS框架，你可以访问它的项目主页https://github.com/twbs/bootstrap，点“Fork”就在自己的账号下克隆了一个bootstrap仓库，然后，从自己的账号下clone： git clone git@github.com:michaelliao/bootstrap.git一定要从自己的账号下clone仓库，这样你才能推送修改。如果从bootstrap的作者的仓库地址git@github.com:twbs/bootstrap.git克隆，因为没有权限，你将不能推送修改。 Bootstrap的官方仓库twbs/bootstrap、你在GitHub上克隆的仓库my/bootstrap，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样： 如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送。 如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了。 在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 忽略文件的原则是： 忽略操作系统自动生成的文件，比如缩略图等；忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件；忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 检验.gitignore的标准是git status命令是不是说working directory clean。如果你在资源管理器里新建一个.gitignore文件，它会非常弱智地提示你必须输入文件名，但是在文本编辑器里“保存”或者“另存为”就可以把文件保存为.gitignore了。 你想添加一个文件到Git，但发现添加不了，原因是这个文件被.gitignore忽略了： $ git add App.classThe following paths are ignored by one of your .gitignore files:App.classUse -f if you really want to add them.如果你确实想添加该文件，可以用-f强制添加到Git： $ git add -f App.class或者你发现，可能是.gitignore写得有问题，需要找出来到底哪个规则写错了，可以用git check-ignore命令检查： $ git check-ignore -v App.class.gitignore:3:.class App.class Git会告诉我们，.gitignore的第3行规则忽略了该文件，于是我们就可以知道应该修订哪个规则。 给Git配置好别名，就可以输入命令时偷个懒。我们鼓励偷懒。 小结初始化一个Git仓库，使用git init命令。添加文件到Git仓库，分两步：第一步，使用命令git add ，注意，可反复多次使用，添加多个文件；第二步，使用命令git commit，完成。 要随时掌握工作区的状态，使用git status命令。如果git status告诉你有文件被修改过，用git diff可以查看修改内容。 HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset –hard commit_id。穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 每次修改，如果不add到暂存区，那就不会加入到commit中。 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。 命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 要关联一个远程库，使用命令git remote add origin git@server-name:path/repo-name.git； 关联后，使用命令git push -u origin master第一次推送master分支的所有内容； 此后，每次本地提交后，只要有必要，就可以使用命令git push origin master推送最新修改； 分布式版本系统的最大好处之一是在本地工作完全不需要考虑远程库的存在，也就是有没有联网都可以正常工作，而SVN在没有联网的时候是拒绝干活的！当有网络的时候，再把本地提交推送一下就完成了同步，真是太方便了！ 要克隆一个仓库，首先必须知道仓库的地址，然后使用git clone命令克隆。 Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快。 Git鼓励大量使用分支： 查看分支：git branch 创建分支：git branch 切换分支：git checkout 创建+切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d 当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。用git log –graph命令可以看到分支合并图。 Git分支十分强大，在团队开发中应该充分应用。 合并分支时，加上–no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除； 当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场。 开发一个新feature，最好新建一个分支； 如果要丢弃一个没有被合并过的分支，可以通过git branch -D 强行删除。 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch –set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 命令git tag 用于新建一个标签，默认为HEAD，也可以指定一个commit id； git tag -a -m “blablabla…”可以指定标签信息； git tag -s -m “blablabla…”可以用PGP签名标签； 命令git tag可以查看所有标签。 命令git push origin 可以推送一个本地标签；命令git push origin –tags可以推送全部未推送过的本地标签；命令git tag -d 可以删除一个本地标签；命令git push origin :refs/tags/可以删除一个远程标签。 在GitHub上，可以任意Fork开源仓库；自己拥有Fork后的仓库的读写权限；可以推送pull request给官方仓库来贡献代码。 忽略某些文件时，需要编写.gitignore；.gitignore文件本身要放到版本库里，并且可以对.gitignore做版本管理！ 配置别名如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。我们只需要敲一行命令，告诉Git，以后st就表示status： $ git config –global alias.st status 当然还有别的命令可以简写，很多人都用co表示checkout，ci表示commit，br表示branch： $ git config –global alias.co checkout$ git config –global alias.ci commit$ git config –global alias.br branch –global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名： $ git config –global alias.unstage ‘reset HEAD’ 配置一个git last，让其显示最后一次提交信息： $ git config –global alias.last ‘log -1’这样，用git last就能显示最近一次的提交： $ git last 甚至还有人丧心病狂地把lg配置成了： git config –global alias.lg “log –color –graph –pretty=format:’%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit” 配置Git的时候，加上–global是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。 配置文件放哪了？每个仓库的Git配置文件都放在.git/config文件中：而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中： 搭建Git服务器非常简单，通常10分钟即可完成；要方便管理公钥，用Gitosis；要像SVN那样变态地控制权限，用Gitolite。 Git虽然极其强大，命令繁多，但常用的就那么十来个，掌握好这十几个常用命令，你已经可以得心应手地使用Git了。 友情附赠国外网友制作的Git Cheat Sheet，建议打印出来备用： Git Cheat Sheet Practice in Action$ git initReinitialized existing Git repository in D:/IPCreatorBlog/themes/yilia/.git/ $ git remote add yilia git@github.com:ipcreator/hexo-theme-yilia.git $ git push -u yilia masterBranch master set up to track remote branch master from yilia.Everything up-to-date $ git statusOn branch masterYour branch is up-to-date with ‘yilia/master’.Changes not staged for commit: (use “git add …” to update what will be committed) (use “git checkout – …” to discard changes in working directory) modified: _config.yml modified: layout/_partial/after-footer.ejs modified: layout/_partial/footer.ejs modified: layout/_partial/left-col.ejs modified: source-src/css/article-main.scss modified: source-src/css/fonts/iconfont.svg modified: source-src/js/mobile.js modified: source/fonts/iconfont.dba24b.svg Untracked files: (use “git add …” to include in what will be committed) source/main.0d8e3c.css source/main.0d8e3c.js source/mobile.0b1d99.js source/slider.fa3fc2.js no changes added to commit (use “git add” and/or “git commit -a”) $ git branch master $ git add _config.yml $ git statusOn branch masterYour branch is up-to-date with ‘yilia/master’.Changes to be committed: (use “git reset HEAD …” to unstage) modified: _config.yml Changes not staged for commit: (use “git add …” to update what will be committed) (use “git checkout – …” to discard changes in working directory) modified: layout/_partial/after-footer.ejs modified: layout/_partial/footer.ejs modified: layout/_partial/left-col.ejs modified: source-src/css/article-main.scss modified: source-src/css/fonts/iconfont.svg modified: source-src/js/mobile.js modified: source/fonts/iconfont.dba24b.svg Untracked files: (use “git add …” to include in what will be committed) source/main.0d8e3c.css source/main.0d8e3c.js source/mobile.0b1d99.js source/slider.fa3fc2.js $ git add layout/_partial/after-footer.ejs$ git add layout/_partial/footer.ejs$ git add layout/_partial/left-col.ejs$ git add source-src/css/article-main.scss$ git add source-src/css/fonts/iconfont.svgwarning: LF will be replaced by CRLF in source-src/css/fonts/iconfont.svg.The file will have its original line endings in your working directory. $ git add source-src/js/mobile.js$ git add source/fonts/iconfont.dba24b.svgwarning: LF will be replaced by CRLF in source/fonts/iconfont.dba24b.svg.The file will have its original line endings in your working directory. $ git add source/main.0d8e3c.css$ git add source/main.0d8e3c.jswarning: LF will be replaced by CRLF in source/main.0d8e3c.js.The file will have its original line endings in your working directory. $ git add source/mobile.0b1d99.js$ git add source/slider.fa3fc2.jswarning: LF will be replaced by CRLF in source/slider.fa3fc2.js.The file will have its original line endings in your working directory. $ git statusOn branch masterYour branch is up-to-date with ‘yilia/master’.Changes to be committed: (use “git reset HEAD …” to unstage) modified: _config.yml modified: layout/_partial/after-footer.ejs modified: layout/_partial/footer.ejs modified: layout/_partial/left-col.ejs modified: source-src/css/article-main.scss modified: source-src/js/mobile.js new file: source/main.0d8e3c.css new file: source/main.0d8e3c.js new file: source/mobile.0b1d99.js new file: source/slider.fa3fc2.js $ git commit -m “first bak”[master 8251377] first bak 10 files changed, 111 insertions(+), 28 deletions(-) create mode 100644 source/main.0d8e3c.css create mode 100644 source/main.0d8e3c.js create mode 100644 source/mobile.0b1d99.js create mode 100644 source/slider.fa3fc2.js $ git push -u yilia masterCounting objects: 18, done.Delta compression using up to 8 threads.Compressing objects: 100% (18/18), done.Writing objects: 100% (18/18), 63.54 KiB | 0 bytes/s, done.Total 18 (delta 10), reused 3 (delta 0)remote: Resolving deltas: 100% (10/10), completed with 10 local objects.Branch master set up to track remote branch master from yilia.To github.com:ipcreator/hexo-theme-yilia.git 8ff6b52..8251377 master -&gt; master $ git statusOn branch masterYour branch is up-to-date with ‘yilia/master’.Changes not staged for commit: (use “git add …” to update what will be committed) (use “git checkout – …” to discard changes in working directory) modified: _config.yml no changes added to commit (use “git add” and/or “git commit -a”) $ git diff HEAD – _config.ymldiff –git a/_config.yml b/_config.ymlindex 4f8698a..e00540b 100644— a/_config.yml+++ b/_config.yml@@ -79,11 +79,11 @@ duoshuo-key: ipcreator style: #header: ‘#4d4d4d’ header: ‘#47A2E4’ header: ‘#4d4d4d’ #header: ‘#47A2E4’ #slider: ‘linear-gradient(200deg,#a0cfe4,#e8c37e)’ slider: ‘linear-gradient(200deg,#47A2E4,#47A2E4)’ slider: ‘linear-gradient(200deg,#a0cfe4,#e8c37e)’ #slider: ‘linear-gradient(200deg,#47A2E4,#47A2E4)’ $ git add _config.yml $ git commit -m “restore color”[master 1acf4a2] restore color 1 file changed, 4 insertions(+), 4 deletions(-) $ git push -u yilia masterCounting objects: 3, done.Delta compression using up to 8 threads.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 329 bytes | 0 bytes/s, done.Total 3 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), completed with 2 local objects.Branch master set up to track remote branch master from yilia.To github.com:ipcreator/hexo-theme-yilia.git 2547415..1acf4a2 master -&gt; master Coding.net实践一、先在coding.net新建一个仓库二、使用gitclone方法新建一个本地库三、将要上传的文件拷贝到本地库四、先在本地add和commit五、提交到远程库 12345$ git clone$ git status$ git add .$ git commit -m \"First commit\"$ git push","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://ipcreator.me/tags/Git/"}]},{"title":"Scikit-learn入门指南","date":"2017-02-18T05:04:06.000Z","path":"2017/02/18/Program/TensorFlow/basic-knowledge-of-scikit-learn/","text":"作者：雷锋网 恒亮 对Python语言有所了解的科研人员可能都知道SciPy——一个开源的基于Python的科学计算工具包。基于SciPy，目前开发者们针对不同的应用领域已经发展出了为数众多的分支版本，它们被统一称为Scikits，即SciPy工具包的意思。而在这些分支版本中，最有名，也是专门面向机器学习的一个就是Scikit-learn。 Scikit-learn项目最早由数据科学家 David Cournapeau 在 2007 年发起，需要NumPy和SciPy等其他包的支持，是Python语言中专门针对机器学习应用而发展起来的一款开源框架。 和其他众多的开源项目一样，Scikit-learn目前主要由社区成员自发进行维护。可能是由于维护成本的限制，Scikit-learn相比其他项目要显得更为保守。这主要体现在两个方面：一是Scikit-learn从来不做除机器学习领域之外的其他扩展，二是Scikit-learn从来不采用未经广泛验证的算法。 本文将简单介绍Scikit-learn框架的六大功能，安装和运行Scikit-learn的大概步骤，同时为后续各更深入地学习Scikit-learn提供参考。原文来自infoworld网站的特约撰稿人Martin Heller，他曾在1986-2010年间做过长达20多年的数据库、通用软件和网页开发，具有丰富的开发经验。 Scikit-learn的六大功能 Scikit-learn的基本功能主要被分为六大部分：分类，回归，聚类，数据降维，模型选择和数据预处理。 分类是指识别给定对象的所属类别，属于监督学习的范畴，最常见的应用场景包括垃圾邮件检测和图像识别等。目前Scikit-learn已经实现的算法包括：支持向量机（SVM），最近邻，逻辑回归，随机森林，决策树以及多层感知器（MLP）神经网络等等。 需要指出的是，由于Scikit-learn本身不支持深度学习，也不支持GPU加速，因此这里对于MLP的实现并不适合于处理大规模问题。有相关需求的读者可以查看同样对Python有良好支持的Keras和Theano等框架。 回归是指预测与给定对象相关联的连续值属性，最常见的应用场景包括预测药物反应和预测股票价格等。目前Scikit-learn已经实现的算法包括：支持向量回归（SVR），脊回归，Lasso回归，弹性网络（Elastic Net），最小角回归（LARS ），贝叶斯回归，以及各种不同的鲁棒回归算法等。可以看到，这里实现的回归算法几乎涵盖了所有开发者的需求范围，而且更重要的是，Scikit-learn还针对每种算法都提供了简单明了的用例参考。 聚类是指自动识别具有相似属性的给定对象，并将其分组为集合，属于无监督学习的范畴，最常见的应用场景包括顾客细分和试验结果分组。目前Scikit-learn已经实现的算法包括：K-均值聚类，谱聚类，均值偏移，分层聚类，DBSCAN聚类等。 数据降维是指使用主成分分析（PCA）、非负矩阵分解（NMF）或特征选择等降维技术来减少要考虑的随机变量的个数，其主要应用场景包括可视化处理和效率提升。 模型选择是指对于给定参数和模型的比较、验证和选择，其主要目的是通过参数调整来提升精度。目前Scikit-learn实现的模块包括：格点搜索，交叉验证和各种针对预测误差评估的度量函数。 数据预处理是指数据的特征提取和归一化，是机器学习过程中的第一个也是最重要的一个环节。这里归一化是指将输入数据转换为具有零均值和单位权方差的新变量，但因为大多数时候都做不到精确等于零，因此会设置一个可接受的范围，一般都要求落在0-1之间。而特征提取是指将文本或图像数据转换为可用于机器学习的数字变量。 需要特别注意的是，这里的特征提取与上文在数据降维中提到的特征选择非常不同。特征选择是指通过去除不变、协变或其他统计上不重要的特征量来改进机器学习的一种方法。 总结来说，Scikit-learn实现了一整套用于数据降维，模型选择，特征提取和归一化的完整算法/模块，虽然缺少按步骤操作的参考教程，但Scikit-learn针对每个算法和模块都提供了丰富的参考样例和详细的说明文档。 安装和运行Scikit-learn 如前所述，Scikit-learn需要NumPy和SciPy等其他包的支持，因此在安装Scikit-learn之前需要提前安装一些支持包，具体列表和教程可以查看Scikit-learn的官方文档： http://scikit-learn.org/stable/install.html ，以下仅列出Python、NumPy和SciPy等三个必备包的安装说明。 Python：https://www.python.org/about/gettingstarted/ NumPy：http://www.numpy.org/ SciPy：http://www.scipy.org/install.html 假定已经完整安装了所有支持包，那么利用安装Scikit-learn只需要简单的一条简单的pip命令（也可以用conda命令，详见官方文档）： $ sudo pip install -U scikit-learn 这里加上sudo是为了避免安装过程中出现一些权限问题，如果用户已经确保了管理员权限也可以省略。 当然，开发者也可以选择自己到GitHub开源平台上下载Scikit-learn的源代码，解压后在根目录键入make自行编译和连接可执行文件，效果是一样的。另外，为了确保测试方便，高级用户还可以选择安装针对Python的测试框架nose，安装方法详见其官方说明： http://nose.readthedocs.io/en/latest/ 。 通过Jupyter Notebook工具运行Scikit-learn样例的过程也很简单，用户只需要在官方给出的样例库： http://scikit-learn.org/stable/auto_examples/index.html#general-examples 选择一个样例，然后在页面中下载其Python源码和IPython notebook文件，借着通过Jupyter Notebook工具运行就可以了。假如选择了交叉验证预测的样例，那么其运行情况的截图如下所示。 原作者在这里表示，Scikit-learn是他测试过的最简单易用的机器学习框架。他表示，Scikit-learn样例的运行结果和文档描述一模一样，API接口的设计合理且一致性高，而且几乎不存在“阻抗不匹配”的数据结构，使用这种功能完善且几乎没有Bug的开源框架进行机器学习研究，无疑是一件值得高兴的事。 更深入地学习Scikit-learn 如前所述，Scikit-learn针对每个算法和模块都提供了丰富的参考样例和详细的说明文档，据官方的统计大约有200多个。而且为了清晰明白，绝大多数样例都至少给出了一张由Matplotlib绘制的数据图表。这些都是官方提供的学习Scikit-learn框架最直接有效的学习材料。 针对科学数据处理的应用场景，官方还给出了一个更为详细和全面的参考教程：A tutorial on statistical-learning for scientific data processing，其中包括统计学习、监督学习、模型选择和无监督学习等若干部分，内容覆盖全面，讲解细致，并且使用了真实的数据、代码和图表。 另外，教程中还调用了与文本相关的样例，例如下图所示的四个不同SVM分类器的比较。 这里需要指出的是，虽然运行Scikit-learn官方给出的样例后通常都能得到一致的结果，但大多数情况下系统都会抛出警告信息。作者认为抛出警告信息的原因来自两个方面：一是苹果vecLib框架本身对Scikit-learn支持不好（作者用的是MacOS），二是样例中使用的Python版本可能是早期的版本，而实际运行中是最新的版本。例如下图中是使用Python 2.7.10版本抛出的警告信息，而Scikit-learn官方页面上并没有出现。 总体上来说，作为专门面向机器学习的Python开源框架，Scikit-learn可以在一定范围内为开发者提供非常好的帮助。它内部实现了各种各样成熟的算法，容易安装和使用，样例丰富，而且教程和文档也非常详细。 另一方面，Scikit-learn也有缺点。例如它不支持深度学习和强化学习，这在今天已经是应用非常广泛的技术，例如准确的图像分类和可靠的实时语音识别和语义理解等。此外，它也不支持图模型和序列预测，不支持Python之外的语言，不支持PyPy，也不支持GPU加速。 看到这里可能会有人担心Scikit-learn的性能表现，这里需要指出的是：如果不考虑多层神经网络的相关应用，Scikit-learn的性能表现是非常不错的。究其原因，一方面是因为其内部算法的实现十分高效，另一方面或许可以归功于Cython编译器：通过Cython在Scikit-learn框架内部生成C语言代码的运行方式，Scikit-learn消除了大部分的性能瓶颈。 应该明确的一点是：虽然概括地说Scikit-learn并不适合深度学习问题，但对于某些特殊场景而言，使用Scikit-learn仍然是明智的选择。例如要创建连接不同对象的预测函数时，或者在未标记的数据集中为了训练模型对不同的对象进行分类时，面对这些场景Scikit-learn只通过普通的旧机器学习模型就能很好地解决，而并不需要建立数十层的复杂神经网络。 就好像喜欢Scala语言的人会选择Spark ML，喜欢绘制图表和偶尔编写少量Python/R语言代码的人会选择微软Cortana和Azure一样，对于那些Python语言的死忠粉而言，Scikit-learn可能是各种机器学习库中的最好选择。雷锋网(公众号：雷锋网)雷锋网 来源：infoworld，雷锋网编译 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Scikit","slug":"Scikit","permalink":"http://ipcreator.me/tags/Scikit/"}]},{"title":"大数据/数据挖掘/推荐系统/机器学习相关资源","date":"2017-02-18T04:23:06.000Z","path":"2017/02/18/Program/TensorFlow/big-data-resources/","text":"作者：Zhe Yu/Flowerowl 大数据/数据挖掘/推荐系统/机器学习相关资源 Share my personal resources 书籍 各种书~各种ppt~更新中~ https://pan.baidu.com/s/1c1Xp6Pa机器学习经典书籍小结 http://www.cnblogs.com/snake-hand/archive/2013/06/10/3131145.html机器学习&amp;深度学习经典资料汇总 http://www.thebigdata.cn/JiShuBoKe/13299.html 视频 浙大数据挖掘系列 http://v.youku.com/v_show/id_XNTgzNDYzMjg=.html?f=2740765用Python做科学计算 http://www.tudou.com/listplay/fLDkg5e1pYM.htmlR语言视频 http://pan.baidu.com/s/1koSpZHadoop视频 http://pan.baidu.com/s/1b1xYd42区 . 技术 . 创业 . 第二讲 http://v.youku.com/v_show/id_XMzAyMDYxODUy.html加州理工学院公开课：机器学习与数据挖掘 http://v.163.com/special/opencourse/learningfromdata.htmlWilliam Huang教授–BI和数据挖掘技术 https://www.youtube.com/watch?v=gPm8SOJ1NaoJingyuan Wang王静远-北航-机器学习工具在城市数据分析中的应用https://www.youtube.com/watch?v=H2_BATE8uokTensor Flow 介紹 (1/2)https://www.youtube.com/watch?v=jA4Bh-xj_mETensor Flow 介紹 (2/2)https://www.youtube.com/watch?v=YUCsOgkFqpk 课程 机器学习 Machine Learning Stanford University https://www.coursera.org/learn/machine-learning機器學習基石 (Machine Learning Foundations) National Taiwan University https://www.coursera.org/course/ntumlone 会议 数据挖掘 ACM SigKDD http://www.kdd.orgICDM http://icdm2015.stonybrook.edu/SIAM http://www.siam.org/ QQ群 机器学习&amp;模式识别 246159753数据挖掘机器学习 236347059推荐系统 274750470 Github 推荐系统 推荐系统开源软件列表汇总和评点 http://in.sdo.com/?p=1707Mrec(Python) https://github.com/mendeley/mrecCrab(Python) https://github.com/muricoca/crabPython-recsys(Python) https://github.com/ocelma/python-recsysCofiRank(C++) https://github.com/markusweimer/cofirankGraphLab(C++) https://github.com/graphlab-code/graphlabEasyRec(Java) https://github.com/hernad/easyrecLenskit(Java) https://github.com/grouplens/lenskitMahout(Java) https://github.com/apache/mahoutRecommendable(Ruby) https://github.com/davidcelis/recommendable 库 NLTK https://github.com/nltk/nltkPattern https://github.com/clips/patternPyrallel https://github.com/pydata/pyrallelTheano https://github.com/Theano/TheanoPylearn2 https://github.com/lisa-lab/pylearn2TextBlob https://github.com/sloria/TextBlobMBSP https://github.com/clips/MBSPGensim https://github.com/piskvorky/gensimLangid.py https://github.com/saffsd/langid.pyJieba https://github.com/fxsjy/jiebaxTAS https://github.com/NLeSC/xtasNumPy https://github.com/numpy/numpySciPy https://github.com/scipy/scipyMatplotlib https://github.com/matplotlib/matplotlibscikit-learn https://github.com/scikit-learn/scikit-learnPandas https://github.com/pydata/pandasMDP http://mdp-toolkit.sourceforge.net/PyBrain https://github.com/pybrain/pybrainPyML http://pyml.sourceforge.net/Milk https://github.com/luispedro/milkPyMVPA https://github.com/PyMVPA/PyMVPATensorFlow https://github.com/tensorflow/tensorflow 博客 周涛 http://blog.sciencenet.cn/home.php?mod=space&amp;uid=3075Greg Linden http://glinden.blogspot.com/ Marcel Caraciolo http://aimotion.blogspot.com/RsysChina http://weibo.com/p/1005051686952981推荐系统人人小站 http://zhan.renren.com/recommendersystem阿稳 http://www.wentrue.net梁斌 http://weibo.com/pennyliang刁瑞 http://diaorui.netguwendong http://www.guwendong.comxlvector http://xlvector.net懒惰啊我 http://www.cnblogs.com/flclain/free mind http://blog.pluskid.org/lovebingkuai http://lovebingkuai.diandian.com/LeftNotEasy http://www.cnblogs.com/LeftNotEasyLSRS 2013 http://graphlab.org/lsrs2013/program/ Google小组 https://groups.google.com/forum/#!forum/resysJournal of Machine Learning Research http://jmlr.org/在线的机器学习社区 http://www.52ml.net/16336.html清华大学信息检索组 http://www.thuir.cn我爱自然语言处理 http://www.52nlp.cn/数据挖掘与数据分析http://spss-market.r.blog.163.com/ 文章 心中永远的正能量 http://blog.csdn.net/yunlong34574机器学习最佳入门学习资料汇总 http://article.yeeyan.org/view/22139/410514Books for Machine Learning with R http://www.52ml.net/16312.html是什么阻碍了你的机器学习目标？ http://www.52ml.net/16436.htm推荐系统初探 http://yongfeng.me/attach/rs-survey-zhang-slices.pdf推荐系统中协同过滤算法若干问题的研究 http://pan.baidu.com/s/1bnjDBYZNetflix 推荐系统：第一部分 http://blog.csdn.net/bornhe/article/details/8222450Netflix 推荐系统：第二部分 http://blog.csdn.net/bornhe/article/details/8222497探索推荐引擎内部的秘密 http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html推荐系统resys小组线下活动见闻2009-08-22 http://www.tuicool.com/articles/vUvQVnRecommendation Engines Seminar Paper, Thomas Hess, 2009: 推荐引擎的总结性文章 http://www.slideshare.net/antiraum/recommender-engines-seminar-paperToward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions, Adomavicius, G.; Tuzhilin, A., 2005 http://dl.acm.org/citation.cfm?id=1070751A Taxonomy of RecommenderAgents on the Internet, Montaner, M.; Lopez, B.; de la Rosa, J. L., 2003 http://www.springerlink.com/index/KK844421T5466K35.pdfA Course in Machine Learning http://ciml.info/基于mahout构建社会化推荐引擎 http://www.doc88.com/p-745821989892.html个性化推荐技术漫谈 http://blog.csdn.net/java060515/archive/2007/04/19/1570243.aspxDesign of Recommender System http://www.slideshare.net/rashmi/design-of-recommender-systemsHow to build a recommender system http://www.slideshare.net/blueace/how-to-build-a-recommender-system-presentation推荐系统架构小结 http://blog.csdn.net/idonot/article/details/7996733System Architectures for Personalization and Recommendation http://techblog.netflix.com/2013/03/system-architectures-for.htmlThe Netflix Tech Blog http://techblog.netflix.com/百分点推荐引擎——从需求到架构http://www.infoq.com/cn/articles/baifendian-recommendation-engine推荐系统 在InfoQ上的内容 http://www.infoq.com/cn/recommend推荐系统实时化的实践和思考 http://www.infoq.com/cn/presentations/recommended-system-real-time-practice-thinking质量保证的推荐实践 http://www.infoq.com/cn/news/2013/10/testing-practice/ 推荐系统的工程挑战 http://www.infoq.com/cn/presentations/Recommend-system-engineering社会化推荐在人人网的应用 http://www.infoq.com/cn/articles/zyy-social-recommendation-in-renren/利用20%时间开发推荐引擎 http://www.infoq.com/cn/presentations/twenty-percent-time-to-develop-recommendation-engine使用Hadoop和 Mahout实现推荐引擎 http://www.jdon.com/44747SVD 简介 http://www.cnblogs.com/FengYan/archive/2012/05/06/2480664.htmlNetflix推荐系统：从评分预测到消费者法则 http://blog.csdn.net/lzt1983/article/details/7696578关于数据挖掘学习的讨论https://www.zhihu.com/question/20751219 论文 《推荐系统实战》引用 P1A Guide to Recommender System P4Cross Selling P6课程：Data Mining and E-Business: The Social Data Revolution P7)An Introduction to Search Engines and Web Navigation p7 p8p9(The Youtube video recommendation system) p9 (PPT: Music Recommendation and Discovery) p12P13 (Digg Recommendation Engine Updates) P16(The Learning Behind Gmail Priority Inbox)p17 (Accurate is not always good: How Accuracy Metrics have hurt Recommender Systems) P20(Don’t Look Stupid: Avoiding Pitfalls when Recommending Research Papers)P23 (Major componets of the gravity recommender system) P25(What is a Good Recomendation Algorithm?) P26(Evaluation Recommendation Systems) P27 (Music Recommendation and Discovery in the Long Tail) P29 (Internation Workshop on Novelty and Diversity in Recommender Systems) p29(Auralist: Introducing Serendipity into Music Recommendation ) P30 (Metrics for evaluating the serendipity of recommendation lists) P30(The effects of transparency on trust in and acceptance of a content-based art recommender) P31 (Trust-aware recommender systems) P31(Tutorial on robutness of recommender system) P32(Five Stars Dominate Ratings) P37 (Book-Crossing Dataset) P38 (Lastfm Dataset) P39 浅谈网络世界的Power Law现象 P39 (MovieLens Dataset) P42(Empirical Analysis of Predictive Algorithms for Collaborative Filtering) P49(Digg Vedio) P50(Amazon.com Recommendations Item-to-Item Collaborative Filtering) P59 (Greg Linden Blog) P63(One-Class Collaborative Filtering) P67(Stochastic Gradient Descent) P68 (Latent Factor Models for Web Recommender Systems) P70 (Bipatite Graph) P73(Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation) P74(Topic Sensitive Pagerank) P74 (FAST ALGORITHMS FOR SPARSE MATRIX INVERSE COMPUTATIONS) P77(LIFESTYLE FINDER: Intelligent User Profiling Using Large-Scale Demographic Data) P80( adaptive bootstrapping of recommender systems using decision trees) P87 (Vector Space Model) P90(冷启动问题的比赛) P92(Latent Dirichlet Allocation) P92(Kullback–Leibler divergence) P93(About The Music Genome Project) P94(Pandora Music Genome Project Attributes) P94(Jinni Movie Genome) P94 (Tagsplanations: Explaining Recommendations Using Tags) P96(Tag Wikipedia) P96(Nurturing Tagging Communities) P100(Why We Tag: Motivations for Annotation in Mobile and Online Media ) P100(Delicious Dataset) P101(Finding Advertising Keywords on Web Pages) P118(基于标签的推荐系统比赛) P119(Tag recommendations based on tensor dimensionality reduction）P119(latent dirichlet allocation for tag recommendation) P119(Folkrank: A ranking algorithm for folksonomies) P119 (Tagommenders: Connecting Users to Items through Tags) P119 (The Quest for Quality Tags) P120(Challenge on Context-aware Movie Recommendation) P123(The Lifespan of a link) P125(Temporal Diversity in Recommender Systems) P129(Evaluating Collaborative Filtering Over Time) P129(Hotpot) P139 (Google Launches Hotpot, A Recommendation Engine for Places) P139 (geolocated recommendations) P140(A Peek Into Netflix Queues) P141(Distance Browsing in Spatial Databases1) P142(Efﬁcient Evaluation of k-Range Nearest Neighbor Queries in Road Networks) P143(Global Advertising: Consumers Trust Real Friends and Virtual Strangers the Most) P144 (Suggesting Friends Using the Implicit Social Graph) P145(Friends &amp; Frenemies: Why We Add and Remove Facebook Friends) P147(Stanford Large Network Dataset Collection) P149 (Workshop on Context-awareness in Retrieval and Recommendation) P151(Factorization vs. Regularization: Fusing Heterogeneous Social Relationships in Top-N Recommendation) P153 (Twitter, an Evolving Architecture) P154(Recommendations in taste related domains) P155(Comparing Recommendations Made by Online Systems and Friends) P155 (EdgeRank: The Secret Sauce That Makes Facebook’s News Feed Tick) P157(Speak Little and Well: Recommending Conversations in Online Social Streams) P158(Learn more about “People You May Know”) P160(“Make New Friends, but Keep the Old” – Recommending People on Social Networking Sites) P164 (SoRec: Social Recommendation Using Probabilistic Matrix) P165 (A Dynamic Bayesian Network Click Model for Web Search Ranking) P177(Online Learning from Click Data for Sponsored Search) P177(Contextual Advertising by Combining Relevance with Click Feedback) P177 (Hulu 推荐系统架构) P178(MyMedia Project) P178(item-based collaborative filtering recommendation algorithms) P185(Learning Collaborative Information Filters) P186 (Simon Funk Blog:Funk SVD) P187 (Factor in the Neighbors: Scalable and Accurate Collaborative Filtering) P190 (Time-dependent Models in Collaborative Filtering based Recommender System) P193 (Collaborative filtering with temporal dynamics) P193(Least Squares Wikipedia) P195(Improving regularized singular value decomposition for collaborative filtering) P195(Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model) P195 【CIKM 2012 Best Stu Paper】Incorporating Occupancy into Frequent Pattern Mini.pdf 【CIKM 2012 poster】A Latent Pairwise Preference Learning Approach for Recomme.pdf 【CIKM 2012 poster】An Effective Category Classification Method Based on a Lan.pdf 【CIKM 2012 poster】Learning to Rank for Hybrid Recommendation.pdf 【CIKM 2012 poster】Learning to Recommend with Social Relation Ensemble.pdf 【CIKM 2012 poster】Maximizing Revenue from Strategic Recommendations under De.pdf 【CIKM 2012 poster】On Using Category Experts for Improving the Performance an.pdf 【CIKM 2012 poster】Relation Regularized Subspace Recommending for Related Sci.pdf 【CIKM 2012 poster】Top-N Recommendation through Belief Propagation.pdf 【CIKM 2012 poster】Twitter Hyperlink Recommendation with User-Tweet-Hyperlink.pdf 【CIKM 2012 short】Automatic Query Expansion Based on Tag Recommendation.pdf 【CIKM 2012 short】Graph-Based Workflow Recommendation- On Improving Business .pdf 【CIKM 2012 short】Location-Sensitive Resources Recommendation in Social Taggi.pdf 【CIKM 2012 short】More Than Relevance- High Utility Query Recommendation By M.pdf 【CIKM 2012 short】PathRank- A Novel Node Ranking Measure on a Heterogeneous G.pdf 【CIKM 2012 short】PRemiSE- Personalized News Recommendation via Implicit Soci.pdf 【CIKM 2012 short】Query Recommendation for Children.pdf 【CIKM 2012 short】The Early-Adopter Graph and its Application to Web-Page Rec.pdf 【CIKM 2012 short】Time-aware Topic Recommendation Based on Micro-blogs.pdf 【CIKM 2012 short】Using Program Synthesis for Social Recommendations.pdf 【CIKM 2012】A Decentralized Recommender System for Effective Web Credibility .pdf 【CIKM 2012】A Generalized Framework for Reciprocal Recommender Systems.pdf 【CIKM 2012】Dynamic Covering for Recommendation Systems.pdf 【CIKM 2012】Efficient Retrieval of Recommendations in a Matrix Factorization .pdf 【CIKM 2012】Exploring Personal Impact for Group Recommendation.pdf 【CIKM 2012】LogUCB- An Explore-Exploit Algorithm For Comments Recommendation.pdf 【CIKM 2012】Metaphor- A System for Related Search Recommendations.pdf 【CIKM 2012】Social Contextual Recommendation.pdf 【CIKM 2012】Social Recommendation Across Multiple Relational Domains.pdf 【COMMUNICATIONS OF THE ACM】Recommender Systems.pdf 【ICDM 2012 short___】Multiplicative Algorithms for Constrained Non-negative M.pdf 【ICDM 2012 short】Collaborative Filtering with Aspect-based Opinion Mining- A.pdf 【ICDM 2012 short】Learning Heterogeneous Similarity Measures for Hybrid-Recom.pdf 【ICDM 2012 short】Mining Personal Context-Aware Preferences for Mobile Users.pdf 【ICDM 2012】Link Prediction and Recommendation across Heterogenous Social Networks.pdf 【IEEE Computer Society 2009】Matrix factorization techniques for recommender .pdf 【IEEE Consumer Communications and Networking Conference 2006】FilmTrust movie.pdf 【IEEE Trans on Audio, Speech and Laguage Processing 2010】Personalized music .pdf 【IEEE Transactions on Knowledge and Data Engineering 2005】Toward the next ge.pdf 【INFOCOM 2011】Bayesian-inference Based Recommendation in Online Social Network.pdf 【KDD 2009】Learning optimal ranking with tensor factorization for tag recomme.pdf 【SIGIR 2009】Learning to Recommend with Social Trust Ensemble.pdf 【SIGIR 2012】Adaptive Diversification of Recommendation Results via Latent Fa.pdf 【SIGIR 2012】Collaborative Personalized Tweet Recommendation.pdf 【SIGIR 2012】Dual Role Model for Question Recommendation in Community Questio.pdf 【SIGIR 2012】Exploring Social Influence for Recommendation - A Generative Mod.pdf 【SIGIR 2012】Increasing Temporal Diversity with Purchase Intervals.pdf 【SIGIR 2012】Learning to Rank Social Update Streams.pdf 【SIGIR 2012】Personalized Click Shaping through Lagrangian Duality for Online.pdf 【SIGIR 2012】Predicting the Ratings of Multimedia Items for Making Personaliz.pdf 【SIGIR 2012】TFMAP-Optimizing MAP for Top-N Context-aware Recommendation.pdf 【SIGIR 2012】What Reviews are Satisfactory- Novel Features for Automatic Help.pdf 【SIGKDD 2012】 A Semi-Supervised Hybrid Shilling Attack Detector for Trustwor.pdf 【SIGKDD 2012】 RecMax- Exploiting Recommender Systems for Fun and Profit.pdf 【SIGKDD 2012】Circle-based Recommendation in Online Social Networks.pdf 【SIGKDD 2012】Cross-domain Collaboration Recommendation.pdf 【SIGKDD 2012】Finding Trending Local Topics in Search Queries for Personaliza.pdf 【SIGKDD 2012】GetJar Mobile Application Recommendations with Very Sparse Datasets.pdf 【SIGKDD 2012】Incorporating Heterogenous Information for Personalized Tag Rec.pdf 【SIGKDD 2012】Learning Personal+Social Latent Factor Model for Social Recomme.pdf 【VLDB 2012】Challenging the Long Tail Recommendation.pdf 【VLDB 2012】Supercharging Recommender Systems using Taxonomies for Learning U.pdf 【WWW 2012 Best paper】Build Your Own Music Recommender by Modeling Internet R.pdf 【WWW 2013】A Personalized Recommender System Based on User’s Informatio.pdf 【WWW 2013】Diversified Recommendation on Graphs-Pitfalls, Measures, and Algorithms.pdf 【WWW 2013】Do Social Explanations Work-Studying and Modeling the Effects of S.pdf 【WWW 2013】Generation of Coalition Structures to Provide Proper Groups’.pdf 【WWW 2013】Learning to Recommend with Multi-Faceted Trust in Social Networks.pdf 【WWW 2013】Multi-Label Learning with Millions of Labels-Recommending Advertis.pdf 【WWW 2013】Personalized Recommendation via Cross-Domain Triadic Factorization.pdf 【WWW 2013】Profile Deversity in Search and Recommendation.pdf 【WWW 2013】Real-Time Recommendation of Deverse Related Articles.pdf 【WWW 2013】Recommendation for Online Social Feeds by Exploiting User Response.pdf 【WWW 2013】Recommending Collaborators Using Keywords.pdf 【WWW 2013】Signal-Based User Recommendation on Twitter.pdf 【WWW 2013】SoCo- A Social Network Aided Context-Aware Recommender System.pdf 【WWW 2013】Tailored News in the Palm of Your HAND-A Multi-Perspective Transpa.pdf 【WWW 2013】TopRec-Domain-Specific Recommendation through Community Topic Mini.pdf 【WWW 2013】User’s Satisfaction in Recommendation Systems for Groups-an .pdf 【WWW 2013】Using Link Semantics to Recommend Collaborations in Academic Socia.pdf 【WWW 2013】Whom to Mention-Expand the Diffusion of Tweets by @ Recommendation.pdf Recommender+Systems+Handbook.pdf tutorial.pdf 各个领域的推荐系统 图书 Amazon豆瓣读书当当网 新闻 Google NewsGenieoGetprismatic http://getprismatic.com/ 电影 NetflixJinniMovieLensRotten TomatoesFlixsterMTime 音乐 豆瓣电台LastfmPandoraMufinLalaEMusicPing虾米电台Jing.FM 视频 YoutubeHuluClciker 文章 CiteULikeGoogle ReaderStumbleUpon 旅游 WanderflyTripAdvisor 社会网络 FacebookTwitter 综合 AmazonGetGlueStrandsHunch 欢迎贡献资源~~待续","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://ipcreator.me/tags/Big-Data/"},{"name":"Data Mining","slug":"Data-Mining","permalink":"http://ipcreator.me/tags/Data-Mining/"}]},{"title":"Python 资源大全中文版","date":"2017-02-18T01:02:06.000Z","path":"2017/02/18/Program/Python/tools-of-python/","text":"作者：litai wong/wangaicc 我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-python 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。 Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。 我们要做什么？ 基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。 整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容： 《Scrapy：Python的爬虫框架》 《Flask：一个使用Python编写的轻量级Web应用框架》 如何参与本项目？从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。 不过加入前，有几个小要求： 英文还不错，能读懂英文并用自己的话复述； 在用 Python； 如有兴趣，请加 QQ：50872495。加 Q 时请注明「Python大全」 本项目的参与者 维护者： 贡献者：艾凌风、Namco、Daetalus、黄利民、atupal、rainbow、木头lbj 注：名单不分排名，不定期补充更新 奖励计划虽然奖励可能并不是你加入的主要原因，但还是有必要提一下： 整理超过 20 个资源后，可在伯乐在线上开通打赏； 每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品； 奖励详情 环境管理管理 Python 版本和环境的工具 p：非常简单的交互式 python 版本管理工具。官网 pyenv：简单的 Python 版本管理工具。官网 Vex：可以在虚拟环境中执行命令。官网 virtualenv：创建独立 Python 环境的工具。官网 virtualenvwrapper：virtualenv 的一组扩展。官网 包管理管理包和依赖的工具。 pip：Python 包和依赖关系管理工具。官网 pip-tools：保证 Python 包依赖关系更新的一组工具。官网 conda：跨平台，Python 二进制包管理工具。官网 Curdling：管理 Python 包的命令行工具。官网 wheel：Python 分发的新标准，意在取代 eggs。官网 包仓库本地 PyPI 仓库服务和代理。 warehouse：下一代 PyPI。官网 Warehouse：PyPA 提供的 PyPI 镜像工具。官网 bandersnatch devpi：PyPI 服务和打包/测试/分发工具。官网 localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。官网 分发打包为可执行文件以便分发。 PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。官网 dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。官网 Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。官网 py2app：将 Python 脚本变为独立软件包（Mac OS X）。官网 py2exe：将 Python 脚本变为独立软件包（Windows）。官网 pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python本身。官网 构建工具将源码编译成软件。 buildout：一个构建系统，从多个组件来创建，组装和部署应用。官网 BitBake：针对嵌入式 Linux 的类似 make 的构建工具。官网 fabricate：对任何语言自动找到依赖关系的构建工具。官网 PlatformIO：多平台命令行构建工具。官网 PyBuilder：纯 Python 实现的持续化构建工具。官网 SCons：软件构建工具。官网 交互式解析器交互式 Python 解析器。 IPython：功能丰富的工具，非常有效的使用交互式 Python。官网 bpython：界面丰富的 Python 解析器。官网 ptpython：高级交互式Python解析器， 构建于python-prompt-toolkit 之上。官网 文件文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。 imghdr：（Python 标准库）检测图片类型。官网 mimetypes：（Python 标准库）将文件名映射为 MIME 类型。官网 path.py：对 os.path 进行封装的模块。官网 pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。官网 python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。官网 Unipath：用面向对象的方式操作文件和目录。官网 watchdog：管理文件系统事件的 API 和 shell 工具官网 日期和时间操作日期和时间的类库。 arrow：更好的 Python 日期时间操作类库。官网 Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。官网 dateutil：Python datetime 模块的扩展。官网 delorean：解决 Python 中有关日期处理的棘手问题的库。官网 moment：一个用来处理时间和日期的Python库。灵感来自于Moment.js。官网 PyTime：一个简单易用的Python模块，用于通过字符串来操作日期/时间。官网 pytz：现代以及历史版本的世界时区定义。将时区数据库引入Python。官网 when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。官网 文本处理用于解析和操作文本的库。 通用 chardet：字符编码检测器，兼容 Python2 和 Python3。官网 difflib：(Python 标准库)帮助我们进行差异化比较。官网 ftfy：让Unicode文本更完整更连贯。官网 fuzzywuzzy：模糊字符串匹配。官网 Levenshtein：快速计算编辑距离以及字符串的相似度。官网 pangu.py：在中日韩语字符和数字字母之间添加空格。官网 yfiglet-figlet：pyfiglet -figlet 的 Python实现。 shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。官网 unidecode：Unicode 文本的 ASCII 转换形式 。官网 uniout：打印可读的字符，而不是转义的字符串。官网 xpinyin：一个用于把汉字转换为拼音的库。官网 Slug化 awesome-slugify：一个 Python slug 化库，可以保持 Unicode。官网 python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。官网 unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。官网 解析器 phonenumbers：解析，格式化，储存，验证电话号码。官网 PLY：lex 和 yacc 解析工具的 Python 实现。官网 Pygments：通用语法高亮工具。官网 pyparsing：生成通用解析器的框架。官网 python-nameparser：把一个人名分解为几个独立的部分。官网 python-user-agents：浏览器 user agent 解析器。官网 sqlparse：一个无验证的 SQL 解析器。官网 特殊文本格式处理一些用来解析和操作特殊文本格式的库。 通用 tablib：一个用来处理中表格数据的模块。官网 Office Marmir：把输入的Python 数据结构转换为电子表单。官网 openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。官网 python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。官网 unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。官网 XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。官网 xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。官网 xlwt：读写 Excel 文件的数据和格式信息。官网 / xlrd relatorio：模板化OpenDocument 文件。官网 PDF PDFMiner：一个用于从PDF文档中抽取信息的工具。官网 PyPDF2：一个可以分割，合并和转换 PDF 页面的库。官网 ReportLab：快速创建富文本 PDF 文档。官网 Markdown Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。官网 Python-Markdown：John Gruber’s Markdown 的 Python 版实现。官网 YAML PyYAML：Python 版本的 YAML 解析器。官网 CSV csvkit：用于转换和操作 CSV 的工具。官网 Archive unp：一个用来方便解包归档文件的命令行工具。官网 自然语言处理用来处理人类语言的库。 NLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。官网 jieba：中文分词工具。官网 langid.py：独立的语言识别系统。官网 Pattern：Python 网络信息挖掘模块。官网 SnowNLP：一个用来处理中文文本的库。官网 TextBlob：为进行普通自然语言处理任务提供一致的 API。官网 TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。官网 文档用以生成项目文档的库。 Sphinx：Python 文档生成器。官网 awesome-sphinxdoc：官网 MkDocs：对 Markdown 友好的文档生成器。官网 pdoc：一个可以替换Epydoc 的库，可以自动生成 Python 库的 API 文档。官网 Pycco：文学编程（literate-programming）风格的文档生成器。官网 配置用来保存和解析配置的库。 config：logging 模块作者写的分级配置模块。官网 ConfigObj：INI 文件解析器，带验证功能。官网 ConfigParser：(Python 标准库) INI 文件解析器。官网 profig：通过多种格式进行配置，具有数值转换功能。官网 python-decouple：将设置和代码完全隔离。官网 命令行工具用于创建命令行程序的库。 命令行程序开发 cement：Python 的命令行程序框架。官网 click：一个通过组合的方式来创建精美命令行界面的包。官网 cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。官网 clint：Python 命令行程序工具。官网 colorama：跨平台彩色终端文本。官网 docopt：Python 风格的命令行参数解析器。官网 Gooey：一条命令，将命令行程序变成一个 GUI 程序。官网 python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。官网 Pythonpy：在命令行中直接执行任何Python指令。官网 生产力工具 aws-cli：Amazon Web Services 的通用命令行界面。官网 bashplotlib：在终端中进行基本绘图。官网 caniusepython3：判断是哪个项目妨碍你你移植到 Python 3。官网 cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。官网 doitlive：一个用来在终端中进行现场演示的工具。官网 howdoi：通过命令行获取即时的编程问题解答。官网 httpie：一个命令行HTTP 客户端，cURL 的替代品，易用性更好。官网 PathPicker：从bash输出中选出文件。官网 percol：向UNIX shell 传统管道概念中加入交互式选择功能。官网 SAWS：一个加强版的 AWS 命令行。官网 thefuck：修正你之前的命令行指令。官网 mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。官网 pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。官网 下载器用来进行下载的库. s3cmd：一个用来管理Amazon S3 和 CloudFront 的命令行工具。官网 s4cmd：超级 S3 命令行工具，性能更加强劲。官网 you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。官网 youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。官网 图像处理用来操作图像的库. pillow：Pillow 是一个更加易用版的 PIL。官网 hmap：图像直方图映射。官网 imgSeek：一个使用视觉相似性搜索一组图片集合的项目。官网 nude.py：裸体检测。官网 pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。官网 pygram：类似 Instagram 的图像滤镜。官网 python-qrcode：一个纯 Python 实现的二维码生成器。官网 Quads：基于四叉树的计算机艺术。官网 scikit-image：一个用于（科学）图像处理的 Python 库。官网 thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。官网 wand：MagickWand的Python 绑定。MagickWand 是 ImageMagick的 C API 。官网 OCR光学字符识别库。 pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。官网 pytesseract：Google Tesseract OCR 的另一个封装(wrapper)。官网 python-tesseract - Google Tesseract OCR 的一个包装类。 音频用来操作音频的库 audiolazy：Python 的数字信号处理包。官网 audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。官网 beets：一个音乐库管理工具及 MusicBrainz 标签添加工具官网 dejavu：音频指纹提取和识别官网 django-elastic-transcoder：Django + Amazon Elastic Transcoder。官网 eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。官网 id3reader：一个用来读取 MP3 元数据的 Python 模块。官网 m3u8：一个用来解析 m3u8 文件的模块。官网 mutagen：一个用来处理音频元数据的 Python 模块。官网 pydub：通过简单、简洁的高层接口来操作音频文件。官网 pyechonest：Echo Nest API 的 Python 客户端官网 talkbox：一个用来处理演讲/信号的 Python 库官网 TimeSide：开源 web 音频处理框架。官网 tinytag：一个用来读取MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。官网 mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。官网 Video用来操作视频和GIF的库。 moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。官网 scikit-video：SciPy 视频处理常用程序。官网 地理位置地理编码地址以及用来处理经纬度的库。 GeoDjango：世界级地理图形 web 框架。官网 GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。官网 geojson：GeoJSON 的 Python 绑定及工具。官网 geopy：Python 地址编码工具箱。官网 pygeoip：纯 Python GeoIP API。官网 django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。官网 HTTP使用HTTP的库。 requests：人性化的HTTP请求库。官网 grequests：requests 库 + gevent ，用于异步 HTTP 请求.官网 httplib2：全面的 HTTP 客户端库。官网 treq：类似 requests 的Python API 构建于 Twisted HTTP 客户端之上。官网 urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。官网 数据库Python实现的数据库。 pickleDB：一个简单，轻量级键值储存数据库。官网 PipelineDB：流式 SQL 数据库。官网 TinyDB：一个微型的，面向文档型数据库。官网 ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。官网 数据库驱动用来连接和操作数据库的库。 ySQL：awesome-mysql系列 mysql-python：Python 的 MySQL 数据库连接器。官网 ysqlclient：mysql-python 分支，支持 Python 3。 oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs.官网 PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。官网 PostgreSQL psycopg2：Python 中最流行的 PostgreSQL 适配器。官网 queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。官网 txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。官网 其他关系型数据库 apsw：另一个 Python SQLite封装。官网 dataset：在数据库中存储Python字典 pymssql：一个简单的Microsoft SQL Server数据库接口。官网 NoSQL 数据库 cassandra-python-driver：Cassandra 的 Python 驱动。官网 HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。官网 Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。官网 py2neo：Neo4j restful 接口的Python 封装客户端。官网 pycassa：Cassandra 的 Python Thrift 驱动。官网 PyMongo：MongoDB 的官方 Python 客户端。官网 redis-py：Redis 的 Python 客户端。官网 telephus：基于 Twisted 的 Cassandra 客户端。官网 txRedis：基于 Twisted 的 Redis 客户端。官网 ORM实现对象关系映射或数据映射技术的库。 关系型数据库 Django Models：Django 的一部分。官网 SQLAlchemy：Python SQL 工具以及对象关系映射工具。官网 awesome-sqlalchemy系列 Peewee：一个小巧，富有表达力的 ORM。官网 PonyORM：提供面向生成器的 SQL 接口的 ORM。官网 python-sql：编写 Python 风格的 SQL 查询。官网 NoSQL 数据库 django-mongodb-engine：Django MongoDB 后端。官网 PynamoDB：Amazon DynamoDB 的一个 Python 风格接口。官网 flywheel：Amazon DynamoDB 的对象映射工具。官网 MongoEngine：一个Python 对象文档映射工具，用于 MongoDB。官网 hot-redis：为 Redis 提供 Python 丰富的数据类型。官网 redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。官网 其他 butterdb：Google Drive 电子表格的 Python ORM。官网 Web 框架全栈 Web 框架。 Django：Python 界最流行的 web 框架。官网 awesome-django系列 Flask：一个 Python 微型框架。官网 awesome-flask系列 yramid：一个小巧，快速，接地气的开源Python web 框架。 awesome-pyramid系列 Bottle：一个快速小巧，轻量级的 WSGI 微型 web 框架。官网 CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有WSGI 线程池。官网 TurboGears：一个可以扩展为全栈解决方案的微型框架。官网 web.py：一个 Python 的 web 框架，既简单，又强大。官网 web2py：一个全栈 web 框架和平台，专注于简单易用。官网 Tornado：一个web 框架和异步网络库。官网 权限允许或拒绝用户访问数据或功能的库。 Carteblanche：Module to align code with thoughts of users and designers. Also magically handles navigation and permissions.官网 django-guardian：Django 1.2+ 实现了单个对象权限。官网 django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。官网 CMS内容管理系统 django-cms：一个开源的，企业级 CMS，基于 Django。官网 djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。官网 FeinCMS：基于 Django 构建的最先进的内容管理系统之一。官网 Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。官网 Mezzanine：一个强大的，持续的，灵活的内容管理平台。官网 Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。官网 Plone：一个构建于开源应用服务器 Zope 之上的 CMS。官网 Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。官网 Wagtail：一个 Django 内容管理系统。官网 Widgy：最新的 CMS 框架，基于 Django。官网 电子商务用于电子商务以及支付的框架和库。 django-oscar：一个用于 Django 的开源的电子商务框架。官网 django-shop：一个基于 Django 的店铺系统。官网 Cartridge：一个基于 Mezzanine 构建的购物车应用。官网 shoop：一个基于 Django 的开源电子商务平台。官网 alipay：非官方的 Python 支付宝 API。官网 merchant：一个可以接收来自多种支付平台支付的 Django 应用。官网 money：货币类库with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.官网 python-currencies：显示货币格式以及它的数值。官网 RESTful API用来开发RESTful APIs的库 Django django-rest-framework：一个强大灵活的工具，用来构建 web API。官网 django-tastypie：为Django 应用开发API。官网 django-formapi：为 Django 的表单验证，创建 JSON APIs 。官网 Flask flask-api：为 flask 开发的，可浏览 Web APIs 。官网 flask-restful：为 flask 快速创建REST APIs 。官网 flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。官网 flask-api-utils：为 Flask 处理 API 表示和验证。官网 eve：REST API 框架，由 Flask, MongoDB 等驱动。官网 Pyramid cornice：一个Pyramid 的 REST 框架 。官网 与框架无关的 falcon：一个用来建立云 API 和 web app 后端的噶性能框架。官网 sandman：为现存的数据库驱动系统自动创建 REST APIs 。官网 restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。官网 ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。官网 验证实现验证方案的库。 OAuth Authomatic：简单但是强大的框架，身份验证/授权客户端。官网 django-allauth：Django 的验证应用。官网 django-oauth-toolkit：为 Django 用户准备的 OAuth2。官网 django-oauth2-provider：为 Django 应用提供 OAuth2 接入。官网 Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。官网 OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。官网 python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。官网 python-social-auth：一个设置简单的社会化验证方式。官网 rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。官网 sanction：一个超级简单的OAuth2 客户端实现。官网 其他 jose：JavaScript 对象签名和加密草案的实现。官网 PyJWT：JSON Web 令牌草案 01。官网 python-jws：JSON Web 签名草案 02 的实现。官网 python-jwt：一个用来生成和验证 JSON Web 令牌的模块。官网 模板引擎模板生成和词法解析的库和工具。 Jinja2：一个现代的，对设计师友好的模板引擎。官网 Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。官网 Genshi：Python 模板工具，用以生成 web 感知的结果。官网 Mako：Python 平台的超高速轻量级模板。官网 Queue处理事件以及任务队列的库。 celery：一个异步任务队列/作业队列，基于分布式消息传递。官网 huey：小型多线程任务队列。官网 mrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。官网 rq：简单的 Python 作业队列。官网 simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。官网 搜索对数据进行索引和执行搜索查询的库和软件。 django-haystack：Django 模块化搜索。官网 elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。官网 elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。官网 solrpy：solr的 Python 客户端。官网 Whoosh：一个快速的纯 Python 搜索引擎库。官网 动态消息用来创建用户活动的库。 django-activity-stream：从你的站点行为中生成通用活动信息流。官网 Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。官网 资源管理管理、压缩、缩小网站资源的工具。 django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。官网 django-storages：一个针对 Django 的自定义存储后端的工具集合。官网 fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。官网 File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。官网 Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。官网 jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。官网 webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。官网 缓存缓存数据的库。 Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python脚本和应用上。官网 django-cache-machine：Django 模型的自动缓存和失效。官网 django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。官网 django-viewlet：渲染模板，同时具有额外的缓存控制功能。官网 dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。官网 HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。官网 johnny-cache：django应用缓存框架。官网 pylibmc：libmemcached 接口的 Python 封装。官网 电子邮件用来发送和解析电子邮件的库。 django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。官网 envelopes：供人类使用的电子邮件库。官网 flanker：一个 email 地址和 Mime 解析库。官网 imbox：Python IMAP 库官网 inbox.py：Python SMTP 服务器。官网 inbox：一个开源电子邮件工具箱。官网 lamson：Python 风格的 SMTP 应用服务器。官网 mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。官网 marrow.mailer：高性能可扩展邮件分发框架。官网 modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。官网 pyzmail：创建，发送和解析电子邮件。官网 Talon：Mailgun 库，用来抽取信息和签名。官网 国际化用来进行国际化的库。 Babel：一个Python 的国际化库。官网 Korean：一个韩语词态库。官网 URL处理解析URLs的库 furl：一个让处理 URL 更简单小型 Python 库。官网 purl：一个简单的，不可变的URL类，具有简洁的 API 来进行询问和处理。官网 pyshorteners：一个纯 Python URL 缩短库。官网 shorturl：生成短小 URL 和类似 bit.ly 短链的Python 实现。官网 webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado和 Pyramid。官网 HTML处理处理 HTML和XML的库。 BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。官网 bleach：一个基于白名单的 HTML 清理和文本链接库。官网 cssutils：一个 Python 的 CSS 库。官网 html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。官网 lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。官网 MarkupSafe：为Python 实现 XML/HTML/XHTML 标记安全字符串。官网 pyquery：一个解析 HTML 的库，类似 jQuery。官网 untangle：将XML文档转换为Python对象，使其可以方便的访问。官网 xhtml2pdf：HTML/CSS 转 PDF 工具。官网 xmltodict：像处理 JSON 一样处理 XML。官网 爬取网络站点的库 Scrapy：一个快速高级的屏幕爬取及网页采集框架。官网 cola：一个分布式爬虫框架。官网 Demiurge：基于PyQuery 的爬虫微型框架。官网 feedparser：通用 feed 解析器。官网 Grab：站点爬取框架。官网 MechanicalSoup：用于自动和网络站点交互的 Python 库。官网 portia：Scrapy 可视化爬取。官网 pyspider：一个强大的爬虫系统。官网 RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。官网 网页内容提取用于进行网页内容提取的库。 Haul：一个可以扩展的图像爬取工具。官网 html2text：将 HTML 转换为 Markdown 格式文本官网 lassie：人性化的网页内容检索库。官网 micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。官网 newspaper：使用 Python 进行新闻提取，文章提取以及内容策展。官网 opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python模块。官网 python-goose：HTML内容/文章提取器。官网 python-readability：arc90 公司 readability 工具的 Python 高速端口。官网 sanitize：为杂乱的数据世界带来调理性。官网 sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。官网 textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。官网 表单进行表单操作的库。 Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。官网 django-bootstrap3：集成了 Bootstrap 3 的 Django。官网 django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don’t repeat yourself） 的方式来创建美观的表单。官网 django-remote-forms：一个平台独立的 Django 表单序列化工具。官网 WTForms：一个灵活的表单验证和呈现库。官网 WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。官网 数据验证数据验证库。多用于表单验证。 Cerberus：A mappings-validator with a variety of rules, normalization-features and simple customization that uses a pythonic schema-definition.官网 colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。官网 kmatch：一种用于匹配/验证/筛选 Python 字典的语言。官网 schema：一个用于对 Python 数据结构进行验证的库。官网 Schematics：数据结构验证。官网 valideer：轻量级可扩展的数据验证和适配库。官网 voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python的 JSON，YAML 等数据。官网 反垃圾技术帮助你和电子垃圾进行战斗的库。 django-simple-captcha：一个简单、高度可定制的Django 应用，可以为任何Django表单添加验证码。官网 django-simple-spam-blocker：一个用于Django的简单的电子垃圾屏蔽工具。官网 标记用来进行标记的库。 django-taggit：简单的 Django 标记工具。官网 管理面板管理界面库。 Ajenti：一个你的服务器值得拥有的管理面板。官网 django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。官网 django-xadmin：Django admin 的一个替代品，具有很多不错的功能。官网 flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。官网 flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。官网 Grappelli：Django 管理界面的一个漂亮的皮肤。官网 Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。官网 静态站点生成器静态站点生成器是一个软件，它把文本和模板作为输入，然后输出HTML文件。 Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。官网 Cactus：为设计师设计的静态站点生成器。官网 Hyde：基于 Jinja2 的静态站点生成器。官网 Nikola：一个静态网站和博客生成器。官网 Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由Sphinx驱动。官网 Lektor：一个简单易用的静态 CMS 和博客引擎。官网 进程操作系统进程启动及通信库。 envoy：比 Python subprocess 模块更人性化。官网 sarge：另一 种 subprocess 模块的封装。官网 sh：一个完备的 subprocess 替代库。官网 并发和并行用以进行并发和并行操作的库。 multiprocessing：(Python 标准库) 基于进程的“线程”接口。官网 threading：(Python 标准库)更高层的线程接口。官网 eventlet：支持 WSGI 的异步框架。官网 gevent：一个基于协程的 Python 网络库，使用greenlet。官网 Tomorrow：用于产生异步代码的神奇的装饰器语法实现。官网 网络用于网络编程的库。 asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。官网 Twisted：一个事件驱动的网络引擎。官网 pulsar：事件驱动的并发框架。官网 diesel：基于Greenlet 的事件 I/O 框架。官网 pyzmq：一个 ZeroMQ 消息库的 Python 封装。官网 txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。官网 WebSocket帮助使用WebSocket的库。 AutobahnPython：给 Python 、使用的 WebSocket &amp; WAMP 基于 Twisted 和 asyncio。官网 Crossbar：开源统一应用路由(Websocket &amp; WAMP for Python on Autobahn).官网 django-socketio：给 Django 用的 WebSockets。官网 WebSocket-for-Python：为Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。官网 WSGI 服务器兼容 WSGI 的 web 服务器 gunicorn：Pre-forked, 部分是由 C 语言编写的。官网 uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。官网 bjoern：异步，非常快速，由 C 语言编写。官网 fapws3：异步 (仅对于网络端)，由 C 语言编写。官网 meinheld：异步，部分是由 C 语言编写的。官网 netius：异步，非常快速。官网 paste：多线程，稳定，久经考验。官网 rocket：多线程。官网 waitress：多线程, 是它驱动着 Pyramid 框架。官网 Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。官网 RPC 服务器兼容 RPC 的服务器。 SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。官网 SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。官网 zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。官网 密码学 cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。官网 hashids：在 Python 中实现 hashids 。官网 Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。官网 Passlib：安全密码存储／哈希库，官网 PyCrypto：Python 密码学工具箱。官网 PyNacl：网络和密码学(NaCl) 库的 Python 绑定。官网 图形用户界面用来创建图形用户界面程序的库。 curses：内建的 ncurses 封装，用来创建终端图形用户界面。官网 enaml：使用类似 QML 的Declaratic语法来创建美观的用户界面。官网 kivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS平台上。官网 pyglet：一个Python 的跨平台窗口及多媒体库。官网 PyQt：跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4 和 Qt v5。官网 PySide：P跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4。官网 Tkinter：Tkinter 是 Python GUI 的一个事实标准库。官网 Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。官网 urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。官网 wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。官网 PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定官网 Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。官网 游戏开发超赞的游戏开发库。 Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。官网 Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用C++编写, 针对 Python 进行了完全的封装。官网 Pygame：Pygame 是一组 Python 模块，用来编写游戏。官网 PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。官网 PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。官网 PySDL2：SDL2 库的封装，基于 ctypes。官网 RenPy：一个视觉小说（visual novel）引擎。官网 日志用来生成和操作日志的库。 logging：(Python 标准库) 为 Python 提供日志功能。官网 logbook：Logging 库的替代品。官网 Eliot：为复杂的和分布式系统创建日志。官网 Raven：Sentry的 Python 客户端。官网 Sentry：实时记录和收集日志的服务器。官网 Testing进行代码库测试和生成测试数据的库。 测试框架 unittest：(Python 标准库) 单元测试框架。官网 nose：nose 扩展了 unittest 的功能。官网 contexts：一个 Python 3.3+ 的 BDD 框架。受到C# hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。官网 mamba：Python 的终极测试工具， 拥护BDD。官网 PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。官网 pyshould：Should 风格的断言，基于 PyHamcrest。官网 pytest：一个成熟的全功能 Python 测试工具。官网 green：干净，多彩的测试工具。官网 pyvows：BDD 风格的测试工具，受Vows.js的启发。官网- Robot Framework：一个通用的自动化测试框架。官网 Web 测试 Selenium：Selenium WebDriver 的 Python 绑定。官网 locust：使用 Python 编写的，可扩展的用户加载测试工具。官网 sixpack：一个和语言无关的 A/B 测试框架。官网 splinter：开源的 web 应用测试工具。官网 Mock测试 mock：(Python 标准库) 一个用于伪造测试的库。官网 doublex：Python 的一个功能强大的 doubles 测试框架。官网 freezegun：通过伪造日期模块来生成不同的时间。官网 httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。官网 httpretty：Python 的 HTTP 请求 mock 工具。官网 responses：伪造 Python 中的 requests 库的一个通用库。官网 VCR.py：在你的测试中记录和重放 HTTP 交互。官网 对象工厂 factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。官网 mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。官网 modelmommy：为 Django 测试创建随机固件官网 代码覆盖率 coverage：代码覆盖率测量。官网 伪数据 faker：一个 Python 库，用来生成伪数据。官网 fake2db：伪数据库生成器。官网 radar：生成随机的日期/时间。官网 错误处理 FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。官网 代码分析和Lint工具进行代码分析，解析和操作代码库的库和工具。 代码分析 code2flow：把你的 Python 和 JavaScript 代码转换为流程图。官网 pycallgraph：这个库可以把你的Python 应用的流程(调用图)进行可视化。官网 pysonar2：Python 类型推断和检索工具。官网 Lint工具 Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。官网 Pylint：一个完全可定制的源码分析器。官网 pylama：Python 和 JavaScript 的代码审查工具。官网 Debugging Tools用来进行代码调试的库。 调试器 ipdb：IPython 启用的 pdb。官网 pudb：全屏，基于控制台的 Python 调试器。官网 pyringe：可以在 Python 进程中附加和注入代码的调试器。官网 wdb：一个奇异的 web 调试器，通过 WebSockets 工作。官网 winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。官网 django-debug-toolbar：为 Django 显示各种调试信息。官网 django-devserver：一个 Django 运行服务器的替代品。官网 flask-debugtoolbar：django-debug-toolbar 的 flask 版。官网 性能分析器 lineprofiler：逐行性能分析。官网 memoryprofiler：监控 Python 代码的内存使用。官网 profiling：一个交互式 Python 性能分析工具。官网 其他 pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。官网 python-statsd：statsd 服务器的 Python 客户端。官网 Science and Data Analysis用来进行科学计算和数据分析的库。 astropy：一个天文学 Python 库。官网 bcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。官网 bccb：生物分析相关代码集合官网 Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。官网 blaze：NumPy 和 Pandas 的大数据接口。官网 cclib：一个用来解析和解释计算化学软件包输出结果的库。官网 NetworkX：一个为复杂网络设计的高性能软件。官网 Neupy：执行和测试各种不同的人工神经网络算法。官网 Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由Cython 和 NumPy 的开发者开发。官网 NumPy：使用 Python 进行科学计算的基础包。官网 Open Babel：一个化学工具箱，用来描述多种化学数据。官网 Open Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。官网 orange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。官网 Pandas：提供高性能，易用的数据结构和数据分析工具。官网 PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。官网 PyMC：马尔科夫链蒙特卡洛采样工具。官网 RDKit：化学信息学和机器学习软件。官网 SciPy：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。官网 statsmodels：统计建模和计量经济学。官网 SymPy：一个用于符号数学的 Python 库。官网 zipline：一个 Python 算法交易库。官网 数据可视化进行数据可视化的库。 参见: awesome-javascript。 matplotlib：一个 Python 2D 绘图库。官网 bokeh：用 Python 进行交互式 web 绘图。官网 ggplot：ggplot2 给 R 提供的 API 的 Python 版本。官网 plotly：协同 Python 和 matplotlib 工作的 web 绘图库。官网 pygal：一个 Python SVG 图表创建工具。官网 pygraphviz：Graphviz 的 Python 接口。官网 PyQtGraph：交互式实时2D/3D/图像绘制及科学/工程学组件。官网 SnakeViz：一个基于浏览器的 Python’s cProfile 模块输出结果查看工具。官网 vincent：把 Python 转换为 Vega 语法的转换工具。官网 VisPy：基于 OpenGL 的高性能科学可视化工具。官网 计算机视觉计算机视觉库。 OpenCV：开源计算机视觉库。官网 SimpleCV：一个用来创建计算机视觉应用的开源框架。官网 机器学习机器学习库。 参见: awesome-machine-learning. Crab：灵活、快速的推荐引擎。官网 gensim：人性化的话题建模库。官网 hebel：GPU 加速的深度学习库。官网 NuPIC：智能计算 Numenta 平台。官网 pattern：Python 网络挖掘模块。官网 PyBrain：另一个 Python 机器学习库。官网 Pylearn2：一个基于 Theano 的机器学习库。官网 python-recsys：一个用来实现推荐系统的 Python 库。官网 scikit-learn：基于 SciPy 构建的机器学习 Python 模块。官网 pydeep：Python 深度学习库。官网 vowpalporpoise：轻量级 Vowpal Wabbit 的 Python 封装。官网 skflow：一个 TensorFlow 的简化接口(模仿 scikit-learn)。官网 MapReduceMapReduce 框架和库。 dpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。官网 dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。官网 luigi：这个模块帮你构建批处理作业的复杂流水线。官网 mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。官网 PySpark：Spark 的 Python API 。官网 streamparse：运行针对事实数据流的 Python 代码。集成了Apache Storm。官网 函数式编程使用 Python 进行函数式编程。 CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。官网 fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。官网 funcy：炫酷又实用的函数式工具。官网 Toolz：一组用于迭代器，函数和字典的函数式编程工具。官网 第三方 API用来访问第三方 API的库。 参见： List of Python API Wrappers and Libraries。 apache-libcloud：一个为各种云设计的 Python 库。官网 boto：Amazon Web Services 的 Python 接口。官网 django-wordpress：WordPress models and views for Django.官网 facebook-sdk：Facebook 平台的 Python SDK.官网 facepy：Facepy 让和 Facebook’s Graph API 的交互变得更容易。官网 gmail：Gmail 的 Python 接口。官网 google-api-python-client：Python 用的 Google APIs 客户端库。官网 gspread：Google 电子表格的 Python API.官网 twython：Twitter API 的封装。官网 DevOps 工具用于 DevOps 的软件和库。 Ansible：一个非常简单的 IT 自动化平台。官网 SaltStack：基础设施自动化和管理系统。官网 OpenStack：用于构建私有和公有云的开源软件。官网 Docker Compose：快速，分离的开发环境，使用 Docker。官网 Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。官网 cuisine：为 Fabric 提供一系列高级函数。官网 Fabtools：一个用来编写超赞的 Fabric 文件的工具。官网 gitapi：Git 的纯 Python API。官网 hgapi：Mercurial 的纯 Python API。官网 honcho：Foreman的 Python 克隆版，用来管理基于Procfile的应用。官网 pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。官网 psutil：一个跨平台进程和系统工具模块。官网 supervisor：UNIX 的进程控制系统。官网 任务调度任务调度库。 APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。官网 django-schedule：一个 Django 排程应用。官网 doit：一个任务执行和构建工具。官网 gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。官网 Joblib：一组为 Python 提供轻量级作业流水线的工具。官网 Plan：如有神助地编写 crontab 文件。官网 schedule：人性化的 Python 任务调度库。官网 Spiff：使用纯 Python 实现的强大的工作流引擎。官网 TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。官网 外来函数接口使用外来函数接口的库。 cffi：用来调用 C 代码的外来函数接口。官网 ctypes：(Python 标准库) 用来调用 C 代码的外来函数接口。官网 PyCUDA：Nvidia CUDA API 的封装。官网 SWIG：简化的封装和接口生成器。官网 高性能让 Python 更快的库。 Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。官网 PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。官网 PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。官网 Pyston：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。官网 Stackless Python：一个强化版的 Python。官网 微软的 Windows平台在 Windows 平台上进行 Python 编程。 Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。官网 pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。官网 PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。官网 PyWin32：针对 Windows 的Python 扩展。官网 WinPython：Windows 7/8 系统下便携式开发环境。官网 网络可视化和SDN用来进行网络可视化和SDN(软件定义网络)的工具和库。 Mininet：一款流行的网络模拟器以及用 Python 编写的 API。官网 POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。官网 Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。官网 SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。官网 硬件用来对硬件进行编程的库。 ino：操作Arduino的命令行工具。官网 Pyro：Python 机器人编程库。官网 PyUserInput：跨平台的，控制鼠标和键盘的模块。官网 scapy：一个非常棒的操作数据包的库。官网 wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作WiFi。官网 Pingo：Pingo 为类似Raspberry Pi，pcDuino， Intel Galileo等设备提供统一的API用以编程。官网 兼容性帮助从 Python 2 向 Python 3迁移的库。 Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。官网 Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。官网 Six：Python 2 和 3 的兼容性工具。官网 杂项不属于上面任何一个类别，但是非常有用的库。 blinker：一个快速的 Python 进程内信号/事件分发系统。官网 itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。官网 pluginbase：一个简单但是非常灵活的 Python 插件系统。官网 Pychievements：一个用来创建和追踪成就的 Python 框架。官网 Tryton：一个通用商务框架。官网 算法和设计模式Python 实现的算法和设计模式。 algorithms：一个 Python 算法模块。官网 python-patterns：Python 设计模式的集合。官网 sortedcontainers：快速，纯 Python 实现的SortedList，SortedDict 和 SortedSet 类型。官网 编辑器插件编辑器和 IDE 的插件 Emacs Elpy：Emacs Python 开发环境。官网 Sublime Text SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。官网 Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。官网 Vim YouCompleteMe：引入基于 Jedi 的 Python 自动补全引擎。官网 Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。官网 Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。官网 Visual Studio PTVS：Visual Studio 的 Python 工具官网 集成开发环境流行的 Python 集成开发环境。 PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。官网 LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。官网 Spyder：开源 Python IDE。官网 服务在线工具和简化开发的 API 。 持续集成参见: awesome-CIandCD. Travis CI：一个流行的工具，为你的开源和私人项目提供持续集成服务。(仅支持 GitHub)官网 CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)官网 Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。官网 Wercker：基于 Docker 平台，用来构建和部署微服务。官网 代码质量 Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。官网 QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。官网 资源在这里可以找到新的 Python 库。 网站 r/Python CoolGithubProjects Django Packages Full Stack Python Python 3 Wall of Superpowers Python Hackers Python ZEEF Trending Python repositories on GitHub today PyPI Ranking 周刊 Import Python Newsletter Pycoder’s Weekly Python Weekly Twitter @codetengu @getpy @planetpython @pycoders @pypi @pythontrending @PythonWeekly 学习指南 Scipy-lecture-notes：如何用Python来做学术？官网 SScientific-python-lectures：Python科学计算的资料。官网 Mario-Level-1：用Python和Pygame写的超级马里奥第一关。官网 Python Koans：Python的交互式学习工具。官网 Minecraft：用python写的Minecraft游戏。官网 pycrumbs：Python资源大全。官网 python-patterns：使用python实现设计模式。官网 Projects：Python项目大集合。官网 The Hitchhiker’s Guide to Python：旅行者的Python学习指南。官网 知名网站值得关注的 Python 技术站点。 中文站点 伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。官网 英文站点 待补充 微博、微信公众号 Python开发者 微博：@Python开发者 Python开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享Python技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://ipcreator.me/tags/Python/"}]},{"title":"谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革","date":"2017-02-18T01:02:06.000Z","path":"2017/02/18/Program/TensorFlow/changes-by-google-tensorflow/","text":"谷歌工智能开源项目Tensorflow预示着硬件领域的重大变革 摘要：在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。 谷歌宣布将其最重要的创新项目之一 —— 人工智能引擎 ——作为开源项目发布到网上供大家免费使用，这展示了计算机软件行业正进行着什么样的变革。 最近，互联网巨头们接二连三地将自己线上核心业务所用的软件开源。项目开源加快了技术发展的进程。随着人工智能引擎TensorFlow的开源，谷歌能以各种方式为公司范围之外的机器学习研究提供支持，这些研究成果也将反馈给谷歌。 不过谷歌的人工智能引擎也反映了当今计算机硬件行业的发展趋势。在谷歌内部，处理图像识别、语音识别和语言翻译等任务时，TensorFlow依赖于配备图像处理单元（GPU）的机器，和被用于渲染游戏图像的芯片等，但对其它的任务也擅长。它对这些芯片的依赖比想象中的更多。 根据负责谷歌AI项目的工程师Jeff Dean的说法，谷歌不仅用GPU训练其AI服务，而且还运行这些服务产品 —— 将它们植入用户手中的智能电话。 那是一次重大的转变。目前，Facebook在其庞大的计算机数据中心里用GPU训练人脸识别模型，但在为用户提供服务时 —— 真刀实战地在社交网站上识别人脸 —— 还是使用传统的处理器，或者CPU。Facebook的CTO Mike “Schrep” Schroepfer近日在公司总部举行的一次简短的记者见面会上指出，这种基本配置是目前的行业标准。但谷歌为了追求更高层次的效率，某些时候在数据中心里GPU既用来训练AI模型，又用来执行模型。谷歌也并不是踽踽独行。中国搜索引擎巨头百度也正在搭建一套类似的AI系统。“这是一次巨大的模式变革”，百度首席科学家Andrew Ng说道。 这一变革对于专注于GPU的芯片巨头NVIDIA来说是件好事。而且这也是世界最大的芯片制造商Intel产品的空白区。Intel不生产GPU。一些互联网企业和研究院开始关注可编程逻辑阵列FPGA了，将它作为AI领域的GPU替代品，并且Intel最近收购了一家专门生产可编程芯片的公司。 AI在全球的在线服务业务中扮演了越来越重要的角色 —— 备选芯片架构在AI中的地位也越来越重要。目前，在我们提供线上服务的计算机数据中心里已经如此了，若干年内，同样的现象也将会在移动设备上出现，因为我们使用的服务其实是相同的。 深度学习实践在谷歌、Facebook、微软、百度等公司，GPU被证明对“深度学习”非常有效，因为它可以并行处理许多小数据集。深度学习依赖于神经网络 —— 一种模拟人类大脑中神经元的系统 —— 这些网络是用来快速分析大量的数据。举个例子，为了教会神经网络识别一只猫，你就需要输入无数张猫的图像。GPU擅长处理这类任务。另外，它们的能耗也没有CPU这么高。 但是，这些公司在实际应用中使用深度学习技术时 —— 比如识别猫的手机App —— 这个App是由运行在CPU上的数据系统驱动的。根据在百度AI团队负责高性能计算系统的Bryan Catanzaro介绍，这是因为GPU只在持续不断输入数据的时候效率才高，而通常用来驱动手机App的数据服务器软件并不以这种方式往芯片传输数据。通常情况下，当收到手机App发来的请求后，服务器每次处理一个请求。Catanzaro解释道，如果你使用GPU分别处理收到的每个请求，“很难保证GPU有足够多的任务，让它能够有效运行。GPU从未真正发挥出作用。” 就是说，如果在执行环节你能不断地给GPU传入数据，那么它的效率比CPU高得多。百度正在其新的AI平台做这方面尝试。简单说来，就是请求发送到数据中心，然后将多个请求打包传入GPU。“我们打包这些请求，不再让处理器每次处理一个请求，而是每次处理多个请求，”Catanzaro说道。“别让GPU闲下来。” 目前还不清楚谷歌将如何处理这个问题。但是他们表示已经有TensorFlow在执行阶段使用GPU的案例。“基于不同的问题，我们有时候把GPU既用于训练，又用于识别，”谷歌发言人Jason Freidenfelds证实。 这似乎显得微不足道。事实上却是一项大工程。驱动这些AI应用产品的系统包括数十台、数百台、甚至上千台的机器。而且这些系统在我们日常生活中的地位日益重要。现在谷歌的深度学习技术不仅用来识别照片、识别语音、机器翻译，还用来提高搜索质量。其它公司也将同样的技术用于精准广告投放、计算机安全，甚至理解自然语言的应用。换句话说，像谷歌和百度这样的公司还需要大量的GPU。 无处不在的AI与此同时，TensorFlow也将其中一些AI产品从数据中心推向了智能手机端。 一般来说，如果在手机端使用深度学习相关的App，必须往数据中心回传信息。所有的AI都在服务器端。例如，你在安卓手机上执行了一个命令，这条命令必须传到谷歌的数据中心，在那里用巨大的CPU或者GPU网络来处理。 但是，谷歌也一直在提升自己的AI引擎，某些情况下可以在手机端执行完成。“你能使用一个模型描述，并且在手机端上运行”，Dean说，“而且你并不需要真的对模型描述或是代码做改动。” 谷歌的翻译App正是这么搭建的。谷歌在数据中心训练模型来识别单词和完成翻译，一旦训练完成，App就能独立地运行 —— 不需要网络连接。你可以把手机对准一块法语路牌，立即就能显示出英语翻译。 这要做好很困难。毕竟，手机的处理能力有限。随着时间推进，越来越多的这类任务会被迁移到手机端。深度学习软件会改进，移动设备硬件也在发展。“深度学习的未来在小巧灵活的移动设备上”，深度学习创业公司的创始人Chris Nicholson如是说。 举例来说，GPU正在试图寻找置入手机的方式，硬件制造商也在不断改进CPU的速度和效率。同时，IBM也在开发专为AI任务定制的“neuromorphic”芯片，使用过的人觉得它非常适合移动设备。 如今，谷歌的AI引擎不仅运行在服务器的CPU和GPU上，还运行在常规的智能手机芯片上。但据谷歌工程师Rajat Monga称，他们开发的TensorFlow能让工程师们轻而易举地迁移到其它硬件平台上。现在工具已经开源，外部人员也可以使用了。Dean如此描述TensorFlow：“它应该可以移植到各种硬件。”没错，硬件界也在经历变革 —— 和软件界并驾齐驱。 原文链接：TensorFlow, Google’s Open Source AI, Signals Big Changes in Hardware Too（译者/赵屹华 审校/刘帝伟、朱正贵 责编/周建丁） 译者简介：赵屹华，计算广告工程师@搜狗，前生物医学工程师，关注推荐算法、机器学习领域。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"超智能体","date":"2017-02-17T23:53:06.000Z","path":"2017/02/18/Program/Concepts/super-intelligence-individual/","text":"作者：yjango 生命不限于个体。并非所有生命拥有意识，但所有生命都拥有智能。这些智能体通过大量并行和多层迭代的方式形成新的智能体。细胞、器官、个体、国家、地球，不论从哪个层级上观察，都是一个“智能体”。人类作为智能的一环，需跳出自身层级，用超出人类自身感知、情感和意识的方式去理解生命。 关于本书该书最终的目的是：通过理解智能，学习如何学习。 如何机器学习 如何大脑学习 如何阅读 智能并非人类所特有，而是自生命诞生时起就产生了。没有智能就没有生命。智能又并非单一状态，它和宇宙一样，都在不断的扩张。不同阶段的智能表现出的能力不同。神经元、蚁群、人类、社会、国家、地球，乃至整个宇宙都可被视为智能体。它们通过组合和迭代来形成更高级的智能功能。智能从未停止发展，而我们人类也只不过是其中一个“细胞”。这本书将从智能的角度展示对世界的不同理解。 核心知识：并非每个章节的内容本身（读者完全可以找到很多对应内容的经典书籍）。真正有价值的是将这些知识以何种方式排列和表达。 传达方式：语言是交流的工具，而交流的前提是双方的脑中都有相同内容。但是读者和作者的信息是不对等的。语言作为教学手段本身就有限。所以我描述的方式也并非直接告诉读者一个结论，打上这就是真理的标签，而是结合图，结合例子尽可能的消除信息的不等。我不是以教学者的身份来分享知识，而是引出一个问题让读者一起思考。虽然我提供了我的见解，但我相信会有很多读者能提出比我更好的见解。 行文风格 行文分很多部分，彼此的关系是递进或并列。每个部分通常会以一个问题的引入开始，结合若干实例对该问题进行思考，经过描述，最后得出总结性概括。文中带链接的内容请打开观看。 表达格式问题：一、斜线文字 实例： 例子（情景、方式等）：普通格式 描述：普通格式 结论： 引用格式 例如 猫咪觉得自己属于人类吗？ 实例1：实例内容 实例2：实例内容 描述内容 猫咪觉得人类属于自己 智能的起源我们对智能的探索陷入了错误的方式中。 一、如果某天所有人类突然失忆，在不拆开计算机的情况下，我们该如何弄清计算机的工作原理，并给计算机下一个定义？ 方式：从计算机软件开始研究，描述各种软件的功能，并找一个可以概括所有功能的定义。人们会发现计算机可以产生图像。但很快又发现很多软件并没有图形界面。有的软件可以玩射击游戏，有的却可以操控机械。各式各样的功能会被人们发现并逐一分类，使得用一个定义概括所有功能成为不可能。更不用说这些软件的功能还在持续增长。 显然我们并不以具体功能，而是以计算机最基本的工作原理去定义计算机。如今人们对智能的探索正是陷入了以功能来研究智能的方式中。人们把智能划分成了认知、理解、思考、学习等各式各样的功能并研究着，使得研究不同功能的专家对智能的定义都不相同。 如果我们能够知道宇宙自大爆炸之后是以何种方式进行扩张的。我们就可以从起点开始，推测出所有星系可能的形状甚至它们在未来可能的形状。 所以要想搞清智能的本质，不妨先试着找出智能的源头，思考一下为什么会产生智能。 智能的研究需要从智能的源头开始 智能的本质一、生命是如何产生的？在漫漫的宇宙演变中，我想很多星球都有产生生命的概率。 情景：想象某刻火星上产生了生命，但却遇到高温又被分解成了无机物。 第二个产生的生命却因为找不到支持机体的能源而再次化成了无机物。 第三个有机体幸运的诞生在大量能源旁，却由于能源的耗尽而前功尽弃。 问题的关键并非生命能否产生，而是产生的生命能否存活。 二、究竟是什么阻碍了生命，生命又该如何存活？如果世界是静止的，那么生命自然不朽。然而我们的世界在时时刻刻发生着变化，会从一个状态变化到另一个状态。生物无从知道下一刻等待它的究竟是毁灭还是幸存？这种未来的不确定性（uncertainty）阻碍了生命的延续。 实例： 植物会因为干旱而枯萎；野兽会因为捕不到猎物而饿死；每天又有约160中国人死于交通事故。 阻碍生命的正是这种不可预测性（随机），它还有另一个名字，叫做熵（entropy）。而热力学第二定律表述孤立系统会自发的朝向最大熵状态演化。 实例： 我们房间会越来越乱，掉在地上的杯子的碎片会随处散落，熵会自发性的不断增加。我们从未见过房间自己越来越整洁，将杯子碎片会摔出一个完整的杯子的情况。说明了熵增在孤立系统下并不可逆。 熵增不可逆的现象也意味着世界持续的发生变化。在过去可能产生过无数个生命，但只有那些可以根据变化而做出相应变化的生命才能躲避危险从而幸存。这种能力就是智能，同时也是生命得以延续的原因。 智能：可以根据环境变化而做出相应变化的能力 由于阻止生命延续的实际是不确定性（随机性、不可预测性），那生命所做的就是减少该不确定性来延续。 奥地利物理学家薛定谔在《生命是什么》首次提出负熵的概念，并认为生命以负熵为生，所以智能也可被描述是： 智能：熵减的能力 线性代数 一、什么是线性代数？不断变化的世界使我们产生时间观念。正确描述事物状态及其不同时间下的变化至关重要。我们知道在三维空间下如何描述物体的位置。然而除了长宽高，世界上还有很多决定事物状态的因素。如决定股票价钱的因素、决定天气的因素。这些因素又该如何合理的描述？线性代数给了我们答案。推荐读物《Linear Algebra and Its Applications》。 线性代数是有关任意维度空间下事物状态和状态变化的规则。 矩阵乘法 二、矩阵是什么？矩阵乘法又是什么？ 带着这个问题我们开始对矩阵及其乘法进行第一遍理解。 向量点乘 全篇将会以一个实例进行讨论，请观看一遍视频PPAP洗脑全球。 三、视频的内容涉及到很多种状态及变换。用线性代数应该如何描述？ 视频内容可以写成3个向量乘法： 1、I have a pen, I have an apple—-&gt;apple pen [applepen][applepen][applepen] = [11]⋅[penapple][11]⋅[penapple][][11]⋅[penapple] （eq.1） https://yjango.gitbooks.io/superorganism/content/applepen.jpg 2、I have a pen, I have a pineapple—-&gt;pineapple pen[pineapplepen][pineapplepen][pineapplepen] = [11]⋅[penpineapple][11]⋅[penpineapple][][11]⋅[penpineapple] （eq.2） 1 https://yjango.gitbooks.io/superorganism/content/pineapplepen.jpg 3、apple pen, pineapple pen—-&gt;pen pineapple apple pen[penpineappleapplepen][penpineappleapplepen][penpineappleapplepen] = [11]⋅[applepenpineapplepen][11]⋅[applepenpineapplepen][][11]⋅[applepenpineapplepen] （eq.3） https://yjango.gitbooks.io/superorganism/content/allpen.jpg 每个等式右边的第二个向量表示变化前拥有什么，右边的第一个向量表示变化时各拿几个，而等式的左边表示变化后获得了什么。从中可以看出来： 向量点乘(dot product)是一种组合(combination) 矩阵乘向量 四、有没有其他描述方式？ 可以把（eq.1）（eq.2）合二为一，表示为（eq.4）：（eq.1）I have a pen, I have an apple—-&gt;apple pen，（eq.2）I have a pen, I have a pineapple—-&gt;pineapple pen [applepenpineapplepen][applepenpineapplepen][][applepenpineapplepen] = [100111]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[100111][]⋅[applepineapplepen][101011]⋅[applepineapplepen] （eq.4） 1 此时，表示各拿几个的向量变成了两行（两组）向量，也就成了矩阵（向量是只有一行或一列的矩阵）。 每个向量也叫一组权重(weights)。 在 [101][101][101] 中，第一个1对应着apple，第二个0对应着pineapple，第三个1对应着pen。不可以随意调换位置，所以， 向量是有顺序的一组数字，每个数字是向量的一个因素(element)因素横着排列的向量叫做行向量(row vector)因素竖着排列的向量叫做列向量(column vector)更具体的描述一下第一个结论。向量点乘是一种组合，但向量点乘是一个向量中各个因素的一个组合 五、如何计算矩阵乘向量？（eq.4）可分两步：计算第一行权重形成的组合： [101]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[101]⋅[applepineapplepen][101]⋅[applepineapplepen] 得到的组合apple pen后，放到第一行 [applepen][applepen][][applepen] 。计算第二行权重形成的组合： [011]⋅⎡⎣⎢applepineapplepen⎤⎦⎥[011]⋅[applepineapplepen][011]⋅[applepineapplepen] 得到的组合pineapple pen后，放到第二行 [pineapplepen][pineapplepen][][pineapplepen] 。行成的 [applepenpineapplepen][applepenpineapplepen][][applepenpineapplepen] 依然有顺序，仍然是一个向量。比较向量点乘，可以看出 矩阵乘向量是向量中各个因素有顺序的多个组合 向量乘矩阵 六、形成组合的成分一定是元素（数）吗？形成组合的成分并非一定是向量中的各个元素，也可以是不同向量之间形成组合。可以把（eq.1）（eq.2）（eq.3）所完成的行为改写成（eq.5）（eq.6）：[applepenpineapplepen][applepenpineapplepen][applepenpineapplepen] = [11]⋅[penapplepenpineapple][11]⋅[penapplepenpineapple][][11]⋅[penpenapplepineapple] （eq.5）[penpineappleapplepen][penpineappleapplepen][penpineappleapplepen] = [pineapplepenapplepen]⋅[11][pineapplepenapplepen]⋅[11][][pineapplepenapplepen]⋅[11] （eq.6）（eq.5）等式右侧的矩阵由两个行向量组成。 矩阵中的第一个行向量表示两次组合中分别先拿什么，第二个行向量表示两次组合中分别后拿什么。 权重 [11][11][11] 的第一个因素对应着矩阵中第一个行向量的个数，第二个因素表示右侧第二个行向量的个数。 矩阵中每个行向量内部因素的比例不变，整体完成矩阵内向量与向量之间的组合。 向量乘矩阵可以是矩阵中各个行向量有顺的多个组合 你会发现（eq.6）不同于（eq.5），要形成组合的向量被拿到了乘法点(dot)的左边，而权重被拿到了右边。 效果是拿一个penpineapple和一个applepen形成组合。 因为当行向量的因素作为组合成分时，乘法点右侧的矩阵（向量）是权重的信息。可以看出矩阵乘法并不满足乘法交换律，因为交换了两个矩阵的位置，就交换了权重与要形成组合的向量的位置。 矩阵乘法不满足乘法交换律：commutative law: AB =! BA 矩阵乘矩阵 七、可以进行批量组合吗？矩阵乘矩阵就可以看作是对一个矩阵中各个向量的批量线性组合。如果视频中跳了两遍舞蹈。第二遍跳舞时，他在两次组合中，首次拿的东西都是两个，那么就可以把（eq.5）等式右侧的行向量变成两个行向量，形成了一个矩阵。[applepenapple+2∗penpineapplepenpineapple+2∗pen][applepenapple+2∗penpineapplepenpineapple+2∗pen][][applepenpineapplepenapple+2∗penpineapple+2∗pen] = [1211]⋅[penapplepenpineapple][1211][]⋅[penapplepenpineapple][][1121]⋅[penpenapplepineapple] 在唱第二遍时，就要唱：I have two pens. I have an apple. Apple-2pens!I have two pens. I have a pineapple. Pineapple-2pens! 之前仅仅是把单词放在一起，并没有说明他们是如何组合的。而上式中终于写出了：pineapple +2*pen。 也就是只有乘法来控制数量，加法来组合不同向量。这样的组合方式才是线性代数讨论的组合，即线性组合。 所以所有已概括的结论中，组合前面都要加上“线性”两个字。同时控制数量的数是属于什么数要事先规定好（经常被规定为是实数 ∈R∈R∈R ，也有虚数域）。不过这还没有结束，严谨性是数学的特点。上文所说的“加法”和“乘法”也只不过是个名字而已。它们到底指的是什么运算，遵循什么样的规则需要明确规定。当你看线性代数教材的时候，你就会发现这8条规则。 x+y=y+x x+(y+z)=(x+y)+z 有一个唯一的“零向量” 对任意 x 都能使 x+0=x 每个 x都有一个唯一的相反数使得 x+(−x)=0 1x=x (c1c2)x=c1(c2x) c(x+y)=cx+cy (c1+c2)x=c1x+c2x(c1+c2)x=c1x+c2x 不需要去记它们。只需要知道，它们是用于描述和约束在线性代数中的加法，乘法的运算。 特别要注意的是，这些运算都有一个原点（0），为了允许正负的出现。 线性组合：向量乘上各自对应的标量后再相加所形成的组合。（满足上述对乘法、加法的规则） ##矩阵是什么## 八、熟悉了各个乘法后，矩阵到底是什么？ 线性代数是用来描述状态和变化的，而矩阵是存储状态和变化的信息的媒介。 矩阵的信息可以分为状态（静态）和变化（动态）信息来看待。 矩阵的静态信息 当把矩阵以静态信息来看待时，其信息的侧重点在于状态二字。向量可用于描述一个事物的状态，该事物的状态由向量内各个因素来描述。而矩阵可以视为多个维度（因素的个数）相同的向量的有序排列。同时矩阵也可以视为一个“向量”，用于描述一个事物的状态，内部的每个向量就是矩阵的“因素”，该事物的状态由矩阵内各个向量来描述。 多个标量有序排列后形成向量，多个向量有序排列后形成矩阵，多个矩阵有序排列后形成三维张量（3D tensor）。 所以标量可以视为因素个数为1的向量，向量可以视为因素个数为1的矩阵，矩阵可以视为因素个数为1的三维张量（3D tensor）。 坐标值与坐标系： 描述一个事物的状态需要在一个选好的坐标系中进行，所以矩阵所包含的信息从来都是成对出现。 向量举例来说，这个向量并没有被赋予任何数值。但已经确定了我们要在apple的数量和pen的数量的两个因素（两个维度）下描述数据。换句话说，坐标系已被规定好。所以当写出任何具有实际数值的向量，如时，坐标系（二维向量空间）和坐标值就同时被确定了。它实际上是和的缩写。二者无法分割。即使是，虽然pen，apple前没有任何具体数字。但依然包含所有因素间的比例相同的隐含信息。调换2和1的顺序同时也表示坐标轴之间的调换。 矩阵的动态信息 当把矩阵以动态信息来看待时，其信息的侧重点在于变化二字。这时的矩阵可以看做是一个方程。变化可以理解为由于矩阵的作用，事物本身的变化，也可以理解为坐标系的变化。向量可用于控制变化时所用成分的数量，即一组权重。矩阵可以视为多个维度（因素的个数）相同的权重的有序排列。可对另一个矩阵的静态信息进行批量变化。 矩阵乘法是什么 矩阵可以被视为载有状态和变化两种信息的媒介。而矩阵乘法就是变化的行为。在一个矩阵内，把矩阵内的向量理解为向量或权重都可以。但是当两个矩阵进行矩阵乘法时，一旦选择以动态信息理解其中一个矩阵，另一个矩阵的信息就会被瞬间静态信息。 两个矩阵相乘，一个矩阵提供状态信息，另个矩阵提供变化信息。 两个矩阵相乘 时， 当把前者矩阵(A)中行向量理解成若干组权重，后者矩阵(B)中的行向量就是要形成组合的成分。 当把后者矩阵(B)中列向量理解成若干组权重，前者矩阵(A)中的列向量就是要形成组合的成分。 注意对应行向量与列向量。 转置一个矩阵可以理解为调换一个矩阵的动态与静态信息。 单位矩阵可以被理解为动态与静态信息相同。 回想线性组合的描述（向量乘上各自对应的标量后再相加所形成的组合），因为向量的维度和权重的维度要一一对应。所以， 矩阵A(m by n)和矩阵B(p by q)能够做乘法的条件是 n = p 向量空间很多线性代数教材所引入的第一个概念就是线性空间（linear space）。可见它的地位。虽然它有些抽象，但是却是自然而然推演出来的一个概念。 九、空间是什么？ 空间的本质是集合。而且是一个能够容纳所有要描述状态的集合。若超过空间范围，就该寻找正确的空间。 对“要描述内容”进行进一步说明，需从如何理解线性代数这四个字开始。 我们已经知道了 什么是线性（那8个条件约束的加法和乘法）。那什么是代数？意思是指你可以把任何概念都代入其中。 看视频的时候，人们自然而然的会把苹果菠萝换成其他事物，比如PPAP河南话版。也可以换成任何宇宙上有的物体。不仅仅是物体，甚至可以是一个抽象的概念。 我个人最喜欢的描述是： 向量空间是描述状态(state)的线性空间。再加上之前的约束，于是我们就有了向量空间是能够容纳所有线性组合的状态空间 十、什么样的状态空间能够容纳所有的线性组合？ 情景：假如要描述一个人的两个状态（下图中的行向位置和纵向位置），向量的维度就是二维。那么一个大圆盘够不够容纳所有的线性组合？答案是不够。 因为线性组合是向量乘以各自对应的标量后再相加所形成的组合，而这个标量是实数域的时候，由于实数域无线延伸，那么乘以标量后的状态也会无限延伸。所以 向量空间一定是各个维度都像实数轴一样可以无线延伸。最终得到的将不会是一维下的线段，二维下的圆盘。而一定是一维下的无限延伸的直线，二维下的无限延伸的平面。 向量空间的基本特点是各个维度都可以无限延伸，且过原点。之所以用状态二字，是因为刚才的两个维度，可以用于描述速度和体温。这时两个维度所展开的依然是一个平面，但却不是描述位置的平面。 子空间子空间（subspace）可以被想成是向量空间内的向量空间，同样要满足能够容纳线性组合的条件。 十一、最小的子空间是什么？只有一个状态的空间（集合）。这个状态不是其他状态，就是0。只有这样才可以在乘以标量后依然不会跑出空间外。 十二、其次空集可不可以是向量空间？不可以，空集是没有任何元素的集合，既然什么状态都没有，又怎么能够容纳线性组合。最小的向量空间是只包含零向量的空间 十三、假如上图的圆盘是个无线延伸的平面，那平面的子空间可以是平面上所有直线吗？不可以，8个运算规则中明确规定了，一定要有原点，这样才可以包含正负。所以这个平面的子空间是所有过原点的直线，加上中心的那个原点自己所组成的最小子空间，再加上这个平面自身（最大的子空间）。 线性无关十四、该如何选择因素？ 在视频的例子中，当要把（eq.1）（eq.2）合为（eq.4）时，是这个样子： = （eq.4），但最右侧的向量并不是4个维度。而是三个。因为pen 和pen是一个东西。 我们想用的是 若干个毫不相关的因素去描述状态。在线性空间下的毫不相关，叫做线性无关。 十五、要描述的状态是由向量来描述时怎么办？ 判断两个向量是否线性无关时，可以看他是否在空间下平行。 但怎么判断几个向量之间（不一定是两个）是否线性无关？我们需要可靠的依据。线性无关（linearly independent）: 当表示权重，表示向量时，只发生在when 全都等于零时。 换句话说，这些向量不可以通过线性组合形成彼此。形成彼此的情况只能是他们都是零向量。 张成注意词的属性和关联词。张成（spanning）是一个动词，动词的主语是一组向量（a set of vectors）。描述的是一组向量通过线性组合所能形成子空间。描述的内容并不是形成的这个空间，而是形成的这个行为。 ，是4个向量，但只可以张成一个三维空间。（因为有两维线性相关，所以并不能张成4维） 基底 一个向量空间的一个基底（A basis for a vector space V）是一串有顺序的向量（a sequence of vectors），满足：A、向量之间彼此线性无关 （不可多余）B、这些向量可以张成向量空间V （不可过少）刚刚好可以张成向量空间V的一串向量是该向量空间V的一个基底.基底是一个类似people的复数名词，是从属于某个空间的，而不是矩阵，也不是向量。 维度一个向量空间可以有无数个基底。但每个基底所包含的向量的个数（the number of vectors in every basis）是一个空间的维度。 注意：维度是空间的概念，而不是描述一个具体的向量。人们常说的n维向量实际是指n维向量空间内的向量，由于在讨论时并未给向量指定任何实际的数值，所以可以是任何值，可以张成整个空间。所以其真正描述的依旧是一个空间。并且，维度是站在观察者角度，希望在某个向量空间下尽可能的描述物体状态而选择的，并不一定是被描述者真实处在的空间。 但若是你觉得理解起来有困难。就简单记住：互不相关的因素的个数是一个向量空间的维度 秩矩阵可以视为动态和静态信息的媒介。而 一个具体的矩阵到底涵盖了多少信息可以由秩（rank）来描述。指的是一个矩阵的所有列向量所能张成的空间的维度。矩阵的所有列向量所张成的空间叫做列空间（column space）矩阵的所有行向量所张成的空间叫做行空间（row space）一个矩阵的列空间的维度是这个矩阵的秩，同时也等于该矩阵行空间的维度秩是用于描述矩阵所包含信息量的。 线性变换最终我们想要做的就是描述事物的变化。上文所有的内容都可以说是为此刻所做的铺垫。矩阵乘以矩阵可以视作一个矩阵内部向量的批量线性变换（linear transformation）。 所以可以仅讨论由矩阵乘以向量所形成的一次线性变换。 十六、什么是变换？这里写图片描述 by David C.Lay 一个从n维实数域（）到m维实数域（）的变换（transformation or mapping or function）是将n维实数域（）空间下任意一个向量转换成为在m维实数域（）空间下对应向量其中n维实数域（）空间叫做变换的domain，m维实数域（）空间叫做该变换的codomain。向量叫做向量的image（变换行为下的）所有image组成的集合叫做变换的range 而线性变换是是指线性规则所造成的变换，是由一个矩阵来实现的。此时你就会看到无处不在的式子： y=Ax ：列向量 xx 左乘一个矩阵 AA 后得到列向量 yy = （eq.4）举例来说， 是三维空间的向量（即的domain是三维），而经过线性变换后，变成了二维空间的向量（即的codomain是二维）。 矩阵可以被理解成一个函数(function)，将三维空间下的每个向量投到二维空间下。y=Ax 也可以理解为经由一个外力，使其状态发生了改变。同时也是深层神经网络每层变换中的核心：y=a(Ax+b)","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://ipcreator.me/tags/Algorithm/"}]},{"title":"A Visual and Interactive Guide to the Basics of Neural Networks","date":"2017-02-17T02:36:06.000Z","path":"2017/02/17/Program/TensorFlow/visual-interactive-guide-basics-neural-networks/","text":"J Alammar MotivationI’m not a machine learning expert. I’m a software engineer by training and I’ve had little interaction with AI. I had always wanted to delve deeper into machine learning, but never really found my “in”. That’s why when Google open sourced TensorFlow in November 2015, I got super excited and knew it was time to jump in and start the learning journey. Not to sound dramatic, but to me, it actually felt kind of like Prometheus handing down fire to mankind from the Mount Olympus of machine learning. In the back of my head was the idea that the entire field of Big Data and technologies like Hadoop were vastly accelerated when Google researchers released their Map Reduce paper. This time it’s not a paper – it’s the actual software they use internally after years and years of evolution. So I started learning what I can about the basics of the topic, and saw the need for gentler resources for people with no experience in the field. This is my attempt at that. Start hereLet’s start with a simple example. Say you’re helping a friend who wants to buy a house. She was quoted $400,000 for a 2000 sq ft house (185 meters). Is this a good price or not?It’s not easy to tell without a frame of reference. So you ask your friends who have bought houses in that same neighborhoods, and you end up with three data points: Area (sq ft) (x) Price (y) 2,104 399,900 1,600 329,900 2,400 369,000 Personally, my first instinct would be to get the average price per sq ft. That comes to $180 per sq ft.Welcome to your first neural network! Now it’s not quite at Siri level yet, but now you know the fundamental building block. And it looks like this: Diagrams like this show you the structure of the network and how it calculates a prediction. The calculation starts from the input node at the left. The input value flows to the right. It gets multiplied by the weight and the result becomes our output.Multiplying 2,000 sq ft by 180 gives us $360,000. That’s all there is to it at this level. Calculating the prediction is simple multiplication. But before that, we needed to think about the weight we’ll be multiplying by. Here we started with an average, later we’ll look at better algorithms that can scale as we get more inputs and more complicated models. Finding the weight is our “training” stage. So whenever you hear of someone “training” a neural network, it just means finding the weights we use to calculate the prediction. This is a form of prediction. This is a simple predictive model that takes an input, does a calculation, and gives an output (since the output can be of continuous values, the technical name for what we have would be a “regression model”)Let us visualize this process (for simplicity, let’s switch our price unit from $1 to $1000. Now our weight is 0.180 rather than 180):Harder, Better, Faster, Stronger Can we do better than estimate the price based on the average of our data points? Let’s try. Let’s first define what it means to be better in this scenario. If we apply our model to the three data points we have, how good of a job would it do? That’s quite a bit of yellow. Yellow is bad. Yellow is error. We want to shrink yellow as much as we can. Area (x) Price ($1000) (y) Prediction (y) &lt;span class=”y“&gt;y-y (&lt;span class=”y“&gt;y_-y)² 2,104 399.9 379 21 449 1,600 329.9 288 42 1756 2,400 369 432 -63 3969 Average: 2,058 Here we can see the actual price value, the predicted price value, and the difference between them. Then we’ll need to average these differences so we have a number that tells us how much error there is in this prediction model. The problem is, the 3rd row has -63 as its value. We have to deal with this negative value if we want to use the difference between the prediction and price as our error measuring stick. That’s one reason why we introduce an additional column that shows the error squared, thus getting rid of the negative value. This is now our definition of doing better – a better model is one that has less error. Error is measured as the average of the errors for each point in our data set. For each point, the error is measured by the difference between the actual value and the predicted value, raised to the power of 2. This is called Mean Square Error. Using it as a guide to train our model makes it our loss function (also, cost function). Now that we defined our measuring stick for what makes a better model, let’s experiment with a couple more weight values and compare them with our average pick: We can’t improve much on the model by varying the weight any more. But if we add a bias we can find values that improve the model.Our lines can better approximate our values now that we have this b value added to the line formula. In this context, we call it a “bias”. This makes our neural network look like this: We can generalize it by saying that a neural network with one input and one output (spoiler warning: and no hidden layers) looks like this: In this graph, W and b are values we find during the training process. X is the input we plug into the formula (area in sq ft in our example). Y is the predicted price.Calculating a prediction now uses this formula: So our current model calculates predictions by plugging in the area of house as x in this formula: Train Your DragonHow about you take a crack at training our toy neural network? Minimize the loss function by tweaking the weight and bias dials. Can you get an error value below 799? Error &nbsp; Weight 0 Bias 0 AutomationCongratulations on manually training your first neural network! Let’s look at how to automate this training process. Below is another example with an additional autopilot-like functionality. These are the GD Step buttons. They use an algorithm called “Gradient Descent” to try to step towards the correct weight and bias values that minimize the loss function. Error &nbsp; Weight 0 Bias 0 The two new graphs are to help you track the error values as you fiddle with the parameters (weight and bias) of the model. It’s important to keep track of the error as the training process is all about reducing this error as much possible.How does gradient descent know where its next step should be? Calculus. You see, knowing the function we’re minimizing (our loss function, the average of (y_ - y)² for all our data points), and knowing the current inputs into it (the current weight and bias), the derivatives of the loss function tell us which direction to nudge W and b in order to minimize the error.Learn more about gradient descent and how to use it to calculate the new weights &amp; bias in the first lectures of Coursera’s Machine Learning course.And Then There Were Two Is the size of the house the only variable that goes into how much it costs? Obviously there are many other factors. Let’s add another variable and see how we can adjust our neural network to it. Say your friend does a bit more research and finds a bunch more data points. She also finds out how many bathrooms each house has: Area (sq ft) (x1) Bathrooms (x2) Price (y) 2,104 3 399,900 1,600 3 329,900 2,400 3 369,000 1,416 2 232,000 3,000 4 539,900 1,985 4 299,900 1,534 3 314,900 1,427 3 198,999 1,380 3 212,000 1,494 3 242,500 Our neural network with two variables looks like this: We now have to find two weights (one for each input) and one bias to create our new model. Calculating Y looks like this: But how do we find w1 and w2? This is a little trickier than when we only had to worry about one weight value. How much does having an extra bathroom change how we predict the value of a home? Take a stab at finding the right weights and bias. You will start here to see the complexity we start getting into as the number of our inputs increase. We start losing the ability to create simple 2d shapes that allow us to visualize the model at a glance. Instead, we’ll have to mainly rely on how the error value is evolving as we tweak our model parameters. &lt;/div&gt; &lt;div class=&quot;col-sm-6&quot;&gt; &lt;table id=&quot;training-two-table&quot; class=&quot;training-table&quot;&gt; &lt;tr&gt; &lt;td colspan=&quot;3&quot; class=&quot;gd-buttons&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;GD Step&quot; id=&quot;gradient-descent-button&quot; class=&quot;btn btn-primary&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;10 GD Steps &quot; id=&quot;gradient-descent-10-button&quot; class=&quot;btn btn-primary&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;100 GD Steps &quot; id=&quot;gradient-descent-100-button&quot; class=&quot;btn btn-primary&quot; /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Error &lt;/td&gt; &lt;td colspan=&quot;2&quot;&gt; &lt;span id=&quot;error-value&quot;&gt;&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;error-cell&quot; colspan=&quot;3&quot;&gt; &lt;span id=&quot;error-value-message&quot;&gt;&lt;/span&gt;&amp;nbsp; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Weight #1 &lt;/td&gt; &lt;td&gt; &lt;input id=&quot;weight0Slider&quot; type=&quot;range&quot; class=&quot;weight&quot; min=&quot;-0.4&quot; max=&quot;0.4&quot; step=&quot;0.0001&quot; /&gt; &lt;/td&gt; &lt;td class=&quot;slider-value&quot;&gt; &lt;span id=&quot;weight0&quot; class=&quot;weight&quot;&gt;0&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Weight #2 &lt;/td&gt; &lt;td&gt; &lt;input id=&quot;weight1Slider&quot; type=&quot;range&quot; class=&quot;weight&quot; min=&quot;-100&quot; max=&quot;200&quot; step=&quot;0.0001&quot; /&gt; &lt;/td&gt; &lt;td class=&quot;slider-value&quot;&gt; &lt;span id=&quot;weight1&quot; class=&quot;weight&quot;&gt;0&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Bias &lt;/td&gt; &lt;td&gt; &lt;input id=&quot;biasSlider&quot; type=&quot;range&quot; class=&quot;bias&quot; min=&quot;-100&quot; max=&quot;300&quot; step=&quot;0.1&quot; /&gt; &lt;/td&gt; &lt;td class=&quot;slider-value&quot;&gt; &lt;span id=&quot;bias&quot; class=&quot;bias&quot;&gt;0&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;div id=&quot;neural-network-two-graph&quot; class=&quot;nn-graph-area&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; Our trusty gradient descent is here to help once again. It still is valuable in helping us find the right weights and bias. FeaturesNow that you’ve seen neural networks with one and two features, you can sort of figure out how to add additional features and use them to calculate your predictions. The number of weights will continue to grow, and our implementation of gradient descent will have to be tweaked as we add each feature so that it can update the new weights associated with the new feature.It’s important to note here that we don’t blindly feed the network everything we know about our examples. We have to be selective about which features we feed the model. Feature selection/processing is an entire discipline with its own set of best practices and considerations. If you want to see an example of the process of examining a dataset to choose which features to feed a prediction model, check out A Journey Through Titanic. It’s a notebook where Omar EL Gabry narrates his process for solving Kaggle’s Titanic challenge. Kaggle makes available the passenger’s manifest of the Titanic including data like name, sex, age, cabin, and whether the person survived or not. The challenge is to build a model that predicts whether a person survived or not given their other information.Classification Let’s continue to tweak our example. Assume your friend gives you a list of houses. This time, she has labeled which ones she thinks have a good size and number of bathrooms: Area (sq ft) (x1) Bathrooms (x2) Label (y) 2,104 3 Good 1,600 3 Good 2,400 3 Good 1,416 2 Bad 3,000 4 Bad 1,985 4 Good 1,534 3 Bad 1,427 3 Good 1,380 3 Good 1,494 3 Good She needs you to use this to create a model to predict whether she would like a house or not given its size and number of bathrooms. You will use this list above to build the model, then she will use the model to classify many other houses. One additional change in the process, is that she has another list of 10 houses she has labeled, but she’s keeping it from you. That other list would be used to evaluate your model after you’ve trained it – thus trying to ensure your model grasps the conditions that actually make her like the features of the house. The neural networks we’ve been toying around with until now are all doing “regression” – they calculate and output a “continuous” value (the output can be 4, or 100.6, or 2143.342343). In practice, however, neural networks are more often used in “classification” type problems. In these problems, the neural network’s output has to be from a set of discrete values (or “classes”) like “Good” or “Bad”. How this works out in practice, is that we’ll have a model that will say that it’s 75% sure that a house is “Good” rather than just spit out “good” or “bad”. The TensorFlow app I discussed in my previous post is a good example for a classification model in practice. One way we can transform the network we’ve seen into a classification network is to have it output two values – one for each class (our classes now being “good” and “bad”). We then pass these values through an operation called “softmax”. The output of softmax is the probability of each class. For example, say that layer of the network outputs 2 for “good” and 4 for “bad”, if we feed [2, 4] to softmax, it will return [0.11, 0.88] as the output. Which translates the values to say the network is 88% sure that the inputted value is “bad” and our friend would not like that house. Softmax takes an array and outputs an array of the same length. Notice that its outputs are all positive and sum up to 1 – which is useful when we’re outputting a probability value. Also notice that even though 4 is double 2, its probability is not only double, but is eight times that of 2. This is a useful property that exaggerates the difference in output thus improving our training process. output softmax([ 1 ]) [ 1 ] softmax([ 1, 1 ]) [ 0.5, 0.5 ] softmax([ 0, 1 ]) [ 0.26, 0.73 ] softmax([ 2, 4 ]) [ 0.11, 0.88 ] softmax([ 5, 10 ]) [ 0.007, 0.993 ] softmax([ -1, 0, 1 ]) [ 0.09, 0.24, 0.66 ] softmax([ 1, 2, 4 ]) [ 0.04, 0.11, 0.84 ] As you can see in the last two rows, softmax extends to any number of inputs. So now if our friend adds a third label (say “Good, but I’ll have to airbnb one room”), softmax scales to accomedate that change. Take a second to explore the shape of the network as you vary the number of features (x1, x2, x3…etc) (which can be area, number of bathrooms, price, proximity to school/work…etc) and vary the number of classes (y1, y2, y3…etc) (which can be “too expensive”, “good deal”, “good if I airbnb”, “too small”): Features (x): Classes (y): You can see an example of how to create and train this network using TensorFlow in this notebook I created to accompany this post. True Motivation If you have reached this far, I have to reveal to you another motivation of mine to write this post. This post is meant as an even gentler intro to TensorFlow tutorials. If you start working through MNIST For ML Beginners now, and come across this graph: I wrote this post to prepare people without machine learning experience for this graph in the TensorFlow introductory tutorial. That’s why I simulated its visual style. I hope you would feel prepared and that you have an understanding of this system and how it works. If you want to start tinkering with code, feel free to pick up from the intro tutorial and teach a neural network how to detect handwritten digits. You should also continue your education by learning the theoretical and mathematical underpinnings of the concepts we discussed here. Good questions to ask now include: What other kinds of cost functions exist? Which are better for which applications? What’s the algorithm to actually calculate new weights using gradient descent? What are the applications for machine learning in the fields you’re already knowledgeable about? What new magic can you wield by mixing this spell with others in your spell book? Great learning resources include: Coursera’s Machine Learning course by Andrew Ng. This is the one I started with. Starts with regression then moves to classification and neural networks. Coursera’s Neural Networks for Machine Learning by Geoffrey Hinton. More focused on neural networks and its visual applications. Stanford’s CS231n: Convolutional Neural Networks for Visual Recognition by Andrej Karpathy. It’s interesting to see some advanced concepts and the state of the art in visual recognition using deep neural networks. The Neural Network Zoo is a great resource to learn more about the different types of neural networks. Acknowledgements Thanks to Yasmine Alfouzan, Ammar Alammar, Khalid Alnuaim, Fahad Alhazmi, Mazen Melibari, and Hadeel Al-Negheimish for their assistance in reviewing previous versions of this post. Please contact me on Twitter with any corrections or feedback.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Neural Networks","slug":"Neural-Networks","permalink":"http://ipcreator.me/tags/Neural-Networks/"}]},{"title":"TensorFlow Android Camera Demo","date":"2017-02-17T02:26:06.000Z","path":"2017/02/17/Program/TensorFlow/tensorflow-android-camera-demo/","text":"作者：tensorflow This folder contains an example application utilizing TensorFlow for Android devices. DescriptionThe demos in this folder are designed to give straightforward samples of using TensorFlow in mobile applications. Inference is done using the TensorFlow Android Inference Interface, which may be built separately if you want a standalone library to drop into your existing application. A device running Android 5.0 (API 21) or higher is required to run the demo. Current samples:TF Classify: Uses the Google Inception model to classify camera frames in real-time, displaying the top results in an overlay on the camera image. TF Detect: Demonstrates a model based on Scalable Object Detection using Deep Neural Networks to localize and track people in the camera preview in real-time. TF Stylize: Uses a model based on A Learned Representation For Artistic Style to restyle the camera preview image to that of a number of different artists. Prebuilt APK:If you just want the fastest path to trying the demo, you may download the nightly build here. Expand the &quot;View&quot; and then the &quot;out&quot; folders under &quot;Last Successful Artifacts to find tensorflow_demo.apk. Also available are precompiled native libraries that you may drop into your own applications. See tensorflow/contrib/android/README.md for more details. Running the DemoOnce the app is installed it can be started via the &quot;TF Classify&quot;, &quot;TF Detect&quot; and &quot;TF Stylize&quot; icons, which have the orange TensorFlow logo as their icon. While running the activities, pressing the volume keys on your device will toggle debug visualizations on/off, rendering additional info to the screen that may be useful for development purposes. Building the Demo from SourcePick your preferred approach below. At the moment, we have full support for Bazel, and partial support for gradle, cmake, make, and Android Studio. As a first step for all build types, clone the TensorFlow repo with: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git Note that --recurse-submodules is necessary to prevent some issues with protobuf compilation. BazelInstall Bazel and Android Prerequisites Bazel is the primary build system for TensorFlow. To build with Bazel, it and the Android NDK and SDK must be installed on your system. Get the recommended Bazel version listed in os_setup.html The Android NDK is required to build the native (C/C++) TensorFlow code. The current recommended version is 12b, which may be found here. The Android SDK and build tools may be obtained here, or alternatively as part of Android Studio. Build tools API &gt;= 23 is required to build the TF Android demo. Edit WORKSPACE The Android entries in &lt;workspace_root&gt;/WORKSPACE must be uncommented with the paths filled in appropriately depending on where you installed the NDK and SDK. Otherwise an error such as: &quot;The external label &apos;//external:android/sdk&apos; is not bound to anything&quot; will be reported. Also edit the API levels for the SDK in WORKSPACE to the highest level you have installed in your SDK. This must be &gt;= 23 (this is completely independent of the API level of the demo, which is defined in AndroidManifest.xml). The NDK API level may remain at 21. Install Model Files (optional) The TensorFlow GraphDefs that contain the model definitions and weights are not packaged in the repo because of their size. They are downloaded automatically and packaged with the APK by Bazel via a new_http_archive defined in WORKSPACE during the build process. Optional: If you wish to place the models in your assets manually (E.g. for non-Bazel builds), remove all of the model_files entries from the assets list in tensorflow_demo found in the [BUILD](BUILD) file. Then download and extract the archives yourself to the assets directory in thesource tree: BASE_URL=https://storage.googleapis.com/download.tensorflow.org/models for MODEL_ZIP in inception5h.zip mobile_multibox_v1a.zip stylize_v1.zip do curl -L ${BASE_URL}/${MODEL_ZIP} -o /tmp/${MODEL_ZIP} unzip /tmp/${MODEL_ZIP} -d tensorflow/examples/android/assets/ done This will extract the models and their associated metadata files to the local assets/ directory. Build After editing your WORKSPACE file to update the SDK/NDK configuration, you may build the APK. Run this from your workspace root: bazel build -c opt //tensorflow/examples/android:tensorflow_demo If you get build errors about protocol buffers, run git submodule update --init and make sure that you&apos;ve modified your WORKSPACE file as instructed, then try building again. Install Make sure that adb debugging is enabled on your Android 5.0 (API 21) or later device, then after building use the following command from your workspace root to install the APK: adb install -r bazel-bin/tensorflow/examples/android/tensorflow_demo.apk Android StudioAndroid Studio may be used to build the demo in conjunction with Bazel. First, make sure that you can build with Bazel following the above directions. Then, look at build.gradle and make sure that the path to Bazel matches that of your system. At this point you can add the tensorflow/examples/android directory as a new Android Studio project. Click through installing all the Gradle extensions it requests, and you should be able to have Android Studio build the demo like any other application (it will call out to Bazel to build the native code with the NDK). CMakeFull CMake support for the demo is coming soon, but for now it is possible to build the TensorFlow Android Inference library using tensorflow/contrib/android/cmake.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Supercharging Android Apps With TensorFlow","date":"2017-02-17T02:26:06.000Z","path":"2017/02/17/Program/TensorFlow/supercharging-android-apps-with-tensorflow/","text":"J Alammar Supercharging Android Apps With TensorFlow (Google’s Open Source Machine Learning Library)In November 2015, Google announced and open sourced TensorFlow, its latest and greatest machine learning library. This is a big deal for three reasons: Machine Learning expertise: Google is a dominant force in machine learning. Its prominence in search owes a lot to the strides it achieved in machine learning. Scalability: the announcement noted that TensorFlow was initially designed for internal use and that it’s already in production for some live product features. Ability to run on Mobile. This last reason is the operating reason for this post since we’ll be focusing on Android. If you examine the tensorflow repo on GitHub, you’ll find a little tensorflow/examples/android directory. I’ll try to shed some light on the Android TensorFlow example and some of the things going on under the hood. A Look of RecognitionThe app glances out through your camera and tries to identify the objects it sees. Sometimes it does a good job, other times it can’t quite pin down the object, and at times it leads to thought provoking guesses! Overall, it feels pretty magical. android_tensorflow_classifier_results.jpg The app accomplishes this feat using a bundled machine learning model running in TensorFlow on the device (no network calls to a backend service). The model is trained against millions of images so that it can look at the photos the camera feeds it and classify the object into its best guess (from the 1000 object classifications it knows). Along with its best guess, it shows a confidence score to indicate how sure it is about its guess. The Android example page gives you an idea on how to build the app, and ultimately culminates in producing this APK (I built and uploaded the APK to save you some time since the building process requires installing the Android NDK and Bazel, Google’s build tool). NOTE: Android 5.0 or later required since the example uses the Camera2 package introduced in Android 5.0. NOTE: if your device runs Android 6.0 or later, you have to install the app with the following command (It gives the app the appropriate permissions it needs to run): adb install -r -g /path/to/apk.apk App Structure Walkthroughandroid-tensorflow-app-structure_1.png The core TensorFlow engine is built with C++, but programmers can write their TensorFlow software in either C++ or Python. The Android TensorFlow example uses the C++ interface in the following manner: On startup, the app launches an Android activity (CameraActivity.java) which then starts a fragment (CameraConnectionFragment.java)The fragment does some setup to basically start the camera and feed the incoming stream of images to an object it instantiates (TensorflowImageListener.java)The listener consults the classifier (TensorflowClassifier.java) about each image it gets, and receives the classification and confidence score for each image.The good thing is that most of this logic is in normal Android Java SDK territory – so this should be familiar to most Android devs. So where is the C++?android-tensorflow-app-structure_2.png If you look closely at TensorflowClassifier, you may notice the following methods: public native int initializeTensorflow( ); private native String classifyImageBmp(Bitmap bitmap); The native keywords in these method signatures indicate that these methods are implemented in native C++ code. Look for them under the “android/jni” directory and true enough, you’ll find tensorflow_jni.cc JNIEXPORT jint JNICALL TENSORFLOW_METHOD(initializeTensorflow)(...) { ... } JNIEXPORT jstring JNICALL TENSORFLOW_METHOD(classifyImageBmp)(...) { ... } JNI (short for Java Native Interface) is a way in which the Java parts of an Android app can communicate with the native C++ parts. So when we call classifyImageBmp(bitmap) in our Java code, it will actually invoke the C++ function exported in tensorflow_jni.cc and return the value it returns. A Bitmap file cannot directly be sent to TensorFlow as input. It has be transformed into an input tensor that we’d send in step #2 in the flow above. A tensor is an n-dimensional array of values, and is the motif TensorFlow uses to send data between all of its different parts/operations. This model expect a 3-dimensional array that supplies the Red/Green/Blue value of each pixel in the image. The dimensions are: X-index of the pixel Y-index of the pixel indication of which value this cell holds (0 for red, 1 for green, 2 for blue)And the value of the cell would be the actual value of R or G or B channel for that pixel.input_tensor.png (This is somewhat oversimplified. I glanced over two things for simplicity’s sake. First is the conversion from the YUV format that the Android camera exports to the RGB format the model expects. Second is that the model actually takes a 4-dimensional tensor, but these three are the ones we care about) The ModelAs you read the example’s README.md, you’ll notice that it instructs you to download a zip file containing the TensorFlow model and add it to the assets directory. This zip file contains two files that are important for us: tensorflow_inception_graph.pb- At 54 MBs unzipped, this file constitutes the majority of the APK size (58 MBs). This is our trained machine learning model and where the magic comes from. It’s a pre-built TensorFlow Graph describing the exact operations needed to compute a classification from input image data. This Graph is serialized and encoded into binary with Google’s Protocol Buffers so it can be deserialized across different platforms (think of it as a binary-encoded JSON file). imagenet_comp_graph_label_strings.txt- this contains the 1000 classifications that the output of the model corresponds to (e.g. “vending machine”, “water bottle”, “coffee mug”). These classifications are defined by the ImageNet Large Scale Visual Recognition Challenge which the model was built to compete in. The model here is what’s known as a deep convolutional neural network. It is built in the Inception architecture described in Going Deeper with Convolutions. Convolutional neural networks are some of the most popular models in deep learning. They have been very successful in image recognition (so much so, that most highly ranked teams in the competition used them). The model is read from the file and fed into TensorFlow when the app starts up. This code is actually really interesting to read and see how to communicate with tensorflow (if you run the app with your device connected to your computer, you can see these helpful log messages printed in logcat). Build SystemThe Android app example is not built the traditional Gradle way. Because the app has to contain NDK elements as well as TensorFlow itself, a more elaborate build system was utilized. The example is configured to be built with Google’s Bazel build system running from the TensorFlow root directory. The WORKSPACE file in the root directory specifies the main parameters of the project. The BUILD file in the Android directory instructs the build system to build the Java and C++ files of the app. The PossibilitiesUsing a trained model in your app seems to be the lowest hanging fruit for mobile TensorFlow apps at the moment. While you can probably train a model on Android, mobile devices are not well suited for the intensive processing required by complex models with larger training sets. Want to learn more about machine learning? Consider checking out the Machine Learning course on Coursera. There’s also a good discussion in /r/MachineLearning here: In your experience, which machine learning course on Coursera (or other MOOC web site) was the best?. Want to comment? /r/androiddev, Hacker News. Written on January 6, 2016","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow Android stand-alone demo","date":"2017-02-17T02:16:06.000Z","path":"2017/02/17/Program/TensorFlow/tensorflow-android-stand-alone-demo/","text":"作者：miyosuda Android demo source files extracted from original TensorFlow source. (TensorFlow r0.10) To build this demo, you don’t need to prepare build environment with Bazel, and it only requires AndroidStudio. If you would like to build jni codes, only NDK is requied to build it. How to build jni codes First install NDK, and set path for NDK tools, and then type commands below to create .so file. 123$ cd jni-build$ make$ make install","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Android","slug":"Android","permalink":"http://ipcreator.me/tags/Android/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow的技术应用","date":"2017-02-17T02:06:06.000Z","path":"2017/02/17/Program/TensorFlow/applications-of-tensorflow/","text":"作者：AI研习社 通过一些TensorFlow实际应用，让大家对TensorFlow有理性和感性的双层认知。 随着谷歌2015年发布开源人工系统TensorFlow，让本就如火如荼的深度学习再添一把火，截至现在，TensorFlow已经历了多个版本演进，功能不断完善，AI开发者也能灵活自如的运用TensorFlow解决一些实际问题，下面雷锋网(公众号：雷锋网)会对一些比较实用的TensorFlow应用做相关整理，让大家对TensorFlow有理性和感性的双层认知。 TensorFlow在图像识别中的应用 对人类而言，区分画面、图像就如同与生俱来一样简单，例如我们能够轻松的识别老虎与雄狮的区别，但如果把这个问题交给计算机看上去并不简单。 在过去几年里，机器学习在解决这些难题方面取得了巨大的进步。其中，我们发现一种称为深度卷积神经网络的模型在困难的视觉识别任务中取得了理想的效果 —— 达到人类水平，在某些领域甚至超过。下面这篇文章雷锋网重点整理了TensorFlow在图像识别中的应用，看计算机如何识别图像。 地址：http://www.csdn.net/article/2015-12-16/2826496 除了认识TensorFlow在图像识别中的应用，关于如何搭建图像识别系统雷锋网也有相关教程： 手把手教你用TensorFlow搭建图像识别系统（一） 手把手教你用TensorFlow搭建图像识别系统（二） 手把手教你用TensorFlow搭建图像识别系统（三） 农场主与TensorFlow的邂逅，AI告诉你一根优秀的黄瓜应该具备什么素质 一根优秀的黄瓜应该具备什么素质？相信这是很多人不可描述的问题，而对于黄瓜农场主而言，同一个品种的黄瓜可以根据颜色、刺、体态等因素分成9类，但分检工作对于人来说恰好是一个枯燥繁琐的过程。 一位日本农场主 Makoto 为解决这一难题，利用TensorFlow制作了一款黄瓜分类机，通过机器就能够完成黄瓜的分类工作，但识别准确率目前只有70%，Makoto 目前正打算使用谷歌的云机器学习（Cloud Machine Learning）平台，来进一步改善他的黄瓜分类机。 地址：http://www.leiphone.com/news/201609/dHgxLbz96OQqVN8z.html（来源雷锋网） 用TensorFlow搭建图像分类器 本文将详细介绍如何通过TensorFlow搭建图像分类器，从安装、优化、编码、和使用等方面手把手教你用TensorFlow搭建图像分类器。 地址：http://www.leiphone.com/news/201702/JdaLcpYO59zTTF06.html 如何使用Tensorflow实现快速风格迁移？ 风格迁移（Style Transfer）是深度学习众多应用中非常有趣的一种，如图，我们可以使用这种方法把一张图片的风格“迁移”到另一张图片上，但原始的风格迁移的速度是非常慢的。在GPU上，生成一张图片都需要10分钟左右，而如果只使用CPU而不使用GPU运行程序，甚至需要几个小时。这个时间还会随着图片尺寸的增大而迅速增大，那么能否实现使用Tensorflow实现快速风格迁移？ 地址：http://www.leiphone.com/news/201701/tGlVRXWShwe7ffHW.html 运用TensorFlow处理简单的NLP问题 当前互联网每天都在产生大量的文本和音频数据，通过挖掘这些数据，我们可以做一些更加便捷的应用，例如机器翻译、语音识别、词性标注以及信息检索等，这些都属于NLP范畴。而在NLP领域中，语言模型是最基本的一个环节，本文主要围绕语言模型展开，首先介绍其基本原理，进而引出词向量(word2vec)、循环神经网络(RNN)、长短时记忆网络(LSTM)等深度学习相关模型，并详细介绍如何利用 TensorFlow 实现上述模型。 地址：http://blog.csdn.net/frankiegu/article/details/52133763 在TensorFlow中用深度度学习修复图像 生活中经常会遇到图片缺失问题，设计师和摄影师用内容自动填补来补充图像中不想要的或缺失的部分，本文将介绍通过一个 DCGAN 用深度学习进行图像修复。 地址：http://blog.csdn.net/whiteboy1999/article/details/53727376?locationNum=1&amp;fps=1 基于Tensorflow的CNN/CRF图像分割技术 本篇文章验证了卷积神经网络应用于图像分割领域时存在的一个问题——粗糙的分割结果。根据像素间交叉熵损失的定义，我们在简化的场景下进行了模型的训练，并使用后向传播来更新权重。我们使用条件随机场（CRFs）来解决分割结果粗糙的问题，并取得了很好的效果。 地址：https://yq.aliyun.com/articles/67189?spm=5176.8067842.tagmain.47.W3YH1h 利用Docker和阿里云容器服务轻松搭建分布式TensorFlow训练集群 由于在现实世界里，单机训练大型神经网络的速度非常缓慢，这就需要运行分布式TensorFlow集群并行化的训练模型。但是TensorFlow本身只是计算框架，要将其应用在生产环境，还是需要集群管理工具的资源调度，监控以及生命周期管理等能力。 本文将分两个部分介绍如何在阿里云容器服务上玩转TensorFlow训练集群。 第一部分：https://yq.aliyun.com/articles/68337?spm=5176.100239.blogcont60894.15.tOeTKV 第二部分：https://yq.aliyun.com/articles/60894?spm=5176.8067842.tagmain.29.W3YH1h 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"框架平台的综合对比","date":"2017-02-17T01:56:06.000Z","path":"2017/02/17/Program/TensorFlow/platforms-of-tensorflow/","text":"作者：AI研习社 TensorFlow 与其他平台、框架对比，具有哪些优点及劣势？ 作为机器学习领域、尤其是 Python 生态圈最受欢迎的框架平台，TensorFlow 具有许多吸引开发者的优点。其中最显而易见的是谷歌的技术支持和完善的社区（庞大用户群）。这些都为 TensorFlow 的普及打下了基础。但是，开发者需要了解 Tensorflow 在技术上有哪些值得一提的优势，又有哪些不足，以便在处理特定任务时进行工具选择。而这些，必须要在与其他平台、框架的对比中才能凸显。顺便说一句老生常谈的话，没有万能的工具，只有在不同应用场景下最合适的选择。 因此，雷锋网(公众号：雷锋网)整理了介绍 Tensorflow、Caffe、Microsoft Cognitive Toolkit （CNTK）、MXnet、Torch 等平台框架，以及对它们做横向对比的文章，供读者按图索骥。 ## 综合介绍 这部分的文章，对 TensorFlow 和其它主流深度学习框架、平台做了概括性介绍，归纳它们的主要特点。有经验的开发者可跳过。 **谷歌、微软、OpenAI 等巨头的七大机器学习开源项目 看这篇就够了** 对 Tensorflow、DeepMind Lab、Universe、FastText、CNTK、MXNet、SystemML 这七个开源机器学习平台、框架做了介绍。它们都是谷歌、微软、亚马逊、IBM 等国际互联网巨头开发或维护的平台，在一定程度上反应了巨头们的 ML 布局以及研究倾向。 注意：该文章发布时 Facebook 尚未推出 Pytorch。现在看来，Pytorch 是脸书在 ML 领域的关键项目。 地址：http://www.leiphone.com/news/201612/rFVygnQf4WjogJQR.html **深度学习——你需要了解的八大开源框架** 对 TensorFlow、Torch、Caffe、Theano、Deeplearning4j 等主流开源框架作了简要介绍，总结了它们的核心优势及特点。 地址：http://www.leiphone.com/news/201608/5kCJ4Vim3wMjpBPU.html （来源雷锋网） **对比深度学习十大框架：TensorFlow 最流行但并不是最好** 这篇文章翻译自 Medium，同样是对开源框架的综合性介绍。它出自 BEEVA Labs 的数据分析师 Ricardo Guerrero Gomez-Ol 之手，对 TensorFlow、Theano、Keras、Lasagne 等框架和工具做了简要介绍。 地址：http://geek.csdn.net/news/detail/132553 ## 横向对比 **这几天 AI 圈都在关注的深度学习库评测** 整理自香港浸会大学褚晓文教授研究团队的论文。褚教授在论文中对 Caffe、CNTK、MXNet、TensorFlow、Torch 几大工具在 CPU、GPU 平台上的性能表现做了深度评测。该论文一经发表便受到广泛关注，堪称是迄今为止，对上述几个主流深度学习框架最深入、客观的计算性能对比。其研究结果，简明扼要得归纳了这几大平台分别最适合处理何种神经网络任务。雷锋网强力推荐。 地址：http://www.leiphone.com/news/201701/OlEiX6kZLKHVUyW2.html （来源雷锋网） **机器学习和深度学习的最佳框架大比拼** 这篇文章翻译自 Infoworld，对 TensorFlow、Caffe、CNTK、MXNet、Scikit-learning、Spark MLlib 等几大框架的优缺点进行了点评，以及实践总结。本文针对不同背景、习惯的开发者，提供了平台选择上的建议。 地址：https://news.cnblogs.com/n/562250/ **TensorFlow 等主流深度学习框架比较分析** 这篇文章罗列了 TensorFlow、Theano、MXnet 三者的主要属性和技术规格，做了简明扼要的对比。 地址：http://www.tuicool.com/articles/BVFb6bb **Caffe、TensorFlow、MXnet 三个开源库对比** 这是国内一名为陈汝丹的开发者的实操心得，对三个框架发表了自己的看法。文章对技术的讨论较为细致，适合做实践参考。 地址：http://chenrudan.github.io/blog/2015/11/18/comparethreeopenlib.html#0-tsina-1-2654-397232819ff9a47a7b7e80a40613cfe1 ## 与其它框架的对比 **如何评价百度刚刚开源的 Paddle 平台？** 2016 年下半年开源的 PaddlePaddle 是百度的诚意之作，或许还是国内诞生的最具重量级的机器学习框架。这篇文章对其做了介绍，并邀请行业人士对 PaddlePaddle 相对于 TensorFlow、Caffe 的优缺点做了简要评论。 地址：http://www.leiphone.com/news/201608/TfDtMfbKkUOEieWm.html（来源雷锋网） **应该选择 TensorFlow 还是 Theano？** 由于 TensorFlow 与 Theano 有替代关系，两者之间的比较是个相对热门的话题。这是知乎上的问答，直接对比了这两个深度学习框架。 地址：https://www.zhihu.com/question/41907061 ## 补充 **TensorFlow 与 Apache Spark 结合：雅虎开源“TensorFlowOnSpark”** 最后，说到 TensorFlow 就不得不提最近的一个大新闻——“TensorFlowOnSpark”。该框架使得 TensorFlow 兼容于 Apache Spark，能直接获取后者的数据集，为开发者减少大量麻烦。 地址：http://www.leiphone.com/news/201702/XwhHugKHTk86WQso.html 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Tensorflow 的入门与安装","date":"2017-02-17T01:56:06.000Z","path":"2017/02/17/Program/TensorFlow/setup-of-tensorflow/","text":"作者：AI研习社 作为AI 领域最受关注和使用率最高的开源框架之一，TensorFlow 究竟是如何安装的呢？这篇汇总资料你不得不看！ 自2015年11月发布以来，谷歌旗下的机器学习开源框架TensorFlow已经在图像识别，大数据分析，语音识别和语义理解，机器翻译等各个领域得到了广泛应用，同时也得到了业内人士的普遍认可，成为了目前最受关注和使用率最高的开源框架之一。 本文将重点整理TensorFlow框架的入门和安装教程。更多关于TensorFlow的深入介绍、应用项目以及各机器学习开源框架之间的对比等内容，请见雷锋网(公众号：雷锋网)的系列文章。 下面是本文整理的资料内容： 在安装之前，这里先列出一些对TensorFlow给出大略介绍的文章，其中包括一些重要的概念解释，TensorFlow的具体含义和优点，以及TensorFlow的基本工作原理等。 《TensorFlow极速入门》链接：http://www.leiphone.com/news/201702/vJpJqREn7EyoAd09.html本文介绍了 graph 与 session 等基本组件，解释了 rank 和 shape 等基础数据结构概念，讲解了一些 variable 需要注意的地方并介绍了 placeholders 与 feed_dict 。最终以一个手写数字识别的实例将这些点串起来进行了具体说明。 《TensorFlow学习笔记1：入门》链接：http://www.jeyzhang.com/tensorflow-learning-notes.html本文与上一篇的行文思路基本一致，首先概括了TensorFlow的特性，然后介绍了graph、session、variable 等基本概念的含义，以具体代码的形式针对每个概念给出了进一步的解释。最后通过手写数字识别的实例将这些点串起来进行了具体说明。需要指出的是，两篇文章覆盖的基础概念不尽相同，并且举例用的代码也不一样。 《TensorFlow入门》链接：http://www.jianshu.com/p/6766fbcd43b9#与上面两篇不同，本文简单介绍了 TensorFlow 的含义、优点、安装和基本工作原理之后，直接通过代码示例的方式讲解了 TensorFlow 的简单用法，包括生成三维数据，然后用一个平面拟合它，以及通过 variable 实现一个简单的计数器等。 值得一提的是，以上第二和第三篇分别来自两个系列文章，这两个系列也都是关于 TensorFlow 入门和实践的优秀博客。第二篇的后续文章讲述了卷积神经网络（CNN）模型构建，以及利用 TensorFlow 生成词向量 (Word Embedding) 的具体过程。第三篇则实际上是基于斯坦福大学基于深度学习的自然语言处理课程的学习笔记，该系列其他的文章还讲述了循环神经网络（RNN）和 word2vec 模型等更深入的知识，感兴趣的读者可以从文章的作者页找到更多文章。 上述文章都更倾向于 TensorFlow 的简单介绍了基础用法，但对于TensorFlow具体安装过程的讲述则不够细致。因此这里专门针对TensorFlow的安装过程推荐一篇教程。 《真正从零开始，TensorFlow详细安装入门图文教程！》链接：http://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html上文来自雷锋网小编的亲身实践，真正做到了从零开始，详细介绍了在Linux环境下如何通过pip命令安装TensorFlow框架的完整流程，以及面对一些常见问题的处理办法。值得一提的是，本文在讲解完框架安装之后，还针对Komodo开发环境进行了简单介绍。 经过了以上来自民间的实践教程之后，相信各位读者对TensorFlow的大致情况和具体安装方法已经有了自己的理解。下面对于那些想要更全面和深入地了解TensorFlow的读者，我们推荐几个官方的教程。 谷歌官方入门教程链接：https://www.tensorflow.org/get_started/ 谷歌教程翻译https://github.com/jikexueyuanwiki/tensorflow-zh 这里谷歌给出的入门教程内容十分丰富，除了最基本的安装、名词解释和代码示例之外，还给出了 API 接口的详细解释和说明。但考虑到内容全是英文，因此雷锋网在这里给出了国内志愿者对谷歌内容的中文翻译版，可以为那些英文不好的读者提供参考。 TensorFlow中文社区http://www.tensorfly.cn/最后我们在这里推荐一个 TensorFlow 的中文社区，该网站几乎可以认为是 TensorFlow 的中文官网，除了上述谷歌官方教程的中文翻译之外，该网站还包括进阶指南、API中文手册、精华文章和TF社区等诸多板块。 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Tensorflow的迭代更新","date":"2017-02-17T01:49:06.000Z","path":"2017/02/17/Program/TensorFlow/history-of-tensorflow/","text":"作者：AI研习社 谷歌于2015年11月发布了全新人工智能系统TensorFlow，距今已有15个月时间，在这期间发生了哪些变化？ 谷歌于2015年11月发布了全新人工智能系统TensorFlow。该系统可被用于语音识别或照片识别等多项机器深度学习领域，主要针对2011年开发的深度学习基础架构DistBelief进行了各方面的改进，它可在小到一部智能手机、大到数千台数据中心服务器的各种设备上运行。 那么为什么会产生TensorFlow系统，以及谷歌为何将其开源？这个问题可以看雷锋网文章[《Google开源TensorFlow系统，这背后都有什么门道？》](http://www.leiphone.com/news/201511/Voza1pFNQB4bzKdR.html)。 2016年4月14日，Google发布了分布式TensorFlow，版本号为0.8，这是TensorFlow发布之后的比较重大的版本更新。Google的博文介绍了TensorFlow在图像分类的任务中，在100个GPUs和不到65小时的训练时间下，达到了78%的正确率。在激烈的商业竞争中，更快的训练速度是人工智能企业的核心竞争力。而分布式TensorFlow意味着它能够真正大规模进入到人工智能产业中，产生实质的影响。 详情可以阅读雷锋网文章《开源后5个月，Google的深度学习系统都有哪些改变？》。 在2016年6月，TensorFlow发布了新版本的早期版本，版本号为0.9，增加了对iOS的支持。 随着谷歌增加了TensorFlow对iOS的支持，应用程序将能够在更聪明的神经网络功能集成到它们的应用程序，最终使它们更聪明相当能干。具体更新内容可以在《谷歌AI平台发布早期版本，并登陆iOS》中看到。 在2017年1月底，TensorFlow 终于将迎来史上最重大更新：TensorFlow 1.0。Tensorflow它已成为 GitHub 最受欢迎的机器学习开源项目。因其高度普及率，尤其是在 Python 生态圈中，TensorFlow 的功能变化会对全世界的机器学习开发者造成重大影响。 上月初，谷歌公布了 TensorFlow 1.0.0-alpha ，即 TensorFlow 1.0 的第一个“草稿”版本。近日，新的候选版本 TensorFlow 1.0.0-rc0 被发布出来，披露了更多技术细节，标志着我们离 “完全体”的 TensorFlow 1.0 更近一步。 1.0 版本不仅为 TensorFlow 机器学习函数库带来多重升级，而且为 Python 和 Java 用户使用 TensorFlow 做开发降低了难度。另外，新版本的漏洞修补也得到了改善。更有意思的是，由于对 TensorFlow 计算做优化的新编译器，在智能手机上运行基于 TensorFlow 的机器学习 APP 将成为可能。 具体更新内容可以看雷锋网(公众号：雷锋网)文章《TensorFlow 1.0 要来了！它将带来哪些革命性变化？》 在2月7日谷歌通过博客正式发布了 TensorFlow Fold，该库针对 TensorFlow 1.0 框架量身打造，可以帮助深度学习开发者根据不同结构的输入数据建立动态的计算图（Dynamic Computation Graphs），简化了模型训练阶段对输入数据的预处理过程，提升了系统的运行效率。这个库的更多信息可以在《谷歌刚发布的深度学习动态计算图工具TensorFlow Fold是什么？》中看到。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"人工智能 VS 机器学习","date":"2017-02-15T14:49:06.000Z","path":"2017/02/15/Program/Concepts/ai-vs-machine-learning/","text":"作者：网易AI研究院 对于企业而言，该投资人工智能还是机器学习呢？国外媒体发表Avanade高级总监贾马尔·赫瓦贾（Jamal Khawaja）的文章对这一问题进行了深入解析。 在过去的一年里，笔者一直在研究两种在如何利用大数据上相互矛盾的方法：人工智能（AI）和机器学习（ML）。毕竟，大数据没什么令人兴奋的，除非你有个机制去处理它。经过数周的深入研究后，我意识到大家对于一切的定义都是不一致的。另外，二者之间的区别相当无趣乏味。因此，我将尝试用一种既不讨好供应商也不讨好学术界的语言，来解析我对未来十年行业的发展的看法。 不过，在展开讨论之前，我们首先说明一些背景信息。先来谈谈AI和ML与大数据相关的定义： 人工智能：AI的目标是理解神经功能，模拟大脑的神经功能来从给定的情境中学习。在很多情况下，大脑实质上就是鲁布·戈德堡机器（即极为复杂的机器设备）。有了这种进化性的构建模块，我们就能够达到一种复杂的终端状态。 早在1980年代，AI在科学家当中是一个热门研究领域：专家们是如何做他们的工作的，如何将他们的那些任务简化成一系列的规则，如何通过编程给计算机引入那些规则，进而取代那些专家。研究人员想要教导计算机诊断疾病，翻译各种语言，甚至推断我们想要但不自知的东西。从根本上说，AI寻求构造在一个系统内进行逻辑推理的能力。 这种努力并没有成功。 在被宣告失败之前，传统的AI项目吸引了数亿美元的风投资金。当时，AI的问题在于，我们没有足够有成本效率的计算能力去完成那些目标。但得益于Map Reduce和云技术，我们现在有足够充裕的计算能力去做AI。 机器学习：ML实际上是数项技术的集合，其中包括计算统计学、算法设计和数学，旨在尝试进行数据挖掘分析，以发现模式，再将模式转化成语言。这种技术会给系统提供初始的指令组，然后系统进行数据归纳，发现或者推断出模式，以期将那些信息应用到新的解决方案。 ML是从AI进化而来的。当AI的挑战变得非常显著，变得无法克服时，理论家们寻求一种更加定制化的归纳计算决策方法。这种模式有不同的种类。供应商们将它们的系统称为“机器智能”或者“监督式学习”。 除了更容易构造以外，机器学习的好处都显而易见。ML始于一个界定的问题，以及描述对给定数据集的恰当分析的规则组。 AI与ML的相似之处 - 迭代算法：尽管机制上存在差异，但ML和AI有着共同的主要组成部分：迭代学习。在ML中，迭代学习是从所描述的参数组中定义不确定边界的过程。在AI中，迭代学习通过通常随时间变动的非线性序列发生。 - 数据越多，迭代越快：系统本身会从学习中构造和优化算法模型。 - 可应用在明确算法不能实行的地方（垃圾邮件过滤、OCM和计算机视觉）。本质上，当物体、动作或者任何其它的东西的定义无法精确描述出来的时候，就需要更加复杂的指令组（通常是概率建模）来分析和理解。 -两种系统都依靠基于归纳推理的“学会学习”能力：二者的运作过程存在着很大的差异，但最终的效果都取决于系统从经验中学习的能力。那种学习可以是外显的，有指导的（典型的例子就是机器学习），也可以是基于一系列的先验知识，由系统本身进行推测（典型例子就是人工智能）。 人工智能 - AI的目标是推理。系统不仅仅要鉴别需要估算什么，还要鉴别如何进行估算，即便在不确定的情况下也是如此。这是一项困难的任务，很多人都缺乏这种能力。 - 所基于的神经网络：AI执行最常见的解决方案机制是人工神经网络。从根本上说，不同抽象层次的互联神经元会权衡受观察或者被计算的行为的价值，会通过使用输入的非线性函数来调整驱动系统的算法。 - 在不同的抽象层次学习：AI算法会在信号从输入层传送到输出层的过程中将信号遇到的转变参数化。该转变是有可训练的考量因素的处理单元，如权重和阈值。层数反映神经网络的复杂性，参数的权重反映它背后的逻辑。 - 寻找方差的转变，以识别变化：在神经网络中，有机制识别方差的实际转变和变化的程度。这是AI的基石之一；量化方差和推断其影响的能力对于AI而言必不可少。 机器学习 - ML专注于根据已知属性预测未知属性，这反过来是依据概率分布。这反映出ML的两个主要目标： 1. 目标是解决问题；利用给定的带有定义输入的数据组和监督式误差反向传播，鉴别和解决问题 2. ML并不是寻求思考的能力；相反，它是寻求做会思考的实体能够做的事情的能力 -ML方面有两类函数：能够被学习的东西和不能够被学习的东西。这种机制是通过围绕与前馈控制系统相关的复杂性建模建立起来的，该系统负责将来自来源的控制信号向外部环境进行例示。这表明理解的层次不仅仅是围绕系统扰动，还围绕基于数学建模的系统中的预期变化。相反地，反馈系统会反应性地改变控制信号。这些系统无法使得行为有理化时，则会将函数渲染为无法学习的东西，以及在机器学习环境范畴之外的东西。 关于ML，值得注意的是量子机器开始被引入系统的学习过程。理论上，量子计算可给给定环境提供无限量的前馈系统。人们可能会断定，量子学习本质上不是确定性的；量子计算（量子位）的基本计算元素创造了一种模糊的逻辑模型。这可能会带来已知物理定律下最具创造性的问题解决过程。目前，它正被应用于图像识别，但未来的实施会考虑训练基于难解运算的概率模型。 然而，不管使用哪一种系统： - 你最终都会得出经过优化的结果。你不一定理解你是如何将其进化的，但结果不言而喻。你只能够理解过程和界面。 - 学习的中心从产品转向过程：不改动最终产品，而是改动过程。 - 这两种模型都不仅仅涉及工程设计：我们试图创造的东西比我们想象的要多。 那么，该投资AI还是ML呢？说到底，这取决于你的业务需求。ML可提供大量的企业友好型工具，这使得它成为很多企业项目的首选解决方案：它能够受到已知技术的约束；它能够解决特定的问题，所出现的问题能够通过调整输入信息、数据结构或者输出值来解决。事实上，AI在1980年代失宠是有原因的：无法将专家的能力转化成可外推到更加复杂的场景的规则组。 然而，我认为AI才是未来。推理能力包含比商业需要重要的智力能力和情感能力。这是程序员、理论家和科学家们自统计学分析创立以来一直在竭力追求的东西；我们如何才能创造出能够解答我们不知道的问题的机器呢？IBM在这一领域进行了巨额投资，微软，特斯拉，甲骨文，谷歌，地球上的每一家医疗保健公司，大多数的银行，每一位想要找到赚更多钱的窍门且精通技术的企业家亦然。 如果你是位普通的企业家，那就投资机器学习。它会给你带来好处。但如果你是有远见的人，那就投资人工智能，你可能会改变世界。（皓慧） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 AI研究院 | 科普：人工智能与机器学习到底有什么区别？ 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月10日消息，人们常常把人工智能与机器学习混为一谈，其实这两者之间有着很大的区别。 机器学习和人工智能是当前科技领域的两大趋势。实际上，这两个术语经常可以互换使用。然而，两者之间仍然存在着微妙却重大的差异。 从很多方面来说，机器学习是人工智能的一部分。而且，人工智能这个术语也比机器学习出现得更早。 它们之间的区别到底是什么呢? 人工智能的核心是试图让机器以人脑的方式进行思考。 著名的图灵测试表明，如果人类不能将一个系统的行为与人类的行为区别开来，那么这个系统就可以说是智能的。然而，目前的技术远未达到这一目标，所以人工智能目前也只是意味着创造出能够做出人类擅长的行为的系统。但这只是个笼统的说法。 机器学习也可以追溯到20世纪中期。阿瑟塞缪尔将机器学习定义为“在没有进行明确编程的情况下的学习能力”。 使用及应用 机器学习 机器学习的原理几十年来一直没有得到重视(这一点与人工智能很像)，但随着上个世纪末之前数据挖掘工作的兴起，人们 需要一种算法来寻找每一个数据集的模式。机器学习做到了这一点，但它又更进一步，从过程中学习，而它的性能也会随着不断学习而提高。 机器学习的另一种用途是图像识别。这些应用最初是由人类训练的，先观察图像，然后进行描述。在使用了成千上万的图像进行训练之后，机器学习系统就可以根据像素分辨出画面中是一条狗、一座房子、一束鲜花还是一个人。 机器学习也可以在推荐引擎中使用。这些算法可以帮助Facebook决定在新闻中显示什么信息，或者帮助亚马逊决定向用户推送什么广告。 随着大数据分析越来越普及，企业正在向依靠机器学习来驱动预测分析转变。与统计数据、数据挖掘和预测分析的联系已经足够让人认为机器学习是人工智能的一个领域。 原因就在于，诸如自然语言处理或自动推理的人工智能技术可以在没有机器学习能力的情况下完成。机器学习系统并不需要具有人工智能的其他特征。 人工智能 人工智能目前有数百个使用案例，而随着企业不断采用人工智能来应对商业挑战，人工智能的案例也开始为人所知。 当前最受欢迎的人工智能应用之一是语音助手。微软的Cortana、Siri、谷歌助理和亚马逊Alexa都是智能家居和智能手机的核心部分，用户可以通过聊天机器人预约午餐会议，或者用语音助手来控制家里的照明开关。但是，Alexa现在站在另一个行业的前沿。聊天机器人和davis可以让IT管理员通过询问davis问题来识别和修复IT基础架构的问题。 人们有充分的理由担心人工智能将取代人类的工作岗位，如数据输入。牛津大学预计，在未来20年，英国约有35%的就业机会将被自动化取代。 将两个术语混淆 还有一些与这一主题相关的其他的术语。人工神经网络处理信息的方式与人脑类似。但是人工神经网络也相当擅长机器学习，这就让事情变得更加复杂了。 这种神经网络构成了深度学习的基础，而 深度学习本身就是机器学习的一种形式。 大量的机器学习算法能够利用成百上千的GPU瞬间处理大量数据。 如果你对这些感到困惑，不要担心，科学家们仍在探讨机器学习和人工智能的确切定义，探讨可能会一直持续下去。 （英文来源：ITPRO 编译：机器小易 审校：日月沉香） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"Atom编辑器入门到精通","date":"2017-02-15T13:38:06.000Z","path":"2017/02/15/Program/techniques-of-atom-editor/","text":"原文作者：PeterHo Atom是GitHub推出的一款编辑器, 被称为21世纪的黑客编辑器. 其主要的特点是现代, 易用, 可定制. 命令面板命令面板是Atom中最常用的功能之一, 当你在编辑器中使用快捷键Ctrl+Shift+P时, 就会看到它在控制面板中可以输入Atom中和插件中定义的所有命令, 并且支持模糊搜索比如说当你输入cboo时, 所有包含有这4个字符的命令就都列出来了在列出的命令后还显示了此命令对应的快捷键(如果有的话) 保存文件 快捷键 Ctrl+S保存所有文件: File-&gt;Save All 打开文件夹是一个很实用的功能, 可以像IDE一样打开一个项目的根目录可以通过在主菜单选择File-&gt;Add Project Folder…来打开或者添加一个目录,也可以使用快捷键Ctrl+Alt+O.在打开一个文件夹以后该文件夹下的所有子目录和文件就会如下图一样以目录树的方式显示在主窗口左边你可以通过在目录树栏中右键菜单或选中文件时使用快捷键a,m,delete来对文件进行新建,重命名,删除等操作如果要切换目录树栏的显示与隐藏可以使用快捷键Ctrl+\\或输入命令Tree View:Toggle目录树中右键菜单中还能实现文件的复制粘贴等功能 查找文件 当打开一个或多个目录时,你可以: 通过Ctrl+T或Ctrl+P来搜索目录中的文件 通过Ctrl+B来搜索一个当前打开的文件 通过Ctrl+Shift+B来搜索一个新建的或更改过的文件 文本编辑基础使用Ctrl+F进行文件内查找使用Ctrl+Shift+F进行工程内查找 代码片段(Snippets)代码片段(Snippets) 片段（Snippet）是一个编程用语，指的是源代码、机器码、文本中可重复使用的小区块。通常它们是有正式定义的执行单位，以纳入更大的编程模块。片段经常用来明晰其他“凌乱”函式的功用，或尽量减少使用与其他函式共用的重复代码。 片段管理是某些文本编辑器、程式源代码编辑器、IDE、与相关软件的其中一项功能。其使得使用者能够在反复的编辑作业中保持和使用这些片段。 让我们通过一个实验来感受一下Snippets给我们带来的便利体验 打开Atom编辑器 使用Cmd+N新建一个文件 使用Cmd+S保存文件,将文件名改为new.html 在new.html中键入html四个字符,然后按tab键,这时你会发现html这段文本被扩展成了12345678&lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt;&lt;/html&gt; 并且光标被移到了标签之间,方便你直接输入这个html文件的标题 在标签之间输入完成html页面标题以后,再次键入tab键你会发现光标又被移到了标签下面了 Snippets,它让你可以很方便地通过一个关键词来插入一段代码块,并且还能通过tab键在这段代码块的输入点之间移动光标,达到快速编码的目的不同类型的文件有不同的Snippets,你可以通过控制面板输入Snippets:available来列出当前文件所提供的所有的Snippets 预览在进行Markdown文档的编辑时, 我们经常想要看一看编辑的效果. Atom默认就支持这一功能.我们只需要在编辑md文件时使用Ctrl+Shift+M, 就能显示一个预览窗口, 方便我们随时查看md编辑的效果. 并且这个预览窗口还能随着我们的编辑自动刷新预览的内容和效果. Snippets(代码片段) Atom中内置了多个Snippets来方便Markdown文档的编辑.比如img(插入图片), table(插入表格), b(插入粗体), i(插入斜体), code(插入代码)等.关于Snippets的详细使用方法请参考本系列文章的第四章Atom使用进阶. CSONCSON(CoffeeScript Object Notation)是Atom配置文件的文件格式, 它使用键值对的格式来存储数据. 就像下面这个样子 key: key: value key: value key: [value, value] 跟Python类似, CSON使用缩进来标识语句块. CSON的key的名字不能重复, 如果CSON中包含了多个同名的key, 那么最后的那个key的值会覆盖之前同名的key.因此不能这样配置 只有第二个snippet会被载入‘.source.js’: ‘console.log’: ‘prefix’: ‘log’ ‘body’: ‘console.log(${1:”crash”});$2’‘.source.js’: ‘console.error’: ‘prefix’: ‘error’ ‘body’: ‘console.error(${1:”crash”});$2’ 而应该这样配置 两个snippets都会被载入‘.source.js’: ‘console.log’: ‘prefix’: ‘log’ ‘body’: ‘console.log(${1:”crash”});$2’ ‘console.error’: ‘prefix’: ‘error’ ‘body’: ‘console.error(${1:”crash”});$2’ value可以是字符串, 数字, 对象, 布尔值, null, 或数组. 配置热键在Atom中热键的配置方式与主题类似, 举个例子: 12345'atom-text-editor': 'enter': 'editor:newline''atom-text-editor[mini] input': 'enter': 'core:confirm' 上面的代码定义了Enter键在不同环境中的不同表现. 在正常的编辑窗口中按enter键触发editor:newline命令, 也即是普通的回车. 而当在一个编辑框中键入enter时, 则会触发core:confirm命令. 在默认情况下, 当Atom启动时会加载keymap.cson文件来获取自定义热键, 并且keymap.cson是最后被加载的配置文件, 这样可以保证我们配置的热键可以覆盖Atom自身或其插件定义的热键. 这个文件同样位于~/.atom目录下, 当然也可以通过主菜单Edit-&gt;Keymap…来直接编辑这个文件. 我们也可以在设置窗口的Keybindings页面查看当前所有的快捷键. Atom还提供了一个窗口来帮助我们调试热键的设置, 可以使用Ctrl+.或命令Key Binding Resolver: Toggle来呼出该窗口. 此窗口可以实时显示我们按下的热键所对应的处理方法.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Atom","slug":"Atom","permalink":"http://ipcreator.me/tags/Atom/"}]},{"title":"吴恩达 NIPS 2016：利用深度学习开发人工智能应用的基本要点","date":"2017-02-14T06:39:06.000Z","path":"2017/02/14/Program/Concepts/ppt-of-andrew-ng/","text":"作者：雷锋网 亚峰 雷锋网(公众号：雷锋网)按：为了方便读者学习和收藏，雷锋网特地把吴恩达教授在NIPS 2016大会中的PPT做为中文版，由三川和亚峰联合编译并制作。 今日，在第 30 届神经信息处理系统大会（NIPS 2016）中，百度首席科学家吴恩达教授发表演讲：《利用深度学习开发人工智能应用的基本要点（Nuts and Bolts of Building Applications using Deep Learning）》。 此外，吴恩达教授曾在今年 9 月 24/25 日也发表过同为《Nuts and Bolts of Applying Deep Learning》的演讲(1小时20分钟)，以下是 YouTube 链接： https://www.youtube.com/watch?v=F1ka6a13S9I 一、深度学习为何崛起 吴恩达在开场提到：深度学习为何这么火？ 答案很简单： 第一是因为规模正在推动深度学习的进步。 从传统算法到小型神经网络、中型神经网络最后演化为现在的大型神经网络。 第二：端到端学习的崛起 从下图中的上半部分可以看出，传统端到端学习是把实体数据表达成数字数据，输出数字值作为结果。如退昂识别最后以整数标签输出为结果。 而现在的端对端学习更为直接纯粹，如机器翻译：输入英语文本，输出法语文本；语音识别：输入音频，输出文本。但端对端学习需要大量的训练集。 吴恩达先讲述了常见的深度学习模型，然后再着分析端到端学习的具体应用。 二、主要的深度学习模型 普通神经网络 顺序模型 (1D 顺序) RNN, GRU, LSTM, CTC, 注意力模型 图像模型 2D 和 3D 卷积神经网络 先进/未来 技术：无监督学习（稀疏编码 ICA, SFA,）增强学习 三、端到端学习应用案例 语音识别 传统模型：语音→运算特征—（人工设计的 MFCC 特征）→音素识别器—（音素识别）→最终识别器→输出。 端到端学习：音频→学习算法→转录结果；在给定了足够的有标注数据（音频、转录结果）时，这种方法的效果会很好。 自动驾驶 传统模型：摄像头图像→检测汽车+检测行人→路径规划→方向控制。 端到端学习：摄像头图像→学习算法→方向控制。 自动驾驶对安全有极高要求，因此需要极高的精确度。采取纯粹的端到端学习十分有挑战性。只在有足够（x，y）的数据，来学习足够复杂的函数的情况下，端到端学习才有效果。 四、机器学习策略 你经常有很多改进 AI 系统的主意，应该怎么做？好的战略能避免浪费数月精力做无用的事。 以语音识别为例，可以把原语音数据分割成： 60% 训练集（训练模型） 20% 开发集（开发过程中用于调参、验证等步骤的数据集） 20% 测试集（测试时所使用的数据集） 这里面普及几个概念： 人类水平的误差与训练集的误差之间的差距是可避免的偏差，这部分误差可以通过进一步的学习/模型调整优化来避免。 训练集和开发集之间的差距称为方差，其因为跑了不同的数据从而导致误差率变化。 上述两种偏差合在一起，就是偏差-方差权衡（bias-variance trade-off）。 机器学习的基本方案 自动数据合成示例 不同训练、测试集的分布 假设你想要为一个汽车后视镜产品，开发语音识别系统。你有 5000 小时的普通语音数据，还有 10 小时的车内数据。你怎么对数据分组呢？这是一个不恰当的方式： 不同训练和测试集分配 更好的方式：让开发和测试集来自同样的分配机制。 五、机器学习新方案 普通人类、偏差、方差分析 人类的表现水平 当机器学习在处理某项任务上比人类表现还差时，你经常会看到最快的进步。 机器学习超越人后，很快就会靠近贝叶斯最优误差线。 可以依靠人类的直觉：（i）人类提供加标签的数据。（ii）进行错误分析，来理解人是怎么对样本正确处理的（iii）预估偏差/方差。比如，一项图像识别任务的训练误差 8%， 开发误差 10%，你应该怎么处理？ 六、人工智能产品管理 新的监督DL算法的存在，意味着对使用 DL开发应用的团队合作，我们在重新思考工作流程。产品经理能帮助 AI 团队，优先进行最出成果的机器学习任务。比如，对于汽车噪音、咖啡馆的谈话声、低带宽音频、带口音的语音，你是应该提高语音效果呢，还是改善延迟，缩小二进制，还是做别的什么？ 今天的人工智能能做什么呢？这里给产品经理一些启发： 如果一个普通人完成一项智力任务只需不到一秒的思考时间，我们很可能现在，或者不远的将来，用 AI 把该任务自动化。 对于我们观察到的具体的、重复性的事件（比如用户点击广告；快递花费的时间），我们可以合理地预测下一个事件的结果（用户是否点击下一个此类广告）。 产品经理和研究员、工程师该如何分工 七、吴恩达新书推荐 雷锋网原创文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"Facebook 发布开源框架 PyTorch","date":"2017-02-14T05:11:06.000Z","path":"2017/02/14/Program/TensorFlow/pytorch-of-facebook/","text":"作者：雷锋网 三川 本周，Facebook 的 AI 研究团队发布了一个 Python 工具包，专门针对 GPU 加速的深度神经网络（DNN）编程。它有望辅助、或在一定程度上替代，现有的 Python 数学、统计库（比如 NumPy）。它实现了机器学习框架 Torch 在 Python 语言环境的执行。开发团队表示，除 Facebook之外，它还已经被推特、卡内基梅隆大学和 Salesforce 等机构采用。 Torch 是一个十分老牌、对多维矩阵数据进行操作的张量（tensor ）库，在机器学习和其他数学密集型应用有广泛应用。但由于其语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。如今，作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。雷锋网此前对 Torch 做过介绍。详情请看盘点四大民间机器学习开源框架：Theano、Caffe、Torch 和 SciKit-learn 。 PyTorch 的特点和优势 PyTorch 提供了： 运行在 GPU 或 CPU 之上、基础的张量操作库， 内置的神经网络库 模型训练功能 支持共享内存的多进程并发（multiprocessing ）库。PyTorch 开发团队表示：这对数据载入和 hogwild 训练十分有帮助。 PyTorch 的首要优势是，它处于机器学习第一大语言 Python 的生态圈之中，使得开发者能接入广大的 Python 库和软件。因此，Python 开发者能够用他们熟悉的风格写代码，而不需要针对外部 C 语言或 C++ 库的 wrapper，使用它的专门语言。雷锋网获知，现有的工具包可以与 PyTorch 一起运行，比如 NumPy、SciPy 和 Cython（为了速度把 Python 编译成 C 语言）。 PyTorch 还为改进现有的神经网络，提供了更快速的方法——不需要从头重新构建整个网络。这是由于 PyTorch 采用了动态计算图（dynamic computational graph）结构，而不是大多数开源框架，比如 TensorFlow、Caffe、CNTK、Theano 等采用的静态计算图。雷锋网(公众号：雷锋网)获知，该技术从另一个 Python 的神经网络框架——Chainer 那里借用。开发者团队还强调 PyTorch 优越的内存效率，因为它采用了定制的 GPU 内存分配器。这使得开发者的深度学习模型能够有“最大限度的内存效能”，训练比从前更大的深度神经网络。 虽然 PyTorch 为机器学习应用而优化，这并不是它的唯一使用场景。比如说，相比 NumPy ，PyTorch 的张量计算可作为它对应功能的替代。PyTorch 为这些功能提供了 GPU 加速的版本。在没有强力 GPU 加持的情况下，开发者能使用 CPU 运行。 这是 PyTorch 中包含的工具包列表： torch ：类似 NumPy 的张量库，强 GPU 支持 torch.autograd ：基于 tape 的自动区别库，支持 torch 之中的所有可区分张量运行。 torch.nn ：为最大化灵活性未涉及、与 autograd 深度整合的神经网络库 torch.optim：与 torch.nn 一起使用的优化包，包含 SGD, RMSProp, LBFGS, Adam 等标准优化方式 torch.multiprocessing： python 多进程并发，进程之间 torch Tensors 的内存共享。 torch.utils：数据载入器。具有训练器和其他便利功能。 Trainer and other utility functions for convenience torch.legacy(.nn/.optim) ：处于向后兼容性考虑，从 Torch 移植来的 legacy 代码。 via infoworld","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"如何训练深度神经网络？老司机的 15 点建议","date":"2017-02-13T23:54:06.000Z","path":"2017/02/14/Program/TensorFlow/how-to-train-deep-neural-network/","text":"作者：雷锋网 本文为印度深度学习专家、创业者 Rishabh Shukla 在 GitHub 上发表的长博文，总结了他过去的开发经验，旨在给新入门的开发者提供指导。雷锋网做了不改变原意的编译。 在深度学习领域，为了高效训练深度神经网络，有些实践方法被过来人强烈推荐。 在这篇博文中，我会覆盖几种最常使用的实践方法，从高品质训练数据的重要性、超参数（hyperparameters）到更快创建 DNN（深度神经网络） 原型模型的一般性建议。这些推荐方法中的大多数，已被学术界的研究所证实，并在论文中展示了相关实验、数学证据，比如 Efficient BackProp(Yann LeCun et al.) 和 Practical Recommendations for Deep Architectures(Yoshua Bengio)。 训练数据 许多 ML 开发者习惯把原始训练数据直接扔给 DNN——为什么不这么做呢？既然任何 DNN （大多数人的假设）仍然能够给出不错的结果，不是吗？但是，有句老话叫“给定恰当的数据类型，一个简单的模型能比复杂 DNN 提供更好、更快的结果”。虽然这有一些例外，但在今天，这句话仍然没有过时。因此，不管你是在计算机视觉（ CV），自然语言处理（NLP）还是统计建模（Statistical Modelling）等领域，想要对原始数据预处理，有几个方法可以得到更好的训练数据： 获取越大的数据库越好。DNN 对数据很饥渴，越多越好。 去除所有包含损坏数据的训练样本，比如短文字，高度扭曲的图像，假输出标签，包含许多虚值（null values）的属性。 Data Augmentation（数据扩张）——生成新样例。以图像为例，重新调节，增加噪声等等。 选择恰当的激励函数（activation function） 激励函数是所有神经网络的核心部分之一。 激励函数把渴望已久的非线性（non-linearity）加入了模型。多年来，Sigmoid 函数 一直是多数人倾向的选择。但是，Sigmoid 函数不可避免地存在两个缺陷：1. 尾部 sigmoids 的饱和，进一步导致梯度消失。2. 不以 0 为中心（输出在 0 到 1 之间）。 一个更好的替代选择是 Tanh 函数。数学上来说，Tanh 只是调整、平移过的 Sigmoid 函数：tanh(x) = 2*sigmoid(x) - 1。虽然 Tanh 仍旧存在梯度消失的缺陷，但好消息是：Tanh 以 0 为中心。因此，把 Tanh 作为激励函数能更快地收敛（converge）。我发现使用 Tanh 通常比 Sigmoid 效果更好。 你还可以探索其他选择，比如 ReLU, SoftSign 等等。对于一些特定任务， 它们能够改善上述问题。 隐藏单元和隐层（Hidden Units and Layers）的数量 如何训练深度神经网络？老司机的 15 点建议 保留超出最优数量的隐藏单元，一般是比较保险的做法。这是因为任何正则化方法（ regularization method）都会处理好超出的单元，至少在某种程度上是这样。在另一方面，保留比最优数量更少的隐藏单元，会导致更高的模型欠拟合（underfitting）几率。 另外，当采用无监督预训练的表示时（unsupervised pre-trained representations，下文会做进一步解释），隐藏单元的最优数目一般会变得更大。因此，预训练的表示可能会包含许多不相关信息（对于特定任务）。通过增加隐藏单元的数目，模型会得到所需的灵活性，以在预训练表示中过滤出最合适的信息。 选择隐层的最优数目比较直接。正如 Yoshua Bengio 在 Quora 中提到的： “你只需不停增加层，直到测试误差不再减少。” 权重初始化 （Weight Initialization） 永远用小的随机数字初始化权重，以打破不同单元间的对称性（symmetry）。但权重应该是多小呢？推荐的上限是多少？用什么概率分布产生随机数字？ 当使用 Sigmoid 激励函数时，如果权重初始化为很大的数字，那么 sigmoid 会饱和（尾部区域），导致死神经元（dead neurons）。如果权重特别小，梯度也会很小。因此，最好是在中间区域选择权重，比如说那些围绕平均值均衡分布的数值。 幸运的是，已经有许多关于初始权重合适取值的研究。这对于高效的收敛非常重要。为初始化均衡分布的权重，均匀分布（uniform distribution ）或许是最好的选择之一。另外，就像论文中所展示的（Glorot and Bengio, 2010），有更多输入连接（fan_in）的单位，应该有相对更小的权重。 多亏这些十分透彻的试验，现在我们已经有了经过检验的公式，可以直接用来权重的初始化。 比如说在 ~ Uniform(-r, r) 提取的权重，对于 tanh 激励 r=sqrt(6/(fan_in+fan_out))；对于 sigmoid 激励 r=4*(sqrt(6/fan_in+fan_out)) 。fan_in 是上一层的大小， 而 fan_out 是下一层的。 学习率 这或许是最重要的超参数之一，调节着学习过程。如果学习率设置得太小，你的模型很可能需要 n 年来收敛。设置得太大，再加上不多的初始训练样本，你的损失可能会极高。一般来说，0.01 的学习率比较保险。但雷锋网(公众号：雷锋网)提醒各位读者，这不是一个严格的标准。最优学习率与特定任务的属性息息相关。 相比固定学习率，在每个周期、或每几千个样例后逐渐降低学习率是另一个选择。虽然这能更快地训练，但需要人工决定新的学习率。一般来说，学习率可以在每个周期后减半。几年前，这种策略十分普遍。 幸运的是，我们现在有了更好的、基于动能（momentum based）的方法，来调整学习率。这取决于误差函数的曲率。另外，既然有些参数有更快、或更慢的学习速率；它或许能帮助我们针对模型中的单独参数，设定不同的学习率。 最近有大量关于优化方法的研究，导致了自适应学习率（adaptive learning rates）。目前我们有许多选择，从老式动能方法（ Momentum Method ），到 Adagrad、Adam （个人最爱）、 RMSProp 等等。；类似于 Adagrad 或 Adam 的方法，能替我们省去人工选择初始学习率的麻烦；给定合适的时间，模型会开始平滑地收敛。当然，选择一个特别合适的初始学习率仍然能起到帮助作用。 超参数调参：扔掉网格搜索，拥抱随机搜索 网格搜索（Grid Search ）在经典机器学习中十分普遍。但它在寻找 DNN 的最优超参数方面一点也不高效。这主要是由于 DNN 尝试不同超参数组合所耗费的时间。随着超参数不断增长，网格搜索需要的计算性能会指数级增长。 有两种解决办法： 取决于你之前的经验，你可以人工对部分常见超参数调参，比如学习率、隐层数目。 采用随机搜索（random search），或者随机采样代替网格搜索，来选择最优超参数。 超参数组合通常在期望范围之内、从均匀分布中被选择出来。加入之前获得的知识来进一步缩小搜寻空间，也是有可能的（比如，学习率不应该太大也不应该太小）。大家发现，随机搜索比网格搜索高效地多。 学习方法 随机梯度下降（ Stochastic Gradient Descent ）的老方法也许对于 DNN 不是那么有效率（有例外）。最近，有许多研究聚焦于开发更灵活的优化算法，比如 Adagrad、Adam,、AdaDelta,、RMSProp 等等。在提供自适应学习率之外，这些复杂的方法还对于模型的不同参数使用不同的学习率，通常能有更平滑的收敛。把这些当做超参数是件好事，你应该每次都在训练数据的子集上试试它们。 权重的维度保持为 2 的幂 即便是运行最先进的深度学习模型，使用最新、最强大的计算硬件，内存管理仍然在字节（byte）级别上进行。所以，把参数保持在 64, 128, 512, 1024 等 2 的次方永远是件好事。这也许能帮助分割矩阵和权重，导致学习效率的提升。当用 GPU 运算，这变得更明显。 无监督预训练（Unsupervised Pretraining ） 不管你进行的是 NLP（自然语言处理）、计算机视觉还是语音识别等任务，无监督预训练永远能帮助你训练监督、或其他无监督模型：NLP 中词向量就（Word Vectors）无所不在；你可以用 ImageNet 的数据库，使用无监督方式对你的模型预训练，或是对于两个类别的监督分类；或是更大频域的音频样本，来在扬声器消崎模型（speaker disambiguation model）中使用该信息。 Mini-Batch（小批量） 对比随机学习（Stochastic Learning） 训练一个模型的主要目的是学习合适的参数，即产生输入到输出的最优映射。这些参数利用每个训练样本进行调参，不管你决定使用 batch, mini-batch 还是随机学习。当采用随机学习方法时，学习每个训练样本后权重的梯度都会进行调参，向梯度加入噪音（随机学习中“随机”的由来）。这样做的结果十分理想，比如说，训练中加入的噪音使得模型更不容易过拟合。 但是，随机学习方法也许效率不高。如今的计算设备有非常可观的运算能力，随机学习很可能会浪费其中的一大部分。如果我们能计算矩阵相乘，那么为什么要限制自己，重复单个矢量组之间的乘法呢？因此，为了更高的吞吐率和更快的学习，我推荐使用 mini-batch 而不是随机学习。 但是，选择适当的 batch 规模同样重要。所以我们能保留一些噪音（相比大规模 batch），与此同时更高效地利用计算性能。一般来说，包含 16 个到 128 个样例的 batch（2 的幂）是不错的选择。通常，一旦你发现了更重要的超参数（通过随机搜索或是人工搜索），batch 规模就会确性下来。但是，有些场景中模型得到训练数据流（比如网络学习），那么采用随机学习就是不错的选择。 打乱训练样本 这来自于信息理论（Information Theory）——“学习到一件不太可能发生的事却发生了，比学习一件很可能发生的事已经发生，包含更多的信息。”同样的，把训练样例的顺序随机化（在不同周期，或者 mini-batch），会导致更快的收敛。如果模型看到的很多样例不在同一种顺序下，运算速度会有小幅提升。 使用 Dropout 正则化 如果有数百万的参数需要学习，正则化就是避免 DNN 过拟合的必须手段。你也可以继续使用 L1/L2 正则化，但 Dropout 是检查 DNN 过拟合的更好方式（雷锋网按：Dropout 是指随机让网络某些隐层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重会保留下来）。执行 Dropout 很容易，并且通常能带来更快地学习。0.5 的默认值是一个不错的选择，当然，这取决于具体任务。如果模型不太复杂，0.2 的 Dropout 值或许就够了。 在测试阶段，Dropout 应该被关闭，权重要调整到相应大小。只要对一个模型进行 Dropout 正则化，多一点训练时间，误差一定会降低。 周期 / 训练迭代次数 “对深度学习模型进行多个周期的训练，会得到更好的模型”——我们经常听到这句话。但多少周期才是“多”呢？其实，这里有一个简单的策略：继续按照一个固定的样例数或者周期训练模型，比如两万个样例或者一个周期。在每批样例之后，比较测试误差（test error）和训练误差（train error），如果它们的差距在缩小，那么继续训练。另外，记得在每批训练之后，保存模型的参数，所以训练好之后你可以从多个模型中做选择。 可视化 训练深度学习模型有上千种出差错的方式。我猜大家都遇到过这样的场景：模型已经训练了几个小时或者好几天，然而在训练完成之后，才意识到某个地方出问题了。为了不让你自己神经错乱，一定要对训练过程作可视化处理。比较显而易见的措施是保存或打印损失值、训练误差、测试误差等项目的日志。 在此之外，一个很好的措施是采用可视化库（visualization library ），在几个训练样例之后、或者周期之间，生成权重柱状图。这或许能帮助我们追踪深度学习模型中的一些常见问题，比如梯度消失与梯度爆发（Exploding Gradient）。 使用支持 GPU 和自动微分法 (Automatic Differentiation）的库 谢天谢地，对于快速创建原型模型，我们已经有了相当不错的库，比如 Theano, Tensorflow, Keras 等等。几乎所有这些深度学习库支持 GPU 计算和自动微分法。所以，你不需要深入研究核心 GPU 编程技术（除非你想——这绝对很有意思）。你也不需要写自己的微分代码——在非常复杂的模型上这相当费劲（但若需要，你应该有能力去做）。 Tensorflow还提供了分布式计算的支持——如果你是土豪的话。 最后雷锋网提醒，这并不是训练 DNN 的完整注意事项表。为了容纳最常见的实践方法，作者去除了一些概念，比如 Normalization of inputs, Batch/Layer Normalization, Gradient Check 等。 via github","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Neural Network","slug":"Neural-Network","permalink":"http://ipcreator.me/tags/Neural-Network/"}]},{"title":"脑芯编：窥脑究竟，织网造芯","date":"2017-02-13T23:14:06.000Z","path":"2017/02/14/Program/Concepts/brain-and-chips/","text":"作者：雷锋网：本文作者痴笑，矽说（微信号：silicon_talks）主笔。 你信不信有一天，硅工造的芯片会写诗？ 如果信，那说好的“诗三百，一言以蔽之，思无邪”，还真的是“无邪”么？如果不信，请读下面这一首：脑芯编：窥脑究竟，织网造芯（一） 如果要给这诗一个赏析，大概可以是一个忧伤的故事。 天边云的变换复杂，而我却是半梦半醒，我在想一个人，想第一次和他相见，想他的风流倜傥，想他的英雄飒爽。如果你是个文科生，或许你会嘲笑这首连平仄都不满足的劣质诗歌，韵脚也押的有些蹩脚，故事更是为赋新词强说愁。 如果你是理科男，或许对这种思春的小情怀不以为然。 不过，那是因为你们并没有看懂这首诗。 因为这诗暗藏了一个密码，藏着人工智能遇到摩尔定律后蹭出的火花。 另外，这诗不是人工智能的产物，只是矽说在这个人工智能横行的年代里特有的小情怀。 但可能在不远的将来，人工智能将会开车，会翻译，会调情，也会写下更美的篇章。想解开这个人工智能与集成电路的秘密？关注雷锋网(公众号：雷锋网)后期更新，我们一句一句地读下去。 〈一〉昨夜神风送层云在我读书的时候，人工智能（Artifical Intelligence, AI）从来就是CS (Computer Science)的天下，哪有电路撺掇的份。那时候的码农们或许会挂着机器学习，数据挖掘，支持向量机，压缩感知……但从来没有一次，电路的突破是由人工智能推动的。可是在今天，如果你打开半导体行业的利好消息，有多少不是和人工智能，深度学习相关的？ 过去几个月，光在半导体巨头们发生的人工智能的故事就足以吊足大家的胃口。何况，这还是只是很多硅工心目中的人工智能元年。 是什么导致了半导体行业”AI一出惊天下“的巨大改变？矽说推出“脑芯编”系列，为你揭秘类脑芯片的过去，现在与未来。 从人工智能到神经网络神经网络 在人工智能改变半导体行业之前，在AI领域发生过一场“华山论剑”，耗时数载，最终以“深度学习神经网络（Deep Learning Neural Network）”一统江湖落下帷幕。该过程腥风血雨，而主角“神经网络”的遭遇更堪比张无忌、杨过，历经少年时的悲惨遭遇，被无数号称时代“大侠”嗤之以鼻，但终究是主角光环加持，加之得外家指点，十年一剑终成大器，号令天下，谁敢不从。 本篇对这里其中的故事，按下不表，有好事者，可以去各处搜搜，剧情精彩不容错过。但是这里还是要感谢，在神经网络经历最寒冬的时候，一众大牛如 Yann LeCun (读作杨雷昆，不是严立春！！)，Geoffrey Hinton等的默默坚守，才有神经网络的今天。不过他们也早已是Facebook / Google的首席科学家，如今功成名就，也是吾等小辈无法企及的高度。 Yann LeCun, Geoffrey Hinton 神经网络在人工智能领域，属于机器学习一路的分支。所谓机器学习，就是让电脑经过学习后代替人脑做出判断，理解，甚至决定（还记得赢了李世石的AlphaGo么？）。而所谓深度学习和浅学习的区别在于设计者是否告诉电脑的学习策略。最常见的例子是大家电子邮件系统里的垃圾邮件分类，一般一份邮件是否是垃圾邮件，在于它是否满足一些标准，比如是不是群发的，有没有叫你买东西的广告，是不是图片占有比例很高，然后发信人有没有被举报过等等……这些标准都是一个个特征，如果一种机器学习方法规定了学习的特征与策略，那就是浅学习，如果没有规定，需要算法本身去挖掘策略，那就是深度学习。 所以，深度学习的一大隐忧就是——人类并不知道算法本身究竟在想什么？所以如果哪天他在他负责的算法下隐藏了一个暗算/统治人类的bug，那我们就被彻底奴役了。 不过，所谓“庄生晓梦迷蝴蝶”，人类自己究竟是不是被另外一个物种开发出来的一种新智慧呢？然后，那个物种是不是已经被我们灭绝了呢？我们并没有答案。 码农老师教的生物课 为了弄清这横扫千军的神经网络，首先让我们来上一堂不污的生物课。既然叫神经网络，那起源就是生物脑科学。很久以前，人们发现一个单神经细胞（也叫神经元）包括输入（树突dendrites），激活判断（细胞核nucleus），输出（轴突axon）和与下一个神经元的连接关系（突触synapse）。如果用数学抽象出来过程，就是把一堆输入经过线性组合以后经过一个阈值判断，然后输出给下一级。这样一个简单的神经元就形成。把足够多个神经元连起来就能实现神经网络了。 上面两个图就是真实的神经元和它的数学模型。不过我还是要吐槽下： 从上述神经元的提出，到许多仿生的算法结构的研究，如多层感知器(Multilayer Perceptron) ，脉冲神经元(Spiking Neural)之类的，经过了一个甲子的时间，特别但都没没什么巨大的成功，原因有两个： （1）当时的集成电路计算规模与资源远没有达到面向实际应用的需求，仔细去研究神经元的数学模型，会发现每个神经元有若干个权重和成累加计算 。他对应汇编可以大致是如下流程： 累加器清零 (mov)– 循环开始 (branch) 从存储器中加载权重 (load) 从存储器/外设中加载输入 (load) 权重 乘以 输入 (multiply) 累加 (add)– 判断是否重新循环 (goto) 激活函数 (??)输出 存储 (store)对于一个N输入的神经元要走N个循环，这对于上个世纪的单核单线程的CPU，实在是操作难度太复杂。这也就是为什么当流水线与并行处理 不断壮大的近十年，神经网络的发展得到了迅猛发展。 （2）连得不对。这短短四个字，虽说的轻巧，但要找到连连看的窍门，着实花费了多少人的青春？关于怎么连，各位看官先别着急，且听脑芯编下回分解。 作为脑芯编的开篇，今天就到这里，所谓“神风送层云”指的就是集成电路的下一个增长点或许就在在人工智能领域取得巨大成功的神经网络硬件实现上。 〈二〉几重卷积几重生蜘蛛结网，是为了捕食昆虫；蜘蛛侠结网，是为了拯救世界；码农Data Scientist (~ds~) 结网，是为了——换一个角度看世界，英语叫做： Representation。如果你只想知道一个关于神经网络的常识，我认为上面这个单词是最不应该错过的。就像每个学模拟电子学的人，其实归根结底就是学了两个字——放大。 话接上回，我们说到，通过一系列乘累加和非线性激活函数，我们就可以实现一个神经元。而关键的问题就是如何把神经元们连起来。解决这个问题之前，我们先要明白神经网络的作用——通过一系列线性和非线性的变化重新将输入信息映射成为表达事物的本质的简化特征。 如果你觉得上面一句的每个字都认识，却不知道他在说什么，那么我们来看一个经典的例子——人类的视觉皮层（Visual Cortex）。 视觉皮层, 一场生物与AI的伟大握手 码农老师的生物课又来了…… 你有没有想过当你看到生命中一个重要的人的时候，比如说基友（码农怎么会有妹纸？），你是看到是他/她的鼻子，眼睛，脸上的痘痘，昨晚熬夜的黑眼圈……但是这些东西最后都只留下了一个映像——我面基了。可是你有没有想过从你看到图像，到你得到的结论，无数的信息都已经没有过滤，你的脑子完成了一次将4K3D图像压缩成两个字的过程，到底发生了什么事？ 这个过程就是从信息经过视觉皮层（神经网络？？）的过程。从前到后，他经过了几站： （1）始发站——视网膜 ，比较像是一个电子系统的传感器，用来接收信号； （2）快速交流道——LGN，他是将左右眼看到的信号重新编码后传递给视觉皮层，像是一个电子系统中的主控处理器与总线（请原谅我不说LGN的中文，因为说了你也记 不住） ； （3）第一站——主视觉区V1，第一层神经网络，司“边界检测（Edge Detection）”一职，这可能是神经元数量最丰富的一个区域； （4）第二站——次视觉区V2，第二层神经网络，司“基础特征提取”一职，归纳视觉信号的形状、大小、颜色、频率…… （5）第三站—— V3，司“位置“，也是个过渡区，一条线上你有些站你不知道为什么会停~ （6）第四站——V4/V5（MT）分支，深度神经网络，各司“色彩/运动”； （6）V4分支终点站1——换乘inferotemporal Cortex，近深度智能TE区，司 ”目标识别“ ~终于终于我认出基友来了，撒花 （7）V5分支终点站2——换乘Parietal Cortex, 进深度智能MST区，司“空间运动分析”。 视觉皮层可能是目前为止人类认识的最透彻的大脑部分，不过，好像建立在无数的活体实验上。。。即使如此，还是有很多未知的空间亟待生物学家探索。 不知道读到这里，对人工智能略有了解的你有没有觉得这堂生物课在哪里见过？ 先做边界检测，在再做特征提取，在进行分类识别，这不就是大名鼎鼎的 卷积，让加速成为一种可能 其实在神经网络领域里，目前为止唯一能算的上前所未有成功的就是CNN （Convolution Neural Network，卷积神经网络）。最早的CNN可以追溯到98年Yann LeCun的一篇如何识别手写数字的paper，这里出现了第一个CNN的雏形LeNet： 从结构上来，CNN继承了视觉皮层中对信号处理“层”的概念，虽然不是那么的100%的吻合，但是CNN的初级层往往用来做“边界检测”这样的简单的特征提取，而在深度层重新组合初级层的信息成为抽象的再表达（Representation）,最后交给事件的发生的相关概率归纳出事物的本质。 另外，一个比较不太准确的趋势是神经元的数量随层的深度逐渐减少，但是单个神经元的粗壮程度（输入数量）随层的深度逐渐增加。视觉皮层也具有相似的规律，V1的数量多，但是结构比较简单，但到了V4/V5，链接变得很复杂，但占的区域却比V1小的多。 然而，这些都不是做电路的人重点。 对于硅工们而言，CNN获得巨大成功的原因在于：它极大地节省了神经网络的硬件开销，使神经元为单位作加速器成为了可能。 （1） CNN定义了一种更高能效的元操作——卷积核 关于卷积是什么，大家可以去参考一篇《一文读懂卷积神经网络》（广泛地转载于各大公众号间），下图是我目前看到的最形象的卷积描述。 该图片源自网络，感谢原gif作者 其本质就是对于一个区块，判断和自己系数组成的“基”区块的相似程度，得到的分数越高就越相似。这样，当一种“基区块”被赋予一种特征是，即使用于整张图片的特征提取，他的系数也是固定的，因此大量的系数加载操作可以被省略。同时，一个固定大小的“卷积核”成为了比“乘累加”更高阶、更高效的原子操作，在现代计算机体系结构中，实现越复杂，但操作越固定的加速器，其效率和速度的提升也就越大。 （2） Pooling —— 是垃圾就要扔掉 CNN网络的另一个巨大贡献就是在卷积层和层之间，设置了一个”垃圾箱“，把上一层产生的无效信息都扔掉，避免了超大规模的数据传输和存储。大家把这叫做Pooling，我又要来吐槽那个中国人给他取了个”池化“的名字，虽然我也找不到更好的名字，但根本无法帮助理解。Pooling的策略很多，最常见的是max pooling就是留个最大的，然后又其他都扔掉。 （3） “乱撸”？ (ReLU) LeNet后期发展到AlexNet后，激活函数也从sigmoid变成了ReLu，他们的图形曲线大概如下所示。用脚趾头也知道，Relu操作的实现就是把符号位为负置0就好了。至于sigmoid么，传承自经典机器学习回归理论，是e指数的除法操作，编译后简直就是一场噩梦，我们先把他当作一个古老的神话就好了。 以上种种硬件实现的简化，加上CNN的巨大胜利，都当让硅工们看到了直接从电路角度优化的角度切入人工智能芯片的可能。但是，也发现了一个问题，传统的硬件加速的算法往往是做死的，比如椭圆加密，浮点乘除等等。但是CNN的元操作——卷积核——虽然模式固定，但是其每一层的卷积核数量和层数却是纷繁复杂，固定的硬件并不能实现网络的可塑性（structual plasticity）？ 那该怎么办？下一次，如何利用具有高度可编程性的CPU来配置不同结构的神经网络——计算机的”形与令“。就到这里，且听下回分解。 〈三〉梦里不问形与令世界上有两种管家： 一种是Batman的Alfred能服务能做饭能伪装能打架狠起来超人也不是干不过另一种是天朝的大内总管掌印秉笔，啥事不会老大又吩咐了就去传个话你脑子里的CPU是哪一种？ 有了神经元，知道了怎么把神经元连成网络，这个系列终于进入了主题——怎么实现神经网络。如果在这个问题上加一个条件，那就是“怎样用芯片实现神经网络的计算”？ 在回答这个问题以前，让我们先去拜访两位长者——Alan Turing和John Von Neumann，目前大家公认的计算机之父。话说前者才是真的“苟利国家生死以，岂因祸福避趋之”，详见卷福主演的奥斯卡获奖电影《模仿游戏》。 Turing-Von-Neumann架构 为了表达对大师的尊敬，我起了个很干脆的标题。大师之所以是大师，是因为他们定义了在80年前定义了通用计算机的数学模型和体系结构。在这过去的80年里，任何试图推翻这些结构的“投机”分子几乎都没什么好下场。但是，总有人希望推翻这个架构。先简单的描述下两位长者干了什么。 Alan Turing在1936年提出了一种具有普适性的逻辑计算模型，证明通过有限状态机完成输入数据的操作，可以实现任意复杂的逻辑运算。图灵机本身描述的场景在现在看来已经没什么意义，但是他第一次完整的定义普适计算机体系机构——一卷很长很长的带子（infinite lengthtape）通过一个有磁头(head)的有限状态表(finite state table)进行读取/处理/改写的机器。 9年后，Von Neumann把带子改叫做“Memory”，状态表叫做“CPU”，磁头改叫做“Connection (Bus) ”，换了一副图，就有了史称“冯诺依曼架构”的现代计算机体系结构。 教科书上会说这个结构有啥特点，这是让你背的。其实很简单，图灵-冯诺依曼架构最大的特点是把计算任务分为了2个部分——数据存储(memory)和数据处理(processor)。处理器几乎不能存数据，存储器几乎不能算数据。两部分用一种连接方式(bus)按一定规则通信。泾渭分明的特点让冯诺依曼架构处理事情起来特别有条理，就像“男主外女主内”的家庭角色分配一样，在硬件资源极度受限的情况下，成为了自动化发展的中坚力量。 冯诺依曼架构有一个升级版，叫做哈佛(Harvard)架构，把存储空间分为了指令(instruction)存储和数据存储，对应不一样的操作。目前的主流嵌入式微处理器基本采用这个架构，但Anyway这并不重要。 冯诺依曼架构在过去的60年称霸人间，如果这项专利申请成功的话，这一定是史上最赚钱的专利。可是，冯诺依曼架构在经历了各种法院撕逼后，被判定为一项没有收益人的专利……（Youyou Tu和青蒿素在这面前简直不值一提） 成也萧何 - x86的不可一世 虽然冯老爷子在自己的架构下发明了人类第一台计算机，ENIAC和EDVAC，但诺依曼的真正崛起还是要归功于x86。如果你不知道80x86是什么，那只能说明我们已经有代沟了，嗯，很深深的代沟。 Intel自1978年推出8086后，x86体系架构就一直是电脑（上到服务器，下到平板电脑）核心处理芯片的不二选择。 Intel x86 i7 版图 顺便做个普及，在冯诺依曼架构下，每个处理器会干的事情是有限制的，通常这个限制叫做指令集。它规定CPU的基本操作，没有指令集(instruction set)定义的复杂操作可以通过基本操作的组合来完成，比如指令集里没有乘法，那我们可以通过一定数量的加法来完成。 在冯老爷子的机构里，谁的指令集越大，可以访问的存储空间越大，谁就越牛逼。x86的指令集从8086到i7不断扩张与膨胀，最终成为了一个会算双精单精、矢量图像，多核多线程多Cache的巨无霸。简单的说，到2013年的时候，史上最强core已经无所不能了。可是历史不断在重演一幕就是，当绝顶高手号称要独孤求败的时候，不知道哪里窜出来的毛小伙子可能一个起手式就把你撂倒了。圣经里大卫王这么干掉了Goliath，《倚天屠龙记》里，张无忌这么称霸了光明顶。 那谁是x86的张无忌呢？ 移动设备，RISC的春天 独孤求败的x86其实有个致命的缺陷——能效，通俗地说就是“做一次”要花费的能量。可是每块肌肉都很发达的muscleman总是要比一般人多吃几碗饭吧。我们现在能买到的i7即使在省电模式也要消费超过47W的功耗。本身47W不算什么，但是苹果乔大叔的出现，让47W一下子很麻烦。 Iphone/Ipad和一系列手持的充电设备对瓦级以上的功耗是非常敏感的！x86的功耗导致它“充电2小时使用5分钟”的悲惨结局。肌肉男瘦身变成筋肉男的必然的命运。 这时，x86，或者说是intel的张无忌出现了—ARM Cortex RISC. 所谓RSIC就是精简指令集（Reduced Instruction Set），他能干的事情很有限，但是他的功耗低。X86在其巅峰时期无数次地战胜过RISC，以至于ARM出现时并有没足够重视他，那时候Intel还在和AMD抢64位x86的主导权呢。 为什么无数次败下阵来的RISC可以最终成功呢？因为这次，他寻找到了一个partner——加速器。在移动端的应用设备里，其实也有很对需要强大计算消耗的进程，这是RISC本身无法胜任的。但是，实际应用上，往往这些进程是有固定的模式和使用场景的。比如手机在通话时的语音编解码，拍照时的图像处理（俗称“美颜”）和无线通信是的编解码。对于这样一个经常重复，且模式固定的高通量计算，可以在总线上加入一个专用模块（ASIC）加速，在处理专用任务是ASIC的能效又比通用处理器高很多。下图就是ARM有名的产品之一A9，除了CPU外，它的浮点与超标量计算（NEON）都被移到了CPU外（一般来说，这不能算作加速器） 这就是开头的那个故事，你每天充的电不够“超人”吃的，与只能换个块头小，但是能够指挥其他人的总管 败也萧何 – 冯诺依曼瓶颈 “泾渭分明，靠总线连”的冯诺依曼架构带来了单核/少核时代计算机的春天，但冯诺依曼架构的致命缺陷——冯诺依曼瓶颈——也悄悄地增长。随着摩尔定律的发展，远距离的搬移大规模数据早已取代了计算本身，成为制约高效计算的重要瓶颈，对于x86结构，有太多指令可以直接穿过总线访问存储空间。 在RISC+加速器的体系结构里，总线作为“总管”和“内务府”、“上书房”、“御膳房”间的桥梁，更是好不吃紧。当瓶颈出现在通信上时，冯诺依曼架构就体现出了它垂垂老矣的一面。 这个问题，在实时处理的人工智能场景下显得格外突出，信号从入到出，都是按照是数据流(Data flow)的传输模式一帧一帧地来。这一特征在类脑的神经网络实现中就更加明显。如果每一个卷积的系数都要去云深不知处的存储海洋里去寻找，那神经元的处理效率会非常低。简单地说： 谁脑子TM的是一半纯记忆一半纯分析的呢？ 脑子么，都是左右开工的。边走边忘，雁过留痕，却也是旧相识，恢复不出来一个一毛一样的。 所以，摆在类脑芯面前的路有三条： （1） 采用冯诺依曼经典架构，把神经元计算写在指令集里，反正是超人，技多不压身； （2） 采用RISC+神经元/神经网络加速器，给“总管”再开个府呗； （3） 放弃冯诺依曼架构，完全分布式硬件，像“数据流“一样的风骚走位。 这三个选项都有不错的代表，我们慢慢来。 梦里不问形与令，你知道计算机形（体系结构）和令（指令集）了么？ 如何对神经网络人工智能硬件进行优化设计？有三种方式，可以在传统体系结构的基础上面向神经网络人工智能硬件进行优化设计。 本文为《脑芯编：窥脑究竟，织网造芯》系列第四篇。 写这篇的时候想到哥哥的《我》，因为这次的主角就是，那个特里独行的我： 我就是我，是长度不一样的开拓天空海阔，要讨最并行的生活我喜欢我，让矢量算出一种结果简单的指令集，一样加速的很妥妥他的名字，叫做SIMDSingle Instruction Multiple Data话接上回《窥脑究竟，结网造芯（三）》我们说到，有三种方式，可以在传统体系结构的基础上面向神经网络人工智能硬件进行优化设计。这次，我们先来提第一种——在简单指令集（RISC）中增加指令的方式来达到性能的优化。我们将着重介绍如何加速卷积核的计算（忘了（一）和（二）？点这里！） 这次的故事，要从并行计算机体系结构讲起。说到并行计算机体系结构，就要掉一个书袋—— 我从上的第一门计算机体系结构课，到并行提算计体系机构，到高级计算机体系结构都在用这一本书。不得不感谢作者让我少买了好多教科书钱。当然，牛x书的作者也很牛x，这里就不八卦了。有人愿意把这本书叫做计算机体系结构的bible，我不评论，但是下面我们所讲的，好多都出自这本书。 言归正传，这个特立独行的故事从这里开先，我们要认识一个老爷爷（还活着好像），他叫Michael Flynn。老人家生于大萧条时代的扭腰城，一不小心提出了一个分类法，叫做Flynn Taxonomy（1966）。然后计算机体系机构就被Flynn taxonomy的五指山给压几十年。 Flynn Taxonomy的五指山把计算机结构分为两个部分：指令与数据。在时间轴上指令与数据可以单步执行或多次运行进行分类，即单指令单数据（SISD），单指令多数据（SIMD），多指令单数据（MISD）和多指令多数据（MIMD）。 并行，从Pipeline到SIMD Flynn taxonomy给并行计算机体系结构指了两条明路——指令级并行和数据级并行。 首先来看下指令与数据的关系。指令是处理器单步可以实现的操作的集合。指令集里的每一条指令，都包含两个部分：（1）什么操作；（2）对什么数据进行操作。专业地，我们把前者叫做opcode，后者叫做operand（也就是数据）。当然，并不是所有的命令都有数据操作。传统定义的指令集里面，对应的operand不超过2。比如，加减乘除都是典型的二元操作。数据读写就是一元的，还有些就是没有任何数据的操作，比如一个条件判断（if）发生了，根据判断结果程序何去何从，只是一个jump操作，他并不需要任何数据输入。 指令级并行的第一种、也是最经典的办法叫做时间上并行，这是所有的体系结构教科书最喜欢教的流水线架构（pipeline）。简而言之，在发明流水线以前，处理器里面只有一个老司机，什么事情都得他来干，但是下一条指令得等老司机干完上一个~但是，流水线就是把一个老死机变成了三个臭皮匠，每个人干三分之一就给下一个，这样下一条指令只需在上一条被干完1/3后就可以进来了。虽然老司机体力好，但赶不上年轻的臭皮匠干的快啊。这样，流水线可以实现时间上的指令集并行，成倍提高实际指令的处理效率。 经典MIPS-5 级流水线 有一就有二，有时间当然就有空间。所以，第二种办法是空间上的并行。空间并行基于一个观察——对数据的操作有很多种——加减乘除移位、整数操作、浮点操作……每一个模块的处理（ALU/EXU）是独立的，所以，就空间上，一个浮点加法在处理的时候，完全可以同时进行一个整数移位操作，像老顽童教小龙女的左右互搏分心二用。所以，在计算机体系的历史上，练成“左右互博”术的处理器包括超标量（Superscalar）/超长指令(Very Long Instruction Word, VLIW)处理器。具体我们先不展开。 相比于流水线／超标量复杂的修炼过程（黄蓉都练不会“左右互博”），数据级并行就是简单纯粹的叠加硬件，打造并行处理的“千手观音”： “千手观音”的学名叫做SIMD，Single Instruction Multiple Data，单指令多数据（流）处理器。其实，说白了就是原来有处理单元（ALU/EXU）现在一个加法器，现在变成了N个了。对应神经网络的计算，原来要M次展开的乘累加，现在只要M/N次，对应的时钟和时间都显著地降低。 简单粗暴的并行，不仅提高了让每个指令的数据吞吐率，还让本身单一的标量处理进化成阵列式的“矢量型”处理，于是就有SIMD又有了“矢量处理”指令的称呼。其实，SIMD并不是到了神经网络再兴起的新玩样儿，早在MP3的年代，SIMD处理器就广泛地使用在各类信号处理芯片中。所以关于SIMD指令也早有了需要行业标准。以下，我们就来看一个SIMD指令集实例—— ARM NEON，厉害了word令 在上一编中，我们简单提到了史上第一个攻城掠地的RISC-ARM。为手机、平板等便携式的最重要处理器，ARM的SIMD指令也是王者风范，从它的名字开始——NEON。 NEON的指令的操作的输入（operand）是一组128位位宽的寄存器，但这个寄存器存着的几个数，就由码农自己去预定义了，可以是4个32位的浮点，或者定点，或者8个16位定点，或者16个8位定点……整个指令集宽泛地定义了输入、输出的位宽，供变成者自由支配，考虑到在神经网络中，前馈网络往往只要16位、8位整数位宽，所以最高效的NEON命令可以一次实现16个乘累加计算（16个Synapse）。 仅仅是SIMD怎能彰显NEON的侠者风范？ NEON还充分应用了指令级并行，采用10级流水线（4级decode+6级运算单元）,可以简单地理解为把卷积计算的吞吐率由提高了10倍。加起来，相比与传统的单指令5级流水，提高至少32倍的效率。再辅以ARM Cortex A7以上的超标量核心处理单元,筑起了第一条通用并行计算的快车道。 当神经网络遇上SIMD，滑起吧！ 流水线和SIMD都是在神经网络还没羽翼丰满的时候就已经称霸江湖的大侠。在神经网络不可一世的今天，这两者还是固步自封么？答案显然是否定的。 当通用SIMD处理器遇上神经网络，他们既碰撞出了火花，也开始相互埋怨。我们先说埋怨——存储空间管理。我们知道，在NN中通常每个卷积核都需要先load系数与输入数据，再算出部分的乘累加结果，再store回存储空间。而指令执行与存储空间的通信就是我们上一编讲到的——冯诺伊曼瓶颈。对于神经网络来说，如此多次的存储读写是制约性能的关键。减少数据的载入与中间结果是面向神经网络的SIMD指令的主要问题。 那火花是什么？ 这就给SIMD带来了一个面向神经网络的新机遇——部分更新与数据滑行（sliding）。我们来看下面这张动图「原作为MIT Eyeriss项目研究组」。 对于一个采用SIMD的卷积核，有一组输入是固定——系数矢量，而另一组输入像一个FIFO，在起始填满后，每次注入一个单元（也排出一个单元）进行乘雷佳，另外上一次累加的结果在保存在执行单元的寄存器内，只有最终的卷积核结果会写回到存储器中。 这样，在神经网络中，无论是数据导入、还是结果输出，起对存储空间的访问都会大大降低。当然，上述示意图仅仅是一维的。当卷积核的维度达到二三维时，情况会复杂很多。这里推荐大家可以去读读MIT的Eyeriss，Kaist的MIMD，或者IMEC的2D-SIMD（ENVISION）。这里就不太多展开了。 好了，这次就到这里。所谓“烛台簇华照单影”就是那一粒粒自由定义的小数据，在同一声SIMD的指令下，排成队，集成行，成为了一个孤独的矢量运算。 脑芯编：分手？摆脱冯诺依曼的深度学习硬件本文作者：矽说 2017-01-21 12:26 导语：“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。很多人把TrueNorth看作深度学习硬件发展史上打得最响的水花。 雷锋网(公众号：雷锋网)按：本文作者痴笑，矽说（微信号：silicon_talks）主笔。本文为《脑芯编：窥脑究竟，织网造芯》系列第五篇。 不知不觉，《脑芯编》已经走过了上半阙。默默挥手告别那些弃剧的看官，也由衷感谢仍然愿意用手指点进来的您。你们是撑住脑芯编不烂尾的重要力量，与其肉麻，不如再念一遍诗的上半阙： 昨夜神风送层云，（神经元与网络） 几重卷积几重生。（卷积神经网络） 梦里不知形与令，（计算体系结构） 烛台簇华照单影。（单指令多数据） 上次我们讲到，现行的计算机体系结构——“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。其计算和存储分离的特点，使得神经元计算的效率低下。合理改变指令集，加入乘累加指令和SIMD（单指令多数据）指令可以缓解该问题，但仍然指标不治本。 此时，革“冯诺依曼”的命变成了很多懵逼骚年（讲的是心态，年纪可是很大哦）的选项。非冯架构的深度学习硬件一时间成为了洛阳纸贵的一时之选。这个过程自然有资本主义的糖衣炮弹加持，美国国防部先进项目研究局（传说中的DARPA，可以理解为神盾局？）便在非冯架构上与世界顶级研究机构——IBM合作，搞了个叫SyNAPSE （System of Neuromophic Adaptive Plastic Scalable Electronics，其实synapse在字面上也“突触”的拼法）的项目。从第一阶段到最终，DARPA赞助了IBM 4千2百万刀，打响了深度学习抗冯的第一枪——TrueNorth（真北）。 当然，很多人也把TrueNorth看作深度学习硬件发展史上打得最响的水花。 Neuromophic，替天行道？ 任何革命都要师出有名，就算水泊梁山也有个“替天行道”的名头。那真北的“名”在哪里呢？很简单，我们要造一个真“大脑”，而不是计算机这样给冯老爷子当傀儡的“伪电脑”。英语叫做Neuromophic，神经形态的硬件。于是就有了这张图： 真北的设计理念，以人脑为起蓝本，依葫芦画瓢，不带点儿差的。 IBM的工程狮从微观到宏观，将人的大脑分成三个层次——神经核团、脑功能区和脑皮层。每个核团由很多个神经元组成，每个功能区由很多核团组成，一个能完整地进行一项任务的皮层由很多个功能区组成。（是不是好久没有上过码农老师的生物课了，有没有点怀念呢？下面还有。） 对应的，真北架构下，也分为这三个层次。先做了一个核团对应的硬件——neurosynaptic core，每个core由256个输出与输入、以及对应的系数存储，并集成了神经信号的路由器（router）使得信号可以在长距离上游走；在此基础上，一块芯片有64乘64个这样的核团，共4096个，组成了一个“功能区”。而很多完整的应用和复杂的任务，还需要芯片与芯片间的互联，实现一个完整的皮层功能。看，这才是真正的神经形态的“电脑”。 TrueNorth还追求了一个大脑的特点，没有全局时钟控制的信号传递。真北只有帧时钟（1KHz，和intel的3.6GHz比慢了几百万倍哦~），并没有控制信号流的时钟，数据和数据之间采用异步的方式进行通讯，寻求高能效和低功耗。 这里留给读者一个问题：为什么是非冯呢？（提示：memory在哪里？）如果各位看官到这里眼皮还没有搭起来，可以考虑去读读TrueNorth的Science原著，保证一夜睡到天明。 SpikeNN，致命缺陷？ 如果有一件事情，可以把昏昏欲睡的人们从周公的世界里拉回来，那一定是——撕逼。 当所有人都觉得TrueNorth要改变人类的时候，惊天一声雷从华山之巅劈下来。出手的，是在神经网络中有“东邪西毒南帝北丐”之称呼的Yann LeCun。（我们在脑芯编（一）中提到过他。） 深度学习的“东邪西毒南帝北丐”F4 Yann大人在Facebook上发了一篇长长的博客来表达自己对True North的不屑。这里节录部分。（冬天了，小编最近比较懒，所以靠复制黏贴凑字数） Now, what wrong with TrueNorth? My main criticism is that TrueNorth implements networks of integrate-and-fire spiking neurons. This type of neural net that has never been shown to yield accuracy anywhere close to state of the art on any task of interest (like, say recognizing objects from the ImageNet dataset).简单的说，问题出在Spiking Neural Networks。Spiking的中文可以叫做脉冲，用现代的生物医学技术发现，spike是人脑中信息传递的真实电学过程。下图就是人脑中一个神经元附近测到spike信号： 医学上，也叫这个信号为细胞膜动作电位（Action Potential）。事事以脑科学为准绳的TrueNorth，自然在这基础理论上一定是向生物学看齐的。可是，问题便在于，在神经网络被提出来的前几十年，就是这spike NN的英魂不散，才导致了其早期“食之无味，弃之可惜”的尴尬地位。 就像那个最有名的比喻：因为鸟的翅膀，让人类渴望飞翔；但放弃对翅膀的模仿，才让飞机真正飞上蓝天。很多事物只能赐予灵感，却无法100%照搬，否则下场就是那些个鸟人。（这话也不是我这种小辈敢说的，同样来自Yann大人） Memristor，吴下阿蒙? 一方面，如果spike完成神经信号的传递与运算真的有问题，那人类为什么聪明？ 另一方面，如果SpikeNN真的100%模仿了我们的脑子，为什么连个ImageNet分类都分不清楚？一定是哪里出了问题。答案是后者。 首先，在我们通常使用的神经网络里面有个假设——系数（Weight）在训练完成后是固定，不改变的。这个假设在CNN/RNN等一系列架构中显得天下太平，因为系数位宽大么。但是到了SpikeNN就是个大麻烦，所有的信号是二进制的，所谓的系数只改变链接关系、延时，不改变幅度，自由度大大衰减。那我们的脑子真的是这样的么？ 唉，生物课又来了。 虽然我们的大脑的神经元看上去是二元的，但是神经元通路还有一个可塑性维度，叫STDP （Spike Timing Dependent Plasticity），就是突触的连接强度（Plasticity，可塑性）收到输入输出脉冲（Spikie）间的时间先后（Time Dependent）关系，其本质核心如下图。 如果输入将将早于输出，代表输入输出间是完美的因果关系，神经元联系会被增强；如果输入的脉冲稍晚于输出，那么他们之间是果因关系，神经元的联系应该要减弱。STDP被认为是我们大脑的主要学习机制，而且在不同动物上都经过了实验验证。 问题来了，这种学习机制和CS里面主流的学习机制——Stochastic Gradient Descent (SGD，中文叫做随机梯度最速下降？) 的后馈算法有着天壤之别。小编觉得这也是目前神经网络算法与神经科学的最大分歧。 没有STDP的真北就这样陷入了SpikeNN的坑。但话说回来，STDP这么高级的操作模型，用传统模数混合集成电路实现是非常浪费面积，且不划算的。好巧不巧，人类突然造出了一个除了电阻电容电感之外的第四类电学器件——Memristor，忆阻器。仿佛是上帝要有光，就有一缕阳光照进SpikeNN的黑暗的胡同里。 对于一个电阻，两端的电压和电流成正比，对于一个电容，两段的电荷和电压正比，对于一个电感，两端的磁通量和电流正比，对于一个忆阻器，就应该是两端的磁通量和电荷成正比。虽然很抽象，但是忆阻器的实际效果就是其电阻（导通强度）受流过的电流调制。这个效果已经非常接近STDP了。 试想，连在忆阻器两端的突触，当设定为上一层的神经元先发生spike，而下一层后发生spike，那一个正向的电路流过忆阻器，减小忆阻器阻值，加强链接。反之，负向电流流过忆阻器，增大阻值，减缓链接。 于是，大家逐渐开始相信，在真北架构上如果能用可随摩尔定律减小的微纳尺寸忆阻器，或许才是Brain Inspired Computer真正焕发春天时候。 于是，兼容先进集成电路的高性能忆阻器就成了问题的关键。但是，作为memristor的发明者和最努力的推广者——HP，最近好像有点无奈。 但是也不要太灰心，最近intel和micron联合推得风声水起的3D Xpoint Memory被认为是某种程度的RRAM/memristor。究竟忆阻器是吴下阿蒙，还是未来的江左梅郎，还在未定之天呢。 这一期可能是脑心编目前为止最为干货满满的一期，牵涉好多paper，如果看官您的目光移驾到这里，小编我也是要这厢有礼的，不容易啊。 ”真北路上初相见“，告诉你采用非冯架构的IBM TrueNorth（真北）的出生、虐缘和不明亮也不灰暗的未来。下一次，我们要来讲讲以GPU为代表的协处理器深度学习架构——“一见泰坦误终身”。 特别鸣谢复旦大学脑芯片研究中心提供技术咨询，欢迎有志青年报考。 雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"}]},{"title":"Google RAISR技术落地应用 可节约75%流量","date":"2017-02-13T06:30:06.000Z","path":"2017/02/13/BusinessAI/google-raisr/","text":"作者：网易AI研究院 谷歌在11月推出了一项新技术 RAISR，全称为“Rapid and Accurate Image Super-Resolution”，意即“快速、精确的超解析度技术”。RAISR利用机器学习将低分辨率图像转化为高分辨率图像。 RAISR首先制作较小版本的图像，使用传统方法将至拉伸，然后将拉伸后的模糊图像同原本的高分辨率图像进行对比。算法习得两者之间的差异，这允许它在保留图像的底层结构之上构建信息。 （谷歌RAISR流程图） 谷歌已经在自家社交平台Google+上应用RAISR技术。RAISR也能够在手机上工作，帮助用户在传输信息时节省数据流量。 使用RAISR之后，Google +能够节省高达75%的网络带宽。通过网络传送低分辨率的图像，图像在接受之后又能恢复高清。 相当于只有1/4的文件体积需要网络传输。 图像的传输对网络带宽具有很高的要求，在网络连接昂贵或连接状态不稳定的情况下尤其如此。在这种情况下通过网络加载图像是让人头痛的事，很多人甚至选择关闭图像，纯文本浏览网页。如今RAISR技术可以大幅度减少图像传输对网络带宽的需求。 该功能正被逐步推广到安卓用户中去。从用户的角度来看，RAISR的整个运行过程几乎难以察觉，无形地帮用户节约流量。现在每周有十亿张图像经过RAISR处理，为用户减少了1/3的网络消耗。谷歌计划在未来更广泛地推广这项技术，并表示将进一步努力减少图像传输所需的时间和带宽要求。 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"}]},{"title":"大数据深度学习下车辆厂牌型号识别","date":"2017-02-13T06:30:01.000Z","path":"2017/02/13/BusinessAI/recognize-license-number-of-car/","text":"作者：36大数据 数控小V 2015年3月，北京文安公司发布了基于大数据下深度学习的机动车厂牌型号识别技术。 车辆身份识别系统是智能交通的重要分支，它需要人工智能、图像处理、计算机视觉、模式识别等相关技术的综合应用。目前国内的车牌识别技术已经日益成熟，随着智能交通技术应用的不断加深，业界迫切希望提取更多元的车辆信息，除车牌号码外，还需要车辆的厂牌、型号以及颜色等信息特征。这些特征在停车场无人管理、交通事故处理、交通肇事逃逸、违章车辆自动记录等领域具有广泛而迫切的应用需求。 ## 技术实现途径 机动车厂牌型号识别技术分为多个环节，一般是通过对摄像机采集的数字图像进行去噪、增强、车标定位、特征提取、识别等分析完成。为了得到较高的识别率，要求每一个处理步骤要有很高的准确率，而实际背景复杂，四季、昼夜、晴雨等不同情况的光照以及车辆运动速度的快慢等直接影响车辆图像的成像环节，造成车辆图像颜色失真、车身及车标区域灰度不均匀、边缘模糊、粘连等问题，增加了处理难度；反光、逆光、夜晚光照不足、树荫、车身颜色显著区域分布位置不同等情况又增加车身颜色识别难度；再加上车辆类别繁多以及车身本身的污损、遮挡、模糊，也为进一步提高识别率带来诸多困难。 北京文安自05年起，在行业里深耕多年，掌握了大量的实际数据与丰富的算法经验，针对诸多问题，公司综合采用了国际先进的人工智能、计算机视觉、图像处理、模式识别、大数据训练、深度学习等等技术来，通过从视频流中检测车辆、车头区域的定位、变形和倾斜校正、去除运动和成像造成的模糊、车辆特征的定位和识别、海量特征的选取和决策等多个环节来实现。 ## 1. 百万级大数据训练，特征提取更丰富 在系统的设计和实现过程中，公司开发应用了当今国际上最先进的计算机视觉技术，并通过超百万的大数据学习样本进行训练，大量实地数据的系统调整和测试，还采集了描述车头、车灯、散热格栅等各个部分的外形轮廓、相对位置、颜色、纹理等多种特征，组成了海量的辅助分类信息，与厂牌型号识别的结果一起最终通过可在线学习的特征决策模块，得到综合可信度评价，从而得到最终的识别结果。 ## 2. 深度学习算法，提高数据精准性 浩瀚如海的大数据，结构复杂，种类繁多，单纯依靠人力定义的过程无法处理这海量数据。于是我们采用基于模仿人类神经网络的人工智能算法，让机器从海量数据当中自我学。深度学习的实质，就是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。我们通过利用大数据来深度学习各类信息、特征，更能够刻画数据的丰富内在信息。从而得出更多元更精准的厂牌型号及其他信息。 ## 3. 并行计算，使算法不断优化 系统还通过利用北京文安强大的并行计算能力，极大的加快了计算速度和数据处理速度，使算法不断优化，目前厂牌识别种类已达632种。常规情况下，识别率在92%以上，识别车身颜色包括黑白灰红等十余种。在样本大数据不断增加的同时，通过模型训练及深度学习，指标将不断提升。 ![](http://www.36dsj.com/wp-content/uploads/2015/03/337.jpg) 机动车厂牌型号的识别为违法车辆以及套牌车辆的有效监测提供了有力的手段，为保障人民人身安全和打击违法犯罪行为提供了有效的工具。机动车厂牌型作为车辆识别的重要属性，在大数据深度学习背景下，未来将不断完善，并将推动为智能交通向更加精准、高效发展，使我们的生活更加智能、高效、便捷。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://ipcreator.me/tags/Deep-Learning/"}]},{"title":"基于char-rnn和tensorflow生成周杰伦歌词","date":"2017-02-13T06:30:00.000Z","path":"2017/02/13/BusinessAI/generate-lyric-from-lyric-of-jay/","text":"作者：leido 最近深度学习在机器视觉CV、自然语言处理NLP领域表现出强大的潜力，各种深度学习/机器学习框架也层出不穷。TensorFlow是google于去年(2015.11)开源的深度学习框架，截止目前(2016-11-28)Github上已经有38000+的star数，称之为最近最受欢迎的深度学习框架一点也不过分。 本着学习TensorFlow和RNN的目的，前些天发现了char-rnn这个有趣的项目，具体就是基于字符预测下一个字符，比日说已知hello的前四个字母hell，那我们就可以据此预测下一个字符很可能是o,因为是字符char级别的，并没有单词或句子层次上的特征提取，相对而言比较简单易学。 因为原作者的代码是基于torch写的，为了熟悉tensorflow，我就仔细地研究了一下具体代码，然后改写成基于tf的代码，github上也有基于TensorFlow的char-rnn-tensorflow，恕我直言，有以下三点比较膈应： 代码写的不够直观简洁另外因为最新tensorflow的部分api有所变化中英文之间有一些差异，看能否成功移植到处理中文上于是打算基于以上两个项目，自己重写! 基本原理 拿中文举例来说，每个字与每个字并不是统计上独立的，比如说如果不爱就不要再伤害长度为10的序列，如果我们知道如，下一个字有可能是果，如果知道前两个字如果，第三个字就是不的可能性大些，依次类推，如果知道前9个字如果不爱就不要再伤，那么最后一个就有可能是害字。用图直观的表示如下。 总的来说，这是一个seq2seq的模型，训练数据用的是周杰伦01年到11年所有歌的歌词，训练数据和代码我都放到Github上，可以从这里下载 全部代码如下： python3 gen_lyrics 0训练差不多10几分钟，然后运行python3 gen_lyrics.py 1生成的歌词如下： End.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"新型耳机将要拉开AI增强人耳听觉序幕？","date":"2017-02-13T06:21:06.000Z","path":"2017/02/13/BusinessAI/ai-on-ear-phone/","text":"作者：网易AI研究院 据国外媒体报道，有家新公司在打造一种经过人工智能（AI）技术增强的耳机产品，其背后的理念是 AI人耳比普通的人耳要好使。 我们往往要在喧闹环境中专注于特定的声音——如孩子的哭喊声，在嘈杂的俱乐部中听朋友说话等等——这并不容易做到。要是人工智能能够让我们的耳朵变得更加智能呢？有家公司打算明年初推出这种智能平台：售价299美元的蓝牙耳机。他们的真正目的是什么呢？揭开AI增强的人耳听觉的序幕。（这可能也预示着手机的末日。） 该款耳机名为Here One。 其背后的新公司Doppler Labs对即将推出的产品的演示令人印象深刻。它的功能清单令人大开眼界，既能够让人一窥人耳听觉被强化的未来，也能够呈现各种有待征服的技术挑战。该产品是那种基于技术的个性化人类增强型设备的一个例子，未来可能将会出现更多这样的设备。 以下是Doppler希望Here One和相配的手机应用在推出之时能够提供的功能。而它明显将会配备的功能则包括：无线流式音频，无线电话，控制Siri、Google Voice等虚拟助手。 用户能够同时听到混合串流音乐和周围的声音 之前尝试捕捉环境声音的一些产品听上去很怪异，声音有点滞后。而Doppler的产品则显然终于解决了这一问题。刚刚戴上Here One耳机时，《连线》杂志撰稿人大卫·皮尔斯（David Pierce）发现，Here One版的真实世界相当通透，相当即时，以至于他一开始都意识不到自己已经戴上耳机开始听。该功能背后的理念在于，在给人们提供收听美妙音乐的方式的同时，确保没有将他们与周围的世界隔绝。 放大或减弱用户需要倾听的说话者的声音 在戴上Here One耳机后，《连线》撰稿人与Doppler高管的对话持续正常进行，直至后者突然将自己在Here One耳机中的声音停掉。专注于你想要倾听的人和屏蔽不想要听的那些人的声音，这我们可以尝试去做到，但我们的器官是做不到这一点的。 减弱噪音音量，或者完全将其消除 Here One的智能过滤功能依赖于机器学习技术。 它需要在用户可能遇到的声音上有广泛的数据，日常生活中有着各种各样的声音。Doppler的弗里茨·拉恩曼（Fritz Lanman）向Quartz表示，“婴儿的哭喊声极其多变，它们属于宽频带噪声，变化莫测，非常特别。” 为了实现那一目标，Doppler一直在收集音频样本——截至目前已经超过100万份，它们收集自五大洲——收集过后它会将那些样本转化成供Here One使用的声音检测算法。该公司目前在做的一件很有意思的事情是，在全球各地从卖出的Here One耳机收集音频数据，并持续以新算法形式将那些数据反馈回用户。（Doppler表示那些数据都有进行匿名化处理。）也就是说，该公司实质上是在众包其系统的声音检测算法，他们卖出的耳机越多，覆盖的受众就越多。 倾听不同方向的声音 通过设置，Here One耳机可以变得只倾听你身前或者身后的东西，完全隔绝其它方向的声音。Doppler在决定如何称呼向后倾听功能，考虑将其称作“窃听”或者“间谍”模式。从根本上说，它就像是转耳“猫”模式。我们再也不用羡慕会180度转耳的猫了。 定制用户周围的声音 一系列的控制功能让用户改变听到的世界，让用户都能够享有自己的音景。这是一种新型的泡沫现实——这可能是好事，也有可能是坏事。不管怎么样，用户都将能够调整那些声音的音量——智能过滤器让你可以锁定它们——用均衡器（EQ）改变它们的音调特点，又或者给它们增加音频效果。 创建个人收听档案 Here One能够注意用户的收听习惯，当用户进入不同的声音环境时，它会根据用户的习惯提供调整建议。这是让用户走出刺耳的环境，进入属于自己的定制化音频环境的又一种方式。 Doppler还让媒体看了一下其它的一些还没有完善的功能特性。 实时翻译 在演示中，Doppler用西班牙语给《连线》的皮尔斯讲了一个笑话，而后者听到的是用英语说出的笑话。这应该是得益于人工智能技术。该功能目前尚不完善——比如，笑话延时了大概五秒钟——但这种功能的价值显而易见。可以说，这是旅行者们期盼已久的功能，它有望促进世界各地文化背景不同的人之间的沟通交流。 自动识别和提高你在乎的人的声音 这种功能在很多时候都很有帮助，比如在嘈杂的环境中听到你疼爱的婴儿在哭。当然，若能够自动识别和屏蔽用户讨厌的人的声音，也是很不错的：用户可以让Here One自动屏蔽一个烦人的朋友的声音。但从AI角度来看，在现实世界中鉴别声音的身份是件非常困难的事情。Siri、Echo、Google Voice和Cortana能够轻松做到这一点：他们只需在安静的环境中听几次你的声音，就能够根据声音辨认出来。而从混乱而不断变化的音景中鉴别出某人的声音则要困难得多，Doppler还没有走到这一步。 关于用户的手机的未来 要是用户可以直接通过蓝牙耳机打电话，用户还有什么理由需要手机上的应用呢？未来我们还需要手机屏幕和应用吗？我们可能还是需要的：对于复杂的信息，视觉体验可让用户更容易理解。《连线》指出，技术专家克里斯·诺赛尔（Chris Noessel）曾这么说到《她》（Her）科幻电影中AI操作系统Samantha与人类的沟通方式，“Samantha经常通过耳机跟西奥多说话。而当她需要向他展示某样东西时，她会让他注意手机或者桌面屏幕。” 不过，Doppler还是想要将手机完全剔除出去。“我们知道，用户从口袋中掏出手机这一步，就是体验的阻力部分。”Doppler用户体验与用户界面主管西恩·弗尔（Sean Furr）指出。 这涉及很多重要的问题，如我们是什么，我们该如何互动，我们该如何体验和穿梭于这个世界。我们所有人都生活在自己的声音世界是好事情吗？这会让人们更难对现实产生共鸣吗？在这种技术真正整合到我们的生活中之前，这些问题都不会有答案。（皓慧） 车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统本文作者：李子湃 2017-02-10 23:22 导语：在汽车传感器检测到将要发生不可避免的碰撞时，粉红噪声（Pink Noise）刺激耳内镫骨肌收缩，保护内耳和鼓膜。 车祸造成听力损伤？奔驰将粉色噪声加入PRE-SAFE 预警系统 从制动辅助系统(BAS)到电子感应制动系统（SBC），主动安全技术已经从避免车辆碰撞发展到避免更加微小的人身伤害。 奔驰在近日公布了应对车祸造成听力损伤的解决方案：通过检测不可避免的车祸并发出安全的粉色噪声（最大80分贝），让声音刺激耳内肌肉收缩，预防车辆碰撞甚至是气囊弹开所发出的巨大噪声造成的听力受损。 粉色噪声是自然界最常见的噪音，简单说来，粉红噪音的频率分量功率主要分布在中低频段。根据IEEE的数据，奔驰采用的粉色噪声强度大约是 80 分贝，相当于一台洗碗机工作的声音，对于人耳来说比较安全。而在车祸发生时产生的高达 145 分贝的声音，有极大几率对听力造成损害，安全气囊弹开的时候，声音更高达 165 分贝。雷锋网(公众号：雷锋网)查阅到的数据显示，曾遭受车祸并得到安全气囊保护的被调查者中，有 17% 的人受到永久性的听力损伤。 这种听觉保护技术加入奔驰称之为 PRE-SAFE的主动安全系统之后，这套系统几乎已经覆盖了目前车祸发生时大部分人员受伤的情况，包括正副驾驶之间的碰撞，甚至是汽车最忌讳的侧面撞击。 此前奔驰公布的一项PRE-SAFE技术显示，车辆在预警到侧面撞击之后，会主动将撞击一侧的乘客“推”向中间位置，整个过程的响应速度在毫秒级别。 雷锋网原创文章，未经授权禁止转载。详情见转载须知。 ]我如何用深度学习改造母亲的助听器？本文作者：小东 2016-12-20 10:12 导语：深度学习重新定义助听设备，过滤杂音效果良好。 雷锋网(公众号：雷锋网)按：目前的人造听力系统存在一个关键问题：无法过滤背景噪音。尽管用户对倾听的需求十分强烈，然而硬件只是单纯地将声音放大——自然也包括噪音。英国认知科学家Colin Cherry于1953年首次将这一问题称为”cocktail party problem”（鸡尾酒会难题）。 作者 DeLiang Wang 是一名俄亥俄州立大学的教授，他主要关注计算机科学及工程领域，此外，他也在学校的认知及大脑科学研究中心工作。本文是他基于自己亲人的切身体会，利用深度学习改造助听器的自述，雷锋网编译，未经许可不得转载。 我如何用深度学习改造母亲的助听器？ 我上大学的时候，母亲的听力逐渐下降。不过一直以来，我很愿意回家将我所学的东西与她分享，她也很乐意倾听。但渐渐地我发现，如果多个人同时说话，那么母亲很难分清到底是哪个人在和她讲话。尽管她使用了助听器，但对她来说区分这些声音仍旧很难。在我们家庭聚餐的时候，我母亲不希望我们同时和他说话，希望每次只有一个人和她说话。 我母亲的痛苦遭遇反应了目前助听设备面临的一个主要问题，即助听器滤音效果不好。尽管信号处理专家、人工智能专家、听力专家已经努力了几十年，但现在的人造听力系统仍不能很好滤掉背景噪音。 据估计，六十年后将会有约25%的人需要佩戴助听设备，如果这些设备去除杂音的效果不好，那么我们可以想象这样一个场景： 当一个人和佩戴助听设备的人谈话时，此时一辆汽车呼啸而过，但这些助听设备只是简单的将杂音与话音放大，却无法很好去除汽车杂音，此时对于用户的听力将会造成多么大的伤害，他们将听不清对方的讲话。是时候该解决这个问题了，我在俄亥俄州立大学的实验室目前尝试使用深度学习模型实现杂音与声音分离，此外我们还尝试了多种用于去除杂音的数字滤波器。 我们相信基于深度学习模型的听力修复可以使听力受损人的听力理解能力达到甚至超过正常人。实际上，我们的早期模型效果一直在提升。由原来听清 10% 提高到 90%。在现实生活中，即使人们没有听清一句话中的每一词，他们也可以理解这句话的意思。所以这实际上已经意味着，人们已经从“一句都听不懂”变成了“能听懂一句话”的状态。 对于有听觉问题的人，没有好的助听设备，人的听力只会越来越糟。世界卫生组织估计约 15%（776百万人）患有听觉问题，随着老年人口的增多，这一数字将会逐渐变大，并且高级听力设备的潜在市场不仅局限于听觉受损用户。开发商可以将这一技术用于智能手机，以提升智能手机的通话质量。一些人的工作环境背景噪音复杂，这个设备可以解决这问题。处于战争环境中的士兵也可以佩戴这个设备使得他们之间的通话更加顺畅。 语音清洗与过滤 助听设备的市场广阔，据印度MarketsandMarkets研究发现，目前助听行业规模大约为60亿美金，市场规模在2020年以前预计以每年6%的速度递增。为了满足新用户需求，我们需要解决‘鸡尾酒会难题’，那么如何解决呢？深度学习给我们提供了一个很好的解决思路。 语音清洗流程如下： 信号转换：机器学习程序首先将语音信号转换为时域信号。 特征表示：在时域范围内用85个特征表示语音信号， 语音分类：将这些用特征表示的语音信号传入深度学习模型中，找出语音信号与杂音信号， 杂音过滤：使用滤波器去除杂音信号，保留语音信号。 数十年来，电子与计算机专家尝试从信号处理的角度实现语音与杂音的分离，但均以失败告终。目前最有效的方法就是语音活动检测器，用于识别不同人之间的说话。在这种方法下，系统检测出不同的语音信号，然后滤去这些声音信号，留下理想的、无杂音信号。不幸的是，这种方法效果很不好，它通常会滤去很多语音或只滤去少量杂音。即便经过了几十年的发展，这项技术的实际效果仍然不太理想。 我觉得我们得使用新的方法解决这个问题，我们首先研究了 Albert Bregman（ McGill University）的关于人类听力系统的理论，他认为人类的听觉系统将不同的声音分成不同的声音流，一个声音流对应一个音源，每一个声音流据有不同的音高、音量、方向。 上图展示了声音场景是如何形成的 总之，许多音流（像曲棍球比赛中朋友们的呐喊）组成 Bregman 所谓的听觉场景。如果不同音波的音频一样，那么音量最大那个将会盖过其它声音，这一现象被称作听觉掩蔽效应。例如，下雨的的时候没人会听到钟表的滴答声。这原理也用在了MP3的文件中，它通过压缩被掩蔽的声音，使得文件大小变为了原来的十分之一，文件虽然缩小了，但用户却没有任何感觉。 回顾了Bregman的工作，我们设想我们是否可以构建一个滤波器，在特定时刻对于特定音频，这个滤波器可以找到主声波。听觉感知专家Psychoacousticians将人类的听觉频率（20Hz到20000Hz）分成24份，那么问题就变成了我们需要一个滤波器，在某一时刻这个滤波器可以告诉我们是否存在一个包含比其它语音或杂音都大的声音，然后江这个大的声音进行分离出来。 我的实验室在2001年就开始了这项工作，并给音流打标签，以表明他们的主音流是语音流还是杂音流。有了这些标记数据，然后我们基于机器学习的方法，训练一个能区分主音流是声音还是杂音的分类器，这些特征包括音量、音调等。 原始过滤器是一个二元过滤器，用于对特定时刻特定频率的声音进行标识，这个过滤器在时域范围对声音信号进行0、1标识，如果主音为声音，标1；主音为杂音，标0。最后生成一个主音为声音与主音为杂音的样本集合，滤波器除去标识为0的声音，保留标识为1的声音。为了保证句子能够被理解，必须保证标识为1的语音占有一定的比例。 2006年，在美国空军实验室我们对声音滤波器进行测试，与此同时，另外一家机构也队我们的产品进行独立的第三方评估，在这些试验中，我们的产品性能优异。不仅有助于提高听觉受损者的听力水平，还有助于提高正常人的听力水平。 我们创造了一款在实验室中表现优良的听力设备，在设计过程中，我们训练的时候是将语音信号与杂音信号分开的。测试的时候将这两者混合在一起，然后测试。由于这些信息均为为标记信息，所以过滤器知道什么情况下语音信号要大于杂音信号，所以我们称之为理想滤波器。但实际情况是滤波器应该能靠自己进行判断，而不是靠我们提前告诉它。 不过，理想滤波器确实能提高听觉受损者与正常者的听力理解水平。这表明我们可以将分类方法用于区分语音与噪音。分类方法实际上是一种机器学习的方法，通过训练、反馈、惩罚等一些列类似于人的学习过程，来实现对声音信号的正确分类。 在接下来的几年中，我们实验室开始尝试使用分类方法来模仿我们滤波器，同时，我们基于机器学习设计新的分类器，提高自动语音识别的质量。后来一组来自University of Texas的研究人员使用一种不同的方法首次实现语音可懂性的实质意义上的进步，这种方法仅使用了单声道特征。 但是对于助听设备来说，这些分类方法的效果与精度还不够，这些方法还不能处理现实世界中复杂环境下的声音信息。因此，我们需要更好的方法。 如何进一步改善系统？ 我们决定进一步改善系统效果，使我们的系统可以应用在现实环境中且不需训练。为了解决这个问题，我们构建了一个以前从未构建过的机器学习系统，经过复杂的训练，这个神经网络系统，可以用于声音与杂音的分离。在24个测试样本中，这套系统提高听力受损人员的听力理解力约50%。效果良好。 神经网络是由一些简单的神经元组成，这些简单那神经元组合在一起就可以处理复杂的问题。当一个新的神经网络模型构建好以后，这个模型需要利用数据不断的调整神经元与神经元之间的权重（类似于人脑学习），以达到实现语音信号分类的目的。 如上图所示：左侧为为输入层，右侧为输出层，通过调节层与层之间的神经元之间的链接权重提高系统性能。 神经网络有不同的形状、大小、深度。隐层多余两层的就可以称为深度神经网络，上一层的输出是下一层的输入，就好比给下一个隐层增加一些先验知识。 例如，我们通过数据训练一个签名识别网络，如果此时有一个新的签名，这个签名与数据集中的签名是一个人写的，却与数据集中的签名不完全一样，但我们的网络仍可以识别出来，因为我们的网络层是可以识别出同一人签名的不同特征的，只要特征相同，就可以认为是同一个人写的，这些特征包括文字的倾斜角度，字母i的点是否点上等。 为了构建我们自己的深度学习网络，我们开始编写基于音频、振幅的特征抽取器，我们定义了数十个特征用以区别声音与杂音。最终我们确定了85个特征。其中最重要的特征是音频与音强。抽完特征以后，我们用这85个特征对神经网络进行训练。我们的训练包含两个阶段： 一、通过无监督方法训练系统参数。二、用杂音数据对模型进行训练，这一步是有监督训练。我们用标记好的正例与负例对我们的系统进行测试与改善。具体流程如下：输入一个新数据，系统首先对数据进行特征提取，特征表示，对数据进行分类（是声音还是杂音），与正确结果进行比较。如果结果有误，对神经网络进行调参，使得我们的输出在下一次的训练中尽可能与正确结果相接近。 为了实现神经元与神经元之间的权重调整（调参），我们首先计算神经网络的输出误差，我们有一个误差函数，这个函数用来计算神经网络的输出结果误差。根据这个结果误差，我们对神经元之间的连接权重进行调整，以降低误差，这个训练过程需要重复上千次。最终实现一个较好的训练模型。 为了使得结果更好，我们在前面深度学习的基础上在构建一个深度学习模型，将第一个的输出做为第二模型的输入，对结果进行细粒度的调优，第一层的关注的是声音单元本身的特征，第二层检验的是声音单元‘邻居’的特征。那么为什么对周围声音进行检测也有用呢？道理很简单，第一层好比是一个正在销售的房屋，我们对它的各个房间进行查看，第二层就好比这个屋子的‘邻居’，我们对它的‘邻居’进行检验。换句话说，第二层为第一层提供了声音信号的上下文信息，有助于提高分类的准确率。例如，一个音节可能包含几个时域，背景噪音可能只在突然出现音节的起始阶段，后面就没有了。在这个例子中，上下文信息就可以使我们更好的从杂音中提取出声音。 在完成训练后，我们的深度学习分类器要比我们原先的分类器好很多，事实上，这是我们首次在算法上取得突破，使得我们的助听设备可以提高听觉受损人员的听力水平。为了测试我们的设备性能，我们对12名听障人员、12名听力正常人员进行测试，测试用例是成对出现的，第一次声音与杂音混在一起，第二次是经过我们神经网络处理过的声音。例如包含“It’s getting cold in here”和“They ate the lemon pie,”的句子有两种杂音，一种是嗡嗡声，另一种背景杂音是很多人在一起说话。这个嗡嗡声很像冰箱压缩机工作的声音，而另一种杂音是是我们生成的，是四男四女的说话声，以此来模仿鸡尾酒会的这一类背景噪音。 在对背景噪音进行处理后，无论是听觉受损人员还是听觉正常人员其听力理解能力均有大幅提升，在未经处理的声音中，听觉受损人员只可以听清29%的单词，但在处理过的声音中，他们可以理解84%的内容。在一些例子中，一开始只能听清10%，经过处理后就可以理解90%的内容了。在有嗡嗡杂音环境下，听觉受损人员的理解力从未经处理时的36%提升到82%。 对于听力正常的人，我们的系统同样有效，它可以使正常人在有杂音的环境下听到的更多，这就意味着将来的某一天，我们的系统可以帮助更多的人。在嗡嗡杂音下，未经处理，正常人只能听懂37%，处理后可以听懂80%，在鸡尾酒会的这一类背景噪音下，其听力理解力由42%提升到78%。 我们实验中最有意思的结果是，如果一个听力受损的人使用我们的助听设备，那么他的听力能否超过正常人？答案是肯定的。在嗡嗡环境下，听力受损的人（使用我们的助听设备）可以比正常人多听懂15%内容，在聚会噪音背景下可以多听懂20%。以这个结果来看，可以说我们的系统是最接近解决‘鸡尾酒会问题’的系统。 局限自然有，展望依然在 尽管如此，我们的算法仍有局限，在测试样例中，我们的背景噪声与我们训练用的背景噪声很相似。但实际情况却不是这样的，所以在实际应用中，系统需要快速学习周围环境中的各种背景噪声，并将其滤掉。例如通风系统的声音、房间内回音等。 我们购买了一个包含10000种杂音的数据集（这个数据集起初是为电影制造商准备的），用其来训练我们模型。今年，我们发现经过训练的程序可以处理以前从未遇到过的杂音了，并且去杂音效果得到了及具现实意义的提高（无论对听觉受损者还是听觉正常者），现在，由于得到了全国失聪及其他沟通障碍研究所（ National Institute on Deafness and Other Communication Disorders ）的支持，我们决定在更多环境下，使用更多的听障人员来测试我们的系统。 最后，我相信我们系统可以在性能更加强大的计算机上进行训练，并且移植到人听障人士身上，或者与智能手机进行配对使用。商家会周期性的对新数据进行训练，并发布新的版本以便让用户升级他们的助听设备，从而使其能够滤去新的杂音。我们已经申请了数个专利并且与多个合作伙伴进行了商业化应用。 使用这个方法，鸡尾酒会难题看起来不在是那么难以解决。我们坚信，只要有更多杂音数据、更加广泛的训练，我们终究可以解决这个难题。事实上，我认为我们现在处理声音的流程与小孩早期区分杂音与声音的过成是很类似的。都是在不断的重复中提升性能的。总之，经验越多，方法就变得越好。 雷锋网小编也设想到，如果一个有着听力障碍的热心读者参加了明年雷锋网举办的GAIR大会，在人头攒动的会场，他可能一直会被会展播放的背景音乐所打扰，无法专心与新结识的大牛们聊天。如果有了硬件相关的技术提升，那么想必会让活动的效果更好，而这也是科技尤其是人工智能所带给我们的福祉：让智能与未来伴随我们的生活，并使之变得更加美好。 via Deep Learning Reinvents the Hearing Aid","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"}]},{"title":"TensorFlow极速入门","date":"2017-02-13T01:20:06.000Z","path":"2017/02/13/Program/TensorFlow/quick-learning-of-tensorflow/","text":"AI研习社 目前，深度学习已经广泛应用于各个领域，很多童鞋想要一探究竟，这里抛砖引玉的介绍下最火的深度学习开源框架tensorflow。 雷锋网按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于深度学习技术的探索，对新事物有着强烈的好奇心。 雷锋网(公众号：雷锋网)按：本文原载于Qunar技术沙龙，原作者已授权雷锋网发布。作者孟晓龙，2016年加入Qunar，目前在去哪儿网机票事业部担任算法工程师。热衷于深度学习技术的探索，对新事物有着强烈的好奇心。一、前言目前，深度学习已经广泛应用于各个领域，比如图像识别，图形定位与检测，语音识别，机器翻译等等，对于这个神奇的领域，很多童鞋想要一探究竟，这里抛砖引玉的简单介绍下最火的深度学习开源框架 tensorflow。本教程不是 cookbook，所以不会将所有的东西都事无巨细的讲到，所有的示例都将使用 python。那么本篇教程会讲到什么？首先是一些基础概念，包括计算图，graph 与 session，基础数据结构，Variable，placeholder 与 feed_dict 以及使用它们时需要注意的点。最后给出了在 tensorflow 中建立一个机器学习模型步骤，并用一个手写数字识别的例子进行演示。1、tensorflow是什么？tensorflow 是 google 开源的机器学习工具，在2015年11月其实现正式开源，开源协议Apache 2.0。下图是 query 词频时序图，从中可以看出 tensorflow 的火爆程度。2、 why tensorflow?Tensorflow 拥有易用的 python 接口，而且可以部署在一台或多台 cpu , gpu 上，兼容多个平台，包括但不限于 安卓/windows/linux 等等平台上，而且拥有 tensorboard这种可视化工具，可以使用 checkpoint 进行实验管理，得益于图计算，它可以进行自动微分计算，拥有庞大的社区，而且很多优秀的项目已经使用 tensorflow 进行开发了。3、 易用的tensorflow工具如果不想去研究 tensorflow 繁杂的API,仅想快速的实现些什么，可以使用其他高层工具。比如 tf.contrib.learn，tf.contrib.slim，Keras 等，它们都提供了高层封装。这里是 tflearn 的样例集（github链接 &nbsp;https://github.com/tflearn/tflearn/tree/master/examples）。4、 tensorflow安装目前 tensorflow 的安装已经十分方便，有兴趣可以参考官方文档 （https://www.tensorflow.org/get_started/os_setup）。二、 tensorflow基础实际上编写tensorflow可以总结为两步.（1）组装一个graph;（2）使用session去执行graph中的operation。因此我们从 graph 与 session 说起。1、 graph与session（1）计算图Tensorflow 是基于计算图的框架，因此理解 graph 与 session 显得尤为重要。不过在讲解 graph 与 session 之前首先介绍下什么是计算图。假设我们有这样一个需要计算的表达式。该表达式包括了两个加法与一个乘法，为了更好讲述引入中间变量c与d。由此该表达式可以表示为：当需要计算e时就需要计算c与d，而计算c就需要计算a与b，计算d需要计算b。这样就形成了依赖关系。这种有向无环图就叫做计算图，因为对于图中的每一个节点其微分都很容易得出，因此应用链式法则求得一个复杂的表达式的导数就成为可能，所以它会应用在类似tensorflow这种需要应用反向传播算法的框架中。（2）概念说明下面是 graph , session , operation , tensor 四个概念的简介。Tensor：类型化的多维数组，图的边；Operation:执行计算的单元，图的节点；Graph：一张有边与点的图，其表示了需要进行计算的任务；Session:称之为会话的上下文，用于执行图。Graph仅仅定义了所有 operation 与 tensor 流向，没有进行任何计算。而session根据 graph 的定义分配资源，计算 operation，得出结果。既然是图就会有点与边，在图计算中 operation 就是点而 tensor 就是边。Operation 可以是加减乘除等数学运算，也可以是各种各样的优化算法。每个 operation 都会有零个或多个输入，零个或多个输出。 tensor 就是其输入与输出，其可以表示一维二维多维向量或者常量。而且除了Variables指向的 tensor 外所有的 tensor 在流入下一个节点后都不再保存。（3）举例下面首先定义一个图（其实没有必要，tensorflow会默认定义一个），并做一些计算。import &nbsp;tensorflow as tfgraph &nbsp;= tf.Graph()with &nbsp;graph.as_default():&nbsp;&nbsp;&nbsp; foo = tf.Variable(3,name=&#39;foo&#39;)&nbsp;&nbsp;&nbsp; bar = tf.Variable(2,name=&#39;bar&#39;)&nbsp;&nbsp;&nbsp; result = foo + bar&nbsp;&nbsp;&nbsp; initialize = &nbsp;tf.global_variables_initializer()这段代码，首先会载入tensorflow，定义一个graph类，并在这张图上定义了foo与bar的两个变量，最后对这个值求和，并初始化所有变量。其中，Variable是定义变量并赋予初值。让我们看下result（下方代码）。后面是输出，可以看到并没有输出实际的结果，由此可见在定义图的时候其实没有进行任何实际的计算。print(result) &nbsp;#Tensor(&quot;add:0&quot;, shape=(), dtype=int32)下面定义一个session，并进行真正的计算。with &nbsp;tf.Session(graph=graph) as sess:&nbsp;&nbsp;&nbsp; sess.run(initialize)&nbsp;&nbsp;&nbsp; res = sess.run(result)&nbsp;&nbsp;&nbsp;print(res)&nbsp; # 5这段代码中，定义了session，并在session中执行了真正的初始化，并且求得result的值并打印出来。可以看到，在session中产生了真正的计算，得出值为5。下图是该graph在tensorboard中的显示。这张图整体是一个graph,其中foo,bar,add这些节点都是operation，而foo和bar与add连接边的就是tensor。当session运行result时，实际就是求得add这个operation流出的tensor值，那么add的所有上游节点都会进行计算，如果图中有非add上游节点（本例中没有）那么该节点将不会进行计算，这也是图计算的优势之一。2、数据结构Tensorflow的数据结构有着rank,shape,data types的概念，下面来分别讲解。（1）rankRank一般是指数据的维度，其与线性代数中的rank不是一个概念。其常用rank举例如下。（2）shapeShape指tensor每个维度数据的个数，可以用python的list/tuple表示。下图表示了rank,shape的关系。（3）data typeData type，是指单个数据的类型。常用DT_FLOAT，也就是32位的浮点数。下图表示了所有的types。3、 Variables（1）介绍当训练模型时，需要使用Variables保存与更新参数。Variables会保存在内存当中，所有tensor一旦拥有Variables的指向就不会在session中丢失。其必须明确的初始化而且可以通过Saver保存到磁盘上。Variables可以通过Variables初始化。weights &nbsp;= tf.Variable(tf.random_normal([784, 200], stddev=0.35),name=&quot;weights&quot;)biases &nbsp;= tf.Variable(tf.zeros([200]), name=&quot;biases&quot;)其中，tf.random_normal是随机生成一个正态分布的tensor，其shape是第一个参数，stddev是其标准差。tf.zeros是生成一个全零的tensor。之后将这个tensor的值赋值给Variable。（2）初始化实际在其初始化过程中做了很多的操作，比如初始化空间，赋初值（等价于tf.assign），并把Variable添加到graph中等操作。注意在计算前需要初始化所有的Variable。一般会在定义graph时定义global_variables_initializer，其会在session运算时初始化所有变量。直接调用global_variables_initializer会初始化所有的Variable，如果仅想初始化部分Variable可以调用tf.variables_initializer。Init_ab &nbsp;= tf.variables_initializer([a,b],name=”init_ab”)Variables可以通过eval显示其值，也可以通过assign进行赋值。Variables支持很多数学运算，具体可以参照官方文档 （https://www.tensorflow.org/api_docs/python/math_ops/）。（3）Variables与constant的区别值得注意的是Variables与constant的区别。Constant一般是常量，可以被赋值给Variables，constant保存在graph中，如果graph重复载入那么constant也会重复载入，其非常浪费资源，如非必要尽量不使用其保存大量数据。而Variables在每个session中都是单独保存的，甚至可以单独存在一个参数服务器上。可以通过代码观察到constant实际是保存在graph中，具体如下。const &nbsp;= tf.constant(1.0,name=&quot;constant&quot;)print(tf.get_default_graph().as_graph_def())这里第二行是打印出图的定义，其输出如下。node {&nbsp; name: &quot;constant&quot;&nbsp; op: &quot;Const&quot;&nbsp; attr {&nbsp;&nbsp;&nbsp; key: &quot;dtype&quot;&nbsp;&nbsp;&nbsp; value {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; type: DT_FLOAT&nbsp;&nbsp;&nbsp; }&nbsp; }&nbsp; attr {&nbsp;&nbsp;&nbsp; key: &quot;value&quot;&nbsp;&nbsp;&nbsp; value {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tensor {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dtype: DT_FLOAT&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tensor_shape {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float_val: 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }&nbsp;&nbsp;&nbsp; }&nbsp; }}versions {&nbsp; producer: 17}（4）命名另外一个值得注意的地方是尽量每一个变量都明确的命名，这样易于管理命令空间，而且在导入模型的时候不会造成不同模型之间的命名冲突，这样就可以在一张graph中容纳很多个模型。4、 placeholders与feed_dict当我们定义一张graph时，有时候并不知道需要计算的值，比如模型的输入数据，其只有在训练与预测时才会有值。这时就需要placeholder与feed_dict的帮助。定义一个placeholder，可以使用tf.placeholder(dtype,shape=None,name=None)函数。foo = &nbsp;tf.placeholder(tf.int32,shape=[1],name=&#39;foo&#39;)bar = tf.constant(2,name=&#39;bar&#39;)result = foo + barwith tf.Session() as sess:&nbsp;&nbsp;&nbsp; print(sess.run(result))在上面的代码中，会抛出错误（InvalidArgumentError），因为计算result需要foo的具体值，而在代码中并没有给出。这时候需要将实际值赋给foo。最后一行修改如下:print(sess.run(result,{foo:[3]}))其中最后的dict就是一个feed_dict，一般会使用python读入一些值后传入，当使用minbatch的情况下，每次输入的值都不同。三、mnist识别实例介绍了一些tensorflow基础后，我们用一个完整的例子将这些串起来。首先，需要下载数据集，mnist数据可以在Yann LeCun&#39;s website（&nbsp;http://yann.lecun.com/exdb/mnist/&nbsp;）下载到，也可以通过如下两行代码得到。from &nbsp;tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, &nbsp;one_hot=True)该数据集中一共有55000个样本，其中50000用于训练，5000用于验证。每个样本分为X与y两部分，其中X如下图所示，是2828的图像，在使用时需要拉伸成784维的向量。整体的X可以表示为。y为X真实的类别，其数据可以看做如下图的形式。因此，问题可以看成一个10分类的问题。而本次演示所使用的模型为逻辑回归，其可以表示为用图形可以表示为下图，具体原理这里不再阐述，更多细节参考&nbsp;该链接&nbsp;（http://tech.meituan.com/intro_to_logistic_regression.html）。那么 let&#39;s coding。当使用tensorflow进行graph构建时，大体可以分为五部分：&nbsp; &nbsp;1、 为 输入X与 输出y 定义placeholder；&nbsp;&nbsp;&nbsp;&nbsp;2、定义权重W；&nbsp;&nbsp;&nbsp;&nbsp;3、定义模型结构；&nbsp;&nbsp;&nbsp;&nbsp;4、定义损失函数；&nbsp;&nbsp;&nbsp;&nbsp;5、定义优化算法。首先导入需要的包，定义X与y的placeholder以及 W,b 的 Variables。其中None表示任意维度，一般是min-batch的 batch size。而 W 定义是 shape 为784,10，rank为2的Variable，b是shape为10，rank为1的Variable。import tensorflow as tfx = tf.placeholder(tf.float32, &nbsp;[None, 784])y_ = tf.placeholder(tf.float32, &nbsp;[None, 10])W = tf.Variable(tf.zeros([784, &nbsp;10]))b = tf.Variable(tf.zeros([10]))之后是定义模型。x与W矩阵乘法后与b求和，经过softmax得到y。y = tf.nn.softmax(tf.matmul(x, &nbsp;W) + b)求逻辑回归的损失函数，这里使用了cross entropy，其公式可以表示为：这里的 cross entropy 取了均值。定义了学习步长为0.5，使用了梯度下降算法（GradientDescentOptimizer）最小化损失函数。不要忘记初始化 Variables。cross_entropy=tf.reduce_mean(-tf.reducesum(ytf.log(y),reduction_indices=[1]))train_step = &nbsp;tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)init = &nbsp;tf.global_variables_initializer()最后，我们的 graph 至此定义完毕，下面就可以进行真正的计算，包括初始化变量，输入数据，并计算损失函数与利用优化算法更新参数。with tf.Session() as sess:&nbsp;&nbsp;&nbsp; sess.run(init)&nbsp;&nbsp;&nbsp; for i in range(1000):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; batch_xs, batch_ys = &nbsp;mnist.train.next_batch(100)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(train_step, feed_dict={x: &nbsp;batchxs, y: batch_ys})其中，迭代了1000次，每次输入了100个样本。mnist.train.next_batch 就是生成下一个 batch 的数据，这里知道它在干什么就可以。那么训练结果如何呢，需要进行评估。这里使用单纯的正确率，正确率是用取最大值索引是否相等的方式，因为正确的 label 最大值为1，而预测的 label 最大值为最大概率。correctprediction = &nbsp;tf.equal(tf.argmax(y,1), tf.argmax(y,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, &nbsp;tf.float32))print(sess.run(accuracy, &nbsp;feeddict={x: mnist.test.images, y: mnist.test.labels}))至此，我们开发了一个简单的手写数字识别模型。总结总结全文，我们首先介绍了 graph 与 session，并解释了基础数据结构，讲解了一些Variable需要注意的地方并介绍了 placeholders 与 feed_dict 。最终以一个手写数字识别的实例将这些点串起来，希望可以给想要入门的你一丢丢的帮助。雷锋网雷锋网版权文章，未经授权禁止转载。详情见转载须知。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"TensorFlow基本用法","date":"2017-02-13T01:10:06.000Z","path":"2017/02/13/Program/TensorFlow/simple-understanding-of-tensorflow/","text":"yjango 目前主流的TensorFlow。用tensorflow这样工具的原因是：它允许我们用计算图（Computational Graphs）的方式建立网络。同时又可以非常方便的对网络进行操作。下面就是对计算图的直观讲解。 注：看完这部分内容的人，可以紧接着实现一个神经网络：代码演示LV1。 比喻说明：结构：而计算图所建立的只是一个网络框架。在编程时，并不会有任何实际值出现在框架中。所有权重和偏移都是框架中的一部分，初始时至少给定初始值才能形成框架。因此需要initialization初始化。 比喻：计算图就是一个管道。编写网络就是搭建一个管道结构。在投入实际使用前，不会有任何液体进入管道。而神经网络中的权重和偏移就是管道中的阀门，可以控制液体的流动强弱和方向。在神经网络的训练中，阀门会根据数据进行自我调节、更新。但是使用之前至少要给所有阀门一个初始的状态才能形成结构。用计算图又允许我们可以从任意一个节点处取出液体。 用法说明：请类比管道构建来理解计算图的用法 构造阶段（construction phase）：组装计算图（管道）计算图（graph）：要组装的结构。由许多操作组成。操作（ops）：接受（流入）零个或多个输入（液体），返回（流出）零个或多个输出。数据类型：主要分为张量（tensor）、变量（variable）和常量（constant）张量：多维array或list（管道中的液体）创建语句： tensor_name=tf.placeholder(type, shape, name)变量：在同一时刻对图中所有其他操作都保持静态的数据（管道中的阀门）创建语句： name_variable = tf.Variable(value, name)初始化语句： #个别变量init_op=variable.initializer() #所有变量init_op=tf.initialize_all_variables() #注意：init_op的类型是操作（ops），加载之前并不执行更新语句： update_op=tf.assign(variable to be updated, new_value)常量：无需初始化的变量创建语句：name_constant=tf.constant(value) 执行阶段（execution phase）：使用计算图（获取液体）会话：执行（launch）构建的计算图。可选择执行设备：单个电脑的CPU、GPU，或电脑分布式甚至手机。创建语句： #常规sess = tf.Session() #交互sess = tf.InteractiveSession() #交互方式可用tensor.eval()获取值，ops.run()执行操作 #关闭sess.close()执行操作：使用创建的会话执行操作执行语句：sess.run(op)送值（feed）：输入操作的输入值（输入液体）语句：sess.run([output], feed_dict={input1:value1, input2:value1}) 取值（fetch）：获取操作的输出值（得到液体） 语句**： #单值获取sess.run(one op) #多值获取sess.run([a list of ops])","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"这一年来，数据科学家都用了哪些算法玩转人工智能？","date":"2017-02-13T00:58:06.000Z","path":"2017/02/13/Program/Concepts/ai-and-algorithms/","text":"作者：刘志勇 在“数据为王”的今天，越来越多的人对数据科学产生了兴趣。数据科学家离不开算法的使用，那么，数据科学家最常用的算法，都是哪些呢？ 最近，著名的资料探勘信息网站KDnuggets策划了十大算法调查，这次调查对数据科学家常用的算法进行排名，并发现最“产业”和最“学术”的算法，还对这些算法在过去5年间（2011~2016）的变化，做了一番详细的介绍。 这次调查结果，是基于844名受访者投票整理出来。 KDnuggets总结出十大算法及其投票份额如下： 图1：数据科学家使用的十大算法和方法。 请参阅文末的所有算法和方法的完整列表。 从调查中得知，受访者平均使用8.1个算法，与2011年的一项类似调查相比大幅提高。 与用于数据分析/数据挖掘的2011年投票算法相比，我们注意到流行的算法仍然是 回归算法、聚类算法、决策树和可视化。相对来说最大的增长是以(pct2016/pct2011-1)测定的以下算法： Boosting，从2011年的23.5％至2016年的32.8％，同比增长40％ 文本挖掘，从2011年的从27.7％至2016年的35.9％，同比增长30％ 可视化，从2011年的从38.3％至2016年的48.7％，同比增长27％ 时间序列分析，从2011年的从29.6％至2016年的37.0％，同比增长25％ 异常/偏差检测，从2011年的从16.4％至2016年的19.5％，同比增长19％ 集合方法，从2011年的从28.3％至2016年的33.6％，同比增长19％ 支持向量机，从2011年的从28.6%至2016年的33.6%，同比增长18% 回归算法，从2011年的从57.9%至2016年的67.1%，同比增长16% 在2016年最受欢迎的新算法是： K-近邻算法（K-nearest neighbors，KNN），46%份额 主成分分析（Principal Commponent Analysis，PCA），43% 随机森林算法（Random Forests，RF），38% 最优化算法（Optimization），24% 神经网络-深度学习（Neural networks-Deep Learning），19% 奇异值矩阵分解（Singular Value Decomposition，SVD）， 16% 跌幅最大的算法分别为： 关联规则（Association rules），从2011年的28.6%至2016年的15.3%，同比下降47% 增量建模（Uplift modeling），从2011年的4.8%至2016年的3.1%，同比下降36% 因子分析（Factor Analysis），从2011年的18.6%至2016年的14.2%，同比下降24% 生存分析（Survival Analysis），从2011年的9.3%至2016年的7.9%，同比下降15% 下表显示了不同算法类型的用途：监督学习、无监督学习、元分析和其他算法类型。我们排除了NA（4.5%）和其他（3%）的算法。 表1：按行业类型的算法使用 我们注意到，几乎所有人都在使用监督学习算法。 政府和产业的数据科学家们比学生或学术界使用了更多的不同类型的算法，产业数据科学家更倾向使用元算法。 接下来，我们分析深度学习的十大算法按行业类型的使用。 表2：深度学习的十大算法按就业类型的使用 Table 2: Top 10 Algorithms + Deep Learning usage by Employment Type 为了使差异更为醒目，我们计算特定行业类型相关的平均算法使用量设计算法为Bias(Alg,Type)=Usage(Alg,Type)/Usage(Alg,All)-1。 图2：按行业的算法使用偏差 我们注意到产业界数据科学家更倾向使用回归算法、可视化、统计算法、随机森林算法和时间序列。政府/非盈利组织更倾向使用可视化、主成分分析和时间序列。学术研究人员更倾向使用主成分分析和深度学习。学生通常使用算法较少，但他们用的更多的是文本挖掘和深度学习。 接下来，我们看看代表整体KDnuggets访客的地区参与情况。 参与投票者的地区分布如下： 北美，40% 欧洲，32% 亚洲8% 拉美，5.0% 非洲/中东，3.4% 澳洲/新西兰，2.2% 与2011年的调查一样，我们将产业/政府合并为同一个组，将学术研究人员/学生合并为第二组，并计算算法对产业/ 政府的“亲切度”： N(Alg,Ind_Gov) / N(Alg,Aca_Stu) ——————————- - 1 N(Ind_Gov) / N(Aca_Stu) 亲切度为0的算法在产业/政府和学术研究人员/学生的使用情况相同。IG亲切度约稿表示该算法越“产业”，越低则表示越“学术”。 其中最“产业”的算法”是： 增量建模（Uplift modeling），2.01 异常检测（Anomaly Detection），1.61 生存分析（Survival Analysis），1.39 因子分析（Factor Analysis），0.83 时间序列（Time series/Sequences），0.69 关联规则（Association Rules），0.5 虽然增量建模又一次成为最“产业”的算法，但出乎意料的是它的使用率如此低：区区3.1%，在这次调查中，是使用率最低的算法。 最“学术”的算法是： 神经网络（Neural networks - regular），-0.35 朴素贝叶斯（Naive Bayes），-0.35 支持向量机（SVM），-0.24 深度学习（Deep Learning），-0.19 最大期望算法（EM），-0.17 下图显示了所有算法以及它们在产业界/学术界的亲切度： 图3：Kdnugets调查：数据科学家使用的流行算法：产业界vs学术界 下表包含了算法的详细信息，在2016年和2011年使用它们的受访者百分比调查，变化（％2016 /％2011 - 1）和行业亲切度如上所述。 表3：KDnuggets2016调查：数据科学家使用的算法 下表包含各个算法的详细信息： N: 根据使用度排名 Algorithm: 算法名称 Type：类型。S - 监督，U - 无监督，M - 元，Z - 其他， 2016 % used：2016年调查中使用该算法的受访者比例 2011 % used：2011年调查中使用该算法的受访者比例 %Change：变动 (%2016 / %2011 - 1) Industry Affinity：产业亲切度（上文已提到） 感谢杜小芳对本文的审校。 AI研究院 | AI学习方式越来越像人 却越来越不靠谱？ 【AI研究院 | 网易智能工作室倾力打造的人工智能行业专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月4日报道，据《连线》杂志报道，神经网络正风靡整个硅谷，无数的互联网服务中嵌入各种各样的人工智能（AI）。令人感到激动的是，最好的AI已经可以识别网络照片中的猫咪。但AI研究人员知道，神经网络依然存在许多缺陷。实际上，它们的缺陷非常多，以至于有些人怀疑这些模式识别系统是否是实现AI的可行、可靠方式。 神经网络可以通过分析大量数据来学习和了解任务，比如帮助Facebook进行面部识别、帮助微软进行翻译、帮助谷歌进行互联网搜索等。它们甚至已经开始帮助聊天机器人学习对话艺术。它们正成为无人驾驶汽车和其他自动化机器的重要组成部分。但是在没有大量经过仔细标注的数据的帮助下，它们就无法理解世界的意义，它们不适合执行任何任务。AI研究人员很想知道，为何神经网络在做出具体决定时受到如此多的限制？在很多情况下，它们实际上就是“黑盒子”。这种不透明会引发严重问题：如果无人驾驶汽车向着某人撞去，结果会如何？ 卡内基梅隆大学计算机学教授、帮助开发顶级扑克人工智能系统Libratus的托马斯·桑德霍尔姆（Tuomas Sandholm）说：“深度学习已经受到许多关注，它当之无愧。但是深度学习并不能给你提供任何保证。”这是真的，但也正是因为神经网络存在这些明显弱点，许多世界上最大的科技公司正在扩展它们的AI思维，从最近的招聘、收购、研究动向中作出判断，许多初创企业也正涌往相同的方向。 你可能认为这是贝叶斯算法(bayesian)的崛起，这类研究人员通常以科学方法研究AI，他们最初从假设开始，然后基于数据更新这个假设，而非像人经网络那样依赖数据去驱动结论。贝叶斯算法的研究人员寻找处理不确定性的方法，将新的证据输入到现有模型中，可以执行神经网络不擅长的工作。 与神经网络相似的是，贝叶斯算法也可以通过数据进行学习，但是这种机器学习可通过不同的方式进行。AI初创企业Gamalon创始人本·魏格达（Ben Vigoda）说：“令我们感兴趣的是自动化科学方法。”他的公司正通过所谓的“概率规划”计划推动这种趋势。 这再次提醒我们，神经网络的快速崛起也将生命注入到许多其他技术中，这些技术可帮助机器变得更加聪明，从强化学习到进化计算等。有许多方法，可以帮助机器进行学习。 神秘技术 2016年12月份，当加里·马库斯（Gary Marcus）将15人的初创企业卖给Uber时，他带着全新的AI到来。至少他是那样说的。他的公司叫做几何智能（Geometric Intelligence），一个小小的操作就能做出巨大改变。这位现年47岁的纽约大学心理学教授说，他与同事们正在开发能够从很少数据中学习任务的系统，这与人类十分相似，同时超越了深度神经网络的力量。 马库斯认为，小数据系统是建造机器必不可少的部分。这些机器可自主进行交谈，汽车也可以自己在公路上行驶。当Uber宣布收购Geometric Intelligence时，马库斯说：“在语言领域和无人驾驶汽车领域，你永远不会有足够数据像深度学习那样产生野蛮之力，这会产生许多问题。毕竟，你不能在繁忙的公路上撞车以便数据，用以预防将来发生车祸。你也不能购买它，它根本不存在。” 马库斯和他的联合创始人、剑桥大学信息工程学教授左斌·加拉玛尼(Zoubin Ghahramani)依然没有探讨他们正在开发的技术的具体细节。就像技术界常见的情况，特别是AI领域，这种保密性通常会催生“神秘感”。但是加拉玛尼是贝叶斯算法的支持者之一。他专门从事名为“高斯过程（Gaussian process）”的特殊统计模型，而这种模型在马库斯开发的技术中发挥了重要作用。 高斯过程 在某种层次上，高斯过程是寻找特定问题最优解决方案的方式。同时，它也是另一种名为贝叶斯优化的数学技术的基础。 到目前为止，高斯过程已经帮助网站确定应该显示哪些广告，以及它们的网页应该如何排版。Uber已经招募擅长高斯过程的专家，改善其拼车服务。在谷歌，高斯过程帮助控制该公司的高空联网气球。 从根本上说，高斯过程是确定不确定性的最佳方式。 爱丁堡大学AI研究员克里斯·威廉姆斯（Chris Williams）说：“知道你不知道的事情是件好事，而犯下自信的错误是你能做到的最糟糕的事情。” 在2015年被Twitter收购的初创企业Whetlab，该技术提供了设计神经网络的更好方式。设计神经网络是个充满错误的实验过程，你没有编写软件那么多的编码，以便于从海量数据中学习。这是个困难、耗时的过程，但高斯过程和贝叶斯优化可帮助自动化这些任务。正如WhetLab创始人、哈佛大学计算机科学家赖安·亚当斯（Ryan Adams）所说，他的公司使用机器学习技术改善机器学习技术。神经网络可能会遇到“信心错误”问题，在识别不确定性方面，这种优化可帮助处理问题。亚当斯已经离开Twitter，加盟了谷歌AI团队Google Brain。 有些研究人员还认为，小数据驱动的高斯过程在推动AI自动化方面可能会发挥关键作用。AI初创企业Prowler首席执行官维沙尔·查特拉斯（Vishal Chatrath）说：“为了开发真正的自动化代理人，它必须能够非常迅速地适应环境。这意味着，它需要以高效的方式学习。高斯过程可轻松胜任。与神经网络不同，它们没有‘黑盒子’问题的负担。如果发生意外，你可以追踪到源头。” 不要恐慌 在Prowler，查特拉斯已经招募了3名技术专家。之所以将总部选在剑桥，因为这里有许多人是高斯过程及其相关技术的专家。这家公司正开发新的AI系统，它可以学习浏览大型多人游戏和其他数字数节。这是个复杂的过程，但他们希望将来AI系统能出现在真实世界中 与此同时，亚马逊也招募了擅长贝叶斯算法技术的AI研究人员，即舍费尔德大学计算机科学家尼尔·劳伦斯（Neil Lawrence）。劳伦斯最近在帖文中指出：“无需感到惊慌，通过使用我们的数学工具可以探索新一轮的深度学习方法。我们可以保证，它们大多数都是无害的。”（小小） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 识别假新闻与NLP有何不同 为何连FB都搞不定？ 【网易智能讯 1月16日消息】假新闻成为新闻头条已达几个月，现在一组研究人员试图运用AI技术来解决假新闻难题。 卡内基梅隆大学副教授迪恩·波美勒（Dean Pomerleau）发起一项挑战，声称如果有人开发出能准确发现假新闻的AI算法，他将奖赏研究者2000美元。 与此同时一些硅谷大公司——比如谷歌和Facebook——也在解决努力解决这个问题。开发AI算法来解决假新闻。 但识别假新闻与其他AI算法的成功（比如图像识别和自然语言处理）不同，假新闻千变万化，本质上的多变性决定其难以抓取模式特征。 制服假新闻要求AI系统多一层判断，而这是今日之AI还不具备的能力。 除了这个问题，竞争或许更能见证AI的进化。未来研究人员能够开发出比今日更优秀的工具。 此外他还更详细地介绍了研究人员在解决假新闻过程中将要面临的挑战和机遇，以及他们的成败如何反映当今AI的发展状态。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://ipcreator.me/tags/Algorithm/"}]},{"title":"避免炒作，如何寻找有价值的人工智能初创企业？","date":"2017-02-13T00:58:06.000Z","path":"2017/02/13/BusinessAI/how-to-find-ai-start-up-firm/","text":"作者：网易AI研究院 据国外媒体报道，毫无疑问现在人工智能概念已经牢牢抓住了公众想象力和媒体的眼球，也带来了大量的业内投资和收购。在新一轮的炒作周期中，投资者该如何辨别相关的人工智能到底是炒作还是真正的现实，这将是一个挑战。 日前，科技网站venturebeat采访了CRV, IA Ventures, Two Sigma等知名投资公司中经验丰富的风险投资人，从而深入探究这些成功的投资者是如何评估一家人工智能初创公司的。如果你也是一名人工智能相关创业公司的创始人，在投资者面前需要回答好以下的关键问题： 人工智能是公司的核心价值所在吗？ 投资公司Qualcomm Ventures的风险投资人Varun Jain坦言，“很多陷入资金困境的公司都会将自己包装成人工智能企业。”Varun Jain列举了从人工智能路由器到人工智能榨汁机等产品和设备。 Varun Jain解释称，在很多情况下，公司所宣传的人工智能仅仅是一个附加功能，而不是公司的核心价值。他指出，“传统的WiFi路由器可以使用人工智能技术来检测网络中的异常数据，但路由器的功能并不会有实质性的改变。” 相比之下，Qualcomm Ventures投资了Clarifai和Cruise Automation等真正的人工智能初创企业，而Cruise Automation已经被通用收购。Cruise Automation通过人工智能技术为自动驾驶汽车供电，而Clarifai则是利用先进的深度学习和计算机视觉技术来识别图像和视频中的特定物体。 技术团队有多可靠？ CRV公司的风险投资人Max Gazor指出，“具备先进人工智能技术的公司往往拥有顶尖的技术人才，他们或者来自业内先进研究实验室，或是来自诸如Google Brain或Facebook人工智能团队等知名行业组织。” CRV对技术的追求直接体现在他们的投资行为中，他们投资的公司创始人普遍具有非凡的技术经验。初创企业Rethink Robotics创始人Rod Brooks是麻省理工学院人工智能实验室的创始主管，也是著名机器人公司iRobot的创始人。而Jibo的Cynthia Breazeal也曾在麻省理工大学媒体实验室成立过机器人小组，是一名世界知名的社交机器人专家。Pullstring公司的创始人Oren Jacob也是如此，他曾是皮克斯的首席技术官，自公司成立初期就与史蒂夫乔布斯共事。 而投资公司DCM Capital的创始人David Cheng则指出，“在整个行业生命周期的这一特定阶段，一个公司拥有一定数量的人工智能专家就能够获得开发技术的必要经验，从而开发真正的创新解决方案。 如果一个团队声称他们的产品使用了领先的人工智能技术却没有相应的团队，那么我们对此将持怀疑态度。” 能够有效解决客户的实际问题吗？ 投资公司GE Ventures投资人Michael Dolbec指出，“就我个人而言，一个公司若是仅仅对人工智能夸夸其谈，而毫不涉及客户问题，那我就没有什么兴趣。我们投资的是宝贵的技术成果，而不是科学实验项目。” 每一位投资者对此都表示认同。 IA Ventures的Brad Gillespie补充称，“如果让我在二者中选择其一时，那么一个公司的业务专业知识将胜过其机器学习专业技能。”IA Ventures曾投资了Vectra Networks，这是一家由经验丰富业内专家领导的网络安全公司，专注于为客户解决重要问题，为安全分析师最大限度提高可用性。而Vectra Networks的竞争对手不断强调他们机器学习技术的复杂性，但客户的反应是“这些家伙很聪明，但他们并不理解我的业务是什么。他们的产品很花哨，但我并不明白它到底是什么。” 有效解决客户的业务痛点需要创始团队能够超越狭隘的技术方法，拥有解决特定业务的能力。投资公司Two Sigma Ventures的Colin Beirne指出，“当然，解决当今大多数困难问题需要不同技术的整合，而在特定业务领域使用人工智能能够在一定程度上降低学习理解的复杂性。” 是否有相关的，自有或可扩展的数据源？ 投资公司Qualcomm Ventures的Jain总习惯于这样问创始人，“你是如何获取数据的？你是依托大公司提供的数据，还是独立获取数据？”当然这两种方法都是可行的，但投资人更倾向于创业公司能够独立获取数据。 传统上。自动驾驶汽车会在郊区等封闭环境中进行测试。而Qualcomm所投资的Cruise Automation则通过在开放城市环境中操作测试车辆，整合人工干预的因素，从而获取更多驾驶数据。同样，Qualcomm所投资的Clarifai通过应用程序能够获取更多的数据，通过此也能够处理更多的业务数据。 投资者除了对数据源的独特性和合理性有要求，此外人工智能数据还必须要与其面对的问题密切相关。投资公司Battery Ventures的Dharmesh Thakker指出，“新一代人工智能技术往往取决于获取数据的复杂程度。诸如图像、音视频等非结构化数据处理要比普通文本困难的多。”在投资决策中，Dharmesh Thakker还会考虑目标公司处理静态数据和快速移动物体数据的能力。诸如自动驾驶汽车获取的实时图像等快速移动物体数据处理算法通常会复杂很多。 最后，创始团队还需要 证实其有根据自有数据不断改进产品性能的能力。Qualcomm的Jain会定期考察团队是否有“快速处理数据并不断优化的能力，从而使系统更加健壮。” 开发独有技术还是依靠开源产品 投资公司Verizon Ventures的投资人Suresh Madhavan指出，相比于开发专有技术，依托开源框架往往就像是一种赠品，“开源的确能够让你分析解决一些表面问题，但无助于从根本上解决有难度的业务问题。” DCM Ventures的Cheng也同意这一点。DCM的投资团队背后拥有一个由行业顾问和技术专家组成的强大网络。“（这些专家）帮我们审查团队技术、数据架构方式，并能够确定创业团队进行数据收集、存储、解析的根本方法。他们也帮助我们擦亮眼睛，找出滥竽充数者。” 产品是否有粘性？ Sumant Mandal是投资公司March Capital的合伙人，也是The Hive的共同创始人，后者是一家专注于人工智能初创企业的孵化器。Mandal坦言，“对于人工智能初创企业来说， 如果效率不能提高5到10倍，那么就很难打入市场，从而为投资者带来价值。”Mandal建议初创企业需要考虑客户的收益。比如要将人工智能用于改进招聘流程，Mandal就建议初创团队要问自己，“如果我能够将相应效率提高5倍，那么能否让客户从雇员身上获得百倍收益？” 此外，Mandal还指出，价值提升必须要以客户可见的方式提供给客户，譬如以仪表盘或是真正有价值的情报等形式展现出来。 Mandal警告称，虽然人工智能在网络安全领域的应用已经很多，但数据和相关人才的缺乏，导致“安全分析师并不需要过多的警报”。 而即便有一个较为理想的产品，仅仅为客户提供单一的解决方案也不是一个可行的商业模式。Woodside Capital的Kartik Gada建议创业公司要寻求收益以及客户的多元化。“你的收入是否稳健？是否常态化？你的客户是否需要相同或更多的解决方案？” 创业团队是否全面？ 最后一点，投资者倾向于寻求那些能够解决人工智能业务的多样化团队。投资公司Monsanto Growth Ventures的Kiersten Stead解释称，“多样化意味着团队包括业内专家、商业领袖以及销售精英，而不仅仅是工程技术人员。” 但是，Stead观察到，很多创业团队，特别是那些仅仅由人工智能研究人员组成的技术团队，并没有特定行业的相关经验，更容易失败。在农业技术开发和遗传育种方面尤为如此。 她强调，“人工智能技术团队在销售上有短板，反之亦然。我们会寻找行业经验丰富的人工智能企业创始人，他们往往有完整成熟的职业生涯，可与各类人组成一个多样化的团队。”人工智能企业往往会忽视销售和营销，但这对于成功非常重要。 投资公司Woodside Capital的Gada也警告称，“很多人工智能初创企业犯下的最大错误就是完全无视营销的重要性。很多客户根本不知道他们需要这些产品。”（晗冰） AI研究院 | 企业做人工智能转型有四大关键要素 【AI研究院 | 网易智能工作室倾力打造的人工智能专业栏目，聚焦行业，深度分析，只为专业】 网易智能讯 2月10日消息，在很多行业我们都已接近人工智能技术发展的临界点，包括自动驾驶汽车、蜂巢无人机、自动售货等。如今一个公司无论规模大小如何，都必须了解人工智能将怎样影响、甚至消灭某个行业，以及学会利用人工智能和机器学习（ML）。 对于企业来说这是一个至关重要的选择——是投身到人工智能领域还是保持现状等着被淘汰，前者可以更有效地帮助企业实现商业目标。人工智能—机器学习将令我们的日常生活更加美好高效，把现有工作提升到更加精确、有效的水平。 像优步、谷歌和Facebook这样的科技创新公司，通过收购和内部组织的转型，在人工智能领域进行了大胆尝试，使它成为一项战略重点。在2017年达沃斯论坛上，世界各国领导人探讨了人工智能对就业的影响，以及哪些行业适合应用这项技术。 事实上，根据互联网数据中心（IDC）的数据显示，到2020年，企业在人工智能方面的投入将从2016年的80亿美元飙升至470亿美元。另外，到2019年，将会有超过1.1亿个安装了嵌入式智能助手的设备走进美国家庭。 Intuit公司的人工智能转型始于4年前，当时业内都在探讨两个问题：金融软件的未来是什么；我们在帮助客户方面扮演怎样的角色。人工智能的趋势在当时是很明显的，包括工作的个性化、自动化、增强和速度等，这些都需要软件来进行辅助。近年来，随着人工智能技术的进步，我们对它的看法也作出了改变。 现在我们将人工智能看作一种为用户提供方便的技术。我们预计人工智能将创造新技术，例如以一种曾经无法想象的高科技方法为消费者处理税务、为小型企业完成账目记录等。但要实现这一目标并非易事。Intuit公司拥有30多种人工智能和机器学习模型，可以在实时体验中接触客户，而且我们还在不断作出新的尝试。我们在实验和成果中不断学习、发展和改进技术。 如果你的公司致力于通过人工智能打造能够满足消费者需求的产品和服务，那么这里有几个关键的问题需要考虑。 1.重视数据 每一家公司的人工智能探索之旅都从数据开始。数据令机器学习和人工智能更强大。如果你一直在考虑如何利用数据，那么现在就可以开始制定和实施计划了。 在Intuit，我们几年前就已经转向了对数据的关注。我们在与业务部门同事进行沟通后制定了技术路线，充分了解了客户需求、行业趋势以及数据能够带来的客户利益。我们的Intuit Analytics Cloud云分析系统打破了一些障碍，让我们能够以更全面地认识产品产生的海量数据。在拥有人工智能或机器学习模型之前，我们就开始专注于数据分析和个性化的基础性工作。可靠、快速、准确的数据是人工智能—机器学习发展的催化剂。 2.展望未来 设想公司的未来是很重要的，同时也要观察人工智能将如何令你更加强大，或者改变你对研发工作的想法。我们在Intuit进行了一场活动，会见了各种各样的组织和个人，包括大学的学者专家、创业公司、风投公司等，探讨了人工智能和机器学习的未来蓝图，以及Intuit公司将如何适应这一转变。规模较小的公司同样可以在相应的资源范围内做出创新。 3.转变心态 在开始阶段向业务部门和产品负责人解释投资人工智能的益处，可能是一件很有挑战性的事情。重要的是每个季度的客户利益需要体现在商业价值上，而不是单纯研究数据。例如，Intuit的税务分析系统就分析了3000万客户的纳税申报表，对分项扣除还是统一扣除作出相应建议，这可以节省40%的税收工作准备时间。这样一个甚至非数据专家都能理解的切实的商业成果。可以说，人工智能—机器学习是一段探索之旅。通过实际产生的影响来预估潜在的成果，这是很重要的。 4.成立团队，选择项目 要在企业中开始发展人工智能，先选择一个容易解决的业务问题，组件一支跨职能员工团队，包括数据科学家、工程师和质量监管人员，同时要注意及时更新团队。在团队中建立起能够理解实验价值的文化。珍惜从人工智能应用中得来的知识。另外，你的团队还应同时拥有专业知识和实战经验。千万不要认为只需要聘请专家。同时，在亟待解决的问题上还需要保持与其他行业科学家的互动，比如其他领域的博士等，他们天生具有好奇心，能够理解科学原理，并且有一套不同的解决方案。真正的人工智能—机器学习可以在应用数据科学方面带来重大成果。 不要低估了它的重要性，同时也要改变心态。 我们才刚刚到达人工智能和机器学习的起步阶段。在公司初创之时紧跟最先进的技术，将有助于你在未来发展中处于优势地位。 （来源/VentureBeat 翻译/机器小易 审校/小ka） 注：本文为网易智能工作室稿件，转载需注明出处，否则追究其法律责任。 人工智能的迅速崛起需要警惕这四大风险 【网易智能讯 1月21日消息】大家可以想象一下，一名营销主管深夜翻看公司的幻灯片，该公司承诺利用人工智能（AI）自动化他的评分过程、优化他的广告开支方案、帮助增加他的营销开支回报率，他想要知道，哪里可能出现问题？ 的确有可能出现问题。尽管公司使用AI会让营销人员的工作变得更简单，但我们必须承认，AI的承诺往往言过其实。AI带来的好处是显而易见的，但也存在巨大风险。即使你找到最好的AI，并将其应用到你的营销技术堆栈中，依然存在影响你成功部署AI的风险。我并不担心这些风险，也不想将它们藏起来，我认为最好是直接面对它们，直至最终解决它们。 AI主要存在四大类危险： AI危险一：害怕失去工作这是最容易理解的AI危险，同时也是最容易解决的。人们经常害怕AI，因为他们担心AI会让人类变得多余，最终被拥有机器大脑的AI取代我们独特的技能。对于某些工作来说，这可能是真的。但我认为，AI带来的实际危险可能比人类预想的更低。AI还不够先进，也无法全面取代营销专家。如果营销人员学会有效地使用AI，它们反而会增强人类能力。也就是说，为了促使人们购买AI支持的技术，我们首先需要平抚人们对AI的恐惧。 AI危险二：错位的激励技术传道者有时候会深入企业内部，并利用让人惊叹的创意，阐述他们的产品如何改变每个人。但是有了AI和许多企业技术，这些热情常常会撞墙，因为这些墙将各个部门隔离开。事实证明，公司中拥有大量数据的人，往往不会与其他利益相关者分享数据。无论是出于隐私担忧、部门政策、个人冲突亦或是简单的流程偏差，比如障碍往往可能导致雄心勃勃的AI项目被搁置。 为此，到目前为止，两类公司在部署AI时取得最大成功，一类是初创企业（公司规模较小，刚刚创建还没有僵化思维），一类是像谷歌和Facebook这样的大科技公司（其全部生命线都基于对数据的利用）。介于这两类极端公司之间的其他企业，几乎包括世界上所有公司，部署AI都会遇到更大阻碍。想要利用AI提高效率的营销人员需要意识到部门和监管问题，这些问题可能影响到他们。此外，数据价值链上的所有玩家都需要保持一致。 AI危险三：不可预测性这可能是AI固有的最大危险。所有AI项目都是不可预测的，因为它们正被用于解决未知问题。与传统软件开发不同，目前还没有标准的工程方法，可以通过分步获得可预知的AI结果。在这种情况下，将AI应用到营销数据中就像纯粹的科幻。我们不知道特定的数据集是否能解决特定的问题。就像无法预测科学实验的所有结果那样，AI也很难预测结果。这是有关软件开发的全新思维方式，但对任何营销领域或没有AI经验的人来说，这将是个巨大挑战。 AI危险四：人才匮乏这是AI带来的最后危险，阻碍你的团队引入足够的人才。不幸的是，当前AI领域存在巨大的技术鸿沟。AI领域的绝大多数人才都没有真正处理大规模行业数据的经验。而真正的专家还很少，最新统计显示，数据科学家的职位空缺高达1.6万个。这意味着，找到你需要的专业人士，并让他们帮助部署和执行AI驱动的营销计划非常困难。 由于存在这些风险，你可以看到截止到目前许多AI实验都以失败告终。举例来说，麦肯锡最近做了一项研究，对石油和天然气钻探作业决策中的数据进行实时分析。麦肯锡研究的1家公司在离岸钻井仪器方面投入巨资，并通过RFID标签和内嵌传感器收集到大量数据。不幸的是，他们收集的数据中只有40%能传回到陆地数据中心，只有1%能真正进入数据库中，不到1%能被用于终端用户的产品中。最终，这些数据没有为人们的决策提供任何帮助。 不幸的是，你可能发现同样大的阻力。在使用AI过程中，你会遇到强烈的文化阻碍。许多人不相信机器做出的决定，直到机器算法有机会证明自己的决定。营销高管们部署AI面对的挑战是，需要确保所有相关利益者支持他们。确保人们受到相关训练，确保他们对可能结果产生现实期待，并获得正确的激励奖励。 只有做到这些，你才能开始意识到AI革命为营销领域带来的惊人好处。（小小）","comments":true,"categories":[{"name":"理财","slug":"理财","permalink":"http://ipcreator.me/categories/理财/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Business","slug":"Business","permalink":"http://ipcreator.me/tags/Business/"}]},{"title":"Gentlest Tensorflow","date":"2017-02-13T00:52:06.000Z","path":"2017/02/13/Program/TensorFlow/gentle-understanding-of-tensorflow/","text":"作者：Neth Six GoalTensorflow (TF) is Google’s attempt to put the power of Deep Learning into the hands of developers around the world. It comes with a beginner &amp; an advanced tutorial, as well as a course on Udacity. However, the materials attempt to introduce both ML and TF concurrently to solve a multi-feature problem — character recognition, which albeit interesting, unnecessarily convolutes understanding. Gentlest Tensorflow attempts to overcome that by showing how to do linear regression for a single feature problem, and expand from there. Cheatsheetcheatsheets/tensorflow_cheatsheet_1.pngLinear regression: single feature, single scalar outcomeLinear regression: multi-feature, single scalar outcomeLogistic regression: multi-feature, multi-class outcomeCode All the code are in /code directory:linear_regression_one_feature.py ML with linear regression for a single feature Example: predict house price from house size (single feature) linear_regression_one_feature_with_tensorboard.py Add visualization for ‘ML for single feature’ with Tensorboard Use tf.scalar_summary, tf.histogram_summary to collect data for variables that we want to visualize Use scope to collapse TF network graph in to expandable/collapsible black boxes to faciliate visualization linear_regression_one_feature_using_mini_batch_with_tensorboard.py Perform ‘stochastic/mini-batch/batch’ Gradient Descent with TF The CUSTOMIZABLE section contains all the configurations that we can tweak, e.g., batch size, etc. linear_regression_multi_feature_using_mini_batch_without_matrix_with_tensorboard.py ML with linear regrssion for 2 features without using ‘matrix’ Create additional tf.Variable, tf.placeholder for each feature IMPORTANT: This is a messy way to do ML with multiple features. This is provided as an explanation of multi-feature concept. linear_regression_multi_feature_using_mini_batch_with_tensorboard.py ML with linear regrssion for 2 features Expanding existing W (tf.Variable) in matrix ‘height’, and existing x (tf.placeholder) in matrix ‘width’ to accomodate each feature","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"深度 | 机器学习敲门砖:任何人都能看懂的TensorFlow介绍","date":"2017-02-13T00:51:06.000Z","path":"2017/02/13/Program/TensorFlow/good-understanding-of-tensorflow/","text":"作者：Soon Hin Khor 原文：The Gentlest Introduction to Tensorflow – Part 1The Gentlest Introduction to Tensorflow – Part 2 机器之心编译 参与：Rick、吴攀、李亚洲 本文是日本东京 TensorFlow 聚会联合组织者 Hin Khor 所写的 TensorFlow 系列介绍文章的前两部分，自称给出了关于 TensorFlow 的 gentlest 的介绍。这两部分谈到单一特征问题的线性回归问题以及训练（training）的含义，机器之心将继续关注本系列文章的后续更新。 第一部分 引言 我们要解决的是一个过于简单且不现实的问题，但其好的一面是便于我们了解机器学习和 TensorFlow 的概念。我们要预测一个基于单一特征（房间面积/平方米）的单标量输出（房价/美元）。这样做消除了处理多维数据的需要，使我们能够在 TensorFlow 中只专注于确定、实现以及训练模型。 机器学习简介 我们从一组收集到的数据点开始（见下图），每个数据点代表两个值之间的关系——输出（房价）与影响因素（房子面积）。 然而我们无法预测没有数据点的特征的值（见上图）。 我们可以使用机器学习来挖掘它们之间的关系（见下图的「最佳拟合预测曲线」），即给定一个不属于数据点的特征值，我们可以准确地预测出输出（特征值和预测线的交点）。 步骤一：选择一个模型 1.模型种类 为了使用机器学习来做预测，我们需要选择一个能够拟合收集到的数据的最佳模型。 我们可以选择一个线性（直线）模型，并通过改变其陡度/梯度和位置对其进行调整，从而匹配数据点。 我们也可以选择一个指数（曲线）模型，并通过改变其曲率（curvature）和位置对其进行调整，从而匹配同一数据点集。 2.成本函数 为了比较哪个模型拟合得更严密，数学上我们将最佳拟合定义为一个需要被最小化的成本函数。 成本函数的一个简单样例是每个数据点所代表的实际输出与预测输出之间偏差的绝对值总和（实际结果到最佳拟合曲线的垂直投影）。用图表表示，成本函数被描述为下表中蓝色线段的长度和。 注意：更准确地说，成本函数往往是实际输出和预测输出之间的方差，因为差值有时是负数；这也称为最小二乘法。 3.线性模型简介 秉持简洁精神，我们将使用线性模型来对数据点进行建模。线性模型的数学表示是： y = W.x + b Where: x: house size, in sqm y: predicted house price, in $ 为了调整模型来更好地拟合数据点，我们可以这样做： 调整 W 来改变线性模型的梯度 调整 b 来改变线性模型的位置 通过使用许多个 W、b 的值，最终我们可以找到一个最佳拟合线性模型，能够将成本函数降到最小。 除了随机尝试不同的值，有没有一个更好的方法来快速找到 W、b 的值？ 4.梯度下降 如果你试图从山上下降到最低点，你的视角就是这个样子。 下降趋势并不明显！其最佳方式是执行梯度下降： 在当前位置以最陡的下降梯度确定方向 在该方向上采取步长 X 重复 &amp; 刷新；这就是训练过程 最小化成本函数是类似的，因为成本函数就像是起伏的山，我们想要找到其中的最低点，我们可以通过梯度下降类似地实现。 现在我们有了线性模型、成本函数和梯度下降的概念，可以开始使用 TensorFlow 了。 步骤二：在TensorFlow 中建立模型 1.TensorFlow 中的线性模型 TensorFlow 的2个基本组件是： 占位符（Placeholder）：表示执行梯度下降时将实际数据值输入到模型中的一个入口点。例如房子面积 (x) 和房价 (y_)。 变量：表示我们试图寻找的能够使成本函数降到最小的「good」值的变量，例如 W 和 b。 然后 TensorFlow 中的线性模型 (y = W.x + b) 就是： 2.TensorFlow 中的成本函数 与将数据点的实际房价 (y_) 输入模型类似，我们创建一个占位符。 成本函数的最小方差就是： 3.数据 由于没有房价(y_) 和房子面积 (x) 的实际数据点，我们就生成它们。 简单起见，我们将房价 (ys) 设置成永远是房子面积 (xs) 的 2 倍。 4.梯度下降 有了线性模型、成本函数和数据，我们就可以开始执行梯度下降从而最小化代价函数，以获得 W、b 的「good」值。 0.00001 是我们每次进行训练时在最陡的梯度方向上所采取的「步」长；它也被称作学习率（learning rate）。 步骤三：训练模型 训练包含以预先确定好的次数执行梯度下降，或者是直到成本函数低于某个预先确定的临界值为止。 1.TensorFlow 的怪异 所有变量都需要在训练开始时进行初始化，否则它们可能会带有之前执行过程中的残余值。 2.TensorFlow 会话 虽然 TensorFlow 是一个 Python 库，Python 是一种解释性的语言，但是默认情况下不把 TensorFlow 运算用作解释性能的原因，因此不执行上面的 init 。相反 TensorFlow 是在一个会话中进行；创建一个会话 (sess) 然后使用 sess.run() 去执行。 类似地我们在一个循环中调用 withinsess.run() 来执行上面的 trainstep。 你需要将由 x, y 所组成的实际数据输入再提供给输入，因为 TensorFlow 将 trainstep 分解为它的从属项： 从属项的底部是占位符 x，y；而且正如我们之前提到的，tf.placeholders 是用来表示所要提供的实际数据点值房价 (y_) 和房子面积 (x) 的位置。 结果 循环中的 print 语句将显示 TensorFlow 如何在每次迭代中学习 W 和 b 的「good」值。 小结 我们已经以最简单的形式学习了机器学习；从一个单一特征预测结果。（为简单起见）我们选择了一个线性模型来拟合我们的数据点，定义一个成本函数来表示最佳拟合，并通过反复调整其梯度变量 W 与位置变量 b 来训练我们的模型，使成本函数降到最小。 第二部分 简单回顾 在上一部分，我们使用 TensorFlow 构建并学习了一个带有单一特征的线性回归模型——给定一个特征值（房屋面积/平方米），我们可以预测输出（房价/美元）。 下面是一些总结： 我们有一些房屋面积和房价的数据（灰色点） 我们使用线性回归对这些数据进行了建模（红色虚线） 我们通过训练该线性回归模型的 W（权重）和 b（偏置）找到了最小化「成本」（竖直蓝色实线的长度总和，这些蓝线代表了预测和实际输出之间的差异）的「最好」模型 给定任意房屋面积，我们可以使用该线性模型预测房价（带箭头的蓝色虚线） 一张图解释线性回归 在机器学习文献中，我们常常看到「训练（training）」这个词。在这一部分，我们将在 TensorFlow 中理解「训练」的含义。 线性回归建模 Linear Model (in TF notation): y = tf.matmul(x,W) + b 线性回归的目标是寻找 W 和 b，这样对于给定的任意特征值 x，我们可以通过将 W、b 和 x 的值代入到模型中得到预测 y。 但是为了找到能准确做出预测的 W 和 b 的值，我们需要使用可用的数据（许多实际特征 x 和实际输出 y_ 的配对，注意下划线）来「训练」该模型。 解释「训练」 为了找到最佳的 W 和 b 值，我们可以从任意的 W 和 b 值开始。我们也需要定义一个成本函数，该函数可以衡量对于一个给定特征值 x 预测输出 y 和实际输出 y_ 之间差异。为了简单起见，我们使用最简单的最小均方误差（MSE：minimum squared error）作为我们的成本函数。 Cost function (in TF notation): tf.reducemean(tf.square(y - y)) 通过最小化成本函数，我们可以得到很好的 W 和 b 值。 我们的训练代码实际上非常简单，并且用 [A, B, C, D] 进行了注释，后面我们还会谈到这些代码。完整代码请访问：https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py # … (省略) 变量/常量声明 … # [A] TensorFlow图 y = tf.matmul(x,W) + b cost = tf.reducemean(tf.square(y-y)) # [B] 用固定「学习率（learn_rate）」训练 learn_rate = 0.1 train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost) for i in range(steps): # [C] 准备数据点 # … (省略) 准备作为x和y的数据点的代码 … # [D] 在每个步骤/epoch将数据送入’trainstep’ feed = { x: xs, y: ys } sess.run(train_step, feed_dict=feed) 我们的线性模型和成本函数[A]可以表示成下面的 TensorFlow 图： 创造一个带有模型和成本函数的 TensorFlow 图，并使用一些值初始化 W 和 b 接下来，我们选择一个数据点 (x, y_) [C]，然后将其送入[D] TensorFlow 图，从而得到预测 y 和相应的成本。 使用单个数据点计算预测 y 和成本 为了得到更好的 W 和 b，我们使用TensorFlow 的 tf.train.GradientDescentOptimizer [B]执行梯度下降以降低成本。用非技术的术语来说：给定当前成本，并基于成本岁其它变量（即 W 和 b）的变化方式，优化器（optimizer）将对 W 和 b 执行一些小调整（递增或递减）以使我们的预测更好地契合那个单个数据点。 基于当前的成本，决定如何调整 W 和 b 以提升预测 y 和降低成本 训练周期中的最后步骤是在调整 W 和 b 对它们进行更新。注意这里的「周期」用机器学习的术语来说是「epoch」。 在下一训练 epoch 的迭代前，通过调整 W 和 b 对它们进行更新 在下一训练 epoch 中，重复这些步骤，但使用一个不同的数据点！ 使用不同的数据点进行训练 使用各种数据点泛化（generalize）我们的模型，即学习可被用于预测任何特征值的 W 和 b 值。注意： 在大部分情况下，数据点越多，模型的学习和泛化就越好 如果你训练的 epoch 比数据点还多，你可以重复使用数据点，这不成问题。梯度下降优化总是会同时使用数据点及其成本（根据该 epoch 的 W 和 b 值从数据点中计算得到）来对 W 和 b 值进行调整；该优化器也许之前已经见过了这个数据点，但成本并不一样，因此它还是可以学到新的东西，并以不同的方式调整 W 和 b 值。 你可以用固定数量的 epoch 训练一个模型，直到其达到令人满意的成本阈值。 训练变量 1.随机、mini-batch、batch 在上面的训练中，我们在每个 epoch 送入单个数据点。这被称为随机梯度下降（stochastic gradient descent）。我们也可以在每个 epoch 送入一堆数据点，这被称为 mini-batch 梯度下降，或者甚至在一个 epoch 一次性送入所有的数据点，这被称为 batch 梯度下降。请看下图的比较，注意这 3 张图的 2 处不同： 每个 epoch 送入 TensorFlow 图（TF.Graph）的数据点的数量（图右上方） 梯度下降优化在调整 W 和 b 值时所考虑的数据点的数量（图右下方） 随机梯度下降 mini-batch 梯度下降 batch 梯度下降 每张图中的数据点的数量有 2 个含义。当数据点更多时： 计算成本和执行梯度下降所需的计算资源（减法、平方、加法）会增加 模型的学习和泛化的速度增加 选择随机、mini-batch、batch 梯度下降的优缺点总结在下图中： 选择随机、mini-batch、batch 梯度下降的优缺点 要在随机/mini-batch/batch 梯度下降之间切换，我们只需要在将数据点送入训练步骤[D]之前将这些数据点分成不同的 batch 大小，即为 [C] 使用如下的代码片段： # all_xs: 所有的特征值 # all_ys: 所有的输出值 # datapoint_size: all_xs/all_ys 中点/项的数量 # batch_size: 配置如下: # 1: 随机模型 # integer &lt; datapoint_size: mini-batch模式 # datapoint_size: batch模式 # i: 当前epoch数量 if datapoint_size == batch_size: # Batch 模式，所以选择所有数据点从 index 0 开始 batch_start_idx = 0 elif datapoint_size &lt; batch_size: # 不可能 raise ValueError(“datapoint_size: %d, must be greater than batch_size: %d” % (datapoint_size, batch_size)) else: # 随机/mini-batch模式: 从所有可能的数据点中分批选择数据点 batch_start_idx = (i * batch_size) % (datapoint_size — batch_size) batch_end_idx = batch_start_idx + batch_size batch_xs = all_xs[batch_start_idx:batch_end_idx] batch_ys = all_ys[batch_start_idx:batch_end_idx] # 将分批的数据点定义为xs, ys, 它们会被送入 ‘train_step’训练步骤 xs = np.array(batch_xs) ys = np.array(batch_ys) 2.学习率变化 学习率（learn rate）是指梯度下降调整 W 和 b 递增或递减的速度。学习率较小时，处理过程会更慢，但肯定能得到更小成本；而当学习率更大时，我们可以更快地得到最小成本，但有「冲过头」的风险，导致我们没法找到最小成本。 为了克服这一问题，许多机器学习实践者选择开始时使用较大的学习率（假设开始时的成本离最小成本还很远），然后随每个 epoch 而逐渐降低学习率。 TensorFlow 提供了 2 种方法可以做到这一点，详细解释可参考： train_step = tf.train.GradientDescentOptimizer( learning_rate=learn_rate).minimize(cost) # 修改[D]，包含送入一个’learn_rate’值, # 即 ‘initial_learnrate’（初始学习率）除以’i’ (当前epoch数) # 注: 这是过于简化的，仅用作示例 feed = { x: xs, y: ys, learn_rate: initial_learn_rate/i } sess.run(train_step, feed_dict=feed) 小结 我们解释了机器学习中「训练（training）」的含义，以及在 TensorFlow 中通过模型和成本定义、然后循环通过训练步骤（将数据点送入梯度下降优化器）来进行训练的方式。我们还讨论了训练中的常见变量，即改变模型学习时每个 epoch 所用的数据点的大小和改变梯度下降优化器的学习率。 后续内容 创建 Tensor Board 来可视化 Tensorflow 的执行，从而检测我们的模型、成本函数或梯度下降中的问题 使用多个特征表达线性回归 ©本文由机器之心编译，转载请联系本公众号获得授权。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"Tensorflow一些常用基本概念与函数","date":"2017-02-13T00:50:06.000Z","path":"2017/02/13/Program/TensorFlow/basic-concept-and-operation-of-tensorflow/","text":"作者：林海山波 本文主要对tf的一些常用概念与方法进行描述。 1、tensorflow的基本运作 为了快速的熟悉TensorFlow编程，下面从一段简单的代码开始： import tensorflow as tf #定义‘符号’变量，也称为占位符 a = tf.placeholder(\"float\") b = tf.placeholder(\"float\") y = tf.mul(a, b) #构造一个op节点 sess = tf.Session()#建立会话 #运行会话，输入数据，并计算节点，同时打印结果 print sess.run(y, feed_dict={a: 3, b: 3}) # 任务完成, 关闭会话. sess.close() 其中tf.mul(a, b)函数便是tf的一个基本的算数运算，接下来介绍跟多的相关函数。 2、tf函数 TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU。一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测。如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作. 并行计算能让代价大的算法计算加速执行，TensorFlow也在实现上对复杂操作进行了有效的改进。大部分核相关的操作都是设备相关的实现，比如GPU。下面是一些重要的操作/核： 操作组 操作 Maths Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal Array Concat, Slice, Split, Constant, Rank, Shape, Shuffle Matrix MatMul, MatrixInverse, MatrixDeterminant Neuronal Network SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool Checkpointing Save, Restore Queues and syncronizations Enqueue, Dequeue, MutexAcquire, MutexRelease Flow control Merge, Switch, Enter, Leave, NextIteration TensorFlow的算术操作如下： 操作 描述 tf.add(x, y, name=None) 求和 tf.sub(x, y, name=None) 减法 tf.mul(x, y, name=None) 乘法 tf.div(x, y, name=None) 除法 tf.mod(x, y, name=None) 取模 tf.abs(x, name=None) 求绝对值 tf.neg(x, name=None) 取负 (y = -x). tf.sign(x, name=None) 返回符号 y = sign(x) = -1 if x &lt; 0; 0 if x == 0; 1 if x &gt; 0. tf.inv(x, name=None) 取反 tf.square(x, name=None) 计算平方 (y = x * x = x^2). tf.round(x, name=None) 舍入最接近的整数# ‘a’ is [0.9, 2.5, 2.3, -4.4]tf.round(a) ==&gt; [ 1.0, 3.0, 2.0, -4.0 ] tf.sqrt(x, name=None) 开根号 (y = \\sqrt{x} = x^{1/2}). tf.pow(x, y, name=None) 幂次方 # tensor ‘x’ is [[2, 2], [3, 3]]# tensor ‘y’ is [[8, 16], [2, 3]]tf.pow(x, y) ==&gt; [[256, 65536], [9, 27]] tf.exp(x, name=None) 计算e的次方 tf.log(x, name=None) 计算log，一个输入计算e的ln，两输入以第二输入为底 tf.maximum(x, y, name=None) 返回最大值 (x &gt; y ? x : y) tf.minimum(x, y, name=None) 返回最小值 (x &lt; y ? x : y) tf.cos(x, name=None) 三角函数cosine tf.sin(x, name=None) 三角函数sine tf.tan(x, name=None) 三角函数tan tf.atan(x, name=None) 三角函数ctan 张量操作Tensor Transformations 数据类型转换Casting 操作 描述 tf.string_to_number(string_tensor, out_type=None, name=None) 字符串转为数字 tf.to_double(x, name=’ToDouble’) 转为64位浮点类型–float64 tf.to_float(x, name=’ToFloat’) 转为32位浮点类型–float32 tf.to_int32(x, name=’ToInt32’) 转为32位整型–int32 tf.to_int64(x, name=’ToInt64’) 转为64位整型–int64 tf.cast(x, dtype, name=None) 将x或者x.values转换为dtype# tensor a is [1.8, 2.2], dtype=tf.floattf.cast(a, tf.int32) ==&gt; [1, 2] # dtype=tf.int32 形状操作Shapes and Shaping 操作 描述 tf.shape(input, name=None) 返回数据的shape# ‘t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]shape(t) ==&gt; [2, 2, 3] tf.size(input, name=None) 返回数据的元素数量# ‘t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]size(t) ==&gt; 12 tf.rank(input, name=None) 返回tensor的rank注意：此rank不同于矩阵的rank，tensor的rank表示一个tensor需要的索引数目来唯一表示任何一个元素也就是通常所说的 “order”, “degree”或”ndims”#’t’ is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]# shape of tensor ‘t’ is [2, 2, 3]rank(t) ==&gt; 3 tf.reshape(tensor, shape, name=None) 改变tensor的形状# tensor ‘t’ is [1, 2, 3, 4, 5, 6, 7, 8, 9]# tensor ‘t’ has shape [9]reshape(t, [3, 3]) ==&gt; [[1, 2, 3],[4, 5, 6],[7, 8, 9]]#如果shape有元素[-1],表示在该维度打平至一维# -1 将自动推导得为 9:reshape(t, [2, -1]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],[4, 4, 4, 5, 5, 5, 6, 6, 6]] tf.expand_dims(input, dim, name=None) 插入维度1进入一个tensor中#该操作要求-1-input.dims()# ‘t’ is a tensor of shape [2]shape(expand_dims(t, 0)) ==&gt; [1, 2]shape(expand_dims(t, 1)) ==&gt; [2, 1]shape(expand_dims(t, -1)) ==&gt; [2, 1] &lt;= dim &lt;= input.dims() 切片与合并（Slicing and Joining） 操作 描述 tf.slice(input_, begin, size, name=None) 对tensor进行切片操作其中size[i] = input.dim_size(i) - begin[i]该操作要求 0 &lt;= begin[i] &lt;= begin[i] + size[i] &lt;= Di for i in [0, n]#’input’ is #[[[1, 1, 1], [2, 2, 2]],[[3, 3, 3], [4, 4, 4]],[[5, 5, 5], [6, 6, 6]]]tf.slice(input, [1, 0, 0], [1, 1, 3]) ==&gt; [[[3, 3, 3]]]tf.slice(input, [1, 0, 0], [1, 2, 3]) ==&gt; [[[3, 3, 3],[4, 4, 4]]]tf.slice(input, [1, 0, 0], [2, 1, 3]) ==&gt; [[[3, 3, 3]],[[5, 5, 5]]] tf.split(split_dim, num_split, value, name=’split’) 沿着某一维度将tensor分离为num_split tensors# ‘value’ is a tensor with shape [5, 30]# Split ‘value’ into 3 tensors along dimension 1split0, split1, split2 = tf.split(1, 3, value)tf.shape(split0) ==&gt; [5, 10] tf.concat(concat_dim, values, name=’concat’) 沿着某一维度连结tensort1 = [[1, 2, 3], [4, 5, 6]]t2 = [[7, 8, 9], [10, 11, 12]]tf.concat(0, [t1, t2]) ==&gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]tf.concat(1, [t1, t2]) ==&gt; [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]如果想沿着tensor一新轴连结打包,那么可以：tf.concat(axis, [tf.expand_dims(t, axis) for t in tensors])等同于tf.pack(tensors, axis=axis) tf.pack(values, axis=0, name=’pack’) 将一系列rank-R的tensor打包为一个rank-(R+1)的tensor# ‘x’ is [1, 4], ‘y’ is [2, 5], ‘z’ is [3, 6]pack([x, y, z]) =&gt; [[1, 4], [2, 5], [3, 6]] # 沿着第一维packpack([x, y, z], axis=1) =&gt; [[1, 2, 3], [4, 5, 6]]等价于tf.pack([x, y, z]) = np.asarray([x, y, z]) tf.reverse(tensor, dims, name=None) 沿着某维度进行序列反转其中dim为列表，元素为bool型，size等于rank(tensor)# tensor ‘t’ is [[[[ 0, 1, 2, 3],#[ 4, 5, 6, 7],#[ 8, 9, 10, 11]],#[[12, 13, 14, 15],#[16, 17, 18, 19],#[20, 21, 22, 23]]]]# tensor ‘t’ shape is [1, 2, 3, 4]# ‘dims’ is [False, False, False, True]reverse(t, dims) ==&gt; [[[[ 3, 2, 1, 0], [ 7, 6, 5, 4],[ 11, 10, 9, 8]], [[15, 14, 13, 12], [19, 18, 17, 16], [23, 22, 21, 20]]]] tf.transpose(a, perm=None, name=’transpose’) 调换tensor的维度顺序按照列表perm的维度排列调换tensor顺序，如为定义，则perm为(n-1…0)# ‘x’ is [[1 2 3],[4 5 6]]tf.transpose(x) ==&gt; [[1 4], [2 5],[3 6]]# Equivalentlytf.transpose(x, perm=[1, 0]) ==&gt; [[1 4],[2 5], [3 6]] tf.gather(params, indices, validate_indices=None, name=None) 合并索引indices所指示params中的切片 tf.one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None) indices = [0, 2, -1, 1]depth = 3on_value = 5.0 off_value = 0.0 axis = -1 #Then output is [4 x 3]: output = [5.0 0.0 0.0] // one_hot(0) [0.0 0.0 5.0] // one_hot(2) [0.0 0.0 0.0] // one_hot(-1) [0.0 5.0 0.0] // one_hot(1) 矩阵相关运算 操作 描述 tf.diag(diagonal, name=None) 返回一个给定对角值的对角tensor# ‘diagonal’ is [1, 2, 3, 4]tf.diag(diagonal) ==&gt; [[1, 0, 0, 0][0, 2, 0, 0][0, 0, 3, 0][0, 0, 0, 4]] tf.diag_part(input, name=None) 功能与上面相反 tf.trace(x, name=None) 求一个2维tensor足迹，即对角值diagonal之和 tf.transpose(a, perm=None, name=’transpose’) 调换tensor的维度顺序按照列表perm的维度排列调换tensor顺序，如为定义，则perm为(n-1…0)# ‘x’ is [[1 2 3],[4 5 6]]tf.transpose(x) ==&gt; [[1 4], [2 5],[3 6]]# Equivalentlytf.transpose(x, perm=[1, 0]) ==&gt; [[1 4],[2 5], [3 6]] tf.matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None) 矩阵相乘 tf.matrix_determinant(input, name=None) 返回方阵的行列式 tf.matrix_inverse(input, adjoint=None, name=None) 求方阵的逆矩阵，adjoint为True时，计算输入共轭矩阵的逆矩阵 tf.cholesky(input, name=None) 对输入方阵cholesky分解，即把一个对称正定的矩阵表示成一个下三角矩阵L和其转置的乘积的分解A=LL^T tf.matrix_solve(matrix, rhs, adjoint=None, name=None) 求解tf.matrix_solve(matrix, rhs, adjoint=None, name=None)matrix为方阵shape为[M,M],rhs的shape为[M,K]，output为[M,K] 复数操作 操作 描述 tf.complex(real, imag, name=None) 将两实数转换为复数形式# tensor ‘real’ is [2.25, 3.25]# tensor imag is [4.75, 5.75]tf.complex(real, imag) ==&gt; [[2.25 + 4.75j], [3.25 + 5.75j]] tf.complex_abs(x, name=None) 计算复数的绝对值，即长度。# tensor ‘x’ is [[-2.25 + 4.75j], [-3.25 + 5.75j]]tf.complex_abs(x) ==&gt; [5.25594902, 6.60492229] tf.conj(input, name=None) 计算共轭复数 tf.imag(input, name=None)tf.real(input, name=None) 提取复数的虚部和实部 tf.fft(input, name=None) 计算一维的离散傅里叶变换，输入数据类型为complex64 归约计算(Reduction) 操作 描述 tf.reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None) 计算输入tensor元素的和，或者安照reduction_indices指定的轴进行求和# ‘x’ is [[1, 1, 1]# [1, 1, 1]]tf.reduce_sum(x) ==&gt; 6tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]tf.reduce_sum(x, 1) ==&gt; [3, 3]tf.reduce_sum(x, 1, keep_dims=True) ==&gt; [[3], [3]]tf.reduce_sum(x, [0, 1]) ==&gt; 6 tf.reduce_prod(input_tensor, reduction_indices=None, keep_dims=False, name=None) 计算输入tensor元素的乘积，或者安照reduction_indices指定的轴进行求乘积 tf.reduce_min(input_tensor, reduction_indices=None, keep_dims=False, name=None) 求tensor中最小值 tf.reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None) 求tensor中最大值 tf.reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None) 求tensor中平均值 tf.reduce_all(input_tensor, reduction_indices=None, keep_dims=False, name=None) 对tensor中各个元素求逻辑’与’# ‘x’ is # [[True, True]# [False, False]]tf.reduce_all(x) ==&gt; Falsetf.reduce_all(x, 0) ==&gt; [False, False]tf.reduce_all(x, 1) ==&gt; [True, False] tf.reduce_any(input_tensor, reduction_indices=None, keep_dims=False, name=None) 对tensor中各个元素求逻辑’或’ tf.accumulate_n(inputs, shape=None, tensor_dtype=None, name=None) 计算一系列tensor的和# tensor ‘a’ is [[1, 2], [3, 4]]# tensor b is [[5, 0], [0, 6]]tf.accumulate_n([a, b, a]) ==&gt; [[7, 4], [6, 14]] tf.cumsum(x, axis=0, exclusive=False, reverse=False, name=None) 求累积和tf.cumsum([a, b, c]) ==&gt; [a, a + b, a + b + c]tf.cumsum([a, b, c], exclusive=True) ==&gt; [0, a, a + b]tf.cumsum([a, b, c], reverse=True) ==&gt; [a + b + c, b + c, c]tf.cumsum([a, b, c], exclusive=True, reverse=True) ==&gt; [b + c, c, 0] 分割(Segmentation) 操作 描述 tf.segment_sum(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的和其中segment_ids为一个size与data第一维相同的tensor其中id为int型数据，最大id不大于sizec = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])tf.segment_sum(c, tf.constant([0, 0, 1]))==&gt;[[0 0 0 0] [5 6 7 8]]上面例子分为[0,1]两id,对相同id的data相应数据进行求和,并放入结果的相应id中，且segment_ids只升不降 tf.segment_prod(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的积 tf.segment_min(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的最小值 tf.segment_max(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的最大值 tf.segment_mean(data, segment_ids, name=None) 根据segment_ids的分段计算各个片段的平均值 tf.unsorted_segment_sum(data, segment_ids, num_segments, name=None) 与tf.segment_sum函数类似，不同在于segment_ids中id顺序可以是无序的 tf.sparse_segment_sum(data, indices, segment_ids, name=None) 输入进行稀疏分割求和c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])# Select two rows, one segment.tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0])) ==&gt; [[0 0 0 0]]对原data的indices为[0,1]位置的进行分割，并按照segment_ids的分组进行求和 序列比较与索引提取(Sequence Comparison and Indexing) 操作 描述 tf.argmin(input, dimension, name=None) 返回input最小值的索引index tf.argmax(input, dimension, name=None) 返回input最大值的索引index tf.listdiff(x, y, name=None) 返回x，y中不同值的索引 tf.where(input, name=None) 返回bool型tensor中为True的位置# ‘input’ tensor is #[[True, False]#[True, False]]# ‘input’ 有两个’True’,那么输出两个坐标值.# ‘input’的rank为2, 所以每个坐标为具有两个维度.where(input) ==&gt; [[0, 0],[1, 0]] tf.unique(x, name=None) 返回一个元组tuple(y,idx)，y为x的列表的唯一化数据列表，idx为x数据对应y元素的index# tensor ‘x’ is [1, 1, 2, 4, 4, 4, 7, 8, 8]y, idx = unique(x)y ==&gt; [1, 2, 4, 7, 8]idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4] tf.invert_permutation(x, name=None) 置换x数据与索引的关系# tensor x is [3, 4, 0, 2, 1]invert_permutation(x) ==&gt; [2, 4, 3, 0, 1] 神经网络(Neural Network) 激活函数（Activation Functions） 操作 描述 tf.nn.relu(features, name=None) 整流函数：max(features, 0) tf.nn.relu6(features, name=None) 以6为阈值的整流函数：min(max(features, 0), 6) tf.nn.elu(features, name=None) elu函数，exp(features) - 1 if &lt; 0,否则featuresExponential Linear Units (ELUs) tf.nn.softplus(features, name=None) 计算softplus：log(exp(features) + 1) tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None) 计算dropout，keep_prob为keep概率noise_shape为噪声的shape tf.nn.bias_add(value, bias, data_format=None, name=None) 对value加一偏置量此函数为tf.add的特殊情况，bias仅为一维，函数通过广播机制进行与value求和,数据格式可以与value不同，返回为与value相同格式 tf.sigmoid(x, name=None) y = 1 / (1 + exp(-x)) tf.tanh(x, name=None) 双曲线切线激活函数 卷积函数（Convolution） 操作 描述 tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None) 在给定的4D input与 filter下计算2D卷积输入shape为 [batch, height, width, in_channels] tf.nn.conv3d(input, filter, strides, padding, name=None) 在给定的5D input与 filter下计算3D卷积输入shape为[batch, in_depth, in_height, in_width, in_channels] 池化函数（Pooling） 操作 描述 tf.nn.avg_pool(value, ksize, strides, padding, data_format=’NHWC’, name=None) 平均方式池化 tf.nn.max_pool(value, ksize, strides, padding, data_format=’NHWC’, name=None) 最大值方法池化 tf.nn.max_pool_with_argmax(input, ksize, strides, padding, Targmax=None, name=None) 返回一个二维元组(output,argmax),最大值pooling，返回最大值及其相应的索引 tf.nn.avg_pool3d(input, ksize, strides, padding, name=None) 3D平均值pooling tf.nn.max_pool3d(input, ksize, strides, padding, name=None) 3D最大值pooling 数据标准化（Normalization） 操作 描述 tf.nn.l2_normalize(x, dim, epsilon=1e-12, name=None) 对维度dim进行L2范式标准化output = x / sqrt(max(sum(x*2), epsilon)) tf.nn.sufficient_statistics(x, axes, shift=None, keep_dims=False, name=None) 计算与均值和方差有关的完全统计量返回4维元组,元素个数，元素总和，元素的平方和，*shift结果参见算法介绍 tf.nn.normalize_moments(counts, mean_ss, variance_ss, shift, name=None) 基于完全统计量计算均值和方差 tf.nn.moments(x, axes, shift=None, name=None, keep_dims=False) 直接计算均值与方差 损失函数（Losses） 操作 描述 tf.nn.l2_loss(t, name=None) output = sum(t ** 2) / 2 分类函数（Classification） 操作 描述 tf.nn.sigmoid_cross_entropy_with_logits(logits, targets, name=None)* 计算输入logits, targets的交叉熵 tf.nn.softmax(logits, name=None) 计算softmaxsoftmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j])) tf.nn.log_softmax(logits, name=None) logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i]))) tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None) 计算logits和labels的softmax交叉熵logits, labels必须为相同的shape与数据类型 tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name=None) 计算logits和labels的softmax交叉熵 tf.nn.weighted_cross_entropy_with_logits(logits, targets, pos_weight, name=None) 与sigmoid_cross_entropy_with_logits()相似，但给正向样本损失加了权重pos_weight 符号嵌入（Embeddings） 操作 描述 tf.nn.embedding_lookup(params, ids, partition_strategy=’mod’, name=None, validate_indices=True) 根据索引ids查询embedding列表params中的tensor值如果len(params) &gt; 1，id将会安照partition_strategy策略进行分割1、如果partition_strategy为”mod”，id所分配到的位置为p = id % len(params)比如有13个ids，分为5个位置，那么分配方案为：[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]2、如果partition_strategy为”div”,那么分配方案为：[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]] tf.nn.embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy=’mod’, name=None, combiner=’mean’) 对给定的ids和权重查询embedding1、sp_ids为一个N x M的稀疏tensor，N为batch大小，M为任意，数据类型int642、sp_weights的shape与sp_ids的稀疏tensor权重，浮点类型，若为None，则权重为全’1’ 循环神经网络（Recurrent Neural Networks） 操作 描述 tf.nn.rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None) 基于RNNCell类的实例cell建立循环神经网络 tf.nn.dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None) 基于RNNCell类的实例cell建立动态循环神经网络与一般rnn不同的是，该函数会根据输入动态展开返回(outputs,state) tf.nn.state_saving_rnn(cell, inputs, state_saver, state_name, sequence_length=None, scope=None) 可储存调试状态的RNN网络 tf.nn.bidirectional_rnn(cell_fw, cell_bw, inputs, initial_state_fw=None, initial_state_bw=None, dtype=None, sequence_length=None, scope=None) 双向RNN, 返回一个3元组tuple(outputs, output_state_fw, output_state_bw) — tf.nn.rnn简要介绍— cell: 一个RNNCell实例 inputs: 一个shape为[batch_size, input_size]的tensor initial_state: 为RNN的state设定初值，可选 sequence_length：制定输入的每一个序列的长度，size为[batch_size],值范围为[0, T)的int型数据 其中T为输入数据序列的长度 @ @针对输入batch中序列长度不同，所设置的动态计算机制 @对于在时间t，和batch的b行，有 (output, state)(b, t) = ? (zeros(cell.output_size), states(b, sequence_length(b) - 1)) : cell(input(b, t), state(b, t - 1)) 求值网络（Evaluation） 操作 描述 tf.nn.top_k(input, k=1, sorted=True, name=None) 返回前k大的值及其对应的索引 tf.nn.in_top_k(predictions, targets, k, name=None) 返回判断是否targets索引的predictions相应的值是否在在predictions前k个位置中，返回数据类型为bool类型，len与predictions同 监督候选采样网络（Candidate Sampling） 对于有巨大量的多分类与多标签模型，如果使用全连接softmax将会占用大量的时间与空间资源，所以采用候选采样方法仅使用一小部分类别与标签作为监督以加速训练。 操作 描述 Sampled Loss Functions tf.nn.nce_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=False, partition_strategy=’mod’, name=’nce_loss’) 返回noise-contrastive的训练损失结果 tf.nn.sampled_softmax_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=True, partition_strategy=’mod’, name=’sampled_softmax_loss’) 返回sampled softmax的训练损失参考- Jean et al., 2014第3部分 Candidate Samplers tf.nn.uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None) 通过均匀分布的采样集合返回三元tuple1、sampled_candidates 候选集合。2、期望的true_classes个数，为浮点值3、期望的sampled_candidates个数，为浮点值 tf.nn.log_uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None) 通过log均匀分布的采样集合，返回三元tuple tf.nn.learned_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None) 根据在训练过程中学习到的分布状况进行采样返回三元tuple tf.nn.fixed_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, vocab_file=”, distortion=1.0, num_reserved_ids=0, num_shards=1, shard=0, unigrams=(), seed=None, name=None) 基于所提供的基本分布进行采样 保存与恢复变量 操作 描述 类tf.train.Saver(Saving and Restoring Variables) tf.train.Saver.init(var_list=None, reshape=False, sharded=False, max_to_keep=5, keep_checkpoint_every_n_hours=10000.0, name=None, restore_sequentially=False, saver_def=None, builder=None) 创建一个存储器Savervar_list定义需要存储和恢复的变量 tf.train.Saver.save(sess, save_path, global_step=None, latest_filename=None, meta_graph_suffix=’meta’, write_meta_graph=True) 保存变量 tf.train.Saver.restore(sess, save_path) 恢复变量 tf.train.Saver.last_checkpoints 列出最近未删除的checkpoint 文件名 tf.train.Saver.set_last_checkpoints(last_checkpoints) 设置checkpoint文件名列表 tf.train.Saver.set_last_checkpoints_with_time(last_checkpoints_with_time) 设置checkpoint文件名列表和时间戳 相关链接： [1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 摘要：本文主要对tf的一些常用概念与方法进行描述。为‘Tensorflow一些常用基本概念与函数’系列之二。1、tensorflow的基本运作为了快速的熟悉TensorFlow编程，下面从一段简单的代码开始：import tensorflow as tf #定义‘符号’变量，也称为占位符 a = tf.placeholder(“float”) b = tf.placeholder(“float”) y = tf.mul(a, b) #构造一个op节点 sess = tf.Session()#建立会话 #运行会话，输入数据，并计算节点，同时打印结果 print sess.run(y, feed_dict={a: 3, b: 3}) # 任务完成, 关闭会话. sess.close()其中tf.mul(a, b)函数便是tf的一个基本的算数运算，接下来介绍跟多的相关函数。2、tf函数TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU。一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测。如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作.并行计算能让代价大的算法计算加速执行，TensorFlow也在实现上对复杂操作进行了有效的改进。大部分核相关的操作都是设备相关的实现，比如GPU。本文主要涉及的相关概念或操作有以下内容： 操作组 操作 Building Graphs Core graph data structures，Tensor types，Utility functions Inputs and Readers Placeholders，Readers，Converting，Queues，Input pipeline2.1 建立图(Building Graphs)本节主要介绍建立tensorflow图的相关类或函数 核心图的数据结构（Core graph data structures）tf.Graph 操作 描述 class tf.Graph tensorflow中的计算以图数据流的方式表示一个图包含一系列表示计算单元的操作对象以及在图中流动的数据单元以tensor对象表现 tf.Graph.init() 建立一个空图 tf.Graph.as_default() 一个将某图设置为默认图，并返回一个上下文管理器如果不显式添加一个默认图，系统会自动设置一个全局的默认图。所设置的默认图，在模块范围内所定义的节点都将默认加入默认图中 tf.Graph.as_graph_def(from_version=None, add_shapes=False) 返回一个图的序列化的GraphDef表示序列化的GraphDef可以导入至另一个图中(使用 import_graph_def())或者使用C++ Session API tf.Graph.finalize() 完成图的构建，即将其设置为只读模式 tf.Graph.finalized 返回True，如果图被完成 tf.Graph.control_dependencies(control_inputs) 定义一个控制依赖，并返回一个上下文管理器with g.control_dependencies([a, b, c]):# d 和 e 将在 a, b, 和c执行完之后运行.d = … e = … tf.Graph.device(device_name_or_function) 定义运行图所使用的设备，并返回一个上下文管理器with g.device(‘/gpu:0’): …with g.device(‘/cpu:0’): … tf.Graph.name_scope(name) 为节点创建层次化的名称，并返回一个上下文管理器 tf.Graph.add_to_collection(name, value) 将value以name的名称存储在收集器(collection)中 tf.Graph.get_collection(name, scope=None) 根据name返回一个收集器中所收集的值的列表 tf.Graph.as_graph_element(obj, allow_tensor=True, allow_operation=True) 返回一个图中与obj相关联的对象，为一个操作节点或者tensor数据 tf.Graph.get_operation_by_name(name) 根据名称返回操作节点 tf.Graph.get_tensor_by_name(name) 根据名称返回tensor数据 tf.Graph.get_operations() 返回图中的操作节点列表 tf.Graph.gradient_override_map(op_type_map) 用于覆盖梯度函数的上下文管理器#class tf.Graph#tensorflow运行时需要设置默认的图g = tf.Graph()with g.as_default(): # Define operations and tensors in g. c = tf.constant(30.0) assert c.graph is g##也可以使用tf.get_default_graph()获得默认图，也可在基础上加入节点或子图c = tf.constant(4.0)assert c.graph is tf.get_default_graph()#tf.Graph.as_default#以下两段代码功能相同#1、使用Graph.as_default():g = tf.Graph()with g.as_default(): c = tf.constant(5.0) assert c.graph is g#2、构造和设置为默认with tf.Graph().as_default() as g: c = tf.constant(5.0) assert c.graph is g#tf.Graph.control_dependencies(control_inputs)# 错误代码def my_func(pred, tensor): t = tf.matmul(tensor, tensor) with tf.control_dependencies([pred]): # 乘法操作(op)没有创建在该上下文，所以没有被加入依赖控制 return t# 正确代码def my_func(pred, tensor): with tf.control_dependencies([pred]): # 乘法操作(op)创建在该上下文，所以被加入依赖控制中 #执行完pred之后再执行matmul return tf.matmul(tensor, tensor)# tf.Graph.name_scope(name)# 一个图中包含有一个名称范围的堆栈，在使用name_scope(…)之后，将压(push)新名称进栈中，#并在下文中使用该名称with tf.Graph().as_default() as g: c = tf.constant(5.0, name=“c”) assert c.op.name == “c” c_1 = tf.constant(6.0, name=“c”) assert c_1.op.name == “c_1” # Creates a scope called “nested” with g.name_scope(“nested”) as scope: nested_c = tf.constant(10.0, name=“c”) assert nested_c.op.name == “nested/c” # Creates a nested scope called “inner”. with g.name_scope(“inner”): nested_inner_c = tf.constant(20.0, name=“c”) assert nested_inner_c.op.name == “nested/inner/c” # Create a nested scope called “inner_1”. with g.name_scope(“inner”): nested_inner_1_c = tf.constant(30.0, name=“c”) assert nested_inner_1_c.op.name == “nested/inner_1/c” # Treats scope as an absolute name scope, and # switches to the “nested/“ scope. with g.name_scope(scope): nested_d = tf.constant(40.0, name=“d”) assert nested_d.op.name == “nested/d” with g.name_scope(“”): e = tf.constant(50.0, name=“e”) assert e.op.name == “e”tf.Operation 操作 描述 class tf.Operation 代表图中的一个节点，用于计算tensors数据该类型将由python节点构造器产生(比如tf.matmul())或者Graph.create_op()例如c = tf.matmul(a, b)创建一个Operation类为类型为”MatMul”,输入为’a’,’b’，输出为’c’的操作类 tf.Operation.name 操作节点(op)的名称 tf.Operation.type 操作节点(op)的类型，比如”MatMul” tf.Operation.inputstf.Operation.outputs 操作节点的输入与输出 tf.Operation.control_inputs 操作节点的依赖 tf.Operation.run(feed_dict=None, session=None) 在会话(Session)中运行该操作 tf.Operation.get_attr(name) 获取op的属性值tf.Tensor 操作 描述 class tf.Tensor 表示一个由操作节点op产生的值，TensorFlow程序使用tensor数据结构来代表所有的数据, 计算图中, 操作间传递的数据都是 tensor，一个tensor是一个符号handle,里面并没有表示实际数据，而相当于数据流的载体 tf.Tensor.dtype tensor中数据类型 tf.Tensor.name 该tensor名称 tf.Tensor.value_index 该tensor输出外op的index tf.Tensor.graph 该tensor所处在的图 tf.Tensor.op 产生该tensor的op tf.Tensor.consumers() 返回使用该tensor的op列表 tf.Tensor.eval(feed_dict=None, session=None) 在会话中求tensor的值需要使用with sess.as_default()或者 eval(session=sess) tf.Tensor.get_shape() 返回用于表示tensor的shape的类TensorShape tf.Tensor.set_shape(shape) 更新tensor的shape tf.Tensor.device 设置计算该tensor的设备#tf.Tensor.get_shape()c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])print(c.get_shape())==&gt; TensorShape([Dimension(2), Dimension(3)])#现在有个用于图像处理的tensor-&gt;imageprint(image.get_shape())==&gt; TensorShape([Dimension(None), Dimension(None), Dimension(3)])# 假如我们知道数据集中图像尺寸为28 x 28，那么可以设置image.set_shape([28, 28, 3])print(image.get_shape())==&gt; TensorShape([Dimension(28), Dimension(28), Dimension(3)]) tensor类型(Tensor types)tf.DType 操作 描述 class tf.DType 数据类型主要包含tf.float16，tf.float16,tf.float32,tf.float64,tf.bfloat16,tf.complex64,tf.complex128,tf.int8,tf.uint8,tf.uint16,tf.int16,tf.int32,tf.int64,tf.bool,tf.string tf.DType.is_compatible_with(other) 判断other的数据类型是否将转变为该DType tf.DType.name 数据类型名称 tf.DType.base_dtype 返回该DType的基础DType，而非参考的数据类型(non-reference) tf.DType.as_ref 返回一个基于DType的参考数据类型 tf.DType.is_floating 判断是否为浮点类型 tf.DType.is_complex 判断是否为复数 tf.DType.is_integer 判断是否为整数 tf.DType.is_unsigned 判断是否为无符号型数据 tf.DType.as_numpy_dtype 返回一个基于DType的numpy.dtype类型 tf.DType.maxtf.DType.min 返回这种数据类型能表示的最大值及其最小值 tf.as_dtype(type_value) 返回由type_value转变得的相应tf数据类型 通用函数（Utility functions） 操作 描述 tf.device(device_name_or_function) 基于默认的图，其功能便为Graph.device() tf.container(container_name) 基于默认的图，其功能便为Graph.container() tf.name_scope(name) 基于默认的图，其功能便为 Graph.name_scope() tf.control_dependencies(control_inputs) 基于默认的图，其功能便为Graph.control_dependencies() tf.convert_to_tensor(value, dtype=None, name=None, as_ref=False) 将value转变为tensor数据类型 tf.get_default_graph() 返回返回当前线程的默认图 tf.reset_default_graph() 清除默认图的堆栈，并设置全局图为默认图 tf.import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None) 将graph_def的图导入到python中 图收集（Graph collections） 操作 描述 tf.add_to_collection(name, value) 基于默认的图，其功能便为Graph.add_to_collection() tf.get_collection(key, scope=None) 基于默认的图，其功能便为Graph.get_collection() 定义新操作节点（Defining new operations）tf.RegisterGradient 操作 描述 class tf.RegisterGradient 返回一个用于寄存op类型的梯度函数的装饰器 tf.NoGradient(op_type) 设置操作节点类型op_type的节点没有指定的梯度 class tf.RegisterShape 返回一个用于寄存op类型的shape函数的装饰器 class tf.TensorShape 表示tensor的shape tf.TensorShape.merge_with(other) 与other合并shape信息，返回一个TensorShape类 tf.TensorShape.concatenate(other) 与other的维度相连结 tf.TensorShape.ndims 返回tensor的rank tf.TensorShape.dims 返回tensor的维度 tf.TensorShape.as_list() 以list的形式返回tensor的shape tf.TensorShape.is_compatible_with(other) 判断shape是否为兼容TensorShape(None)与其他任何shape值兼容 class tf.Dimension tf.Dimension.is_compatible_with(other) 判断dims是否为兼容 tf.Dimension.merge_with(other) 与other合并dims信息 tf.op_scope(values, name, default_name=None) 在python定义op时，返回一个上下文管理器#tf.RegisterGradient#该装饰器只使用于定义一个新的op类型时候，如果一个op有m个输入，n个输出。那么该梯度函数应该设置原始的#操作类型，以及n个Tensor对象（表示每一个op输出的梯度），以及m个对象(表示每一个op输入的偏梯度)#以操作节点类型为’Sub’为例，两输入为x,y。为一个输出x-y@tf.RegisterGradient(“Sub”)def _sub_grad(unused_op, grad): return grad, tf.neg(grad)#tf.op_scope#定义一个名称为my_op的python操作节点opdef my_op(a, b, c, name=None): with tf.op_scope([a, b, c], name, “MyOp”) as scope: a = tf.convert_to_tensor(a, name=“a”) b = tf.convert_to_tensor(b, name=“b”) c = tf.convert_to_tensor(c, name=“c”) # Define some computation that uses a, b, and c. return foo_op(…, name=scope)2.2 输入和读取器(Inputs and Readers)本节主要介绍tensorflow中数据的读入相关类或函数 占位符（Placeholders）tf提供一种占位符操作，在执行时需要为其提供数据data。 操作 描述 tf.placeholder(dtype, shape=None, name=None) 为一个tensor插入一个占位符eg:x = tf.placeholder(tf.float32, shape=(1024, 1024)) tf.placeholder_with_default(input, shape, name=None) 当输出没有fed时，input通过一个占位符op tf.sparse_placeholder(dtype, shape=None, name=None) 为一个稀疏tensor插入一个占位符 读取器（Readers）tf提供一系列读取各种数据格式的类。对于多文件输入，可以使用函数tf.train.string_input_producer，该函数将创建一个保持文件的FIFO队列，以供reader使用。或者如果输入的这些文件名有相雷同的字符串，也可以使用函数tf.train.match_filenames_once。 操作 描述 class tf.ReaderBase 不同的读取器类型的基本类 tf.ReaderBase.read(queue, name=None) 返回下一个记录对(key, value),queue为tf文件队列FIFOQueue tf.ReaderBase.read_up_to(queue, num_records, name=None) 返回reader产生的num_records对(key, value) tf.ReaderBase.reader_ref 返回应用在该reader上的Op tf.ReaderBase.reset(name=None) 恢复reader为初始状态 tf.ReaderBase.restore_state(state, name=None) 恢复reader为之前的保存状态state tf.ReaderBase.serialize_state(name=None) 返回一个reader解码后产生的字符串tansor class tf.TextLineReader tf.TextLineReader.num_records_produced(name=None) 返回reader已经产生的记录(records )数目 tf.TextLineReader.num_work_units_completed(name=None) 返回该reader已经完成的处理的work数目 tf.TextLineReader.read(queue, name=None) 返回reader所产生的下一个记录对 (key, value)，该reader可以限定新产生输出的行数 tf.TextLineReader.reader_ref 返回应用在该reader上的Op tf.TextLineReader.reset(name=None) 恢复reader为初始状态 tf.TextLineReader.restore_state(state, name=None) 恢复reader为之前的保存状态state tf.TextLineReader.serialize_state(name=None) 返回一个reader解码后产生的字符串tansor class tf.WholeFileReader 一个阅读器，读取整个文件，返回文件名称key,以及文件中所有的内容value,该类的方法同上，不赘述 class tf.IdentityReader 一个reader，以key和value的形式，输出一个work队列。该类其他方法基本同上 class tf.TFRecordReader 读取TFRecord格式文件的reader。该类其他方法基本同上 class tf.FixedLengthRecordReader 输出 数据转换（Converting）tf提供一系列方法将各种格式数据转换为tensor表示。 操作 描述 tf.decode_csv(records, record_defaults, field_delim=None, name=None) 将csv转换为tensor，与tf.TextLineReader搭配使用 tf.decode_raw(bytes, out_type, little_endian=None, name=None) 将bytes转换为一个数字向量表示，bytes为一个字符串类型的tensor与函数 tf.FixedLengthRecordReader搭配使用，详见tf的CIFAR-10例子选取与要输入的文件格式相匹配的reader，并将文件队列提供给reader的读方法( read method)。读方法将返回文件唯一标识的key，以及一个记录(record)（有助于对出现一些另类的records时debug），以及一个标量的字符串值。再使用一个（或多个）解码器(decoder) 或转换操作(conversion ops)将字符串转换为tensor类型。#读取文件队列，使用reader中read的方法，返回key与valuefilename_queue = tf.train.string_input_producer([“file0.csv”, “file1.csv”])reader = tf.TextLineReader()key, value = reader.read(filename_queue)record_defaults = [[1], [1], [1], [1], [1]]col1, col2, col3, col4, col5 = tf.decode_csv( value, record_defaults=record_defaults)features = tf.pack([col1, col2, col3, col4])with tf.Session() as sess: # Start populating the filename queue. coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(coord=coord) for i in range(1200): # Retrieve a single instance: example, label = sess.run([features, col5]) coord.request_stop() coord.join(threads) Example protocol buffer提供了一些Example protocol buffers，tf所推荐的用于训练样本的数据格式，它们包含特征信息，详情可见。 这是一种与前述将手上现有的各种数据类型转换为支持的格式的方法，这种方法更容易将网络结构与数据集融合或匹配。这种tensorflow所推荐的数据格式是一个包含tf.train.Example protocol buffers (包含特征Features域)的TFRecords文件。 1、获取这种格式的文件方式为，首先将一般的数据格式填入Example protocol buffer中，再将 protocol buffer序列化为一个字符串，然后使用tf.python_io.TFRecordWriter类的相关方法将字符串写入一个TFRecords文件中，参见MNIST例子，将MNIST 数据转换为该类型数据。 2、读取TFRecords格式文件的方法为，使用tf.TFRecordReader读取器和tf.parse_single_example解码器。parse_single_example操作将 example protocol buffers解码为tensor形式。参见MNIST例子 操作 描述 class tf.VarLenFeature 解析变长的输入特征feature相关配置 class tf.FixedLenFeature 解析定长的输入特征feature相关配置 class tf.FixedLenSequenceFeature 序列项目中的稠密(dense )输入特征的相关配置 tf.parse_example(serialized, features, name=None, example_names=None) 将一组Example protos解析为tensor的字典形式解析serialized所给予的序列化的一些Example protos返回一个由特征keys映射Tensor和SparseTensor值的字典 tf.parse_single_example(serialized, features, name=None, example_names=None) 解析一个单独的Example proto，与tf.parse_example方法雷同 tf.decode_json_example(json_examples, name=None) 将JSON编码的样本记录转换为二进制protocol buffer字符串#tf.parse_example的使用举例#输入序列化数据如下： serialized = [ features { feature { key: “ft” value { float_list { value: [1.0, 2.0] } } } }, features { feature []}, features { feature { key: “ft” value { float_list { value: [3.0] } } }]#那么输出为一个字典(dict),如下：{“ft”: SparseTensor(indices=[[0, 0], [0, 1], [2, 0]], values=[1.0, 2.0, 3.0], shape=(3, 2)) }##########再来看一个例子，给定两个序列化的原始输入样本：[ features { feature { key: “kw” value { bytes_list { value: [ “knit”, “big” ] } } } feature { key: “gps” value { float_list { value: [] } } } }, features { feature { key: “kw” value { bytes_list { value: [ “emmy” ] } } } feature { key: “dank” value { int64_list { value: [ 42 ] } } } feature { key: “gps” value { } } }]#相关参数如下：example_names: [“input0”, “input1”],features: { “kw”: VarLenFeature(tf.string), “dank”: VarLenFeature(tf.int64), “gps”: VarLenFeature(tf.float32),}#那么有如下输出：{ “kw”: SparseTensor( indices=[[0, 0], [0, 1], [1, 0]], values=[“knit”, “big”, “emmy”] shape=[2, 2]), “dank”: SparseTensor( indices=[[1, 0]], values=[42], shape=[2, 1]), “gps”: SparseTensor( indices=[], values=[], shape=[2, 0]),}##########对于两个样本的输出稠密结果情况[ features { feature { key: “age” value { int64_list { value: [ 0 ] } } } feature { key: “gender” value { bytes_list { value: [ “f” ] } } } }, features { feature { key: “age” value { int64_list { value: [] } } } feature { key: “gender” value { bytes_list { value: [ “f” ] } } } }]#我们可以使用以下参数example_names: [“input0”, “input1”],features: { “age”: FixedLenFeature([], dtype=tf.int64, default_value=-1), “gender”: FixedLenFeature([], dtype=tf.string),}#期望的结果如下{ “age”: [[0], [-1]], “gender”: [[“f”], [“f”]],}##Example protocol buffer相关使用的例子#将mnist的数据转换为TFRecords文件格式import osimport tensorflow as tffrom tensorflow.contrib.learn.python.learn.datasets import mnistSOURCE_URL = ‘http://yann.lecun.com/exdb/mnist/‘TRAIN_IMAGES = ‘train-images-idx3-ubyte.gz’ # MNIST filenamesTRAIN_LABELS = ‘train-labels-idx1-ubyte.gz’TEST_IMAGES = ‘t10k-images-idx3-ubyte.gz’TEST_LABELS = ‘t10k-labels-idx1-ubyte.gz’tf.app.flags.DEFINE_string(‘directory’, ‘/tmp/data’, ‘Directory to download data files and write the ‘ ‘converted result’)tf.app.flags.DEFINE_integer(‘validation_size’, 5000, ‘Number of examples to separate from the training ‘ ‘data for the validation set.’)FLAGS = tf.app.flags.FLAGSdef _int64_feature(value): return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))def _bytes_feature(value): return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))def convert_to(data_set, name): images = data_set.images labels = data_set.labels num_examples = data_set.num_examples if images.shape[0] != num_examples: raise ValueError(‘Images size %d does not match label size %d.’ % (images.shape[0], num_examples)) rows = images.shape[1] cols = images.shape[2] depth = images.shape[3] filename = os.path.join(FLAGS.directory, name + ‘.tfrecords’) print(‘Writing’, filename) writer = tf.python_io.TFRecordWriter(filename) for index in range(num_examples): image_raw = images[index].tostring() example = tf.train.Example(features=tf.train.Features(feature={ ‘height’: _int64_feature(rows), ‘width’: _int64_feature(cols), ‘depth’: _int64_feature(depth), ‘label’: _int64_feature(int(labels[index])), ‘image_raw’: _bytes_feature(image_raw)})) writer.write(example.SerializeToString()) writer.close()def main(argv): # Get the data. data_sets = mnist.read_data_sets(FLAGS.directory, dtype=tf.uint8, reshape=False) # Convert to Examples and write the result to TFRecords. convert_to(data_sets.train, ‘train’) convert_to(data_sets.validation, ‘validation’) convert_to(data_sets.test, ‘test’)if name == ‘main‘: tf.app.run() 队列(Queues)tensorflow提供了几个队列应用，用来将tf计算图与tensors的阶段流水组织到一起。队列是使用tensorflow计算的一个强大的机制，正如其他Tensorflow的元素一样，一个队列也是tf图中的一个节点(node),它是一个有状态的node，就像一个变量：其他节点可以改变其内容。 我们来看一个简单的例子，如下gif图，我们将创建一个先入先出队列(FIFOQueue)并且将值全设为0，然后我们构建一个图以获取队列出来的元素，对该元素加1操作，并将结果再放入队列末尾。渐渐地，队列中的数字便增加。 操作 描述 class tf.QueueBase 基本的队列应用类.队列(queue)是一种数据结构，该结构通过多个步骤存储tensors,并且对tensors进行入列(enqueue)与出列(dequeue)操作 tf.QueueBase.enqueue(vals, name=None) 将一个元素编入该队列中。如果在执行该操作时队列已满，那么将会阻塞直到元素编入队列之中 tf.QueueBase.enqueue_many(vals, name=None) 将零个或多个元素编入该队列中 tf.QueueBase.dequeue(name=None) 将元素从队列中移出。如果在执行该操作时队列已空，那么将会阻塞直到元素出列，返回出列的tensors的tuple tf.QueueBase.dequeue_many(n, name=None) 将一个或多个元素从队列中移出 tf.QueueBase.size(name=None) 计算队列中的元素个数 tf.QueueBase.close(cancel_pending_enqueues=False, name=None) 关闭该队列 f.QueueBase.dequeue_up_to(n, name=None) 从该队列中移出n个元素并将之连接 tf.QueueBase.dtypes 列出组成元素的数据类型 tf.QueueBase.from_list(index, queues) 根据queues[index]的参考队列创建一个队列 tf.QueueBase.name 返回最队列下面元素的名称 tf.QueueBase.names 返回队列每一个组成部分的名称 class tf.FIFOQueue 在出列时依照先入先出顺序，其他方法与tf.QueueBase雷同 class tf.PaddingFIFOQueue 一个FIFOQueue ，同时根据padding支持batching变长的tensor class tf.RandomShuffleQueue 该队列将随机元素出列，其他方法与tf.QueueBase雷同 文件系统的处理(Dealing with the filesystem) 操作 描述 tf.matching_files(pattern, name=None) 返回与pattern匹配模式的文件名称 tf.read_file(filename, name=None) 读取并输出输入文件的整个内容 输入管道(Input pipeline)用于设置输入预取数的管道TF函数，函数 “producer”添加一个队列至图中，同时一个相应用于运行队列中子图(subgraph)的QueueRunner 操作 描述 tf.train.match_filenames_once(pattern, name=None) 保存与pattern的文件列表 tf.train.limit_epochs(tensor, num_epochs=None, name=None) 返回一个num_epochs次数，然后报告OutOfRange错误 tf.train.input_producer(input_tensor, element_shape=None, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, summary_name=None, name=None) 为一个输入管道输出input_tensor中的多行至一个队列中 tf.train.range_input_producer(limit, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None) 产生一个从1至limit-1的整数至队列中 tf.train.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None) 对tensor_list中的每一个tensor切片 tf.train.string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None) 为一个输入管道输出一组字符串(比如文件名)至队列中 在输入管道末端批量打包(Batching at the end of an input pipeline)该相关函数增添一个队列至图中以将数据一样本打包为batch。它们也会添加 一个QueueRunner，以便执行的已经被填满队列的子图 操作 描述 tf.train.batch(tensors, batch_size, num_threads=1, capacity=32, enqueue_many=False, shapes=None, dynamic_pad=False, allow_smaller_final_batch=False, shared_name=None, name=None) 在输入的tensors中创建一些tensor数据格式的batch，若输入为shape[, x, y, z]，那么输出则为[batch_size, x, y, z]返回一个列表或者一个具有与输入tensors相同类型tensors的字典 tf.train.batch_join(tensors_list, batch_size, capacity=32, enqueue_many=False, shapes=None, dynamic_pad=False, allow_smaller_final_batch=False, shared_name=None, name=None) 将一个tensors的列表添加至一个队列中以创建样本的batcheslen(tensors_list)个线程将启动，线程i将tensors_list[i]的tensors入列tensors_list[i1][j]与tensors_list[i2][j]有相同的类型和shape tf.train.shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, allow_smaller_final_batch=False, shared_name=None, name=None) 使用随机乱序的方法创建batchestensors:用于入列的一个list或者dictcapacity:一个整数，表示队列中元素最大数目 tf.train.shuffle_batch_join(tensors_list, batch_size, capacity, min_after_dequeue, seed=None, enqueue_many=False, shapes=None, allow_smaller_final_batch=False, shared_name=None, name=None) 随机乱序的tensors创建batches，其中tensors_list参数为tensors元组或tensors字典的列表len(tensors_list)个线程将启动，线程i将tensors_list[i]的tensors入列tensors_list[i1][j]与tensors_list[i2][j]有相同的类型和shape# 一个简单例子，使用tf.train.shuffle_batch创建一个具有32张图像和32个标签的batches.image_batch, label_batch = tf.train.shuffle_batch( [single_image, single_label], batch_size=32, num_threads=4, capacity=50000, min_after_dequeue=10000)#Batching函数相关例子，以函数tf.train.shuffle_batch为例#为training, evaluation等操作将样本batching，以下代码使用随机顺序打包样本def read_my_file_format(filename_queue): reader = tf.SomeReader() key, record_string = reader.read(filename_queue) example, label = tf.some_decoder(record_string) processed_example = some_processing(example) return processed_example, labeldef input_pipeline(filenames, batch_size, num_epochs=None): filename_queue = tf.train.string_input_producer( filenames, num_epochs=num_epochs, shuffle=True) example, label = read_my_file_format(filename_queue) # min_after_dequeue defines how big a buffer we will randomly sample # from – bigger means better shuffling but slower start up and more # memory used. # capacity must be larger than min_after_dequeue and the amount larger # determines the maximum we will prefetch. Recommendation: # min_after_dequeue + (num_threads + a small safety margin) batch_size min_after_dequeue = 10000 capacity = min_after_dequeue + 3 batch_size example_batch, label_batch = tf.train.shuffle_batch( [example, label], batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue) return example_batch, label_batch#如果需要跟多的并行或文件之间的样本乱序操作，可以使用函数tf.train.shuffle_batch_join多实例化readerdef read_my_file_format(filename_queue): # 与上例子相同def input_pipeline(filenames, batch_size, read_threads, num_epochs=None): filename_queue = tf.train.string_input_producer( filenames, num_epochs=num_epochs, shuffle=True) example_list = [read_my_file_format(filenamequeue) for in range(read_threads)] min_after_dequeue = 10000 capacity = min_after_dequeue + 3 * batch_size example_batch, label_batch = tf.train.shuffle_batch_join( example_list, batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue) return example_batch, label_batch相关链接：[1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 [7] Tensorflow一些常用基本概念与函数（1） http://blog.csdn.net/lenbow/article/details/52152766 摘要：本系列主要对tf的一些常用概念与方法进行描述。本文主要针对tensorflow的数据IO、图的运行等相关函数进行讲解。为‘Tensorflow一些常用基本概念与函数’系列之三。1、序言本文所讲的内容主要为以下相关函数： 操作组 操作 Data IO (Python functions) TFRecordWrite，rtf_record_iterator Running Graphs Session management，Error classes2、tf函数2.1 数据IO {Data IO (Python functions)}一个TFRecords 文件为一个字符串序列。这种格式并非随机获取，它比较适合大规模的数据流，而不太适合需要快速分区或其他非序列获取方式。数据IO {Data IO (Python functions)} 操作 描述 class tf.python_io.TFRecordWriter 一个用于将记录(records)写入TFRecords文件的类 tf.python_io.TFRecordWriter.init(path, options=None) 打开文件路径，并创建一个TFRecordWriter以供写入 tf.python_io.TFRecordWriter.write(record) 将一个字符串records写入文件中 tf.python_io.TFRecordWriter.close() 关闭文件 tf.python_io.tf_record_iterator(path, options=None) 从TFRecords文件中读取记录的迭代器2.2 运行图(Running Graphs)会话管理 (Session management) 操作 描述 class tf.Session 运行TF操作的类,一个Session对象将操作节点op封装在一定的环境内运行，同时tensor对象将被计算求值 tf.Session.init(target=”, graph=None, config=None) 创建一个新的会话 tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None) 运行fetches中的操作节点并求其值 tf.Session.close() 关闭会话 tf.Session.graph 返回加载值该会话的图(graph) tf.Session.as_default() 设置该对象为默认会话，并返回一个上下文管理器 tf.Session.reset(target, containers=None, config=None) 重设target的资源容器，并关闭所有连接的会话在0.10版本该功能仅应用在分布会话中target:为执行引擎所连接的目标，其包含有资源容器，该资源容器分布在同一个集群的所有works上 class tf.InteractiveSession 使用在交互式上下文环境的tf会话，比如shell，ipython tf.InteractiveSession.close() 关闭一个InteractiveSession tf.get_default_session() 返回当前线程的默认会话tf.Session#一个简单的tf.Session例子# 建立一个graph.a = tf.constant(5.0)b = tf.constant(6.0)c = a b# 将graph载入到一个会话session中sess = tf.Session()# 计算tensor c.print(sess.run(c))#一个会话可能会占用一些资源，比如变量、队列和读取器(reader)。释放这些不再使用的资源非常重要。#使用close()方法关闭会话，或者使用上下文管理器，释放资源。# 使用close()方法.sess = tf.Session()sess.run(…)sess.close()# 使用上下文管理器with tf.Session() as sess: sess.run(…)tf.Session()的变量设置， ConfigProto protocol buffer为会话提供了不同的配置选项。比如，创建一个会话，对设备布局使用软约束条件，以及对分布# Launch the graph in a session that allows soft device placement and# logs the placement decisions.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))tf.Session.run a = tf.constant([10, 20]) b = tf.constant([1.0, 2.0]) # ‘fetches’ 可以为单个数 v = session.run(a) # v is the numpy array [10, 20] # ‘fetches’ 可以为一个list. v = session.run([a, b]) # v a Python list with 2 numpy arrays: the numpy array [10, 20] and the # 1-D array [1.0, 2.0] # ‘fetches’ 可以是 lists, tuples, namedtuple, dicts中的任意: MyData = collections.namedtuple(‘MyData’, [‘a’, ‘b’]) v = session.run({‘k1’: MyData(a, b), ‘k2’: [b, a]}) # v 为一个dict，并有 # v[‘k1’] is a MyData namedtuple with ‘a’ the numpy array [10, 20] and # ‘b’ the numpy array [1.0, 2.0] # v[‘k2’] is a list with the numpy array [1.0, 2.0] and the numpy array # [10, 20].tf.Session.as_default() 使用关键字with指定会话， 可以在会话中执行Operation.run()或Tensor.eval()，以得到运行的tensor结果c = tf.constant(..)sess = tf.Session()with sess.as_default(): assert tf.get_default_session() is sess print(c.eval())使用函数tf.get_default_session()来得到当前默认的会话 需要注意的是，退出该as_default上下文管理器时，并没有关闭该会话(session )，必须明确的关闭会话c = tf.constant(…)sess = tf.Session()with sess.as_default(): print(c.eval())# …with sess.as_default(): print(c.eval())#关闭会话sess.close()#使用 with tf.Session()方式可以创建并自动关闭会话tf.InteractiveSessionsess = tf.InteractiveSession()a = tf.constant(5.0)b = tf.constant(6.0)c = a b# 我们直接使用’c.eval()’ 而没有通过’sess’print(c.eval())sess.close()以上的例子，在非交互会话的版本中为，a = tf.constant(5.0)b = tf.constant(6.0)c = a * bwith tf.Session(): # We can also use ‘c.eval()’ here. print(c.eval())ABC错误类 (Error classes) 操作 描述 class tf.OpError 一个基本的错误类型，在当TF执行失败时候报错 tf.OpError.op 返回执行失败的操作节点，有的操作如Send或Recv可能不会返回，那就要用用到node_def方法 tf.OpError.node_def 以NodeDef proto形式表示失败的op tf.OpError.error_code 描述该错误的整数错误代码 tf.OpError.message 返回错误信息 class tf.errors.CancelledError 当操作或者阶段呗取消时候报错 class tf.errors.UnknownError 未知错误类型 class tf.errors.InvalidArgumentError 在接收到非法参数时候报错 class tf.errors.NotFoundError 当发现不存在所请求的一个实体时候，比如文件或目录 class tf.errors.AlreadyExistsError 当创建的实体已经存在的时候报错 class tf.errors.PermissionDeniedError 没有执行权限做某操作的时候报错 class tf.errors.ResourceExhaustedError 资源耗尽时报错 class tf.errors.FailedPreconditionError 系统没有条件执行某个行为时候报错 class tf.errors.AbortedError 操作中止时报错，常常发生在并发情形 class tf.errors.OutOfRangeError 超出范围报错 class tf.errors.UnimplementedError 某个操作没有执行时报错 class tf.errors.InternalError 当系统经历了一个内部错误时报出 class tf.errors.DataLossError 当出现不可恢复的错误例如在运行 tf.WholeFileReader.read()读取整个文件的同时文件被删减 tf.errors.XXXXX.init(node_def, op, message) 使用该形式方法创建以上各种错误类相关链接：[1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 [7] Tensorflow一些常用基本概念与函数（1） http://blog.csdn.net/lenbow/article/details/52152766 [8] Tensorflow一些常用基本概念与函数（2） http://blog.csdn.net/lenbow/article/details/52181159 摘要：本系列主要对tf的一些常用概念与方法进行描述。本文主要针对tensorflow的模型训练Training与测试Testing等相关函数进行讲解。为‘Tensorflow一些常用基本概念与函数’系列之四。1、序言本文所讲的内容主要为以下列表中相关函数。函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作，在训练过程中，先实例化一个优化函数，比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：optimizer = tf.train.GradientDescentOptimizer(learning_rate)然后，可以设置 一个用于记录全局训练步骤的单值。以及使用minimize()操作，该操作不仅可以优化更新训练的模型参数，也可以为全局步骤(global step)计数。与其他tensorflow操作类似，这些训练操作都需要在tf.session会话中进行global_step = tf.Variable(0, name=’global_step’, trainable=False)train_op = optimizer.minimize(loss, global_step=global_step) 操作组 操作 Training Optimizers，Gradient Computation，Gradient Clipping，Distributed execution Testing Unit tests，Utilities，Gradient checking2、Tensorflow函数2.1 训练 (Training)一个TFRecords 文件为一个字符串序列。这种格式并非随机获取，它比较适合大规模的数据流，而不太适合需要快速分区或其他非序列获取方式。█ 优化 (Optimizers)tf中各种优化类提供了为损失函数计算梯度的方法，其中包含比较经典的优化算法，比如GradientDescent 和Adagrad。▶▶class tf.train.Optimizer 操作 描述 class tf.train.Optimizer 基本的优化类，该类不常常被直接调用，而较多使用其子类，比如GradientDescentOptimizer, AdagradOptimizer或者MomentumOptimizer tf.train.Optimizer.init(use_locking, name) 创建一个新的优化器，该优化器必须被其子类(subclasses)的构造函数调用 tf.train.Optimizer.minimize(loss, global_step=None, var_list=None, gate_gradients=1, aggregation_method=None, colocate_gradients_with_ops=False, name=None, grad_loss=None) 添加操作节点，用于最小化loss，并更新var_list该函数是简单的合并了compute_gradients()与apply_gradients()函数返回为一个优化更新后的var_list，如果global_step非None，该操作还会为global_step做自增操作 tf.train.Optimizer.compute_gradients(loss,var_list=None, gate_gradients=1, aggregation_method=None, colocate_gradients_with_ops=False, grad_loss=None) 对var_list中的变量计算loss的梯度该函数为函数minimize()的第一部分，返回一个以元组(gradient, variable)组成的列表 tf.train.Optimizer.apply_gradients(grads_and_vars, global_step=None, name=None) 将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global_step做自增操作 tf.train.Optimizer.get_name() 获取名称▷ class tf.train.Optimizer 用法# Create an optimizer with the desired parameters.opt = GradientDescentOptimizer(learning_rate=0.1)# Add Ops to the graph to minimize a cost by updating a list of variables.# “cost” is a Tensor, and the list of variables contains tf.Variable objects.opt_op = opt.minimize(cost, var_list=&lt;list of variables&gt;)# Execute opt_op to do one step of training:opt_op.run()▶▶在使用它们之前处理梯度 使用minimize()操作，该操作不仅可以计算出梯度，而且还可以将梯度作用在变量上。如果想在使用它们之前处理梯度，可以按照以下三步骤使用optimizer ：1、使用函数compute_gradients()计算梯度2、按照自己的愿望处理梯度3、使用函数apply_gradients()应用处理过后的梯度例如：# 创建一个optimizer.opt = GradientDescentOptimizer(learning_rate=0.1)# 计算&lt;list of variables&gt;相关的梯度grads_and_vars = opt.compute_gradients(loss, &lt;list of variables&gt;)# grads_and_vars为tuples (gradient, variable)组成的列表。#对梯度进行想要的处理，比如cap处理capped_grads_and_vars = [(MyCapper(gv[0]), gv[1]) for gv in grads_and_vars]# 令optimizer运用capped的梯度(gradients)opt.apply_gradients(capped_grads_and_vars)▶▶选通梯度(Gating Gradients) 函数minimize() 与compute_gradients()都含有一个参数gate_gradient，用于控制在应用这些梯度时并行化的程度。其值可以取：GATE_NONE, GATE_OP 或 GATE_GRAPH GATE_NONE : 并行地计算和应用梯度。提供最大化的并行执行，但是会导致有的数据结果没有再现性。比如两个matmul操作的梯度依赖输入值，使用GATE_NONE可能会出现有一个梯度在其他梯度之前便应用到某个输入中，导致出现不可再现的(non-reproducible)结果 GATE_OP: 对于每个操作Op，确保每一个梯度在使用之前都已经计算完成。这种做法防止了那些具有多个输入，并且梯度计算依赖输入情形中，多输入Ops之间的竞争情况出现。 GATE_GRAPH: 确保所有的变量对应的所有梯度在他们任何一个被使用前计算完成。该方式具有最低级别的并行化程度，但是对于想要在应用它们任何一个之前处理完所有的梯度计算时很有帮助的。█ Slots一些optimizer的之类，比如 MomentumOptimizer 和 AdagradOptimizer 分配和管理着额外的用于训练的变量。这些变量称之为’Slots’，Slots有相应的名称，可以向optimizer访问的slots名称。有助于在log debug一个训练算法以及报告slots状态 操作 描述 tf.train.Optimizer.get_slot_names() 返回一个由Optimizer所创建的slots的名称列表 tf.train.Optimizer.get_slot(var, name) 返回一个name所对应的slot，name是由Optimizer为var所创建var为用于传入 minimize() 或 apply_gradients()的变量 class tf.train.GradientDescentOptimizer 使用梯度下降算法的Optimizer tf.train.GradientDescentOptimizer.init(learning_rate, use_locking=False, name=’GradientDescent’) 构建一个新的梯度下降优化器(Optimizer) class tf.train.AdadeltaOptimizer 使用Adadelta算法的Optimizer tf.train.AdadeltaOptimizer.init(learning_rate=0.001, rho=0.95, epsilon=1e-08, use_locking=False, name=’Adadelta’) 创建Adadelta优化器 class tf.train.AdagradOptimizer 使用Adagrad算法的Optimizer tf.train.AdagradOptimizer.init(learning_rate, initial_accumulator_value=0.1, use_locking=False, name=’Adagrad’) 创建Adagrad优化器 class tf.train.MomentumOptimizer 使用Momentum算法的Optimizer tf.train.MomentumOptimizer.init(learning_rate, momentum, use_locking=False, name=’Momentum’, use_nesterov=False) 创建momentum优化器momentum：动量，一个tensor或者浮点值 class tf.train.AdamOptimizer 使用Adam 算法的Optimizer tf.train.AdamOptimizer.init(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name=’Adam’) 创建Adam优化器 class tf.train.FtrlOptimizer 使用FTRL 算法的Optimizer tf.train.FtrlOptimizer.init(learning_rate, learning_rate_power=-0.5, initial_accumulator_value=0.1, l1_regularization_strength=0.0, l2_regularization_strength=0.0, use_locking=False, name=’Ftrl’) 创建FTRL算法优化器 class tf.train.RMSPropOptimizer 使用RMSProp算法的Optimizer tf.train.RMSPropOptimizer.init(learning_rate, decay=0.9, momentum=0.0, epsilon=1e-10, use_locking=False, name=’RMSProp’) 创建RMSProp算法优化器▷ tf.train.AdamOptimizer Adam 的基本运行方式，首先初始化：m_0 &lt;- 0 (Initialize initial 1st moment vector)v_0 &lt;- 0 (Initialize initial 2nd moment vector)t &lt;- 0 (Initialize timestep)在论文中的 section2 的末尾所描述了更新规则，该规则使用梯度g来更新变量：t &lt;- t + 1lr_t &lt;- learning_rate sqrt(1 - beta2^t) / (1 - beta1^t)m_t &lt;- beta1 m_{t-1} + (1 - beta1) gv_t &lt;- beta2 v_{t-1} + (1 - beta2) g gvariable &lt;- variable - lr_t m_t / (sqrt(v_t) + epsilon)其中epsilon 的默认值1e-8可能对于大多数情况都不是一个合适的值。例如，当在ImageNet上训练一个 Inception network时比较好的选择为1.0或者0.1。 需要注意的是，在稠密数据中即便g为0时， m_t, v_t 以及variable都将会更新。而在稀疏数据中，m_t, v_t 以及variable不被更新且值为零。█ 梯度计算与截断(Gradient Computation and Clipping)TensorFlow 提供了计算给定tf计算图的求导函数，并在图的基础上增加节点。优化器(optimizer )类可以自动的计算网络图的导数，但是优化器中的创建器(creators )或者专业的人员可以通过本节所述的函数调用更底层的方法。 操作 描述 tf.gradients(ys, xs, grad_ys=None, name=’gradients’, colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None) 构建一个符号函数，计算ys关于xs中x的偏导的和，返回xs中每个x对应的sum(dy/dx) tf.stop_gradient(input, name=None) 停止计算梯度，在EM算法、Boltzmann机等可能会使用到 tf.clip_by_value(t, clip_value_min, clip_value_max, name=None) 基于定义的min与max对tesor数据进行截断操作，目的是为了应对梯度爆发或者梯度消失的情况 tf.clip_by_norm(t, clip_norm, axes=None, name=None) 使用L2范式标准化tensor最大值为clip_norm返回 t clip_norm / l2norm(t) tf.clip_by_average_norm(t, clip_norm, name=None) 使用平均L2范式规范tensor数据t，并以clip_norm为最大值返回 t clip_norm / l2norm_avg(t) tf.clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None) 返回t_list[i] clip_norm / max(global_norm, clip_norm)其中global_norm = sqrt(sum([l2norm(t)2 for t in t_list])) tf.global_norm(t_list, name=None) 返回global_norm = sqrt(sum([l2norm(t)2 for t in t_list]))█ 退化学习率(Decaying the learning rate) 操作 描述 tf.train.exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None) 对学习率进行指数衰退▷ tf.train.exponential_decay#该函数返回以下结果decayed_learning_rate = learning_rate decay_rate ^ (global_step / decay_steps)##例： 以0.96为基数，每100000 步进行一次学习率的衰退global_step = tf.Variable(0, trainable=False)starter_learning_rate = 0.1learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 100000, 0.96, staircase=True)# Passing global_step to minimize() will increment it at each step.learning_step = ( tf.train.GradientDescentOptimizer(learning_rate) .minimize(…my loss…, global_step=global_step))█ 移动平均(Moving Averages)一些训练优化算法，比如GradientDescent 和Momentum 在优化过程中便可以使用到移动平均方法。使用移动平均常常可以较明显地改善结果。 操作 描述 class tf.train.ExponentialMovingAverage 将指数衰退加入到移动平均中 tf.train.ExponentialMovingAverage.apply(var_list=None) 对var_list变量保持移动平均 tf.train.ExponentialMovingAverage.average_name(var) 返回var均值的变量名称 tf.train.ExponentialMovingAverage.average(var) 返回var均值变量 tf.train.ExponentialMovingAverage.variables_to_restore(moving_avg_variables=None) 返回用于保存的变量名称的映射▷ tf.train.ExponentialMovingAverage# Example usage when creating a training model:# Create variables.var0 = tf.Variable(…)var1 = tf.Variable(…)# … use the variables to build a training model……# Create an op that applies the optimizer. This is what we usually# would use as a training op.opt_op = opt.minimize(my_loss, [var0, var1])# Create an ExponentialMovingAverage objectema = tf.train.ExponentialMovingAverage(decay=0.9999)# Create the shadow variables, and add ops to maintain moving averages# of var0 and var1.maintain_averages_op = ema.apply([var0, var1])# Create an op that will update the moving averages after each training# step. This is what we will use in place of the usual training op.with tf.control_dependencies([opt_op]): training_op = tf.group(maintain_averages_op)…train the model by running training_op…#Example of restoring the shadow variable values:# Create a Saver that loads variables from their saved shadow values.shadow_var0_name = ema.average_name(var0)shadow_var1_name = ema.average_name(var1)saver = tf.train.Saver({shadow_var0_name: var0, shadow_var1_name: var1})saver.restore(…checkpoint filename…)# var0 and var1 now hold the moving average values▷ tf.train.ExponentialMovingAverage.variables_to_restore variables_to_restore = ema.variables_to_restore() saver = tf.train.Saver(variables_to_restore)█ 协调器和队列运行器(Coordinator and QueueRunner)查看queue中，queue相关的内容，了解tensorflow中队列的运行方式。 操作 描述 class tf.train.Coordinator 线程的协调器 tf.train.Coordinator.clear_stop() 清除停止标记 tf.train.Coordinator.join(threads=None, stop_grace_period_secs=120) 等待线程终止threads:一个threading.Threads的列表，启动的线程，将额外加入到registered的线程中 tf.train.Coordinator.register_thread(thread) Register一个用于join的线程 tf.train.Coordinator.request_stop(ex=None) 请求线程结束 tf.train.Coordinator.should_stop() 检查是否被请求停止 tf.train.Coordinator.stop_on_exception() 上下文管理器，当一个例外出现时请求停止 tf.train.Coordinator.wait_for_stop(timeout=None) 等待Coordinator提示停止进程 class tf.train.QueueRunner 持有一个队列的入列操作列表，用于线程中运行queue:一个队列enqueue_ops: 用于线程中运行的入列操作列表 tf.train.QueueRunner.create_threads(sess, coord=None, daemon=False, start=False) 创建运行入列操作的线程，返回一个线程列表 tf.train.QueueRunner.from_proto(queue_runner_def) 返回由queue_runner_def创建的QueueRunner对象 tf.train.add_queue_runner(qr, collection=’queue_runners’) 增加一个QueueRunner到graph的收集器(collection )中 tf.train.start_queue_runners(sess=None, coord=None, daemon=True, start=True, collection=’queue_runners’) 启动所有graph收集到的队列运行器(queue runners)▷ class tf.train.Coordinator#Coordinator的使用，用于多线程的协调try: … coord = Coordinator() # Start a number of threads, passing the coordinator to each of them. …start thread 1...(coord, …) …start thread N…(coord, …) # Wait for all the threads to terminate, give them 10s grace period coord.join(threads, stop_grace_period_secs=10)except RuntimeException: …one of the threads took more than 10s to stop after request_stop() …was called.except Exception: …exception that was passed to coord.request_stop()▷ tf.train.Coordinator.stop_on_exception()with coord.stop_on_exception(): # Any exception raised in the body of the with # clause is reported to the coordinator before terminating # the execution of the body. …body…#等价于try: …body…exception Exception as ex: coord.request_stop(ex)█ 布执行(Distributed execution)可以阅读TensorFlow的分布式学习框架简介 查看更多tensorflow分布式细节。 操作 描述 class tf.train.Server 一个进程内的tensorflow服务，用于分布式训练 tf.train.Server.init(server_or_cluster_def, job_name=None, task_index=None, protocol=None, config=None, start=True) 创建一个新的服务，其中job_name, task_index, 和protocol为可选参数，优先级高于server_or_cluster_def中相关信息server_or_cluster_def : 为一个tf.train.ServerDef 或 tf.train.ClusterDef 协议(protocol)的buffer，或者一个tf.train.ClusterSpec对象 tf.train.Server.create_local_server(config=None, start=True) 创建一个新的运行在本地主机的单进程集群 tf.train.Server.target 返回tf.Session所连接的目标服务器 tf.train.Server.server_def 返回该服务的tf.train.ServerDef tf.train.Server.start() 开启服务 tf.train.Server.join() 阻塞直到服务已经关闭 # class tf.train.Supervisor 一个训练辅助器，用于checkpoints模型以及计算的summaries。该监视器只是一个小的外壳(wrapper),用于Coordinator, a Saver, 和a SessionManager周围 tf.train.Supervisor.init(graph=None, ready_op=0, is_chief=True, init_op=0, init_feed_dict=None, local_init_op=0, logdir=None, summary_op=0, saver=0, global_step=0, save_summaries_secs=120, save_model_secs=600, recovery_wait_secs=30, stop_grace_secs=120, checkpoint_basename=’model.ckpt’, session_manager=None, summary_writer=0, init_fn=None) 创建一个监视器Supervisor tf.train.Supervisor.managed_session(master=”, config=None, start_standard_services=True, close_summary_writer=True) 返回一个管路session的上下文管理器 tf.train.Supervisor.prepare_or_wait_for_session(master=”, config=None, wait_for_checkpoint=False, max_wait_secs=7200, start_standard_services=True) 确保model已经准备好 tf.train.Supervisor.start_standard_services(sess) 为sess启动一个标准的服务 tf.train.Supervisor.start_queue_runners(sess, queue_runners=None) 为QueueRunners启动一个线程，queue_runners为一个QueueRunners列表 tf.train.Supervisor.summary_computed(sess, summary, global_step=None) 指示计算的summary tf.train.Supervisor.stop(threads=None, close_summary_writer=True) 停止服务以及协调器(coordinator),并没有关闭session tf.train.Supervisor.request_stop(ex=None) 参考Coordinator.request_stop() tf.train.Supervisor.should_stop() 参考Coordinator.should_stop() tf.train.Supervisor.stop_on_exception() 参考 Coordinator.stop_on_exception() tf.train.Supervisor.Loop(timer_interval_secs, target, args=None, kwargs=None) 开启一个循环器线程用于调用一个函数每经过timer_interval_secs秒执行，target(args, *kwargs) tf.train.Supervisor.coord 返回监督器(Supervisor)使用的协调器(Coordinator ) # class tf.train.SessionManager 训练的辅助器，用于从checkpoint恢复数据以及创建一个session tf.train.SessionManager.init(local_init_op=None, ready_op=None, graph=None, recovery_wait_secs=30) 创建一个SessionManager tf.train.SessionManager.prepare_session(master, init_op=None, saver=None, checkpoint_dir=None, wait_for_checkpoint=False, max_wait_secs=7200, config=None, init_feed_dict=None, init_fn=None) 创建一个session，并确保model可以被使用 tf.train.SessionManager.recover_session(master, saver=None, checkpoint_dir=None, wait_for_checkpoint=False, max_wait_secs=7200, config=None) 创建一个session，如果可以的话，使用恢复方法创建 tf.train.SessionManager.wait_for_session(master, config=None, max_wait_secs=inf) 创建一个session，并等待model准备完成 # class tf.train.ClusterSpec 将一个集群表示为一系列“tasks”，并整合至“jobs”中 tf.train.ClusterSpec.as_cluster_def() 返回该cluster中一个tf.train.ClusterDef协议的buffer tf.train.ClusterSpec.as_dict() 返回一个字典，由job名称对应于网络地址 tf.train.ClusterSpec.job_tasks(job_name) 返回一个给定的job对应的task列表 tf.train.ClusterSpec.jobs 返回该cluster的job名称列表 tf.train.replica_device_setter(ps_tasks=0, ps_device=’/job:ps’, worker_device=’/job:worker’, merge_devices=True, cluster=None, ps_ops=None) 返回一个设备函数(device function)，以在建立一个副本graph的时候使用，设备函数(device function)用在with tf.device(device_function)中▷ tf.train.Serverserver = tf.train.Server(…)with tf.Session(server.target): # …▷ tf.train.Supervisor 相关参数： ready_op : 一维 字符串 tensor。该tensor是用过监视器在prepare_or_wait_for_session()计算，检查model是否准备好可以使用。如果准备好，将返回一个空阵列，如果为None，该model没有被检查。 is_chief : 如果为True，创建一个主监视器用于负责初始化与模型的恢复，若为False，则依赖主监视器。 init_op : 一个操作，用于模型不能恢复时的初始化操作。默认初始化所有操作 local_init_op : 可被所有监视器运行的初始化操作。 logdir : 设置log目录 summary_op : 一个操作(Operation )，返回Summary 和事件logs，需要设置 logdir saver : 一个Saver对象 save_summaries_secs : 保存summaries的间隔秒数 save_model_secs : 保存model的间隔秒数 checkpoint_basename : checkpoint保存的基本名称使用在单进程中with tf.Graph().as_default(): …add operations to the graph… # Create a Supervisor that will checkpoint the model in ‘/tmp/mydir’. sv = Supervisor(logdir=‘/tmp/mydir’) # Get a TensorFlow session managed by the supervisor. with sv.managed_session(FLAGS.master) as sess: # Use the session to train the graph. while not sv.should_stop(): sess.run(&lt;my_train_op&gt;)# 在上下文管理器with sv.managed_session()内，所有在graph的变量都被初始化。# 或者说，一些服务器checkpoint相应模型并增加summaries至事件log中。# 如果有例外发生，should_stop()将返回True使用在多副本运行情况中 要使用副本训练已经部署在集群上的相同程序，必须指定其中一个task为主要，该task处理 initialization, checkpoints, summaries, 和recovery相关事物。其他task依赖该task。# Choose a task as the chief. This could be based on server_def.task_index,# or job_def.name, or job_def.tasks. It’s entirely up to the end user.# But there can be only one chief*.is_chief = (server_def.task_index == 0)server = tf.train.Server(server_def)with tf.Graph().as_default(): …add operations to the graph… # Create a Supervisor that uses log directory on a shared file system. # Indicate if you are the ‘chief’ sv = Supervisor(logdir=‘/shared_directory/…’, is_chief=is_chief) # Get a Session in a TensorFlow server on the cluster. with sv.managed_session(server.target) as sess: # Use the session to train the graph. while not sv.should_stop(): sess.run(&lt;my_train_op&gt;)如果有task崩溃或重启，managed_session() 将检查是否Model被初始化。如果已经初始化，它只需要创建一个session并将其返回至正在训练的正常代码中。如果model需要被初始化，主task将对它进行重新初始化，而其他task将等待模型初始化完成。 注意：该程序方法一样适用于单进程的work，该单进程标注自己为主要的便行▷ supervisor中master的字符串形式 无论运行在本机或者集群上，都可以使用以下值设定master flag：定义为 ” ，要求一个进程内且没有使用RPC的session定义为 ‘local’，要求一个使用基于RPC的主服务接口(“Master interface” )的session来运行tensorflow程序。更多细节可以查看 tf.train.Server.create_local_server()相关内容。定义为 ‘grpc://hostname:port’，要求一个指定的RPC接口的session，同时运行内部进程的master接入远程的tensorflow workers。可用server.target返回该形式▷ supervisor高级用法启动额外的服务 managed_session()启动了 Checkpoint 和Summary服务。如果需要运行更多的服务，可以在managed_session()控制的模块中启动他们。#例如： 开启一个线程用于打印loss. 设置每60秒该线程运行一次，我们使用sv.loop() … sv = Supervisor(logdir=‘/tmp/mydir’) with sv.managed_session(FLAGS.master) as sess: sv.loop(60, print_loss, (sess)) while not sv.should_stop(): sess.run(my_train_op)启动更少的的服务 managed_session() 启动了 “summary” 和 “checkpoint” 线程，这些线程通过构建器或者监督器默认自动创建了summary_op 和saver操作。如果想运行自己的 summary 和checkpointing方法，关闭这些服务，通过传递None值给summary_op 和saver参数。在chief中每100个step，创建summaries # Create a Supervisor with no automatic summaries. sv = Supervisor(logdir=‘/tmp/mydir’, is_chief=is_chief, summary_op=None) # As summary_op was None, managed_session() does not start the # summary thread. with sv.managed_session(FLAGS.master) as sess: for step in xrange(1000000): if sv.should_stop(): break if is_chief and step % 100 == 0: # Create the summary every 100 chief steps. sv.summary_computed(sess, sess.run(my_summary_op)) else: # Train normally sess.run(my_train_op)▷ tf.train.Supervisor.managed_sessiondef train(): sv = tf.train.Supervisor(…) with sv.managed_session(&lt;master&gt;) as sess: for step in xrange(..): if sv.should_stop(): break sess.run(&lt;my training op&gt;) …do other things needed at each training step…▷ tf.train.SessionManagerwith tf.Graph().as_default(): …add operations to the graph… # Create a SessionManager that will checkpoint the model in ‘/tmp/mydir’. sm = SessionManager() sess = sm.prepare_session(master, init_op, saver, checkpoint_dir) # Use the session to train the graph. while True: sess.run(&lt;my_train_op&gt;)#其中prepare_session()初始化和恢复一个模型参数。 #另一个进程将等待model准备完成，代码如下with tf.Graph().as_default(): …add operations to the graph… # Create a SessionManager that will wait for the model to become ready. sm = SessionManager() sess = sm.wait_for_session(master) # Use the session to train the graph. while True: sess.run(&lt;my_train_op&gt;)#wait_for_session()等待一个model被其他进程初始化▷ tf.train.ClusterSpec 一个tf.train.ClusterSpec表示一系列的进程，这些进程都参与分布式tensorflow的计算。每一个 tf.train.Server都在一个独有的集群中构建。 创建一个具有两个jobs及其5个tasks的集群们需要定义从job名称列表到网络地址列表之间的映射。cluster = tf.train.ClusterSpec({“worker”: [“worker0.example.com:2222”, “worker1.example.com:2222”, “worker2.example.com:2222”], “ps”: [“ps0.example.com:2222”, “ps1.example.com:2222”]})▷ tf.train.replica_device_setter# To build a cluster with two ps jobs on hosts ps0 and ps1, and 3 worker# jobs on hosts worker0, worker1 and worker2.cluster_spec = { “ps”: [“ps0:2222”, “ps1:2222”], “worker”: [“worker0:2222”, “worker1:2222”, “worker2:2222”]}with tf.device(tf.replica_device_setter(cluster=cluster_spec)): # Build your graph v1 = tf.Variable(…) # assigned to /job:ps/task:0 v2 = tf.Variable(…) # assigned to /job:ps/task:1 v3 = tf.Variable(…) # assigned to /job:ps/task:0# Run compute█ 汇总操作(Summary Operations)我们可以在一个session中获取summary操作的输出，并将其传输到SummaryWriter以添加至一个事件记录文件中。 操作 描述 tf.scalar_summary(tags, values, collections=None, name=None) 输出一个标量值的summary协议buffertag的shape需要与values的相同，用来做summaries的tags，为字符串 tf.image_summary(tag, tensor, max_images=3, collections=None, name=None) 输出一个图像tensor的summary协议buffer tf.audio_summary(tag, tensor, sample_rate, max_outputs=3, collections=None, name=None) 输出一个音频tensor的summary协议buffer tf.histogram_summary(tag, values, collections=None, name=None) 输出一个直方图的summary协议buffer tf.nn.zero_fraction(value, name=None) 返回0在value中的小数比例 tf.merge_summary(inputs, collections=None, name=None) 合并summary tf.merge_all_summaries(key=’summaries’) 合并在默认graph中手机的summaries▶▶将记录汇总写入文件中(Adding Summaries to Event Files) 操作 描述 class tf.train.SummaryWriter 将summary协议buffer写入事件文件中 tf.train.SummaryWriter.init(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None) 创建一个SummaryWriter实例以及新建一个事件文件 tf.train.SummaryWriter.add_summary(summary, global_step=None) 将一个summary添加到事件文件中 tf.train.SummaryWriter.add_session_log(session_log, global_step=None) 添加SessionLog到一个事件文件中 tf.train.SummaryWriter.add_event(event) 添加一个事件到事件文件中 tf.train.SummaryWriter.add_graph(graph, global_step=None, graph_def=None) 添加一个Graph到时间文件中 tf.train.SummaryWriter.add_run_metadata(run_metadata, tag, global_step=None) 为一个单一的session.run()调用添加一个元数据信息 tf.train.SummaryWriter.flush() 刷新时间文件到硬盘中 tf.train.SummaryWriter.close() 将事件问价写入硬盘中并关闭该文件 tf.train.summary_iterator(path) 一个用于从时间文件中读取时间协议buffer的迭代器▷ tf.train.SummaryWriter 创建一个SummaryWriter 和事件文件。如果我们传递一个Graph进入该构建器中，它将被添加到事件文件当中，这一点与使用add_graph()具有相同功能。 TensorBoard 将从事件文件中提取该graph，并将其显示。所以我们能直观地看到我们建立的graph。我们通常从我们启动的session中传递graph：…create a graph…# Launch the graph in a session.sess = tf.Session()# Create a summary writer, add the ‘graph’ to the event file.writer = tf.train.SummaryWriter(&lt;some-directory&gt;, sess.graph)▷ tf.train.summary_iterator#打印时间文件中的内容for e in tf.train.summary_iterator(path to events file): print(e)#打印指定的summary值# This example supposes that the events file contains summaries with a# summary value tag ‘loss’. These could have been added by calling# add_summary(), passing the output of a scalar summary op created with# with: tf.scalar_summary([&#39;loss&#39;], loss_tensor).for e in tf.train.summary_iterator(path to events file): for v in e.summary.value: if v.tag == ‘loss’: print(v.simple_value)█ 训练的通用函数及其他(Training utilities) 操作 描述 tf.train.global_step(sess, global_step_tensor) 一个用于获取全局step的小辅助器 tf.train.write_graph(graph_def, logdir, name, as_text=True) 将一个graph proto写入一个文件中 # :— class tf.train.LooperThread 可重复地执行代码的线程 tf.train.LooperThread.init(coord, timer_interval_secs, target=None, args=None, kwargs=None) 创建一个LooperThread tf.train.LooperThread.is_alive() 返回是否该线程是活跃的 tf.train.LooperThread.join(timeout=None) 等待线程结束 tf.train.LooperThread.loop(coord, timer_interval_secs, target, args=None, kwargs=None) 启动一个LooperThread，用于周期地调用某个函数调用函数target(args) tf.py_func(func, inp, Tout, stateful=True, name=None) 将python函数包装成tf中操作节点▷ tf.train.global_step# Creates a variable to hold the global_step.global_step_tensor = tf.Variable(10, trainable=False, name=‘global_step’)# Creates a session.sess = tf.Session()# Initializes the variable.sess.run(global_step_tensor.initializer)print(‘global_step: %s’ % tf.train.global_step(sess, global_step_tensor))global_step: 10▷ tf.train.write_graphv = tf.Variable(0, name=‘my_variable’)sess = tf.Session()tf.train.write_graph(sess.graph_def, ‘/tmp/my-model’, ‘train.pbtxt’)▷ tf.py_func#tf.py_func(func, inp, Tout, stateful=True, name=None)#func：为一个python函数#inp：为输入函数的参数，Tensor列表#Tout： 指定func返回的输出的数据类型，是一个列表def my_func(x): # x will be a numpy array with the contents of the placeholder below return np.sinh(x)inp = tf.placeholder(tf.float32, […])y = py_func(my_func, [inp], [tf.float32])2.2 测试 (Testing)TensorFlow 提供了一个方便的继承unittest.TestCase类的方法，该类增加有关TensorFlow 测试的方法。如下例子：import tensorflow as tfclass SquareTest(tf.test.TestCase): def testSquare(self): with self.test_session(): x = tf.square([2, 3]) self.assertAllEqual(x.eval(), [4, 9])if name == ‘main‘: tf.test.main()█ 共用(Utilities) 操作 描述 tf.test.main() 运行所有的单元测试 tf.test.assert_equal_graph_def(actual, expected) 断言 两个GraphDefs 是否几乎一样 tf.test.get_temp_dir() 返回测试期间使用的临时目录 tf.test.is_built_with_cuda() 返回是否Tensorflow支持CUDA(GPU)的build█ 梯度检查(Gradient checking)可对比compute_gradient 和compute_gradient_error函数的用法 操作 描述 tf.test.compute_gradient(x, x_shape, y, y_shape, x_init_value=None, delta=0.001, init_targets=None) 计算并返回理论的和数值的Jacobian矩阵 tf.test.compute_gradient_error(x, x_shape, y, y_shape, x_init_value=None, delta=0.001, init_targets=None) 计算梯度的error。在计算所得的与数值估计的Jacobian中 为dy/dx计算最大的error相关链接：[1] 安装Tensorflow（Linux ubuntu） http://blog.csdn.net/lenbow/article/details/51203526 [2] ubuntu下CUDA编译的GCC降级安装 http://blog.csdn.net/lenbow/article/details/51596706 [3] ubuntu手动安装最新Nvidia显卡驱动 http://blog.csdn.net/lenbow/article/details/51683783 [4] Tensorflow的CUDA升级，以及相关配置 http://blog.csdn.net/lenbow/article/details/52118116 [5] 基于gensim的Doc2Vec简析 http://blog.csdn.net/lenbow/article/details/52120230 [6] TensorFlow的分布式学习框架简介 http://blog.csdn.net/lenbow/article/details/52130565 [7] Tensorflow一些常用基本概念与函数（1） http://blog.csdn.net/lenbow/article/details/52152766 [8] Tensorflow一些常用基本概念与函数（2） http://blog.csdn.net/lenbow/article/details/52181159 [9] Tensorflow一些常用基本概念与函数（3） http://blog.csdn.net/lenbow/article/details/52213105","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"}]},{"title":"这一年来，数据科学家都用了哪些算法玩转人工智能？","date":"2017-02-13T00:40:06.000Z","path":"2017/02/13/Program/TensorFlow/benchmark-of-machine-learning/","text":"新智元mp论文作者：Shaohuai Shi, Qiang Wang, Pengfei Xu, Xiaowen Chu译者：吴博, Elaine, Melody 【新智元导读】新年伊始，新智元向你推荐香港浸会大学计算机学院褚晓文团队最新论文《基准评测当前最先进的深度学习软件工具》，评测了 Caffe、CNTK、MXNet、TensorFlow、Torch 这五个最受欢迎的DL框架在 FCN、CNN、RNN 上的表现。这是伯克利RISE实验室大牛、RISC之父 David Patterson 也在关注的深度学习库评测。论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。【进入新智元公众号，在对话框输入“0128”下载论文】 在2016年推出深度学习工具评测的褚晓文团队，赶在猴年最后一天，在arXiv.org上发布了最新的评测版本。这份评测的初版，通过国内AI自媒体的传播，在国内业界影响很大。在学术界，其反响更是非同一般。褚晓文教授在1月5日的朋友圈说David Patterson发邮件咨询他文章细节，感慨老人家论文看得仔细。 David Patterson在体系结构领域的名声如雷贯耳，RISC之父。不熟悉的吃瓜群众可能留意到1月25日蚂蚁金服宣布跟伯克利大学前身为AmpLab，更名为RISE实验室合作的新闻。David Patterson就是RISE实验室的顶梁大佬之一。 褚晓文教授最新版本的论文对Caffe、CNTK、MXNet、TensorFlow、Torch进行比较评测。在两个CPU平台、三个GPU平台下，比较这五个深度学习库在三类流行深度神经网络(FCN、CNN、RNN)上的性能表现。并对它们在单机多GPU卡环境下分布式版本进行了比较。相比以前的评测，最新的评测添加了对多GPU卡的测试，把MXNet纳入评比范围，还测试了MNIST和Cifar10这两个真实数据集。 《基准评测当前最先进的深度学习软件工具》 ## 1. 简介 在过去十年中，深度学习已成功应用到不同领域，包括计算机视觉、语音识别和自然语言处理等。深度学习的成功，归因于许多层人工神经元对输入数据的高表征能力。而GPU通过显著缩短训练时间，在深度学习的成功中扮演着重要的角色。为了提高开发深度学习方法的效率，有很多开源的深度学习工具包，包括伯克利大学的Caffe，微软的CNTK，谷歌的TensorFlow，还有Torch，MXNet，Theano，百度的 PaddlePaddle等。这些工具都支持多核CPU和超多核GPU。 深度学习的主要任务之一，是学习网络的每一层的权重，这可以通过向量或矩阵运算来实现。TensorFlow使用 Eigen作为矩阵加速库，而 Caffe、CNTK、MXNet和Torch采用OpenBLAS、Intel MKL 或 cuBLAS 来加快相关矩阵运算。所有这些工具包都引入了cuDNN，这是一个为神经网络计算进行GPU加速的深度学习库。但是，由于优化方法的差异，加上不同类型的网络或使用不同类型的硬件，上述工具包的性能差异很大。 鉴于深度学习软件工具及其底层硬件平台的多样化，终端用户难以选择合适的平台来执行深度学习任务。在此论文中，作者用三种最主要的深度神经网络（全连接神经网络FCN，卷积神经网络CNN，以及循环神经网络RNN）来基准评测当下最先进的基于GPU加速的深度学习工具（包括Caffe，CNTK， MXNet， TensorFlow 和Torch），比较它们在CPU和GPU上的运行时间性能。 几个工具的性能评估既针对合成数据，也针对真实数据。评测的硬件平台包括两种CPU（台式机级别的英特尔i7-3820 CPU，服务器级别的英特尔Xeon E5-2630 CPU）和三种Nvidia GPU (GTX 980、GTX 1080、Telsa K80，分别是Maxwell、Pascal和Kepler 架构)。作者也用两个Telsa K80卡（总共4个GK210 GPU）来评估多GPU卡并行的性能。每种神经网络类型均选择了一个小型网络和大型网络。 该评测的主要发现可概括如下： 总体上，多核CPU的性能并无很好的可扩展性。在很多实验结果中，使用16核CPU的性能仅比使用4核或8核稍好。TensorFlow在CPU环境有相对较好的可扩展性。 仅用一块GPU卡的话，FCN上Caffe、CNTK和Torch比MXNet和TensorFlow表现更好；CNN上MXNet表现出色，尤其是在大型网络时；而Caffe和CNTK在小型CNN上同样表现不俗；对于带LSTM的RNN，CNTK速度最快，比其他工具好上5到10倍。 通过将训练数据并行化，这些支持多GPU卡的深度学习工具，都有可观的吞吐量提升，同时收敛速度也提高了。多GPU卡环境下，CNTK平台在FCN和AlexNet上的可扩展性更好，而MXNet和Torch在CNN上相当出色。 比起多核CPU，GPU平台效率更高。所有的工具都能通过使用GPU达到显著的加速。 在三个GPU平台中，GTX1080由于其计算能力最高，在大多数实验结果中性能最出色。 某种程度上而言，性能也受配置文件的影响。例如，CNTK允许用户调整系统配置文件，在运算效率和GPU内存间取舍，而MXNet则能让用户对cuDNN库的自动设置进行调整。 ## 2. 背景及相关知识 随着深度学习技术的快速发展，人们针对不同的应用场合开发出各类深度神经网络，包括全连接神经网络(FCN)、卷积神经网络(CNN)、循环神经网络(RNN)、局限型波兹曼机(RBM)。此论文着重分析三种神经网络（FCN、CNN和RNN）的运行性能（或时间速度）及收敛速度。 FCN的历史可追溯到上世纪80年代，反向传播算法（backpropagation）发明之时。而CNN和RNN，一直以来分别在图像识别和自然语言处理应用上展现出优异的效果。 FCN是一个前向神经网络，由Yann LeCun等人在1989年成功应用于邮编识别。为了减少每一层的参数数量，CNN通过使用一组核(kernel)，建立了一个卷积层，每个核的参数在整个域（例如：一个彩色图像的通道）共享。CNN能减轻全连接层容易导致需要学习大量参数的问题。从LeNet架构开始，CNN已经实现很多成果，包括ImageNet分类、人脸识别和目标检测。 RNN允许网络单元的循环连接。RNN可以将整个历史输入序列跟每个输出相连，找到输入的上下文特性和输出之间的关系。有了这个特性，RNN可以保留之前输入的信息，类似于样本训练时的记忆功能。此外，长短时记忆（LSTM）通过适当地记录和丢弃信息，能解决RNN训练时梯度消失和爆炸的难题。含LSTM单元的RNN被证实是处理语音辨识和自然语言处理任务最有效的方法之一。 随着深度学习日益成功，诞生了许多受欢迎的开源GPU加速工具包。其中，Caffe、CNTK、MXNet、TensorFlow和Torch是最活跃、最受欢迎的例子。 Caffe由伯克利视觉和学习中心（BVLC）开发，自2014成为开源项目。作者声称Caffe可以借助NVIDIA K40或Titan GP卡，每天用GPU加速版本处理4000万图像。结合cuDNN之后，还可以加速约1.3倍。 CNTK是一个由微软研究院开发的工具包，支持大部分流行的神经网络。在2015年2月，官方报道了一个基准性能测试结果，针对一个4层全连接神经网络，CNTK与Caffe、TensorFlow、Theano和Torch对比，速度要快上1.5倍。 MXNet是一个支持多种语言的深度学习框架，旨在提供更灵活有效的编程接口，以提升生产效率。 TensorFlow由谷歌开发，它使用数据流图集成了深度学习框架中最常见的单元。它支持许多最新的网络如CNN，以及带不同设置的RNN。TensorFlow是为超凡的灵活性、轻便性和高效率而设计的。 Torch是一个科学计算框架，它为机器学习里最为有用的元件——如多维张量——提供数据结构。 (a) 全连接神经网络 (b) 卷积神经网络(AlexNet) (c) 循环神经网络 图1：深度学习模型的例子 为了加快深度神经网络的训练速度，有的使用CPU SSE技术和浮点SIMD模型来实现深度学习算法，相比浮点优化的版本能实现3倍加速。Andre Viebke等人利用多线程及SIMD并行化在英特尔Xeon Phi处理器上加速CNN。针对多GPU卡的并行化，Jeffrey Dean等人提出了一种大规模分布式深度网络，开发了两种算法（Downpour SGD和Sandblaster L-BFGS），可以在混有GPU机器的集群上运行。 加快训练方法的另一种方式是减少要学习的参数数量，Song Han等人使用修剪冗余连接的方法，在不失去网络表征能力下减少参数，这可以减少670万到6100万的AlexNet参数。Bahrampour等人也做了类似的性能评测工作，但他们仅用了一个GPU架构（NVIDIA Maxwell Titan X）和旧版的软件（cuDNN v2, v3）。 本文作者早前工作也探讨了单个GPU上跑旧版软件的基准测试结果。此文针对三版主要的GPU架构和一些最新的网络（如：ResNet-50）和软件（如：cuDNN v5）进行基准评测，并深入到工具包代码分析性能。此外，本文也比较了单台机器里多个GPU卡的性能。 因为单个GPU卡内存相对较少，限制了神经网络规模，训练的可伸缩性对于深度学习框架至关重要。在如今的深度学习工具中，支持多GPU卡成为了一个标准功能。为了利用多个GPU卡，分布式同步随机梯度下降法（SDG）使用很广泛，实现了很好的扩展性能。 在可扩展性方面，本文作者着重评估处理时间，以及数据同步方法的收敛速度。在数据并行模型里，针对N个worker，把有M个样本的一个mini-batch分成N份，每份M/N个样本，每个worker用相同的模型独立向前向后处理所分配的样本。当所有worker完成后，把梯度聚合，更新模型。 实际上，不同工具实现同步SGD算法的方式各有不同。 Caffe：采用删减树策略减少GPU间的数据通信。例如，假设有4个标记为0,1,2,3的GPU。首先，GPU 0和GPU 1交换梯度，GPU 2和GPU 3交换梯度，然后GPU 0和GPU 2交换梯度。之后，GPU 0会计算更新的模型，再将更新的模型传输到GPU 2中；接着GPU 0把模型传输到GPU 1，同时GPU 2把模型传输到GPU 3。 CNTK：使用MPI作为GPU之间的数据通信方法。CNTK支持4种类型的并行SGD算法（即：DataParallelSGD，BlockMomentumSGD，ModelAveragingSGD，DataParallelASGD）。对于本文关心的 data parallel SGD，CNTK把每个minibatch分摊到N个worker上。每次mini-batch后将梯度进行交换和聚合。 MXNet：同样将mini-batch样本分配到所有GPU中，每个GPU向前后执行一批规模为M/N的任务，然后在更新模型之前，将梯度汇总。 TensorFlow：在每个GPU上放置一份复制模型。也将mini-batch分到所有GPU。 Torch：其数据并行机制类似于MXNet，把梯度聚合的操作放在GPU端，减少了PCI-e卡槽的数据传输。 ## 3. 评测方法 处理时间(Processing time)及收敛速度(Convergence rate) 是用户训练深度学习模型时最看重的两个因素。因此该实验主要通过测量这两个指标以评估这几种深度学习工具。 一方面，评估处理时长有一种高效且主流的方法，就是测出对一个mini-batch所输入数据一次迭代的时长。在实际操作中，经历多轮迭代或收敛以后，深度学习的训练过程会终止。因此，对于每种神经网络，该实验使用不同大小的mini-batch来评测各个深度学习软件工具。作者针对每种大小的mini-batch都多次迭代，最后评估其平均运行速度。另一方面，由于数据并行化可能影响收敛速度，该评测还在多GPU卡的情况下比较了收敛速度。 评测使用合成数据集和真实数据集。合成数据集主要用于评估运行时间，真实数据集用于测量收敛速度。每种工具的时间测量方法如下： Caffe：使用“caffe train”命令训练所指定网络，随之计算两次连续迭代过程间的平均时间差。 CNTK：与Caffe类似，但排除包含磁盘I / O时间的首个epoch。 MXNet：使用内部定时功能，输出每个epoch和迭代的具体时间。 TensorFlow：在源脚本里使用计时功能，计算平均迭代时间。 Torch：和TensorFlow一样。 这几种工具均提供非常灵活的编程API或用于性能优化的配置选项。例如CNTK中可以在配置文件中指定“maxTempMemSizeIn-SamplesForCNN”选项，以控制CNN使用的临时内存的大小，虽然可能导致效率略微降低，但是内存需求更小了。 MXNet、TensorFlow和Torch也有丰富的API，在用于计算任务时供用户选择。换句话说，可能存在不同API以执行相同的操作。因此本评测结果仅仅是基于作者对这些工具用法的理解，不保证是最佳配置下的结果。 评测中的深度学习软件版本和相关库如表1所示。 表1：用于评测的深度学习软件 神经网络和数据集：对于合成数据的测试，实验采用具有约5500万个参数的大型神经网络（FCN-S）来评估FCN的性能。同时选择ImageNet所选的AlexNet和ResNet-50作为CNN的代表。 对于真实数据的测试，为MNIST数据集构建的FCN（FCN-R）较小；针对Cifar10数据集则使用名为AlexNet-R和ResNet-56的AlexNet架构。对于RNN，考虑到主要计算复杂度与输入序列长度有关，作者选择2个LSTM层进行测试，输入长度为32。每个网络的详细配置信息如表2和表3所示。 表2：合成数据的神经网络设置。注意：FCN-S有4层隐藏层，每层2048个节点；并且AlexNet-S中排除了batch normalization操作和dropout操作；为了测试CNN，输入数据是来自ImageNet数据库的彩色图像（维度224×224×3），输出维度是ImageNet数据的类别数量。 表3：真实数据的神经网络设置。注：FCN-R有3个隐藏层，节点数分别为2048、4096和1024。AlexNet-R的架构与原始出处里Cifar10所用的AlexNet相同，但不包括本地响应规范化（LRN）操作（CNTK不支持）。对于ResNet-56，作者沿用了最原始文件里的架构。 硬件平台：评测使用两种类型的多核CPU，其中包括一个4核台式机级CPU（Intel i7-3820 CPU @ 3.60GHz）和两个8核服务器级CPU（Intel XeonCPU E5-2630 v3 @ 2.40GHz），测试不同线程数下各个工具的性能。另外还用三代不同的GPU卡，分别是采用Maxwell架构的NVIDIA GTX 980 @ 1127MHz，采用Pascal架构的GTX 1080 @1607MHz，以及采用Kepler架构的Telsa K80 @ 562MHz。 评测只使用K80 GPU两个GK210芯片中的一个进行单GPU比较，同时，为了使得结果可重复，已禁用GPU自动超频功能。为了避免神经网络大小对主机内存的依赖，两台测试机分别配备64GB内存和128GB内存。硬件配置的详细信息如表4所示。 表4：本评测的硬件设置。注：K80卡上有2个GK210 GPU，但为了比较测试单GPU性能仅使用一个GPU。 数据并行化评测则在两个Tesla K80卡上进行，这样共有4个GK210 GPU。对于多GPU卡实验，系统配置如表5所示。 表5：数据并行性的评测硬件设置。注：K80卡上有两个GK210 GPU，因此进行双GPU并行评测时使用一个K80卡，进行四GPU并行评测时使用两个K80卡。 各神经网络，软件工具和硬件的组合结果如表6所示。 表6：各神经网络、软件工具和硬件的组合结果 4. 评测结果 评测结果分别在三个子部分呈现：CPU结果，单GPU结果和多GPU结果。对于CPU结果和单GPU结果，主要关注运行时长；对于多GPU还提出了关于收敛速度的比较。不同平台上的主要评测结果参见表7及表8。 表7：评测对比结果（每个mini-batch的运算时间，单位：秒）。注：FCN-S，AlexNet-S，ResNet-50，FCN-R，AlexNet-R，ResNet-56和LSTM的mini-batch大小分别为64，16，16，1024，1024，128，128。 表8：单GPU与多GPU间的比对结果（每个mini-batch的运算时间，单位：秒）。注：FCN-R，AlexNet-R和ResNet-56的mini-batch大小分别为4096，1024和128。 4.1. CPU评测结果 具体参见表7及原文。 4.2. 单GPU卡评测结果 在单GPU的比较上，该评测还展示了不同mini-batch大小的结果，以展示mini-batch大小对性能的影响。（译者注：原论文结论中详细描述了不同mini-batch大小下各学习工具的性能，具体见图表） 4.2.1. 合成数据（Synthetic Data） FCN-S：Caffe最佳，其次是CNTK和Torch，最后是TensorFlow及MXNet。 AlexNet-S：MXNet性能最佳，其次是Torch。 ResNet-50：MXNet性能远远高于其他工具，尤其是mini-batch大小比较大的时候。其次是CNTK和TensorFlow，Caffe相对较差。 4.2.2. 真实数据（Real Data） FCN-R：Torch最佳，Caffe、CNTK及MXNet三个工具次之，TensorFlow最差。 AlexNet-R：K80 平台上CNTK表现最佳，Caffe和Torch次之，然后是MXNet。TensorFlow处理时间最长。 ResNet-56：MXNet最优，其次是Caffe、CNTK 和Torch，这三个接近。最后是TensorFlow。 LSTM：CNTK全面超越其他工具。 4.3.多GPU卡评测结果 FCN-R：单GPU的情况下，Caffe、CNTK及MXNet接近，TensorFlow和Torch稍差。GPU数量翻番时，CNTK和MXNet的可扩展性最佳，均实现了约35%的提速，caffe实现了大约28%的提速，而Torch和TensorFlow只有约10%。GPU数量变为4个时，TensorFlow和Torch没有实现进一步的提速。 而收敛速度往往随着GPU数量的增加而增快。单个GPU时，Torch的训练融合速度最快，其次是Caffe、CNTK和MXNet，TensorFlow最慢。当GPU的数量增加到4时，CNTK和MXNet的收敛速度率接近Torch，而Caffe和TensorFlow收敛相对较慢。 AlexNet-R：单个GPU时，CNTK，MXNet和Torch性能接近，且比Caffe和TensorFlow快得多。随着GPU数量的增长，全部工具均实现高达40%的提速，而TensorFlow只有30%。 至于收敛速度，MXNet和Torch最快，CNTK稍慢，但也比Caffe和TensorFlow快得多。 ResNet-56：单GPU时，Torch用时最少。多个GPU时，MXNet往往更高效。 至于收敛速度，整体来说MXNet和Torch比其他三个工具更好，而Caffe最慢。 ## 5. 讨论 对于CPU并行，建议线程数不大于物理CPU内核数。因为在计算过程中需要额外的CPU资源来进行线程调度，如果CPU资源全部用于计算则难以实现高性能。然而，借助于Eigen的BLAS库（BLAS library），因其为了SIMD指令优化过，因此随着CPU内核数的增长，TensorFlow的性能能更好。 在FCN神经网络上，如果只用一个GPU卡，那么Caffe、CNTK和Torch的性能要比MXNet和TensorFlow略好。 通常来说，训练一个网络包含两阶计算（即前馈和后向传播）。在前馈阶段，矩阵乘法是最耗时的操作，评测的四个工具全部采用cuBLAS API：cublasSgemm。如果想要把矩阵A乘以矩阵B的转置，可以将cublasSgemm API的第二个参数设置为CUBLAS_OP_T，即应用in-place矩阵转置。但这就导致与没有转置的矩阵乘法相比，性能减慢3倍（例如，C = A×B^T，其中 A∈R^1024×26752 ，B∈R^2048×26752）。这是因为in-place矩阵转置非常耗时。CNTK和TensorFlow构造自己的数据结构，从而用的是cublasSgemm的CUBLAS_OP_N，而Caffe和Torch使用CUBLAS_OP_T。 在后向传播的阶段，则需要使用矩阵乘法来计算梯度，并使用element-wise矩阵运算来计算参数。如果通过调用cuBLAS来将A乘以B的转置，效率低时，可先转置B（如果GPU具有足够的内存，则采用out-place）再应用矩阵乘法可能会效果更好。 此外，cublasSgemm API完全支持后向传播，因为它在矩阵乘法后添加了一个缩放的矩阵。因此，如果将梯度计算和更新操作合并到单个GPU核中，则可以提高计算效率。为了优化FCN的效率，还可以在不转置的情况下使用cublasSgemm API，并同时使用cublasSgemm来计算梯度及执行更新操作。 在CNN上，所有工具包均使用cuDNN库进行卷积运算。尽管API调用相同，但是参数可能导致GPU内核不同。相关研究发现，在许多情况下，与直接执行卷积运算相比，FFT是更合适的解决方案。在矩阵的FFT之后，卷积计算可以被转换为更快速的内积运算（inner product operation）。 对于使用多个GPU卡的数据并行性，运算的扩展性受到梯度聚合处理的极大影响，因为其需要通过PCI-e传输数据。在本评测的测试平台中，Telsa K80的PCIe 3.0的最高吞吐量约为8GB/秒，这意味着在FCN-R情况下需要0.0256秒的时间将GPU的梯度转移到CPU。但是一个mini-batch的计算时间只有大约100毫秒。因此，减少GPU和CPU之间传输数据的成本将变得极为关键。 不同软件工具的性能表现各异，且与并行设计的策略相关。在Caffe中，梯度更新在GPU端执行，但它使用了树减少策略（tree reduction strategy）。如果说有4个GPU用于训练，则两对GPU将首先各自交换梯度（即GPU 0与GPU 1交换，GPU 2与GPU 3交换），然后GPU 0与GPU 2交换。之后，GPU 0负责计算更新的模型，再将模型传送到GPU 1，然后0将模型传送到1，2传送模型到3，这是一个并行过程。 因此，Caffe的可扩展性（scalability）的性能在很大程度上取决于系统的PCI-e拓扑。CNTK的作者在框架中添加了1比特的随机梯度下降（1-bit stochastic gradient descent），这意味着PCI-e交换梯度的时间可大大缩短。因此，即使使用大型网络，CNTK的可伸缩性也依旧表现良好。 在这类网络上，MXNet也表现出良好的可扩展性，因为它是在GPU上进行梯度聚合，这不仅减少了经常传输梯度数据的PCI-e时间，并能利用GPU资源来进行并行计算。 然而，TensorFlow在CPU端进行梯度聚合和模型更新，这不仅需要很多时间通过PCI-e传输梯度，而且还使用单个CPU更新串行算法中的模型。因此TensorFlow的伸缩性不如其他工具。 对于多个GPU，Torch在扩展性上与TensorFlow类似。其梯度聚合和更新都在CPU端执行，但Torch使用了并行算法来利用所有空闲的CPU资源。因此，其伸缩性要略好于TensorFlow，但仍然比不上Caffe、CNTK和MXNet。 总的来说，因为有了GPU计算资源，上述所有深度学习工具的速度与CPU的版本相比，都有了极大提高。这并不出奇，因为在GPU上的矩阵乘法以及FFT的性能要明显优于CPU。 未来作者还将评测更多的深度学习工具（比如百度的Paddle），也会把 AMD的GPU等也加入评测。并在高性能GPU集群上进行评测。 论文作者强调这是一个开源项目，所有配置文件和实验数据均在 http: //www.comp.hkbu.edu.hk/?chxw/dlbench.html 公开，欢迎读者指正。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://ipcreator.me/tags/Tensorflow/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"}]},{"title":"人工智能和机器学习的进步 需要一个更加开源的世界","date":"2017-02-13T00:33:06.000Z","path":"2017/02/13/Program/TensorFlow/ai-and-machine-learning-need-more-open-sources/","text":"作者：网易AI研究院 国外媒体TechCrunch撰文指出，当前的人工智能（AI）开源模式封闭，存在不足，且不合时宜。 人工智能正变得越来越重要。拥有机器学习（ML）技术经验的企业在寻求取得基于人工智能的技术。 还没有打造出机器学习技术的企业正竭力理解和设计机器学习和AI战略。正当AI受到大肆追捧，人们对该技术既感到困惑，又对它的风险感到恐慌，来自谷歌、Facebook、百度、微软等公司的一连串开源贡献公告（通过 Tensorflow、BigSur、Torch、SciKit、Caffe、CNTK、DMTK、Deeplearning4j、H2O、Mahout、MLLib、NuPIC、OpenNN等项目） 带来了一种明显的上手AI以及ML的方式，科技行业以外的企业尤其受益。 发现项目，下载，安装……应该是件轻而易举的事情。但事实上它并没有表面上那么的简单。 对于在AI使能或者AI影响的系统主导的时代软件的共享来说，当前的开源模式并不足够，且已经不合时宜；用户一天里使用过的AI引擎可能多达数千个。 对于AI和ML先驱们来说，共享他们的代码并不足够。整个行业和世界需要新的开源模式： 经过AI和ML训练的引擎本身开源的同时，数据、功能特性和现实世界表现细节也要开源。 当前的开源模式不足够且过时 AI和ML使能和影响的系统不同于其它用开源部件打造的软件。用开源部件打造的软件本质上还是具有确定性的，也就是说所设计和编写的软件每一次执行时的表现都是一样的。而 AI和ML系统，尤其是人工智能系统，并不能保证能够表现出确定性的行为。 随着对新情境、新环境和新用户的学习和适应，这些系统将会改变它们的行为。本质上，一旦这些AI系统被部署到现实世界，它们的创造者就会失去对AI的控制。当然，创造者们可以在学习框架中加入制衡机制。然而，即便是在AI系统被制约的范围内，仍需要进行大量的解读工作。与此同时，被AI包围的世界面临的更大挑战在于，制定制约条件的人造成的冲突。 想想看，最近有报道援引梅赛德斯董事长克里斯托弗·冯·雨果(Christoph Von Hugo)的话说，梅赛德斯无人驾驶汽车会选择优先保护乘客的生命，而非路人的生命。尽管该公司后来澄清说雨果的话被错误引述，但这揭示了资本主义将如何影响AI系统所嵌入的约束条件的根本性问题。 资本主义与AI伦理道德 如果企业的经营目的是创造利润，那将基于AI的体验描述为带附加价值的差异化体验，要求消费者溢价购买该技术的产品服务会在多久后进入市场呢？ 在这种情况下，愿意且有能力购买那种差异化体验的用户相比其他用户将会获得不正当的好处。因为企业将尝试从其对AI的投入中获得回报，这种技术将会局限于那些买得起的人。这将会导致AI内置的限制和行为对那些掏腰包购买的人有利，给他们提供保护，或者偏爱他们。 另一个担忧是，谁来为AI和M使能的产品的故障或者行为表现不佳负责的法律和政策问题。这个责任由谁来担负？用户，服务提供商，数据科学家，还是AI引擎？该如何问责，如何界定责任？回答这些问题的前提是，清晰地描述和遵守引发AI和ML的创造和使用的一系列事件。 AI与AI的互动 机器人玩木制魔术方块的3D渲染图 AI之间的冲突 考虑到AI使能产品在行为表现上可能存在不确定性，在原来没观察到的交互中可能会有意想不到的表现，在AI使能的产品代表两个或者更多的不同用户相互互动的场景中，这一问题会进一步放大。例如。当两辆由两个独立的AI引擎（由不同的公司用不同的训练数据和功能，以及独立配置的偏好和情境信息打造而成）驱动和运作的汽车遇到停车标志，或者将要发生碰撞时，会发生什么事情呢？这些系统在响应类似的情境时，即便有很细小的差异和变化，都可能会产生意想不到的不良影响。 偏好问题蔓延 互相影响的AI的另一个潜在副作用会放大训练的偏好风险。例如，如果无人驾驶汽车观察到另一辆无人驾驶汽车在以路人受伤为代价来保护乘客，观察到这一选择确保另一辆车能够避免发生事故，这种“学习”会使得它在遇到类似的情况时作出类似的行为。这会造成偏好问题蔓延：被独立训练的AI引擎受到另一个AI引擎的行为的影响（不管是正面的影响，还是负面的影响）。 学习的灵活性 即便类似的AI引擎获得的学习数据是一样的，训练环境和用来执行训练的基础设施方面的差异，也会导致训练和学习速度变得不一样，因而它们会得出不一样的结论。随着时间的推移，这些细微的变化会导致AI引擎的行为出现巨大的变化，带来不可预知的影响。 新的AI开源模式 我们需要新的AI开源模式来提供框架解决上述的部分问题。考虑到AI的本质，开源用于打造AI和ML引擎，将它们嵌入产品当中，并不足够。此外，类似于科学研究，行业将需要贡献回能够形成新改良的系统、引擎和产品基础的AI和ML引擎。 基线、基准与标准 对于无人驾驶汽车、图像识别、语音文本转换等所有重要的场景，尤其是有多家服务提供商涉足的场景， 行业需要能够定义统一的基线和标准，让所有其它的新AI引擎或者现存AI引擎有评估和堆栈排序的标准（例如，美国国家公路安全局针对无人驾驶汽车制定五星安全评级）。 为重要场景定义为行业所接受和批准的基准，可确保服务提供商和消费者能够在挑选AI与ML使能的产品服务时做出精明的决策。此外，现有的AI引擎可不断地根据基准与标准进行评估，进而确保这些系统的质量不断改进。 开发AI和ML模型的公司应当考虑对完整的AI和ML模型进行开源贡献（不仅仅是贡献打造这种模型的技术和框架）。 例如，即便是谷歌已有5年历史的图像识别模型，或者来自微软的Speech to Text语音文本转化模型，都能够在其它的领域或者行业激发AI和ML的快速创新和同化作用，进而形成自维持的创新回路。科技以外的行业也能够利用这些模式来启动自有的项目，以及将它们的学习成果贡献回开源社区。 偏好判定 行业需要偏好判定能力来使得嵌入AI和ML引擎的偏好能够被尽快发现和移除。没有这种能力的话，行业会难以形成在各种各样的场景中有着一致和确定性表现的统一AI引擎。偏好判定和偏好移除在AI开源模型中将需要以下的支持。 数据假定和偏好 AI使能的产品设计师需要确保它们理解其所做的和嵌入AI与ML引擎的数据假定和偏好。与其它AI使能产品进行交互的产品需要确保它们理解且准备好处理AI引擎行为带来的影响。为了确保消费者或者这类AI和ML模型的整合商做好准备，各个AI和ML模型应当揭示和共享以下的标准。 数据收集标准 数据是如何被收集的呢？数据生成器有哪些呢？数据收集的频率、地方、时间、方式和原因呢？数据是如何被收集、分层和传输的呢？ 数据选择标准 数据是如何被选来训练的呢？数据不被选择的标准是什么呢？什么数据子集被选择，什么不被选择呢？定义高质量数据的标准是什么呢？可接受但非高质量的数据标准是什么呢？ 数据处理标准 数据经过怎样的处理后才被拿来训练？数据经过怎样的转变、浓缩和概述呢？数据处理的频率如何？有什么会导致预订的数据处理推迟或者停止呢？ 功能假定与偏好 AI和ML模型通过对被模式化的系统的功能或者特点的观察来训练。这些功能提取自数据，被应用于AI和ML引擎，可预测该系统的行为，或者将新信号归类成想要的类别来触发系统特定的动作或者行为。消费者和AI模型的整合商需要清楚有哪些功能被选来开发AI模型，以及有哪些功能被考虑，哪些没被选择及没被选择的原因。此外，用来判定训练功能的洞见将需要记录下来和共享。 盲点移除 由于模型内置的偏好和假定，AI和ML引擎会形成令其在特定的情境、环境和语境中的有用性和效能受到限制的盲点。 盲点回报和反馈回路 AI和ML开源模型的另一重要功能，应当是既能够判定特定模型是否有盲点，还能够给AI模型贡献回可用于移除这些盲点的数据（现实生活的例子）。大体上，这种机制类似于垃圾邮件的汇报机制：垃圾邮件检测引擎可利用用户新提供的垃圾邮件案例来更新其对垃圾邮件的定义和检测垃圾邮件所需的过滤工具。 协作性盲点移除 理想的开源协议的另一个特性会是，不同服务提供商之间相互共享数据，共同协作移除模型中的盲点。想想谷歌的无人驾驶汽车和特斯拉的Autopilot自动驾驶模式。谷歌的汽车在自动驾驶模式下行驶了大约200万英里，而特斯拉汽车在Autopilot下行驶了大约5000万英里的高速公路。抛开这两家公司是竞争对手的事实，它们的数据集包含大量避免碰撞和确保司机、乘客或者路人的安全相关的数据。它们 可相互利用各自的数据集来改进各自的安全协议和程序。 也许，这种数据应当成为开源模型的一部分，毕竟它们可最大化行业和用户的利益。 总结 要真正变革和颠覆我们的生活，带来更好、更简单、更安全且更令人愉快的体验，AI和ML需要被纳入尽可能多的场景当中，需要被纳入各个行业领域的用户案例当中。 要真正启动和加速这种普及，开源用以打造AI和ML引擎的框架其实并不足够。我们需要新的开源模式来使得企业能够贡献和利用的不只是AI和ML开发技术，而是整个受训模型。而且，这些受训模型能够得到改进或者调整，或者在特定的场景中适应新环境以及AI和ML基准与标准，进而让新的AI和ML有参照标准。此外，揭示AI和ML模型的假定和偏好（数据或者功能层面）的信息，以及让AI和ML模型消费者能够给特定场景中的所有AI和ML产品贡献回重要数据和反馈的反馈回路，也非常重要。 没有这种开源模式，科技行业以外的世界将会继续难以实现AI和ML技术的普及。（皓慧）","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://ipcreator.me/tags/AI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://ipcreator.me/tags/Machine-Learning/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"Google 开源项目风格指南 (中文版)","date":"2017-02-12T04:10:06.000Z","path":"2017/02/12/Program/google-styleguide/","text":"作者：Jinhai ZHOU/JinhaiZ 每个较大的开源项目都有自己的风格指南: 关于如何为该项目编写代码的一系列约定 (有时候会比较武断). 当所有代码均保持一致的风格, 在理解大型代码库时更为轻松. “风格” 的含义涵盖范围广, 从 “变量使用驼峰格式 (camelCase)” 到 “决不使用全局变量” 再到 “决不使用异常”. 英文版项目维护的是在 Google 使用的编程风格指南. 如果你正在修改的项目源自 Google, 你可能会被引导至 英文版项目页面, 以了解项目所使用的风格. 我们已经发布了五份 中文版 的风格指南: Google C++ 风格指南Google Objective-C 风格指南Google Python 风格指南Google JSON 风格指南Google Shell 风格指南中文版项目采用 reStructuredText 纯文本标记语法, 并使用 Sphinx 生成 HTML / CHM / PDF 等文档格式. 英文版项目还包含 cpplint - 一个用来帮助适应风格准则的工具, 以及 google-c-style.el, Google 风格的 Emacs 配置文件.另外, 招募志愿者翻译 JavaScript Style Guide 以及 XML Document Format Style Guide, 有意者请联系 Yang.Y. Software Release Practice HOWTOEric Steven Raymond This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it. This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards. Table of Contents Introduction1.1. Why this document?1.2. New versions of this document Good patching practice2.1. Do send patches, don’t send whole archives or files2.2. Send patches against the current version of the code.2.3. Don’t include patches for generated files.2.4. Don’t send patch bands that just tweak version-control $-symbols.2.5. Do use -c or -u format, don’t use the default (-e) format2.6. Do include documentation with your patch2.7. Do include an explanation with your patch2.8. Do include useful comments in your code2.9. Just one bugfix or new feature per patch. Good project- and archive- naming practice3.1. Use GNU-style names with a stem and major.minor.patch numbering.3.2. But respect local conventions where appropriate3.3. Try hard to choose a name prefix that is unique and easy to type Good licensing and copyright practice: the theory4.1. Open source and copyrights4.2. What qualifies as open source Good licensing and copyright practice: the practice5.1. Make yourself or the FSF the copyright holder5.2. Use a license conformant to the Open Source Definition5.3. Don’t write your own license if you can possibly avoid it.5.4. Make your license visible in a standard place. Good development practice6.1. Choose the most portable language you can6.2. Don’t rely on proprietary code6.3. Build systems6.4. Test your code before release6.5. Sanity-check your code before release6.6. Sanity-check your documentation and READMEs before release6.7. Recommended C/C++ portability practices Good distribution-making practice7.1. Make sure tarballs always unpack into a single new directory7.2. Have a README7.3. Respect and follow standard file naming practices7.4. Design for Upgradability7.5. Provide checksums Good documentation practice8.1. Documentation formats8.2. Good practice recommendations Good communication practice9.1. Announce to Freecode9.2. Have a website9.3. Host project mailing lists9.4. Release to major archives Good project-management practice","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"},{"name":"Open Source","slug":"Open-Source","permalink":"http://ipcreator.me/tags/Open-Source/"}]},{"title":"The Unix and Internet Fundamentals HOWTO","date":"2017-01-20T12:31:06.000Z","path":"2017/01/20/Program/Concepts/the-unix-and-internet-fundamentals-howto/","text":"Eric Raymond This document describes the working basics of PC-class computers, Unix-like operating systems, and the Internet in non-technical language. Table of Contents Introduction1.1. Purpose of this document1.2. New versions of this document1.3. Feedback and corrections1.4. Related resources Basic anatomy of your computer What happens when you switch on a computer? What happens when you log in? What happens when you run programs from the shell? How do input devices and interrupts work? How does my computer do several things at once? How does my computer keep processes from stepping on each other?8.1. Virtual memory: the simple version8.2. Virtual memory: the detailed version8.3. The Memory Management Unit How does my computer store things in memory?9.1. Numbers9.2. Characters How does my computer store things on disk?10.1. Low-level disk and file system structure10.2. File names and directories10.3. Mount points10.4. How a file gets looked up10.5. File ownership, permissions and security10.6. How things can go wrong How do computer languages work?11.1. Compiled languages11.2. Interpreted languages11.3. P-code languages How does the Internet work?12.1. Names and locations12.2. The Domain Name System12.3. Packets and routers12.4. TCP and IP12.5. HTTP, an application protocol To Learn More 1. Introduction1.1. Purpose of this document This document is intended to help Linux and Internet users who are learning by doing. While this is a great way to acquire specific skills, sometimes it leaves peculiar gaps in one’s knowledge of the basics – gaps which can make it hard to think creatively or troubleshoot effectively, from lack of a good mental model of what is really going on. I’ll try to describe in clear, simple language how it all works. The presentation will be tuned for people using Unix or Linux on PC-class hardware. Nevertheless, I’ll usually refer simply to `Unix’ here, as most of what I will describe is constant across platforms and across Unix variants. I’m going to assume you’re using an Intel PC. The details differ slightly if you’re running an Alpha or PowerPC or some other Unix box, but the basic concepts are the same. I won’t repeat things, so you’ll have to pay attention, but that also means you’ll learn from every word you read. It’s a good idea to just skim when you first read this; you should come back and reread it a few times after you’ve digested what you have learned. This is an evolving document. I intend to keep adding sections in response to user feedback, so you should come back and review it periodically. 1.2. New versions of this document New versions of the Unix and Internet Fundamentals HOWTO will be periodically posted to comp.os.linux.help and comp.os.linux.announce and news.answers. They will also be uploaded to various Linux WWW and FTP sites, including the LDP home page. You can view the latest version of this on the World Wide Web via the URL http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html. This document has been translated into Polish. 1.3. Feedback and corrections If you have questions or comments about this document, please feel free to mail Eric S. Raymond, at esr@thyrsus.com. I welcome any suggestions or criticisms. I especially welcome hyperlinks to more detailed explanations of individual concepts. If you find a mistake with this document, please let me know so I can correct it in the next version. Thanks. 1.4. Related resources If you’re reading this in order to learn how to hack, you should also read the How To Become A Hacker FAQ. It has links to some other useful resources. 2. Basic anatomy of your computerYour computer has a processor chip inside it that does the actual computing. It has internal memory (what DOS/Windows people call RAM&#39;&#39; and Unix people often callcore’’; the Unix term is a folk memory from when RAM consisted of ferrite-core donuts). The processor and memory live on the motherboard, which is the heart of your computer. Your computer has a screen and keyboard. It has hard drives and floppy disks. Some of these devices are run by controller cards that plug into the motherboard and help the computer drive them; others are run by specialized chipsets directly on the motherboard that fulfill the same function as a controller card. Your keyboard is too simple to need a separate card; the controller is built into the keyboard chassis itself. We’ll go into some of the details of how these devices work later. For now, here are a few basic things to keep in mind about how they work together: All the parts of your computer inside the case are connected by a bus. Physically, the bus is what you plug your controller cards into (the video card, the disk controller, a sound card if you have one). The bus is the data highway between your processor, your screen, your disk, and everything else. (If you’ve seen references to ISA&#39;,PCI’, and `PCMCIA’ in connection with PCs and have not understood them, these are bus types. ISA is, except in minor details, the same bus that was used on IBM’s original PCs in 1980; it is passing out of use now. PCI, for Peripheral Component Interconnection, is the bus used on most modern PCs, and on modern Macintoshes as well. PCMCIA is a variant of ISA with smaller physical connectors used on laptop computers.) The processor, which makes everything else go, can’t actually see any of the other pieces directly; it has to talk to them over the bus. The only other subsystem that it has really fast, immediate access to is memory (the core). In order for programs to run, then, they have to be in core (in memory). When your computer reads a program or data off the disk, what actually happens is that the processor uses the bus to send a disk read request to your disk controller. Some time later the disk controller uses the bus to signal the processor that it has read the data and put it in a certain location in memory. The processor can then use the bus to look at that data. Your keyboard and screen also communicate with the processor via the bus, but in simpler ways. We’ll discuss those later on. For now, you know enough to understand what happens when you turn on your computer. 3. What happens when you switch on a computer? A computer without a program running is just an inert hunk of electronics. The first thing a computer has to do when it is turned on is start up a special program called an operating system. The operating system’s job is to help other computer programs to work by handling the messy details of controlling the computer’s hardware. The process of bringing up the operating system is called booting (originally this was bootstrapping and alluded to the process of pulling yourself up ``by your bootstraps’’). Your computer knows how to boot because instructions for booting are built into one of its chips, the BIOS (or Basic Input/Output System) chip. The BIOS chip tells it to look in a fixed place, usually on the lowest-numbered hard disk (the boot disk) for a special program called a boot loader (under Linux the boot loader is called LILO). The boot loader is pulled into memory and started. The boot loader’s job is to start the real operating system. The loader does this by looking for a kernel, loading it into memory, and starting it. When you boot Linux and see “LILO” on the screen followed by a bunch of dots, it is loading the kernel. (Each dot means it has loaded another disk block of kernel code.) ( You may wonder why the BIOS doesn’t load the kernel directly – why the two-step process with the boot loader? Well, the BIOS isn’t very smart. In fact it’s very stupid, and Linux doesn’t use it at all after boot time. It was originally written for primitive 8-bit PCs with tiny disks, and literally can’t access enough of the disk to load the kernel directly. The boot loader step also lets you start one of several operating systems off different places on your disk, in the unlikely event that Unix isn’t good enough for you.) Once the kernel starts, it has to look around, find the rest of the hardware, and get ready to run programs. It does this by poking not at ordinary memory locations but rather at I/O ports – special bus addresses that are likely to have device controller cards listening at them for commands. The kernel doesn’t poke at random; it has a lot of built-in knowledge about what it’s likely to find where, and how controllers will respond if they’re present. This process is called autoprobing. Most of the messages you see at boot time are the kernel autoprobing your hardware through the I/O ports, figuring out what it has available to it and adapting itself to your machine. The Linux kernel is extremely good at this, better than most other Unixes and much better than DOS or Windows. In fact, many Linux old-timers think the cleverness of Linux’s boot-time probes (which made it relatively easy to install) was a major reason it broke out of the pack of free-Unix experiments to attract a critical mass of users. But getting the kernel fully loaded and running isn’t the end of the boot process; it’s just the first stage (sometimes called run level 1). After this first stage, the kernel hands control to a special process called `init’ which spawns several housekeeping processes. The init process’s first job is usually to check to make sure your disks are OK. Disk file systems are fragile things; if they’ve been damaged by a hardware failure or a sudden power outage, there are good reasons to take recovery steps before your Unix is all the way up. We’ll go into some of this later on when we talk about how file systems can go wrong. Init’s next step is to start several daemons. A daemon is a program like a print spooler, a mail listener or a WWW server that lurks in the background, waiting for things to do. These special programs often have to coordinate several requests that could conflict. They are daemons because it’s often easier to write one program that runs constantly and knows about all requests than it would be to try to make sure that a flock of copies (each processing one request and all running at the same time) don’t step on each other. The particular collection of daemons your system starts may vary, but will almost always include a print spooler (a gatekeeper daemon for your printer). The next step is to prepare for users. Init starts a copy of a program called getty to watch your console (and maybe more copies to watch dial-in serial ports). This program is what issues the login prompt to your console. Once all daemons and getty processes for each terminal are started, we’re at run level 2. At this level, you can log in and run programs. But we’re not done yet. The next step is to start up various daemons that support networking and other services. Once that’s done, we’re at run level 3 and the system is fully ready for use. 4. What happens when you log in?When you log in (give a name to getty) you identify yourself to the computer. It then runs a program called (naturally enough) login, which takes your password and checks to see if you are authorized to be using the machine. If you aren’t, your login attempt will be rejected. If you are, login does a few housekeeping things and then starts up a command interpreter, the shell. (Yes, getty and login could be one program. They’re separate for historical reasons not worth going into here.) Here’s a bit more about what the system does before giving you a shell (you’ll need to know this later when we talk about file permissions). You identify yourself with a login name and password. That login name is looked up in a file called /etc/passwd, which is a sequence of lines each describing a user account. One of these fields is an encrypted version of the account password (sometimes the encrypted fields are actually kept in a second /etc/shadow file with tighter permissions; this makes password cracking harder). What you enter as an account password is encrypted in exactly the same way, and the login program checks to see if they match. The security of this method depends on the fact that, while it’s easy to go from your clear password to the encrypted version, the reverse is very hard. Thus, even if someone can see the encrypted version of your password, they can’t use your account. (It also means that if you forget your password, there’s no way to recover it, only to change it to something else you choose.) Once you have successfully logged in, you get all the privileges associated with the individual account you are using. You may also be recognized as part of a group. A group is a named collection of users set up by the system administrator. Groups can have privileges independently of their members’ privileges. A user can be a member of multiple groups. (For details about how Unix privileges work, see the section below on permissions.) (Note that although you will normally refer to users and groups by name, they are actually stored internally as numeric IDs. The password file maps your account name to a user ID; the /etc/group file maps group names to numeric group IDs. Commands that deal with accounts and groups do the translation automatically.) Your account entry also contains your home directory, the place in the Unix file system where your personal files will live. Finally, your account entry also sets your shell, the command interpreter that login will start up to accept your commmands. 5. What happens when you run programs from the shell?The shell is Unix’s interpreter for the commands you type in; ## it’s called a shell because it wraps around and hides the operating system kernel.## It’s an important feature of Unix that the shell and kernel are separate programs communicating through a small set of system calls. This makes it possible for there to be multiple shells, suiting different tastes in interfaces. The normal shell gives you the ‘$’ prompt that you see after logging in (unless you’ve customized it to be something else). We won’t talk about shell syntax and the easy things you can see on the screen here; instead we’ll take a look behind the scenes at what’s happening from the computer’s point of view. After boot time and before you run a program, you can think of your computer as containing a zoo of processes that are all waiting for something to do. They’re all waiting on events. An event can be you pressing a key or moving a mouse. Or, if your machine is hooked to a network, an event can be a data packet coming in over that network. The kernel is one of these processes. It’s a special one, because it controls when the other user processes can run, and it is normally the only process with direct access to the machine’s hardware. In fact, user processes have to make requests to the kernel when they want to get keyboard input, write to your screen, read from or write to disk, or do just about anything other than crunching bits in memory. These requests are known as system calls. Normally all I/O goes through the kernel so it can schedule the operations and prevent processes from stepping on each other. A few special user processes are allowed to slide around the kernel, usually by being given direct access to I/O ports. X servers (the programs that handle other programs’ requests to do screen graphics on most Unix boxes) are the most common example of this. But we haven’t gotten to an X server yet; you’re looking at a shell prompt on a character console. The shell is just a user process, and not a particularly special one. It waits on your keystrokes, listening (through the kernel) to the keyboard I/O port. As the kernel sees them, it echoes them to your screen. When the kernel sees an `Enter’ it passes your line of text to the shell. The shell tries to interpret those keystrokes as commands. **Let’s say you type ls&#39; and Enter to invoke the Unix directory lister. The shell applies its built-in rules to figure out that you want to run the executable command in the file/bin/ls’. It makes a system call asking the kernel to start /bin/ls as a new child process and give it access to the screen and keyboard through the kernel. Then the shell goes to sleep, waiting for ls to finish. When /bin/ls is done, it tells the kernel it’s finished by issuing an exit system call. The kernel then wakes up the shell and tells it it can continue running. The shell issues another prompt and waits for another line of input.** Other things may be going on while your `ls’ is executing, however (we’ll have to suppose that you’re listing a very long directory). You might switch to another virtual console, log in there, and start a game of Quake, for example. Or, suppose you’re hooked up to the Internet. Your machine might be sending or receiving mail while /bin/ls runs. 6. How do input devices and interrupts work?Your keyboard is a very simple input device; simple because it generates small amounts of data very slowly (by a computer’s standards). When you press or release a key, that event is signalled up the keyboard cable to raise a hardware interrupt. It’s the operating system’s job to watch for such interrupts. For each possible kind of interrupt, there will be an interrupt handler, a part of the operating system that stashes away any data associated with them (like your keypress/keyrelease value) until it can be processed. What the interrupt handler for your keyboard actually does is post the key value into a system area near the bottom of memory. There, it will be available for inspection when the operating system passes control to whichever program is currently supposed to be reading from the keyboard. More complex input devices like disk or network cards work in a similar way. Earlier, I referred to a disk controller using the bus to signal that a disk request has been fulfilled. What actually happens is that the disk raises an interrupt. The disk interrupt handler then copies the retrieved data into memory, for later use by the program that made the request. Every kind of interrupt has an associated priority level. Lower-priority interrupts (like keyboard events) have to wait on higher-priority interrupts (like clock ticks or disk events). Unix is designed to give high priority to the kinds of events that need to be processed rapidly in order to keep the machine’s response smooth. In your operating system’s boot-time messages, you may see references to IRQ numbers. You may be aware that one of the common ways to misconfigure hardware is to have two different devices try to use the same IRQ, without understanding exactly why. Here’s the answer. IRQ is short for “Interrupt Request”. The operating system needs to know at startup time which numbered interrupts each hardware device will use, so it can associate the proper handlers with each one. If two different devices try use the same IRQ, interrupts will sometimes get dispatched to the wrong handler. This will usually at least lock up the device, and can sometimes confuse the OS badly enough that it will flake out or crash. 7. How does my computer do several things at once?It doesn’t, actually. Computers can only do one task (or process) at a time. But a computer can change tasks very rapidly, and fool slow human beings into thinking it’s doing several things at once. This is called timesharing. One of the kernel’s jobs is to manage timesharing. It has a part called the scheduler which keeps information inside itself about all the other (non-kernel) processes in your zoo. Every 1/60th of a second, a timer goes off in the kernel, generating a clock interrupt. The scheduler stops whatever process is currently running, suspends it in place, and hands control to another process. 1/60th of a second may not sound like a lot of time. But on today’s microprocessors it’s enough to run tens of thousands of machine instructions, which can do a great deal of work. So even if you have many processes, each one can accomplish quite a bit in each of its timeslices. In practice, a program may not get its entire timeslice. If an interrupt comes in from an I/O device, the kernel effectively stops the current task, runs the interrupt handler, and then returns to the current task. A storm of high-priority interrupts can squeeze out normal processing; this misbehavior is called thrashing and is fortunately very hard to induce under modern Unixes. In fact, the speed of programs is only very seldom limited by the amount of machine time they can get (there are a few exceptions to this rule, such as sound or 3-D graphics generation). Much more often, delays are caused when the program has to wait on data from a disk drive or network connection. An operating system that can routinely support many simultaneous processes is called “multitasking”. The Unix family of operating systems was designed from the ground up for multitasking and is very good at it – much more effective than Windows or the Mac OS, which have had multitasking bolted into it as an afterthought and do it rather poorly. Efficient, reliable multitasking is a large part of what makes Linux superior for networking, communications, and Web service. 8. How does my computer keep processes from stepping on each other?The kernel’s scheduler takes care of dividing processes in time. Your operating system also has to divide them in space, so that processes can’t step on each others’ working memory. Even if you assume that all programs are trying to be cooperative, you don’t want a bug in one of them to be able to corrupt others. The things your operating system does to solve this problem are called memory management. Each process in your zoo needs its own area of memory, as a place to run its code from and keep variables and results in. You can think of this set as consisting of a read-only code segment (containing the process’s instructions) and a writeable data segment (containing all the process’s variable storage). The data segment is truly unique to each process, but if two processes are running the same code Unix automatically arranges for them to share a single code segment as an efficiency measure. 8.1. Virtual memory: the simple version Efficiency is important, because memory is expensive. Sometimes you don’t have enough to hold the entirety of all the programs the machine is running, especially if you are using a large program like an X server. To get around this, Unix uses a technique called virtual memory. It doesn’t try to hold all the code and data for a process in memory. Instead, it keeps around only a relatively small working set; the rest of the process’s state is left in a special swap space area on your hard disk. Note that in the past, that “Sometimes” last paragraph ago was “Almost always” – the size of memory was typically small relative to the size of running programs, so swapping was frequent. Memory is far less expensive nowadays and even low-end machines have quite a lot of it. On modern single-user machines with 64MB of memory and up, it’s possible to run X and a typical mix of jobs without ever swapping after they’re initially loded into core. 8.2. Virtual memory: the detailed version Actually, the last section oversimplified things a bit. Yes, programs see most of your memory as one big flat bank of addresses bigger than physical memory, and disk swapping is used to maintain that illusion. But your hardware actually has no fewer than five different kinds of memory in it, and the differences between them can matter a good deal when programs have to be tuned for maximum speed. To really understand what goes on in your machine, you should learn how all of them work. The five kinds of memory are these: processor registers, internal (or on-chip) cache, external (or off-chip) cache, main memory, and disk. And the reason there are so many kinds is simple: speed costs money. I have listed these kinds of memory in decreasing order of access time and increasing order of cost. Register memory is the fastest and most expensive and can be random-accessed about a billion times a second, while disk is the slowest and cheapest and can do about 100 random accesses a second. Here’s a full list reflecting early-2000 speeds for a typical desktop machine. While speed and capacity will go up and prices will drop, you can expect these ratios to remain fairly constant – and it’s those ratios that shape the memory hierarchy. DiskSize: 13000MB Accesses: 100KB/sec Main memorySize: 256MB Accesses: 100M/sec External cacheSize: 512KB Accesses: 250M/sec Internal CacheSize: 32KB Accesses: 500M/sec ProcessorSize: 28 bytes Accesses: 1000M/sec We can’t build everything out of the fastest kinds of memory. It would be way too expensive – and even if it weren’t, fast memory is volatile. That is, it loses its marbles when the power goes off. Thus, computers have to have hard disks or other kinds of non-volatile storage that retains data when the power goes off. And there’s a huge mismatch between the speed of processors and the speed of disks. The middle three levels of the memory hierarchy (internal cache, external cache, and main memory) basically exist to bridge that gap. Linux and other Unixes have a feature called virtual memory. What this means is that the operating system behaves as though it has much more main memory than it actually does. Your actual physical main memory behaves like a set of windows or caches on a much larger “virtual” memory space, most of which at any given time is actually stored on disk in a special zone called the swap area. Out of sight of user programs, the OS is moving blocks of data (called “pages”) between memory and disk to maintain this illusion. The end result is that your virtual memory is much larger but not too much slower than real memory. How much slower virtual memory is than physical depends on how well the operating system’s swapping algorithms match the way your programs use virtual memory. Fortunately, memory reads and writes that are close together in time also tend to cluster in memory space. This tendency is called locality, or more formally locality of reference – and it’s a good thing. If memory references jumped around virtual space at random, you’d typically have to do a disk read and write for each new reference and virtual memory would be as slow as a disk. But because programs do actually exhibit strong locality, your operating system can do relatively few swaps per reference. It’s been found by experience that the most effective method for a broad class of memory-usage patterns is very simple; it’s called LRU or the “least recently used” algorithm. The virtual-memory system grabs disk blocks into its working set as it needs them. When it runs out of physical memory for the working set, it dumps the least-recently-used block. All Unixes, and most other virtual-memory operating systems, use minor variations on LRU. Virtual memory is the first link in the bridge between disk and processor speeds. It’s explicitly managed by the OS. But there is still a major gap between the speed of physical main memory and the speed at which a processor can access its register memory. The external and internal caches address this, using a technique similar to virtual memory as I’ve described it. Just as the physical main memory behaves like a set of windows or caches on the disk’s swap area, the external cache acts as windows on main memory. External cache is faster (250M accesses per sec, rather than 100M) and smaller. The hardware (specifically, your computer’s memory controller) does the LRU thing in the external cache on blocks of data fetched from the main memory. For historical reasons, the unit of cache swapping is called a “line” rather than a page. But we’re not done. The internal cache gives us the final step-up in effective speed by caching portions of the external cache. It is faster and smaller yet – in fact, it lives right on the processor chip. If you want to make your programs really fast, it’s useful to know these details. Your programs get faster when they have stronger locality, because that makes the caching work better. The easiest way to make programs fast is therefore to make them small. If a program isn’t slowed down by lots of disk I/O or waits on network events, it will usually run at the speed of the smallest cache that it will fit inside. If you can’t make your whole program small, some effort to tune the speed-critical portions so they have stronger locality can pay off. Details on techniques for doing such tuning are beyond the scope of this tutorial; by the time you need them, you’ll be intimate enough with some compiler to figure out many of them yourself. 8.3. The Memory Management Unit Even when you have enough physical core to avoid swapping, the part of the operating system called the memory manager still has important work to do. It has to make sure that programs can only alter their own data segments – that is, prevent erroneous or malicious code in one program from garbaging the data in another. To do this, it keeps a table of data and code segments. The table is updated whenever a process either requests more memory or releases memory (the latter usually when it exits). This table is used to pass commands to a specialized part of the underlying hardware called an MMU or memory management unit. Modern processor chips have MMUs built right onto them. The MMU has the special ability to put fences around areas of memory, so an out-of-bound reference will be refused and cause a special interrupt to be raised. If you ever see a Unix message that says “Segmentation fault”, “core dumped” or something similar, this is exactly what has happened; an attempt by the running program to access memory (core) outside its segment has raised a fatal interrupt. This indicates a bug in the program code; the core dump it leaves behind is diagnostic information intended to help a programmer track it down. There is another aspect to protecting processes from each other besides segregating the memory they access. You also want to be able to control their file accesses so a buggy or malicious program can’t corrupt critical pieces of the system. This is why Unix has file permissions which we’ll discuss later. 9. How does my computer store things in memory?You probably know that everything on a computer is stored as strings of bits (binary digits; you can think of them as lots of little on-off switches). Here we’ll explain how those bits are used to represent the letters and numbers that your computer is crunching. Before we can go into this, you need to understand about the word size of your computer. The word size is the computer’s preferred size for moving units of information around; technically it’s the width of your processor’s registers, which are the holding areas your processor uses to do arithmetic and logical calculations. When people write about computers having bit sizes (calling them, say, 32-bit&#39;&#39; or64-bit’’ computers), this is what they mean. Most computers (including 386, 486, and Pentium PCs) have a word size of 32 bits. The old 286 machines had a word size of 16. Old-style mainframes often had 36-bit words. A few processors (like the Alpha from what used to be DEC and is now Compaq) have 64-bit words. The 64-bit word will become more common over the next five years; Intel is planning to replace the Pentium series with a 64-bit chip called the `Itanium’. The computer views your memory as a sequence of words numbered from zero up to some large value dependent on your memory size. That value is limited by your word size, which is why programs on older machines like 286s had to go through painful contortions to address large amounts of memory. I won’t describe them here; they still give older programmers nightmares. 9.1. Numbers Integer numbers are represented as either words or pairs of words, depending on your processor’s word size. One 32-bit machine word is the most common integer representation. Integer arithmetic is close to but not actually mathematical base-two. The low-order bit is 1, next 2, then 4 and so forth as in pure binary. But signed numbers are represented in twos-complement notation. The highest-order bit is a sign bit which makes the quantity negative, and every negative number can be obtained from the corresponding positive value by inverting all the bits and adding one. This is why integers on a 32-bit machine have the range -2^31 to 2^31 - 1 1 (where ^ is the `power’ operation, 2^3 = 8). That 32nd bit is being used for sign. Some computer languages give you access to unsigned arithmetic which is straight base 2 with zero and positive numbers only. Most processors and some languages can do operations in floating-point numbers (this capability is built into all recent processor chips). Floating-point numbers give you a much wider range of values than integers and let you express fractions. The ways in which this is done vary and are rather too complicated to discuss in detail here, but the general idea is much like so-called `scientific notation’, where one might write (say) 1.234 * 10^23; the encoding of the number is split into a mantissa (1.234) and the exponent part (23) for the power-of-ten multiplier (which means the number multiplied out would have 20 zeros on it, 23 minus the three decimal places). 9.2. Characters Characters are normally represented as strings of seven bits each in an encoding called ASCII (American Standard Code for Information Interchange). On modern machines, each of the 128 ASCII characters is the low seven bits of an octet or 8-bit byte; octets are packed into memory words so that (for example) a six-character string only takes up two memory words. For an ASCII code chart, type `man 7 ascii’ at your Unix prompt. The preceding paragraph was misleading in two ways. The minor one is that the term octet&#39; is formally correct but seldom actually used; most people refer to an octet as byte and expect bytes to be eight bits long. Strictly speaking, the termbyte’ is more general; there used to be, for example, 36-bit machines with 9-bit bytes (though there probably never will be again). The major one is that not all the world uses ASCII. In fact, much of the world can’t – ASCII, while fine for American English, lacks many accented and other special characters needed by users of other languages. Even British English has trouble with the lack of a pound-currency sign. There have been several attempts to fix this problem. All use the extra high bit that ASCII doesn’t, making it the low half of a 256-character set. The most widely-used of these is the so-called `Latin-1’ character set (more formally called ISO 8859-1). This is the default character set for Linux, HTML, and X. Microsoft Windows uses a mutant version of Latin-1 that adds a bunch of characters such as right and left double quotes in places proper Latin-1 leaves unassigned for historical reasons (for a scathing account of the trouble this causes, see the demoroniser page). Latin-1 handles western European languages, including English, French, German, Spanish, Italian, Dutch, Norwegian, Swedish, Danish. However, this isn’t good enough either, and as a result there is a whole series of Latin-2 through -9 character sets to handle things like Greek, Arabic, Hebrew, Esperanto, and Serbo-Croatian. For details, see the ISO alphabet soup page. The ultimate solution is a huge standard called Unicode (and its identical twin ISO/IEC 10646-1:1993). Unicode is identical to Latin-1 in its lowest 256 slots. Above these in 16-bit space it includes Greek, Cyrillic, Armenian, Hebrew, Arabic, Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada, Malayalam, Thai, Lao, Georgian, Tibetan, Japanese Kana, the complete set of modern Korean Hangul, and a unified set of Chinese/Japanese/Korean (CJK) ideographs. For details, see the Unicode Home Page. 10. How does my computer store things on disk?When you look at a hard disk under Unix, you see a tree of named directories and files. Normally you won’t need to look any deeper than that, but it does become useful to know what’s going on underneath if you have a disk crash and need to try to salvage files. Unfortunately, there’s no good way to describe disk organization from the file level downwards, so I’ll have to describe it from the hardware up. 10.1. Low-level disk and file system structure The surface area of your disk, where it stores data, is divided up something like a dartboard – into circular tracks which are then pie-sliced into sectors. Because tracks near the outer edge have more area than those close to the spindle at the center of the disk, the outer tracks have more sector slices in them than the inner ones. Each sector (or disk block) has the same size, which under modern Unixes is generally 1 binary K (1024 8-bit words). Each disk block has a unique address or disk block number. Unix divides the disk into disk partitions. Each partition is a continuous span of blocks that’s used separately from any other partition, either as a file system or as swap space. The original reasons for partitions had to do with crash recovery in a world of much slower and more error-prone disks; the boundaries between them reduce the fraction of your disk likely to become inaccessible or corrupted by a random bad spot on the disk. Nowadays, it’s more important that partitions can be declared read-only (preventing an intruder from modifying critical system files) or shared over a network through various means we won’t discuss here. The lowest-numbered partition on a disk is often treated specially, as a boot partition where you can put a kernel to be booted. Each partition is either swap space (used to implement virtual memory) or a file system used to hold files. Swap-space partitions are just treated as a linear sequence of blocks. File systems, on the other hand, need a way to map file names to sequences of disk blocks. Because files grow, shrink, and change over time, a file’s data blocks will not be a linear sequence but may be scattered all over its partition (from wherever the operating system can find a free block when it needs one). This scattering effect is called fragmentation. 10.2. File names and directories Within each file system, the mapping from names to blocks is handled through a structure called an i-node. There’s a pool of these things near the ``bottom’’ (lowest-numbered blocks) of each file system (the very lowest ones are used for housekeeping and labeling purposes we won’t describe here). Each i-node describes one file. File data blocks (including directories) live above the i-nodes (in higher-numbered blocks). Every i-node contains a list of the disk block numbers in the file it describes. (Actually this is a half-truth, only correct for small files, but the rest of the details aren’t important here.) Note that the i-node does not contain the name of the file. Names of files live in directory structures. A directory structure just maps names to i-node numbers. This is why, in Unix, a file can have multiple true names (or hard links); they’re just multiple directory entries that happen to point to the same i-node. 10.3. Mount points In the simplest case, your entire Unix file system lives in just one disk partition. While you’ll see this arrangement on some small personal Unix systems, it’s unusual. More typical is for it to be spread across several disk partitions, possibly on different physical disks. So, for example, your system may have one small partition where the kernel lives, a slightly larger one where OS utilities live, and a much bigger one where user home directories live. The only partition you’ll have access to immediately after system boot is your root partition, which is (almost always) the one you booted from. It holds the root directory of the file system, the top node from which everything else hangs. The other partitions in the system have to be attached to this root in order for your entire, multiple-partition file system to be accessible. About midway through the boot process, your Unix will make these non-root partitions accessible. It will mount each one onto a directory on the root partition. For example, if you have a Unix directory called `/usr’, it is probably a mount point to a partition that contains many programs installed with your Unix but not required during initial boot. 10.4. How a file gets looked up Now we can look at the file system from the top down. When you open a file (such as, say, /home/esr/WWW/ldp/fundamentals.sgml) here is what happens:Your kernel starts at the root of your Unix file system (in the root partition). It looks for a directory there called home&#39;. Usuallyhome’ is a mount point to a large user partition elsewhere, so it will go there. In the top-level directory structure of that user partition, it will look for a entry called esr&#39; and extract an i-node number. It will go to that i-node, notice that its associated file data blocks are a directory structure, and look upWWW’. Extracting that i-node, it will go to the corresponding subdirectory and look up ldp&#39;. That will take it to yet another directory i-node. Opening that one, it will find an i-node number forfundamentals.sgml’. That i-node is not a directory, but instead holds the list of disk blocks associated with the file.## 10.5. File ownership, permissions and security To keep programs from accidentally or maliciously stepping on data they shouldn’t, Unix has permission features. These were originally designed to support timesharing by protecting multiple users on the same machine from each other, back in the days when Unix ran mainly on expensive shared minicomputers. In order to understand file permissions, you need to recall the description of users and groups in the section What happens when you log in?. Each file has an owning user and an owning group. These are initially those of the file’s creator; they can be changed with the programs chown(1) and chgrp(1). The basic permissions that can be associated with a file are read&#39; (permission to read data from it),write’ (permission to modify it) and execute&#39; (permission to run it as a program). Each file has three sets of permissions; one for its owning user, one for any user in its owning group, and one for everyone else. Theprivileges’ you get when you log in are just the ability to do read, write, and execute on those files for which the permission bits match your user ID or one of the groups you are in, or files that have been made accessible to the world. To see how these may interact and how Unix displays them, let’s look at some file listings on a hypothetical Unix system. Here’s one: snark:~$ ls -l notes-rw-r–r– 1 esr users 2993 Jun 17 11:00 notesThis is an ordinary data file. The listing tells us that it’s owned by the user esr&#39; and was created with the owning groupusers’. Probably the machine we’re on puts every ordinary user in this group by default; other groups you commonly see on timesharing machines are staff&#39;,admin’, or `wheel’ (for obvious reasons, groups are not very important on single-user workstations or PCs). Your Unix may use a different default group, perhaps one named after your user ID. The string -rw-r--r--&#39; represents the permission bits for the file. The very first dash is the position for the directory bit; it would showd’ if the file were a directory. After that, the first three places are user permissions, the second three group permissions, and the third are permissions for others (often called world&#39; permissions). On this file, the owning useresr’ may read or write the file, other people in the `users’ group may read it, and everybody else in the world may read it. This is a pretty typical set of permissions for an ordinary data file. Now let’s look at a file with very different permissions. This file is GCC, the GNU C compiler. snark:~$ ls -l /usr/bin/gcc-rwxr-xr-x 3 root bin 64796 Mar 21 16:41 /usr/bin/gccThis file belongs to a user called root&#39; and a group calledbin’; it can be written (modified) only by root, but read or executed by anyone. This is a typical ownership and set of permissions for a pre-installed system command. The bin&#39; group exists on some Unixes to group together system commands (the name is a historical relic, short forbinary’). Your Unix might use a root&#39; group instead (not quite the same as theroot’ user!). The `root’ user is the conventional name for numeric user ID 0, a special, privileged account that can override all privileges. Root access is useful but dangerous; a typing mistake while you’re logged in as root can clobber critical system files that the same command executed from an ordinary user account could not touch. Because the root account is so powerful, access to it should be guarded very carefully. Your root password is the single most critical piece of security information on your system, and it is what any crackers and intruders who ever come after you will be trying to get. About passwords: Don’t write them down – and don’t pick a passwords that can easily be guessed, like the first name of your girlfriend/boyfriend/spouse. This is an astonishingly common bad practice that helps crackers no end. In general, don’t pick any word in the dictionary; there are programs called dictionary crackers that look for likely passwords by running through word lists of common choices. A good technique is to pick a combination consisting of a word, a digit, and another word, such as shark6cider&#39; orjump3joy’; that will make the search space too large for a dictionary cracker. Don’t use these examples, though – crackers might expect that after reading this document and put them in their dictionaries. Now let’s look at a third case: snark:~$ ls -ld ~drwxr-xr-x 89 esr users 9216 Jun 27 11:29 /home2/esrsnark:~$This file is a directory (note the `d’ in the first permissions slot). We see that it can be written only by esr, but read and executed by anybody else. Read permission gives you the ability to list the directory – that is, to see the names of files and directories it contains. Write permission gives you the ability to create and delete files in the directory. If you remember that the directory includes a list of the names of the files and subdirectories it contains, these rules will make sense. Execute permission on a directory means you can get through the directory to open the files and directories below it. In effect, it gives you permission to access the i-nodes in the directory. A directory with execute completely turned off would be useless. Occasionally you’ll see a directory that is world-executable but not world-readable; this means a random user can get to files and directories beneath it, but only by knowing their exact names (the directory cannot be listed). It’s important to remember that read, write, or execute permission on a directory is independent of the permissions on the files and directories beneath. In particular, write access on a directory means you can create new files or delete existing files there, but does not automatically give you write access to existing files. Finally, let’s look at the permissions of the login program itself. snark:~$ ls -l /bin/login-rwsr-xr-x 1 root bin 20164 Apr 17 12:57 /bin/loginThis has the permissions we’d expect for a system command – except for that ‘s’ where the owner-execute bit ought to be. This is the visible manifestation of a special permission called the `set-user-id’ or setuid bit. The setuid bit is normally attached to programs that need to give ordinary users the privileges of root, but in a controlled way. When it is set on an executable program, you get the privileges of the owner of that program file while the program is running on your behalf, whether or not they match your own. Like the root account itself, setuid programs are useful but dangerous. Anyone who can subvert or modify a setuid program owned by root can use it to spawn a shell with root privileges. For this reason, opening a file to write it automatically turns off its setuid bit on most Unixes. Many attacks on Unix security try to exploit bugs in setuid programs in order to subvert them. Security-conscious system administrators are therefore extra-careful about these programs and reluctant to install new ones. There are a couple of important details we glossed over when discussing permissions above; namely, how the owning group and permissions are assigned when a file or directory is first created. The group is an issue because users can be members of multiple groups, but one of them (specified in the user’s /etc/passwd entry) is the user’s default group and will normally own files created by the user. The story with initial permission bits is a little more complicated. A program that creates a file will normally specify the permissions it is to start with. But these will be modified by a variable in the user’s environment called the umask. The umask specifies which permission bits to turn off when creating a file; the most common value, and the default on most systems, is ——-w- or 002, which turns off the world-write bit. See the documentation of the umask command on your shell’s manual page for details. Initial directory group is also a bit complicated. On some Unixes a new directory gets the default group of the creating user (this in the System V convention); on others, it gets the owning group of the parent directory in which it’s created (this is the BSD convention). On some modern Unixes, including Linux, the latter behavior can be selected by setting the set-group-ID on the directory (chmod g+s). 10.6. How things can go wrong Earlier it was hinted that file systems can be fragile things. Now we know that to get to a file you have to hopscotch through what may be an arbitrarily long chain of directory and i-node references. Now suppose your hard disk develops a bad spot? If you’re lucky, it will only trash some file data. If you’re unlucky, it could corrupt a directory structure or i-node number and leave an entire subtree of your system hanging in limbo – or, worse, result in a corrupted structure that points multiple ways at the same disk block or i-node. Such corruption can be spread by normal file operations, trashing data that was not in the original bad spot. Fortunately, this kind of contingency has become quite uncommon as disk hardware has become more reliable. Still, it means that your Unix will want to integrity-check the file system periodically to make sure nothing is amiss. Modern Unixes do a fast integrity check on each partition at boot time, just before mounting it. Every few reboots they’ll do a much more thorough check that takes a few minutes longer. If all of this sounds like Unix is terribly complex and failure-prone, it may be reassuring to know that these boot-time checks typically catch and correct normal problems before they become really disastrous. Other operating systems don’t have these facilities, which speeds up booting a bit but can leave you much more seriously screwed when attempting to recover by hand (and that’s assuming you have a copy of Norton Utilities or whatever in the first place…). One of the trends in current Unix designs is journalling file systems. These arrange traffic to the disk so that it’s guaranteed to be in a consistent state that can be recovered when the system comes back up. This will speed up the boot-time integrity check a lot. 11. How do computer languages work?We’ve already discussed how programs are run. Every program ultimately has to execute as a stream of bytes that are instructions in your computer’s machine language. But human beings don’t deal with machine language very well; doing so has become a rare, black art even among hackers. Almost all Unix code except a small amount of direct hardware-interface support in the kernel itself is nowadays written in a high-level language. (The high-level&#39; in this term is a historical relic meant to distinguish these fromlow-level’ assembler languages, which are basically thin wrappers around machine code.) There are several different kinds of high-level languages. In order to talk about these, you’ll find it useful to bear in mind that the source code of a program (the human-created, editable version) has to go through some kind of translation into machine code that the machine can actually run. 11.1. Compiled languages The most conventional kind of language is a compiled language. Compiled languages get translated into runnable files of binary machine code by a special program called (logically enough) a compiler. Once the binary has been generated, you can run it directly without looking at the source code again. (Most software is delivered as compiled binaries made from code you don’t see.) Compiled languages tend to give excellent performance and have the most complete access to the OS, but also to be difficult to program in. C, the language in which Unix itself is written, is by far the most important of these (with its variant C++). FORTRAN is another compiled language still used among engineers and scientists but years older and much more primitive. In the Unix world no other compiled languages are in mainstream use. Outside it, COBOL is very widely used for financial and business software. There used to be many other compiler languages, but most of them have either gone extinct or are strictly research tools. If you are a new Unix developer using a compiled language, it is overwhelmingly likely to be C or C++. 11.2. Interpreted languages An interpreted language depends on an interpreter program that reads the source code and translates it on the fly into computations and system calls. The source has to be re-interpreted (and the interpreter present) each time the code is executed. Interpreted languages tend to be slower than compiled languages, and often have limited access to the underlying operating system and hardware. On the other hand, they tend to be easier to program and more forgiving of coding errors than compiled languages. Many Unix utilities, including the shell and bc(1) and sed(1) and awk(1), are effectively small interpreted languages. BASICs are usually interpreted. So is Tcl. Historically, the most important interpretive language has been LISP (a major improvement over most of its successors). Today, Unix shells and the Lisp that lives inside the Emacs editor are probably the most important pure interpreted languages. 11.3. P-code languages Since 1990 a kind of hybrid language that uses both compilation and interpretation has become increasingly important. P-code languages are like compiled languages in that the source is translated to a compact binary form which is what you actually execute, but that form is not machine code. Instead it’s pseudocode (or p-code), which is usually a lot simpler but more powerful than a real machine language. When you run the program, you interpret the p-code. P-code can run nearly as fast as a compiled binary (p-code interpreters can be made quite simple, small and speedy). But p-code languages can keep the flexibility and power of a good interpreter. Important p-code languages include Python, Perl, and Java. 12. How does the Internet work?To help you understand how the Internet works, we’ll look at the things that happen when you do a typical Internet operation – pointing a browser at the front page of this document at its home on the Web at the Linux Documentation Project. This document is http://www.linuxdoc.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.htmlwhich means it lives in the file LDP/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html under the World Wide Web export directory of the host www.linuxdoc.org. 12.1. Names and locations The first thing your browser has to do is to establish a network connection to the machine where the document lives. To do that, it first has to find the network location of the host www.linuxdoc.org (host&#39; is short forhost machine’ or network host&#39;; www.linuxdoc.org is a typical hostname). The corresponding location is actually a number called an IP address (we&#39;ll explain theIP’ part of this term later). To do this, your browser queries a program called a name server. The name server may live on your machine, but it’s more likely to run on a service machine that yours talks to. When you sign up with an ISP, part of your setup procedure will almost certainly involve telling your Internet software the IP address of a nameserver on the ISP’s network. The name servers on different machines talk to each other, exchanging and keeping up to date all the information needed to resolve hostnames (map them to IP addresses). Your nameserver may query three or four different sites across the network in the process of resolving www.linuxdoc.org, but this usually happens very quickly (as in less than a second). We’ll look at how nameservers detail in the next section. The nameserver will tell your browser that www.linuxdoc.org’s IP address is 152.19.254.81; knowing this, your machine will be able to exchange bits with www.linuxdoc.org directly. 12.2. The Domain Name System The whole network of programs and databases that cooperates to translate hostnames to IP addresses is called DNS&#39; (Domain Name System). When you see references to aDNS server’, that means what we just called a nameserver. Now I’ll explain how the overall system works. Internet hostnames are composed of parts separated by dots. A domain is a collection of machines that share a common name suffix. Domains can live inside other domains. For example, the machine www.linuxdoc.org lives in the .linuxdoc.org subdomain of the .org domain. Each domain is defined by an authoritative name server that knows the IP addresses of the other machines in the domain. The authoritative (or primary&#39;) name server may have backups in case it goes down; if you see references to a secondary name server or (secondary DNS’) it’s talking about one of those. These secondaries typically refresh their information from their primaries every few hours, so a change made to the hostname-to-IP mapping on the primary will automatically be propagated. Now here’s the important part. The nameservers for a domain do not have to know the locations of all the machines in other domains (including their own subdomains); they only have to know the location of the nameservers. In our example, the authoritative name server for the .org domain knows the IP address of the nameserver for .linuxdoc.org, but not the address of all the other machines in linuxdoc.org. The domains in the DNS system are arranged like a big inverted tree. At the top are the root servers. Everybody knows the IP addresses of the root servers; they’re wired into your DNS software. The root servers know the IP addresses of the nameservers for the top-level domains like .com and .org, but not the addresses of machines inside those domains. Each top-level domain server knows where the nameservers for the domains directly beneath it are, and so forth. DNS is carefully designed so that each machine can get away with the minimum amount of knowledge it needs to have about the shape of the tree, and local changes to subtrees can be made simply by changing one authoritative server’s database of name-to-IP-address mappings. When you query for the IP address of www.linuxdoc.org, what actually happens is this: First, your nameserver asks a root server to tell it where it can find a nameserver for .org. Once it knows that, it then asks the .org server to tell it the IP address of a .linuxdoc.org nameserver. Once it has that, it asks the .linuxdoc.org nameserver to tell it the address of the host www.linuxdoc.org. Most of the time, your nameserver doesn’t actually have to work that hard. Nameservers do a lot of cacheing; when yours resolves a hostname, it keeps the association with the resulting IP address around in memory for a while. This is why, when you surf to a new website, you’ll usually only see a message from your browser about “Looking up” the host for the first page you fetch. Eventually the name-to-address mapping expires and your DNS has to re-query — this is important so you don’t have invalid information hanging around forever when a hostname changes addresses. Your cached IP address for a site is also thrown out if the host is unreachable. 12.3. Packets and routers What the browser wants to do is send a command to the Web server on www.linuxdoc.org that looks like this: GET /LDP/HOWTO/Fundamentals.html HTTP/1.0Here’s how that happens. The command is made into a packet, a block of bits like a telegram that is wrapped with three important things; the source address (the IP address of your machine), the destination address (152.19.254.81), and a service number or port number (80, in this case) that indicates that it’s a World Wide Web request. Your machine then ships the packet down the wire (your connection to your ISP, or local network) until it gets to a specialized machine called a router. The router has a map of the Internet in its memory – not always a complete one, but one that completely describes your network neighborhood and knows how to get to the routers for other neighborhoods on the Internet. Your packet may pass through several routers on the way to its destination. Routers are smart. They watch how long it takes for other routers to acknowledge having received a packet. They also use that information to direct traffic over fast links. They use it to notice when another routers (or a cable) have dropped off the network, and compensate if possible by finding another route. There’s an urban legend that the Internet was designed to survive nuclear war. This is not true, but the Internet’s design is extremely good at getting reliable performance out of flaky hardware in an uncertain world. This is directly due to the fact that its intelligence is distributed through thousands of routers rather than concentrated in a few massive and vulnerable switches (like the phone network). This means that failures tend to be well localized and the network can route around them. Once your packet gets to its destination machine, that machine uses the service number to feed the packet to the web server. The web server can tell where to reply to by looking at the command packet’s source IP address. When the web server returns this document, it will be broken up into a number of packets. The size of the packets will vary according to the transmission media in the network and the type of service. 12.4. TCP and IP To understand how multiple-packet transmissions are handled, you need to know that the Internet actually uses two protocols, stacked one on top of the other. The lower level, IP (Internet Protocol), is responsible for labeling individual packets with the source address and destination address of two computers exchanging information over a network. For example, when you access http://www.linuxdoc.org, the packets you send will have your computer’s IP address, such as 192.168.1.101, and the IP address of the www.linuxdoc.org computer, 152.2.210.81. These addresses work in much the same way that your home address works when someone sends you a letter. The post office can read the address and determine where you are and how best to route the letter to you, much like a router does for Internet traffic. The upper level, TCP (Transmission Control Protocol), gives you reliability. When two machines negotiate a TCP connection (which they do using IP), the receiver knows to send acknowledgements of the packets it sees back to the sender. If the sender doesn’t see an acknowledgement for a packet within some timeout period, it resends that packet. Furthermore, the sender gives each TCP packet a sequence number, which the receiver can use you reassemble packets in case they show up out of order. (This can easily happen if network links go up or down during a connection.) TCP/IP packets also contain a checksum to enable detection of data corrupted by bad links. (The checksum is computed from the rest of the packet in such a way that if the either the rest of the packet or the checksum is corrupted, redoing the computation and comparing is very likely to indicate an error.) So, from the point of view of anyone using TCP/IP and nameservers, it looks like a reliable way to pass streams of bytes between hostname/service-number pairs. People who write network protocols almost never have to think about all the packetizing, packet reassembly, error checking, checksumming, and retransmission that goes on below that level. 12.5. HTTP, an application protocol Now let’s get back to our example. Web browsers and servers speak an application protocol that runs on top of TCP/IP, using it simply as a way to pass strings of bytes back and forth. This protocol is called HTTP (Hyper-Text Transfer Protocol) and we’ve already seen one command in it – the GET shown above. When the GET command goes to www.linuxdoc.org’s webserver with service number 80, it will be dispatched to a server daemon listening on port 80. Most Internet services are implemented by server daemons that do nothing but wait on ports, watching for and executing incoming commands. If the design of the Internet has one overall rule, it’s that all the parts should be as simple and human-accessible as possible. HTTP, and its relatives (like the Simple Mail Transfer Protocol, SMTP, that is used to move electronic mail between hosts) tend to use simple printable-text commands that end with a carriage-return/line feed. This is marginally inefficient; in some circumstances you could get more speed by using a tightly-coded binary protocol. But experience has shown that the benefits of having commands be easy for human beings to describe and understand outweigh any marginal gain in efficiency that you might get at the cost of making things tricky and opaque. Therefore, what the server daemon ships back to you via TCP/IP is also text. The beginning of the response will look something like this (a few headers have been suppressed): HTTP/1.1 200 OKDate: Sat, 10 Oct 1998 18:43:35 GMTServer: Apache/1.2.6 Red HatLast-Modified: Thu, 27 Aug 1998 17:55:15 GMTContent-Length: 2982Content-Type: text/htmlThese headers will be followed by a blank line and the text of the web page (after which the connection is dropped). Your browser just displays that page. The headers tell it how (in particular, the Content-Type header tells it the returned data is really HTML). To Learn More There is a Reading List HOWTO that lists books you can read to learn more about the topics we have touched on here. You might also want to read the How To Become A Hacker document.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Unix","slug":"Unix","permalink":"http://ipcreator.me/tags/Unix/"},{"name":"Internet","slug":"Internet","permalink":"http://ipcreator.me/tags/Internet/"}]},{"title":"如何成为一名黑客","date":"2017-01-20T12:31:06.000Z","path":"2017/01/20/Program/Concepts/how-to-become-a-hacker/","text":"如何成为一名黑客——Eric S. Raymond &#x65;&#115;&#114;&#x40;&#116;&#104;&#x79;&#x72;&#115;&#117;&#x73;&#x2e;&#x63;&#x6f;&#x6d;Wang Dingwei &#x77;&#x61;&#x6e;&#x67;&#x64;&#105;&#110;&#103;&#119;&#101;&#105;&#x38;&#x32;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#x6f;&#109; 基于 Barret 的翻译更正而成。转载请注明出处。 目录 为什么会有这份文档？ 什么是黑客？ 黑客的态度 黑客的基本技能 提高自己在黑客圈中的地位 黑客和书呆子(Nerd)的联系 向黑客的格调靠拢 关于黑客、开源、以及自由软件的历史 其它资源 FAQ（常见问题解答） 为什么会有这份文档？作为 Jargon File（译注：黑客行话大全）的编辑和几份其他类似性质知名文章的作者，我经常收到充满热情的网络新手的电子邮件询问：“我如何才能成为一名出色的 Hacker？”早在 1996 年，我注意到网上似乎没有任何的 FAQ 或者 Web 形式的文档提到及这个至关重要的问题，因此我写了这份文档。现在，很多 Hacker 都认为这是一篇权威性文档，那我也姑且这么认为吧。不过，我不认为我是这个话题的绝对权威；如果你不喜欢这篇文档，你也可以自己写一份。 如果你读到的是这份文档的离线拷贝，你可以在 http://catb.org/~esr/faqs/hacker-howto.html 读到最新版本。 注意：文档的结尾有一份 FAQ（常见问题解答）。如果你想通过邮件询问我关于这份文档的问题，请先读这份 FAQ 看看能否找到答案——一遍不行就读两遍。 目前这份文档有很多翻译版本：阿拉伯语、白俄罗斯语、丹麦语、 荷兰语 、爱沙尼亚语、德语 、希腊语、意大利语 、希伯来语、 挪威语 、葡萄牙语（巴西）、 罗马尼亚语 、西班牙语 、土耳其语、瑞典语 。注意由于这份文档时有修正，所以以上翻译版本可能有不同程度的过时。 装饰本文的“五点九宫格”图像被称作“glider”，在一种叫做 Life 的数学模型中，这个简单的样本有一些异乎寻常的属性，多年以来 Hacker 们都为此着迷。我认为这个图像是一个很好的黑客徽标：它显得抽象而且神秘，而且像是一扇大门，通向一个截然不同的有其内在逻辑的世界。你可以阅读更多关于 Glider 徽标 的内容。 什么是黑客？Jargon File 讲了一堆关于“hacker”这个词的定义，大部分是关于“技术高超”、“热衷解决问题”、以及“超越极限”的内容。但如果你只想知道如何成为一名黑客的话，真正重要的只有两条。 这可以追溯到几十年前，那时候第一代分时微型计算机才刚刚诞生, 而 ARPAnet 的实验也才刚展开。那时的编程专家和组网高手建立了一个具有共享性质的文化社群， “hacker” 这个名词就是其中的成员创造的。黑客们建立了互联网，黑客们让 Unix 操作系统演化到现在的模样，黑客们经营着 Usenet，黑客们让万维网运转起来。如果你是这个文化的一部分，如果你对这种文化有所贡献，而且这个社群的其它成员也认识你并称你为 hacker，那么你就是一名黑客。 黑客的思维方式并不仅仅局限在软件黑客的文化圈内。也有人用黑客态度对待其它事情，如电子和音乐方面——其实你可以在任何最高级别的科学和艺术活动中发现它的身影。软件黑客对这些领域的践行者尊重有加，并把他们也称作黑客——有人宣称黑客天性是绝对独立于他们工作的特定领域的。但在这份文档中，我们将集中书写在软件黑客的技术和态度，以及发明了“黑客”一词的、以共享为特征的文化传统。 有另外一群人大声嚷嚷着自己是黑客，但他们根本不是。他们主要由青少年男性构成，是一些蓄意破坏计算机和电话系统的人。真正的黑客把这些人叫做 “骇客”(cracker)，并不屑与之为伍。黑客们通常认为他们是一群懒散、没有责任心、而且不是很聪明的人。会通过热接线发动汽车并不意味着你是一个汽车工程师。一样的道理，会破坏安全也不意味着你是一名黑客，不幸的是，很多记者和作家往往错把“骇客”当成黑客；这种做法一直使真正的黑客感到恼火。 根本的区别是：黑客搞建设，骇客搞破坏。 如果你想成为一名黑客，请接着读下去。如果你想做一个骇客，就去读 alt.2600 新闻组吧，顺便准备好去蹲个五到十年的监狱，而且最终你会意识到你并不像自己想象的那么聪明。 关于骇客，我能说的只有这些。 黑客的态度 这个世界充满了令人着迷的问题等着我们解决。 一个问题不应该被解决两次。 无聊和乏味的工作是罪恶。 崇尚自由。 态度不能替代能力。 黑客们解决问题，建设事物，同时他们信仰自由和无私的双向帮助。 要想作为一名黑客被社群认同，你需要体现出自己已经具备了这种态度。而要体现出这种态度，你就得真正相信和赞同这种态度。 但是，如果你认为培养黑客态度只是进入黑客文化圈的敲门砖，那就大错特错了。这种态度将有助于有助于你的学习，并且能为你提供源源不断的动力，所以它对你而言是至关重要的。和所有创造性的艺术一样，成为大师的最有效方法，就是模仿大师的精神——智力上的模仿还不够，还要从感情上进行模仿。 或者正如下面这首现代的禅诗讲的： 修行之道： 关注大师的言行， 跟随大师的举动， 和大师一并修行， 领会大师的意境， 成为真正的大师。 所以，如果你想成为一名黑客，反复读下面的事情直至你相信它们为止： 1. 这个世界充满了令人着迷的问题等着我们解决。做一名黑客会有很多乐趣，但是这些乐趣需要付出很多努力才能获得。这些努力需要动力。成功的运动员在表演和超越自我极限的时候获得身体上的愉悦，并把这种愉悦作为自己的动力。同样，为了成为一名黑客，你要从 解决问题、磨练技术，以及锻炼智力中得到基本的享受。 如果你不是天性如此，而你又想成为一名黑客，你就要设法成为这样的人。否则你会发现，你的黑客热情会被其他分心的事物吞噬掉——如金钱、性、以及社交圈的认同。 （你必须建立对于 自己学习能力的信念——就算你掌握的知识不足以解决当前的问题，如果你从问题的一小部分下手并从中学习，你将学到足够的知识用来解决下一部分——以此类推，直到整个问题都被你解决为止。） 2. 一个问题不应该被解决两次。有创新能力的大脑是一种宝贵的有限资源。当世界还充满非常多有待解决的有趣的新问题时，它们不应该被浪费在重新发明轮子的事情上。 作为一名黑客，你必须相信其他黑客的思考时间是宝贵的——因此共享信息、解决问题、并发布结果给其他黑客几乎是一种道义，这样其他人就可以去解决新问题，而不用在旧问题上面浪费精力了。 （这并不是在说你有义务把自己所有的作品都免费发布出来，但这样做的黑客能获得大家最大的尊敬。使用黑客技能养家糊口甚至发财致富都没关系，只要你别忘记自己作为一个黑客的责任，不背离黑客群体即可。） 3. 无聊和乏味的工作是罪恶。黑客（以及所有创造力的人们）都不应该被愚蠢的重复性劳动所困扰。重复性劳动浪费了他们解决新问题的时间，而 解决新问题正是黑客最大的价值所在。 这种浪费会伤害到每一个人。无聊和乏味的工作不仅仅是令人不舒服而已，而且本身就是一种罪恶。 作为一个黑客，你必须坚信这点并 尽可能多地将乏味的工作自动化，这不仅是为了你自己，也是为了其他人（尤其是其他黑客们）。 (对此有一个明显的例外。黑客有时为了休息大脑、学习技能、或者别的特别的原因，也会做一些在他人看来是重复性或枯燥的事情。但这是自愿的——只要是有思维能力的人，就不应该被迫做无聊的活儿。） 4. 崇尚自由。黑客们是天生的反权威主义者。任何能向你发号施令的人都可以让你停止解决令你着迷的问题，同时，按照权威主义者的一般思路，他通常会给出一些极端愚昧的理由。因此，不论何处，任何权威主义的做法，只要它影响到了你和其他的黑客，你就要和它斗到底。 （这并非向所有权威挑战。儿童需要监护，罪犯要被看管起来。如果服从命令得到某种东西比起用其他方式得到它更节约时间，黑客可以同意接受某种形式的权威。但这是一个有限度的，斟酌过的的交易；那种权威主义者想要的个人服从是不在考虑范围内的。） 权威主义者喜欢审查和保密。他们不信任自愿的合作和信息的共享——他们只喜欢由他们控制的所谓“合作”。因此，作为一个黑客，你应该对审查、保密，以及使用武力或欺骗去压迫有行为能力的人们的做法有一种本能的敌意。同时你要有为此信念付出的意愿。 5. 态度不能替代能力。作为一名黑客，你必须培养起这些态度。但只具备这些态度并不能使你成为一名黑客，也不能使你成为一个运动健将和摇滚明星。成为一名黑客需要智力、实践、奉献精神、以及辛苦的工作。 因此，你 必须学着忽略态度问题，并尊重各种各样的能力。 黑客们不会为那些装模做样的人浪费时间，但他们却非常尊重能力——尤其是从事黑客工作的能力（虽然有能力总归是好事）。如果能具备少有人能掌握的技能就更好了，当然如果你具备一些急需的技能，而这些技能又需要敏锐的思维、高超的技巧、和专注的精神，那就是再好不过了。 如果你尊重能力，你就会享受到提高自己能力的乐趣——辛苦的工作和奉献将不会是一件苦差事，而是一种紧张的娱乐，这是成为黑客至关重要重要的一点。 黑客的基本技能 学习如何编程。 学习使用开源 Unix 系统。 学会使用万维网以及编写 HTML。 学习英语，如果你的水平不够用的话。 黑客态度重要，但技术更加重要。态度无法替代技术，在你被别的黑客称为黑客之前，你必须掌握一些基本的技术作为你随身携带的工具。 随着新技术的出现和老技术的过时，这个工具包的内容也在不断改变。比如以前机器语言编程也被列在里边，而 HTML 是直到最近才包括进去的。不过现在可以清楚地告诉你包含以下内容： 1. 学习如何编程。这一条无须多说，当然是最基本的黑客技能。如果你还不会任何编程语言，我建议你 从 Python 开始学起。它设计清晰，文档齐全，而且对初学者比较友好。虽然它很适合作为一种入门语言，但它不仅仅只是个玩具；它非常强大、灵活，也适合做大型项目。我在一篇更详细的 Evaluation of Python（译注：Python 试用体验）中有更详细的论述。 Python 网站有很好的入门教程。 我曾经推荐过将 Java 作为初学的语言，但这则批评改变了我的想法（在里边搜索”The Pitfalls of Java as a First Programming Language” 就知道我的意思了）。作为一名黑客，你不能像人们挖苦的一样，“像水管工人一样装电脑”，你必须知道各个部件的工作原理。现在我觉得可能还是学过 C 和 Lisp 后再学 Java 比较好。 有一个大体的规律，就是如果你过于偏重使用一种语言，这种语言一方面会成为你得心应手的工具，另一方面也会阻碍你的学习。有这个问题的不只是编程语言，类似 RubyOnRails、CakePHP、以及 Django 的 web 应用框架也有这个问题，它们只会让你肤浅地懂得一些东西，当你碰到难以解决的问题或者需要调试时，你就可能不知所措了。 如果你想进入正式的编程领域，你将不得不学习 C 语言，它是 Unix 的核心语言。C++ 与 C 非常其他类似；如果你了解其中一种，学习另一种应该不难。但这两种都不适合编程入门者学习。而且事实上，你越避免用C编程，你的工作效率会越高。 C 语言效率极高，而且占用很少的系统资源。不幸的是，C 的高效是通过你手动做很多底层的管理（如内存管理）来达到的。底层代码都很复杂，而且极易出现 bug，你要花很多的时间调试。而现今的计算机速度如此之快，花时间调试程序通常是得不偿失——比较明智的做法是使用一种运行较慢、效率较低，但能大幅节省你的开发时间的语言。因此，还是选择 Python 吧。 其他对黑客而言比较重要的语言包括 Perl 和 LISP。从实用的角度来说，Perl 是值得一学的；它被广泛用于动态网页和系统管理中，因此，即便你从不用Perl 写程序，至少也应该学会读懂 Perl。 许多人使用 Perl 的理由和 我建议你使用 Python 的理由一样，都是为了避免用 C 完成那些不需要 C 高效率的工作。你会需要理解那些工作的代码的。 LISP 值得学习的理由不同——最终掌握了它时你会得到丰富的启迪和经验。 虽然你实际上很少会用到 LISP，但这些经验会使你在以后的日子里成为一个更好的程序员。 当然，实际上你 最好五种都会（Python，Java，C/C++，Perl 和 LISP）。除了是最重要的黑客语言外，它们还代表了截然不同的编程思路和方法，每种都会让你受益非浅。（你可以通过修改 Emacs 编辑器的模式） 单单学习编程语言并不会让你达到黑客的程度，甚至连程序员的程度都难企及——你需要脱离某种编程语言的素服，学习通过编程解决问题的思路。要成为一个真正的黑客，你需要达到几天就能学会一门编程语言的水平，你可以将文档里的信息和你已经掌握的知识结合起来，很快就学会一门编程语言。这意味着你需要先学会机种思路截然不同的语言才行。 编程是一个复杂的技能，我无法给你完整的指南来教会你如何编程，不过我可以告诉你，书本和课程也无法教会你如何编程——很多黑客，或者也许几乎所有的黑客，都是靠自学的。你从书本上学到语言的特点——只是一些皮毛，但要使书面知识成为自身技能，你只能通过实践和虚心向他人学习。因此你 要做的就是 (a) 读代码，(b) 写代码。 Peter Novig 是 Google 公司的顶尖黑客之一，而且是最受欢迎的 AI 课本的一名作者。他写了一篇好文章名叫 Teach Yourself Programming in Ten Years（译注：十年教会自己编程） ，其中的“recipe for programming success”（译注：编程的成功之道）尤其值得一读。 学习编程就象学习自然语言写作一样。最好的做法是读一些大师的名著，试着自己写点东西，再读些，再写点，再读些，再写点……如此往复，直到你的文章具备范文的力量和感觉为止。 以前要找适合阅读的好代码并不容易，因为几乎没有大型程序的源代码能让新手练手。这种状况已经戏剧性地发生变化；开源软件、编程工具、和操作系统（全都由黑客写成）现在已经随处可见。让我们在下一个话题中继续讨论…… 2. 学习使用开源的 Unix 系统。我将假设你已经有一台个人计算机供自己使用了（你可以体会一下这意味着多少东西。早些时候，计算机是如此的昂贵，没有人能买得起。而黑客文化就是在那样的环境下演化来的）。新手们能够朝学习黑客技能迈出的最基本的一步，就是找一版 Linux 或 BSD-Unix，安装在个人电脑上，并且把它跑起来。 没错，这世界上除了Unix还有其他操作系统。但它们都是以二进制形式发布的——你无法读到它的源代码，也不可能修改它。尝试在运行 DOS、Windows、或 MacOS 的机器上学习黑客技术，就象是穿着骑士铠甲学跳舞。 除此之外，Unix 还是 Internet 的操作系统。你可以学会上网却不知道 Unix，但你不了解 Unix 就无法成为一名 Internet 黑客。因此，今天的黑客文化在很大程度上是以 Unix 为核心的。（这点并不总是真的，一些很早的黑客对此一直很不满，但 Unix 和 Internet 之间的联系已是如此之强，就连 Microsoft 这样强力的公司也对此也无可奈何。） 所以, 安装一套 Unix 吧——我个人偏爱 Linux，但还有其他种类共你选择（是的，你可以在同一电脑上同时安装 Linux 和 DOS/Windows)。学习它，运行它，鼓捣它。用它上 Internet。阅读它的源代码。修改它的源代码。你会用到很多优秀的编程工具（包括 C， LISP，Python 及 Perl），这些工具在 Windows 下是做梦都没法得到的。你会觉得乐趣无穷。当你有一天成为大师再回顾初学的日子，你会觉得那时学到的东西可真多。 如果你想了解更多关于学习 Unix 的信息，读一下 The Loginataka（译注：ESR 的另一著作，可以称为黑客大藏经）吧。也许你还想看看 The Art of Unix Programming （译注：Unix 编程艺术，经典著作）。 你可以访问 Linux Online! 网站，这个网站可以帮你起步。你可以从那里下载到Linux，或者更好的办法是找一个本地的 Linux 用户组，让他们帮你安装 Linux。 在这份 HOWTO 文档发布后的前十年里，关于 Linux 我写的是，从新人的观点来看，所有的Linux 发行版都差不多，但在 2006-2007 之间，我们终于有了一个最佳选择： Ubuntu。我们可以说各种Linux 发行版各有千秋，但 Ubuntu 是新人最容易上手的一个发行版。 你可以在 www.bsd.org 找到 BSD Unix 的求助及其他资源。 Linux 有一种被称为 Live CD 的发行方式，这种发行版会从CD 运行起来，而且不会动到你硬盘里的东西，Live CD 是尝试 Linux 的一个不错的方法。由于光驱读写本来就比较慢，Live CD 的速度一般也会比较慢，不过 Live CD 总归是一个能尝试各种可能性而又不过激的方法。 我有写一篇]关于 Unix 和 Internet 基础的入门文章。 对于新手，我以前不鼓励你自己独立安装Linux 或者 BSD，现在这些系统的安装工具已经足够好了，就算对新手来说，独立安装操作系统也不是不可能的事。无论如何，我还是推荐你联系本地的 Linux 用户组，向他们寻求帮助，这会进程更加顺利。 3. 学会使用万维网以及编写 HTML。黑客文化建造的大多东西都在你看不见的地方发挥着作用。这些东西可以帮助工厂、办公室、以及大学正常运转起来，但从表面上很难看到它们对非黑客的普通人的生活的影响。而 Web 是一个大大的例外。就连政客也同意，这个庞大耀眼的黑客玩具正在改变整个世界。就算只是因为这个（还有许多其它的原因），Web 也值得你一学。 这并不是仅仅意味着如何使用浏览器（谁都会），而是要学会如何写 HTML，也就是 Web 的标记语言。如果你不会编程，写HTML会教你一些有助于学习的思考习惯。因此，先完成一个主页。 但仅仅拥有一个主页不能使你成为一名黑客。 Web里充满了各种网页。大多数是毫无意义的、毫无信息量的垃圾——界面时髦的垃圾，不过还是垃圾（更多相关信息访问 The HTML Hell Page）。 要想有价值，你的网页必须有内容——它必须有趣或对其它黑客有帮助。这是下一个话题所涉及的…… 4. 学习英语，如果你的水平不够用的话。作为一个以英语为母语的美国人，我以前很不情愿提到这点，免得被当做一种文化上的帝国主义。但相当多以其他语言为母语的人一直劝我指出这一点，那就是：英语是黑客文化和 Internet 的工作语言，只有懂英语，你才能在黑客社区顺利做事。 大概1991年的时候，我就了解到许多黑客在技术讨论中使用英语，甚至有时他们来自同一种母语也在用英文讨论。在现阶段，英语有着比其他语言丰富得多的技术词汇，因此是一个对于工作来说相当好的工具。基于类似的原因，英文技术书籍的翻译通常都不怎么令人满意。（如果有翻译的话）。 Linus Torvalds 是芬兰人，但他的代码注解是用英语写的（很明显他从没想过其他的可能性）。他流利的英语。是他能够管理全球范围的 Linux 开发人员社区的重要因素。 这是一个值得学习的例子。 就算你的母语是英语，这也无法保证你的语言技能足够达到黑客的标准。如果你的写作文字不通、语法混乱、错字连篇，包括我在内的大部分的黑客都会忽略你的存在。虽然写作马虎不一定意味着思考也马虎，但我们发现两者的关联性还是挺强的——马虎的头脑对我们来说毫无价值，如果你写作能力不够，就好好学习写作吧。 提高自己在黑客圈中的地位 撰写开源软件 帮助测试并调试开源软件 发布有用的信息 帮助维护基础设施的运转 为黑客文化本身服务 和大部分不涉及金钱的文化一样，黑客王国靠声誉运转。你设法解决有趣的问题，但它们到底多有趣，你的解法有多好，是要由那些和你具有同样技术水平，或比你更厉害的人去评判的。 相应地你需要认识到，当你在玩黑客游戏时，你的分数主要是靠其他黑客对你的技术的评价得到的（这就是为什么只有在其它黑客称你为黑客时，你才算得上是一名黑客）。常人的印象里，黑客是一项独来独往的工作，所以上述评价方式并不为众人所知。另一个黑客文化误区是拒绝承认自我或外部评价是一个人的动力，这种想法在 1990 年代末以后就逐渐衰退了，但现在还有人这么认为。这也是让上述评价方式鲜为人知的原因之一。 明确地讲，黑客行为就是人类学家所称的“奉献文化”。在这里你不是凭借你对别人的统治来建立地位和名望，也不是靠美貌，或拥有其他人想要的东西，而是靠你的贡献。尤其是贡献你的时间、你的创造、以及你的技术成果。 要获得其他黑客的尊敬，你可以从下面五种事情着手： 1. 撰写开源软件第一个方法（也是最重要，最传统的方法）是写些被其他黑客认为有趣或有用的程序，并把程序源代码提供给整个黑客文化圈使用。 （过去我们称之为“free software （自由软件）”， 但这却使很多不知 free 的精确含义的人感到困惑。现在我们很多人，根据搜索引擎网页内容分析，至少三分之二的人在使用”open-source software，即“开源软件”这个词）。 黑客领域里最受尊敬的偶像，是那些写了大型的、好用的、用途广泛的软件，并把它们发布出来，使得每人都在使用他软件的人。 但是从历史方面来讲有一点值得一提。虽然黑客们一直认为开源软件的开发者是真正的黑客，但在 1990 年代中期以前，大部分黑客会把自己的主要时间用来撰写闭源软件，直到我 1996 年开始写这篇 HOWTO 时也是如此。但从 1997 年后开源软件进入了主流，而且改变了这一切。以现在的观点来看，“黑客社群”和“开源开发者”是对这一个社群的两种称呼，但值得记住的是，以前这两者的概念并不完全一样。(要了解更多信息，你可以看看 关于黑客、开源、以及自由软件的历史这一节的内容。) 2. 帮助测试并调试开源软件黑客也尊敬那些使用和测试开源软件的人。这个世界并不完美，我们不可避免地要把大多数的开发时间放在调试阶段。这就是为什么任何有头脑的开源代码的作者都会告诉你好的 beta 测试员象红宝石一样珍贵。好的测试者知道如何清楚描述出错症状，很好地定位错误，能忍受快速发布中的 bug，并且乐意配合做一些例行的诊断性工作。一个优秀的测试者可以让一场旷日持久辛苦不堪的调试大战变成一场有益身心的小打小闹。 如果你是个新手，试着找一个你感兴趣的正在开发中的程序，做一个好的 beta 测试员。你会自然地从帮着测试，进步到帮着抓 bug，到最后帮着改程序。你会从中学到很多，而且善因种善果，以后别人也会很乐意帮助你。 3. 发布有用的信息另一件好事是收集整理有用有趣的信息，做成网页或类似 FAQ 的文档，并且让大家都能看到。 技术性 FAQ 的维护者会受到和开源代码的作者一样多的尊敬。 4. 帮助维护基础设施的运转黑客文化（还有互联网工程方面的发展）是靠志愿者推动的。要使Internet能正常工作，就要有大量枯燥的工作不得不去完成——管理邮件列表和新闻组，维护大型软件库，开发 RFC 和其它技术标准等等。 做这类事情的人会得到很多尊敬，因为每人都知道这些事情费时颇多，而又不象编程那样有趣。做这些事情需要奉献精神。 5. 为黑客文化本身服务最后，你可以为这个文化本身做宣传（例如像我这样，写一个“如何成为黑客”的教程 :-) ）这并不要求在你已经在这个圈子呆了很久，因以上四点中的某点而出名，有一定声誉后才能去做。 黑客文化没有领袖，这点是确认无疑的。但黑客圈里确实有些文化英雄、部落长者、史学家、还有发言人。如果你在这圈里呆足够长时间，你也许也能成为其中之一。 记住：黑客们不相信他们的部落长者的自夸，因此过分追求这种名誉是危险的。与其奋力追求，不如先摆正自己的位置，等它自己落到你的手中——那时则要做到谦虚和优雅。 ##黑客和书呆子(Nerd)的联系 和大家普遍认为的相反，并不是只有书呆子才能成为一名黑客。但它确实有帮助，而且许多黑客事实上是书呆子。做一个深居简出的人有助于你集中精力进行十分重要的事情，如思考和编程。 因此，很多黑客都接受了“geek（奇客）”这个标签，并把它作为骄傲的奖章——这是宣布他们独立于主流社会期望的一种方式（这个标签也是他们喜欢科幻小说和策略型游戏的标记，而这些也是很多黑客喜欢的东西）。1990 年代更多用的称呼是“nerd（书呆子）”，那时“nerd”只带点轻微的贬义，而“geek”则是地地道道的蔑称，而在 2000 年以后，这两者逐渐调转过来了，至少再美国的大众文化中是这样。而到了现在，甚至在非技术人群里，也有不少以 geek 精神为傲的文化团体。 如果你能集中足够的精力做好黑客工作同时还能有正常的生活，这是件好事。现在要做到这一点比我在 1970 年代还是新手的时候要容易的多；如今主流文化对技术怪人要友善得多。甚至有越来越多的人意识到黑客通常是很好的恋人和配偶的材料。 如果你因为生活上不如意而迷上做黑客，那也没什么——至少你不会分神了。也许你以后还能找到自己的生活。 向黑客的格调靠拢重申一下，要做一名黑客，你必须深入体验黑客精神。就算你不在计算机边上，你仍然有很多对黑客工作有帮助的事情可做。它们并不能替代真正的编程（没有什么能替代编程），但很多黑客都那么做，并感到它们与黑客的本质存在某些基本的连系。 学会用母语流畅地写作。尽管很多人认为程序员写不出好文章，但是有相当数量的黑客（包括所有我知道的最棒的黑客）都是很有能力的写手。 阅读科幻小说。参加科幻小说讨论会。（这是一个认识黑客和准黑客的好方法） 学习一种武术。武术中需要的精神自律能力和黑客在这方面的需求非常相似。黑中最受欢迎的武术是来自亚洲的空手格斗类武术，例如跆拳道、空手道、武术、合气道、柔术等。西式击剑和亚洲剑术也有不少的跟随者。1990 年后期以来，在可以合法使用枪支的地方，射击受欢迎的程度也越来越高了。大部分黑客喜欢的武术类型都是那些强调精神的自律，放松的意识，以及意念的控制，而不仅仅是单纯的力量、运动精神、以及身体的强健。 实实在在学习一种冥想修炼。多年以来黑客中最受欢迎的形式是参禅。（很重要的一点是，参禅和宗教可以说是独立的，你不需要接受一种新宗教，或者放弃现有的宗教信仰，就能做参禅的修炼。其他的形式也许也管用，但注意一定要挑那些靠谱的，不需要你相信不着边际的事物的冥想方式来演练。 提高自己对双关语和文字游戏的鉴赏能力。如果这些事情有很多你已经在做了，那你可能是天生做黑客的材料。至于为什么偏偏是这些事情，原因并不完全清楚，但它们都涉及用到左－右脑能力的综合，这似乎是关键所在（黑客们既需要清晰的逻辑思维，有时又需要偏离逻辑跳出问题的表象）。 最后，还有一些不要去做的事情。 不要使用愚蠢的，哗众取宠的ID或昵称。 不要卷入 Usenet（或任何其他地方）的骂战。 不要自称为“cyberpunk（网络朋克）”，也不要浪费时间和那些人打交道。 不要让你的 email 或者帖子中充满错误的拼写和语法。以上的事情只会为你招来嘲笑。黑客们个个记忆超群——你将需要数年的时间让他们忘记你犯下的错误。 网名的问题值得深思。将身份隐藏在虚假的名字后是骇客、软件破解者、及其他低等生物幼稚愚蠢的行为。黑客不会做这些事；他们对他们所作的感到骄傲，而且乐于人们将作品与他们的真名相联系。因此, 如果你现在还在使用假名，那就放弃它吧。在黑客文化里假名是失败者的标记。 关于黑客、开源、以及自由软件的历史1996 年我开始写这篇 HOWTO，那时候的大环境和现在很不一样。这里会给你简单介绍一下相关的历史变迁，这样大致可以澄清一下开源软件、自由软件、以及 Linux 和黑客圈的关系。如果你对这些不感兴趣，你可以直接跳过这一节，继续读下面的 FAQ。 我在这里所描述黑客精神和社会远远早于1990 Linux 出现的时候，我第一次涉足黑客圈是 1976 年，而究其根源则可追溯到20世纪60年代初。但在 Linux 出现之前，大多数黑客使用的操作系统要么是私有的商业版本，要么是自己开发的未得到广泛使用的系统（例如麻省理工学院的 ITS 系统）。虽然那时也有人想要改变这种状况，但他们的努力影响范围相当有限，充其量仅在某个黑客社区有少数忠实用户而已。 现在所谓“开源”历史和黑客社区的历史几乎一样长，但直到 1985 年前，它只是一种没有固定称谓的习惯做法，而不是一套有理论做后盾，有宣言做前锋的自觉运动。这种状态在 1985年结束了，长老级黑客 Richard Stallman（也被称为“RMS”）将其命名为“自由软件 (Free Software)”。这种命名也是一种宣言的方式，不过大多数黑客社区都不接收这种包含明显思想烙印的标签。因此而大多数现有的黑客社区从来没有接受。结果，“自由软件”这一标签被黑客社群中声音较大的少数人（尤其是 BSD Unix 的相关人士）拒绝掉了，而剩下的大部分人（包括我）虽然也有保留意见，可也还是沿用了这一称谓。 尽管很多人存在保留意见，RMS 的“自由软件”的大旗也一直举到了 1990 年代中期。直到 Liunx 崛起时它才受到了重大挑战。Linux 给了的开源开发者一个新的自然归宿，很多项目都已我们现称的开源的方式由 Unix 移植到了 Linux 系统中。Linux 的社区也得到了爆炸性增长，成为了一个比以前黑客文化更为庞大，并且异质化的新的群体。RMS 曾今尝试将这一社群也归并到他的“自由软件运动”大旗下，但终究没有成功，原因可以归于 Linux 社区的样性，以及 Linus Torvalds 本人的质疑。Torvalds 公开拒绝了 RMS 的自由软件思想，但还是沿用了“自由软件”这一术语，这也引来了很多年轻黑客的效仿。 1996年，当我第一次发表这篇 HOWTO 的时候，黑客社团正在围绕着 Linux 和其它几个开源操作系统（尤其是 BSD Unix 的衍生系统）进行着快速的重组。几十年来围绕着闭源系统进行闭源开发的方式还没有开始淡出集体记忆，但在大家看来，这似乎已经是死去的历史了。越来越多的黑客都已经开始注重自己在开源项目（例如 Linux、Apache 等）上的贡献，并将这些贡献当做自己的成就。 然而在那个时候“开源”这一名词还没有出现。这个名词是 1998 年初才开始出现的，而在出现的半年内，大部分的黑客社区就接受了这一名词，只有少数不接受这一概念的人还在坚持使用“自由软件”这一名词。1998 年以后，或者更准确地说是 2003 年以后，所谓的“hacking” 和 “开源（自由）软件开发”的含义已经非常接近了。从今天的眼光来看，这种区分已经没有意义了，看趋势，这个现状将来也不大可能有多大的改变。 不管怎样，这段变更的历史还是值得记住的。 其它资源Paul Graham 写了一篇 Great Hackers，还有 Undergraduation 一篇，里边有充满智慧的言论。 Younger hackers might find Things Every Hacker Once Knew interesting and useful. 我还写过一篇 A Brief History Of Hackerdom （译注：黑客文化简史）。 我写了一本 The Cathedral and the Bazaar（译注：大教堂与市集），对于 Linux 及开放源代码文化现象有详细的解释。这种现象在我的另一篇 Homesteading the Noosphere （译注：开拓智域）中还有更直接的阐述。 Rick Moen 写了一份很好的关于 how to run a Linux user group（译注：如何运营Linux 用户组）的文档。 我和Rick Moen合作完成了另一份关于 How To Ask Smart Questions（译注：提问的智慧）的文章，可以让在寻求帮助时得到事半功倍的效果。 如果你想知道 PC、UNIX 及 Internet 基本概念和工作原理，参考 The Unix and Internet Fundamentals HOWTO。 当你发布软件或者补丁的时候，请遵照 Software Release Practice HOWTO 去做。 如果你对禅诗感兴趣，也许你还喜欢看这篇 Rootless Root: The Unix Koans of Master Foo FAQ（常见问题解答）怎样才能知道自己已经是一名够格的黑客？你能教我做黑客吗？那么，我要如何开始？我得什么时候开始学？现在会不会太迟了？要学多久才能学会黑客技能？Visual Basic 是好的入门语言吗？你能帮我“黑”掉一个站点吗？或者教我怎么黑它？我怎么样才能得到别人帐号的密码？我如何入侵/查看/监视别人的 Email？我如何才能在IRC聊天室里偷到频道 op 的特权？我被黑了。你能帮我避免以后再被攻击吗？我的 Windows 软件出现问题了。你能帮我吗？我在哪里能找到可以与之交流的真正的黑客？你能推荐一些有关黑客的好书吗？成为一名黑客我需要擅长数学吗？我该从那种语言学起？我需要什么样的机器配置？我想贡献社区。你可以帮我选一个问题让我下手吗？我得因此憎恨和反对 Microsoft 吗？开放源代码软件不会使程序员丢饭碗吗？我要如何开始？哪里有免费的Unix？ 怎样才能知道自己已经是一名够格的黑客？你可以问自己下面三个问题： 你能流利地读写代码吗？ 你认同黑客社群的目的和价值吗？ 黑客社群里有没有资深成员称呼你为黑客呢？ 如果你对这三个问题的答案都是“是”的话，你已经是一名黑客了。如果你只满足其中两项，那就说明你还不够格。 第一个问题是关于技能的。如果你已经符合本文前面提到的最低需求的话，你也算过关，不过如果你发布过为数不少的开源代码并被社群接受，那你就算满分过关了。 第二个问题是关于态度的。如果黑客精神的五项基本原则对你来说能有共鸣，而且已经是你处事的方式，你就算过关一半了。这算靠里的一半，靠外的一半和你在黑客社区长期项目上的投入和关联程度有关。 这里列出了一些项目的不完全列表供你参考：Linux 的改进和用户群扩大对你来说是否重要？你对于自由软件精神是否充满激情？你对于垄断是否有敌意？你是否相信计算机这种工具会让增加世界财富，让这个世界更富有人道主义？ 不过值得注意的一点是，黑客社群有一些特有的政治倾向，其中两条，一条是保卫言论自由权，一种是抵御所谓“知识产权”对于开源社区的侵害。实践这两条的是一些民间组织，例如电子前沿基金会（Electronic Frontier Foundation）就是其中之一。不过虽然如此，黑客们对于有任何明确政治目的的团体都是心怀戒备的，因为我们已经从各种经验教训中学到一点：这些活动只会分裂黑客社团，并让黑客们分心。如果有人以黑客精神为名组织一场首都大游行，那他就完全没有弄明白这点。真正的应对方式也许应该是“闭上嘴巴，给他们看代码”。 第三个问题有点循环递归的味道。在“什么是黑客”一节我已经讲过，作为一名黑客的意义在于参与某个黑客社群，也就是社交网络的一个亚文化团体，作为内部的贡献成员以及外部的宣传者积极活动。和很久以前相比，黑客群体现在的团结意识和自我意识已经增强了很多。过去三十年来，随着互联网的发展，社交网络逐渐开始发挥举足轻重的作用，而黑客的亚文化团体也更加容易发展和维护了。这种变革的明显一个有代表性的现象是：有的黑客社群现在都有自己专门的文化衫了。 研究社交网络的社会学家把黑客文化归为“看不见的大学”，而且注意到这些网络社交圈还有所谓的“看门人”——其中的一些核心成员，他们有一定的权威，可以准新成员的进入。所谓的“看不见的大学”本来就是一个松散的非正式组织，所以这些“看门人”也只是这门称呼而已。但不是每个黑客都是“看门人”，这是每个黑客都深刻明白的一点。“看门人”需要有一定的资历和成就，究竟要到什么程度很难讲，但一旦有这样的人出现，每一个黑客都能辨识出来。 你能教我做黑客吗？自从第一次发布这份文档，我每周都会收到一些请求，（频繁的话一天几封）要我“教会他们做黑客”。遗憾的是，我 没有时间和精力来做这个；我自己的黑客项目，及我作为一个开放源代码倡导者 的四处奔波已经占用了我110%的时间。 即便我想教你，黑客也依然基本上是一项自行修炼的的态度和技术。 当真正的黑客想帮助你的时候，如果你乞求他们一汤匙一汤匙“喂”你的话，你会发现他们不会尊重你。 先去学一些东西。显示你在尝试，你能靠自己去学习。然后再去向你遇到的黑客请教特殊的问题。 如果你发E-mail给一位黑客寻求他的帮助，这是两件首要记住的事情。 第一，写出来的文字显得懒且粗心的人通常非常懒于思考且非常马大哈，不能成为好黑客——因此注意拼写正确，使用正确的语法及发音，否则你可能会无人理睬。 第二，不要试图要求回复到一个ISP帐号，而那个帐号与你 的发信地址不同。这样做的人一般是使用盗用帐号，我们对于回报或者帮助窃贼不感兴趣。 那么，我要如何开始？对你而言最佳的入门方式也许是去参加 LUG（Linux用户组）的聚会。 你可以找到在 LDP 的综合 Linux 信息页面上找到类似的组织；也许有一个在你家附近的，而且非常有可能与一所大学或学校挂钩。如果你提出要求，LUG 成员兴许会给你一套 Linux，当然此后会帮你安装并带你入门。 我得什么时候开始学？现在会不会太迟了？你有动力学习的时候就是好时候。大多数人看来都是在15－20岁之间开始感兴趣的，但据我所知，在此年龄段之外的例外也是有的。 要学多久才能学会黑客技能？这取决于你的聪明程度和努力程度。对于大多数人，只要足够专注，就能在 18 个月到 2 年之间学会一套令人尊敬的技能。 但是，不要以为这样就够了；如果你是一个真正的黑客，你要用你的余生来学习和完善你的技术。 Visual Basic 是好的入门语言吗？既然你问了这个问题，那你肯定是想在 Microsoft Windows 操作系统下学习黑客技能。这本身就不是一个好主意。我前面讲过在 Windows 下 hack 就跟穿着骑士铠甲跳舞一样，我不是在开玩笑。别走这条路，Windows 是一个很低劣的 hack 环境，而且一直如此。 Visual Basic 有一个特征性问题，就是它不可以被移植到其他平台。虽然也有些 Visual Basic 开源实现的雏形，但实现的只是 ECMA 标准的一个很小的子集。在 Windows 下大部分类库的知识产权都是 Microsoft 独家所有，如果你不是及其小心的话，你的代码将只能在 Microsoft 支持的平台上使用。 如果你不打算从 Unix 起步，那你也有更好的语言可选，而且类库质量还更高，例如 Python 就是其中之一 和其他的 Basic 类语言一样，Visual Basic 这门编程语言的设计也很糟糕，它会教你一些坏的变成习惯。你就别问我细节了，这可是罄竹难书。还是去学一门设计优良的语言吧。其中一个坏习惯是让你依赖于单一厂商的函数库、控件及开发工具。 一般而言，任何不能够支持至少 Linux 或者某一种 BSD，或其不能支持至少三种以上操作系统的语言，都是一种不适合应付黑客工作的语言。 你能帮我“黑”掉一个站点吗？或者教我怎么黑它？No。任何读完这份 FAQ 后还问这个问题的人，都是无可救药的蠢材，即使有时间指教我也不会理睬。任何发给我的此类电子邮件都会被忽略或被痛骂一顿。 我怎么样才能得到别人帐号的密码？这是骇客行为。滚得远远的，白痴。 我如何入侵/查看/监视别人的 Email？这是骇客行为。在我面前消失，智障。 我如何才能在IRC聊天室里偷到频道 op 的特权？这是骇客行为。滚开，笨蛋。 我被黑了。你能帮我避免以后再被攻击吗？不行。目前为止，每次问我这个问题的，都是一些运行 Microsoft Windows 的菜鸟。不可能有效的保护 Windows 系统免受骇客攻击；太多代码和架构的缺陷使保护 Windows 的努力有如隔靴搔痒。唯一可靠的预防来自转移到 Linux 或其他设计得至少足够安全的系统。 我的 Windows 软件出现问题了。你能帮我吗？当然。打开 DOS 命令行输入“format c:”。你遇到的任何问题将会在几分钟之内消失。 我在哪里能找到可以与之交流的真正的黑客？最佳办法是在你附近找一个Unix或Linux的用户组，参加他们的聚会。（你可以在 ibiblio 的 LDP 站点找到一些用户组的链接。） （我过去曾说过不能在IRC上找到真正的黑客，但我发觉现在情况有所改变。显然一些真正的黑客的社区像 GIMP 及 Perl，也有IRC频道了。） 你能推荐一些有关黑客的好书吗？我维护着一份 Linux Reading List HOWTO，也许你会觉得有用。The Loginataka 也大致值得一读。 关于Python的介绍，请访问在Python站点上的入门教程。 成为一名黑客我需要擅长数学吗？不用。黑客道很少使用常规的数学或算术，不过你绝对 需要能逻辑性地思考和进行精密的推理。 尤其是你不会用到微积分或电路分析（我们把这些留给电子工程师们 :-)）。有限数学中的一些grounding （包括布尔代数，集合论，组合数学，图论）的背景知识会对你有所帮助。 更重要的一点：你要有逻辑思维能力，能够以数学家的方式追溯因果。虽然大部分的数学知识对你可能没什么用处，但数学思维的能力对你来说是极其重要的。如果你缺乏这方面的智慧，要做一名黑客恐怕是无望了。如果你缺乏这方面的训练，还是尽早开始吧。 我该从那种语言学起？如果你还没学过XHTML（HTML最新的表现形式）的话，就从它开始吧。市面上有一大堆的封面精美，宣传得天花乱坠的HTML 书籍，不幸的是质量优秀的几近于无。我最喜欢的是 HTML: The Definitive Guide。 但HTML 不是一种完整的编程语言。当你准备开始编程时，我推荐从 Python 起步。 你会听到一大群人推荐 Perl，但是 Perl 要难学得多，而且（以我之见）设计得不是很好。 C 确实重要，但它也比 Python 或 Perl 难多了。不要尝试先学 C。 Windows用户注意：不要满足于 Visual Basic。它会教给你坏习惯，而且它不可以跨平台移植，只能在Windows下运行。因此还是敬而远之为好。 我需要什么样的机器配置？过去个人电脑能力相当不足并且内存很小，这给黑客的学习过程设置了人为的障碍。不过 1990 中期以后就不是这样了；任何一台 Intel 486DX50 以上配置的机器都有足够的能力进行开发工作、运行 X 系统、以及进行 Internet 通讯。而且你买到的市面上最小的硬盘都大得足够你使用了。 选择用来学习的机器时重要的一点是注意配件是否是Linux兼容的（或BSD兼容，如果你选择 BSD 的话）。和刚才提到的一样，大多数现在的机器都是符合的；唯一值得注意的区域在于 modem 和打印机；有些具备为Windows设计的配件的机器不会在Linux下工作。 你可以查看这份 Linux Hardware Compatibility FAQ。 我想贡献社区。你可以帮我选一个问题让我下手吗？不行，因为我不知道你的兴趣和擅长领域在哪里。如果你没有内在动力，你就很难坚持下去，所以说，别人只给你的路是行不通的。 试试这么做吧。在 Freshmeat 网站观察几天，看看里边的项目更新，如果你看到一个看上去很酷而且你也很感兴趣的项目，就加入吧。 我得因此憎恨和反对 Microsoft 吗？不，你不必如此。不是因为Microsoft不令人讨厌，而是因为黑客文化早在 Microsoft 出现之前就存在了，且将在 Microsoft 成为历史后依然存在。 你耗费在憎恨 Microsoft 的任何力气不如花在爱你的技术上。写好的代码——那会相当有效地打击 Microsoft 又不会让你得到恶报应。 开放源代码软件不会使程序员丢饭碗吗？目前看起来不太可能，开放源代码软件产业似乎创造了更多的就业机会而不是减少就业机会。如果写一个程序比起不写来是纯经济收益的话，那么在写完后，程序员应该得到报酬不管程序是否是开放源代码。并且，无论写出多么“免费自由”的软件，都存在更多对新的，定制的软件的需求。我有这方面更多的论述，放在放源代码]网站资料中。 我要如何开始？哪里有免费的Unix？在本份文档的某个地方我已经提到过何处可以得到最常用的免费 Unix。要做一名黑客，你需要自己找到激励和动力，还要有自学的能力。现在就开始努力吧…… How To Become A HackerEric Steven Raymond Thyrsus Enterprises &lt;esr@thyrsus.com&gt; Copyright © 2001 Eric S. Raymond Revision HistoryRevision 1.50 19 July 2015 esrAdded link to “Let’s Go Larval”.Revision 1.49 21 November 2014 esrAdded link to “How To Learn Hacking”.Revision 1.48 19 June 2014 esrfreshmeat/freecode is dead, alas.Revision 1.47 20 May 2014 esrFix up various stale links. Join a hackerspace!Revision 1.46 25 Sep 2013 esrAdd micropatronage explanation and gittip link. Why you should not ask me for advice on how to get started.Revision 1.45 12 May 2013 esrOpen Solaris isn’t, and Unity screwed the pooch.Revision 1.44 20 May 2012 esrUpdated the critique of Java.Revision 1.43 07 Feb 2011 esrPython passed Perl in popularity in 2010.Revision 1.42 22 Oct 2010 esrAdded “Historical note”.Revision 1.40 3 Nov 2008 esrLink fixes.Revision 1.39 14 Aug 2008 esrLink fixes.Revision 1.38 8 Jan 2008 esrDeprecate Java as a language to learn early.Revision 1.37 4 Oct 2007 esrRecommend Ubuntu as a Unix distro for newbies.Table of Contents Why This Document?What Is a Hacker?The Hacker Attitude The world is full of fascinating problems waiting to be solved. No problem should ever have to be solved twice. Boredom and drudgery are evil. Freedom is good. Attitude is no substitute for competence.Basic Hacking Skills Learn how to program. Get one of the open-source Unixes and learn to use and run it. Learn how to use the World Wide Web and write HTML. If you don’t have functional English, learn it.Status in the Hacker Culture Write open-source software Help test and debug open-source software Publish useful information Help keep the infrastructure working Serve the hacker culture itselfThe Hacker/Nerd ConnectionPoints For StyleHistorical Note: Hacking, Open Source, and Free SoftwareOther ResourcesFrequently Asked Questions Why This Document? As editor of the Jargon File and author of a few other well-known documents of similar nature, I often get email requests from enthusiastic network newbies asking (in effect) “how can I learn to be a wizardly hacker?”. Back in 1996 I noticed that there didn’t seem to be any other FAQs or web documents that addressed this vital question, so I started this one. A lot of hackers now consider it definitive, and I suppose that means it is. Still, I don’t claim to be the exclusive authority on this topic; if you don’t like what you read here, write your own. If you are reading a snapshot of this document offline, the current version lives at http://catb.org/~esr/faqs/hacker-howto.html. Note: there is a list of Frequently Asked Questions at the end of this document. Please read these—twice—before mailing me any questions about this document. Numerous translations of this document are available: Arabic Belorussian Bulgarian Chinese, Danish Dutch Estonian French German, Greek Italian Hebrew, Japanese Lithuanian Norwegian, Persian Polish Portuguese (Brazilian), Romanian Spanish, Turkish, and Swedish. Note that since this document changes occasionally, they may be out of date to varying degrees. The five-dots-in-nine-squares diagram that decorates this document is called a glider. It is a simple pattern with some surprising properties in a mathematical simulation called Life that has fascinated hackers for many years. I think it makes a good visual emblem for what hackers are like — abstract, at first a bit mysterious-seeming, but a gateway to a whole world with an intricate logic of its own. Read more about the glider emblem here. If you find this document valuable, please support me on Patreon. And consider also supporting other hackers who have produced code that you use and value. Lots of small but continuing donations add up quickly, and can free the people who have given you gifts of their labor to create more value. What Is a Hacker? The Jargon File contains a bunch of definitions of the term ‘hacker’, most having to do with technical adeptness and a delight in solving problems and overcoming limits. If you want to know how to become a hacker, though, only two are really relevant. There is a community, a shared culture, of expert programmers and networking wizards that traces its history back through decades to the first time-sharing minicomputers and the earliest ARPAnet experiments. The members of this culture originated the term ‘hacker’. Hackers built the Internet. Hackers made the Unix operating system what it is today. Hackers make the World Wide Web work. If you are part of this culture, if you have contributed to it and other people in it know who you are and call you a hacker, you’re a hacker. The hacker mind-set is not confined to this software-hacker culture. There are people who apply the hacker attitude to other things, like electronics or music — actually, you can find it at the highest levels of any science or art. Software hackers recognize these kindred spirits elsewhere and may call them ‘hackers’ too — and some claim that the hacker nature is really independent of the particular medium the hacker works in. But in the rest of this document we will focus on the skills and attitudes of software hackers, and the traditions of the shared culture that originated the term ‘hacker’. There is another group of people who loudly call themselves hackers, but aren’t. These are people (mainly adolescent males) who get a kick out of breaking into computers and phreaking the phone system. Real hackers call these people ‘crackers’ and want nothing to do with them. Real hackers mostly think crackers are lazy, irresponsible, and not very bright, and object that being able to break security doesn’t make you a hacker any more than being able to hotwire cars makes you an automotive engineer. Unfortunately, many journalists and writers have been fooled into using the word ‘hacker’ to describe crackers; this irritates real hackers no end. The basic difference is this: hackers build things, crackers break them. If you want to be a hacker, keep reading. If you want to be a cracker, go read the alt.2600 newsgroup and get ready to do five to ten in the slammer after finding out you aren’t as smart as you think you are. And that’s all I’m going to say about crackers. The Hacker Attitude The world is full of fascinating problems waiting to be solved. No problem should ever have to be solved twice. Boredom and drudgery are evil. Freedom is good. Attitude is no substitute for competence.Hackers solve problems and build things, and they believe in freedom and voluntary mutual help. To be accepted as a hacker, you have to behave as though you have this kind of attitude yourself. And to behave as though you have the attitude, you have to really believe the attitude. But if you think of cultivating hacker attitudes as just a way to gain acceptance in the culture, you’ll miss the point. Becoming the kind of person who believes these things is important for you — for helping you learn and keeping you motivated. As with all creative arts, the most effective way to become a master is to imitate the mind-set of masters — not just intellectually but emotionally as well. Or, as the following modern Zen poem has it: To follow the path: look to the master, follow the master, walk with the master, see through the master, become the master. So, if you want to be a hacker, repeat the following things until you believe them: The world is full of fascinating problems waiting to be solved. Being a hacker is lots of fun, but it’s a kind of fun that takes lots of effort. The effort takes motivation. Successful athletes get their motivation from a kind of physical delight in making their bodies perform, in pushing themselves past their own physical limits. Similarly, to be a hacker you have to get a basic thrill from solving problems, sharpening your skills, and exercising your intelligence. If you aren’t the kind of person that feels this way naturally, you’ll need to become one in order to make it as a hacker. Otherwise you’ll find your hacking energy is sapped by distractions like sex, money, and social approval. (You also have to develop a kind of faith in your own learning capacity — a belief that even though you may not know all of what you need to solve a problem, if you tackle just a piece of it and learn from that, you’ll learn enough to solve the next piece — and so on, until you’re done.) No problem should ever have to be solved twice. Creative brains are a valuable, limited resource. They shouldn’t be wasted on re-inventing the wheel when there are so many fascinating new problems waiting out there. To behave like a hacker, you have to believe that the thinking time of other hackers is precious — so much so that it’s almost a moral duty for you to share information, solve problems and then give the solutions away just so other hackers can solve new problems instead of having to perpetually re-address old ones. Note, however, that “No problem should ever have to be solved twice.” does not imply that you have to consider all existing solutions sacred, or that there is only one right solution to any given problem. Often, we learn a lot about the problem that we didn’t know before by studying the first cut at a solution. It’s OK, and often necessary, to decide that we can do better. What’s not OK is artificial technical, legal, or institutional barriers (like closed-source code) that prevent a good solution from being re-used and force people to re-invent wheels. (You don’t have to believe that you’re obligated to give all your creative product away, though the hackers that do are the ones that get most respect from other hackers. It’s consistent with hacker values to sell enough of it to keep you in food and rent and computers. It’s fine to use your hacking skills to support a family or even get rich, as long as you don’t forget your loyalty to your art and your fellow hackers while doing it.) Boredom and drudgery are evil. Hackers (and creative people in general) should never be bored or have to drudge at stupid repetitive work, because when this happens it means they aren’t doing what only they can do — solve new problems. This wastefulness hurts everybody. Therefore boredom and drudgery are not just unpleasant but actually evil. To behave like a hacker, you have to believe this enough to want to automate away the boring bits as much as possible, not just for yourself but for everybody else (especially other hackers). (There is one apparent exception to this. Hackers will sometimes do things that may seem repetitive or boring to an observer as a mind-clearing exercise, or in order to acquire a skill or have some particular kind of experience you can’t have otherwise. But this is by choice — nobody who can think should ever be forced into a situation that bores them.) Freedom is good. Hackers are naturally anti-authoritarian. Anyone who can give you orders can stop you from solving whatever problem you’re being fascinated by — and, given the way authoritarian minds work, will generally find some appallingly stupid reason to do so. So the authoritarian attitude has to be fought wherever you find it, lest it smother you and other hackers. (This isn’t the same as fighting all authority. Children need to be guided and criminals restrained. A hacker may agree to accept some kinds of authority in order to get something he wants more than the time he spends following orders. But that’s a limited, conscious bargain; the kind of personal surrender authoritarians want is not on offer.) Authoritarians thrive on censorship and secrecy. And they distrust voluntary cooperation and information-sharing — they only like ‘cooperation’ that they control. So to behave like a hacker, you have to develop an instinctive hostility to censorship, secrecy, and the use of force or deception to compel responsible adults. And you have to be willing to act on that belief. Attitude is no substitute for competence. To be a hacker, you have to develop some of these attitudes. But copping an attitude alone won’t make you a hacker, any more than it will make you a champion athlete or a rock star. Becoming a hacker will take intelligence, practice, dedication, and hard work. Therefore, you have to learn to distrust attitude and respect competence of every kind. Hackers won’t let posers waste their time, but they worship competence — especially competence at hacking, but competence at anything is valued. Competence at demanding skills that few can master is especially good, and competence at demanding skills that involve mental acuteness, craft, and concentration is best. If you revere competence, you’ll enjoy developing it in yourself — the hard work and dedication will become a kind of intense play rather than drudgery. That attitude is vital to becoming a hacker. Basic Hacking Skills Learn how to program. Get one of the open-source Unixes and learn to use and run it. Learn how to use the World Wide Web and write HTML. If you don’t have functional English, learn it.The hacker attitude is vital, but skills are even more vital. Attitude is no substitute for competence, and there’s a certain basic toolkit of skills which you have to have before any hacker will dream of calling you one. This toolkit changes slowly over time as technology creates new skills and makes old ones obsolete. For example, it used to include programming in machine language, and didn’t until recently involve HTML. But right now it pretty clearly includes the following: Learn how to program. This, of course, is the fundamental hacking skill. If you don’t know any computer languages, I recommend starting with Python. It is cleanly designed, well documented, and relatively kind to beginners. Despite being a good first language, it is not just a toy; it is very powerful and flexible and well suited for large projects. I have written a more detailed evaluation of Python. Good tutorials are available at the Python web site; there’s an excellent third-party one at Computer Science Circles. I used to recommend Java as a good language to learn early, but this critique has changed my mind (search for “The Pitfalls of Java as a First Programming Language” within it). A hacker cannot, as they devastatingly put it “approach problem-solving like a plumber in a hardware store”; you have to know what the components actually do. Now I think it is probably best to learn C and Lisp first, then Java. There is perhaps a more general point here. If a language does too much for you, it may be simultaneously a good tool for production and a bad one for learning. It’s not only languages that have this problem; web application frameworks like RubyOnRails, CakePHP, Django may make it too easy to reach a superficial sort of understanding that will leave you without resources when you have to tackle a hard problem, or even just debug the solution to an easy one. If you get into serious programming, you will have to learn C, the core language of Unix. C++ is very closely related to C; if you know one, learning the other will not be difficult. Neither language is a good one to try learning as your first, however. And, actually, the more you can avoid programming in C the more productive you will be. C is very efficient, and very sparing of your machine’s resources. Unfortunately, C gets that efficiency by requiring you to do a lot of low-level management of resources (like memory) by hand. All that low-level code is complex and bug-prone, and will soak up huge amounts of your time on debugging. With today’s machines as powerful as they are, this is usually a bad tradeoff — it’s smarter to use a language that uses the machine’s time less efficiently, but your time much more efficiently. Thus, Python. Other languages of particular importance to hackers include Perl and LISP. Perl is worth learning for practical reasons; it’s very widely used for active web pages and system administration, so that even if you never write Perl you should learn to read it. Many people use Perl in the way I suggest you should use Python, to avoid C programming on jobs that don’t require C’s machine efficiency. You will need to be able to understand their code. LISP is worth learning for a different reason — the profound enlightenment experience you will have when you finally get it. That experience will make you a better programmer for the rest of your days, even if you never actually use LISP itself a lot. (You can get some beginning experience with LISP fairly easily by writing and modifying editing modes for the Emacs text editor, or Script-Fu plugins for the GIMP.) It’s best, actually, to learn all five of Python, C/C++, Java, Perl, and LISP. Besides being the most important hacking languages, they represent very different approaches to programming, and each will educate you in valuable ways. But be aware that you won’t reach the skill level of a hacker or even merely a programmer simply by accumulating languages — you need to learn how to think about programming problems in a general way, independent of any one language. To be a real hacker, you need to get to the point where you can learn a new language in days by relating what’s in the manual to what you already know. This means you should learn several very different languages. I can’t give complete instructions on how to learn to program here — it’s a complex skill. But I can tell you that books and courses won’t do it — many, maybe most of the best hackers are self-taught. You can learn language features — bits of knowledge — from books, but the mind-set that makes that knowledge into living skill can be learned only by practice and apprenticeship. What will do it is (a) reading code and (b) writing code. Peter Norvig, who is one of Google’s top hackers and the co-author of the most widely used textbook on AI, has written an excellent essay called Teach Yourself Programming in Ten Years. His “recipe for programming success” is worth careful attention. Learning to program is like learning to write good natural language. The best way to do it is to read some stuff written by masters of the form, write some things yourself, read a lot more, write a little more, read a lot more, write some more … and repeat until your writing begins to develop the kind of strength and economy you see in your models. I have had more to say about this learning process in How To Learn Hacking. It’s a simple set of instructions, but not an easy one. Finding good code to read used to be hard, because there were few large programs available in source for fledgeling hackers to read and tinker with. This has changed dramatically; open-source software, programming tools, and operating systems (all built by hackers) are now widely available. Which brings me neatly to our next topic… Get one of the open-source Unixes and learn to use and run it. I’ll assume you have a personal computer or can get access to one. (Take a moment to appreciate how much that means. The hacker culture originally evolved back when computers were so expensive that individuals could not own them.) The single most important step any newbie can take toward acquiring hacker skills is to get a copy of Linux or one of the BSD-Unixes, install it on a personal machine, and run it. Yes, there are other operating systems in the world besides Unix. But they’re distributed in binary — you can’t read the code, and you can’t modify it. Trying to learn to hack on a Microsoft Windows machine or under any other closed-source system is like trying to learn to dance while wearing a body cast. Under Mac OS X it’s possible, but only part of the system is open source — you’re likely to hit a lot of walls, and you have to be careful not to develop the bad habit of depending on Apple’s proprietary code. If you concentrate on the Unix under the hood you can learn some useful things. Unix is the operating system of the Internet. While you can learn to use the Internet without knowing Unix, you can’t be an Internet hacker without understanding Unix. For this reason, the hacker culture today is pretty strongly Unix-centered. (This wasn’t always true, and some old-time hackers still aren’t happy about it, but the symbiosis between Unix and the Internet has become strong enough that even Microsoft’s muscle doesn’t seem able to seriously dent it.) So, bring up a Unix — I like Linux myself but there are other ways (and yes, you can run both Linux and Microsoft Windows on the same machine). Learn it. Run it. Tinker with it. Talk to the Internet with it. Read the code. Modify the code. You’ll get better programming tools (including C, LISP, Python, and Perl) than any Microsoft operating system can dream of hosting, you’ll have fun, and you’ll soak up more knowledge than you realize you’re learning until you look back on it as a master hacker. For more about learning Unix, see The Loginataka. You might also want to have a look at The Art Of Unix Programming. The blog Let’s Go Larval! is a window on the learning process of a a new Linux user that I think is unusually lucid and helpful. The post How I Learned Linux makes a good starting point. To get your hands on a Linux, see the Linux Online! site; you can download from there or (better idea) find a local Linux user group to help you with installation. During the first ten years of this HOWTO’s life, I reported that from a new user’s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable “Unity” desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better. You can find BSD Unix help and resources at www.bsd.org. A good way to dip your toes in the water is to boot up what Linux fans call a live CD, a distribution that runs entirely off a CD or USB stick without having to modify your hard disk. This may be slow, because CDs are slow, but it’s a way to get a look at the possibilities without having to do anything drastic. I have written a primer on the basics of Unix and the Internet. I used to recommend against installing either Linux or BSD as a solo project if you’re a newbie. Nowadays the installers have gotten good enough that doing it entirely on your own is possible, even for a newbie. Nevertheless, I still recommend making contact with your local Linux user’s group and asking for help. It can’t hurt, and may smooth the process. Learn how to use the World Wide Web and write HTML. Most of the things the hacker culture has built do their work out of sight, helping run factories and offices and universities without any obvious impact on how non-hackers live. The Web is the one big exception, the huge shiny hacker toy that even politicians admit has changed the world. For this reason alone (and a lot of other good ones as well) you need to learn how to work the Web. This doesn’t just mean learning how to drive a browser (anyone can do that), but learning how to write HTML, the Web’s markup language. If you don’t know how to program, writing HTML will teach you some mental habits that will help you learn. So build a home page. But just having a home page isn’t anywhere near good enough to make you a hacker. The Web is full of home pages. Most of them are pointless, zero-content sludge — very snazzy-looking sludge, mind you, but sludge all the same (for more on this see The HTML Hell Page). To be worthwhile, your page must have content — it must be interesting and/or useful to other hackers. And that brings us to the next topic… If you don’t have functional English, learn it. As an American and native English-speaker myself, I have previously been reluctant to suggest this, lest it be taken as a sort of cultural imperialism. But several native speakers of other languages have urged me to point out that English is the working language of the hacker culture and the Internet, and that you will need to know it to function in the hacker community. Back around 1991 I learned that many hackers who have English as a second language use it in technical discussions even when they share a birth tongue; it was reported to me at the time that English has a richer technical vocabulary than any other language and is therefore simply a better tool for the job. For similar reasons, translations of technical books written in English are often unsatisfactory (when they get done at all). Linus Torvalds, a Finn, comments his code in English (it apparently never occurred to him to do otherwise). His fluency in English has been an important factor in his ability to recruit a worldwide community of developers for Linux. It’s an example worth following. Being a native English-speaker does not guarantee that you have language skills good enough to function as a hacker. If your writing is semi-literate, ungrammatical, and riddled with misspellings, many hackers (including myself) will tend to ignore you. While sloppy writing does not invariably mean sloppy thinking, we’ve generally found the correlation to be strong — and we have no use for sloppy thinkers. If you can’t yet write competently, learn to. Status in the Hacker Culture Write open-source software Help test and debug open-source software Publish useful information Help keep the infrastructure working Serve the hacker culture itselfLike most cultures without a money economy, hackerdom runs on reputation. You’re trying to solve interesting problems, but how interesting they are, and whether your solutions are really good, is something that only your technical peers or superiors are normally equipped to judge. Accordingly, when you play the hacker game, you learn to keep score primarily by what other hackers think of your skill (this is why you aren’t really a hacker until other hackers consistently call you one). This fact is obscured by the image of hacking as solitary work; also by a hacker-cultural taboo (gradually decaying since the late 1990s but still potent) against admitting that ego or external validation are involved in one’s motivation at all. Specifically, hackerdom is what anthropologists call a gift culture. You gain status and reputation in it not by dominating other people, nor by being beautiful, nor by having things other people want, but rather by giving things away. Specifically, by giving away your time, your creativity, and the results of your skill. There are basically five kinds of things you can do to be respected by hackers: Write open-source software The first (the most central and most traditional) is to write programs that other hackers think are fun or useful, and give the program sources away to the whole hacker culture to use. (We used to call these works “free software”, but this confused too many people who weren’t sure exactly what “free” was supposed to mean. Most of us now prefer the term “open-source” software). Hackerdom’s most revered demigods are people who have written large, capable programs that met a widespread need and given them away, so that now everyone uses them. But there’s a bit of a fine historical point here. While hackers have always looked up to the open-source developers among them as our community’s hardest core, before the mid-1990s most hackers most of the time worked on closed source. This was still true when I wrote the first version of this HOWTO in 1996; it took the mainstreaming of open-source software after 1997 to change things. Today, “the hacker community” and “open-source developers” are two descriptions for what is essentially the same culture and population — but it is worth remembering that this was not always so. (For more on this, see the section called “Historical Note: Hacking, Open Source, and Free Software”.) Help test and debug open-source software They also serve who stand and debug open-source software. In this imperfect world, we will inevitably spend most of our software development time in the debugging phase. That’s why any open-source author who’s thinking will tell you that good beta-testers (who know how to describe symptoms clearly, localize problems well, can tolerate bugs in a quickie release, and are willing to apply a few simple diagnostic routines) are worth their weight in rubies. Even one of these can make the difference between a debugging phase that’s a protracted, exhausting nightmare and one that’s merely a salutary nuisance. If you’re a newbie, try to find a program under development that you’re interested in and be a good beta-tester. There’s a natural progression from helping test programs to helping debug them to helping modify them. You’ll learn a lot this way, and generate good karma with people who will help you later on. Publish useful information Another good thing is to collect and filter useful and interesting information into web pages or documents like Frequently Asked Questions (FAQ) lists, and make those generally available. Maintainers of major technical FAQs get almost as much respect as open-source authors. Help keep the infrastructure working The hacker culture (and the engineering development of the Internet, for that matter) is run by volunteers. There’s a lot of necessary but unglamorous work that needs done to keep it going — administering mailing lists, moderating newsgroups, maintaining large software archive sites, developing RFCs and other technical standards. People who do this sort of thing well get a lot of respect, because everybody knows these jobs are huge time sinks and not as much fun as playing with code. Doing them shows dedication. Serve the hacker culture itself Finally, you can serve and propagate the culture itself (by, for example, writing an accurate primer on how to become a hacker :-)). This is not something you’ll be positioned to do until you’ve been around for while and become well-known for one of the first four things. The hacker culture doesn’t have leaders, exactly, but it does have culture heroes and tribal elders and historians and spokespeople. When you’ve been in the trenches long enough, you may grow into one of these. Beware: hackers distrust blatant ego in their tribal elders, so visibly reaching for this kind of fame is dangerous. Rather than striving for it, you have to sort of position yourself so it drops in your lap, and then be modest and gracious about your status. The Hacker/Nerd Connection Contrary to popular myth, you don’t have to be a nerd to be a hacker. It does help, however, and many hackers are in fact nerds. Being something of a social outcast helps you stay concentrated on the really important things, like thinking and hacking. For this reason, many hackers have adopted the label ‘geek’ as a badge of pride — it’s a way of declaring their independence from normal social expectations (as well as a fondness for other things like science fiction and strategy games that often go with being a hacker). The term ‘nerd’ used to be used this way back in the 1990s, back when ‘nerd’ was a mild pejorative and ‘geek’ a rather harsher one; sometime after 2000 they switched places, at least in U.S. popular culture, and there is now even a significant geek-pride culture among people who aren’t techies. If you can manage to concentrate enough on hacking to be good at it and still have a life, that’s fine. This is a lot easier today than it was when I was a newbie in the 1970s; mainstream culture is much friendlier to techno-nerds now. There are even growing numbers of people who realize that hackers are often high-quality lover and spouse material. If you’re attracted to hacking because you don’t have a life, that’s OK too — at least you won’t have trouble concentrating. Maybe you’ll get a life later on. Points For Style Again, to be a hacker, you have to enter the hacker mindset. There are some things you can do when you’re not at a computer that seem to help. They’re not substitutes for hacking (nothing is) but many hackers do them, and feel that they connect in some basic way with the essence of hacking. Learn to write your native language well. Though it’s a common stereotype that programmers can’t write, a surprising number of hackers (including all the most accomplished ones I know of) are very able writers. Read science fiction. Go to science fiction conventions (a good way to meet hackers and proto-hackers). Join a hackerspace and make things (another good way to meet hackers and proto-hackers). Train in a martial-arts form. The kind of mental discipline required for martial arts seems to be similar in important ways to what hackers do. The most popular forms among hackers are definitely Asian empty-hand arts such as Tae Kwon Do, various forms of Karate, Kung Fu, Aikido, or Ju Jitsu. Western fencing and Asian sword arts also have visible followings. In places where it’s legal, pistol shooting has been rising in popularity since the late 1990s. The most hackerly martial arts are those which emphasize mental discipline, relaxed awareness, and precise control, rather than raw strength, athleticism, or physical toughness. Study an actual meditation discipline. The perennial favorite among hackers is Zen (importantly, it is possible to benefit from Zen without acquiring a religion or discarding one you already have). Other styles may work as well, but be careful to choose one that doesn’t require you to believe crazy things. Develop an analytical ear for music. Learn to appreciate peculiar kinds of music. Learn to play some musical instrument well, or how to sing. Develop your appreciation of puns and wordplay. The more of these things you already do, the more likely it is that you are natural hacker material. Why these things in particular is not completely clear, but they’re connected with a mix of left- and right-brain skills that seems to be important; hackers need to be able to both reason logically and step outside the apparent logic of a problem at a moment’s notice. Work as intensely as you play and play as intensely as you work. For true hackers, the boundaries between “play”, “work”, “science” and “art” all tend to disappear, or to merge into a high-level creative playfulness. Also, don’t be content with a narrow range of skills. Though most hackers self-describe as programmers, they are very likely to be more than competent in several related skills — system administration, web design, and PC hardware troubleshooting are common ones. A hacker who’s a system administrator, on the other hand, is likely to be quite skilled at script programming and web design. Hackers don’t do things by halves; if they invest in a skill at all, they tend to get very good at it. Finally, a few things not to do. Don’t use a silly, grandiose user ID or screen name. Don’t get in flame wars on Usenet (or anywhere else). Don’t call yourself a ‘cyberpunk’, and don’t waste your time on anybody who does. Don’t post or email writing that’s full of spelling errors and bad grammar. The only reputation you’ll make doing any of these things is as a twit. Hackers have long memories — it could take you years to live your early blunders down enough to be accepted. The problem with screen names or handles deserves some amplification. Concealing your identity behind a handle is a juvenile and silly behavior characteristic of crackers, warez d00dz, and other lower life forms. Hackers don’t do this; they’re proud of what they do and want it associated with their real names. So if you have a handle, drop it. In the hacker culture it will only mark you as a loser. Historical Note: Hacking, Open Source, and Free Software When I originally wrote this how-to in late 1996, some of the conditions around it were very different from the way they look today. A few words about these changes may help clarify matters for people who are confused about the relationship of open source, free software, and Linux to the hacker community. If you are not curious about this, you can skip straight to the FAQ and bibliography from here. The hacker ethos and community as I have described it here long predates the emergence of Linux after 1990; I first became involved with it around 1976, and, its roots are readily traceable back to the early 1960s. But before Linux, most hacking was done on either proprietary operating systems or a handful of quasi-experimental homegrown systems like MIT’s ITS that were never deployed outside of their original academic niches. While there had been some earlier (pre-Linux) attempts to change this situation, their impact was at best very marginal and confined to communities of dedicated true believers which were tiny minorities even within the hacker community, let alone with respect to the larger world of software in general. What is now called “open source” goes back as far as the hacker community does, but until 1985 it was an unnamed folk practice rather than a conscious movement with theories and manifestos attached to it. This prehistory ended when, in 1985, arch-hacker Richard Stallman (“RMS”) tried to give it a name — “free software”. But his act of naming was also an act of claiming; he attached ideological baggage to the “free software” label which much of the existing hacker community never accepted. As a result, the “free software” label was loudly rejected by a substantial minority of the hacker community (especially among those associated with BSD Unix), and used with serious but silent reservations by a majority of the remainder (including myself). Despite these reservations, RMS’s claim to define and lead the hacker community under the “free software” banner broadly held until the mid-1990s. It was seriously challenged only by the rise of Linux. Linux gave open-source development a natural home. Many projects issued under terms we would now call open-source migrated from proprietary Unixes to Linux. The community around Linux grew explosively, becoming far larger and more heterogenous than the pre-Linux hacker culture. RMS determinedly attempted to co-opt all this activity into his “free software” movement, but was thwarted by both the exploding diversity of the Linux community and the public skepticism of its founder, Linus Torvalds. Torvalds continued to use the term “free software” for lack of any alternative, but publicly rejected RMS’s ideological baggage. Many younger hackers followed suit. In 1996, when I first published this Hacker HOWTO, the hacker community was rapidly reorganizing around Linux and a handful of other open-source operating systems (notably those descended from BSD Unix). Community memory of the fact that most of us had spent decades developing closed-source software on closed-source operating systems had not yet begun to fade, but that fact was already beginning to seem like part of a dead past; hackers were, increasingly, defining themselves as hackers by their attachments to open-source projects such as Linux or Apache. The term “open source”, however, had not yet emerged; it would not do so until early 1998. When it did, most of the hacker community adopted it within the following six months; the exceptions were a minority ideologically attached to the term “free software”. Since 1998, and especially after about 2003, the identification of ‘hacking’ with ‘open-source (and free software) development’ has become extremely close. Today there is little point in attempting to distinguish between these categories, and it seems unlikely that will change in the future. It is worth remembering, however, that this was not always so. Other Resources Paul Graham has written an essay called Great Hackers, and another on Undergraduation, in which he speaks much wisdom. Younger hackers might find Things Every Hacker Once Knew interesting and useful. I have also written A Brief History Of Hackerdom. I have written a paper, The Cathedral and the Bazaar, which explains a lot about how the Linux and open-source cultures work. I have addressed this topic even more directly in its sequel Homesteading the Noosphere. Rick Moen has written an excellent document on how to run a Linux user group. Rick Moen and I have collaborated on another document on How To Ask Smart Questions. This will help you seek assistance in a way that makes it more likely that you will actually get it. If you need instruction in the basics of how personal computers, Unix, and the Internet work, see The Unix and Internet Fundamentals HOWTO. When you release software or write patches for software, try to follow the guidelines in the Software Release Practice HOWTO. If you enjoyed the Zen poem, you might also like Rootless Root: The Unix Koans of Master Foo. Frequently Asked Questions Q: How do I tell if I am already a hacker?Q: Will you teach me how to hack?Q: How can I get started, then?Q: When do you have to start? Is it too late for me to learn?Q: How long will it take me to learn to hack?Q: Is Visual Basic a good language to start with?Q: Would you help me to crack a system, or teach me how to crack?Q: How can I get the password for someone else’s account?Q: How can I break into/read/monitor someone else’s email?Q: How can I steal channel op privileges on IRC?Q: I’ve been cracked. Will you help me fend off further attacks?Q: I’m having problems with my Windows software. Will you help me?Q: Where can I find some real hackers to talk with?Q: Can you recommend useful books about hacking-related subjects?Q: Do I need to be good at math to become a hacker?Q: What language should I learn first?Q: What kind of hardware do I need?Q: I want to contribute. Can you help me pick a problem to work on?Q: Do I need to hate and bash Microsoft?Q: But won’t open-source software leave programmers unable to make a living?Q: Where can I get a free Unix?Q: How do I tell if I am already a hacker? A: Ask yourself the following three questions: Do you speak code, fluently? Do you identify with the goals and values of the hacker community? Has a well-established member of the hacker community ever called you a hacker? If you can answer yes to all three of these questions, you are already a hacker. No two alone are sufficient. The first test is about skills. You probably pass it if you have the minimum technical skills described earlier in this document. You blow right through it if you have had a substantial amount of code accepted by an open-source development project. The second test is about attitude. If the five principles of the hacker mindset seemed obvious to you, more like a description of the way you already live than anything novel, you are already halfway to passing it. That’s the inward half; the other, outward half is the degree to which you identify with the hacker community’s long-term projects. Here is an incomplete but indicative list of some of those projects: Does it matter to you that Linux improve and spread? Are you passionate about software freedom? Hostile to monopolies? Do you act on the belief that computers can be instruments of empowerment that make the world a richer and more humane place? But a note of caution is in order here. The hacker community has some specific, primarily defensive political interests — two of them are defending free-speech rights and fending off “intellectual-property” power grabs that would make open source illegal. Some of those long-term projects are civil-liberties organizations like the Electronic Frontier Foundation, and the outward attitude properly includes support of them. But beyond that, most hackers view attempts to systematize the hacker attitude into an explicit political program with suspicion; we’ve learned, the hard way, that these attempts are divisive and distracting. If someone tries to recruit you to march on your capitol in the name of the hacker attitude, they’ve missed the point. The right response is probably “Shut up and show them the code.” The third test has a tricky element of recursiveness about it. I observed in the section called “What Is a Hacker?” that being a hacker is partly a matter of belonging to a particular subculture or social network with a shared history, an inside and an outside. In the far past, hackers were a much less cohesive and self-aware group than they are today. But the importance of the social-network aspect has increased over the last thirty years as the Internet has made connections with the core of the hacker subculture easier to develop and maintain. One easy behavioral index of the change is that, in this century, we have our own T-shirts. Sociologists, who study networks like those of the hacker culture under the general rubric of “invisible colleges”, have noted that one characteristic of such networks is that they have gatekeepers — core members with the social authority to endorse new members into the network. Because the “invisible college” that is hacker culture is a loose and informal one, the role of gatekeeper is informal too. But one thing that all hackers understand in their bones is that not every hacker is a gatekeeper. Gatekeepers have to have a certain degree of seniority and accomplishment before they can bestow the title. How much is hard to quantify, but every hacker knows it when they see it. Q: Will you teach me how to hack? A: Since first publishing this page, I’ve gotten several requests a week (often several a day) from people to “teach me all about hacking”. Unfortunately, I don’t have the time or energy to do this; my own hacking projects, and working as an open-source advocate, take up 110% of my time. Even if I did, hacking is an attitude and skill you basically have to teach yourself. You’ll find that while real hackers want to help you, they won’t respect you if you beg to be spoon-fed everything they know. Learn a few things first. Show that you’re trying, that you’re capable of learning on your own. Then go to the hackers you meet with specific questions. If you do email a hacker asking for advice, here are two things to know up front. First, we’ve found that people who are lazy or careless in their writing are usually too lazy and careless in their thinking to make good hackers — so take care to spell correctly, and use good grammar and punctuation, otherwise you’ll probably be ignored. Secondly, don’t dare ask for a reply to an ISP account that’s different from the account you’re sending from; we find people who do that are usually thieves using stolen accounts, and we have no interest in rewarding or assisting thievery. Q: How can I get started, then? A: The best way for you to get started would probably be to go to a LUG (Linux user group) meeting. You can find such groups on the LDP General Linux Information Page; there is probably one near you, possibly associated with a college or university. LUG members will probably give you a Linux if you ask, and will certainly help you install one and get started. Your next step (and your first step if you can’t find a LUG nearby) should be to find an open-source project that interests you. Start reading code and reviewing bugs. Learn to contribute, and work your way in. The only way in is by working to improve your skills. If you ask me personally for advice on how to get started, I will tell you these exact same things, because I don’t have any magic shortcuts for you. I will also mentally write you off as a probable loser - because if you lacked the stamina to read this FAQ and the intelligence to understand from it that the only way in is by working to improve your skills, you’re hopeless. Another interesting possibility is to go visit a hackerspace. There is a burgeoning movement of people creating physical locations - maker’s clubs - where they can hang out to work on hardware and software projects together, or work solo in a cogenial atmosphere. Hackerspaces often collect tools and specialized equipment that would be too expensive or logistically inconvenient for individuals to own. Hackerspaces are easy to find on the Internet; one may be located near you. Q: When do you have to start? Is it too late for me to learn? A: Any age at which you are motivated to start is a good age. Most people seem to get interested between ages 15 and 20, but I know of exceptions in both directions. Q: How long will it take me to learn to hack? A: That depends on how talented you are and how hard you work at it. Most people who try can acquire a respectable skill set in eighteen months to two years, if they concentrate. Don’t think it ends there, though; in hacking (as in many other fields) it takes about ten years to achieve mastery. And if you are a real hacker, you will spend the rest of your life learning and perfecting your craft. Q: Is Visual Basic a good language to start with? A: If you’re asking this question, it almost certainly means you’re thinking about trying to hack under Microsoft Windows. This is a bad idea in itself. When I compared trying to learn to hack under Windows to trying to learn to dance while wearing a body cast, I wasn’t kidding. Don’t go there. It’s ugly, and it never stops being ugly. There is a specific problem with Visual Basic; mainly that it’s not portable. Though there is a prototype open-source implementations of Visual Basic, the applicable ECMA standards don’t cover more than a small set of its programming interfaces. On Windows most of its library support is proprietary to a single vendor (Microsoft); if you aren’t extremely careful about which features you use — more careful than any newbie is really capable of being — you’ll end up locked into only those platforms Microsoft chooses to support. If you’re starting on a Unix, much better languages with better libraries are available. Python, for example. Also, like other Basics, Visual Basic is a poorly-designed language that will teach you bad programming habits. No, don’t ask me to describe them in detail; that explanation would fill a book. Learn a well-designed language instead. One of those bad habits is becoming dependent on a single vendor’s libraries, widgets, and development tools. In general, any language that isn’t fully supported under at least Linux or one of the BSDs, and/or at least three different vendors’ operating systems, is a poor one to learn to hack in. Q: Would you help me to crack a system, or teach me how to crack? A: No. Anyone who can still ask such a question after reading this FAQ is too stupid to be educable even if I had the time for tutoring. Any emailed requests of this kind that I get will be ignored or answered with extreme rudeness. Q: How can I get the password for someone else’s account? A: This is cracking. Go away, idiot. Q: How can I break into/read/monitor someone else’s email? A: This is cracking. Get lost, moron. Q: How can I steal channel op privileges on IRC? A: This is cracking. Begone, cretin. Q: I’ve been cracked. Will you help me fend off further attacks? A: No. Every time I’ve been asked this question so far, it’s been from some poor sap running Microsoft Windows. It is not possible to effectively secure Windows systems against crack attacks; the code and architecture simply have too many flaws, which makes securing Windows like trying to bail out a boat with a sieve. The only reliable prevention starts with switching to Linux or some other operating system that is designed to at least be capable of security. Q: I’m having problems with my Windows software. Will you help me? A: Yes. Go to a DOS prompt and type “format c:”. Any problems you are experiencing will cease within a few minutes. Q: Where can I find some real hackers to talk with? A: The best way is to find a Unix or Linux user’s group local to you and go to their meetings (you can find links to several lists of user groups on the LDP site at ibiblio). (I used to say here that you wouldn’t find any real hackers on IRC, but I’m given to understand this is changing. Apparently some real hacker communities, attached to things like GIMP and Perl, have IRC channels now.) Q: Can you recommend useful books about hacking-related subjects? A: I maintain a Linux Reading List HOWTO that you may find helpful. The Loginataka may also be interesting. For an introduction to Python, see the tutorial on the Python site. Q: Do I need to be good at math to become a hacker? A: No. Hacking uses very little formal mathematics or arithmetic. In particular, you won’t usually need trigonometry, calculus or analysis (there are exceptions to this in a handful of specific application areas like 3-D computer graphics). Knowing some formal logic and Boolean algebra is good. Some grounding in finite mathematics (including finite-set theory, combinatorics, and graph theory) can be helpful. Much more importantly: you need to be able to think logically and follow chains of exact reasoning, the way mathematicians do. While the content of most mathematics won’t help you, you will need the discipline and intelligence to handle mathematics. If you lack the intelligence, there is little hope for you as a hacker; if you lack the discipline, you’d better grow it. I think a good way to find out if you have what it takes is to pick up a copy of Raymond Smullyan’s book What Is The Name Of This Book?. Smullyan’s playful logical conundrums are very much in the hacker spirit. Being able to solve them is a good sign; enjoying solving them is an even better one. Q: What language should I learn first? A: HTML if you don’t already know it. There are a lot of glossy, hype-intensive bad HTML books out there, and distressingly few good ones. The one I like best is HTML: The Definitive Guide. But HTML is not a full programming language. When you’re ready to start programming, I would recommend starting with Python. You will hear a lot of people recommending Perl, but it’s harder to learn and (in my opinion) less well designed. C is really important, but it’s also much more difficult than either Python or Perl. Don’t try to learn it first. Windows users, do not settle for Visual Basic. It will teach you bad habits, and it’s not portable off Windows. Avoid. Q: What kind of hardware do I need? A: It used to be that personal computers were rather underpowered and memory-poor, enough so that they placed artificial limits on a hacker’s learning process. This stopped being true in the mid-1990s; any machine from an Intel 486DX50 up is more than powerful enough for development work, X, and Internet communications, and the smallest disks you can buy today are plenty big enough. The important thing in choosing a machine on which to learn is whether its hardware is Linux-compatible (or BSD-compatible, should you choose to go that route). Again, this will be true for almost all modern machines. The only really sticky areas are modems and wireless cards; some machines have Windows-specific hardware that won’t work with Linux. There’s a FAQ on hardware compatibility; the latest version is here. Q: I want to contribute. Can you help me pick a problem to work on? A: No, because I don’t know your talents or interests. You have to be self-motivated or you won’t stick, which is why having other people choose your direction almost never works. Q: Do I need to hate and bash Microsoft? A: No, you don’t. Not that Microsoft isn’t loathsome, but there was a hacker culture long before Microsoft and there will still be one long after Microsoft is history. Any energy you spend hating Microsoft would be better spent on loving your craft. Write good code — that will bash Microsoft quite sufficiently without polluting your karma. Q: But won’t open-source software leave programmers unable to make a living? A: This seems unlikely — so far, the open-source software industry seems to be creating jobs rather than taking them away. If having a program written is a net economic gain over not having it written, a programmer will get paid whether or not the program is going to be open-source after it’s done. And, no matter how much “free” software gets written, there always seems to be more demand for new and customized applications. I’ve written more about this at the Open Source pages. Q: Where can I get a free Unix? A: If you don’t have a Unix installed on your machine yet, elsewhere on this page I include pointers to where to get the most commonly used free Unix. To be a hacker you need motivation and initiative and the ability to educate yourself. Start now…","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[]},{"title":"提问的智慧","date":"2017-01-20T12:28:06.000Z","path":"2017/01/20/Program/Concepts/how-to-ask-questions-the-smart-way/","text":"How To Ask Questions The Smart WayEric S. Raymond, Rick Moen 翻译者：2010 by Gasolin, 2015 by Ryan Wu 在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。 目录声明简介在提问之前当你提问时慎选提问的论坛Stack Overflow网站和 IRC 论坛 第二步，使用项目邮件列表使用有意义且描述明确的标题使问题容易回复用清晰、正确、精准并合法语法的语句使用易于读取且标准的文件格式发送问题精确的描述问题并言之有物话不在多而在精别动辄声称找到 Bug可以低声下气，但还是要先做功课描述问题症状而非猜测按发生时间先后列出问题症状描述目标而不是过程别要求使用私人电邮回复清楚明确的表达你的问题以及需求询问有关代码的问题时别把自己家庭作业的问题贴上来去掉无意义的提问句即使你很急也不要在标题写紧急礼多人不怪，而且有时还很有帮助问题解决后，加个简短的补充说明 如何解读答案RTFM 和 STFW：如何知道你已完全搞砸了如果还是搞不懂处理无礼的回应如何避免扮演失败者不该问的问题好问题与蠢问题如果得不到回答如何更好地回答问题相关资源鸣谢 声明许多项目在他们的使用协助/说明网页中链接了本指南，这么做很好，我们也鼓励大家都这么做。但如果你是负责管理这个项目网页的人，请在超链接附近的显著位置上注明： 本指南不提供此项目的实际支持服务！ 我们已经深刻领教到少了上述声明所带来的痛苦。因为少了这点声明，我们不停地被一些白痴纠缠。这些白痴认为既然我们发布了这本指南，那么我们就有责任解决世上所有的技术问题。 如果你是因为需要某些协助而正在阅读这本指南，并且最后离开是因为发现从本指南作者们身上得不到直接的协助，那么你就是我们所说的那些白痴之一。别问我们问题，我们只会忽略你。我们在这本指南中是教你如何从那些真正懂得你所遇到软件或硬件问题的人取得协助，而 99% 的情况下那不会是我们。除非你确定本指南的作者之一刚好是你所遇到的问题领域的专家，否则请不要打扰我们，这样大家都会开心一点。 简介在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。 本指南将教你如何正确的提问以获得你满意的答案。 不只是黑客，现在开放源代码（Open Source）软件已经相当盛行，你常常也可以由其他有经验的使用者身上得到好答案，这是件好事；使用者比起黑客来，往往对那些新手常遇到的问题更宽容一些。然而，将有经验的使用者视为黑客，并采用本指南所提的方法与他们沟通，同样也是能从他们身上得到满意回答的最有效方式。 首先你应该明白，黑客们喜爱有挑战性的问题，或者能激发我们思维的好问题。如果我们并非如此，那我们也不会成为你想询问的对象。如果你给了我们一个值得反复咀嚼玩味的好问题，我们自会对你感激不尽。好问题是激励，是厚礼。好问题可以提高我们的理解力，而且通常会暴露我们以前从没意识到或者思考过的问题。对黑客而言，”好问题！”是诚挚的大力称赞。 尽管如此，黑客们有着蔑视或傲慢面对简单问题的坏名声，这有时让我们看起来对新手、无知者似乎较有敌意，但其实不是那样的。 我们不讳言我们对那些不愿思考、或者在发问前不做他们该做的事的人的蔑视。那些人是时间杀手 -– 他们只想索取，从不付出，消耗我们可用在更有趣的问题或更值得回答的人身上的时间。我们称这样的人为 失败者（撸瑟） （由于历史原因，我们有时把它拼作 lusers）。 我们意识到许多人只是想使用我们写的软件，他们对学习技术细节没有兴趣。对大多数人而言，电脑只是种工具，是种达到目的的手段而已。他们有自己的生活并且有更要紧的事要做。我们了解这点，也从不指望每个人都对这些让我们着迷的技术问题感兴趣。尽管如此，我们回答问题的风格是指向那些真正对此有兴趣并愿意主动参与解决问题的人，这一点不会变，也不该变。如果连这都变了，我们就是在降低做自己最擅长的事情上的效率。 我们（在很大程度上）是自愿的，从繁忙的生活中抽出时间来解答疑惑，而且时常被提问淹没。所以我们无情的滤掉一些话题，特别是拋弃那些看起来像失败者的家伙，以便更高效的利用时间来回答赢家（winner）的问题。 如果你厌恶我们的态度，高高在上，或过于傲慢，不妨也设身处地想想。我们并没有要求你向我们屈服 – 事实上，我们大多数人非常乐意与你平等地交流，只要你付出小小努力来满足基本要求，我们就会欢迎你加入我们的文化。但让我们帮助那些不愿意帮助自己的人是没有效率的。无知没有关系，但装白痴就是不行。 所以，你不必在技术上很在行才能吸引我们的注意，但你必须表现出能引导你变得在行的特质 – 机敏、有想法、善于观察、乐于主动参与解决问题。如果你做不到这些使你与众不同的事情，我们建议你花点钱找家商业公司签个技术支持服务合同，而不是要求黑客个人无偿地帮助你。 如果你决定向我们求助，当然你也不希望被视为失败者，更不愿成为失败者中的一员。能立刻得到快速并有效答案的最好方法，就是像赢家那样提问 – 聪明、自信、有解决问题的思路，只是偶尔在特定的问题上需要获得一点帮助。 （欢迎对本指南提出改进意见。你可以 email 你的建议至 esr@thyrsus.com 或 respond-auto@linuxmafia.com。然而请注意，本文并非网络礼节的通用指南，而我们通常会拒绝无助于在技术论坛得到有用答案的建议。） 在提问之前在你准备要通过电子邮件、新闻群组或者聊天室提出技术问题前，请先做到以下事情： 尝试在你准备提问的论坛的旧文章中搜索答案。 尝试上网搜索以找到答案。 尝试阅读手册以找到答案。 尝试阅读常见问题文件（FAQ）以找到答案。 尝试自己检查或试验以找到答案 向你身边的强者朋友打听以找到答案。 如果你是程序开发者，请尝试阅读源代码以找到答案。 当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并 不是一个不劳而获且浪费别人的时间的提问者。 如果你能一并表达在做了上述努力的过程中所学到的东西会更好，因为我们更乐于回答那些表现出能从答案中学习的人的问题。 运用某些策略，比如先用 Google 搜索你所遇到的各种错误信息（既搜索 Google 论坛，也搜索网页），这样很可能直接就找到了能解决问题的文件或邮件列表线索。即使没有结果，在邮件列表或新闻组寻求帮助时加上一句 我在 Google 中搜过下列句子但没有找到什么有用的东西 也是件好事，即使它只是表明了搜索引擎不能提供哪些帮助。这么做（加上搜索过的字串）也让遇到相似问题的其他人能被搜索引擎引导到你的提问来。 别着急，不要指望几秒钟的 Google 搜索就能解决一个复杂的问题。在向专家求助之前，再阅读一下常见问题文件（FAQ）、放轻松、坐舒服一些，再花点时间思考一下这个问题。相信我们，他们 能从你的提问看出你做了多少阅读与思考，如果你是有备而来，将更有可能得到解答。不要将所有问题一股脑拋出，只因你的第一次搜索没有找到答案（或者找到太多答案）。 准备好你的问题，再将问题仔细的思考过一遍，因为 草率的发问只能得到草率的回答，或者根本得不到任何答案。越是能表现出在寻求帮助前你为解决问题所付出的努力，你越有可能得到实质性的帮助。 小心别问错了问题。如果你的问题基于错误的假设，某个普通黑客（J. Random Hacker）多半会一边在心里想着蠢问题…， 一边用无意义的字面解释来答复你，希望着你会从问题的回答（而非你想得到的答案）中汲取教训。 绝不要自以为够格得到答案，你没有；你并没有。毕竟你没有为这种服务支付任何报酬。你将会是 自己去挣到一个答案，靠提出有内涵的、有趣的、有思维激励作用的问题 –一个有潜力能贡献社区经验的问题，而不仅仅是被动的从他人处索取知识。 另一方面，表明你愿意在找答案的过程中做点什么是一个非常好的开端。谁能给点提示？、我的这个例子里缺了什么？以及我应该检查什么地方比请把我需要的确切的过程贴出来更容易得到答复。因为你表现出只要有人能指个正确方向，你就有完成它的能力和决心。 当你提问时慎选提问的论坛 小心选择你要提问的场合。如果你做了下述的事情，你很可能被忽略掉或者被看作失败者： 在与主题不合的论坛上贴出你的问题 在探讨进阶技术问题的论坛张贴非常初级的问题；反之亦然 在太多的不同新闻群组上重复转贴同样的问题（cross-post） 向既非熟人也没有义务解决你问题的人发送私人电邮 黑客会剔除掉那些搞错场合的问题，以保护他们沟通的渠道不被无关的东西淹没。你不会想让这种事发生在自己身上的。 因此，第一步是找到对的论坛。再说一次，Google 和其它搜索引擎还是你的朋友，用它们来找到与你遭遇到困难的软硬件问题最相关的网站。通常那儿都有常见问题（FAQ）、邮件列表及相关说明文件的链接。如果你的努力（包括阅读 FAQ）都没有结果，网站上也许还有报告 Bug（Bug-reporting）的流程或链接，如果是这样，连过去看看。 向陌生的人或论坛发送邮件最可能是风险最大的事情。举例来说，别假设一个提供丰富内容的网页的作者会想充当你的免费顾问。不要对你的问题是否会受到欢迎做太乐观的估计 – 如果你不确定，那就向别处发送，或者压根别发。 在选择论坛、新闻群组或邮件列表时，别太相信名字，先看看 FAQ 或者许可书以弄清楚你的问题是否切题。发文前先翻翻已有的话题，这样可以让你感受一下那里的文化。事实上，事先在新闻组或邮件列表的历史记录中搜索与你问题相关的关键词是个极好的主意，也许这样就找到答案了。即使没有，也能帮助你归纳出更好的问题。 别像机关枪似的一次”扫射”所有的帮助渠道，这就像大喊大叫一样会使人不快。要一个一个地来。 搞清楚你的主题！最典型的错误之一是在某种致力于跨平台可移植的语言、套件或工具的论坛中提关于 Unix 或 Windows 操作系统程序界面的问题。如果你不明白为什么这是大错，最好在搞清楚这之间差异之前什么也别问。 一般来说，在仔细挑选的公共论坛中提问，会比在私有论坛中提同样的问题更容易得到有用的回答。有几个理由可以支持这点，一是看潜在的回复者有多少，二是看观众有多少。黑客较愿意回答那些能帮助到许多人的问题。 可以理解的是，老练的黑客和一些热门软件的作者正在接受过多的错发信息。就像那根最后压垮骆驼背的稻草一样，你的加入也有可能使情况走向极端 – 已经好几次了，一些热门软件的作者从自己软件的支持中抽身出来，因为伴随而来涌入其私人邮箱的无用邮件变得无法忍受。 Stack Overflow搜索，然后 在 Stack Exchange 问。 近年来，Stack Exchange community 社区已经成为回答技术及其他问题的主要渠道，尤其是那些开放源码的项目。 因为 Google 索引是即时的，在看 Stack Exchange 之前先在 Google 搜索。有很高的机率某人已经问了一个类似的问题，而且 Stack Exchange 网站们往往会是搜索结果中最前面几个。如果你在 Google 上没有找到任何答案，你再到特定相关主题的网站去找。用标签（Tag）搜索能让你更缩小你的搜索结果。 Stack Exchange 已经成长到超过一百个网站，以下是最常用的几个站： Super User 是问一些通用的电脑问题，如果你的问题跟代码或是写程序无关，只是一些网络连线之类的，请到这里。Stack Overflow 是问写程序有关的问题。Server Fault 是问服务器和网管相关的问题。 网站和 IRC 论坛 本地的使用者群组（user group），或者你所用的 Linux 发行版本也许正在宣传他们的网页论坛或 IRC 频道，并提供新手帮助（在一些非英语国家，新手论坛很可能还是邮件列表）， 这些地方是开始提问的好首选，特别是当你觉得遇到的也许只是相对简单或者很普通的问题时。有广告赞助的 IRC 频道是公开欢迎提问的地方，通常可以即时得到回应。 事实上，如果程序出的问题只发生在特定 Linux 发行版提供的版本（这很常见），最好先去该发行版的论坛或邮件列表中提问，再到程序本身的论坛或邮件列表提问。（否则）该项目的黑客可能仅仅回复 “用我们的版本”。 在任何论坛发文以前，先确认一下有没有搜索功能。如果有，就试着搜索一下问题的几个关键词，也许这会有帮助。如果在此之前你已做过通用的网页搜索（你也该这样做），还是再搜索一下论坛，搜索引擎有可能没来得及索引此论坛的全部内容。 通过论坛或 IRC 频道来提供使用者支持服务有增长的趋势，电子邮件则大多为项目开发者间的交流而保留。所以最好先在论坛或 IRC 中寻求与该项目相关的协助。 在使用 IRC 的时候，首先最好不要发布很长的问题描述，有些人称之为频道洪水。最好通过一句话的问题描述来开始聊天。 第二步，使用项目邮件列表当某个项目提供开发者邮件列表时，要向列表而不是其中的个别成员提问，即使你确信他能最好地回答你的问题。查一查项目的文件和首页，找到项目的邮件列表并使用它。有几个很好的理由支持我们采用这种办法： 任何好到需要向个别开发者提出的问题，也将对整个项目群组有益。反之，如果你认为自己的问题对整个项目群组来说太愚蠢，也不能成为骚扰个别开发者的理由。 向列表提问可以分散开发者的负担，个别开发者（尤其是项目领导人）也许太忙以至于没法回答你的问题。 大多数邮件列表都会被存档，那些被存档的内容将被搜索引擎索引。如果你向列表提问并得到解答，将来其它人可以通过网页搜索找到你的问题和答案，也就不用再次发问了。 如果某些问题经常被问到，开发者可以利用此信息来改进说明文件或软件本身，以使其更清楚。如果只是私下提问，就没有人能看到最常见问题的完整场景。 如果一个项目既有”使用者” 也有”开发者”（或”黑客”）邮件列表或论坛，而你又不会动到那些源代码，那么就向”使用者”列表或论坛提问。不要假设自己会在开发者列表中受到欢迎，那些人多半会将你的提问视为干扰他们开发的噪音。 然而，如果你确信你的问题很特别，而且在”使用者” 列表或论坛中几天都没有回复，可以试试前往”开发者”列表或论坛发问。建议你在张贴前最好先暗地里观察几天以了解那里的行事方式（事实上这是参与任何私有或半私有列表的好主意） 如果你找不到一个项目的邮件列表，而只能查到项目维护者的电子邮件地址，尽管向他发信。即使是在这种情况下，也别假设（项目）邮件列表不存在。在你的电子邮件中，请陈述你已经试过但没有找到合适的邮件列表，也提及你不反对将自己的邮件转发给他人（许多人认为，即使没什么秘密，私人电子邮件也不应该被公开。通过允许将你的电子邮件转发他人，你给了相应人员处置你邮件的选择）。 使用有意义且描述明确的标题在邮件列表、新闻群组或论坛中，大约 50 字以内的标题是抓住资深专家注意力的好机会。别用喋喋不休的帮帮忙、跪求、急（更别说救命啊！！！！这样让人反感的话，用这种标题会被条件反射式地忽略）来浪费这个机会。不要妄想用你的痛苦程度来打动我们，而是在这点空间中使用极简单扼要的描述方式来提出问题。 一个好标题范例是目标 – 差异式的描述，许多技术支持组织就是这样做的。在目标部分指出是哪一个或哪一组东西有问题，在差异部分则描述与期望的行为不一致的地方。 蠢问题：救命啊！我的笔电不能正常显示了！ 聪明问题：X.org 6.8.1 的鼠标游标会变形，某牌显卡 MV1005 芯片组。 更聪明问题：X.org 6.8.1 的鼠标游标，在某牌显卡 MV1005 芯片组环境下 - 会变形。 编写目标 – 差异 式描述的过程有助于你组织对问题的细致思考。 是什么被影响了？ 仅仅是鼠标游标或者还有其它图形？只在 X.org 的 X 版中出现？或只是出现在 6.8.1 版中？ 是针对某牌显卡芯片组？或者只是其中的 MV1005 型号？ 一个黑客只需瞄一眼就能够立即明白你的环境和你遇到的问题。 总而言之，请想像一下你正在一个只显示标题的存档讨论串（Thread）索引中查寻。让你的标题更好地反映问题，可使下一个搜索类似问题的人能够关注这个讨论串，而不用再次提问相同的问题。 如果你想在回复中提出问题，记得要修改内容标题，以表明你是在问一个问题， 一个看起来像 Re: 测试 或者 Re: 新 bug 的标题很难引起足够重视。另外，在不影响连贯性之下，适当引用并删减前文的内容，能给新来的读者留下线索。 对于讨论串，不要直接点击回复来开始一个全新的讨论串，这将限制你的观众。因为有些邮件阅读程序，比如 mutt ，允许使用者按讨论串排序并通过折叠讨论串来隐藏消息，这样做的人永远看不到你发的消息。 仅仅改变标题还不够。mutt 和其它一些邮件阅读程序还会检查邮件标题以外的其它信息，以便为其指定讨论串。所以宁可发一个全新的邮件。 在网页论坛上，好的提问方式稍有不同，因为讨论串与特定的信息紧密结合，并且通常在讨论串外就看不到里面的内容，故通过回复提问，而非改变标题是可接受的。不是所有论坛都允许在回复中出现分离的标题，而且这样做了基本上没有人会去看。不过，通过回复提问，这本身就是暧昧的做法，因为它们只会被正在查看该标题的人读到。所以，除非你只想在该讨论串当前活跃的人群中提问，不然还是另起炉灶比较好。 使问题容易回复 以请将你的回复寄到……来结束你的问题多半会使你得不到回答。如果你觉得花几秒钟在邮件客户端设置一下回复地址都麻烦，我们也觉得花几秒钟思考你的问题更麻烦。如果你的邮件程序不支持这样做，换个好点的；如果是操作系统不支持这种邮件程序，也换个好点的。 在论坛，要求通过电子邮件回复是非常无礼的，除非你相信回复的信息可能比较敏感（而且有人会为了某些未知的原因，只让你而不是整个论坛知道答案）。如果你只是想在有人回复讨论串时得到电子邮件提醒，可以要求网页论坛发送给你。几乎所有论坛都支持诸如追踪此讨论串、有回复时发送邮件提醒等功能。 用清晰、正确、精准并语法正确的语句我们从经验中发现，粗心的提问者通常也会粗心的写程序与思考（我敢打包票）。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。 正确的拼字、标点符号和大小写是很重要的。一般来说，如果你觉得这样做很麻烦，不想在乎这些，那我们也觉得麻烦，不想在乎你的提问。花点额外的精力斟酌一下字句，用不着太僵硬与正式 – 事实上，黑客文化很看重能准确地使用非正式、俚语和幽默的语句。但它必须很准确，而且有迹象表明你是在思考和关注问题。 正确地拼写、使用标点和大小写，不要将its混淆为it’s，loose搞成lose或者将discrete弄成discreet。不要全部用大写，这会被视为无礼的大声嚷嚷（全部小写也好不到哪去，因为不易阅读。Alan Cox 也许可以这样做，但你不行。） 更白话的说，如果你写得像是个半文盲[译注：小白]，那多半得不到理睬。也不要使用即时通讯中的简写或火星文，如将的简化为ㄉ会使你看起来像一个为了少打几个键而省字的小白。更糟的是，如果像个小孩似地鬼画符那绝对是在找死，可以肯定没人会理你（或者最多是给你一大堆指责与挖苦）。 如果在使用非母语的论坛提问，你可以犯点拼写和语法上的小错，但决不能在思考上马虎（没错，我们通常能弄清两者的分别）。同时，除非你知道回复者使用的语言，否则请使用英语书写。繁忙的黑客一般会直接删除用他们看不懂语言写的消息。在网络上英语是通用语言，用英语书写可以将你的问题在尚未被阅读就被直接删除的可能性降到最低。 如果英文是你的外语（Second language），提示潜在回复者你有潜在的语言困难是很好的： [译注：以下附上原文以供使用] English is not my native language; please excuse typing errors.英文不是我的母语，请原谅我的错字或语法 If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question.如果你说某语言，请寄信/私讯给我；我需要有人协助我翻译我的问题 I am familiar with the technical terms, but some slang expressions and idioms are difficult for me.我对技术名词很熟悉，但对于俗语或是特别用法比较不甚了解。 I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other.我把我的问题用某语言和英文写出来，如果你只用一种语言回答，我会乐意将其翻译成另一种。 使用易于读取且标准的文件格式发送问题如果你人为地将问题搞得难以阅读，它多半会被忽略，人们更愿读易懂的问题，所以： 使用纯文字而不是 HTML (关闭 HTML 并不难）。 使用 MIME 附件通常是可以的，前提是真正有内容（譬如附带的源代码或 patch），而不仅仅是邮件程序生成的模板（譬如只是信件内容的拷贝）。 不要发送一段文字只是一行句子但自动换行后会变成多行的邮件（这使得回复部分内容非常困难）。设想你的读者是在 80 个字符宽的终端机上阅读邮件，最好设置你的换行分割点小于 80 字。但是，对一些特殊的文件不要设置固定宽度（譬如日志档案拷贝或会话记录）。数据应该原样包含，让回复者有信心他们看到的是和你看到的一样的东西。 在英语论坛中，不要使用Quoted-Printable MIME 编码发送消息。这种编码对于张贴非 ASCII 语言可能是必须的，但很多邮件程序并不支持这种编码。当它们处理换行时，那些文本中四处散布的=20符号既难看也分散注意力，甚至有可能破坏内容的语意。绝对，永远不要指望黑客们阅读使用封闭格式编写的文档，像微软公司的 Word 或 Excel 文件等。大多数黑客对此的反应就像有人将还在冒热气的猪粪倒在你家门口时你的反应一样。即便他们能够处理，他们也很厌恶这么做。 如果你从使用 Windows 的电脑发送电子邮件，关闭微软愚蠢的智能引号功能 （从[选项] &gt; [校订] &gt; [自动校正选项]，勾选掉智能引号单选框），以免在你的邮件中到处散布垃圾字符。 在论坛，勿滥用表情符号和HTML功能（当它们提供时）。一两个表情符号通常没有问题，但花哨的彩色文本倾向于使人认为你是个无能之辈。过滥地使用表情符号、色彩和字体会使你看来像个傻笑的小姑娘。这通常不是个好主意，除非你只是对性而不是对答案感兴趣。 如果你使用图形用户界面的邮件程序（如微软公司的 Outlook 或者其它类似的），注意它们的默认设置不一定满足这些要求。大多数这类程序有基于选单的查看源代码命令，用它来检查发送文件夹中的邮件，以确保发送的是纯文本文件同时没有一些奇怪的字符。 精确的描述问题并言之有物 仔细、清楚地描述你的问题或 Bug 的症状。 描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：Fedora Core 4、Slackware 9.1等）。 描述在提问前你是怎样去研究和理解这个问题的。 描述在提问前为确定问题而采取的诊断步骤。 描述最近做过什么可能相关的硬件或软件变更。 尽可能的提供一个可以重现这个问题的可控环境的方法。 尽量去揣测一个黑客会怎样反问你，在你提问之前预先将黑客们可能遇到的问题回答一遍。 以上几点中，当你报告的是你认为可能在代码中的问题时，给黑客一个可以重现你的问题的环境尤其重要。当你这么做时，你得到有效的回答的机会和速度都会大大的提升。 Simon Tatham 写过一篇名为《如何有效的报告 Bug》的出色文章。强力推荐你也读一读。 话不在多而在精 你需要提供精确有内容的信息。这并不是要求你简单的把成堆的出错代码或者资料完全转录到你的提问中。如果你有庞大而复杂的测试样例能重现程序挂掉的情境，尽量将它剪裁得越小越好。 这样做的用处至少有三点。第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加；第二，简化问题使你更有可能得到有用的答案；第三，在精炼你的 bug 报告的过程中，你很可能就自己找到了解决方法或权宜之计。 别动辄声称找到 Bug 当你在使用软件中遇到问题，除非你非常、非常的有根据，不要动辄声称找到了 Bug。提示：除非你能提供解决问题的源代码补丁，或者提供回归测试来表明前一版本中行为不正确，否则你都多半不够完全确信。这同样适用在网页和文件，如果你（声称）发现了文件的Bug，你应该能提供相应位置的修正或替代文件。 请记得，还有许多其它使用者没遇到你发现的问题，否则你在阅读文件或搜索网页时就应该发现了（你在抱怨前已经做了这些，是吧？）。这也意味着很有可能是你弄错了而不是软件本身有问题。 编写软件的人总是非常辛苦地使它尽可能完美。如果你声称找到了 Bug，也就是在质疑他们的能力，即使你是对的，也有可能会冒犯到其中某部分人。当你在标题中嚷嚷着有Bug时，这尤其严重。 提问时，即使你私下非常确信已经发现一个真正的 Bug，最好写得像是你做错了什么。如果真的有 Bug，你会在回复中看到这点。这样做的话，如果真有 Bug，维护者就会向你道歉，这总比你惹恼别人然后欠别人一个道歉要好一点。 低声下气不能代替你的功课 有些人明白他们不该粗鲁或傲慢的提问并要求得到答复，但他们选择另一个极端 – 低声下气：我知道我只是个可悲的新手，一个撸瑟，但…。这既使人困扰，也没有用，尤其是伴随着与实际问题含糊不清的描述时更令人反感。 别用原始灵长类动物的把戏来浪费你我的时间。取而代之的是，尽可能清楚地描述背景条件和你的问题情况。这比低声下气更好地定位了你的位置。 有时网页论坛会设有专为新手提问的版面，如果你真的认为遇到了初学者的问题，到那去就是了，但一样别那么低声下气。 描述问题症状而非你的猜测 告诉黑客们你认为问题是怎样造成的并没什么帮助。（如果你的推断如此有效，还用向别人求助吗？），因此要确信你原原本本告诉了他们问题的症状，而不是你的解释和理论；让黑客们来推测和诊断。如果你认为陈述自己的猜测很重要，清楚地说明这只是你的猜测，并描述为什么它们不起作用。 蠢问题 我在编译内核时接连遇到 SIG11 错误， 我怀疑某条飞线搭在主板的走线上了，这种情况应该怎样检查最好？ 聪明问题 我的组装电脑是 FIC-PA2007 主机板搭载 AMD K6/233 CPU（威盛 Apollo VP2 芯片组）， 256MB Corsair PC133 SDRAM 内存，在编译内核时，从开机 20 分钟以后就频频产生 SIG11 错误， 但是在头 20 分钟内从没发生过相同的问题。重新启动也没有用，但是关机一晚上就又能工作 20 分钟。 所有内存都换过了，没有效果。相关部分的标准编译记录如下…。 由于以上这点似乎让许多人觉得难以配合，这里有句话可以提醒你：所有的诊断专家都来自密苏里州。 美国国务院的官方座右铭则是：让我看看（出自国会议员 Willard D. Vandiver 在 1899 年时的讲话：我来自一个出产玉米，棉花，牛蒡和民主党人的国家，滔滔雄辩既不能说服我，也不会让我满意。我来自密苏里州，你必须让我看看。） 针对诊断者而言，这并不是一种怀疑，而只是一种真实而有用的需求，以便让他们看到的是与你看到的原始证据尽可能一致的东西，而不是你的猜测与归纳的结论。所以，大方的展示给我们看吧！ 按发生时间先后列出问题症状 问题发生前的一系列操作，往往就是对找出问题最有帮助的线索。因此，你的说明里应该包含你的操作步骤，以及机器和软件的反应，直到问题发生。在命令行处理的情况下，提供一段操作记录（例如运行脚本工具所生成的），并引用相关的若干行（如 20 行）记录会非常有帮助。 如果挂掉的程序有诊断选项（如 -v 的详述开关），试着选择这些能在记录中增加调试信息的选项。记住，多不等于好。试着选取适当的调试级别以便提供有用的信息而不是让读者淹没在垃圾中。 如果你的说明很长（如超过四个段落），在开头简述问题，接下来再按时间顺序详述会有所帮助。这样黑客们在读你的记录时就知道该注意哪些内容了。 描述目标而不是过程 如果你想弄清楚如何做某事（而不是报告一个 Bug），在开头就描述你的目标，然后才陈述重现你所卡住的特定步骤。 经常寻求技术帮助的人在心中有个更高层次的目标，而他们在自以为能达到目标的特定道路上被卡住了，然后跑来问该怎么走，但没有意识到这条路本身就有问题。结果要费很大的劲才能搞定。 蠢问题 我怎样才能从某绘图程序的颜色选择器中取得十六进制的的 RGB 值？ 聪明问题 我正试着用替换一幅图片的色码（color table）成自己选定的色码，我现在知道的唯一方法是编辑每个色码区块（table slot）， 但却无法从某绘图程序的颜色选择器取得十六进制的的 RGB 值。 第二种提问法比较聪明，你可能得到像是建议采用另一个更合适的工具的回复。 别要求使用私人电邮回复 黑客们认为问题的解决过程应该公开、透明，此过程中如果更有经验的人注意到不完整或者不当之处，最初的回复才能够、也应该被纠正。同时，作为提供帮助者可以得到一些奖励，奖励就是他的能力和学识被其他同行看到。 当你要求私下回复时，这个过程和奖励都被中止。别这样做，让回复者来决定是否私下回答 – 如果他真这么做了，通常是因为他认为问题编写太差或者太肤浅，以至于对其它人没有兴趣。 这条规则存在一条有限的例外，如果你确信提问可能会引来大量雷同的回复时，那么这个神奇的提问句会是向我发电邮，我将为论坛归纳这些回复。试着将邮件列表或新闻群组从洪水般的雷同回复中解救出来是非常有礼貌的 – 但你必须信守诺言。 清楚明确的表达你的问题以及需求 漫无边际的提问是近乎无休无止的时间黑洞。最有可能给你有用答案的人通常也正是最忙的人（他们忙是因为要亲自完成大部分工作）。这样的人对无节制的时间黑洞相当厌恶，所以他们也倾向于厌恶那些漫无边际的提问。 如果你明确表述需要回答者做什么（如提供指点、发送一段代码、检查你的补丁、或是其他等等），就最有可能得到有用的答案。因为这会定出一个时间和精力的上限，便于回答者能集中精力来帮你。这么做很棒。 要理解专家们所处的世界，请把 专业技能想像为充裕的资源，而回复的时间则是稀缺的资源。 你要求他们奉献的时间越少，你越有可能从真正专业而且很忙的专家那里得到解答。 所以，界定一下你的问题，使专家花在辨识你的问题和回答所需要付出的时间减到最少，这技巧对你有用答案相当有帮助 – 但这技巧通常和简化问题有所区别。因此，问我想更好的理解 X，可否指点一下哪有好一点说明？通常比问你能解释一下 X 吗？更好。如果你的代码不能运作，通常请别人看看哪里有问题，比要求别人替你改正要明智得多。 询问有关代码的问题时别要求他人帮你调试有问题的代码，不提示一下应该从何入手。张贴几百行的代码，然后说一声：它不能工作会让你完全被忽略。只贴几十行代码，然后说一句：在第七行以后，我期待它显示 ，但实际出现的是 比较有可能让你得到回应。 最有效描述程序问题的方法是提供最精简的 Bug 展示测试示例（bug-demonstrating test case）。什么是最精简的测试示例？那是问题的缩影；一小个程序片段能刚好展示出程序的异常行为，而不包含其他令人分散注意力的内容。怎么制作最精简的测试示例？如果你知道哪一行或哪一段代码会造成异常的行为，复制下来并加入足够重现这个状况的代码（例如，足以让这段代码能被编译/直译/被应用程序处理）。如果你无法将问题缩减到一个特定区块，就复制一份代码并移除不影响产生问题行为的部分。总之，测试示例越小越好（查看话不在多而在精一节）。 一般而言，要得到一段相当精简的测试示例并不太容易，但永远先尝试这样做的是种好习惯。这种方式可以帮助你了解如何自行解决这个问题 —- 而且即使你的尝试不成功，黑客们也会看到你在尝试取得答案的过程中付出了努力，这可以让他们更愿意与你合作。 如果你只是想让别人帮忙审查（Review）一下代码，在信的开头就要说出来，并且一定要提到你认为哪一部分特别需要关注以及为什么。 别把自己家庭作业的问题贴上来 黑客们很擅长分辨哪些问题是家庭作业式的问题；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由你来搞定，你会从中学到东西。你可以要求给点提示，但别要求得到完整的解决方案。 如果你怀疑自己碰到了一个家庭作业式的问题，但仍然无法解决，试试在使用者群组，论坛或（最后一招）在项目的使用者邮件列表或论坛中提问。尽管黑客们会看出来，但一些有经验的使用者也许仍会给你一些提示。 去掉无意义的提问句 避免用无意义的话结束提问，例如有人能帮我吗？或者这有答案吗？。 首先：如果你对问题的描述不是很好，这样问更是画蛇添足。 其次：由于这样问是画蛇添足，黑客们会很厌烦你 – 而且通常会用逻辑上正确，但毫无意义的回答来表示他们的蔑视， 例如：没错，有人能帮你或者不，没答案。 一般来说，避免用 是或否、对或错、有或没有类型的问句，除非你想得到是或否类型的回答。 即使你很急也不要在标题写紧急 这是你的问题，不是我们的。宣称紧急极有可能事与愿违：大多数黑客会直接删除无礼和自私地企图即时引起关注的问题。更严重的是，紧急这个字（或是其他企图引起关注的标题）通常会被垃圾信过滤器过滤掉 – 你希望能看到你问题的人可能永远也看不到。 有半个例外的情况是，如果你是在一些很高调，会使黑客们兴奋的地方，也许值得这样去做。在这种情况下，如果你有时间压力，也很有礼貌地提到这点，人们也许会有兴趣回答快一点。 当然，这风险很大，因为黑客们兴奋的点多半与你的不同。譬如从 NASA 国际空间站（International Space Station）发这样的标题没有问题，但用自我感觉良好的慈善行为或政治原因发肯定不行。事实上，张贴诸如紧急：帮我救救这个毛绒绒的小海豹！肯定让你被黑客忽略或惹恼他们，即使他们认为毛绒绒的小海豹很重要。 如果你觉得这点很不可思议，最好再把这份指南剩下的内容多读几遍，直到你弄懂了再发文。 礼多人不怪，而且有时还很有帮助 彬彬有礼，多用请和谢谢您的关注，或谢谢你的关照。让大家都知道你对他们花时间免费提供帮助心存感激。 坦白说，这一点并没有比清晰、正确、精准并合法语法和避免使用专用格式重要（也不能取而代之）。黑客们一般宁可读有点唐突但技术上鲜明的 Bug 报告，而不是那种有礼但含糊的报告。（如果这点让你不解，记住我们是按问题能教给我们什么来评价问题的价值的） 然而，如果你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。 （我们注意到，自从本指南发布后，从资深黑客那里得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些黑客觉得先谢了意味着事后就不用再感谢任何人的暗示。我们的建议是要么先说先谢了，然后事后再对回复者表示感谢，或者换种方式表达感激，譬如用谢谢你的关注或谢谢你的关照。） 问题解决后，加个简短的补充说明 问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个说明比较恰当。 最理想的方式是向最初提问的话题回复此消息，并在标题中包含已修正，已解决或其它同等含义的明显标记。在人来人往的邮件列表里，一个看见讨论串问题 X和问题 X - 已解决的潜在回复者就明白不用再浪费时间了（除非他个人觉得问题 X的有趣），因此可以利用此时间去解决其它问题。 补充说明不必很长或是很深入；简单的一句你好，原来是网线出了问题！谢谢大家 – Bill比什么也不说要来的好。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇大论更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。 对于有深度的问题，张贴调试记录的摘要是有帮助的。描述问题的最终状态，说明是什么解决了问题，在此之后才指明可以避免的盲点。避免盲点的部分应放在正确的解决方案和其它总结材料之后，而不要将此信息搞成侦探推理小说。列出那些帮助过你的名字，会让你交到更多朋友。 除了有礼貌和有内涵以外，这种类型的补充也有助于他人在邮件列表/新闻群组/论坛中搜索到真正解决你问题的方案，让他们也从中受益。 至少，这种补充有助于让每位参与协助的人因问题的解决而从中得到满足感。如果你自己不是技术专家或者黑客，那就相信我们，这种感觉对于那些你向他们求助的大师或者专家而言，是非常重要的。问题悬而未决会让人灰心；黑客们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次提问时尝到甜头。 思考一下怎样才能避免他人将来也遇到类似的问题，自问写一份文件或加个常见问题（FAQ）会不会有帮助。如果是的话就将它们发给维护者。 在黑客中，这种良好的后继行动实际上比传统的礼节更为重要，也是你如何透过善待他人而赢得声誉的方式，这是非常有价值的资产。 如何解读答案RTFM 和 STFW：如何知道你已完全搞砸了 有一个古老而神圣的传统：如果你收到 RTFM （Read The Fucking Manual） 的回应，回答者认为你应该去读他妈的手册。当然，基本上他是对的，你应该去读一读。 RTFM 有一个年轻的亲戚。如果你收到 STFW（Search The Fucking Web） 的回应，回答者认为你应该到他妈的网上搜索过了。那人多半也是对的，去搜索一下吧。（更温和一点的说法是 Google 是你的朋友！） 在论坛，你也可能被要求去爬爬论坛的旧文。事实上，有人甚至可能热心地为你提供以前解决此问题的讨论串。但不要依赖这种关照，提问前应该先搜索一下旧文。 通常，用这两句之一回答你的人会给你一份包含你需要内容的手册或者一个网址，而且他们打这些字的时候也正在读着。这些答复意味着回答者认为 你需要的信息非常容易获得； 你自己去搜索这些信息比灌给你，能让你学到更多。 你不应该因此不爽；依照黑客的标准，他已经表示了对你一定程度的关注，而没有对你的要求视而不见。你应该对他祖母般的慈祥表示感谢。 如果还是搞不懂 如果你看不懂回应，别立刻要求对方解释。像你以前试着自己解决问题时那样（利用手册，FAQ，网络，身边的高手），先试着去搞懂他的回应。如果你真的需要对方解释，记得表现出你已经从中学到了点什么。 比方说，如果我回答你：看来似乎是 zentry 卡住了；你应该先清除它。，然后，这是一个很糟的后续问题回应：zentry 是什么？ 好的问法应该是这样：哦~~~我看过说明了但是只有 -z 和 -p 两个参数中提到了 zentries，而且还都没有清楚的解释如何清除它。你是指这两个中的哪一个吗？还是我看漏了什么？ 处理无礼的回应 很多黑客圈子中看似无礼的行为并不是存心冒犯。相反，它是直接了当，一针见血式的交流风格，这种风格更注重解决问题，而不是使人感觉舒服而却模模糊糊。 如果你觉得被冒犯了，试着平静地反应。如果有人真的做了出格的事，邮件列表、新闻群组或论坛中的前辈多半会招呼他。如果这没有发生而你却发火了，那么你发火对象的言语可能在黑客社区中看起来是正常的，而你将被视为有错的一方，这将伤害到你获取信息或帮助的机会。 另一方面，你偶而真的会碰到无礼和无聊的言行。与上述相反，对真正的冒犯者狠狠地打击，用犀利的语言将其驳得体无完肤都是可以接受的。然而，在行事之前一定要非常非常的有根据。纠正无礼的言论与开始一场毫无意义的口水战仅一线之隔，黑客们自己莽撞地越线的情况并不鲜见。如果你是新手或外人，避开这种莽撞的机会并不高。如果你想得到的是信息而不是消磨时光，这时最好不要把手放在键盘上以免冒险。 （有些人断言很多黑客都有轻度的自闭症或亚斯伯格综合症，缺少用于润滑人类社会正常交往所需的神经。这既可能是真也可能是假的。如果你自己不是黑客，兴许你认为我们脑袋有问题还能帮助你应付我们的古怪行为。只管这么干好了，我们不在乎。我们喜欢我们现在这个样子，并且通常对病患标记都有站得住脚的怀疑。） Jeff Bigler 的观察总结和这个相关也值得一读 (tact filters)。 在下一节，我们会谈到另一个问题，当你行为不当时所会受到的冒犯。 如何避免扮演失败者在黑客社区的论坛中有那么几次你可能会搞砸 – 以本指南所描述到的或类似的方式。而你会在公开场合中被告知你是如何搞砸的，也许攻击的言语中还会带点夹七夹八的颜色。 这种事发生以后，你能做的最糟糕的事莫过于哀嚎你的遭遇、宣称被口头攻击、要求道歉、高声尖叫、憋闷气、威胁诉诸法律、向其雇主报怨、忘了关马桶盖等等。相反地，你该这么做： 熬过去，这很正常。事实上，它是有益健康且合理的。 社区的标准不会自行维持，它们是通过参与者积极而公开地执行来维持的。不要哭嚎所有的批评都应该通过私下的邮件传送，它不是这样运作的。当有人评论你的一个说法有误或者提出不同看法时，坚持声称受到个人攻击也毫无益处，这些都是失败者的态度。 也有其它的黑客论坛，受过高礼节要求的误导，禁止参与者张贴任何对别人帖子挑毛病的消息，并声称如果你不想帮助用户就闭嘴。 结果造成有想法的参与者纷纷离开，这么做只会使它们沦为毫无意义的唠叨与无用的技术论坛。 夸张的讲法是：你要的是友善（以上述方式）还是有用？两个里面挑一个。 记着：当黑客说你搞砸了，并且（无论多么刺耳）告诉你别再这样做时，他正在为关心你和他的社区而行动。对他而言，不理你并将你从他的生活中滤掉更简单。如果你无法做到感谢，至少要表现得有点尊严，别大声哀嚎，也别因为自己是个有戏剧性超级敏感的灵魂和自以为有资格的新来者，就指望别人像对待脆弱的洋娃娃那样对你。 有时候，即使你没有搞砸（或者只是在他的想像中你搞砸了），有些人也会无缘无故地攻击你本人。在这种情况下，抱怨倒是真的会把问题搞砸。 这些来找麻烦的人要么是毫无办法但自以为是专家的不中用家伙，要么就是测试你是否真会搞砸的心理专家。其它读者要么不理睬，要么用自己的方式对付他们。这些来找麻烦的人在给他们自己找麻烦，这点你不用操心。 也别让自己卷入口水战，最好不要理睬大多数的口水战 – 当然，这是在你检验它们只是口水战，并且未指出你有搞砸的地方，同时也没有巧妙地将问题真正的答案藏于其后（这也是有可能的）。 不该问的问题 以下是几个经典蠢问题，以及黑客没回答时心中所想的： 问题：我能在哪找到 X 程序或 X 资源？ 问题：我怎样用 X 做 Y？ 问题：如何设定我的 shell 提示？ 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？ 问题：我的程序/设定/SQL 语句没有用 问题：我的 Windows 电脑有问题，你能帮我吗？ 问题：我的程序不会动了，我认为系统工具 X 有问题 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？ 问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？ 问题：我能在哪找到 X 程序或 X 资源？回答：就在我找到它的地方啊，白痴 – 搜索引擎的那一头。天哪！难道还有人不会用 Google 吗？ 问题：我怎样用 X 做 Y？回答：如果你想解决的是 Y ，提问时别给出可能并不恰当的方法。这种问题说明提问者不但对 X 完全无知，也对 Y 要解决的问题糊涂，还被特定形势禁锢了思维。最好忽略这种人，等他们把问题搞清楚了再说。 问题：如何设定我的 shell 提示？？回答：如果你有足够的智慧提这个问题，你也该有足够的智慧去 RTFM，然后自己去找出来。 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？回答：试试看就知道了。如果你试过，你既知道了答案，就不用浪费我的时间了。 问题：我的{程序/设定/SQL 语句}不工作回答：这不算是问题吧，我对要我问你二十个问题才找得出你真正问题的问题没兴趣 – 我有更有意思的事要做呢。在看到这类问题的时候，我的反应通常不外如下三种 你还有什么要补充的吗？真糟糕，希望你能搞定。这关我有什么屁事？ 问题：我的 Windows 电脑有问题，你能帮我吗？回答：能啊，扔掉微软的垃圾，换个像 Linux 或 BSD 的开放源代码操作系统吧。 注意：如果程序有官方版 Windows 或者与 Windows 有互动（如 Samba），你可以问与 Windows 相关的问题， 只是别对问题是由 Windows 操作系统而不是程序本身造成的回复感到惊讶， 因为 Windows 一般来说实在太烂，这种说法通常都是对的。 问题：我的程序不会动了，我认为系统工具 X 有问题回答：你完全有可能是第一个注意到被成千上万用户反复使用的系统调用与函数库档案有明显缺陷的人，更有可能的是你完全没有根据。不同凡响的说法需要不同凡响的证据，当你这样声称时，你必须有清楚而详尽的缺陷说明文件作后盾。 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的 Linux 使用群组者寻求实际的指导吧（你能在这儿找到使用者群组的清单）。 注意：如果安装问题与某 Linux 的发行版有关，在它的邮件列表、论坛或本地使用者群组中提问也许是恰当的。此时，应描述问题的准确细节。在此之前，先用 Linux 和所有被怀疑的硬件作关键词仔细搜索。 问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？回答：想要这样做，说明了你是个卑鄙小人；想找个黑客帮你，说明你是个白痴！ 好问题与蠢问题最后，我将透过举一些例子，来说明怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。 蠢问题： 我可以在哪儿找到关于 Foonly Flurbamatic 的资料？这种问法无非想得到 STFW 这样的回答。 聪明问题： 我用 Google 搜索过 “Foonly Flurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？这个问题已经 STFW 过了，看起来他真的遇到了麻烦。 蠢问题 我从 foo 项目找来的源码没法编译。它怎么这么烂？他觉得都是别人的错，这个傲慢自大的提问者。 聪明问题 foo 项目代码在 Nulix 6.2 版下无法编译通过。我读过了 FAQ，但里面没有提到跟 Nulix 有关的问题。这是我编译过程的记录，我有什么做的不对的地方吗？提问者已经指明了环境，也读过了 FAQ，还列出了错误，并且他没有把问题的责任推到别人头上，他的问题值得被关注。 蠢问题 我的主机板有问题了，谁来帮我？某黑客对这类问题的回答通常是：好的，还要帮你拍拍背和换尿布吗？，然后按下删除键。 聪明问题 我在 S2464 主机板上试过了 X 、 Y 和 Z ，但没什么作用，我又试了 A 、 B 和 C 。请注意当我尝试 C 时的奇怪现象。显然 florbish 正在 grommicking，但结果出人意料。通常在 Athlon MP 主机板上引起 grommicking 的原因是什么？有谁知道接下来我该做些什么测试才能找出问题？这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。 在最后一个问题中，注意告诉我答案和给我启示，指出我还应该做什么诊断工作之间微妙而又重要的区别。 事实上，后一个问题源自于 2001 年 8 月在 Linux 内核邮件列表（lkml）上的一个真实的提问。我（Eric）就是那个提出问题的人。我在 Tyan S2464 主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决这一问题的重要信息。 通过我的提问方法，我给了别人可以咀嚼玩味的东西；我设法让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，并邀请他们与我共同探讨。通过告诉他们我所走过的弯路，以避免他们再浪费时间，我也表明了对他们宝贵时间的尊重。 事后，当我向每个人表示感谢，并且赞赏这次良好的讨论经历的时候， 一个 Linux 内核邮件列表的成员表示，他觉得我的问题得到解决并非由于我是这个列表中的名人，而是因为我用了正确的方式来提问。 黑客从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我像个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，这直接导致了本指南的出现。 如果得不到回答如果仍得不到回答，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。 总的来说，简单的重复张贴问题是个很糟的点子。这将被视为无意义的喧闹。有点耐心，知道你问题答案的人可能生活在不同的时区，可能正在睡觉，也有可能你的问题一开始就没有组织好。 你可以通过其他渠道获得帮助，这些渠道通常更适合初学者的需要。 有许多网上的以及本地的使用者群组，由热情的软件爱好者（即使他们可能从没亲自写过任何软件）组成。通常人们组建这样的团体来互相帮助并帮助新手。 另外，你可以向很多商业公司寻求帮助，不论公司大还是小。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了– 完全可能如此 –你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。 对像是 Linux 这种大众化的软件，每个开发者至少会对应到上万名使用者。根本不可能由一个人来处理来自上万名使用者的求助电话。要知道，即使你要为这些协助付费，和你所购买的同类软件相比，你所付出的也是微不足道的（通常封闭源代码软件的技术支持费用比开放源代码软件的要高得多，且内容也没那么丰富）。 如何更好地回答问题态度和善一点。问题带来的压力常使人显得无礼或愚蠢，其实并不是这样。 对初犯者私下回复。对那些坦诚犯错之人没有必要当众羞辱，一个真正的新手也许连怎么搜索或在哪找常见问题都不知道。 如果你不确定，一定要说出来！一个听起来权威的错误回复比没有还要糟，别因为听起来像个专家很好玩，就给别人乱指路。要谦虚和诚实，给提问者与同行都树个好榜样。 如果帮不了忙，也别妨碍他。不要在实际步骤上开玩笑，那样也许会毁了使用者的设置 –有些可怜的呆瓜会把它当成真的指令。 试探性的反问以引出更多的细节。如果你做得好，提问者可以学到点东西 –你也可以。试试将蠢问题转变成好问题，别忘了我们都曾是新手。 尽管对那些懒虫抱怨一声 RTFM 是正当的，能指出文件的位置（即使只是建议个 Google 搜索关键词）会更好。 如果你决定回答，就请给出好的答案。当别人正在用错误的工具或方法时别建议笨拙的权宜之计（wordaround），应推荐更好的工具，重新界定问题。 正面的回答问题！如果这个提问者已经很深入的研究而且也表明已经试过 X 、 Y 、 Z 、 A 、 B 、 C 但没得到结果，回答 试试看 A 或是 B 或者 试试 X 、 Y 、 Z 、 A 、 B 、 C 并附上一个链接一点用都没有。 帮助你的社区从问题中学习。当回复一个好问题时，问问自己如何修改相关文件或常见问题文件以免再次解答同样的问题？，接着再向文件维护者发一份补丁。 如果你是在研究一番后才做出的回答，展现你的技巧而不是直接端出结果。毕竟 授人以鱼不如授人以渔。 相关资源 如果你需要个人电脑、Unix 系统和网络如何运作的基础知识，参阅 Unix 系统和网络基本原理。 当你发布软件或补丁时，试着按软件发布实践操作。 鸣谢 Evelyn Mitchel 贡献了一些愚蠢问题例子并启发了编写如何更好地回答问题这一节， Mikhail Ramendik 贡献了一些特别有价值的建议和改进。 How To Ask Questions The Smart WayEric Steven Raymond Thyrsus Enterprises &lt;esr@thyrsus.com&gt; Rick Moen &lt;respond-auto@linuxmafia.com&gt; Copyright © 2001,2006,2014 Eric S. Raymond, Rick Moen Revision HistoryRevision 3.10 21 May 2014 esrNew section on Stack Overflow.Revision 3.9 23 Apr 2013 esrURL fixes.Revision 3.8 19 Jun 2012 esrURL fix.Revision 3.7 06 Dec 2010 esrHelpful hints for ESL speakers.Revision 3.7 02 Nov 2010 esrSeveral translations have disappeared.Revision 3.6 19 Mar 2008 esrMinor update and new links.Revision 3.5 2 Jan 2008 esrTypo fix and some translation links.Revision 3.4 24 Mar 2007 esrNew section, “When asking about code”.Revision 3.3 29 Sep 2006 esrFolded in a good suggestion from Kai Niggemann.Revision 3.2 10 Jan 2006 esrFolded in edits from Rick Moen.Revision 3.1 28 Oct 2004 esrDocument ‘Google is your friend!’Revision 3.0 2 Feb 2004 esrMajor addition of stuff about proper etiquette on Web forums.Table of Contents TranslationsDisclaimerIntroductionBefore You AskWhen You AskChoose your forum carefullyStack OverflowWeb and IRC forumsAs a second step, use project mailing listsUse meaningful, specific subject headersMake it easy to replyWrite in clear, grammatical, correctly-spelled languageSend questions in accessible, standard formatsBe precise and informative about your problemVolume is not precisionDon’t rush to claim that you have found a bugGrovelling is not a substitute for doing your homeworkDescribe the problem’s symptoms, not your guessesDescribe your problem’s symptoms in chronological orderDescribe the goal, not the stepDon’t ask people to reply by private e-mailBe explicit about your questionWhen asking about codeDon’t post homework questionsPrune pointless queriesDon’t flag your question as “Urgent”, even if it is for youCourtesy never hurts, and sometimes helpsFollow up with a brief note on the solutionHow To Interpret AnswersRTFM and STFW: How To Tell You’ve Seriously Screwed UpIf you don’t understand…Dealing with rudenessOn Not Reacting Like A LoserQuestions Not To AskGood and Bad QuestionsIf You Can’t Get An AnswerHow To Answer Questions in a Helpful WayRelated ResourcesAcknowledgementsTranslations Translations: Bahasa Indonesian Belorussian Brazilo-Portuguese Bulgarian Chinese (Traditional) Croatian Dutch French Georgian German Greek Hindi Irish Gaelic Japanese Lithuanian Polish Portuguese Romanian Russian Serbian Spanish Uzbek If you want to copy, mirror, translate, or excerpt this document, please see my copying policy. Disclaimer Many project websites link to this document in their sections on how to get help. That’s fine, it’s the use we intended — but if you are a webmaster creating such a link for your project page, please display prominently near the link notice that we are not a help desk for your project! We have learned the hard way that without such a notice, we will repeatedly be pestered by idiots who think having published this document makes it our job to solve all the world’s technical problems. If you’re reading this document because you need help, and you walk away with the impression you can get it directly from the authors of this document, you are one of the idiots we are talking about. Don’t ask us questions. We’ll just ignore you. We are here to show you how to get help from people who actually know about the software or hardware you’re dealing with, but 99.9% of the time that will not be us. Unless you know for certain that one of the authors is an expert on what you’re dealing with, leave us alone and everybody will be happier. Introduction In the world of hackers, the kind of answers you get to your technical questions depends as much on the way you ask the questions as on the difficulty of developing the answer. This guide will teach you how to ask questions in a way more likely to get you a satisfactory answer. Now that use of open source has become widespread, you can often get as good answers from other, more experienced users as from hackers. This is a Good Thing; users tend to be just a little bit more tolerant of the kind of failures newbies often have. Still, treating experienced users like hackers in the ways we recommend here will generally be the most effective way to get useful answers out of them, too. The first thing to understand is that hackers actually like hard problems and good, thought-provoking questions about them. If we didn’t, we wouldn’t be here. If you give us an interesting question to chew on we’ll be grateful to you; good questions are a stimulus and a gift. Good questions help us develop our understanding, and often reveal problems we might not have noticed or thought about otherwise. Among hackers, “Good question!” is a strong and sincere compliment. Despite this, hackers have a reputation for meeting simple questions with what looks like hostility or arrogance. It sometimes looks like we’re reflexively rude to newbies and the ignorant. But this isn’t really true. What we are, unapologetically, is hostile to people who seem to be unwilling to think or to do their own homework before asking questions. People like that are time sinks — they take without giving back, and they waste time we could have spent on another question more interesting and another person more worthy of an answer. We call people like this “losers” (and for historical reasons we sometimes spell it “lusers”). We realize that there are many people who just want to use the software we write, and who have no interest in learning technical details. For most people, a computer is merely a tool, a means to an end; they have more important things to do and lives to live. We acknowledge that, and don’t expect everyone to take an interest in the technical matters that fascinate us. Nevertheless, our style of answering questions is tuned for people who do take such an interest and are willing to be active participants in problem-solving. That’s not going to change. Nor should it; if it did, we would become less effective at the things we do best. We’re (largely) volunteers. We take time out of busy lives to answer questions, and at times we’re overwhelmed with them. So we filter ruthlessly. In particular, we throw away questions from people who appear to be losers in order to spend our question-answering time more efficiently, on winners. If you find this attitude obnoxious, condescending, or arrogant, check your assumptions. We’re not asking you to genuflect to us — in fact, most of us would love nothing more than to deal with you as an equal and welcome you into our culture, if you put in the effort required to make that possible. But it’s simply not efficient for us to try to help people who are not willing to help themselves. It’s OK to be ignorant; it’s not OK to play stupid. So, while it isn’t necessary to already be technically competent to get attention from us, it is necessary to demonstrate the kind of attitude that leads to competence — alert, thoughtful, observant, willing to be an active partner in developing a solution. If you can’t live with this sort of discrimination, we suggest you pay somebody for a commercial support contract instead of asking hackers to personally donate help to you. If you decide to come to us for help, you don’t want to be one of the losers. You don’t want to seem like one, either. The best way to get a rapid and responsive answer is to ask it like a person with smarts, confidence, and clues who just happens to need help on one particular problem. (Improvements to this guide are welcome. You can mail suggestions to esr@thyrsus.com or respond-auto@linuxmafia.com. Note however that this document is not intended to be a general guide to netiquette, and we will generally reject suggestions that are not specifically related to eliciting useful answers in a technical forum.) Before You Ask Before asking a technical question by e-mail, or in a newsgroup, or on a website chat board, do the following: Try to find an answer by searching the archives of the forum or mailing list you plan to post to. Try to find an answer by searching the Web. Try to find an answer by reading the manual. Try to find an answer by reading a FAQ. Try to find an answer by inspection or experimentation. Try to find an answer by asking a skilled friend. If you’re a programmer, try to find an answer by reading the source code. When you ask your question, display the fact that you have done these things first; this will help establish that you’re not being a lazy sponge and wasting people’s time. Better yet, display what you have learned from doing these things. We like answering questions for people who have demonstrated they can learn from the answers. Use tactics like doing a Google search on the text of whatever error message you get (searching Google groups as well as Web pages). This might well take you straight to fix documentation or a mailing list thread answering your question. Even if it doesn’t, saying “I googled on the following phrase but didn’t get anything that looked promising” is a good thing to do in e-mail or news postings requesting help, if only because it records what searches won’t help. It will also help to direct other people with similar problems to your thread by linking the search terms to what will hopefully be your problem and resolution thread. Take your time. Do not expect to be able to solve a complicated problem with a few seconds of Googling. Read and understand the FAQs, sit back, relax and give the problem some thought before approaching experts. Trust us, they will be able to tell from your questions how much reading and thinking you did, and will be more willing to help if you come prepared. Don’t instantly fire your whole arsenal of questions just because your first search turned up no answers (or too many). Prepare your question. Think it through. Hasty-sounding questions get hasty answers, or none at all. The more you do to demonstrate that having put thought and effort into solving your problem before seeking help, the more likely you are to actually get help. Beware of asking the wrong question. If you ask one that is based on faulty assumptions, J. Random Hacker is quite likely to reply with a uselessly literal answer while thinking “Stupid question…”, and hoping the experience of getting what you asked for rather than what you needed will teach you a lesson. Never assume you are entitled to an answer. You are not; you aren’t, after all, paying for the service. You will earn an answer, if you earn it, by asking a substantial, interesting, and thought-provoking question — one that implicitly contributes to the experience of the community rather than merely passively demanding knowledge from others. On the other hand, making it clear that you are able and willing to help in the process of developing the solution is a very good start. “Would someone provide a pointer?”, “What is my example missing?”, and “What site should I have checked?” are more likely to get answered than “Please post the exact procedure I should use.” because you’re making it clear that you’re truly willing to complete the process if someone can just point you in the right direction. When You Ask Choose your forum carefully Be sensitive in choosing where you ask your question. You are likely to be ignored, or written off as a loser, if you: post your question to a forum where it’s off topic post a very elementary question to a forum where advanced technical questions are expected, or vice-versa cross-post to too many different newsgroups post a personal e-mail to somebody who is neither an acquaintance of yours nor personally responsible for solving your problem Hackers blow off questions that are inappropriately targeted in order to try to protect their communications channels from being drowned in irrelevance. You don’t want this to happen to you. The first step, therefore, is to find the right forum. Again, Google and other Web-searching methods are your friend. Use them to find the project webpage most closely associated with the hardware or software giving you difficulties. Usually it will have links to a FAQ (Frequently Asked Questions) list, and to project mailing lists and their archives. These mailing lists are the final places to go for help, if your own efforts (including reading those FAQs you found) do not find you a solution. The project page may also describe a bug-reporting procedure, or have a link to one; if so, follow it. Shooting off an e-mail to a person or forum which you are not familiar with is risky at best. For example, do not assume that the author of an informative webpage wants to be your free consultant. Do not make optimistic guesses about whether your question will be welcome — if you’re unsure, send it elsewhere, or refrain from sending it at all. When selecting a Web forum, newsgroup or mailing list, don’t trust the name by itself too far; look for a FAQ or charter to verify your question is on-topic. Read some of the back traffic before posting so you’ll get a feel for how things are done there. In fact, it’s a very good idea to do a keyword search for words relating to your problem on the newsgroup or mailing list archives before you post. It may find you an answer, and if not it will help you formulate a better question. Don’t shotgun-blast all the available help channels at once, that’s like yelling and irritates people. Step through them softly. Know what your topic is! One of the classic mistakes is asking questions about the Unix or Windows programming interface in a forum devoted to a language or library or tool portable across both. If you don’t understand why this is a blunder, you’d be best off not asking any questions at all until you get it. In general, questions to a well-selected public forum are more likely to get useful answers than equivalent questions to a private one. There are multiple reasons for this. One is simply the size of the pool of potential respondents. Another is the size of the audience; hackers would rather answer questions that educate many people than questions serving only a few. Understandably, skilled hackers and authors of popular software are already receiving more than their fair share of mis-targeted messages. By adding to the flood, you could in extreme cases even be the straw that breaks the camel’s back — quite a few times, contributors to popular projects have withdrawn their support because collateral damage in the form of useless e-mail traffic to their personal accounts became unbearable. Stack Overflow Search, then ask on Stack Exchange In recent years, the Stack Exchange community of sites has emerged as a major resource for answering technical and other questions and is even the preferred forum for many open-source projects. Start with a Google search before looking at Stack Exchange; Google indexes it in real time. There’s a very good chance someone has already asked a similar question, and the Stack Exchange sites are often near the top of the search results. If you didn’t find anything through Google, search again on the specific site most relevant to your question (see below). Searching with tags can help narrow down the results. If you still didn’t find anything, post your question on the one site where it’s most on-topic. Use the formatting tools, especially for code, and add tags that are related to the substance of your question (particularly the name of the programming language, operating system, or library you’re having trouble with). If a commenter asks you for more information, edit your main post to include it. If any answer is helpful, click the up arrow to upvote it; if an answer gives a solution to your problem, click the check under the voting arrows to accept it as correct. Stack Exchange has grown to over 100 sites, but here are the most likely candidates: Super User is for questions about general-purpose computing. If your question isn’t about code or programs that you talk to only over a network connection, it probably goes here. Stack Overflow is for questions about programming. Server Fault is for questions about server and network administration. Several projects have their own specific sites, including Android, Ubuntu, TeX/LaTeX, and SharePoint. Check the Stack Exchange site for an up-to-date list. Web and IRC forums Your local user group, or your Linux distribution, may advertise a Web forum or IRC channel where newbies can get help. (In non-English-speaking countries newbie forums are still more likely to be mailing lists.) These are good first places to ask, especially if you think you may have tripped over a relatively simple or common problem. An advertised IRC channel is an open invitation to ask questions there and often get answers in real time. In fact, if you got the program that is giving you problems from a Linux distribution (as is common today), it may be better to ask in the distro’s forum/list before trying the program’s project forum/list. The project’s hackers may just say, “use our build”. Before posting to any Web forum, check if it has a Search feature. If it does, try a couple of keyword searches for something like your problem; it just might help. If you did a general Web search before (as you should have), search the forum anyway; your Web-wide search engine might not have all of this forum indexed recently. There is an increasing tendency for projects to do user support over a Web forum or IRC channel, with e-mail reserved more for development traffic. So look for those channels first when seeking project-specific help. In IRC, it’s probably best not to dump a long problem description on the channel first thing; some people interpret this as channel-flooding. Best to utter a one-line problem description in a way pitched to start a conversation on the channel. As a second step, use project mailing lists When a project has a development mailing list, write to the mailing list, not to individual developers, even if you believe you know who can best answer your question. Check the documentation of the project and its homepage for the address of a project mailing list, and use it. There are several good reasons for this policy: Any question good enough to be asked of one developer will also be of value to the whole group. Contrariwise, if you suspect your question is too dumb for a mailing list, it’s not an excuse to harass individual developers. Asking questions on the list distributes load among developers. The individual developer (especially if he’s the project leader) may be too busy to answer your questions. Most mailing lists are archived and the archives are indexed by search engines. If you ask your question on-list and it is answered, a future querent could find your question and the answer on the Web instead of asking it again. If certain questions are seen to be asked often, developers can use that information to improve the documentation or the software itself to be less confusing. But if those questions are asked in private, nobody has the complete picture of what questions are asked most often. If a project has both a “user” and a “developer” (or “hacker”) mailing list or Web forum, and you are not hacking on the code, ask in the “user” list/forum. Do not assume that you will be welcome on the developer list, where they’re likely to experience your question as noise disrupting their developer traffic. However, if you are sure your question is non-trivial, and you get no answer in the “user” list/forum for several days, try the “developer” one. You would be well advised to lurk there for a few daysor at least review the last few days of archived messages, to learn the local folkways before posting (actually this is good advice on any private or semi-private list). If you cannot find a project’s mailing list address, but only see the address of the maintainer of the project, go ahead and write to the maintainer. But even in that case, don’t assume that the mailing list doesn’t exist. Mention in your e-mail that you tried and could not find the appropriate mailing list. Also mention that you don’t object to having your message forwarded to other people. (Many people believe that private e-mail should remain private, even if there is nothing secret in it. By allowing your message to be forwarded you give your correspondent a choice about how to handle your e-mail.) Use meaningful, specific subject headers On mailing lists, newsgroups or Web forums, the subject header is your golden opportunity to attract qualified experts’ attention in around 50 characters or fewer. Don’t waste it on babble like “Please help me” (let alone “PLEASE HELP ME!!!!”; messages with subjects like that get discarded by reflex). Don’t try to impress us with the depth of your anguish; use the space for a super-concise problem description instead. One good convention for subject headers, used by many tech support organizations, is “object - deviation”. The “object” part specifies what thing or group of things is having a problem, and the “deviation” part describes the deviation from expected behavior. Stupid:HELP! Video doesn’t work properly on my laptop! Smart:X.org 6.8.1 misshapen mouse cursor, Fooware MV1005 vid. chipset Smarter:X.org 6.8.1 mouse cursor on Fooware MV1005 vid. chipset - is misshapen The process of writing an “object-deviation” description will help you organize your thinking about the problem in more detail. What is affected? Just the mouse cursor or other graphics too? Is this specific to the X.org version of X? To version 6.8.1? Is this specific to Fooware video chipsets? To model MV1005? A hacker who sees the result can immediately understand what it is that you are having a problem with and the problem you are having, at a glance. More generally, imagine looking at the index of an archive of questions, with just the subject lines showing. Make your subject line reflect your question well enough that the next person searching the archive with a question similar to yours will be able to follow the thread to an answer rather than posting the question again. If you ask a question in a reply, be sure to change the subject line to indicate that you’re asking a question. A Subject line that looks like “Re: test” or “Re: new bug” is less likely to attract useful amounts of attention. Also, pare quotation of previous messages to the minimum consistent with cluing in new readers. Do not simply hit reply to a list message in order to start an entirely new thread. This will limit your audience. Some mail readers, like mutt, allow the user to sort by thread and then hide messages in a thread by folding the thread. Folks who do that will never see your message. Changing the subject is not sufficient. Mutt, and probably other mail readers, looks at other information in the e-mail’s headers to assign it to a thread, not the subject line. Instead start an entirely new e-mail. On Web forums the rules of good practice are slightly different, because messages are usually much more tightly bound to specific discussion threads and often invisible outside those threads. Changing the subject when asking a question in reply is not essential. Not all forums even allow separate subject lines on replies, and nearly nobody reads them when they do. However, asking a question in a reply is a dubious practice in itself, because it will only be seen by those who are watching this thread. So, unless you are sure you want to ask only the people currently active in the thread, start a new one. Make it easy to reply Finishing your query with “Please send your reply to… ” makes it quite unlikely you will get an answer. If you can’t be bothered to take even the few seconds required to set up a correct Reply-To header in your mail agent, we can’t be bothered to take even a few seconds to think about your problem. If your mail program doesn’t permit this, get a better mail program. If your operating system doesn’t support any e-mail programs that permit this, get a better operating system. In Web forums, asking for a reply by e-mail is outright rude, unless you believe the information may be sensitive (and somebody will, for some unknown reason, let you but not the whole forum know it). If you want an e-mail copy when somebody replies in the thread, request that the Web forum send it; this feature is supported almost everywhere under options like “watch this thread”, “send e-mail on answers”, etc. Write in clear, grammatical, correctly-spelled language We’ve found by experience that people who are careless and sloppy writers are usually also careless and sloppy at thinking and coding (often enough to bet on, anyway). Answering questions for careless and sloppy thinkers is not rewarding; we’d rather spend our time elsewhere. So expressing your question clearly and well is important. If you can’t be bothered to do that, we can’t be bothered to pay attention. Spend the extra effort to polish your language. It doesn’t have to be stiff or formal — in fact, hacker culture values informal, slangy and humorous language used with precision. But it has to be precise; there has to be some indication that you’re thinking and paying attention. Spell, punctuate, and capitalize correctly. Don’t confuse “its” with “it’s”, “loose” with “lose”, or “discrete” with “discreet”. Don’t TYPE IN ALL CAPS; this is read as shouting and considered rude. (All-smalls is only slightly less annoying, as it’s difficult to read. Alan Cox can get away with it, but you can’t.) More generally, if you write like a semi-literate boob you will very likely be ignored. So don’t use instant-messaging shortcuts. Spelling “you” as “u” makes you look like a semi-literate boob to save two entire keystrokes. Worse: writing like a l33t script kiddie hax0r is the absolute kiss of death and guarantees you will receive nothing but stony silence (or, at best, a heaping helping of scorn and sarcasm) in return. If you are asking questions in a forum that does not use your native language, you will get a limited amount of slack for spelling and grammar errors — but no extra slack at all for laziness (and yes, we can usually spot that difference). Also, unless you know what your respondent’s languages are, write in English. Busy hackers tend to simply flush questions in languages they don’t understand, and English is the working language of the Internet. By writing in English you minimize your chances that your question will be discarded unread. If you are writing in English but it is a second language for you, it is good form to alert potential respondents to potential language difficulties and options for getting around them. Examples: English is not my native language; please excuse typing errors. If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question. I am familiar with the technical terms, but some slang expressions and idioms are difficult for me. I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other. Send questions in accessible, standard formats If you make your question artificially hard to read, it is more likely to be passed over in favor of one that isn’t. So: Send plain text mail, not HTML. (It’s not hard to turn off HTML.) MIME attachments are usually OK, but only if they are real content (such as an attached source file or patch), and not merely boilerplate generated by your mail client (such as another copy of your message). Don’t send e-mail in which entire paragraphs are single multiply-wrapped lines. (This makes it too difficult to reply to just part of the message.) Assume that your respondents will be reading mail on 80-character-wide text displays and set your line wrap accordingly, to something less than 80. However, do not wrap data (such as log file dumps or session transcripts) at any fixed column width. Data should be included as-is, so respondents can have confidence that they are seeing what you saw. Don’t send MIME Quoted-Printable encoding to an English-language forum. This encoding can be necessary when you’re posting in a language ASCII doesn’t cover, but many e-mail agents don’t support it. When they break, all those =20 glyphs scattered through the text are ugly and distracting — or may actively sabotage the semantics of your text. Never, ever expect hackers to be able to read closed proprietary document formats like Microsoft Word or Excel. Most hackers react to these about as well as you would to having a pile of steaming pig manure dumped on your doorstep. Even when they can cope, they resent having to do so. If you’re sending e-mail from a Windows machine, turn off Microsoft’s problematic “Smart Quotes” feature (From Tools &gt; AutoCorrect Options, clear the smart quotes checkbox under AutoFormat As You Type.). This is so you’ll avoid sprinkling garbage characters through your mail. In Web forums, do not abuse “smiley” and “HTML” features (when they are present). A smiley or two is usually OK, but colored fancy text tends to make people think you are lame. Seriously overusing smileys and color and fonts will make you come off like a giggly teenage girl, which is not generally a good idea unless you are more interested in sex than answers. If you’re using a graphical-user-interface mail client such as Netscape Messenger, MS Outlook, or their ilk, beware that it may violate these rules when used with its default settings. Most such clients have a menu-based “View Source” command. Use this on something in your sent-mail folder, verifying sending of plain text without unnecessary attached crud. Be precise and informative about your problem Describe the symptoms of your problem or bug carefully and clearly. Describe the environment in which it occurs (machine, OS, application, whatever). Provide your vendor’s distribution and release level (e.g.: “Fedora Core 7”, “Slackware 9.1”, etc.). Describe the research you did to try and understand the problem before you asked the question. Describe the diagnostic steps you took to try and pin down the problem yourself before you asked the question. Describe any possibly relevant recent changes in your computer or software configuration. If at all possible, provide a way to reproduce the problem in a controlled environment. Do the best you can to anticipate the questions a hacker will ask, and answer them in advance in your request for help. Giving hackers the ability to reproduce the problem in a controlled environment is especially important if you are reporting something you think is a bug in code. When you do this, your odds of getting a useful answer and the speed with which you are likely to get that answer both improve tremendously. Simon Tatham has written an excellent essay entitled How to Report Bugs Effectively. I strongly recommend that you read it. Volume is not precision You need to be precise and informative. This end is not served by simply dumping huge volumes of code or data into a help request. If you have a large, complicated test case that is breaking a program, try to trim it and make it as small as possible. This is useful for at least three reasons. One: being seen to invest effort in simplifying the question makes it more likely you’ll get an answer, Two: simplifying the question makes it more likely you’ll get a useful answer. Three: In the process of refining your bug report, you may develop a fix or workaround yourself. Don’t rush to claim that you have found a bug When you are having problems with a piece of software, don’t claim you have found a bug unless you are very, very sure of your ground. Hint: unless you can provide a source-code patch that fixes the problem, or a regression test against a previous version that demonstrates incorrect behavior, you are probably not sure enough. This applies to webpages and documentation, too; if you have found a documentation “bug”, you should supply replacement text and which pages it should go on. Remember, there are many other users that are not experiencing your problem. Otherwise you would have learned about it while reading the documentation and searching the Web (you did do that before complaining, didn’t you?). This means that very probably it is you who are doing something wrong, not the software. The people who wrote the software work very hard to make it work as well as possible. If you claim you have found a bug, you’ll be impugning their competence, which may offend some of them even if you are correct. It’s especially undiplomatic to yell “bug” in the Subject line. When asking your question, it is best to write as though you assume you are doing something wrong, even if you are privately pretty sure you have found an actual bug. If there really is a bug, you will hear about it in the answer. Play it so the maintainers will want to apologize to you if the bug is real, rather than so that you will owe them an apology if you have messed up. Grovelling is not a substitute for doing your homework Some people who get that they shouldn’t behave rudely or arrogantly, demanding an answer, retreat to the opposite extreme of grovelling. “I know I’m just a pathetic newbie loser, but…”. This is distracting and unhelpful. It’s especially annoying when it’s coupled with vagueness about the actual problem. Don’t waste your time, or ours, on crude primate politics. Instead, present the background facts and your question as clearly as you can. That is a better way to position yourself than by grovelling. Sometimes Web forums have separate places for newbie questions. If you feel you do have a newbie question, just go there. But don’t grovel there either. Describe the problem’s symptoms, not your guesses It’s not useful to tell hackers what you think is causing your problem. (If your diagnostic theories were such hot stuff, would you be consulting others for help?) So, make sure you’re telling them the raw symptoms of what goes wrong, rather than your interpretations and theories. Let them do the interpretation and diagnosis. If you feel it’s important to state your guess, clearly label it as such and describe why that answer isn’t working for you. Stupid:I’m getting back-to-back SIG11 errors on kernel compiles, and suspect a hairline crack on one of the motherboard traces. What’s the best way to check for those? Smart:My home-built K6/233 on an FIC-PA2007 motherboard (VIA Apollo VP2 chipset) with 256MB Corsair PC133 SDRAM starts getting frequent SIG11 errors about 20 minutes after power-on during the course of kernel compiles, but never in the first 20 minutes. Rebooting doesn’t restart the clock, but powering down overnight does. Swapping out all RAM didn’t help. The relevant part of a typical compile session log follows. Since the preceding point seems to be a tough one for many people to grasp, here’s a phrase to remind you: “All diagnosticians are from Missouri.” That US state’s official motto is “Show me” (earned in 1899, when Congressman Willard D. Vandiver said “I come from a country that raises corn and cotton and cockleburs and Democrats, and frothy eloquence neither convinces nor satisfies me. I’m from Missouri. You’ve got to show me.”) In diagnosticians’ case, it’s not a matter of skepticism, but rather a literal, functional need to see whatever is as close as possible to the same raw evidence that you see, rather than your surmises and summaries. Show us. Describe your problem’s symptoms in chronological order The clues most useful in figuring out something that went wrong often lie in the events immediately prior. So, your account should describe precisely what you did, and what the machine and software did, leading up to the blowup. In the case of command-line processes, having a session log (e.g., using the script utility) and quoting the relevant twenty or so lines is very useful. If the program that blew up on you has diagnostic options (such as -v for verbose), try to select options that will add useful debugging information to the transcript. Remember that more is not necessarily better; try to choose a debug level that will inform rather than drowning the reader in junk. If your account ends up being long (more than about four paragraphs), it might be useful to succinctly state the problem up top, then follow with the chronological tale. That way, hackers will know what to watch for in reading your account. Describe the goal, not the step If you are trying to find out how to do something (as opposed to reporting a bug), begin by describing the goal. Only then describe the particular step towards it that you are blocked on. Often, people who need technical help have a high-level goal in mind and get stuck on what they think is one particular path towards the goal. They come for help with the step, but don’t realize that the path is wrong. It can take substantial effort to get past this. Stupid:How do I get the color-picker on the FooDraw program to take a hexadecimal RGB value? Smart:I’m trying to replace the color table on an image with values of my choosing. Right now the only way I can see to do this is by editing each table slot, but I can’t get FooDraw’s color picker to take a hexadecimal RGB value. The second version of the question is smart. It allows an answer that suggests a tool better suited to the task. Don’t ask people to reply by private e-mail Hackers believe solving problems should be a public, transparent process during which a first try at an answer can and should be corrected if someone more knowledgeable notices that it is incomplete or incorrect. Also, helpers get some of their reward for being respondents from being seen to be competent and knowledgeable by their peers. When you ask for a private reply, you are disrupting both the process and the reward. Don’t do this. It’s the respondent’s choice whether to reply privately — and if he or she does, it’s usually because he or she thinks the question is too ill-formed or obvious to be interesting to others. There is one limited exception to this rule. If you think the question is such that you are likely to get many answers that are all closely similar, then the magic words are “e-mail me and I’ll summarize the answers for the group”. It is courteous to try and save the mailing list or newsgroup a flood of substantially identical postings — but you have to keep the promise to summarize. Be explicit about your question Open-ended questions tend to be perceived as open-ended time sinks. Those people most likely to be able to give you a useful answer are also the busiest people (if only because they take on the most work themselves). People like that are allergic to open-ended time sinks, thus they tend to be allergic to open-ended questions. You are more likely to get a useful response if you are explicit about what you want respondents to do (provide pointers, send code, check your patch, whatever). This will focus their effort and implicitly put an upper bound on the time and energy a respondent must allocate to helping you. This is good. To understand the world the experts live in, think of expertise as an abundant resource and time to respond as a scarce one. The less of a time commitment you implicitly ask for, the more likely you are to get an answer from someone really good and really busy. So it is useful to frame your question to minimize the time commitment required for an expert to field it — but this is often not the same thing as simplifying the question. Thus, for example, “Would you give me a pointer to a good explanation of X?” is usually a smarter question than “Would you explain X, please?”. If you have some malfunctioning code, it is usually smarter to ask for someone to explain what’s wrong with it than it is to ask someone to fix it. When asking about code Don’t ask others to debug your broken code without giving a hint what sort of problem they should be searching for. Posting a few hundred lines of code, saying “it doesn’t work”, will get you ignored. Posting a dozen lines of code, saying “after line 7 I was expecting to see , but occurred instead” is much more likely to get you a response. The most effective way to be precise about a code problem is to provide a minimal bug-demonstrating test case. What’s a minimal test case? It’s an illustration of the problem; just enough code to exhibit the undesirable behavior and no more. How do you make a minimal test case? If you know what line or section of code is producing the problematic behavior, make a copy of it and add just enough supporting code to produce a complete example (i.e. enough that the source is acceptable to the compiler/interpreter/whatever application processes it). If you can’t narrow it down to a particular section, make a copy of the source and start removing chunks that don’t affect the problematic behavior. The smaller your minimal test case is, the better (see the section called “Volume is not precision”). Generating a really small minimal test case will not always be possible, but trying to is good discipline. It may help you learn what you need to solve the problem on your own — and even when it doesn’t, hackers like to see that you have tried. It will make them more cooperative. If you simply want a code review, say as much up front, and be sure to mention what areas you think might particularly need review and why. Don’t post homework questions Hackers are good at spotting homework questions; most of us have done them ourselves. Those questions are for you to work out, so that you will learn from the experience. It is OK to ask for hints, but not for entire solutions. If you suspect you have been passed a homework question, but can’t solve it anyway, try asking in a user group forum or (as a last resort) in a “user” list/forum of a project. While the hackers will spot it, some of the advanced users may at least give you a hint. Prune pointless queries Resist the temptation to close your request for help with semantically-null questions like “Can anyone help me?” or “Is there an answer?” First: if you’ve written your problem description halfway competently, such tacked-on questions are at best superfluous. Second: because they are superfluous, hackers find them annoying — and are likely to return logically impeccable but dismissive answers like “Yes, you can be helped” and “No, there is no help for you.” In general, asking yes-or-no questions is a good thing to avoid unless you want a yes-or-no answer. Don’t flag your question as “Urgent”, even if it is for you That’s your problem, not ours. Claiming urgency is very likely to be counter-productive: most hackers will simply delete such messages as rude and selfish attempts to elicit immediate and special attention. Furthermore, the word ‘Urgent’ (and other similar attempts to grab attention in the subject line) often triggers spam filters - your intended recipients might never see it at all! There is one semi-exception. It can be worth mentioning if you’re using the program in some high-profile place, one that the hackers will get excited about; in such a case, if you’re under time pressure, and you say so politely, people may get interested enough to answer faster. This is a very risky thing to do, however, because the hackers’ metric for what is exciting probably differs from yours. Posting from the International Space Station would qualify, for example, but posting on behalf of a feel-good charitable or political cause would almost certainly not. In fact, posting “Urgent: Help me save the fuzzy baby seals!” will reliably get you shunned or flamed even by hackers who think fuzzy baby seals are important. If you find this mysterious, re-read the rest of this how-to repeatedly until you understand it before posting anything at all. Courtesy never hurts, and sometimes helps Be courteous. Use “Please” and “Thanks for your attention” or “Thanks for your consideration”. Make it clear you appreciate the time people spend helping you for free. To be honest, this isn’t as important as (and cannot substitute for) being grammatical, clear, precise and descriptive, avoiding proprietary formats etc.; hackers in general would rather get somewhat brusque but technically sharp bug reports than polite vagueness. (If this puzzles you, remember that we value a question by what it teaches us.) However, if you’ve got your technical ducks in a row, politeness does increase your chances of getting a useful answer. (We must note that the only serious objection we’ve received from veteran hackers to this HOWTO is with respect to our previous recommendation to use “Thanks in advance”. Some hackers feel this connotes an intention not to thank anybody afterwards. Our recommendation is to either say “Thanks in advance” first and thank respondents afterwards, or express courtesy in a different way, such as by saying “Thanks for your attention” or “Thanks for your consideration”.) Follow up with a brief note on the solution Send a note after the problem has been solved to all who helped you; let them know how it came out and thank them again for their help. If the problem attracted general interest in a mailing list or newsgroup, it’s appropriate to post the followup there. Optimally, the reply should be to the thread started by the original question posting, and should have ‘FIXED’, ‘RESOLVED’ or an equally obvious tag in the subject line. On mailing lists with fast turnaround, a potential respondent who sees a thread about “Problem X” ending with “Problem X - FIXED” knows not to waste his/her time even reading the thread (unless (s)he personally finds Problem X interesting) and can therefore use that time solving a different problem. Your followup doesn’t have to be long and involved; a simple “Howdy — it was a failed network cable! Thanks, everyone. - Bill” would be better than nothing. In fact, a short and sweet summary is better than a long dissertation unless the solution has real technical depth. Say what action solved the problem, but you need not replay the whole troubleshooting sequence. For problems with some depth, it is appropriate to post a summary of the troubleshooting history. Describe your final problem statement. Describe what worked as a solution, and indicate avoidable blind alleys after that. The blind alleys should come after the correct solution and other summary material, rather than turning the follow-up into a detective story. Name the names of people who helped you; you’ll make friends that way. Besides being courteous and informative, this sort of followup will help others searching the archive of the mailing-list/newsgroup/forum to know exactly which solution helped you and thus may also help them. Last, and not least, this sort of followup helps everybody who assisted feel a satisfying sense of closure about the problem. If you are not a techie or hacker yourself, trust us that this feeling is very important to the gurus and experts you tapped for help. Problem narratives that trail off into unresolved nothingness are frustrating things; hackers itch to see them resolved. The goodwill that scratching that itch earns you will be very, very helpful to you next time you need to pose a question. Consider how you might be able to prevent others from having the same problem in the future. Ask yourself if a documentation or FAQ patch would help, and if the answer is yes send that patch to the maintainer. Among hackers, this sort of good followup behavior is actually more important than conventional politeness. It’s how you get a reputation for playing well with others, which can be a very valuable asset. How To Interpret Answers RTFM and STFW: How To Tell You’ve Seriously Screwed Up There is an ancient and hallowed tradition: if you get a reply that reads “RTFM”, the person who sent it thinks you should have Read The Fucking Manual. He or she is almost certainly right. Go read it. RTFM has a younger relative. If you get a reply that reads “STFW”, the person who sent it thinks you should have Searched The Fucking Web. He or she is almost certainly right. Go search it. (The milder version of this is when you are told “Google is your friend!”) In Web forums, you may also be told to search the forum archives. In fact, someone may even be so kind as to provide a pointer to the previous thread where this problem was solved. But do not rely on this consideration; do your archive-searching before asking. Often, the person telling you to do a search has the manual or the web page with the information you need open, and is looking at it as he or she types. These replies mean that the responder thinks (a) the information you need is easy to find, and (b) you will learn more if you seek out the information than if you have it spoon-fed to you. You shouldn’t be offended by this; by hacker standards, your respondent is showing you a rough kind of respect simply by not ignoring you. You should instead be thankful for this grandmotherly kindness. If you don’t understand… If you don’t understand the answer, do not immediately bounce back a demand for clarification. Use the same tools that you used to try and answer your original question (manuals, FAQs, the Web, skilled friends) to understand the answer. Then, if you still need to ask for clarification, exhibit what you have learned. For example, suppose I tell you: “It sounds like you’ve got a stuck zentry; you’ll need to clear it.” Then: here’s a bad followup question: “What’s a zentry?” Here’s a good followup question: “OK, I read the man page and zentries are only mentioned under the -z and -p switches. Neither of them says anything about clearing zentries. Is it one of these or am I missing something here?” Dealing with rudeness Much of what looks like rudeness in hacker circles is not intended to give offense. Rather, it’s the product of the direct, cut-through-the-bullshit communications style that is natural to people who are more concerned about solving problems than making others feel warm and fuzzy. When you perceive rudeness, try to react calmly. If someone is really acting out, it is very likely a senior person on the list or newsgroup or forum will call him or her on it. If that doesn’t happen and you lose your temper, it is likely that the person you lose it at was behaving within the hacker community’s norms and you will be considered at fault. This will hurt your chances of getting the information or help you want. On the other hand, you will occasionally run across rudeness and posturing that is quite gratuitous. The flip-side of the above is that it is acceptable form to slam real offenders quite hard, dissecting their misbehavior with a sharp verbal scalpel. Be very, very sure of your ground before you try this, however. The line between correcting an incivility and starting a pointless flamewar is thin enough that hackers themselves not infrequently blunder across it; if you are a newbie or an outsider, your chances of avoiding such a blunder are low. If you’re after information rather than entertainment, it’s better to keep your fingers off the keyboard than to risk this. (Some people assert that many hackers have a mild form of autism or Asperger’s Syndrome, and are actually missing some of the brain circuitry that lubricates “normal” human social interaction. This may or may not be true. If you are not a hacker yourself, it may help you cope with our eccentricities if you think of us as being brain-damaged. Go right ahead. We won’t care; we like being whatever it is we are, and generally have a healthy skepticism about clinical labels.) Jeff Bigler’s observations about tact filters are also relevant and worth reading. In the next section, we’ll talk about a different issue; the kind of “rudeness” you’ll see when you misbehave. On Not Reacting Like A Loser Odds are you’ll screw up a few times on hacker community forums — in ways detailed in this article, or similar. And you’ll be told exactly how you screwed up, possibly with colourful asides. In public. When this happens, the worst thing you can do is whine about the experience, claim to have been verbally assaulted, demand apologies, scream, hold your breath, threaten lawsuits, complain to people’s employers, leave the toilet seat up, etc. Instead, here’s what you do: Get over it. It’s normal. In fact, it’s healthy and appropriate. Community standards do not maintain themselves: They’re maintained by people actively applying them, visibly, in public. Don’t whine that all criticism should have been conveyed via private e-mail: That’s not how it works. Nor is it useful to insist you’ve been personally insulted when someone comments that one of your claims was wrong, or that his views differ. Those are loser attitudes. There have been hacker forums where, out of some misguided sense of hyper-courtesy, participants are banned from posting any fault-finding with another’s posts, and told “Don’t say anything if you’re unwilling to help the user.” The resulting departure of clueful participants to elsewhere causes them to descend into meaningless babble and become useless as technical forums. Exaggeratedly “friendly” (in that fashion) or useful: Pick one. Remember: When that hacker tells you that you’ve screwed up, and (no matter how gruffly) tells you not to do it again, he’s acting out of concern for (1) you and (2) his community. It would be much easier for him to ignore you and filter you out of his life. If you can’t manage to be grateful, at least have a little dignity, don’t whine, and don’t expect to be treated like a fragile doll just because you’re a newcomer with a theatrically hypersensitive soul and delusions of entitlement. Sometimes people will attack you personally, flame without an apparent reason, etc., even if you don’t screw up (or have only screwed up in their imagination). In this case, complaining is the way to really screw up. These flamers are either lamers who don’t have a clue but believe themselves to be experts, or would-be psychologists testing whether you’ll screw up. The other readers either ignore them, or find ways to deal with them on their own. The flamers’ behavior creates problems for themselves, which don’t have to concern you. Don’t let yourself be drawn into a flamewar, either. Most flames are best ignored — after you’ve checked whether they are really flames, not pointers to the ways in which you have screwed up, and not cleverly ciphered answers to your real question (this happens as well). Questions Not To Ask Here are some classic stupid questions, and what hackers are thinking when they don’t answer them. Q: Where can I find program or resource X?Q: How can I use X to do Y?Q: How can I configure my shell prompt?Q: Can I convert an AcmeCorp document into a TeX file using the Bass-o-matic file converter?Q: My {program, configuration, SQL statement} doesn’t workQ: I’m having problems with my Windows machine. Can you help?Q: My program doesn’t work. I think system facility X is broken.Q: I’m having problems installing Linux or X. Can you help?Q: How can I crack root/steal channel-ops privileges/read someone’s e-mail?Q: Where can I find program or resource X? A: The same place I’d find it, fool — at the other end of a web search. Ghod, doesn’t everybody know how to use Google yet? Q: How can I use X to do Y? A: If what you want is to do Y, you should ask that question without pre-supposing the use of a method that may not be appropriate. Questions of this form often indicate a person who is not merely ignorant about X, but confused about what problem Y they are solving and too fixated on the details of their particular situation. It is generally best to ignore such people until they define their problem better. Q: How can I configure my shell prompt? A: If you’re smart enough to ask this question, you’re smart enough to RTFM and find out yourself. Q: Can I convert an AcmeCorp document into a TeX file using the Bass-o-matic file converter? A: Try it and see. If you did that, you’d (a) learn the answer, and (b) stop wasting my time. Q: My {program, configuration, SQL statement} doesn’t work A: This is not a question, and I’m not interested in playing Twenty Questions to pry your actual question out of you — I have better things to do. On seeing something like this, my reaction is normally of one of the following: do you have anything else to add to that? oh, that’s too bad, I hope you get it fixed. and this has exactly what to do with me? Q: I’m having problems with my Windows machine. Can you help? A: Yes. Throw out that Microsoft trash and install an open-source operating system like Linux or BSD. Note: you can ask questions related to Windows machines if they are about a program that does have an official Windows build, or interacts with Windows machines (i.e., Samba). Just don’t be surprised by the reply that the problem is with Windows and not the program, because Windows is so broken in general that this is very often the case. Q: My program doesn’t work. I think system facility X is broken. A: While it is possible that you are the first person to notice an obvious deficiency in system calls and libraries heavily used by hundreds or thousands of people, it is rather more likely that you are utterly clueless. Extraordinary claims require extraordinary evidence; when you make a claim like this one, you must back it up with clear and exhaustive documentation of the failure case. Q: I’m having problems installing Linux or X. Can you help? A: No. I’d need hands-on access to your machine to troubleshoot this. Go ask your local Linux user group for hands-on help. (You can find a list of user groups here.) Note: questions about installing Linux may be appropriate if you’re on a forum or mailing list about a particular distribution, and the problem is with that distro; or on local user groups forums. In this case, be sure to describe the exact details of the failure. But do careful searching first, with “linux” and all suspicious pieces of hardware. Q: How can I crack root/steal channel-ops privileges/read someone’s e-mail? A: You’re a lowlife for wanting to do such things and a moron for asking a hacker to help you. Good and Bad Questions Finally, I’m going to illustrate how to ask questions in a smart way by example; pairs of questions about the same problem, one asked in a stupid way and one in a smart way. Stupid: Where can I find out stuff about the Foonly Flurbamatic?This question just begs for “STFW” as a reply. Smart: I used Google to try to find “Foonly Flurbamatic 2600” on the Web, but I got no useful hits. Can I get a pointer to programming information on this device?This one has already STFWed, and sounds like there might be a real problem. Stupid: I can’t get the code from project foo to compile. Why is it broken?The querent assumes that somebody else screwed up. Arrogant git… Smart: The code from project foo doesn’t compile under Nulix version 6.2. I’ve read the FAQ, but it doesn’t have anything in it about Nulix-related problems. Here’s a transcript of my compilation attempt; is it something I did?The querent has specified the environment, read the FAQ, is showing the error, and is not assuming his problems are someone else’s fault. This one might be worth some attention. Stupid: I’m having problems with my motherboard. Can anybody help?J. Random Hacker’s response to this is likely to be “Right. Do you need burping and diapering, too?” followed by a punch of the delete key. Smart: I tried X, Y, and Z on the S2464 motherboard. When that didn’t work, I tried A, B, and C. Note the curious symptom when I tried C. Obviously the florbish is grommicking, but the results aren’t what one might expect. What are the usual causes of grommicking on Athlon MP motherboards? Anybody got ideas for more tests I can run to pin down the problem?This person, on the other hand, seems worthy of an answer. He/she has exhibited problem-solving intelligence rather than passively waiting for an answer to drop from on high. In the last question, notice the subtle but important difference between demanding “Give me an answer” and “Please help me figure out what additional diagnostics I can run to achieve enlightenment.” In fact, the form of that last question is closely based on a real incident that happened in August 2001 on the linux-kernel mailing list (lkml). I (Eric) was the one asking the question that time. I was seeing mysterious lockups on a Tyan S2462 motherboard. The list members supplied the critical information I needed to solve them. By asking the question in the way I did, I gave people something to chew on; I made it easy and attractive for them to get involved. I demonstrated respect for my peers’ ability and invited them to consult with me as a peer. I also demonstrated respect for the value of their time by telling them the blind alleys I had already run down. Afterwards, when I thanked everyone and remarked how well the process had worked, an lkml member observed that he thought it had worked not because I’m a “name” on that list, but because I asked the question in the proper form. Hackers are in some ways a very ruthless meritocracy; I’m certain he was right, and that if I had behaved like a sponge I would have been flamed or ignored no matter who I was. His suggestion that I write up the whole incident as instruction to others led directly to the composition of this guide. If You Can’t Get An Answer If you can’t get an answer, please don’t take it personally that we don’t feel we can help you. Sometimes the members of the asked group may simply not know the answer. No response is not the same as being ignored, though admittedly it’s hard to spot the difference from outside. In general, simply re-posting your question is a bad idea. This will be seen as pointlessly annoying. Have patience: the person with your answer may be in a different time-zone and asleep. Or it may be that your question wasn’t well-formed to begin with. There are other sources of help you can go to, often sources better adapted to a novice’s needs. There are many online and local user groups who are enthusiasts about the software, even though they may never have written any software themselves. These groups often form so that people can help each other and help new users. There are also plenty of commercial companies you can contract with for help, both large and small. Don’t be dismayed at the idea of having to pay for a bit of help! After all, if your car engine blows a head gasket, chances are you would take it to a repair shop and pay to get it fixed. Even if the software didn’t cost you anything, you can’t expect that support to always come for free. For popular software like Linux, there are at least 10,000 users per developer. It’s just not possible for one person to handle the support calls from over 10,000 users. Remember that even if you have to pay for support, you are still paying much less than if you had to buy the software as well (and support for closed-source software is usually more expensive and less competent than support for open-source software). How To Answer Questions in a Helpful Way Be gentle. Problem-related stress can make people seem rude or stupid even when they’re not. Reply to a first offender off-line. There is no need of public humiliation for someone who may have made an honest mistake. A real newbie may not know how to search archives or where the FAQ is stored or posted. If you don’t know for sure, say so! A wrong but authoritative-sounding answer is worse than none at all. Don’t point anyone down a wrong path simply because it’s fun to sound like an expert. Be humble and honest; set a good example for both the querent and your peers. If you can’t help, don’t hinder. Don’t make jokes about procedures that could trash the user’s setup — the poor sap might interpret these as instructions. Ask probing questions to elicit more details. If you’re good at this, the querent will learn something — and so might you. Try to turn the bad question into a good one; remember we were all newbies once. While muttering RTFM is sometimes justified when replying to someone who is just a lazy slob, a pointer to documentation (even if it’s just a suggestion to google for a key phrase) is better. If you’re going to answer the question at all, give good value. Don’t suggest kludgy workarounds when somebody is using the wrong tool or approach. Suggest good tools. Reframe the question. Answer the actual question! If the querent has been so thorough as to do his or her research and has included in the query that X, Y, Z, A, B, and C have already been tried without good result, it is supremely unhelpful to respond with “Try A or B,” or with a link to something that only says, “Try X, Y, Z, A, B, or C.”. Help your community learn from the question. When you field a good question, ask yourself “How would the relevant documentation or FAQ have to change so that nobody has to answer this again?” Then send a patch to the document maintainer. If you did research to answer the question, demonstrate your skills rather than writing as though you pulled the answer out of your butt. Answering one good question is like feeding a hungry person one meal, but teaching them research skills by example is showing them how to grow food for a lifetime. Related Resources If you need instruction in the basics of how personal computers, Unix, and the Internet work, see The Unix and Internet Fundamentals HOWTO. When you release software or write patches for software, try to follow the guidelines in the Software Release Practice HOWTO. Acknowledgements Evelyn Mitchell contributed some example stupid questions and inspired the “How To Give A Good Answer” section. Mikhail Ramendik contributed some particularly valuable suggestions for improvements.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[]},{"title":"如何有效地报告 Bug","date":"2017-01-20T12:23:06.000Z","path":"2017/01/20/Program/Concepts/how-to-report-bugs-effectively/","text":"作者：Simon Tatham 专业的自由软件程序员翻译：Dasn 引言为公众写过软件的人，大概都收到过很拙劣的bug（计算机程序代码中的错误或程序运行时的瑕疵——译者注）报告，例如： 在报告中说“不好用”； 所报告内容毫无意义； 在报告中用户没有提供足够的信息； 在报告中提供了错误信息； 所报告的问题是由于用户的过失而产生的； 所报告的问题是由于其他程序的错误而产生的； 所报告的问题是由于网络错误而产生的； 这便是为什么“技术支持”被认为是一件可怕的工作，因为有拙劣的bug报告需要处理。然而并不是所有的bug报告都令人生厌：我在业余时间维护自由软件，有时我会收到非常清晰、有帮助并且“有内容”的bug报告。在这里我会尽力阐明如何写一个好的bug报告。我非常希望每一个人在报告bug之前都读一下这篇短文，当然我也希望用户在给我报告bug之前已经读过这篇文章。 简单地说，报告bug的目的是为了让程序员看到程序的错误。您可以亲自示范，也可以给出能导致程序出错的、详尽的操作步骤。如果程序出错了，程序员会收集额外的信息直到找到错误的原因；如果程序没有出错，那么他们会请您继续关注这个问题，收集相关的信息。 在bug报告里，要设法搞清什么是事实（例如：“我在电脑旁”和“XX出现了”）什么是推测（例如：“我想问题可能是出在……”）。如果愿意的话，您可以省去推测，但是千万别省略事实。 当您报告bug的时候（既然您已经这么做了），一定是希望bug得到及时修正。所以此时针对程序员的任何过激或亵渎的言语（甚至谩骂）都是与事无补的——因为这可能是程序员的错误，也有可能是您的错误，也许您有权对他们发火，但是如果您能多提供一些有用的信息（而不是激愤之词）或许bug会被更快的修正。除此以外，请记住：如果是免费软件，作者提供给我们已经是出于好心，所以要是太多的人对他们无礼，他们可能就要“收起”这份好心了。 ##“程序不好用” 程序员不是弱智：如果程序一点都不好用，他们不可能不知道。他们不知道一定是因为程序在他们看来工作得很正常。所以，或者是您作过一些与他们不同的操作，或者是您的环境与他们不同。他们需要信息，报告bug也是为了提供信息。信息总是越多越好。 许多程序，特别是自由软件，会公布一个“已知bug列表”。如果您找到的bug在列表里已经有了，那就不必再报告了，但是如果您认为自己掌握的信息比列表中的丰富，那无论如何也要与程序员联系。您提供的信息可能会使他们更简单地修复bug。 本文中提到的都是一些指导方针，没有哪一条是必须恪守的准则。不同的程序员会喜欢不同形式的bug报告。如果程序附带了一套报告bug的准则，一定要读。如果它与本文中提到的规则相抵触，那么请以它为准。 如果您不是报告bug，而是寻求帮助，您应该说明您曾经到哪里找过答案，（例如：我看了第四章和第五章的第二节，但我找不到解决的办法。）这会使程序员了解用户喜欢到哪里去找答案，从而使程序员把帮助文档做得更容易使用。 ##“演示给我看” 报告bug的最好的方法之一是“演示”给程序员看。让程序员站在电脑前，运行他们的程序，指出程序的错误。让他们看着您启动电脑、运行程序、如何进行操作以及程序对您的输入有何反应。 他们对自己写的软件了如指掌，他们知道哪些地方不会出问题，而哪些地方最可能出问题。他们本能地知道应该注意什么。在程序真的出错之前，他们可能已经注意到某些地方不对劲，这些都会给他们一些线索。他们会观察程序测试中的每一个细节，并且选出他们认为有用的信息。 这些可能还不够。也许他们觉得还需要更多的信息，会请您重复刚才的操作。他们可能在这期间需要与您交流一下，以便在他们需要的时候让bug重新出现。他们可能会改变一些操作，看看这个错误的产生是个别问题还是相关的一类问题。如果您不走运，他们可能需要坐下来，拿出一堆开发工具，花上几个小时来好好地研究一下。但是最重要的是在程序出错的时候让程序员在电脑旁。一旦他们看到了问题，他们通常会找到原因并开始试着修改。 ##“告诉我该怎么做” 如今是网络时代，是信息交流的时代。我可以点一下鼠标把自己的程序送到俄罗斯的某个朋友那里，当然他也可以用同样简单的方法给我一些建议。但是如果我的程序出了什么问题，我不可能在他旁边。“演示”是很好的办法，但是常常做不到。 如果您必须报告bug，而此时程序员又不在您身边，那么您就要想办法让bug重现在他们面前。当他们亲眼看到错误时，就能够进行处理了。 确切地告诉程序员您做了些什么。如果是一个图形界面程序，告诉他们您按了哪个按钮，依照什么顺序按的。如果是一个命令行程序，精确的告诉他们您键入了什么命令。您应该尽可能详细地提供您所键入的命令和程序的反应。 把您能想到的所有的输入方式都告诉程序员，如果程序要读取一个文件，您可能需要发一个文件的拷贝给他们。如果程序需要通过网络与另一台电脑通讯，您或许不能把那台电脑复制过去，但至少可以说一下电脑的类型和安装了哪些软件（如果可以的话）。 ##“哪儿出错了？在我看来一切正常哦！” 如果您给了程序员一长串输入和指令，他们执行以后没有出现错误，那是因为您没有给他们足够的信息，可能错误不是在每台计算机上都出现，您的系统可能和他们的在某些地方不一样。有时候程序的行为可能和您预想的不一样，这也许是误会，但是您会认为程序出错了，程序员却认为这是对的。 同样也要描述发生了什么。精确的描述您看到了什么。告诉他们为什么您觉得自己所看到的是错误的，最好再告诉他们，您认为自己应该看到什么。如果您只是说：“程序出错了”，那您很可能漏掉了非常重要的信息。 如果您看到了错误消息，一定要仔细、准确的告诉程序员，这确实很重要。在这种情况下，程序员只要修正错误，而不用去找错误。他们需要知道是什么出问题了，系统所报的错误消息正好帮助了他们。如果您没有更好的方法记住这些消息，就把它们写下来。只报告“程序出了一个错”是毫无意义的，除非您把错误消息一块报上来。 特殊情况下，如果有错误消息号，一定要把这些号码告诉程序员。不要以为您看不出任何意义，它就没有意义。错误消息号包含了能被程序员读懂的各种信息，并且很有可能包含重要的线索。给错误消息编号是因为用语言描述计算机错误常常令人费解。用这种方式告诉您错误的所在是一个最好的办法。 在这种情形下，程序员的排错工作会十分高效。他们不知道发生了什么，也不可能到现场去观察，所以他们一直在搜寻有价值的线索。错误消息、错误消息号以及一些莫名其妙的延迟，都是很重要的线索，就像办案时的指纹一样重要，保存好。 如果您使用UNIX系统，程序可能会产生一个内核输出（coredump）。内核输出是特别有用的线索来源，别扔了它们。另一方面，大多数程序员不喜欢收到含有大量内核输出文件的EMAIL，所以在发邮件之前最好先问一下。还有一点要注意：内核输出文件记录了完整的程序状态，也就是说任何秘密（可能当时程序正在处理一些私人信息或秘密数据）都可能包含在内核输出文件里。 ##“出了问题之后，我做了……” 当一个错误或bug发生的时候，您可能会做许多事情。但是大多数人会使事情变的更糟。我的一个朋友在学校里误删了她所有的Word文件，在找人帮忙之前她重装了Word，又运行了一遍碎片整理程序，这些操作对于恢复文件是毫无益处的，因为这些操作搞乱了磁盘的文件区块。恐怕在这个世界上没有一种反删除软件能恢复她的文件了。如果她不做任何操作，或许还有一线希望。 这种用户仿佛一只被逼到墙角的鼬（黄鼠狼、紫貂一类的动物——译者注）：背靠墙壁，面对死亡的降临奋起反扑，疯狂攻击。他们认为做点什么总比什么都不做强。然而这些在处理计算机软件问题时并不适用。 不要做鼬，做一只羚羊。当一只羚羊面对料想不到的情况或受到惊吓时，它会一动不动，是为了不吸引任何注意，与此同时也在思考解决问题的最好办法（如果羚羊有一条技术支持热线，此时占线。）。然后，一旦它找到了最安全的行动方案，它便去做。 当程序出毛病的时候，立刻停止正在做的任何操作。不要按任何健。仔细地看一下屏幕，注意那些不正常的地方，记住它或者写下来。然后慎重地点击“确定” 或“取消”，选择一个最安全的。学着养成一种条件反射——一旦电脑出了问题，先不要动。要想摆脱这个问题，关掉受影响的程序或者重新启动计算机都不好，一个解决问题的好办法是让问题再次产生。程序员们喜欢可以被重现的问题，快乐的程序员可以更快而且更有效率的修复bug。 ##“我想粒子的跃迁与错误的极化有关” 并不只是非专业的用户才会写出拙劣的bug报告，我见过一些非常差的bug报告出自程序员之手，有些还是非常优秀的程序员。 有一次我与另一个程序员一起工作，他一直在找代码中的bug，他常常遇到一个bug，但是不会解决，于是就叫我帮忙。“出什么毛病了？”我问。而他的回答却总是一些关于bug的意见。如果他的观点正确，那的确是一件好事。这意味着他已经完成了工作的一半，并且我们可以一起完成另一半工作。这是有效率并有用的。 但事实上他常常是错的。这就会使我们花上半个小时在原本正确的代码里来回寻找错误，而实际上问题出在别的地方。我敢肯定他不会对医生这么做。“大夫，我得了Hydroyoyodyne（真是怪病——译者），给我开个方子”，人们知道不该对一位医生说这些。您描述一下症状，哪个地方不舒服，哪里疼、起皮疹、发烧……让医生诊断您得了什么病，应该怎样治疗。否则医生会把您当做疑心病或精神病患者打发了，这似乎没什么不对。 做程序员也是一样。即便您自己的“诊断”有时真的有帮助，也要只说“症状”。“诊断”是可说可不说的，但是“症状”一定要说。同样，在bug报告里面附上一份针对bug而做出修改的源代码是有用处的，但它并不能替代bug报告本身。 如果程序员向您询问额外的信息，千万别应付。曾经有一个人向我报告bug，我让他试一个命令，我知道这个命令不好用，但我是要看看程序会返回一个什么错误（这是很重要的线索）。但是这位老兄根本就没试，他在回复中说“那肯定不好用”，于是我又花了好些时间才说服他试了一下那个命令。 用户多动动脑筋对程序员的工作是有帮助的。即使您的推断是错误的，程序员也应该感谢您，至少您想去帮助他们，使他们的工作变的更简单。不过千万别忘了报告“症状”，否则只会使事情变得更糟。 ##“真是奇怪，刚才还不好用，怎么现在又好了？” “间歇性错误”着实让程序员发愁。相比之下，进行一系列简单的操作便能导致错误发生的问题是简单的。程序员可以在一个便于观察的条件下重复那些操作，观察每一个细节。太多的问题在这种情况下不能解决，例如：程序每星期出一次错，或者偶然出一次错，或者在程序员面前从不出错（程序员一离开就出错。——译者）。当然还有就是程序的截止日期到了，那肯定要出错。 大多数“间歇性错误”并不是真正的“间歇”。其中的大多数错误与某些地方是有联系的。有一些错误可能是内存泄漏产生的，有一些可能是别的程序在不恰当的时候修改某个重要文件造成的，还有一些可能发生在每一个小时的前半个小时中（我确实遇到过这种事情）。 同样，如果您能使bug重现，而程序员不能，那很有可能是他们的计算机和您的计算机在某些地方是不同的，这种不同引起了问题。我曾写过一个程序，它的窗口可以蜷缩成一个小球呆在屏幕的左上角，它在别的计算机上只能在 800x600 的解析度工作，但是在我的机器上却可以在 1024x768 下工作。 程序员想要了解任何与您发现的问题相关的事情。有可能的话您到另一台机器上试试，多试几次，两次，三次，看看问题是不是经常发生。如果问题出现在您进行了一系列操作之后，不是您想让它出现它就会出现，这就有可能是长时间的运行或处理大文件所导致的错误。程序崩溃的时候，您要尽可能的记住您都做了些什么，并且如果您看到任何图形,也别忘了提一下。您提供的任何事情都是有帮助的。即使只是概括性的描述（例如：当后台有EMACS运行时，程序常常出错），这虽然不能提供导致问题的直接线索，但是可能帮助程序员重现问题。 最重要的是：程序员想要确定他们正在处理的是一个真正的“间歇性错误”呢，还是一个在另一类特定的计算机上才出现的错误。他们想知道有关您计算机的许多细节，以便了解您的机器与他们的有什么不同。有许多细节都依仗特定的程序，但是有一件东西您一定要提供——版本号。程序的版本、操作系统的版本以及与问题有关的程序的版本。 ##“我把磁盘装进了 Windows……” 表意清楚在一份bug报告里是最基本的要求。如果程序员不知道您说的是什么意思，那您就跟没说一样。我收到的bug报告来自世界各地，有许多是来自非英语国家，他们通常为自己的英文不好而表示歉意。总的来说，这些用户发来的bug报告通常是清晰而且有用的。几乎所有不清晰的bug报告都是来自母语是英语的人，他们总是以为只要自己随便说说，程序员就能明白。 精确。如果做相同的事情有两种方法，请说明您用的是哪一种。例如：“我选择了‘载入’”，可能意味着“我用鼠标点击‘载入’”或“我按下了‘ALT+L’”，说清楚您用了哪种方法，有时候这也有关系。详细。信息宁多毋少！如果您说了很多，程序员可以略去一部分，可是如果您说的太少，他们就不得不回过头再去问您一些问题。有一次我收到了一份bug报告只有一句话，每一次我问他更多事情时，他每次的回复都是一句话，于是我花了几个星期的时间才得到了有用的信息。慎用代词。诸如“它”，“窗体”这些词，当它们指代不清晰的时候不要用。来看看这句话：“我运行了FooApp，它弹出一个警告窗口，我试着关掉它，它就崩溃了。”这种表述并不清晰，用户究竟关掉了哪个窗口？是警告窗口还是整个FooApp程序？您可以这样说，“我运行FooApp程序时弹出一个警告窗口，我试着关闭警告窗口，FooApp崩溃了。”这样虽然罗嗦点，但是很清晰不容易产生误解。 检查。重新读一遍您写的bug报告，您觉得它是否清晰？如果您列出了一系列能导致程序出错的操作，那么照着做一遍，看看您是不是漏写了一步。 小结 bug报告的首要目的是让程序员亲眼看到错误。如果您不能亲自做给他们看，给他们能使程序出错的详细的操作步骤。 如果首要目的不能达成，程序员不能看到程序出错。这就需要bug报告的第二个目的来描述程序的什么地方出毛病了。详细的描述每一件事情：您看到了什么，您想看到什么，把错误消息记下来，尤其是“错误消息号”。 当您的计算机做了什么您料想不到的事，不要动！在您平静下来之前什么都别做。不要做您认为不安全的事。 尽量试着自己“诊断”程序出错的原因（如果您认为自己可以的话）。即使做出了“诊断”，您仍然应该报告“症状”。 如果程序员需要，请准备好额外的信息。如果他们不需要，就不会问您要。他们不会故意为难自己。您手头上一定要有程序的版本号，它很可能是必需品。 表述清楚，确保您的意思不能被曲解。 总的来说，最重要的是要做到精确。程序员喜欢精确。 声明：我从没有真的看见过鼬和羚羊，我的比喻可能不恰当。 版权所有 Simon Tatham 1999 本文属于OPL（OpenContent License），请在复制和使用本文时自觉遵守OPL。 对本文的任何意见和批评请发送至： 英文版：anakin@pobox.com 中文版：dasn@users.sf.net How to Report Bugs Effectivelyby Simon Tatham, professional and free-software programmer [ English | Português | 简体中文 | Česky | Dansk | Deutsch | Español | Français | Magyar | Italiano | 日本語 | Nederlands | Polski | Русский | 繁體中文 ] Introduction Anybody who has written software for public use will probably have received at least one bad bug report. Reports that say nothing (“It doesn’t work!”); reports that make no sense; reports that don’t give enough information; reports that give wrong information. Reports of problems that turn out to be user error; reports of problems that turn out to be the fault of somebody else’s program; reports of problems that turn out to be network failures. There’s a reason why technical support is seen as a horrible job to be in, and that reason is bad bug reports. However, not all bug reports are unpleasant: I maintain free software, when I’m not earning my living, and sometimes I receive wonderfully clear, helpful, informative bug reports. In this essay I’ll try to state clearly what makes a good bug report. Ideally I would like everybody in the world to read this essay before reporting any bugs to anybody. Certainly I would like everybody who reports bugs to me to have read it. In a nutshell, the aim of a bug report is to enable the programmer to see the program failing in front of them. You can either show them in person, or give them careful and detailed instructions on how to make it fail. If they can make it fail, they will try to gather extra information until they know the cause. If they can’t make it fail, they will have to ask you to gather that information for them. In bug reports, try to make very clear what are actual facts (“I was at the computer and this happened”) and what are speculations (“I think the problem might be this”). Leave out speculations if you want to, but don’t leave out facts. When you report a bug, you are doing so because you want the bug fixed. There is no point in swearing at the programmer or being deliberately unhelpful: it may be their fault and your problem, and you might be right to be angry with them, but the bug will get fixed faster if you help them by supplying all the information they need. Remember also that if the program is free, then the author is providing it out of kindness, so if too many people are rude to them then they may stop feeling kind. “It doesn’t work.” Give the programmer some credit for basic intelligence: if the program really didn’t work at all, they would probably have noticed. Since they haven’t noticed, it must be working for them. Therefore, either you are doing something differently from them, or your environment is different from theirs. They need information; providing this information is the purpose of a bug report. More information is almost always better than less. Many programs, particularly free ones, publish their list of known bugs. If you can find a list of known bugs, it’s worth reading it to see if the bug you’ve just found is already known or not. If it’s already known, it probably isn’t worth reporting again, but if you think you have more information than the report in the bug list, you might want to contact the programmer anyway. They might be able to fix the bug more easily if you can give them information they didn’t already have. This essay is full of guidelines. None of them is an absolute rule. Particular programmers have particular ways they like bugs to be reported. If the program comes with its own set of bug-reporting guidelines, read them. If the guidelines that come with the program contradict the guidelines in this essay, follow the ones that come with the program! If you are not reporting a bug but just asking for help using the program, you should state where you have already looked for the answer to your question. (“I looked in chapter 4 and section 5.2 but couldn’t find anything that told me if this is possible.”) This will let the programmer know where people will expect to find the answer, so they can make the documentation easier to use. “Show me.” One of the very best ways you can report a bug is by showing it to the programmer. Stand them in front of your computer, fire up their software, and demonstrate the thing that goes wrong. Let them watch you start the machine, watch you run the software, watch how you interact with the software, and watch what the software does in response to your inputs. They know that software like the back of their hand. They know which parts they trust, and they know which parts are likely to have faults. They know intuitively what to watch for. By the time the software does something obviously wrong, they may well have already noticed something subtly wrong earlier which might give them a clue. They can observe everything the computer does during the test run, and they can pick out the important bits for themselves. This may not be enough. They may decide they need more information, and ask you to show them the same thing again. They may ask you to talk them through the procedure, so that they can reproduce the bug for themselves as many times as they want. They might try varying the procedure a few times, to see whether the problem occurs in only one case or in a family of related cases. If you’re unlucky, they may need to sit down for a couple of hours with a set of development tools and really start investigating. But the most important thing is to have the programmer looking at the computer when it goes wrong. Once they can see the problem happening, they can usually take it from there and start trying to fix it. “Show me how to show myself.” This is the era of the Internet. This is the era of worldwide communication. This is the era in which I can send my software to somebody in Russia at the touch of a button, and he can send me comments about it just as easily. But if he has a problem with my program, he can’t have me standing in front of it while it fails. “Show me” is good when you can, but often you can’t. If you have to report a bug to a programmer who can’t be present in person, the aim of the exercise is to enable them to reproduce the problem. You want the programmer to run their own copy of the program, do the same things to it, and make it fail in the same way. When they can see the problem happening in front of their eyes, then they can deal with it. So tell them exactly what you did. If it’s a graphical program, tell them which buttons you pressed and what order you pressed them in. If it’s a program you run by typing a command, show them precisely what command you typed. Wherever possible, you should provide a verbatim transcript of the session, showing what commands you typed and what the computer output in response. Give the programmer all the input you can think of. If the program reads from a file, you will probably need to send a copy of the file. If the program talks to another computer over a network, you probably can’t send a copy of that computer, but you can at least say what kind of computer it is, and (if you can) what software is running on it. “Works for me. So what goes wrong?” If you give the programmer a long list of inputs and actions, and they fire up their own copy of the program and nothing goes wrong, then you haven’t given them enough information. Possibly the fault doesn’t show up on every computer; your system and theirs may differ in some way. Possibly you have misunderstood what the program is supposed to do, and you are both looking at exactly the same display but you think it’s wrong and they know it’s right. So also describe what happened. Tell them exactly what you saw. Tell them why you think what you saw is wrong; better still, tell them exactly what you expected to see. If you say “and then it went wrong”, you have left out some very important information. If you saw error messages then tell the programmer, carefully and precisely, what they were. They are important! At this stage, the programmer is not trying to fix the problem: they’re just trying to find it. They need to know what has gone wrong, and those error messages are the computer’s best effort to tell you that. Write the errors down if you have no other easy way to remember them, but it’s not worth reporting that the program generated an error unless you can also report what the error message was. In particular, if the error message has numbers in it, do let the programmer have those numbers. Just because you can’t see any meaning in them doesn’t mean there isn’t any. Numbers contain all kinds of information that can be read by programmers, and they are likely to contain vital clues. Numbers in error messages are there because the computer is too confused to report the error in words, but is doing the best it can to get the important information to you somehow. At this stage, the programmer is effectively doing detective work. They don’t know what’s happened, and they can’t get close enough to watch it happening for themselves, so they are searching for clues that might give it away. Error messages, incomprehensible strings of numbers, and even unexplained delays are all just as important as fingerprints at the scene of a crime. Keep them! If you are using Unix, the program may have produced a core dump. Core dumps are a particularly good source of clues, so don’t throw them away. On the other hand, most programmers don’t like to receive huge core files by e-mail without warning, so ask before mailing one to anybody. Also, be aware that the core file contains a record of the complete state of the program: any “secrets” involved (maybe the program was handling a personal message, or dealing with confidential data) may be contained in the core file. “So then I tried . . .” There are a lot of things you might do when an error or bug comes up. Many of them make the problem worse. A friend of mine at school deleted all her Word documents by mistake, and before calling in any expert help, she tried reinstalling Word, and then she tried running Defrag. Neither of these helped recover her files, and between them they scrambled her disk to the extent that no Undelete program in the world would have been able to recover anything. If she’d only left it alone, she might have had a chance. Users like this are like a mongoose backed into a corner: with its back to the wall and seeing certain death staring it in the face, it attacks frantically, because doing something has to be better than doing nothing. This is not well adapted to the type of problems computers produce. Instead of being a mongoose, be an antelope. When an antelope is confronted with something unexpected or frightening, it freezes. It stays absolutely still and tries not to attract any attention, while it stops and thinks and works out the best thing to do. (If antelopes had a technical support line, it would be telephoning it at this point.) Then, once it has decided what the safest thing to do is, it does it. When something goes wrong, immediately stop doing anything. Don’t touch any buttons at all. Look at the screen and notice everything out of the ordinary, and remember it or write it down. Then perhaps start cautiously pressing “OK” or “Cancel”, whichever seems safest. Try to develop a reflex reaction - if a computer does anything unexpected, freeze. If you manage to get out of the problem, whether by closing down the affected program or by rebooting the computer, a good thing to do is to try to make it happen again. Programmers like problems that they can reproduce more than once. Happy programmers fix bugs faster and more efficiently. “I think the tachyon modulation must be wrongly polarised.” It isn’t only non-programmers who produce bad bug reports. Some of the worst bug reports I’ve ever seen come from programmers, and even from good programmers. I worked with another programmer once, who kept finding bugs in his own code and trying to fix them. Every so often he’d hit a bug he couldn’t solve, and he’d call me over to help. “What’s gone wrong?” I’d ask. He would reply by telling me his current opinion of what needed to be fixed. This worked fine when his current opinion was right. It meant he’d already done half the work and we were able to finish the job together. It was efficient and useful. But quite often he was wrong. We would work for some time trying to figure out why some particular part of the program was producing incorrect data, and eventually we would discover that it wasn’t, that we’d been investigating a perfectly good piece of code for half an hour, and that the actual problem was somewhere else. I’m sure he wouldn’t do that to a doctor. “Doctor, I need a prescription for Hydroyoyodyne.” People know not to say that to a doctor: you describe the symptoms, the actual discomforts and aches and pains and rashes and fevers, and you let the doctor do the diagnosis of what the problem is and what to do about it. Otherwise the doctor dismisses you as a hypochondriac or crackpot, and quite rightly so. It’s the same with programmers. Providing your own diagnosis might be helpful sometimes, but always state the symptoms. The diagnosis is an optional extra, and not an alternative to giving the symptoms. Equally, sending a modification to the code to fix the problem is a useful addition to a bug report but not an adequate substitute for one. If a programmer asks you for extra information, don’t make it up! Somebody reported a bug to me once, and I asked him to try a command that I knew wouldn’t work. The reason I asked him to try it was that I wanted to know which of two different error messages it would give. Knowing which error message came back would give a vital clue. But he didn’t actually try it - he just mailed me back and said “No, that won’t work”. It took me some time to persuade him to try it for real. Using your intelligence to help the programmer is fine. Even if your deductions are wrong, the programmer should be grateful that you at least tried to make their life easier. But report the symptoms as well, or you may well make their life much more difficult instead. “That’s funny, it did it a moment ago.” Say “intermittent fault” to any programmer and watch their face fall. The easy problems are the ones where performing a simple sequence of actions will cause the failure to occur. The programmer can then repeat those actions under closely observed test conditions and watch what happens in great detail. Too many problems simply don’t work that way: there will be programs that fail once a week, or fail once in a blue moon, or never fail when you try them in front of the programmer but always fail when you have a deadline coming up. Most intermittent faults are not truly intermittent. Most of them have some logic somewhere. Some might occur when the machine is running out of memory, some might occur when another program tries to modify a critical file at the wrong moment, and some might occur only in the first half of every hour! (I’ve actually seen one of these.) Also, if you can reproduce the bug but the programmer can’t, it could very well be that their computer and your computer are different in some way and this difference is causing the problem. I had a program once whose window curled up into a little ball in the top left corner of the screen, and sat there and sulked. But it only did it on 800x600 screens; it was fine on my 1024x768 monitor. The programmer will want to know anything you can find out about the problem. Try it on another machine, perhaps. Try it twice or three times and see how often it fails. If it goes wrong when you’re doing serious work but not when you’re trying to demonstrate it, it might be long running times or large files that make it fall over. Try to remember as much detail as you can about what you were doing to it when it did fall over, and if you see any patterns, mention them. Anything you can provide has to be some help. Even if it’s only probabilistic (such as “it tends to crash more often when Emacs is running”), it might not provide direct clues to the cause of the problem, but it might help the programmer reproduce it. Most importantly, the programmer will want to be sure of whether they’re dealing with a true intermittent fault or a machine-specific fault. They will want to know lots of details about your computer, so they can work out how it differs from theirs. A lot of these details will depend on the particular program, but one thing you should definitely be ready to provide is version numbers. The version number of the program itself, and the version number of the operating system, and probably the version numbers of any other programs that are involved in the problem. “So I loaded the disk on to my Windows . . .” Writing clearly is essential in a bug report. If the programmer can’t tell what you meant, you might as well not have said anything. I get bug reports from all around the world. Many of them are from non-native English speakers, and a lot of those apologise for their poor English. In general, the bug reports with apologies for their poor English are actually very clear and useful. All the most unclear reports come from native English speakers who assume that I will understand them even if they don’t make any effort to be clear or precise. Be specific. If you can do the same thing two different ways, state which one you used. “I selected Load” might mean “I clicked on Load” or “I pressed Alt-L”. Say which you did. Sometimes it matters.Be verbose. Give more information rather than less. If you say too much, the programmer can ignore some of it. If you say too little, they have to come back and ask more questions. One bug report I received was a single sentence; every time I asked for more information, the reporter would reply with another single sentence. It took me several weeks to get a useful amount of information, because it turned up one short sentence at a time.Be careful of pronouns. Don’t use words like “it”, or references like “the window”, when it’s unclear what they mean. Consider this: “I started FooApp. It put up a warning window. I tried to close it and it crashed.” It isn’t clear what the user tried to close. Did they try to close the warning window, or the whole of FooApp? It makes a difference. Instead, you could say “I started FooApp, which put up a warning window. I tried to close the warning window, and FooApp crashed.” This is longer and more repetitive, but also clearer and less easy to misunderstand.Read what you wrote. Read the report back to yourself, and see if you think it’s clear. If you have listed a sequence of actions which should produce the failure, try following them yourself, to see if you missed a step.Summary The first aim of a bug report is to let the programmer see the failure with their own eyes. If you can’t be with them to make it fail in front of them, give them detailed instructions so that they can make it fail for themselves.In case the first aim doesn’t succeed, and the programmer can’t see it failing themselves, the second aim of a bug report is to describe what went wrong. Describe everything in detail. State what you saw, and also state what you expected to see. Write down the error messages, especially if they have numbers in.When your computer does something unexpected, freeze. Do nothing until you’re calm, and don’t do anything that you think might be dangerous.By all means try to diagnose the fault yourself if you think you can, but if you do, you should still report the symptoms as well.Be ready to provide extra information if the programmer needs it. If they didn’t need it, they wouldn’t be asking for it. They aren’t being deliberately awkward. Have version numbers at your fingertips, because they will probably be needed.Write clearly. Say what you mean, and make sure it can’t be misinterpreted.Above all, be precise. Programmers like precision.Disclaimer: I’ve never actually seen a mongoose or an antelope. My zoology may be inaccurate. $Id$ Copyright © 1999 Simon Tatham.This document is OpenContent.You may copy and use the text under the terms of the OpenContent Licence. This article is not specific to any particular program. If you have reached this page by following a link from the website for a particular program, DO NOT send bug reports for that program to me. Instead, return to the page you came from to find out where to report bugs in the program. If you have comments or criticism about this article itself, please send them to anakin@pobox.com.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[]},{"title":"Software Release Practice HOWTO","date":"2017-01-20T11:53:06.000Z","path":"2017/01/20/Program/Concepts/software-release-practice-howto/","text":"Software Release Practice HOWTO Eric Steven Raymond This HOWTO describes good release practices for Linux and other open-source projects. By following these practices, you will make it as easy as possible for users to build your code and use it, and for other developers to understand your code and cooperate with you to improve it. This document is a must-read for novice developers. Experienced developers should review it when they are about to release a new project. It will be revised periodically to reflect the evolution of good-practice standards. Table of Contents Introduction1.1. Why this document?1.2. New versions of this document Good patching practice2.1. Do send patches, don’t send whole archives or files2.2. Send patches against the current version of the code.2.3. Don’t include patches for generated files.2.4. Don’t send patch bands that just tweak version-control $-symbols.2.5. Do use -c or -u format, don’t use the default (-e) format2.6. Do include documentation with your patch2.7. Do include an explanation with your patch2.8. Do include useful comments in your code2.9. Just one bugfix or new feature per patch. Good project- and archive- naming practice3.1. Use GNU-style names with a stem and major.minor.patch numbering.3.2. But respect local conventions where appropriate3.3. Try hard to choose a name prefix that is unique and easy to type Good licensing and copyright practice: the theory4.1. Open source and copyrights4.2. What qualifies as open source Good licensing and copyright practice: the practice5.1. Make yourself or the FSF the copyright holder5.2. Use a license conformant to the Open Source Definition5.3. Don’t write your own license if you can possibly avoid it.5.4. Make your license visible in a standard place. Good development practice6.1. Choose the most portable language you can6.2. Don’t rely on proprietary code6.3. Build systems6.4. Test your code before release6.5. Sanity-check your code before release6.6. Sanity-check your documentation and READMEs before release6.7. Recommended C/C++ portability practices Good distribution-making practice7.1. Make sure tarballs always unpack into a single new directory7.2. Have a README7.3. Respect and follow standard file naming practices7.4. Design for Upgradability7.5. Provide checksums Good documentation practice8.1. Documentation formats8.2. Good practice recommendations Good communication practice9.1. Announce to Freecode9.2. Have a website9.3. Host project mailing lists9.4. Release to major archives Good project-management practice","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"Advice for Computer Science College Students","date":"2017-01-20T11:44:06.000Z","path":"2017/01/20/Program/Concepts/advice-for-computer-science-college-students/","text":"Joel Spolsky co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow. Despite the fact that it was only a year or two ago that I was blubbering about how rich Windows GUI clients were the wave of the future, college students nonetheless do occasionally email me asking for career advice, and since it’s recruiting season, I thought I’d write up my standard advice which they can read, laugh at, and ignore. Most college students, fortunately, are brash enough never to bother asking their elders for advice, which, in the field of computer science, is a good thing, because their elders are apt to say goofy, antediluvian things like “the demand for keypunch operators will exceed 100,000,000 by the year 2010” and “lisp careers are really very hot right now.” I, too, have no idea what I’m talking about when I give advice to college students. I’m so hopelessly out of date that I can’t really figure out AIM and still use (horrors!) this quaint old thing called “email” which was popular in the days when music came on flat round plates called “CDs.” So you’d be better off ignoring what I’m saying here and instead building some kind of online software thing that lets other students find people to go out on dates with. Nevertheless. If you enjoy programming computers, count your blessings: you are in a very fortunate minority of people who can make a great living doing work they enjoy. Most people aren’t so lucky. The very idea that you can “love your job” is a modern concept. Work is supposed to be something unpleasant you do to get money to do the things you actually like doing, when you’re 65 and can finally retire, if you can afford it, and if you’re not too old and infirm to do those things, and if those things don’t require reliable knees, good eyes, and the ability to walk twenty feet without being out of breath, etc. What was I talking about? Oh yeah. Advice. Without further ado, then, here are Joel’s Seven Pieces of Free Advice for Computer Science College Students (worth what you paid for them): Learn how to write before graduating. Learn C before graduating. Learn microeconomics before graduating. Don’t blow off non-CS classes just because they’re boring. Take programming-intensive courses. Stop worrying about all the jobs going to India. No matter what you do, get a good summer internship. Now for the explanations, unless you’re gullible enough to do all that stuff just because I tell you to, in which case add: 8. Seek professional help for that self-esteem thing. Learn how to write before graduating.Would Linux have succeeded if Linus Torvalds hadn’t evangelized it? As brilliant a hacker as he is, it was Linus’s ability to convey his ideas in written English via email and mailing lists that made Linux attract a worldwide brigade of volunteers. Have you heard of the latest fad, Extreme Programming? Well, without getting into what I think about XP, the reason you’ve heard of it is because it is being promoted by people who are very gifted writers and speakers. Even on the small scale, when you look at any programming organization, the programmers with the most power and influence are the ones who can write and speak in English clearly, convincingly, and comfortably. Also it helps to be tall, but you can’t do anything about that. The difference between a tolerable programmer and a great programmer is not how many programming languages they know, and it’s not whether they prefer Python or Java. It’s whether they can communicate their ideas. By persuading other people, they get leverage. By writing clear comments and technical specs, they let other programmers understand their code, which means other programmers can use and work with their code instead of rewriting it. Absent this, their code is worthless. By writing clear technical documentation for end users, they allow people to figure out what their code is supposed to do, which is the only way those users can see the value in their code. There’s a lot of wonderful, useful code buried on sourceforge somewhere that nobody uses because it was created by programmers who don’t write very well (or don’t write at all), and so nobody knows what they’ve done and their brilliant code languishes. I won’t hire a programmer unless they can write, and write well, in English. If you can write, wherever you get hired, you’ll soon find that you’re getting asked to write the specifications and that means you’re already leveraging your influence and getting noticed by management. Most colleges designate certain classes as “writing intensive,” meaning, you have to write an awful lot to pass them. Look for those classes and take them! Seek out classes in any field that have weekly or daily written assignments. Start a journal or weblog. The more you write, the easier it will be, and the easier it is to write, the more you’ll write, in a virtuous circle. Learn C before graduatingPart two: C. Notice I didn’t say C++. Although C is becoming increasingly rare, it is still the lingua franca of working programmers. It is the language they use to communicate with one another, and, more importantly, it is much closer to the machine than “modern” languages that you’ll be taught in college like ML, Java, Python, whatever trendy junk they teach these days. You need to spend at least a semester getting close to the machine or you’ll never be able to create efficient code in higher level languages. You’ll never be able to work on compilers and operating systems, which are some of the best programming jobs around. You’ll never be trusted to create architectures for large scale projects. I don’t care how much you know about continuations and closures and exception handling: if you can’t explain why while (s++ = t++); copies a string, or if that isn’t the most natural thing in the world to you, well, you’re programming based on superstition, as far as I’m concerned: a medical doctor who doesn’t know basic anatomy, passing out prescriptions based on what the pharma sales babe said would work. Learn microeconomics before graduatingSuper quick review if you haven’t taken any economics courses: econ is one of those fields that starts off with a bang, with many useful theories and facts that make sense, can be proven in the field, etc., and then it’s all downhill from there. The useful bang at the beginning is microeconomics, which is the foundation for literally every theory in business that matters. After that things start to deteriorate: you get into Macroeconomics (feel free to skip this if you want) with its interesting theories about things like the relationship of interest rates to unemployment which, er, seem to be disproven more often than they are proven, and after that it just gets worse and worse and a lot of econ majors switch out to Physics, which gets them better Wall Street jobs, anyway. But make sure you take Microeconomics, because you have to know about supply and demand, you have to know about competitive advantage, and you have to understand NPVs and discounting and marginal utility before you’ll have any idea why business works the way it does. Why should CS majors learn econ? Because a programmer who understands the fundamentals of business is going to be a more valuable programmer, to a business, than a programmer who doesn’t. That’s all there is to it. I can’t tell you how many times I’ve been frustrated by programmers with crazy ideas that make sense in code but don’t make sense in capitalism. If you understand this stuff, you’re a more valuable programmer, and you’ll get rewarded for it, for reasons which you’ll also learn in micro. Don’t blow off non-CS classes just because they’re boring.Blowing off your non-CS courses is a great way to get a lower GPA. Never underestimate how big a deal your GPA is. Lots and lots of recruiters and hiring managers, myself included, go straight to the GPA when they scan a resume, and we’re not going to apologize for it. Why? Because the GPA, more than any other one number, reflects the sum of what dozens of professors over a long period of time in many different situations think about your work. SAT scores? Ha! That’s one test over a few hours. The GPA reflects hundreds of papers and midterms and classroom participations over four years. Yeah, it’s got its problems. There has been grade inflation over the years. Nothing about your GPA says whether you got that GPA taking easy classes in home economics at Podunk Community College or taking graduate level Quantum Mechanics at Caltech. Eventually, after I screen out all the 2.5 GPAs from Podunk Community, I’m going to ask for transcripts and recommendations. And then I’m going to look for consistently high grades, not just high grades in computer science. Why should I, as an employer looking for software developers, care about what grade you got in European History? After all, history is boring. Oh, so, you’re saying I should hire you because you don’t work very hard when the work is boring? Well, there’s boring stuff in programming, too. Every job has its boring moments. And I don’t want to hire people that only want to do the fun stuff. I took this course in college called Cultural Anthropology because I figured, what the heck, I need to learn something about anthropology, and this looked like an interesting survey course. Interesting? Not even close! I had to read these incredibly monotonous books about Indians in the Brazilian rain forest and Trobriand Islanders, who, with all due respect, are not very interesting to me. At some point, the class was so incredibly wearisome that I longed for something more exciting, like watching grass grow. I had completely lost interest in the subject matter. Completely, and thoroughly. My eyes teared I was so tired of the endless discussions of piling up yams. I don’t know why the Trobriand Islanders spend so much time piling up yams, I can’t remember any more, it’s incredibly boring, but It Was Going To Be On The Midterm, so I plowed through it. I eventually decided that Cultural Anthropology was going to be my Boredom Gauntlet: my personal obstacle course of tedium. If I could get an A in a class where the tests required me to learn all about potlatch blankets, I could handle anything, no matter how boring. The next time I accidentally get stuck in Lincoln Center sitting through all 18 hours of Wagner’s Ring Cycle, I could thank my studies of the Kwakiutl for making it seem pleasant by comparison. I got an A. And if I could do it, you can do it. Take programming-intensive courses.I remember the exact moment I vowed never to go to graduate school. It was in a course on Dynamic Logic, taught by the dynamic Lenore Zuck at Yale, one of the brightest of an array of very bright CS faculty. Now, my murky recollections are not going to do proper credit to this field, but let me muddle through anyway. The idea of Formal Logic is that you prove things are true because other things are true. For example thanks to Formal Logic, “Everyone who gets good grades will get hired” plus “Johnny got good grades” allows you to discover the new true fact, “Johnny will get hired.” It’s all very quaint and it only takes ten seconds for a deconstructionist to totally tear apart everything useful in Formal Logic so you’re left with something fun, but useless. Now, dynamic logic is the same thing, with the addition of time. For example, “after you turn the light on, you can see your shoes” plus “The light went on in the past” implies “you can see your shoes.” Dynamic Logic is appealing to brilliant theoreticians like Professor Zuck because it holds up the hope that you might be able to formally prove things about computer programs, which could be very useful, if, for example, you could formally prove that the Mars Rover’s flash card wouldn’t overflow and cause itself to be rebooted again and again all day long when it’s supposed to be driving around the red planet looking for Marvin the Martian. So in the first day of that class, Dr. Zuck filled up two entire whiteboards and quite a lot of the wall next to the whiteboards proving that if you have a light switch, and the light was off, and you flip the switch, the light will then be on. The proof was insanely complicated, and very error-prone. It was harder to prove that the proof was correct than to convince yourself of the fact that switching a light switch turns on the light. Indeed the multiple whiteboards of proof included many skipped steps, skipped because they were too tedious to go into formally. Many steps were reached using the long-cherished method of Proof by Induction, others by Proof by Reductio ad Absurdum, and still others using Proof by Graduate Student. For our homework, we had to prove the converse: if the light was off, and it’s on now, prove that you flipped it. I tried, I really did. I spent hours in the library trying. After a couple of hours I found a mistake in Dr. Zuck’s original proof which I was trying to emulate. Probably I copied it down wrong, but it made me realize something: if it takes three hours of filling up blackboards to prove something trivial, allowing hundreds of opportunities for mistakes to slip in, this mechanism would never be able to prove things that are interesting. Not that that matters to dynamic logicians: they’re not in it for useful, they’re in it for tenure. I dropped the class and vowed never to go to graduate school in Computer Science. The moral of the story is that computer science is not the same as software development. If you’re really really lucky, your school might have a decent software development curriculum, although, they might not, because elite schools think that teaching practical skills is better left to the technical-vocational institutes and the prison rehabilitation programs. You can learn mere programming anywhere. We are Yale University, and we Mold Future World Leaders. You think your $160,000 tuition entititles you to learn about while loops? What do you think this is, some fly-by-night Java seminar at the Airport Marriott? Pshaw. The trouble is, we don’t really have professional schools in software development, so if you want to be a programmer, you probably majored in Computer Science. Which is a fine subject to major in, but it’s a different subject than software development. If you’re lucky, though, you can find lots of programming-intensive courses in the CS department, just like you can find lots of courses in the History department where you’ll write enough to learn how to write. And those are the best classes to take. If you love programming, don’t feel bad if you don’t understand the point of those courses in lambda calculus or linear algebra where you never touch a computer. Look for the 400-level courses with Practicum in the name. This is an attempt to hide a useful (shudder) course from the Liberal Artsy Fartsy Administration by dolling it up with a Latin name. Stop worrying about all the jobs going to India.Well, OK, first of all, if you’re already in India, you never really had to worry about this, so don’t even start worrying about all the jobs going to India. They’re wonderful jobs, enjoy them in good health. But I keep hearing that enrollment in CS departments is dropping perilously, and one reason I hear for it is “students are afraid to go into a field where all the jobs are going to India.” That’s so wrong for so many reasons. First, trying to choose a career based on a current business fad is foolish. Second, programming is incredibly good training for all kinds of fabulously interesting jobs, such as business process engineering, even if every single programming job does go to India and China. Third, and trust me on this, there’s still an incredible shortage of the really good programmers, here and in India. Yes, there are a bunch of out of work IT people making a lot of noise about how long they’ve been out of work, but you know what? At the risk of pissing them off, really good programmers do have jobs. Fourth, you got any better ideas? What are you going to do, major in History? Then you’ll have no choice but to go to law school. And there’s one thing I do know: 99% of working lawyers hate their jobs, hate every waking minute of it, and they’re working 90 hour weeks, too. Like I said: if you love to program computers, count your blessings: you are in a very fortunate minority of people who can make a great living doing work they love. Anyway, I don’t think students really think about this. The drop in CS enrollment is merely a resumption of historically normal levels after a big bubble in enrollment caused by dotcom mania. That bubble consisted of people who didn’t really like programming but thought the sexy high paid jobs and the chances to IPO at age 24 were to be found in the CS department. Those people, thankfully, are long gone. No matter what you do, get a good summer internship.Smart recruiters know that the people who love programming wrote a database for their dentist in 8th grade, and taught at computer camp for three summers before college, and built the content management system for the campus newspaper, and had summer internships at software companies. That’s what they’re looking for on your resume. If you enjoy programming, the biggest mistake you can make is to take any kind of job–summer, part time, or otherwise–that is not a programming job. I know, every other 19-year-old wants to work in the mall folding shirts, but you have a skill that is incredibly valuable even when you’re 19, and it’s foolish to waste it folding shirts. By the time you graduate, you really should have a resume that lists a whole bunch of programming jobs. The A&amp;F graduates are going to be working at Enterprise Rent-a-Car “helping people with their rental needs.” (Except for Tom Welling. He plays Superman on TV.) To make your life really easy, and to underscore just how completely self-serving this whole essay is, my company, Fog Creek Software, has summer internships in software development that look great on resumes. “You will most likely learn more about software coding, development, and business with Fog Creek Software than any other internship out there,” says Ben, one of the interns from last summer, and not entirely because I sent a goon out to his dorm room to get him to say that. The application deadline is February 1st. Get on it. If you follow my advice, you, too, may end up selling stock in Microsoft way too soon, turning down jobs at Google because you want your own office with a door, and other stupid life decisions, but they won’t be my fault. I told you not to listen to me. WANT TO KNOW MORE? You’re reading Joel on Software, stuffed with years and years of completely raving mad articles about software development, managing software teams, designing user interfaces, running successful software companies, and rubber duckies. ABOUT THE AUTHOR. I’m Joel Spolsky, co-founder of Trello and Fog Creek Software, and CEO of Stack Overflow. More about me.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Education","slug":"Education","permalink":"http://ipcreator.me/tags/Education/"}]},{"title":"Undergraduation, Want to start a startup?","date":"2017-01-20T11:37:06.000Z","path":"2017/01/20/Program/Concepts/want-to-start-a-startup-undergraduate/","text":"Paul Graham July 2004 March 2005 (Parts of this essay began as replies to students who wrote to me with questions.) Recently I’ve had several emails from computer science undergrads asking what to do in college. I might not be the best source of advice, because I was a philosophy major in college. But I took so many CS classes that most CS majors thought I was one. I was certainly a hacker, at least. Hacking What should you do in college to become a good hacker? There are two main things you can do: become very good at programming, and learn a lot about specific, cool problems. These turn out to be equivalent, because each drives you to do the other. The way to be good at programming is to work (a) a lot (b) on hard problems. And the way to make yourself work on hard problems is to work on some very engaging project. Odds are this project won’t be a class assignment. My friend Robert learned a lot by writing network software when he was an undergrad. One of his projects was to connect Harvard to the Arpanet; it had been one of the original nodes, but by 1984 the connection had died. [1] Not only was this work not for a class, but because he spent all his time on it and neglected his studies, he was kicked out of school for a year. [2] It all evened out in the end, and now he’s a professor at MIT. But you’ll probably be happier if you don’t go to that extreme; it caused him a lot of worry at the time. Another way to be good at programming is to find other people who are good at it, and learn what they know. Programmers tend to sort themselves into tribes according to the type of work they do and the tools they use, and some tribes are smarter than others. Look around you and see what the smart people seem to be working on; there’s usually a reason. Some of the smartest people around you are professors. So one way to find interesting work is to volunteer as a research assistant. Professors are especially interested in people who can solve tedious system-administration type problems for them, so that is a way to get a foot in the door. What they fear are flakes and resume padders. It’s all too common for an assistant to result in a net increase in work. So you have to make it clear you’ll mean a net decrease. Don’t be put off if they say no. Rejection is almost always less personal than the rejectee imagines. Just move on to the next. (This applies to dating too.) Beware, because although most professors are smart, not all of them work on interesting stuff. Professors have to publish novel results to advance their careers, but there is more competition in more interesting areas of research. So what less ambitious professors do is turn out a series of papers whose conclusions are novel because no one else cares about them. You’re better off avoiding these. I never worked as a research assistant, so I feel a bit dishonest recommending that route. I learned to program by writing stuff of my own, particularly by trying to reverse-engineer Winograd’s SHRDLU. I was as obsessed with that program as a mother with a new baby. Whatever the disadvantages of working by yourself, the advantage is that the project is all your own. You never have to compromise or ask anyone’s permission, and if you have a new idea you can just sit down and start implementing it. In your own projects you don’t have to worry about novelty (as professors do) or profitability (as businesses do). All that matters is how hard the project is technically, and that has no correlation to the nature of the application. “Serious” applications like databases are often trivial and dull technically (if you ever suffer from insomnia, try reading the technical literature about databases) while “frivolous” applications like games are often very sophisticated. I’m sure there are game companies out there working on products with more intellectual content than the research at the bottom nine tenths of university CS departments. If I were in college now I’d probably work on graphics: a network game, for example, or a tool for 3D animation. When I was an undergrad there weren’t enough cycles around to make graphics interesting, but it’s hard to imagine anything more fun to work on now. Math When I was in college, a lot of the professors believed (or at least wished) that computer science was a branch of math. This idea was strongest at Harvard, where there wasn’t even a CS major till the 1980s; till then one had to major in applied math. But it was nearly as bad at Cornell. When I told the fearsome Professor Conway that I was interested in AI (a hot topic then), he told me I should major in math. I’m still not sure whether he thought AI required math, or whether he thought AI was nonsense and that majoring in something rigorous would cure me of such stupid ambitions. In fact, the amount of math you need as a hacker is a lot less than most university departments like to admit. I don’t think you need much more than high school math plus a few concepts from the theory of computation. (You have to know what an n^2 algorithm is if you want to avoid writing them.) Unless you’re planning to write math applications, of course. Robotics, for example, is all math. But while you don’t literally need math for most kinds of hacking, in the sense of knowing 1001 tricks for differentiating formulas, math is very much worth studying for its own sake. It’s a valuable source of metaphors for almost any kind of work.[3] I wish I’d studied more math in college for that reason. Like a lot of people, I was mathematically abused as a child. I learned to think of math as a collection of formulas that were neither beautiful nor had any relation to my life (despite attempts to translate them into “word problems”), but had to be memorized in order to do well on tests. One of the most valuable things you could do in college would be to learn what math is really about. This may not be easy, because a lot of good mathematicians are bad teachers. And while there are many popular books on math, few seem good. The best I can think of are W. W. Sawyer’s. And of course Euclid. [4] Everything Thomas Huxley said “Try to learn something about everything and everything about something.” Most universities aim at this ideal. But what’s everything? To me it means, all that people learn in the course of working honestly on hard problems. All such work tends to be related, in that ideas and techniques from one field can often be transplanted successfully to others. Even others that seem quite distant. For example, I write essays the same way I write software: I sit down and blow out a lame version 1 as fast as I can type, then spend several weeks rewriting it. Working on hard problems is not, by itself, enough. Medieval alchemists were working on a hard problem, but their approach was so bogus that there was little to learn from studying it, except possibly about people’s ability to delude themselves. Unfortunately the sort of AI I was trying to learn in college had the same flaw: a very hard problem, blithely approached with hopelessly inadequate techniques. Bold? Closer to fraudulent. The social sciences are also fairly bogus, because they’re so much influenced by intellectual fashions. If a physicist met a colleague from 100 years ago, he could teach him some new things; if a psychologist met a colleague from 100 years ago, they’d just get into an ideological argument. Yes, of course, you’ll learn something by taking a psychology class. The point is, you’ll learn more by taking a class in another department. The worthwhile departments, in my opinion, are math, the hard sciences, engineering, history (especially economic and social history, and the history of science), architecture, and the classics. A survey course in art history may be worthwhile. Modern literature is important, but the way to learn about it is just to read. I don’t know enough about music to say. You can skip the social sciences, philosophy, and the various departments created recently in response to political pressures. Many of these fields talk about important problems, certainly. But the way they talk about them is useless. For example, philosophy talks, among other things, about our obligations to one another; but you can learn more about this from a wise grandmother or E. B. White than from an academic philosopher. I speak here from experience. I should probably have been offended when people laughed at Clinton for saying “It depends on what the meaning of the word ‘is’ is.” I took about five classes in college on what the meaning of “is” is. Another way to figure out which fields are worth studying is to create the dropout graph. For example, I know many people who switched from math to computer science because they found math too hard, and no one who did the opposite. People don’t do hard things gratuitously; no one will work on a harder problem unless it is proportionately (or at least log(n)) more rewarding. So probably math is more worth studying than computer science. By similar comparisons you can make a graph of all the departments in a university. At the bottom you’ll find the subjects with least intellectual content. If you use this method, you’ll get roughly the same answer I just gave. Language courses are an anomaly. I think they’re better considered as extracurricular activities, like pottery classes. They’d be far more useful when combined with some time living in a country where the language is spoken. On a whim I studied Arabic as a freshman. It was a lot of work, and the only lasting benefits were a weird ability to identify semitic roots and some insights into how people recognize words. Studio art and creative writing courses are wildcards. Usually you don’t get taught much: you just work (or don’t work) on whatever you want, and then sit around offering “crits” of one another’s creations under the vague supervision of the teacher. But writing and art are both very hard problems that (some) people work honestly at, so they’re worth doing, especially if you can find a good teacher. Jobs Of course college students have to think about more than just learning. There are also two practical problems to consider: jobs, and graduate school. In theory a liberal education is not supposed to supply job training. But everyone knows this is a bit of a fib. Hackers at every college learn practical skills, and not by accident. What you should learn to get a job depends on the kind you want. If you want to work in a big company, learn how to hack Blub on Windows. If you want to work at a cool little company or research lab, you’ll do better to learn Ruby on Linux. And if you want to start your own company, which I think will be more and more common, master the most powerful tools you can find, because you’re going to be in a race against your competitors, and they’ll be your horse. There is not a direct correlation between the skills you should learn in college and those you’ll use in a job. You should aim slightly high in college. In workouts a football player may bench press 300 pounds, even though he may never have to exert anything like that much force in the course of a game. Likewise, if your professors try to make you learn stuff that’s more advanced than you’ll need in a job, it may not just be because they’re academics, detached from the real world. They may be trying to make you lift weights with your brain. The programs you write in classes differ in three critical ways from the ones you’ll write in the real world: they’re small; you get to start from scratch; and the problem is usually artificial and predetermined. In the real world, programs are bigger, tend to involve existing code, and often require you to figure out what the problem is before you can solve it. You don’t have to wait to leave (or even enter) college to learn these skills. If you want to learn how to deal with existing code, for example, you can contribute to open-source projects. The sort of employer you want to work for will be as impressed by that as good grades on class assignments. In existing open-source projects you don’t get much practice at the third skill, deciding what problems to solve. But there’s nothing to stop you starting new projects of your own. And good employers will be even more impressed with that. What sort of problem should you try to solve? One way to answer that is to ask what you need as a user. For example, I stumbled on a good algorithm for spam filtering because I wanted to stop getting spam. Now what I wish I had was a mail reader that somehow prevented my inbox from filling up. I tend to use my inbox as a todo list. But that’s like using a screwdriver to open bottles; what one really wants is a bottle opener. Grad School What about grad school? Should you go? And how do you get into a good one? In principle, grad school is professional training in research, and you shouldn’t go unless you want to do research as a career. And yet half the people who get PhDs in CS don’t go into research. I didn’t go to grad school to become a professor. I went because I wanted to learn more. So if you’re mainly interested in hacking and you go to grad school, you’ll find a lot of other people who are similarly out of their element. And if half the people around you are out of their element in the same way you are, are you really out of your element? There’s a fundamental problem in “computer science,” and it surfaces in situations like this. No one is sure what “research” is supposed to be. A lot of research is hacking that had to be crammed into the form of an academic paper to yield one more quantum of publication. So it’s kind of misleading to ask whether you’ll be at home in grad school, because very few people are quite at home in computer science. The whole field is uncomfortable in its own skin. So the fact that you’re mainly interested in hacking shouldn’t deter you from going to grad school. Just be warned you’ll have to do a lot of stuff you don’t like. Number one will be your dissertation. Almost everyone hates their dissertation by the time they’re done with it. The process inherently tends to produce an unpleasant result, like a cake made out of whole wheat flour and baked for twelve hours. Few dissertations are read with pleasure, especially by their authors. But thousands before you have suffered through writing a dissertation. And aside from that, grad school is close to paradise. Many people remember it as the happiest time of their lives. And nearly all the rest, including me, remember it as a period that would have been, if they hadn’t had to write a dissertation. [5] The danger with grad school is that you don’t see the scary part upfront. PhD programs start out as college part 2, with several years of classes. So by the time you face the horror of writing a dissertation, you’re already several years in. If you quit now, you’ll be a grad-school dropout, and you probably won’t like that idea. When Robert got kicked out of grad school for writing the Internet worm of 1988, I envied him enormously for finding a way out without the stigma of failure. On the whole, grad school is probably better than most alternatives. You meet a lot of smart people, and your glum procrastination will at least be a powerful common bond. And of course you have a PhD at the end. I forgot about that. I suppose that’s worth something. The greatest advantage of a PhD (besides being the union card of academia, of course) may be that it gives you some baseline confidence. For example, the Honeywell thermostats in my house have the most atrocious UI. My mother, who has the same model, diligently spent a day reading the user’s manual to learn how to operate hers. She assumed the problem was with her. But I can think to myself “If someone with a PhD in computer science can’t understand this thermostat, it must be badly designed.” If you still want to go to grad school after this equivocal recommendation, I can give you solid advice about how to get in. A lot of my friends are CS professors now, so I have the inside story about admissions. It’s quite different from college. At most colleges, admissions officers decide who gets in. For PhD programs, the professors do. And they try to do it well, because the people they admit are going to be working for them. Apparently only recommendations really matter at the best schools. Standardized tests count for nothing, and grades for little. The essay is mostly an opportunity to disqualify yourself by saying something stupid. The only thing professors trust is recommendations, preferably from people they know. [6] So if you want to get into a PhD program, the key is to impress your professors. And from my friends who are professors I know what impresses them: not merely trying to impress them. They’re not impressed by students who get good grades or want to be their research assistants so they can get into grad school. They’re impressed by students who get good grades and want to be their research assistants because they’re genuinely interested in the topic. So the best thing you can do in college, whether you want to get into grad school or just be good at hacking, is figure out what you truly like. It’s hard to trick professors into letting you into grad school, and impossible to trick problems into letting you solve them. College is where faking stops working. From this point, unless you want to go work for a big company, which is like reverting to high school, the only way forward is through doing what you love. Notes [1] No one seems to have minded, which shows how unimportant the Arpanet (which became the Internet) was as late as 1984. [2] This is why, when I became an employer, I didn’t care about GPAs. In fact, we actively sought out people who’d failed out of school. We once put up posters around Harvard saying “Did you just get kicked out for doing badly in your classes because you spent all your time working on some project of your own? Come work for us!” We managed to find a kid who had been, and he was a great hacker. When Harvard kicks undergrads out for a year, they have to get jobs. The idea is to show them how awful the real world is, so they’ll understand how lucky they are to be in college. This plan backfired with the guy who came to work for us, because he had more fun than he’d had in school, and made more that year from stock options than any of his professors did in salary. So instead of crawling back repentant at the end of the year, he took another year off and went to Europe. He did eventually graduate at about 26. [3] Eric Raymond says the best metaphors for hackers are in set theory, combinatorics, and graph theory. Trevor Blackwell reminds you to take math classes intended for math majors. “‘Math for engineers’ classes sucked mightily. In fact any ‘x for engineers’ sucks, where x includes math, law, writing and visual design.” [4] Other highly recommended books: What is Mathematics?, by Courant and Robbins; Geometry and the Imagination by Hilbert and Cohn-Vossen. And for those interested in graphic design, Byrne’s Euclid. [5] If you wanted to have the perfect life, the thing to do would be to go to grad school, secretly write your dissertation in the first year or two, and then just enjoy yourself for the next three years, dribbling out a chapter at a time. This prospect will make grad students’ mouths water, but I know of no one who’s had the discipline to pull it off. [6] One professor friend says that 15-20% of the grad students they admit each year are “long shots.” But what he means by long shots are people whose applications are perfect in every way, except that no one on the admissions committee knows the professors who wrote the recommendations. So if you want to get into grad school in the sciences, you need to go to college somewhere with real research professors. Otherwise you’ll seem a risky bet to admissions committees, no matter how good you are. Which implies a surprising but apparently inevitable consequence: little liberal arts colleges are doomed. Most smart high school kids at least consider going into the sciences, even if they ultimately choose not to. Why go to a college that limits their options? Thanks to Trevor Blackwell, Alex Lewin, Jessica Livingston, Robert Morris, Eric Raymond, and several anonymous CS professors for reading drafts of this, and to the students whose questions began it. Joel Spolsky: [Advice for Computer Science College Students](http://www.joelonsoftware.com/articles/CollegeAdvice.html) Eric Raymond: [How to Become a Hacker](http://www.catb.org/~esr/faqs/hacker-howto.html) More Advice for UndergradsI asked several friends who were professors and/or eminent hackers what they thought of Undergraduation. Their comments were so good that I thought I&apos;d just give them directly to you. I&apos;ve given them all codenames for now, since some may want to remain anonymous. NT: The one thing that I felt was missing from your essay was a statement supporting or dispelling the notion that CS is for loners. I disagree with this notion. I love hacking, but I love it even more when it&apos;s a shared experience. The hard problems seem just a bit more surmountable when there&apos;s two of you. Of course, Fred Brooks&apos;s law about adding manpower comes into play eventually. The rule: work in small groups with good people. Stay away from large bureaucratic organizations where status reports are more important than thinking outside the box. There are many individual aspects to CS, just like art. But, being an individual doesn&apos;t mean that the machine takes the place of good friends, colleagues, and mentors. TO: I think you should say &quot;College is where faking starts to stop working.&quot; FS: Math is more difficult than CS, no question. However, it is not at all clear to me that math has as much intellectual content as CS. The math hills are individually harder to climb, but CS is a bigger piece of landscape. (Formally, CS has to encompass reasoning about stateful objects with histories. There are important ways in which this is more difficult and general than pure axiomatic systems.) Empirically, I don&apos;t think the difference between math and CS is very useful for predicting how interesting and effective a thinker will come out the other end. So, while I agree with the spirit of your &quot;dropout graph&quot; heuristic, I think math and CS are an unhelpful choice to explain it with. Much better to note that both are hard subjects with real content, and contrast them with some sort of blatant basket-weaving like political science or (urgh) &quot;ethnic studies.&quot; &quot;They may be trying to make you lift weights with your brain.&quot; Indeed; I think pure mathematics makes excellent weightlifting. SA: The problem with graphics as an application is that doing a decent 3D game has a large component of movie making in it. You need motion capture and an art department for all the textures and backgrounds. Nobody will be impressed with pink cubes and green spheres bouncing around on the screen. I think the technology has pretty much surpassed anyone&apos;s ability to do anything simple and cool with it. DF: I found, when I was studying mathematics, that 2 things were true: (1) the teacher was not too good and (2) the book was not too good. So I would always buy a half-dozen books on the topic and try to get the full picture by reading the same sections in each book. The combination helped me understand much more than the sum of the content. Also, I was never opposed to reading something as much as 10 times until I squeezed everything out of it. I have found mathematics and especially formal logic to be an indispensible tool for structuring ideas. It was like Latin for me. Latin was this very clean natural language and logic was this very clean formal language. I had to teach it to myself because the logic course I had was the first 30 pages of Mendelsohn. When you want to say something unequivocally, describing formally is a good first start. When you want to understand, for example, the excitement of monads, understanding logic and some category theory helps. Category theory is also quite pretty. It simply says that everything has to be described in terms of function composition and this operator has to satisfy certain properties. If you think of logic as something alive, which allows you to prove theorems, it is fascinating. Just think about it: prove theorems by computer. It is mind-boggling. It will not likely lead to a start-up being successful, but what a moment when you prove a theorem without heuristics, etc. I have insisted that all my graduate students minor in logic, so that should say something. ML: The real reason to study math is not that it&apos;s useful but that it&apos;s cool. This should be all the reason a would-be hacker needs. Also, with its emphasis on rigor and abstraction, it&apos;s cool in a lot of the same ways as programming at its best. The fact that it&apos;s occasionally useful as well is just lagniappe. I also disagree that good mathematicians tend to be bad teachers. Having enjoyed the privilege of an expensive education, I am of the opinion that the very best mathematicians are usually (certainly not always) rather good teachers and are sometimes extraordinarily good. The real reason it is hard to learn what math is about is that mathematical understanding requires new and difficult (at least at first) ways of thinking. Cookbook calculus courses sidestep these difficulties and therefore teach little of value. Really understanding calculus was hard for Newton and is hard today.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Education","slug":"Education","permalink":"http://ipcreator.me/tags/Education/"}]},{"title":"Great hacker, Want to start a startup?","date":"2017-01-20T11:37:06.000Z","path":"2017/01/20/Program/Concepts/want-to-start-a-startup-great-hacker/","text":"Paul Graham July 2004 (This essay is derived from a talk at Oscon 2004.) A few months ago I finished a new book, and in reviews I keep noticing words like “provocative’’ and “controversial.’’ To say nothing of “idiotic.’’ I didn’t mean to make the book controversial. I was trying to make it efficient. I didn’t want to waste people’s time telling them things they already knew. It’s more efficient just to give them the diffs. But I suppose that’s bound to yield an alarming book. Edisons There’s no controversy about which idea is most controversial: the suggestion that variation in wealth might not be as big a problem as we think. I didn’t say in the book that variation in wealth was in itself a good thing. I said in some situations it might be a sign of good things. A throbbing headache is not a good thing, but it can be a sign of a good thing– for example, that you’re recovering consciousness after being hit on the head. Variation in wealth can be a sign of variation in productivity. (In a society of one, they’re identical.) And that is almost certainly a good thing: if your society has no variation in productivity, it’s probably not because everyone is Thomas Edison. It’s probably because you have no Thomas Edisons. In a low-tech society you don’t see much variation in productivity. If you have a tribe of nomads collecting sticks for a fire, how much more productive is the best stick gatherer going to be than the worst? A factor of two? Whereas when you hand people a complex tool like a computer, the variation in what they can do with it is enormous. That’s not a new idea. Fred Brooks wrote about it in 1974, and the study he quoted was published in 1968. But I think he underestimated the variation between programmers. He wrote about productivity in lines of code: the best programmers can solve a given problem in a tenth the time. But what if the problem isn’t given? In programming, as in many fields, the hard part isn’t solving problems, but deciding what problems to solve. Imagination is hard to measure, but in practice it dominates the kind of productivity that’s measured in lines of code. Productivity varies in any field, but there are few in which it varies so much. The variation between programmers is so great that it becomes a difference in kind. I don’t think this is something intrinsic to programming, though. In every field, technology magnifies differences in productivity. I think what’s happening in programming is just that we have a lot of technological leverage. But in every field the lever is getting longer, so the variation we see is something that more and more fields will see as time goes on. And the success of companies, and countries, will depend increasingly on how they deal with it. If variation in productivity increases with technology, then the contribution of the most productive individuals will not only be disproportionately large, but will actually grow with time. When you reach the point where 90% of a group’s output is created by 1% of its members, you lose big if something (whether Viking raids, or central planning) drags their productivity down to the average. If we want to get the most out of them, we need to understand these especially productive people. What motivates them? What do they need to do their jobs? How do you recognize them? How do you get them to come and work for you? And then of course there’s the question, how do you become one? More than Money I know a handful of super-hackers, so I sat down and thought about what they have in common. Their defining quality is probably that they really love to program. Ordinary programmers write code to pay the bills. Great hackers think of it as something they do for fun, and which they’re delighted to find people will pay them for. Great programmers are sometimes said to be indifferent to money. This isn’t quite true. It is true that all they really care about is doing interesting work. But if you make enough money, you get to work on whatever you want, and for that reason hackers are attracted by the idea of making really large amounts of money. But as long as they still have to show up for work every day, they care more about what they do there than how much they get paid for it. Economically, this is a fact of the greatest importance, because it means you don’t have to pay great hackers anything like what they’re worth. A great programmer might be ten or a hundred times as productive as an ordinary one, but he’ll consider himself lucky to get paid three times as much. As I’ll explain later, this is partly because great hackers don’t know how good they are. But it’s also because money is not the main thing they want. What do hackers want? Like all craftsmen, hackers like good tools. In fact, that’s an understatement. Good hackers find it unbearable to use bad tools. They’ll simply refuse to work on projects with the wrong infrastructure. At a startup I once worked for, one of the things pinned up on our bulletin board was an ad from IBM. It was a picture of an AS400, and the headline read, I think, “hackers despise it.’’ [1] When you decide what infrastructure to use for a project, you’re not just making a technical decision. You’re also making a social decision, and this may be the more important of the two. For example, if your company wants to write some software, it might seem a prudent choice to write it in Java. But when you choose a language, you’re also choosing a community. The programmers you’ll be able to hire to work on a Java project won’t be as smart as the ones you could get to work on a project written in Python. And the quality of your hackers probably matters more than the language you choose. Though, frankly, the fact that good hackers prefer Python to Java should tell you something about the relative merits of those languages. Business types prefer the most popular languages because they view languages as standards. They don’t want to bet the company on Betamax. The thing about languages, though, is that they’re not just standards. If you have to move bits over a network, by all means use TCP/IP. But a programming language isn’t just a format. A programming language is a medium of expression. I’ve read that Java has just overtaken Cobol as the most popular language. As a standard, you couldn’t wish for more. But as a medium of expression, you could do a lot better. Of all the great programmers I can think of, I know of only one who would voluntarily program in Java. And of all the great programmers I can think of who don’t work for Sun, on Java, I know of zero. Great hackers also generally insist on using open source software. Not just because it’s better, but because it gives them more control. Good hackers insist on control. This is part of what makes them good hackers: when something’s broken, they need to fix it. You want them to feel this way about the software they’re writing for you. You shouldn’t be surprised when they feel the same way about the operating system. A couple years ago a venture capitalist friend told me about a new startup he was involved with. It sounded promising. But the next time I talked to him, he said they’d decided to build their software on Windows NT, and had just hired a very experienced NT developer to be their chief technical officer. When I heard this, I thought, these guys are doomed. One, the CTO couldn’t be a first rate hacker, because to become an eminent NT developer he would have had to use NT voluntarily, multiple times, and I couldn’t imagine a great hacker doing that; and two, even if he was good, he’d have a hard time hiring anyone good to work for him if the project had to be built on NT. [2] The Final Frontier After software, the most important tool to a hacker is probably his office. Big companies think the function of office space is to express rank. But hackers use their offices for more than that: they use their office as a place to think in. And if you’re a technology company, their thoughts are your product. So making hackers work in a noisy, distracting environment is like having a paint factory where the air is full of soot. The cartoon strip Dilbert has a lot to say about cubicles, and with good reason. All the hackers I know despise them. The mere prospect of being interrupted is enough to prevent hackers from working on hard problems. If you want to get real work done in an office with cubicles, you have two options: work at home, or come in early or late or on a weekend, when no one else is there. Don’t companies realize this is a sign that something is broken? An office environment is supposed to be something that helps you work, not something you work despite. Companies like Cisco are proud that everyone there has a cubicle, even the CEO. But they’re not so advanced as they think; obviously they still view office space as a badge of rank. Note too that Cisco is famous for doing very little product development in house. They get new technology by buying the startups that created it– where presumably the hackers did have somewhere quiet to work. One big company that understands what hackers need is Microsoft. I once saw a recruiting ad for Microsoft with a big picture of a door. Work for us, the premise was, and we’ll give you a place to work where you can actually get work done. And you know, Microsoft is remarkable among big companies in that they are able to develop software in house. Not well, perhaps, but well enough. If companies want hackers to be productive, they should look at what they do at home. At home, hackers can arrange things themselves so they can get the most done. And when they work at home, hackers don’t work in noisy, open spaces; they work in rooms with doors. They work in cosy, neighborhoody places with people around and somewhere to walk when they need to mull something over, instead of in glass boxes set in acres of parking lots. They have a sofa they can take a nap on when they feel tired, instead of sitting in a coma at their desk, pretending to work. There’s no crew of people with vacuum cleaners that roars through every evening during the prime hacking hours. There are no meetings or, God forbid, corporate retreats or team-building exercises. And when you look at what they’re doing on that computer, you’ll find it reinforces what I said earlier about tools. They may have to use Java and Windows at work, but at home, where they can choose for themselves, you’re more likely to find them using Perl and Linux. Indeed, these statistics about Cobol or Java being the most popular language can be misleading. What we ought to look at, if we want to know what tools are best, is what hackers choose when they can choose freely– that is, in projects of their own. When you ask that question, you find that open source operating systems already have a dominant market share, and the number one language is probably Perl. Interesting Along with good tools, hackers want interesting projects. What makes a project interesting? Well, obviously overtly sexy applications like stealth planes or special effects software would be interesting to work on. But any application can be interesting if it poses novel technical challenges. So it’s hard to predict which problems hackers will like, because some become interesting only when the people working on them discover a new kind of solution. Before ITA (who wrote the software inside Orbitz), the people working on airline fare searches probably thought it was one of the most boring applications imaginable. But ITA made it interesting by redefining the problem in a more ambitious way. I think the same thing happened at Google. When Google was founded, the conventional wisdom among the so-called portals was that search was boring and unimportant. But the guys at Google didn’t think search was boring, and that’s why they do it so well. This is an area where managers can make a difference. Like a parent saying to a child, I bet you can’t clean up your whole room in ten minutes, a good manager can sometimes redefine a problem as a more interesting one. Steve Jobs seems to be particularly good at this, in part simply by having high standards. There were a lot of small, inexpensive computers before the Mac. He redefined the problem as: make one that’s beautiful. And that probably drove the developers harder than any carrot or stick could. They certainly delivered. When the Mac first appeared, you didn’t even have to turn it on to know it would be good; you could tell from the case. A few weeks ago I was walking along the street in Cambridge, and in someone’s trash I saw what appeared to be a Mac carrying case. I looked inside, and there was a Mac SE. I carried it home and plugged it in, and it booted. The happy Macintosh face, and then the finder. My God, it was so simple. It was just like … Google. Hackers like to work for people with high standards. But it’s not enough just to be exacting. You have to insist on the right things. Which usually means that you have to be a hacker yourself. I’ve seen occasional articles about how to manage programmers. Really there should be two articles: one about what to do if you are yourself a programmer, and one about what to do if you’re not. And the second could probably be condensed into two words: give up. The problem is not so much the day to day management. Really good hackers are practically self-managing. The problem is, if you’re not a hacker, you can’t tell who the good hackers are. A similar problem explains why American cars are so ugly. I call it the design paradox. You might think that you could make your products beautiful just by hiring a great designer to design them. But if you yourself don’t have good taste, how are you going to recognize a good designer? By definition you can’t tell from his portfolio. And you can’t go by the awards he’s won or the jobs he’s had, because in design, as in most fields, those tend to be driven by fashion and schmoozing, with actual ability a distant third. There’s no way around it: you can’t manage a process intended to produce beautiful things without knowing what beautiful is. American cars are ugly because American car companies are run by people with bad taste. Many people in this country think of taste as something elusive, or even frivolous. It is neither. To drive design, a manager must be the most demanding user of a company’s products. And if you have really good taste, you can, as Steve Jobs does, make satisfying you the kind of problem that good people like to work on. Nasty Little Problems It’s pretty easy to say what kinds of problems are not interesting: those where instead of solving a few big, clear, problems, you have to solve a lot of nasty little ones. One of the worst kinds of projects is writing an interface to a piece of software that’s full of bugs. Another is when you have to customize something for an individual client’s complex and ill-defined needs. To hackers these kinds of projects are the death of a thousand cuts. The distinguishing feature of nasty little problems is that you don’t learn anything from them. Writing a compiler is interesting because it teaches you what a compiler is. But writing an interface to a buggy piece of software doesn’t teach you anything, because the bugs are random. [3] So it’s not just fastidiousness that makes good hackers avoid nasty little problems. It’s more a question of self-preservation. Working on nasty little problems makes you stupid. Good hackers avoid it for the same reason models avoid cheeseburgers. Of course some problems inherently have this character. And because of supply and demand, they pay especially well. So a company that found a way to get great hackers to work on tedious problems would be very successful. How would you do it? One place this happens is in startups. At our startup we had Robert Morris working as a system administrator. That’s like having the Rolling Stones play at a bar mitzvah. You can’t hire that kind of talent. But people will do any amount of drudgery for companies of which they’re the founders. [4] Bigger companies solve the problem by partitioning the company. They get smart people to work for them by establishing a separate R&amp;D department where employees don’t have to work directly on customers’ nasty little problems. [5] In this model, the research department functions like a mine. They produce new ideas; maybe the rest of the company will be able to use them. You may not have to go to this extreme. Bottom-up programming suggests another way to partition the company: have the smart people work as toolmakers. If your company makes software to do x, have one group that builds tools for writing software of that type, and another that uses these tools to write the applications. This way you might be able to get smart people to write 99% of your code, but still keep them almost as insulated from users as they would be in a traditional research department. The toolmakers would have users, but they’d only be the company’s own developers. [6] If Microsoft used this approach, their software wouldn’t be so full of security holes, because the less smart people writing the actual applications wouldn’t be doing low-level stuff like allocating memory. Instead of writing Word directly in C, they’d be plugging together big Lego blocks of Word-language. (Duplo, I believe, is the technical term.) Clumping Along with interesting problems, what good hackers like is other good hackers. Great hackers tend to clump together– sometimes spectacularly so, as at Xerox Parc. So you won’t attract good hackers in linear proportion to how good an environment you create for them. The tendency to clump means it’s more like the square of the environment. So it’s winner take all. At any given time, there are only about ten or twenty places where hackers most want to work, and if you aren’t one of them, you won’t just have fewer great hackers, you’ll have zero. Having great hackers is not, by itself, enough to make a company successful. It works well for Google and ITA, which are two of the hot spots right now, but it didn’t help Thinking Machines or Xerox. Sun had a good run for a while, but their business model is a down elevator. In that situation, even the best hackers can’t save you. I think, though, that all other things being equal, a company that can attract great hackers will have a huge advantage. There are people who would disagree with this. When we were making the rounds of venture capital firms in the 1990s, several told us that software companies didn’t win by writing great software, but through brand, and dominating channels, and doing the right deals. They really seemed to believe this, and I think I know why. I think what a lot of VCs are looking for, at least unconsciously, is the next Microsoft. And of course if Microsoft is your model, you shouldn’t be looking for companies that hope to win by writing great software. But VCs are mistaken to look for the next Microsoft, because no startup can be the next Microsoft unless some other company is prepared to bend over at just the right moment and be the next IBM. It’s a mistake to use Microsoft as a model, because their whole culture derives from that one lucky break. Microsoft is a bad data point. If you throw them out, you find that good products do tend to win in the market. What VCs should be looking for is the next Apple, or the next Google. I think Bill Gates knows this. What worries him about Google is not the power of their brand, but the fact that they have better hackers. [7] Recognition So who are the great hackers? How do you know when you meet one? That turns out to be very hard. Even hackers can’t tell. I’m pretty sure now that my friend Trevor Blackwell is a great hacker. You may have read on Slashdot how he made his own Segway. The remarkable thing about this project was that he wrote all the software in one day (in Python, incidentally). For Trevor, that’s par for the course. But when I first met him, I thought he was a complete idiot. He was standing in Robert Morris’s office babbling at him about something or other, and I remember standing behind him making frantic gestures at Robert to shoo this nut out of his office so we could go to lunch. Robert says he misjudged Trevor at first too. Apparently when Robert first met him, Trevor had just begun a new scheme that involved writing down everything about every aspect of his life on a stack of index cards, which he carried with him everywhere. He’d also just arrived from Canada, and had a strong Canadian accent and a mullet. The problem is compounded by the fact that hackers, despite their reputation for social obliviousness, sometimes put a good deal of effort into seeming smart. When I was in grad school I used to hang around the MIT AI Lab occasionally. It was kind of intimidating at first. Everyone there spoke so fast. But after a while I learned the trick of speaking fast. You don’t have to think any faster; just use twice as many words to say everything. With this amount of noise in the signal, it’s hard to tell good hackers when you meet them. I can’t tell, even now. You also can’t tell from their resumes. It seems like the only way to judge a hacker is to work with him on something. And this is the reason that high-tech areas only happen around universities. The active ingredient here is not so much the professors as the students. Startups grow up around universities because universities bring together promising young people and make them work on the same projects. The smart ones learn who the other smart ones are, and together they cook up new projects of their own. Because you can’t tell a great hacker except by working with him, hackers themselves can’t tell how good they are. This is true to a degree in most fields. I’ve found that people who are great at something are not so much convinced of their own greatness as mystified at why everyone else seems so incompetent. But it’s particularly hard for hackers to know how good they are, because it’s hard to compare their work. This is easier in most other fields. In the hundred meters, you know in 10 seconds who’s fastest. Even in math there seems to be a general consensus about which problems are hard to solve, and what constitutes a good solution. But hacking is like writing. Who can say which of two novels is better? Certainly not the authors. With hackers, at least, other hackers can tell. That’s because, unlike novelists, hackers collaborate on projects. When you get to hit a few difficult problems over the net at someone, you learn pretty quickly how hard they hit them back. But hackers can’t watch themselves at work. So if you ask a great hacker how good he is, he’s almost certain to reply, I don’t know. He’s not just being modest. He really doesn’t know. And none of us know, except about people we’ve actually worked with. Which puts us in a weird situation: we don’t know who our heroes should be. The hackers who become famous tend to become famous by random accidents of PR. Occasionally I need to give an example of a great hacker, and I never know who to use. The first names that come to mind always tend to be people I know personally, but it seems lame to use them. So, I think, maybe I should say Richard Stallman, or Linus Torvalds, or Alan Kay, or someone famous like that. But I have no idea if these guys are great hackers. I’ve never worked with them on anything. If there is a Michael Jordan of hacking, no one knows, including him. Cultivation Finally, the question the hackers have all been wondering about: how do you become a great hacker? I don’t know if it’s possible to make yourself into one. But it’s certainly possible to do things that make you stupid, and if you can make yourself stupid, you can probably make yourself smart too. The key to being a good hacker may be to work on what you like. When I think about the great hackers I know, one thing they have in common is the extreme difficulty of making them work on anything they don’t want to. I don’t know if this is cause or effect; it may be both. To do something well you have to love it. So to the extent you can preserve hacking as something you love, you’re likely to do it well. Try to keep the sense of wonder you had about programming at age 14. If you’re worried that your current job is rotting your brain, it probably is. The best hackers tend to be smart, of course, but that’s true in a lot of fields. Is there some quality that’s unique to hackers? I asked some friends, and the number one thing they mentioned was curiosity. I’d always supposed that all smart people were curious– that curiosity was simply the first derivative of knowledge. But apparently hackers are particularly curious, especially about how things work. That makes sense, because programs are in effect giant descriptions of how things work. Several friends mentioned hackers’ ability to concentrate– their ability, as one put it, to “tune out everything outside their own heads.’’ I’ve certainly noticed this. And I’ve heard several hackers say that after drinking even half a beer they can’t program at all. So maybe hacking does require some special ability to focus. Perhaps great hackers can load a large amount of context into their head, so that when they look at a line of code, they see not just that line but the whole program around it. John McPhee wrote that Bill Bradley’s success as a basketball player was due partly to his extraordinary peripheral vision. “Perfect’’ eyesight means about 47 degrees of vertical peripheral vision. Bill Bradley had 70; he could see the basket when he was looking at the floor. Maybe great hackers have some similar inborn ability. (I cheat by using a very dense language, which shrinks the court.) This could explain the disconnect over cubicles. Maybe the people in charge of facilities, not having any concentration to shatter, have no idea that working in a cubicle feels to a hacker like having one’s brain in a blender. (Whereas Bill, if the rumors of autism are true, knows all too well.) One difference I’ve noticed between great hackers and smart people in general is that hackers are more politically incorrect. To the extent there is a secret handshake among good hackers, it’s when they know one another well enough to express opinions that would get them stoned to death by the general public. And I can see why political incorrectness would be a useful quality in programming. Programs are very complex and, at least in the hands of good programmers, very fluid. In such situations it’s helpful to have a habit of questioning assumptions. Can you cultivate these qualities? I don’t know. But you can at least not repress them. So here is my best shot at a recipe. If it is possible to make yourself into a great hacker, the way to do it may be to make the following deal with yourself: you never have to work on boring projects (unless your family will starve otherwise), and in return, you’ll never allow yourself to do a half-assed job. All the great hackers I know seem to have made that deal, though perhaps none of them had any choice in the matter. Notes [1] In fairness, I have to say that IBM makes decent hardware. I wrote this on an IBM laptop. [2] They did turn out to be doomed. They shut down a few months later. [3] I think this is what people mean when they talk about the “meaning of life.” On the face of it, this seems an odd idea. Life isn’t an expression; how could it have meaning? But it can have a quality that feels a lot like meaning. In a project like a compiler, you have to solve a lot of problems, but the problems all fall into a pattern, as in a signal. Whereas when the problems you have to solve are random, they seem like noise. [4] Einstein at one point worked designing refrigerators. (He had equity.) [5] It’s hard to say exactly what constitutes research in the computer world, but as a first approximation, it’s software that doesn’t have users. I don’t think it’s publication that makes the best hackers want to work in research departments. I think it’s mainly not having to have a three hour meeting with a product manager about problems integrating the Korean version of Word 13.27 with the talking paperclip. [6] Something similar has been happening for a long time in the construction industry. When you had a house built a couple hundred years ago, the local builders built everything in it. But increasingly what builders do is assemble components designed and manufactured by someone else. This has, like the arrival of desktop publishing, given people the freedom to experiment in disastrous ways, but it is certainly more efficient. [7] Google is much more dangerous to Microsoft than Netscape was. Probably more dangerous than any other company has ever been. Not least because they’re determined to fight. On their job listing page, they say that one of their “core values’’ is “Don’t be evil.’’ From a company selling soybean oil or mining equipment, such a statement would merely be eccentric. But I think all of us in the computer world recognize who that is a declaration of war on. Thanks to Jessica Livingston, Robert Morris, and Sarah Harlin for reading earlier versions of this talk.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"The Loginataka","date":"2017-01-20T11:31:06.000Z","path":"2017/01/20/Program/Concepts/the-loginataka/","text":"The Loginataka by Eric S. Raymond &#x65;&#x73;&#114;&#64;&#x74;&#x68;&#x79;&#x72;&#x73;&#x75;&#115;&#x2e;&#x63;&#x6f;&#x6d; Speak, O Guru: How can I become a Unix Wizard? O, Nobly Born: know that the Way to Wizardhood is long, and winding, and Fraught with Risks. Thou must Attune thyself with the Source, attaining the arcane Knowledge and Conversation of the System Libraries and Internals. Yea; and such an all-consuming Time and Energy Sink is this as to greatly Imperil thy Grade Point Average (if one thou hast), not to mention thy Sex Life (if one thou hast). But persevere, oh Larval One; rewards beyond the Dreams of Lusers await thee! Speak, O Guru: What books should I study? Are the O’Reilly “Nutshell” guides a good place to start? O, Nobly Born: know that the Nutshell Guides are but the outermost Portal of the True Enlightenment. Worthy are they (and praise to the Name of O’Reilly, whose books show forth the Hacker Spirit in numerous pleasing ways), but the Nutshell Guides are only the Beginning of the Road. If thou desirest with True Desire to tread the Path of Wizardly Wisdom, first learn the elementary Postures of Kernighan &amp; Pike’s The Unix Programming Environment; then, absorb the mantic puissance of March Rochkind’s Advanced Unix Programming and W. Richard Stevens’s Advanced Programming In The Unix Environment. Immerse thyself, then, in the Pure Light of Maurice J. Bach’s The Design Of The Unix Operating System. Neglect not the Berkelian Way; study also The Design and Implementation Of The 4.4BSD Operating System by Kirk McKusick, Keith Bostic et. al. For useful hints, tips, and tricks, see Unix Power Tools, Tim O’Reilly, ed. Consider also the dark Wisdom to be gained from contemplation of the dread Portable C And Unix Systems Programming, e’en though it hath flowed from the keyboard of the mad and doomed Malvernite whom the world of unknowing Man misnames “J. E. Lapin”. These tomes shall instruct thy Left Brain in the Nature of the Unix System; to Feed the other half of thy Head, O Nobly Born, embrace also the Lore of its Nurture. Don Libes’s and Sandy Ressler’s Life With Unix will set thy Feet unerringly upon that Path; take as thy Travelling Companion the erratic but illuminating compendium called The New Hacker’s Dictionary (Eric S. Raymond, ed., with Guy L. Steele Jr.). (In this wise shalt thou travel the Way of the Camel.) Speak, O Guru: To attain Mastery, how many Kernels do I need to take apart and reassemble? O Nobly Born: this question reveals that indeed thou hast touched upon an Ineffable Truth about Unix — that thou canst not Plumb its Mysteries by mere Study but must become One with it through Practice. The true Way to the Knowledge of the Source is not the timid and footling way of the Student, but the Divine Foolery of the Hacker. Hack, then; strive against Mighty Problems, have joy in thy Striving, and let the Crashes fall where they may (maintaining the while, for the Good of thy Karma, a Rigorous Backup Policy). In this day of Boot-Time Autoconfiguration and Dynamically Loadable Device Drivers, reassembling a Kernel is no longer the daunting Test and Seal of Mastery that once it was. However, writing and verifying thine own Device Driver for some piece of Exotic Hardware is still a worthy challenge to thy Budding Guruhood. Indeed, such Challenge may be found the Crafting of any Program sufficiently Powerful to Extend or Compete with the Tools now available in Open Source. Therefore: seek thee out the Open Source Unixes: OpenBSD, FreeBSD, NetBSD, and most Especially Linux in many of its Incarnations. Join the Wizards and Aspirants to Wizardhood who Labor Unceasingly to Improve these. Commune with them in their Great Work, their unceasing Extension and Reinvention of Unix. In this wise may thou become one among the Mighty. Speak, O Guru: Some there are who claim that the sole Path to Wizardry and the proper Way of every Right-Thinking Hacker is to rewrite the Unix Kernel from Scratch. Is this not Sacrilege? Sacrilege, O Nobly Born? Nay! Certainly the Kernel Source is the Inmost Mystery of Unix — but there is a Mystery beyond that Mystery. The Nature of Unix inhereth not in any one Version but in the Design Tradition of which all Unixes are Evolving Parts. The Rite of the Rewrite is not the only Path to Mastery, but it is perhaps the highest and most Sacred of all Paths. Few indeed are those who, travelling it, have crossed the dark and yawning Abyss of Implementation to Delivery. Many, yea, many in truth stagnate yet in the Desert of Delay, or linger ever in the ghastly limbo called Perpetual Beta. (In this wise shalt thou travel the Way of the Lion.) Speak, O Guru: What, then, is the True Path to Wizardhood? O Nobly Born: learn, and seek within thyself. Cultivate the cunning of the Serpent and the courage of the Tiger; sup deeply from the Wisdom of those who came before thee. Hack, and hack again; grow, by trial and by error. Post thy best hacks to the Net and gain in Repute thereby. Also, O Nobly Born, be thou grave and courteous in thy speech; be helpful to those less than thee, quick to succour and slow to flame. If thou dost these things faithfully, if thou travellest with high heart and pure intention, soon shall thy callow Newbiehood be shed. By degrees imperceptible to thyself shalt thou gain Power and Wisdom, Striving and Doing all the while. Gradually shall thy Puissance unfold and deepen. O Nobly Born, if thou dost all these things, thy Wizardhood shall surely come upon thee; but not of a sudden, and not until after thy arrogant Mind hath more than half Forgotten that such was its Aim. For know this — you may not by thyself in Pride claim the Mantle of Wizardry; that way lies only Bogosity without End. Rather must you Become, and Become, and Become, until Hackers respect thy Power, and other Wizards hail thee as a Brother or Sister in Wisdom, and you wake up and realize that the Mantle hath lain unknown upon thy Shoulders since you knew not when. (In this wise shalt thou travel the Way of the Child.) Hear, O nobly born: Techniques can be taught, but the Way of the Hacker cannot be taught. Skills can be acquired, but the Way of the Hacker is not a checklist of skills. Programming can be accomplished, but the Way of the Hacker is not a place at which you can stop and say “I have arrived!” Hear, O nobly born: The Way of the Hacker is a posture of mind; he who seeks a teacher of the Way knows it not, but he is only looking for a mirror. All those competent to teach the Way know that it cannot be taught, only pursued with joyous labor and by emulation of the great hackers of the past. Hear, O nobly born: Great were the hackers of the past! Subtle and deep in their thinking, shaggy-bearded and with thunder on their brows! You may seek to become as them, but it will not suffice you to grow a beard. Hear, O Nobly Born: The center of the mystery is the act of coding. You have a keyboard before you; pursue the Way through work. SHANTIH! SHANTIH! SHANTIH! Annotations: Most of this (up to “(In this wise shalt thou travel the Way of the Child.)”) was originally a Usenet response to some eager newbie questions; it appears that I wrote it on 21 November 1992 in response to a post by one Ade Barkah. After ten years, I guess it’s time to draw aside the veil of those mysteries. The remainder I wrote in 2010 after I was actually asked to give an answer in the style of the Loginataka. For those of you who are not native English speakers, the entirety is written in imitation of the Early Modern English of the late 1500s and early 1600s, the language of the King James Bible. The influence of the King James Bible is such that its dialect has retained connotations of majesty, solemnity, and religious authority. Holy scriptures from other languages are, therefore, often translated into a KJB-like pseudo-archaic English rather than following modern usage. Parts of this border on obsolescence now. Portable C And Unix Systems Programming has been out of print for a long time, but the Lovecraft joke was too funny to lose. Life With Unix is history, too, but the other references are still good. In 1998 I changed references to “freeware” and “free software” to “open source”. Otherwise changes have been pretty minor. “Loginataka” The title of the document is a play on the name of the Tripitaka, an early compilation of Buddhist scriptures. **&quot;Oh Nobly Born:&quot; ** The formulaic use of the salutation is intended to be reminiscent of the Bardo Thödöl — the Tibetan Book Of The Dead. **&quot;the Name of O&apos;Reilly&quot; ** A phrase rich with meaning in the clan system of old Scotland and Ireland. It might refer to the reputation of the clan O’Reilly, or to the person of the clan chief. The implied image is of Tim O’Reilly, be-tartaned, surrounded by louring Celts bristling with weapons. It’s worth noting that O’Reilly and Associates was pretty new at the game when I wrote this; it was over the following five years that they built up their remarkable reputation as friends of the hacker community. **&quot;attaining the arcane Knowledge and Conversation&quot; ** This is a reference to the occultism of Alesteir Crowley. He wrote of attaining the “Knowledge and Conversation of the Holy Guardian Angel” as the central aim of Thelemic mysticism, and added that he had chosen that term for it because it was the most absurd locution he could think of. **&quot;the Pure Light&quot; ** In Buddhist mysticism, the Pure Light of the Void (“void” being the usual English translation of Sanskrit sunyata) is a frequent metaphor for the wisdom that comes from realizing the emptiness of all things. **&quot;the Berkelian Way&quot; ** If you caught the previous reference to sunyata, you might also recall that Bishop Berkeley famously denied the existence of objective reality. **&quot;the mad and doomed Malvernite&quot; ** This is a play on H.P. Lovecraft’s “mad and doomed Arab”, Abdul al-Hazred, the author of the Necronomicon. And the actual doomed Malvernite was…er…me, in 1987. The “world of unknowing man misnames” because I wrote the book, but was pressured into allowing it to be published under a corporate pseudonym. **&quot;feed the other half of thy head&quot; ** Cue Grace Slick, in the last lines of Jefferson Airplane’s White Rabbit, a song about a hallucinogenic drug experience: “Remember…what the dormouse said! FEED YOUR HEAD! FEED YOUR HEAD!” **&quot;the Way of the Camel&quot; ** The references to the Ways of the Camel, Lion, and Child are to a mystical rant in Nietzsche’s Thus Spoke Zarathustra. **&quot;Divine Foolery of the Hacker&quot; ** The image of the Fool of God is a pervasive one in world mysticism. I was thinking here especially of the Fool card in the Rider-Waite Tarot, showing a clown walking or capering at the edge of a precipice. **&quot;Great Work&quot; ** In alchemy, the production of the Philosopher’s Stone that could transmute lead to gold, confer immortality. In some mystical interpretations of alchemy, the transmutation of the adept’s own soul. Modern Hermetic occultism generalizes the second meaning. **&quot;Desert of Delay&quot; ** This part is intended to recall the landscapes in Bunyan’s moral allegory Pilgrim’s Progress. **&quot;cunning of the Serpent and the courage of the Tiger&quot; ** In the New Testament of the Christian Bible, Matthew 10:16 exhorts Christians to be as cunning as serpents and as harmless as doves. This in turn refers to the “cunning of the serpent” in the Old Testament Book of Genesis. **&quot;if thou travellest with high heart and pure intention&quot; ** In the Egyptian Book Of The Dead, “I have travelled here with high heart and pure intention” is part of the ritual one must speak to pass the Weigher of Souls. **&quot;Shantih!&quot; ** “Shanti!” is Sanskrit and means “Peace!” I deliberately used the older transliteration “Shantih!” because it’s found at the end of T.S. Eliot’s poem The Wasteland. The threefold repetition is a form of invocatory magic closely equivalent to the Catholic ritual blessing “Peace be with you!” If you found this entertaining, you would probably also enjoy Rootless Root: The Unix Koans of Master Foo.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"The Art of Unix Programming","date":"2017-01-20T11:16:06.000Z","path":"2017/01/20/Program/Concepts/the-art-of-unix-programming/","text":"The Art of Unix Programming Eric Steven Raymond This book and its on-line version are distributed under the terms of the Creative Commons Attribution-NoDerivs 1.0 license, with the additional proviso that the right to publish it on paper for sale or other for-profit use is reserved to Pearson Education, Inc. A reference copy of this license may be found at http://creativecommons.org/licenses/by-nd/1.0/legalcode. AIX, AS/400, DB/2, OS/2, System/360, MVS, VM/CMS, and IBM PC are trademarks of IBM. Alpha, DEC, VAX, HP-UX, PDP, TOPS-10, TOPS-20, VMS, and VT-100 are trademarks of Compaq. Amiga and AmigaOS are trademarks of Amiga, Inc. Apple, Macintosh, MacOS, Newton, OpenDoc, and OpenStep are trademarks of Apple Computers, Inc. ClearCase is a trademark of Rational Software, Inc. Ethernet is a trademark of 3COM, Inc. Excel, MS-DOS, Microsoft Windows and PowerPoint are trademarks of Microsoft, Inc. Java. J2EE, JavaScript, NeWS, and Solaris are trademarks of Sun Microsystems. SPARC is a trademark of SPARC international. Informix is a trademark of Informix software. Itanium is a trademark of Intel. Linux is a trademark of Linus Torvalds. Netscape is a trademark of AOL. PDF and PostScript are trademarks of Adobe, Inc. UNIX is a trademark of The Open Group. The photograph of Ken and Dennis in Chapter 2 appears courtesy of Bell Labs/Lucent Technologies. The epigraph on the Portability chapter is from the Bell System Technical Journal, v57 #6 part 2 (July-Aug. 1978) pp. 2021-2048 and is reproduced with the permission of Bell Labs/Lucent Technologies. Revision HistoryRevision 1.0 19 September 2003 esrThis is the content that went to Addison-Wesley’s printers.Revision 0.4 5 February 2003 esrRelease for public review.Revision 0.3 22 January 2003 esrFirst eighteen-chapter draft. Manuscript walkthrough at Chapter 12. Limited release for early reviewers.Revision 0.2 2 January 2003 esrFirst manuscript walkthrough at Chapter 7. Released to Dmitry Kirsanov at AW production.Revision 0.1 16 November 2002 esrFirst DocBook draft, fifteen chapters. Languages rewritten to incorporate lots of feedback. Transparency, Modularity, Multiprogramming, Configuration, Interfaces, Documentation, and Open Source chapters released. Shipped to Mark Taub at AW.Revision 0.0 1999 esrPublic HTML draft, first four chapters only.Dedication To Ken Thompson and Dennis Ritchie, because you inspired me. Table of Contents PrefaceWho Should Read This BookHow to Use This BookRelated ReferencesConventions Used in This BookOur Case StudiesAuthor’s AcknowledgementsI. Context PhilosophyCulture? What Culture?The Durability of UnixThe Case against Learning Unix CultureWhat Unix Gets WrongWhat Unix Gets RightOpen-Source SoftwareCross-Platform Portability and Open StandardsThe Internet and the World Wide WebThe Open-Source CommunityFlexibility All the Way DownUnix Is Fun to HackThe Lessons of Unix Can Be Applied ElsewhereBasics of the Unix PhilosophyRule of Modularity: Write simple parts connected by clean interfaces.Rule of Clarity: Clarity is better than cleverness.Rule of Composition: Design programs to be connected with other programs.Rule of Separation: Separate policy from mechanism; separate interfaces from engines.Rule of Simplicity: Design for simplicity; add complexity only where you must.Rule of Parsimony: Write a big program only when it is clear by demonstration that nothing else will do.Rule of Transparency: Design for visibility to make inspection and debugging easier.Rule of Robustness: Robustness is the child of transparency and simplicity.Rule of Representation: Fold knowledge into data, so program logic can be stupid and robust.Rule of Least Surprise: In interface design, always do the least surprising thing.Rule of Silence: When a program has nothing surprising to say, it should say nothing.Rule of Repair: Repair what you can — but when you must fail, fail noisily and as soon as possible.Rule of Economy: Programmer time is expensive; conserve it in preference to machine time.Rule of Generation: Avoid hand-hacking; write programs to write programs when you can.Rule of Optimization: Prototype before polishing. Get it working before you optimize it.Rule of Diversity: Distrust all claims for one true way.Rule of Extensibility: Design for the future, because it will be here sooner than you think.The Unix Philosophy in One LessonApplying the Unix PhilosophyAttitude Matters Too HistoryOrigins and History of Unix, 1969-1995Genesis: 1969–1971Exodus: 1971–1980TCP/IP and the Unix Wars: 1980-1990Blows against the Empire: 1991-1995Origins and History of the Hackers, 1961-1995At Play in the Groves of Academe: 1961-1980Internet Fusion and the Free Software Movement: 1981-1991Linux and the Pragmatist Reaction: 1991-1998The Open-Source Movement: 1998 and OnwardThe Lessons of Unix History ContrastsThe Elements of Operating-System StyleWhat Is the Operating System’s Unifying Idea?Multitasking CapabilityCooperating ProcessesInternal BoundariesFile Attributes and Record StructuresBinary File FormatsPreferred User Interface StyleIntended AudienceEntry Barriers to DevelopmentOperating-System ComparisonsVMSMacOSOS/2Windows NTBeOSMVSVM/CMSLinuxWhat Goes Around, Comes AroundII. Design ModularityEncapsulation and Optimal Module SizeCompactness and OrthogonalityCompactnessOrthogonalityThe SPOT RuleCompactness and the Strong Single CenterThe Value of DetachmentSoftware Is a Many-Layered ThingTop-Down versus Bottom-UpGlue LayersCase Study: C Considered as Thin GlueLibrariesCase Study: GIMP PluginsUnix and Object-Oriented LanguagesCoding for Modularity TextualityThe Importance of Being TextualCase Study: Unix Password File FormatCase Study: .newsrc FormatCase Study: The PNG Graphics File FormatData File MetaformatsDSV StyleRFC 822 FormatCookie-Jar FormatRecord-Jar FormatXMLWindows INI FormatUnix Textual File Format ConventionsThe Pros and Cons of File CompressionApplication Protocol DesignCase Study: SMTP, the Simple Mail Transfer ProtocolCase Study: POP3, the Post Office ProtocolCase Study: IMAP, the Internet Message Access ProtocolApplication Protocol MetaformatsThe Classical Internet Application MetaprotocolHTTP as a Universal Application ProtocolBEEP: Blocks Extensible Exchange ProtocolXML-RPC, SOAP, and Jabber TransparencyStudying CasesCase Study: audacityCase Study: fetchmail’s -v optionCase Study: GCCCase Study: kmailCase Study: SNGCase Study: The Terminfo DatabaseCase Study: Freeciv Data FilesDesigning for Transparency and DiscoverabilityThe Zen of TransparencyCoding for Transparency and DiscoverabilityTransparency and Avoiding OverprotectivenessTransparency and Editable RepresentationsTransparency, Fault Diagnosis, and Fault RecoveryDesigning for Maintainability MultiprogrammingSeparating Complexity Control from Performance TuningTaxonomy of Unix IPC MethodsHanding off Tasks to Specialist ProgramsPipes, Redirection, and FiltersWrappersSecurity Wrappers and Bernstein ChainingSlave ProcessesPeer-to-Peer Inter-Process CommunicationProblems and Methods to AvoidObsolescent Unix IPC MethodsRemote Procedure CallsThreads — Threat or Menace?Process Partitioning at the Design Level MinilanguagesUnderstanding the Taxonomy of LanguagesApplying MinilanguagesCase Study: sngCase Study: Regular ExpressionsCase Study: GladeCase Study: m4Case Study: XSLTCase Study: The Documenter’s Workbench ToolsCase Study: fetchmail Run-Control SyntaxCase Study: awkCase Study: PostScriptCase Study: bc and dcCase Study: Emacs LispCase Study: JavaScriptDesigning MinilanguagesChoosing the Right Complexity LevelExtending and Embedding LanguagesWriting a Custom GrammarMacros — Beware!Language or Application Protocol? GenerationData-Driven ProgrammingCase Study: asciiCase Study: Statistical Spam FilteringCase Study: Metaclass Hacking in fetchmailconfAd-hoc Code GenerationCase Study: Generating Code for the ascii DisplaysCase Study: Generating HTML Code for a Tabular List ConfigurationWhat Should Be Configurable?Where Configurations LiveRun-Control FilesCase Study: The .netrc FilePortability to Other Operating SystemsEnvironment VariablesSystem Environment VariablesUser Environment VariablesWhen to Use Environment VariablesPortability to Other Operating SystemsCommand-Line OptionsThe -a to -z of Command-Line OptionsPortability to Other Operating SystemsHow to Choose among the MethodsCase Study: fetchmailCase Study: The XFree86 ServerOn Breaking These Rules InterfacesApplying the Rule of Least SurpriseHistory of Interface Design on UnixEvaluating Interface DesignsTradeoffs between CLI and Visual InterfacesCase Study: Two Ways to Write a Calculator ProgramTransparency, Expressiveness, and ConfigurabilityUnix Interface Design PatternsThe Filter PatternThe Cantrip PatternThe Source PatternThe Sink PatternThe Compiler PatternThe ed patternThe Roguelike PatternThe ‘Separated Engine and Interface’ PatternThe CLI Server PatternLanguage-Based Interface PatternsApplying Unix Interface-Design PatternsThe Polyvalent-Program PatternThe Web Browser as a Universal Front EndSilence Is Golden OptimizationDon’t Just Do Something, Stand There!Measure before OptimizingNonlocality Considered HarmfulThroughput vs. LatencyBatching OperationsOverlapping OperationsCaching Operation Results ComplexitySpeaking of ComplexityThe Three Sources of ComplexityTradeoffs between Interface and Implementation ComplexityEssential, Optional, and Accidental ComplexityMapping ComplexityWhen Simplicity Is Not EnoughA Tale of Five EditorsedviSamEmacsWilyThe Right Size for an EditorIdentifying the Complexity ProblemsCompromise Doesn’t WorkIs Emacs an Argument against the Unix Tradition?The Right Size of SoftwareIII. Implementation LanguagesUnix’s Cornucopia of LanguagesWhy Not C?Interpreted Languages and Mixed StrategiesLanguage EvaluationsCC++ShellPerlTclPythonJavaEmacs LispTrends for the FutureChoosing an X Toolkit ToolsA Developer-Friendly Operating SystemChoosing an EditorUseful Things to Know about viUseful Things to Know about EmacsThe Antireligious Choice: Using BothSpecial-Purpose Code Generatorsyacc and lexCase Study: Glademake: Automating Your RecipesBasic Theory of makemake in Non-C/C++ DevelopmentUtility ProductionsGenerating MakefilesVersion-Control SystemsWhy Version Control?Version Control by HandAutomated Version ControlUnix Tools for Version ControlRuntime DebuggingProfilingCombining Tools with EmacsEmacs and makeEmacs and Runtime DebuggingEmacs and Version ControlEmacs and ProfilingLike an IDE, Only Better ReuseThe Tale of J. Random NewbieTransparency as the Key to ReuseFrom Reuse to Open SourceThe Best Things in Life Are OpenWhere to Look?Issues in Using Open-Source SoftwareLicensing IssuesWhat Qualifies as Open SourceStandard Open-Source LicensesWhen You Need a LawyerIV. Community PortabilityEvolution of CEarly History of CC StandardsUnix StandardsStandards and the Unix WarsThe Ghost at the Victory BanquetUnix Standards in the Open-Source WorldIETF and the RFC Standards ProcessSpecifications as DNA, Code as RNAProgramming for PortabilityPortability and Choice of LanguageAvoiding System DependenciesTools for PortabilityInternationalizationPortability, Open Standards, and Open Source DocumentationDocumentation ConceptsThe Unix StyleThe Large-Document BiasCultural StyleThe Zoo of Unix Documentation Formatstroff and the Documenter’s Workbench ToolsTeXTexinfoPODHTMLDocBookThe Present Chaos and a Possible Way OutDocBookDocument Type DefinitionsOther DTDsThe DocBook ToolchainMigration ToolsEditing ToolsRelated Standards and PracticesSGMLXML-DocBook ReferencesBest Practices for Writing Unix Documentation Open SourceUnix and Open SourceBest Practices for Working with Open-Source DevelopersGood Patching PracticeGood Project- and Archive-Naming PracticeGood Development PracticeGood Distribution-Making PracticeGood Communication PracticeThe Logic of Licenses: How to Pick OneWhy You Should Use a Standard LicenseVarieties of Open-Source LicensingMIT or X Consortium LicenseBSD Classic LicenseArtistic LicenseGeneral Public LicenseMozilla Public License FuturesEssence and Accident in Unix TraditionPlan 9: The Way the Future WasProblems in the Design of UnixA Unix File Is Just a Big Bag of BytesUnix Support for GUIs Is WeakFile Deletion Is ForeverUnix Assumes a Static File SystemThe Design of Job Control Was Badly BotchedThe Unix API Doesn’t Use Exceptionsioctl2 and fcntl2 Are an EmbarrassmentThe Unix Security Model May Be Too PrimitiveUnix Has Too Many Different Kinds of NamesFile Systems Might Be Considered HarmfulTowards a Global Internet Address SpaceProblems in the Environment of UnixProblems in the Culture of UnixReasons to BelieveA. Glossary of AbbreviationsB. ReferencesC. ContributorsD. Rootless RootEditor’s IntroductionMaster Foo and the Ten Thousand LinesMaster Foo and the Script KiddieMaster Foo Discourses on the Two PathsMaster Foo and the MethodologistMaster Foo Discourses on the Graphical User InterfaceMaster Foo and the Unix ZealotMaster Foo Discourses on the Unix-NatureMaster Foo and the End UserList of Figures 2.1. The PDP-7.3.1. Schematic history of timesharing.4.1. Qualitative plot of defect count and density vs. module size.4.2. Caller/callee relationships in GIMP with a plugin loaded.6.1. Screen shot of audacity.6.2. Screen shot of kmail.6.3. Main window of a Freeciv game.8.1. Taxonomy of languages.11.1. The xcalc GUI.11.2. Screen shot of the original Rogue game.11.3. The Xcdroast GUI.11.4. Caller/callee relationships in a polyvalent program.13.1. Sources and kinds of complexity.18.1. Processing structural documents.18.2. Present-day XML-DocBook toolchain.18.3. Future XML-DocBook toolchain with FOP.List of Tables 8.1. Regular-expression examples.8.2. Introduction to regular-expression operations.14.1. Language choices.14.2. Summary of X Toolkits.List of Examples 5.1. Password file example.5.2. A .newsrc example.5.3. A fortune file example.5.4. Basic data for three planets in a record-jar format.5.5. An XML example.5.6. A .INI file example.5.7. An SMTP session example.5.8. A POP3 example session.5.9. An IMAP session example.6.1. An example fetchmail -v transcript.6.2. An SNG Example.7.1. The pic2graph pipeline.8.1. Glade Hello, World.8.2. A sample m4 macro.8.3. A sample XSLT program.8.4. Taxonomy of languages — the pic source.8.5. Synthetic example of a fetchmailrc.8.6. RSA implementation using dc.9.1. Example of fetchmailrc syntax.9.2. Python structure dump of a fetchmail configuration.9.3. copy_instance metaclass code.9.4. Calling context for copy_instance.9.5. ascii usage screen.9.6. Desired output format for the star table.9.7. Master form of the star table.10.1. A .netrc example.10.2. X configuration example.18.1. groff1 markup example.18.2. man markup example.19.1. tar archive maker production.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Unix","slug":"Unix","permalink":"http://ipcreator.me/tags/Unix/"}]},{"title":"Things Every Hacker Once Knew","date":"2017-01-20T11:16:06.000Z","path":"2017/01/20/Program/Concepts/things-every-hacker-once-knew/","text":"Things Every Hacker Once Knew by Eric S. Raymond &#x65;&#x73;&#x72;&#64;&#x74;&#104;&#x79;&#114;&#x73;&#117;&#115;&#x2e;&#99;&#111;&#109; One fine day in January 2017 I was reminded of something I had half-noticed a few times over the previous decade. That is, younger hackers don’t know the bit structure of ASCII and the meaning of the odder control characters in it. This is knowledge every fledgling hacker used to absorb through their pores. It’s nobody’s fault this changed; the obsolescence of hardware terminals and the near-obsolescence of the RS-232 protocol is what did it. Tools generate culture; sometimes, when a tool becomes obsolete, a bit of cultural commonality quietly evaporates. It can be difficult to notice that this has happened. This document is a collection of facts about ASCII and related technologies, notably hardware serial terminals and RS-232 and modems. This is lore that was at one time near-universal and is no longer. It’s not likely to be directly useful today - until you trip over some piece of still-functioning technology where it’s relevant (like a GPS puck), or it makes sense of some old-fart war story. Even so, it’s good to know anyway, for cultural-literacy reasons. One thing this collection has that tends to be indefinite in the minds of older hackers is calendar dates. Those of us who lived through all this tend to have remembered order and dependencies but not exact timing; here, I did the research to pin a lot of that down. I’ve noticed that people have a tendency to retrospectively back-date the technologies that interest them, so even if you did live through the era it describes you might get a few surprises from reading this. There are lots of references to Unix in here because I am mainly attempting to educate younger open-source hackers working on Unix-derived systems such as Linux and the BSDs. If those terms mean nothing to you, the rest of this document probably won’t either. Hardware contextNowadays, when two computers talk to each other, it’s usually via TCP/IP over some physical layer you seldom need to care much about. And a “terminal” is actually a “terminal emulator”, a piece of software that manages part of your display and itself speaks TCP/IP. Before ubiquitous TCP/IP and bit-mapped displays things were very different. For most hackers that transition took place within a few years of 1992 - perhaps somewhat earlier if you had access to then-expensive workstation hardware. Before then there were video display terminals - VDTs for short. In the mid-1970s these had displaced an earlier generation of printing terminals derived from really old technology called a “teletype”, which had evolved around 1900 from Victorian telegraph networks. The very earliest versions of Unix in the late 1960s were written for these printing terminals, in particular for the Teletype Model 33 (aka ASR-33); the “tty” that shows up in Unix device names was a then-common abbreviation for “teletype”. In those pre-Internet days computers didn’t talk to each other much, and the way teletypes and terminals talked to computers was a hardware protocol called “RS-232” (or, if you’re being pedantic, “EIA RS-232C”) [1]. Before USB, when people spoke of a “serial” link, they meant RS-232, and sometimes referred to the equipment that spoke it as “serial terminals”. RS-232 had a very long service life; it was developed in the early 1960s, not originally for computer use but as a way for teletypewriters to talk to modems. Though it has passed out of general use and is no longer common knowledge, it’s not quite dead even today.I’ve been simplifying a bit here. There were other things besides RS-232 and serial terminals going on, notably on IBM mainframes. But they’ve left many fewer traces in current technology and its folklore. This is because the lineage of modern Unix passes back through a now-forgotten hardware category called a “minicomputer”, especially minicomputers made by the Digital Equipment Corporation. ASCII, RS-232 and serial terminals were part of the technology cluster around minicomputers - as was, for that matter, Unix itself. Minicomputers were wiped out by workstations and workstations by descendants of the IBM PC, but hackers old enough to remember the minicomputer era (mid-1960s to mid-1980s) tend still to get a bit misty-eyed about the DEC hardware they cut their teeth on. Often, however, nostalgia obscures how very underpowered those machines were. For example: a DEC VAX 11-780 minicomputer in the mid-1980s, used for timesharing and often supporting a dozen simultaneous users, had less than 1/1000 the processing power and less than 1/5000 times as much storage available as a low-end smartphone does in 2017. In fact, until well into the 1980s microcomputers ran slowly enough (and had poor enough RF shielding) that this was common knowledge: you could put an AM radio next to one and get a clue when it was doing something unusual, because either fundamentals or major subharmonics of the clock frequencies were in the range of human audibility. Nothing has run that slowly since the turn of the 21st century. The strange afterlife of the Hayes smartmodemAbout those modems: the word is a portmanteau for “modulator/demodulator”. Modems allowed digital signals to pass over copper phone wires - ridiculously slowly by today’s standards, but that’s how we did our primitive wide-area networking in pre-Internet times. It was not generally known back then that modems had first been invented in the late 1950s for use in military communications, notably the SAGE air-defense network; we just took them for granted. Today modems that speak over copper or optical fiber are embedded invisibly in the Internet access point in your basement; other varieties perform over-the-air signal handling for smartphones and tablets. A variety every hacker used to know about (and most of us owned) was the “outboard” modem, a separate box wired to your computer and your telephone line. Inboard modems (expansion cards for your computer) were also known, but never sold as well because being located inside the case made them vulnerable to RF noise, and the blinkenlights on an outboard were useful for diagnosing problems. Also, most hackers learned to interpret (at least to some extent) modem song - the beeping and whooshing noises the outboards made while attempting to establish a connection. The happy song of a successful connect was identifiably different from various sad songs of synchronization failure. These old-fashioned modems were, by today’s standards, unbelievably slow. Modem speeds increased from 110 bits per second back at the beginning of interactive computing to 56 kilobits per second just before the technology was effectively wiped out by wide-area Internet around the end of the 1990s, which brought in speeds of a megabit per second and more (20 times faster). For the longest stable period of modem technology after 1970, about 1984 to 1991, typical speed was 9600bps. This has left some traces; it’s why surviving serial-protocol equipment tends to default to a speed of 9600bps. There was a line of modems called “Hayes Smartmodems” that could be told to dial a number, or set parameters such as line speed, with command codes sent to the modem over its serial link from the machine. Every hacker used to know the “AT” prefix used for commands and that, for example, ATDT followed by a phone number would dial the number. Other modem manufacturers copied the Hayes command set and variants of it became near universal after 1981. What was not commonly known then is that the “AT” prefix had a helpful special property. That bit sequence (1+0 1000 0010 1+0 0010 1010 1+, where the plus suffix indicates one or more repetitions of the preceding bit) has a shape that makes it as easy as possible for a receiver to recognize it even if the receiver doesn’t know the transmit-line speed; this, in turn, makes it possible to automatically synchronize to that speed [2]. That property is still useful, and thus in 2017 the AT convention has survived in some interesting places. AT commands have been found to perform control functions on 3G and 4G cellular modems used in smartphones. On one widely deployed variety, “AT+QLINUXCMD=” is a prefix that passes commands to an instance of Linux running in firmware on the chip itself (separately from whatever OS might be running visibly on the phone). Preserving core valuesFrom about 1955 to 1975 - before semiconductors - the dominant technology in computer memory used tiny magnetic doughnuts strung on copper wires. The doughnuts were known as “ferrite cores” and main memory thus known as “core memory” or “core”. Unix terminology was formed in the early 1970s, and compounds like “in core” and “core dump” survived into the semiconductor era. Until as late as around 1990 it could still be assumed that every hacker knew from where these terms derived; even microcomputer hackers for which memory had always been semiconductor RAM tended to pick up this folklore rapidly on contact with Unix. After 2000, however, as multiprocessor systems became increasingly common even on desktops, “core” increasingly took on a conflicting meaning as shorthand for “processor core”. In 2017 “core” can still mean either thing, but the reason for the older usage is no longer generally understood and idioms like “in core” may be fading. 36-bit machines and the persistence of octalThere’a a power-of-two size hierarchy in memory units that we now think of as normal - 8 bit bytes, 16 or 32 or 64-bit words. But this did not become effectively universal until after 1983. There was an earlier tradition of designing computer architectures with 36-bit words.There was a time when 36-bit machines loomed large in hacker folklore and some of the basics about them were ubiquitous common knowledge, though cultural memory of this era began to fade in the early 1990s. Two of the best-known 36-bitters were the DEC PDP-10 and the Symbolics 3600 Lisp machine. The cancellation of the PDP-10 in ‘83 proved to be the death knell for this class of machine, though the 3600 fought a rear-guard action for a decade afterwards. Hexadecimal is a natural way to represent raw memory contents on machines with the power-of-two size hierarchy. But octal (base-8) representations of machine words were common on 36-bit machines, related to the fact that a 36-bit word naturally divides into 12 3-bit fields naturally represented as octal. In fact, back then we generally assumed you could tell which of the 32- or 36-bit phyla a machine belonged in by whether you could see digits greater than 7 in a memory dump. Here are a few things every hacker used to know that related to these machines: 36 bits was long enough to represent positive and negative integers to an accuracy of ten decimal digits, as was expected on mechanical calculators of the era. Standardization on 32 bits was unsuccessfully resisted by numerical analysts and people in scientific computing, who really missed that last 4 bits of accuracy. A “character” might be 9 bits on these machines, with 4 packed to a word. Consequently, keyboards designed for them might have both a meta key to assert bit 8 and a now-extinct extra modifier key (usually but not always called “Super”) that asserted bit 9. Sometimes this selected a tier of non-ASCII characters including Greek letters and mathematical symbols. It used also to be generally known that 36-bit architectures explained some unfortunate features of the C language. The original Unix machine, the PDP-7, featured 18-bit words corresponding to half-words on larger 36-bit computers. These were more naturally represented as six octal (3-bit) digits. The immediate ancestor of C was an interpreted language written on the PDP-7 and named B. In it, a numeric literal beginning with 0 was interpreted as octal. The PDP-7’s successor, and the first workhorse Unix machine was the PDP-11 (first shipped in 1970). It had 16-bit words - but, due to some unusual peculiarities of the instruction set, octal made more sense for its machine code as well. C, first implemented on the PDP-11, thus inherited the B octal syntax. And extended it: when an in-string backslash has a following digit, that was expected to lead an octal literal. The Interdata 32, VAX, and other later Unix platforms didn’t have those peculiarities; their opcodes expessed more naturally in hex. But C was never adjusted to prefer hex, and the surprising interpretation of leading 0 wasn’t removed. Because many later languages (Java, Python, etc) copied C’s low-level lexical rules for compatibility reasons, the relatively useless and sometimes dangerous octal syntax besets computing platforms for which three-bit opcode fields are wildly inappropriate, and may never be entirely eradicated [3]. The PDP-11 was so successful that architectures strongly influenced by it (notably, including Intel [4] and ARM microprocessors) eventually took over the world, killing off 36-bit machines. RS232 and its discontentsA TCP/IP link generally behaves like a clean stream of 8-bit bytes (formally, octets). You get your data as fast as the network can run, and error detection/correction is done somewhere down below the layer you can see. RS-232 was not like that. Two devices speaking it had to agree on a common line speed - also on how the byte framing works (the latter is why you’ll see references to “stop bits” in related documentation). Finally, error detection and correction was done in-stream, sort of. RS232 devices almost always spoke ASCII, and used the fact that ASCII only filled 7 bits. The top bit might be, but was not always, used as a parity bit for error detection. If not used, the top bit could carry data. You had to set your equipment at both ends for a specific combination of all of these. After about 1984 anything other than “8N1” - eight bits, no parity, one stop bit - became increasingly rare. Before that, all kinds of weird combinations were in use. Even parity (“E”) was more common than odd (“O”) and 1 stop bit more common than 2, but you could see anything come down a wire. And if you weren’t properly set up for it, all you got was “baud barf” - random 8-bit garbage rather than the character data you were expecting. This, in particular, is one reason the API for the POSIX/Unix terminal interface, termios(3), has a lot of complicated options with no obvious modern-day function. It had to be able to manipulate all these settings, and more. Another consequence was that passing binary data over an RS-232 link wouldn’t work if parity was enabled - the high bits would get clobbered. Other now-forgotten wide-area network protocols reacted even worse, treating in-band characters with 0x80 on as control codes with results ranging from amusing to dire. We had a term, “8-bit clean”, for networks and software that didn’t clobber the 0x80 bit. And we needed that term… Even the RS-232 physical connector varied. Standard RS-232 as defined in 1962 used a roughly D-shaped shell with 25 physical pins (DB-25), way more than the physical protocol actually required (you can support a minimal version with just three wires, and this was actually common). Twenty years later, after the IBM PC-AT introduced it in 1984, most manufacturers switched to using a smaller DB-9 connector (which is technically a DE-9 but almost nobody ever called it that). If you look at a PC with a serial port it is most likely to be a DB-9; confusingly, DB-25 came to be used for printer parallel ports (which originally had a very different connector) before those too were obsolesced by USB and Ethernet. Anybody who worked with this stuff had to keep around a bunch of specialized hardware - gender changers, DB-25-to-DB-9 adapters (and the reverse), breakout boxes, null modems, and other stuff I won’t describe in detail because it’s left no traces in today’s tech. Hackers of a certain age still tend to have these things cluttering their toolboxes or gathering dust in a closet somewhere. The main reason to still care about any of this (other than understanding greybeard war stories) is that some kinds of sensor and control equipment, routers, and IoT devices still speak RS-232, often wrapped inside a USB emulation. The most common devices that do this are probably GPS sensors designed to talk to computers (as opposed to handheld GPSes or car-navigation systems). Because of devices like GPSes, you may still occasionally need to know what an RS-232 “handshake line” is. These were originally used to communicate with modems; a terminal, for example, could change the state of the DTR (Data Terminal Ready) line to indicate that it was ready to receive, initiate, or continue a modem session. Later, handshake lines were used for other equipment-specific kinds of out-of-band signals. The most commonly re-used lines were DCD (data carrier detect) and RI (Ring Indicator). Three-wire versions of RS-232 omitted these handshake lines entirely. A chronic source of frustration was equipment at one end of your link that failed to supply an out-of-band signal that the equipment at the other end needed. The modern version of this is GPSes that fail to supply their 1PPS (a high-precision top-of-second pulse) over one of the handshake lines. Another significant problem was that an RS-232 device not actually sending data was undetectable without analog-level monitoring equipment. You couldn’t tell a working but silent device from one that had come unplugged or suffered a connection fault in its wiring. This caused no end of complications when troubleshooting and is a major reason USB was able to displace RS-232 after 1994.A trap for the unwary that opened up after about the year 2000 is that peripheral connectors labeled RS232 could have one of two different sets of voltage levels. If they’re pins or sockets in a DB9 or DB25 shell, the voltage swing between 1 and 0 bits can be as much as 50 volts, and is usually about 26. Bare connectors on a circuit board, or chip pins, increasingly came to use what’s called “TTL serial” - same signalling with a swing of 3.3 or (less often) 5 volts. You can’t wire standard RS232 to TTL serial directly; the link needs a device called a “level shifter”. If you connect without one, components on the TTL side will get fried. RS-232 passed out of common knowledge in the mid- to late 1990s, but didn’t finally disappear from general-purpose computers until around 2010. Standard RS-232 is still widely used on industrial controllers and in some niche applications, including point-of-sale systems and diagnostic consoles on commercial-grade routers. The TTL serial variant is often used on maker devices. UUCP and BBSes, the forgotten pre-InternetsEvery hacker over a certain age remembers either UUCP or the BBS scene. Many participated in both. In those days access to to the “real” net (ARPANET, which became Internet) was difficult if you weren’t affiliated with one of a select group of federal agencies, military contractors, or university research labs. So we made do with what we had, which was modems and the telephone network. UUCP stands for Unix to Unix Copy Program. Between its escape from Bell Labs in 1979 and the mass-market Internet explosion of the mid-1990s, it provided slow but very low-cost networking among Unix sites using modems and the phone network. UUCP was a store-and-forward system originally intended for propagating software updates, but its major uses rapidly became email and a thing called USENET (launched 1981) that was the ur-ancestor of Stack Overflow and other modern web fora. It supported topic groups for messages which, propagated from their point of origin through UUCP, would eventually flood to the whole network. In part, UUCP and USENET were a hack around the two-tier rate structure that then existed for phone calls, with “local” being flat-rate monthly and “long-distance” being expensively metered by the minute. UUCP traffic could be relayed across long distances by local hops.A direct descendant of USENET still exists, as Google Groups [5], but was much more central to the hacker culture before cheap Internet. Open source as we now know it germinated in USENET groups dedicated to sharing source code. Several conventions still in use today, like having project metadata files named README and NEWS and INSTALL, originated there in the early 1980s. Two key dates in USENET history were universally known. One was the Great Renaming in 1987, when the name hierarchy of USENET topic groups was reorganized. The other was the “September that never ended” in 1993, when the AOL commercial timesharing services gave its users access to USENET. The resulting vast flood of newbies proved difficult to acculturate. UUCP explains a quirk you may run across in old mailing-list archives: the bang-path address. UUCP links were point-to-point and you had to actually specify the route of your mail through the UUCP network; this led to people publishing addresses of the form “…!bigsite!foovax!barbox!user”, presuming that people who wanted to reach them would know how to reach bigsite. UUCP was notoriously difficult to configure, enough so that people who knew how often put that skill on their CVs in the justified expectation that it could land them a job. Meanwhile, in the microcomputer world, a different kind of store-and-forward evolved - the BBS (Bulletin-Board System). This was software running on a computer (after 1991 usually an MS-DOS machine) with one (or, rarely, more) attached modems that could accept incoming phone calls. Users (typically, just one user at a time!) would access the BBS using a their own modem and a terminal program; the BBS software would allow them to leave messages for each other, upload and download files, and sometimes play games. The first BBS, patterned after the community notice-board in a supermarket, was fielded in Chicago in 1978. Over the next eighteen years over a hundred thousand BBSes flashed in and out of existence, typically operated out of the sysop’s bedroom or garage with a spare computer. From 1984 the BBS culture evolved a primitive form of internetworking called “FidoNet” that supported cross-site email and a forum system broadly resembling USENET. During a very brief period after 1990, just before mass-market Internet, software with BBS-like capabilities but supporting multiple simultaneous modem users (and often offeing USENET access) got written for low-cost Unix systems. The end-stage BBSes, when they survived, moved to the Web and dropped modem access. The history of cellar.org chronicles this period. A handful of BBSes are still run by nostalgicists, and some artifacts from the culture are still preserved. But, like the UUCP network, the BBS culture as a whole collapsed when inexpensive Internet became widely available. Almost the only cultural memory of BBSes is around a family of file-transfer protocols - XMODEM, YMODEM, and ZMODEM - developed and used on BBSes. For hackers of that day who did not cut their teeth on minicomputers with native TCP/IP, these were a first introduction to concepts like packetization, error detection, and retransmission. To this day, hardware from at least one commercial router vendor accepts software patches by XMODEM upload through a serial port. Also roughly contemporaneous with USENET and the BBS culture, and also destroyed or absorbed by cheap Internet, were some commercial timesharing services supporting dialup access by modem, of which the best known were AOL (America Online) CompuServe, and GEnie. These provided BBS-like facilities. Every hacker knew of these, though few used them. They have left no traces at all in today’s hacker culture.Terminal confusion The software terminal emulators on modern Unix systems are the near-end - and probably final - manifestations of a long and rather confused history. It began with early displays sometimes called “glass TTYs” because they emulated teletypes - but less expensively, because they didn’t require consumables like paper. The phrase “dumb terminal” is equivalent. The first of these was shipped in 1969. The best-remembered of them is probably still the ADM-3 from 1975. The very earliest VDTs, like the ASR-33, could form only upper-case letters. An interesting hangover from that these devices was that, even though most VDTs made after 1975 could form lower-case letters, for many years afterwards Unix and Linux responded to an all-upper-case login by switching to an mode which upcased all input. If you created an account with an all-upper-case login name and a mixed-case password, hilarity ensued. If the password was also upper-case the hilarity was less desparate but still confusing for the user.The classic “smart terminal” VDT designs that have left a mark on later computing appeared during a relatively short period beginning in 1975. Devices like the Lear-Siegler ADM-3A (1976) and the DEC VT-100 (1978) inherited the 80-character line width of punched cards (longer than the 72-character line length of teletypes) and supported as many lines as could fit on an approximately 4:3 screen; they are the reason your software terminal emulator has a 24x80 or 25x80 default size. These terminals were called “smart” because they could interpret control codes to do things like addressing the cursor to any point on the screen in order to produce truly 2-dimensional displays [6]. The ability to do bold, underline or reverse-video highlighting also rapidly became common. Colored text and backgrounds, however, only became available a few years before VDTs were obsolesced; before that displays were monochromatic. Some had crude, low-resolution dot graphics; a few types supported black-and-white vector graphics.Early VDTs used a crazy variety of control codes. One of the principal relics of this era is the Unix terminfo database, which tracked these codes so terminal-using applications could do abstracted operations like “move the cursor” without being restricted to working with just one terminal type. The curses(3) library still used with software terminal emulators was originally intended to make this sort of thing easier. After 1979 there was an ANSI standard for terminal control codes, based on the DEC VT-100 (being supported in the IBM PC’s original screen driver gave it a boost) [7]. By the early 1990s ANSI conformance was close to universal in VDTs, which is why that’s what your software terminal emulator does. This whole technology category was rapidly wiped out in general-purpose computing, like dinosaurs after the Alvarez strike, when bit-mapped color displays on personal computers that could match the dot pitch of a monochrome VDT became relatively inexpensive, around 1992. The legacy VDT hardware lingered longest in dedicated point-of-sale systems, remaining not uncommon until as late as 2010 or so.It’s not true, as is sometime suggested, that heritage from the VDT era explains the Unix command line - that actually predated VDTs, going back to the last generation of printing terminals in the late 1960s and early 1970s. Every hacker once knew that this is why we often speak of of “printing” output when we mean sending it to standard output that is normally connected to a terminal emulator.What the VDT era does explain is some of our heritage games (see next section) and a few surviving utility programs like vi(1), top(1) and mutt(1). These are what advanced visual interfaces looked like in the VDT era, before bitmapped displays. Games before GUIsBefore bit-mapped color displays became common and made graphics-intensive games the norm, there was a vigorous tradition of games that required only textual interfaces or the character-cell graphics on a VDT. Every hacker once knew what the phrase “You are in a maze of twisty little passages, all alike” meant, and often used variants about confusing situations in real life (For example, “You are in a maze of twisty little technical standards, all different”). It was from the very first dungeon-crawling adventure game, Colossal Cave Adventure (1976). People who knew this game from its beginnings often thought of it as ADVENT, after its 6-character filename on the PDP-10 where it first ran. ADVENT had a direct successor that was even more popular - Zork, first released in 1979 by hackers at MIT and later successfully commercialized. This game is why every hacker once knew that a zorkmid was the currency of the Great Underground Empire, and that if you wander around in dark places without your lantern lit you might be eaten by a grue. There was a another family of games that took a different, more visual approach to dungeon-crawling. They are generally called “roguelikes”, after one of the earliest widely-distributed games in this group, Rogue from 1980. They featured top-down, maplike views of dungeon levels through which the player would wander battling monsters and seeking treasure. The most widely played games in this group were Hack (1982) and Nethack (1987). Nethack is a notable for having been one of the earliest programs in which the development group was consciously organized as a distributed collaboration over the Internet; at the time, this was a sufficiently novel idea to be advertised in the project’s name. These games gradually passed out of universal common knowledge after the mid-1990s, but they retain devoted minority followings today. Their fans accurately point out that the primitive state of interface design encouraged concentration on plot and story values, leading to a surprisingly rich imaginative experience. ASCIIASCII, the American Standard Code for Information Interchange, evolved in the early 1960s out of a family of character codes used on teletypes.ASCII, unlike a lot of other early character encodings, is likely to live forever - because by design the low 127 code points of Unicode are ASCII. If you know what UTF-8 is (and you should) every ASCII file is correct UTF-8 as well.The following table describes ASCII-1967, the version in use today.Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex Dec Hex 0 00 NUL 16 10 DLE 32 20 48 30 0 64 40 @ 80 50 P 96 60 ` 112 70 p 1 01 SOH 17 11 DC1 33 21 ! 49 31 1 65 41 A 81 51 Q 97 61 a 113 71 q 2 02 STX 18 12 DC2 34 22 “ 50 32 2 66 42 B 82 52 R 98 62 b 114 72 r 3 03 ETX 19 13 DC3 35 23 # 51 33 3 67 43 C 83 53 S 99 63 c 115 73 s 4 04 EOT 20 14 DC4 36 24 $ 52 34 4 68 44 D 84 54 T 100 64 d 116 74 t 5 05 ENQ 21 15 NAK 37 25 % 53 35 5 69 45 E 85 55 U 101 65 e 117 75 u 6 06 ACK 22 16 SYN 38 26 &amp; 54 36 6 70 46 F 86 56 V 102 66 f 118 76 v 7 07 BEL 23 17 ETB 39 27 ‘ 55 37 7 71 47 G 87 57 W 103 67 g 119 77 w 8 08 BS 24 18 CAN 40 28 ( 56 38 8 72 48 H 88 58 X 104 68 h 120 78 x 9 09 HT 25 19 EM 41 29 ) 57 39 9 73 49 I 89 59 Y 105 69 i 121 79 y 10 0A LF 26 1A SUB 42 2A * 58 3A : 74 4A J 90 5A Z 106 6A j 122 7A z 11 0B VT 27 1B ESC 43 2B + 59 3B ; 75 4B K 91 5B [ 107 6B k 123 7B { 12 0C FF 28 1C FS 44 2C , 60 3C &lt; 76 4C L 92 5C \\ 108 6C l 124 7C | 13 0D CR 29 1D GS 45 2D - 61 3D = 77 4D M 93 5D ] 109 6D m 125 7D } 14 0E SO 30 1E RS 46 2E . 62 3E &gt; 78 4E N 94 5E ^ 110 6E n 126 7E ~ 15 0F SI 31 1F US 47 2F / 63 3F ? 79 4F O 95 5F _ 111 6F o 127 7F DEL It used to be common knowledge that the original 1963 ASCII had been sightly different. It lacked tilde and vertical bar; 5E was an up-arrow rather than a caret, and 5F was a left arrow rather than underscore. Some early adopters (notably DEC) held to the 1963 version.If you learned your chops after 1990 or so, the mysterious part of this is likely the control characters, code points 0-31. You probably know that C uses NUL as a string terminator. Others, notably LF = Line Feed and HT = Horizontal Tab, show up in plain text. But what about the rest? Many of these are remnants from teletype protocols that have either been dead for a very long time or, if still live, are completely unknown in computing circles. A few had conventional meanings that were half-forgotten even before Internet times. A very few are still used in binary data protocols today. Here’s a tour of the meanings these had in older computing, or retain today. If you feel an urge to send me more, remember that the emphasis here is on what was common knowledge back in the day. If I don’t know it now, we probably didn’t generally know it then. NUL (Null)Survives as the string terminator in C. SOH (Start of Heading)Rarely used (as Ctrl-A) as a section divider in otherwise textual formats. Some versions of Unix mailbox format used it as a message divider. One very old version-control system (SCCS) did something similar. STX (Start of Text), ETX (End of Text)Very rarely used as packet or control-sequence delimiters. You will probably never see this, and the only place I’ve ever seen it was on a non-Unix OS in the early 1980s. ETX is Ctrl-C, which is a SIGINT interrupt character on Unix systems, but that has nothing to do with its ASCII meaning per se and probably derives from abbreviating the word “Cancel”. EOT (End of Transmission)As Ctrl-D, the way you type “End of file” to a Unix terminal. ENQ (Enquiry)In the days of hardware serial terminals, there was a convention that if a computer sent ENQ to a terminal, it should reply with terminal type identification. While this was not universal, it at least gave computers a fighting chance of autoconfiguring what capabilities it could assume the terminal to have. ACK (Acknowledge)It used to be common for wire protocols written in ASCII to use ENQ/ACK as a handshake, sometimes with NAK as a failure indication. Hackers used to use ACK in speech as “I hear you” and were a bit put out when this convention was disrupted in the 1980s by Bill The Cat’s “Ack! Thppt!” BEL (Bell)Make the bell ring on the teletype - an attention signal. This often worked on VDTs as well, but is no longer reliably the default on software terminal emulators. Some map it to a visual indication like flashing the title bar. BS (Backspace)Still does what it says on the tin, though there has been some historical confusion over whether the backspace key on a keyboard should behave like BS (nondestructive cursor move) or DEL (backspace and delete). Never used in textual data protocols. HT (Horizontal tab)Still does what it says on the tin. Sometimes used as a field separator in Unix textual file formats, but this is now old-fashioned and declining in usage. LF (Line Feed)The Unix textual end-of-line. Printing terminals interpreted it as “scroll down one line”; the Unix tty driver would normally wedge in a CR right after it on output. VT (Vertical Tab)In the days of printing terminals this often caused them to scroll down a configurable number of lines. VDTs had any number of possible behaviors; at least some pre-ANSI ones interpreted VT as “scroll up one line”. The only reason anybody remembers this one at all is that it persisted in Unix definitions of what a whitespace character is, even though it’s now extinct in the wild. FF (Form Feed)Eject the current page from your printing terminal. Many VDTs interpreted this as a “clear screen” instruction. Software terminal emulators sometimes still do. CR (Carriage Return)It is now possible that the reader has never seen a typewriter, so this needs explanation: “carriage return” is the operation of moving your print head or cursor to the left margin. Windows, other non-Unix operating systems, and some Internet protocols (such as SMTP) tend to use CR-LF as a line terminator, rather than bare LF. Pre-Unix MacOS used a bare CR. SO (Shift Out), SI (Shift In)Escapes to and from an alternate character set. Unix software used to emit them to drive pre-ANSI VDTs that interpreted them that way, but native Unix usage is rare to nonexistent. DLE (Data Link Escape)Sometimes used as a packet-framing character in binary protocols. That is, a packet starts with a DLE, ends with a DLE, and if one of the interior data bytes matches DLE it is doubled. DC[1234] (Device Control [1234])Never to my knowledge used specially after teletypes. However: there was a common software flow-control protocol, used over ASCII but separate from it, in which XOFF (DC3) was used as a request to pause transmission and XON (DC1) was used as a request to resume transmission. As Ctrl-S and Ctrl-Q these were implemented in the Unix terminal driver and long outlived their origin in the Model 33 Teletype. And not just Unix; this was implemented in CP/M and DOS, too. NAK (Negative Acknowledge)Never to my knowledge used specially after teletypes, but it would have been unsurprising to anybody if a device-control protocol used it as a negative response to ENQ. SYN (Synchronous Idle)Never to my knowledge used specially after teletypes. Be careful not to confuse this with the SYN (synchronization) packet used in TCP/IP’s SYN SYN-ACK initialization sequence. ETB (End of Transmission Block)Never to my knowledge used specially after teletypes. CAN (Cancel), EM (End of Medium)Never to my knowledge used specially after teletypes. SUB (Substitute)DOS and Windows use Ctrl-Z (SUB) as an end-of-file character; this is unrelated to its ASCII meaning. It was common knowledge then that this use of ^Z had been inherited from a now largely forgotten earlier OS called CP/M (1974), and into CP/M from earlier DEC minicomputer OSes such as RSX-11 (1972). ESC (Escape)Still commonly used as a control-sequence introducer. This usage is especially associated with the control sequences recognized by VT100 and ANSI-standard VDTs, and today by essentially all software terminal emulators[FGRU]S ({Field|Group|Record|Unit} Separator)Never to my knowledge used specially after teletypes. FS, as Ctrl-\\, sends SIGQUIT under some Unixes, but this has nothing to do with ASCII. Ctrl-] (GS) is the exit character from telnet, but this also has nothing to do with its ASCII meaning. DEL (Delete)Usually an input character meaning “backspace and delete”. Under older Unix variants, sometimes a SIGINT interrupt character.Not all of these were so well known that any hacker could instantly map from mnemonic to binary, or vice-versa. The well-known set was roughly NUL, BEL, BS, HT, LF, FF, CR, ESC, and DEL.There are a few other bits of ASCII lore worth keeping in mind…The Control modifier on your keyboard basically clears the top three bits of whatever character you type, leaving the bottom five and mapping it to the 0..31 range. So, for example, Ctrl-SPACE, Ctrl-@, and Ctrl-` all mean the same thing: NUL.A Meta or Alt key on a VDT added 128 to the ASCII keycode for whatever it’s modifying (probably - on a few machines with peculiar word lengths they did different things). Software terminal emulators have more variable behavior; many of them now simply insert an ESC before the modified key, which Emacs treats as equivalent to adding 128.Very old keyboards used to do Shift just by toggling the 32 or 16 bit, depending on the key; this is why the relationship between small and capital letters in ASCII is so regular, and the relationship between numbers and symbols, and some pairs of symbols, is sort of regular if you squint at it. The ASR-33, which was an all-uppercase terminal, even let you generate some punctuation characters it didn’t have keys for by shifting the 16 bit; thus, for example, Shift-K (0x4B) became a [ (0x5B) Key datesThese are dates that every hacker knew were important at the time, or shortly afterwards. I’ve tried to concentrate on milestones for which the date - or the milestone itself - seems to have later passed out of folk memory.1961MIT takes delivery of a PDP-1. The first recognizable ancestor of the hacker culture of today rapidly coalesces around it.1969Ken Thompson begins work on what will become Unix. First commercial VDT ships; it’s a glass TTY. First packets exchanged on the ARPANET, the direct ancestor of today’s Internet.1970DEC PDP-11 first ships; architectural descendants of this machine, including later Intel microprocessors, will come to dominate computing.1973Interdata 32 ships; the long 32-bit era begins [8]. Unix Edition 5 (not yet on the Interdata) escapes Bell Labs to take root at a number of educational institutions. The XEROX Alto pioneers the “workstation” - a networked personal computer with a high-resolution display and a mouse.1975First Altair 8800 ships. Beginning of heroic age of microcomputers. First 24x80 and 25x80 “smart” (addressable-cursor) VDTs. ARPANET declared “operational”, begins to spread to major universities.1976“Lions’ Commentary on UNIX 6th Edition, with Source Code” released. First look into the Unix kernel source for most hackers, and was a huge deal in those pre-open-source days.1977Unix ported to the Interdata. First version with a kernel written largely in C rather than machine-dependent assembler.1978First BBS launched - CBBS, in Chicago.1981First IBM PC ships. End of the heroic age of micros. TCP/IP is implemented on a VAX-11/780 under 4.1BSD Unix; ARPANET and Unix cultures begin to merge.1982Sun Microsystems founded. Era of commercial Unix workstations begins.1983PDP-10 canceled. This is effectively the end of 36-bit architectures anywhere outside of deep mainframe country, though Symbolics Lisp machines hold out a while longer. ARPANET, undergoing some significant technical changes, becomes Internet.1984AT&amp;T begins a largely botched attempt to commercialize Unix, clamping down on access to source code. In the BBS world, FidoNet is invented.1985RMS published GNU Manifesto. This is also roughly the year the C language became the dominant lingua franca of both systems and applications programming, eventually displacing earlier compiled language so completely that they are almost forgotten.1986Intel 386 ships; end of the line for 8- and 16-bit PCs. Consumer-grade hardware in this class wouldn’t be generally available until around 1989, but after that would rapidly surpass earlier 32-bit minicomputers in and workstations capability.1991Linux and the World Wide Web are (separately) launched.1992Bit-mapped color displays with a dot pitch matching that of a monochrome VDT (and a matching ability to display crisp text at 80x25) ship on consumer-grade PCs. Bottom falls out of the VDT market.1993Linux gets TCP/IP capability, moves from hobbyist’s toy to serious OS. America OnLine offers USENET access to its uses; “September That Never Ended” begins.1994Mass-market Internet takes off in the U.S. USB promulgated.1995-1996Peak years of UUCP/USENET and the BBS culture, then collapse under pressure from mass-market Internet.1997I first give the “Cathedral and Bazaar” talk.1999Peak year of the dot-com bubble. End of workstation era: Market for Suns and other proprietary Unix workstations collapses under pressure from Linux running on PCs.2005Major manufacturers cease production of cathode-ray tubes in favor of flat-panel displays. Flat-panels have been ubiquitous on new hardware since about 2003. There is a brief window until about 2007 during which high-end CRTs no longer in production still exceed the resolution of flat-panel displays and are still sought after. Also in 2005, AOL drops USENET support and Endless September ends.2007-200864-bit transition in mass market PCs. The 32-bit era ends. The first smartphones ship. Request to contributorsA lot of people reading this have been seized by the urge to send me some bit of lore or trivia for inclusion. Thank you, but bear in mind that the most important choice is what to leave out. Here are some guidelines: I’m trying to describe common knowledge at the time. That means not every bit of fascinating but obscure trivia belongs here.Anything from a tech generation before early minis - in particular the era of mainframes, punched cards, and paper tape - is out of scope. I gotta draw the line somewhere, and it’s there. Stories about isolated survivals of old tech today are not interesting if the tech wasn’t once common knowledge.Please do not send me timeline entries for dates which you think are important unless you think the date has been generally been forgotten, or is in serious danger of same. Supporting this workIf you enjoyed this, please contribute at my Patreon page so I won’t be forced to get a $DAYJOB and no longer have time to think up or write things like this document. I work on a lot of more serious projects too, including critical network infrastructure. So give generously; the civilization you save could be your own. Related ReadingHow To Become A HackerThe Lost Art of C Structure Packing Change history1.0: 2017-01-26Initial version.1.1: 2017-01-27Pin down the date DB-9 came in. Added a minor section on the persistence of octal. More on the afterlife of RS-232.1.2: 2017-01-29More about the persistence of octal. Mention current-loop ASR-33s. 36-bit machines and their lingering influence. Explain ASCII shift. A bit more about ASCII-1963. Some error correction.1.3: 2017-01-30Added “Key dates” and “Request to contributors”.1.4: 2017-02-03The curious survival of the Hayes AT command set.1.5: 2017-02-04TTL in serial and maker devices. The AT Hayes prefix explained. UUCP and long distance rates. Reference to space-cadet keyboard removed, as it turned out to ship a 32-bit word. Improved description of ASCII shift.1.6: 2017-02-08How VDTs explain some heritage programs, and how bitmapped displays eventually obsolesced them. Explain why the ADM-3 was called “dumb” even though it was smart.1.7: 2017-02-09The BBS subculture. XMODEM/YMODEM/ZMODEM. Commercial timesharing. Two dates in USENET history.1.8: 2017-02-14Heritage games. The legacy of all-uppercase terminals. Where README came from. What “core” is. The ARPANET. Monitoring your computer with a radio. Actually, there was an even older style of tty interface called “current loop” that the ASR-33 originally used; in the 1970s dual-mode ASR-33s that could also speak RS-232 began to ship, and RS-232 eventually replaced current loop entirely. A full explanation of the magic of the AT prefix can be found at http://esr.ibiblio.org/?p=7333&amp;cpage=1#comment-1802568 Python 3 and Perl 6 have at least gotten rid of the dangerous leading-0-for-octal syntax, but Go kept it Early Intel microprocessors weren’t much like the 11, but the 80286 and later converged with it in important ways. The old free-floating USENET still exists too, but Google Groups is where you can find what has been preserved of the historical USENET archives. Confusingly, the ADM-3A (which could address any screen cell) was described in marketing copy as a “dumb” terminal, not a “smart” one. This is because there was a rival definition of “smart” as capable of doing local editing of the screen without involving the remote computer, like an IBM 3270. But since minicomputers never used that capability this definition was never live in the Unix world, and has mostly faded out of use. It was not commonly known that the VT100 was designed to fit a 1976 stanfard called ECMA-48; ANSI simply adopted it. There were a few 32-bit minis before the Interdata, but they seem to have been designed for real-time or other non-timesharing uses.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"Teach Yourself Programming in Ten Years","date":"2017-01-20T09:22:06.000Z","path":"2017/01/20/Program/Concepts/teach-yourself-programming-in-ten-years/","text":"Teach Yourself Programming in Ten YearsPeter Norvig Why is everyone in such a rush?Walk into any bookstore, and you’ll see how to Teach Yourself Java in 24 Hours alongside endless variations offering to teach C, SQL, Ruby, Algorithms, and so on in a few days or hours. The Amazon advanced search for [title: teach, yourself, hours, since: 2000 and found 512 such books. Of the top ten, nine are programming books (the other is about bookkeeping). Similar results come from replacing “teach yourself” with “learn” or “hours” with “days.” The conclusion is that either people are in a big rush to learn about programming, or that programming is somehow fabulously easier to learn than anything else. Felleisen et al. give a nod to this trend in their book How to Design Programs, when they say “Bad programming is easy. Idiots can learn it in 21 days, even if they are dummies.” The Abtruse Goose comic also had their take. Let’s analyze what a title like Teach Yourself C++ in 24 Hours could mean: Teach Yourself: In 24 hours you won’t have time to write several significant programs, and learn from your successes and failures with them. You won’t have time to work with an experienced programmer and understand what it is like to live in a C++ environment. In short, you won’t have time to learn much. So the book can only be talking about a superficial familiarity, not a deep understanding. As Alexander Pope said, a little learning is a dangerous thing. C++: In 24 hours you might be able to learn some of the syntax of C++ (if you already know another language), but you couldn’t learn much about how to use the language. In short, if you were, say, a Basic programmer, you could learn to write programs in the style of Basic using C++ syntax, but you couldn’t learn what C++ is actually good (and bad) for. So what’s the point? Alan Perlis once said: “A language that doesn’t affect the way you think about programming, is not worth knowing”. One possible point is that you have to learn a tiny bit of C++ (or more likely, something like JavaScript or Processing) because you need to interface with an existing tool to accomplish a specific task. But then you’re not learning how to program; you’re learning to accomplish that task. in 24 Hours: Unfortunately, this is not enough, as the next section shows. Teach Yourself Programming in Ten YearsResearchers (Bloom (1985), Bryan &amp; Harter (1899), Hayes (1989), Simmon &amp; Chase (1973)) have shown it takes about ten years to develop expertise in any of a wide variety of areas, including chess playing, music composition, telegraph operation, painting, piano playing, swimming, tennis, and research in neuropsychology and topology. The key is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes. Then repeat. And repeat again. There appear to be no real shortcuts: even Mozart, who was a musical prodigy at age 4, took 13 more years before he began to produce world-class music. In another genre, the Beatles seemed to burst onto the scene with a string of #1 hits and an appearance on the Ed Sullivan show in 1964. But they had been playing small clubs in Liverpool and Hamburg since 1957, and while they had mass appeal early on, their first great critical success, Sgt. Peppers, was released in 1967. Malcolm Gladwell has popularized the idea, although he concentrates on 10,000 hours, not 10 years. Henri Cartier-Bresson (1908-2004) had another metric: “Your first 10,000 photographs are your worst.” (He didn’t anticipate that with digital cameras, some people can reach that mark in a week.) True expertise may take a lifetime: Samuel Johnson (1709-1784) said “Excellence in any department can be attained only by the labor of a lifetime; it is not to be purchased at a lesser price.” And Chaucer (1340-1400) complained “the lyf so short, the craft so long to lerne.” Hippocrates (c. 400BC) is known for the excerpt “ars longa, vita brevis”, which is part of the longer quotation “Ars longa, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile”, which in English renders as “Life is short, [the] craft long, opportunity fleeting, experiment treacherous, judgment difficult.” Of course, no single number can be the final answer: it doesn’t seem reasonable to assume that all skills (e.g., programming, chess playing, checkers playing, and music playing) could all require exactly the same amount of time to master, nor that all people will take exactly the same amount of time. As Prof. K. Anders Ericsson puts it, “In most domains it’s remarkable how much time even the most talented individuals need in order to reach the highest levels of performance. The 10,000 hour number just gives you a sense that we’re talking years of 10 to 20 hours a week which those who some people would argue are the most innately talented individuals still need to get to the highest level.” So You Want to be a ProgrammerHere’s my recipe for programming success: Get interested in programming, and do some because it is fun. Make sure that it keeps being enough fun so that you will be willing to put in your ten years/10,000 hours. Program. The best kind of learning is learning by doing. To put it more technically, “the maximal level of performance for individuals in a given domain is not attained automatically as a function of extended experience, but the level of performance can be increased even by highly experienced individuals as a result of deliberate efforts to improve.” (p. 366) and “the most effective learning requires a well-defined task with an appropriate difficulty level for the particular individual, informative feedback, and opportunities for repetition and corrections of errors.” (p. 20-21) The book Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life is an interesting reference for this viewpoint. Talk with other programmers; read other programs. This is more important than any book or training course.If you want, put in four years at a college (or more at a graduate school). This will give you access to some jobs that require credentials, and it will give you a deeper understanding of the field, but if you don’t enjoy school, you can (with some dedication) get similar experience on your own or on the job. In any case, book learning alone won’t be enough. “Computer science education cannot make anybody an expert programmer any more than studying brushes and pigment can make somebody an expert painter” says Eric Raymond, author of The New Hacker’s Dictionary. One of the best programmers I ever hired had only a High School degree; he’s produced a lot of great software, has his own news group, and made enough in stock options to buy his own nightclub. Work on projects with other programmers. Be the best programmer on some projects; be the worst on some others. When you’re the best, you get to test your abilities to lead a project, and to inspire others with your vision. When you’re the worst, you learn what the masters do, and you learn what they don’t like to do (because they make you do it for them). Work on projects after other programmers. Understand a program written by someone else. See what it takes to understand and fix it when the original programmers are not around. Think about how to design your programs to make it easier for those who will maintain them after you. Learn at least a half dozen programming languages. Include one language that emphasizes class abstractions (like Java or C++), one that emphasizes functional abstraction (like Lisp or ML or Haskell), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), and one that emphasizes parallelism (like Clojure or Go). Remember that there is a “computer” in “computer science”. Know how long it takes your computer to execute an instruction, fetch a word from memory (with and without a cache miss), read consecutive words from disk, and seek to a new location on disk. (Answers here.) Get involved in a language standardization effort. It could be the ANSI C++ committee, or it could be deciding if your local coding style will have 2 or 4 space indentation levels. Either way, you learn about what other people like in a language, how deeply they feel so, and perhaps even a little about why they feel so. Have the good sense to get off the language standardization effort as quickly as possible.With all that in mind, its questionable how far you can get just by book learning. Before my first child was born, I read all the How To books, and still felt like a clueless novice. 30 Months later, when my second child was due, did I go back to the books for a refresher? No. Instead, I relied on my personal experience, which turned out to be far more useful and reassuring to me than the thousands of pages written by experts. Fred Brooks, in his essay No Silver Bullet identified a three-part plan for finding great software designers: Systematically identify top designers as early as possible. Assign a career mentor to be responsible for the development of the prospect and carefully keep a career file. Provide opportunities for growing designers to interact and stimulate each other. This assumes that some people already have the qualities necessary for being a great designer; the job is to properly coax them along. Alan Perlis put it more succinctly: “Everyone can be taught to sculpt: Michelangelo would have had to be taught how not to. So it is with the great programmers”. Perlis is saying that the greats have some internal quality that transcends their training. But where does the quality come from? Is it innate? Or do they develop it through diligence? As Auguste Gusteau (the fictional chef in Ratatouille) puts it, “anyone can cook, but only the fearless can be great.“ I think of it more as willingness to devote a large portion of one’s life to deliberative practice. But maybe fearless is a way to summarize that. Or, as Gusteau’s critic, Anton Ego, says: “Not everyone can become a great artist, but a great artist can come from anywhere.” So go ahead and buy that Java/Ruby/Javascript/PHP book; you’ll probably get some use out of it. But you won’t change your life, or your real overall expertise as a programmer in 24 hours or 21 days. How about working hard to continually improve over 24 months? Well, now you’re starting to get somewhere… References Bloom, Benjamin (ed.) Developing Talent in Young People, Ballantine, 1985. Brooks, Fred, No Silver Bullets, IEEE Computer, vol. 20, no. 4, 1987, p. 10-19. Bryan, W.L. &amp; Harter, N. “Studies on the telegraphic language: The acquisition of a hierarchy of habits. Psychology Review, 1899, 8, 345-375 Hayes, John R., Complete Problem Solver Lawrence Erlbaum, 1989. Chase, William G. &amp; Simon, Herbert A. “Perception in Chess” Cognitive Psychology, 1973, 4, 55-81. Lave, Jean, Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life, Cambridge University Press, 1988. Answers Approximate timing for various operations on a typical PC:execute typical instruction 1/1,000,000,000 sec = 1 nanosecfetch from L1 cache memory 0.5 nanosecbranch misprediction 5 nanosecfetch from L2 cache memory 7 nanosecMutex lock/unlock 25 nanosecfetch from main memory 100 nanosecsend 2K bytes over 1Gbps network 20,000 nanosecread 1MB sequentially from memory 250,000 nanosecfetch from new disk location (seek) 8,000,000 nanosecread 1MB sequentially from disk 20,000,000 nanosecsend packet US to Europe and back 150 milliseconds = 150,000,000 nanosecAppendix: Language Choice Several people have asked what programming language they should learn first. There is no one answer, but consider these points: Use your friends. When asked “what operating system should I use, Windows, Unix, or Mac?”, my answer is usually: “use whatever your friends use.” The advantage you get from learning from your friends will offset any intrinsic difference between OS, or between programming languages. Also consider your future friends: the community of programmers that you will be a part of if you continue. Does your chosen language have a large growing community or a small dying one? Are there books, web sites, and online forums to get answers from? Do you like the people in those forums? Keep it simple. Programming languages such as C++ and Java are designed for professional development by large teams of experienced programmers who are concerned about the run-time efficiency of their code. As a result, these languages have complicated parts designed for these circumstances. You’re concerned with learning to program. You don’t need that complication. You want a language that was designed to be easy to learn and remember by a single new programmer. Play. Which way would you rather learn to play the piano: the normal, interactive way, in which you hear each note as soon as you hit a key, or “batch” mode, in which you only hear the notes after you finish a whole song? Clearly, interactive mode makes learning easier for the piano, and also for programming. Insist on a language with an interactive mode and use it. Given these criteria, my recommendations for a first programming language would be Python or Scheme. Another choice is Javascript, not because it is perfectly well-designed for beginners, but because there are so many online tutorials for it, such as Khan Academy’s tutorial. But your circumstances may vary, and there are other good choices. If your age is a single-digit, you might prefer Alice or Squeak or Blockly (older learners might also enjoy these). The important thing is that you choose and get started. Appendix: Books and Other Resources Several people have asked what books and web pages they should learn from. I repeat that “book learning alone won’t be enough” but I can recommend the following:Scheme: Structure and Interpretation of Computer Programs (Abelson &amp; Sussman) is probably the best introduction to computer science, and it does teach programming as a way of understanding the computer science. You can see online videos of lectures on this book, as well as the complete text online. The book is challenging and will weed out some people who perhaps could be successful with another approach. Scheme: How to Design Programs (Felleisen et al.) is one of the best books on how to actually design programs in an elegant and functional way. Python: Python Programming: An Intro to CS (Zelle) is a good introduction using Python. Python: Several online tutorials are available at Python.org. Oz: Concepts, Techniques, and Models of Computer Programming (Van Roy &amp; Haridi) is seen by some as the modern-day successor to Abelson &amp; Sussman. It is a tour through the big ideas of programming, covering a wider range than Abelson &amp; Sussman while being perhaps easier to read and follow. It uses a language, Oz, that is not widely known but serves as a basis for learning other languages. &lt; Notes T. Capey points out that the Complete Problem Solver page on Amazon now has the “Teach Yourself Bengali in 21 days” and “Teach Yourself Grammar and Style” books under the “Customers who shopped for this item also shopped for these items” section. I guess that a large portion of the people who look at that book are coming from this page. Thanks to Ross Cohen for help with Hippocrates.","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://ipcreator.me/tags/Algorithm/"}]},{"title":"十分钟后开始使用英语","date":"2017-01-19T18:13:06.000Z","path":"2017/01/20/MyShare/how-to-use-english/","text":"原文作者：李笑来，十分钟后开始使用英语…… 阅读这一篇文章，最多需要十分钟而已，之后你就可以开始使用英语了。学习英语的最少必要知识是什么呢？ 学会音标 学会查词典 学会查语法书 学会正确地提问 养成最基本语言学习习惯 学会音标音标只是一个符号系统。首先，任何人花上一下午就都可以学会。其次，千万别信那种胡说八道：“外国人都不用音标的”。先说说我们自己的母语，你什么时候见过一个受过教育的人不会用拼音的？遇到生词生字的时候，连拼音都不会的话，就算查到了，也不知道那字或词如何读。英语世界更是如此，要知道英语是目前地球上词汇量最多的语言，也就是说，在英语世界里，任何人遇到生词的概率都要大出许多许多倍 —— 只要是个正常受过教育的人，怎么可能不去查词典？怎么可能甘心于查了词典之后竟然不懂如何发音？ 学习音标真的很简单。 从任何一本有文本的有声书中截取一段大约三五分钟的录音，然后把电子书的文本拷贝出来，粘贴复制到这个网站提供的工具里：http://upodn.com/phon.php ，然后你就会得到一个英语与音标对应的文本。（我是如何知道这个网站的？Google 呗 —— ‘Phonetic Transcription’……）三五分钟的语音中（大约三五百个词）一定包含了所有的音素（辅音、元音）……一边看音标文本文件，一边反复跟读这段文本……一个下午，任何一个正常成年人都能搞定。 学会查词典查词典，是学习语言的必需习惯 —— 正如学习是生活的必需习惯一样，也正如翻阅文档是开发者必需习惯一样，其实，哪个领域都是一样的。 遇到生词就查。对，每一个。查着查着就越查越少了 —— 这是一定的。那些告诉你，“遇到生词（先）不（用）查，先猜”的人，让他们去屎。望文生义的笨蛋说的就是他们。 一句话里感觉没有生词，可就是看不懂，原因可能是某个单词有另外的词义，而你却只知道最常用的词义。比如，“down”这个单词，竟然还可以做名词使用，意思是“小鸟小鸡身上的软毛”…… 那可能是有“你全都认识的词构成的你完全猜不到的词义”造成的，比如“purple passage”，“purple”你认识，“紫色的”，“passage”你也认识，“文章”，但“purple passage”是“辞藻过分华丽，金玉其外败絮其中的文章” —— 你可能就不知道了。 还有一种情况是，语法结构弄不明白…… 比如，“as” 有很多用法，到底是哪一个呢？那就走下一步：查语法书。 学会查语法书语法书是用来查的，不是用来背的 —— 你啥时候见过人们背地图？ 一张地图拿过来，知道“上北下南左西右东”，以及“少量标记符号”（比如，公交线长什么样，地铁线长什么样）这两个最少必要知识之后，就可以开始查地图了，不是吗？ 语法书也一样，除了你在初中的时候已经学过的一些基础语法概念，比如“名词”、“动词”、“形容词”、“副词”什么的之外，你还需要知道另外一个概念：“功能词”。什么叫功能词呢？就是那些在语法书的附录里，带着页码编号的词…… 你应该找个时间，比如一下午，大概翻翻那些功能词都有哪些，有个印象就好。 然后，在遇到“没有生词、没有不了解的词义、没有不认识的词组，但就是读不懂的句子”的时候，仔细看看那句子里有没有功能词存在？有的话，去查查语法书，在附录里找到对应的页码（可能不止一个），按图索骥地查下去，一定能找到答案…… 你以为你遇到过的英语老师啥都懂吗？不是的！他们就是比学生多一个技能：遇到问题的时候，他们懂得如何查词典，如何查语法书…… 哪个领域都是一样的 —— 你以为“高级程序员”什么都懂吗？某种意义上，他们只比那些“低级程序员”多一个技能：遇到问题的时候，他们懂得如何检索文档，如何问 Google…… 学会正确提问能问 Google 的，都不要去问别人，这是礼貌。 别问人家这个单词什么意思，别问人家这句话什么意思 —— 自己动手去查！一个词典查不到，再换一个，换一个还查不到，还有 Gooogle 呢！ 实在查不明白，还有个办法，去 Google 那句原文，然后加上一个汉字“的”或者“了”（这两个字是中文中使用频率最高的词），这个搜索组合很可能让你找到已经有人在网上提问过…… 自己折腾过了，还搞不明白，再去问可能帮你的人 —— 他们也搞不定，也有可能，那就记在本子里。很神奇的事情是，大量的问题，都会在某一天自动出现解决方案的 —— 前提是，你还记得那个问题! 不会正确提问，其实只不过是懒惰的表现，懒人是没救的，所以千万不能做懒人。 养成最基本语言学习习惯朗读。天天朗读。每天朗读半小时，坚持两百天，才 100 小时…… 每天朗读一小时，坚持 100 天，也就是三个月多一点点 —— 你已经把 90% 的人甩在身后了，真的！ 阅读先行是很自然的口语难练，这是很正常的，因为在大多数情况下，我们读书、看电影的时候，由于面对的并不是真实的人，所以我们大脑中的“镜像神经元”很难被激发，于是学习能力处于“冬眠状态”。其实每个人都很有语言天赋的，顶多是一点点的好坏差异而已。你看，几乎任何一个人在一个新的城市里住上一周以上，口音就会发生一些微妙的变化，并且根本不是故意的（都没有刻意练习） —— 只是因为镜像神经元被激发了。 可是阅读这东西，用不着镜像神经元过分活跃 —— 只是在小时候启动的时候可能需要（家长喜欢看书，孩子通常更容易喜欢看书）。所以，你要相信你的阅读能力可以很快提高的，事实上，确实如此 —— 只需要啃上一本原版书，基本上就过关了。 选择原版书的时候，一定要选择自己感兴趣的领域 —— 英语教科书在这方面几乎是最差的。现在对你来说，这是个很好的机会，你不是对编程感兴趣吗？不是对成为计算机工程师感兴趣吗？那就读这个领域的原版书好了。这样的时候，你的焦点并不在于英语本，而是在于那语言文字背后的思想，这样的时候，你的大脑会很厉害，它自己会想办法穿透那层“毛玻璃”（英语），看到那玻璃背后的意义…… 不知不觉之间，那“毛玻璃”就会变成“透明玻璃” —— 就这么简单。 刻意练习永远是必须的每天都要挤出一点时间，把今天遇到过的生词复习几遍 —— 上学的时候不懂如何复习的人学习都不好，现在在成年阶段重新学习的时候，可别再吃这个亏了！而且，这个习惯是会“遗传”的：你的孩子若是看到你总是通过重复获得进步，他们也会自然而然地习惯于重复获得进步，这是真理。 没！有！别！的！了！ 任何正常人都可以上路了。如果还想让自己更心安一点，那就去读一本书《人人都能用英语》，其实只有一个字和一个感叹号：“用！” 用吧用吧，不是罪。 大多数人的平庸和愚蠢，其实都是当初自己选的 —— 这真是一个残酷的事实。 任务 今天就彻底学会音标。 从明天早上就开始坚持朗读。 配置好自己的计算机以便随时查词典，请 Google Mac Dictionary 添加词典。 请 Google 新编英语阅读手册。 请 Google 人人都能用英语。 请 Google how to ask questions，第一个就是 Eric Steven Raymond 写的 How to ask questions the smart way，必须精读。 另外，还有一篇 HBR 的文章，也要细看。","comments":true,"categories":[{"name":"英语","slug":"英语","permalink":"http://ipcreator.me/categories/英语/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"正确高效使用 Google","date":"2017-01-19T18:12:06.000Z","path":"2017/01/20/MyShare/how-to-use-google/","text":"原文作者：李笑来，摘自《新生 —— 七年就是一辈子》 研究这个词，在英文中是research，我把它理解为re-search，实际上各种语言是相通的，所谓re-search其实就是“反复搜索”，就是“上下求索”（路漫漫其修远兮，吾将上下而求索）。所以，如果你想学点什么，就要善于搜索。而在这个时代里，最好的搜索工具就是 Google。 搜索引擎之所以迷人，就是因为它就好像望远镜一样： 能让你看到你原本完全看不到的东西……互联网就好像那浩瀚的宇宙，里面几乎什么都有，只要你肯用“望远镜”去看、用搜索引擎去搜…… 搜索引擎是公开的，人人都可以用的，可偏偏大多数人不用、不会用，甚至错误地用…… 于是人与人之间的差异多了另外一个不断延展的维度。在这个维度上你不如人家你能怪谁？ 最烂的提问是：“我连不上 Google 怎么办呀？” 答案是“自己想办法” —— 如果你在乎，你就肯花时间自己解决这个问题，如果你不在乎，就不用在乎了。 1 使用“本尊” 最好使用 http://www.google.com/ncr NCR: No Country Redirection，而不是http://www.google.com.hk；有时，直接输入http://www.google.com也会被自动转到“本地Google”，比如，我用日本的 VPN，浏览器就会把我转到http://www.google.co.jp…… 2 优先使用英文关键字搜索 这是个好习惯。别说不会英文，不会就学，没那么难。 3 基本技巧 Google 搜索引擎也许是世界上最简单的应用界面，只有一个输入框和一个按钮。然而，用好它还是需要花点时间去学习的。Google 有帮助文档，还专门设计了个学习网站 A Google A Day 3.a 加号 在 Google 的输入框里，所有的空格都被 Google 理解为加号+。如果你输入的是 purpose of education那么 Google 返回的文章里既有“purpose”存在，也有“education”存在，但不一定有“purpose of education”存在。另外，过分常用的、单独存在没有意义的词汇往往被忽略掉，比如冠词“a”、“the”；介词“of”、“in”、“on”、“at”、“to”；连词“and”、“or”、“but”；从属连词“that”、“which”、“when”；代词“my”、“his”、“them”等等。 3.b 引号 如果你想要找含有“purpose of education”这个词组的文章，那么你必须输入”purpose of education”。现在的 Google 已经可以处理 utf-8 大字符集了，所以，即便你在输入的时候使用的是全角字符（不是半角字符的”而是“或者”）Google也照样能够正确处理。比较一下两种输入返回的结果：purpose of education vs.“purpose of education”。再试试 the most important benefit of education 和 “the most important benefit of education”。这就是引号（“……”）的作用——返回“完整匹配”的结果。 3.c 减号 为了进一步筛选搜索结果，还需要学会另外一个符号——减号-。比如，“the most important benefit of education” – “united states”要求Google返回含有“the most important benefit of education”但不存在“united states”的文章。 3.d 星号 另外一个威力无穷的符号是星号。Google 支持通配符搜索，即搜索字符串中可以包含星号，用来替代任意字符串。比如，“the most * examples of censorship”将会返回含有类似“the most outrageous examples of censorship”、“the most brazen examples of censorship”、“the most heinous examples of censorship”、“the most stupidest examples of censorship”、“the most dangerous examples of censorship”、“the most egregious examples of censorship”、“the most prolific examples of censorship”、“the most absurd examples of censorship”…… 3.e 波浪号 还有一个运用相当灵活、经常带来意外收获的符号是波浪号~。把波浪号~加在某个单词前面，是在告诉 Google：除了给出的关键字之外，还要搜索与波浪号~后面的那个单词相关的词汇。比如，搜索the importance of ~censorship的结果中包含着“the importance of censorship”，也包含着与censorship相关的另外一个词汇“propaganda”——“the importance of propaganda”。 4 高级技巧 4.a 站内搜索 再学一个在指定网站中搜索的语法“site:”。比如，“the purpose of education” site:http://www.time.com/就是要求 Google 只返回 http://www.time.com 这个网站里的含有“the purpose of education”的文章。 4.b 定制搜索 2006年，Google 推出了“co-op”服务（自定义搜索引擎）。其中最常用的功能之一就是可以指定 Google 搜索一个或者若干个指定的网站——相当于前面提到的 Google 语法“site:”的扩展。比如，我就曾经为我的学生定制了一个 Google cse（Custom Search Engine）——Search News Media。不妨看看在这个自定义搜索引擎上搜索censorship返回的结果（GRE/SAT 的作文考试中，都有很多关于“censorship”的作文题）。这个 cse 只搜索以下10个网站： http://www.economist.com/http://www.cnn.com/http://www.time.com/http://nytimes.com/http://www.washingtonpost.com/http://www.usnews.com/http://usatoday.com/http://www.reuters.com/http://www.bbc.co.uk/http://en.wikinews.org/","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://ipcreator.me/tags/Google/"}]},{"title":"理财理念","date":"2017-01-19T18:11:06.000Z","path":"2017/01/20/MyShare/financial-philosophy./","text":"原文作者：李笑来 摘自《新生————七年一辈子》 越早越好 从今天开始存钱 躺着赚钱 自由意志 生活目标 注重学识 节省与否 被动支出 认识周期 性格养成 别做“险盲” 越早开始越好的事情没几个，理财排在第一位对大多数人来说，理财的困难与矛盾来自这样一个窘境：很难很早开始，等开始的时候已经太晚。 所谓理财，这个定义比较合理、准确：如何有效管理现金流—— 这其实与钱多钱少关系不大。 研究者发现，贫穷与自制力差有很大的正相关。这也很容易解释：贫穷意味着诱惑显得更多、更大、更明显。也就是说，即便在自制力实际上差不多的情况下，贫穷的个体与富有的个体相比，贫穷的个体也会表现得更差。年轻人相对是穷的，于是，相对来看需要更多的自制力才能抵制诱惑。这其中的重要因素是：不同年龄段的人对时间的感受不同。 为什么今天的人更应该重视理财呢？人们的平均寿命变得更长了。人们可获得收入的工作时间也随之变长了。 有更多的钱需要管理，有更长的时间去管理钱，而最为重要的是 —— 哪怕起点稍微低一点也无所谓了。 理财最难的地方有两个：对自我的把控对风险的把控这两个都是可习得的，且习得之后不可逆的技能。更为重要的是，这两个都是必须通过反复实践才能习得的技能。 转移注意力是抵御诱惑的一种常用的有效手段，这其实也是后来理财成功的人常用的手段。他们会尝试着骗自己，把那些定期存款或者股票投资当作“已经丢了”，尽量不去想它，不去看它。这跟聪明与否其实没有什么关系。有时候，骗骗自己也挺好的，不是吗？ 理财上的风险意识，跟遗传没什么关系，跟智商关系也不大，它是必须通过自己的实践、通过自己的失败、通过自己的教训、通过自己的总结才能获得的东西—哪怕在书上看过、听别人说过也没用。理财这件事肯定是越早开始越好。年轻的时候理财虽然难，但即便发生风险，损失也不会太多—因为本来就没有太多。等可管理的财富多了才开始学习，一旦损失，就肯定惨重得多。在这种情况下，尤其可怕的是—剩下的时间不多了！ 自控与自制是可以习得的，并且，一旦习得就不会失去，这才是关键。而反过来，开始学习理财，可能也是改善自制力、自控力的方法，不是吗？ 理财越早开始越好，这已经说过了。那如何开始呢？从今天开始存钱。“我得存钱，我才不想跟那些笨蛋一样呢……”因为没有引发负面情绪而更容易被大脑采纳的建议 一个人的自控能力是总量一定的，某些方面的高度自控，会导致在其他方面的失控。该花就要花，有的时候就要活在当下人的年纪越大，赚到的钱对生活质量的改善越小，这是事实。年轻的时候，确实应该适当地享受人生，甚至应该有意培养一些高质量的生活习惯。 爱面子其实是绝大多数人存不下钱的根本原因。年轻人更爱面子，为什么呢？说穿了，就是不成熟呗 —— 过分地、没必要地在意他人的看法。从商业模式上，校园分期是很成功的；从风险投资的角度，那几个做校园分期的创始人也是非常优秀的，优秀到令人眼红。但从另外一个角度看，那些肯支付年化 30% 甚至 50% 的利息购买 iPhone 的人，也挺吓人的…… 真的合适吗？分期没还完的时候，新一代 iPhone 又出来了…… 如何摆脱呢？我有经验 —— 海量阅读心理学书籍。尼采认为“一切都是主观的”，其实也有一点点道理，因为现代心理学告诉我们，我们都是受自己的主观意识所影响的，或轻或重，只不过有些人可以通过对心理学常识的理解去调整自己。 还有一个办法非常有效：给自己培养一个不那么费钱的兴趣爱好。大多数人出去花钱，根本上来看就是“闲的” —— 女性读者该笑出声了，因为她们自己最清楚。在我看来，读书就是一个超级省钱的兴趣爱好，可竟然有很多人认为“书太贵了”！这也是没办法的事，因为“连希望对一些人而言都是极其危险的”。再如，弹琴也是一个花钱比较少的兴趣爱好，吉他比钢琴花钱更少。有个兴趣爱好的好处是，闲暇时间有所寄托 —— 没工夫乱花钱，这不挺好的吗？ 从另外一个角度，理财无非就是“开源节流”。相对来看，“节流”固然重要，“开源”才是正途。对年轻人来说，努力提高自己未来的营收能力才是当务之急。微博、微信朋友圈固然得看，但更为重要的是要花更多时间去系统地研读正式书籍，多花时间去打磨自己的劳动技能。不要只顾着升级手机系统，也要常常升级自己的大脑，选择更好、更强的思维模式，进而有能力作出不同的选择。 最后，死活存不下钱的人，某种意义上都有共同的特征 —— 常常“一厢情愿”。他们一开始是“心里希望”，后来是“认定”一切都会自动变好，甚至进一步成功地欺骗自己：“这才是正能量”……骨子里，这是拒绝成长，拒绝承担责任，乃至心理学上还有个专门的词 —— 彼得潘综合症1。 现实是这样的：这个世界和这个社会整体上来看是会越来越好的，可每个个体的状况却不一定。很多人越来越糟，没有人会自动变好，只有行动才会带来变化，期望本身在没有行动支持的情况下只能变成自我欺骗。 成年之后，生活的一切几乎都是选择的结果。然后，给自己设置一个机制，使自己就是不能动用存起来的钱。这时，欺骗自己其实是有用的 —— 还记得那些 4 岁的孩子是怎么学会通过骗自己忍住不吃棉花糖的吗？就当那些钱丢了。丢了的钱，不是用来“应急”的，丢了就是丢了！“丢了”的意思是，没了，那些钱彻底没了！ 如何制造这种效果呢？这个灵感来自《本能：为什么我们管不住自己？》的作者。你可以这么干：到外地办一张储蓄卡，记下卡号之后把卡扔掉；以后每个月转一定金额的钱到那张卡上。其实金额大小并不重要，是收入的 20% 还是 5% 也不是很重要，真正重要的是 —— 给自己一个机会，在 5 年之后体会一下突然可以动用一笔闲钱的机会。如果你今年 25 岁，等待相当于自己已有生命的 1/5 的时段是很惊人的成就，这段经历在未来很可能会“折现”成惊人的毅力（Grit） —— 另外一个提高收入的重要能力。而且，来自经验的毅力更可靠 —— 5 年后你可就赚大了。 给自己存出一个机会，这就试试吧。 作为这个时代的年轻人，要坚定地理解两个事实： 普遍来看，普通人的赚钱能力在越来越快地提高； 普遍来看，普通人在生活必需上的开销所占比例正在缩小。这两条都笃信且实践，才能做到“别把自己的青春过得太穷”。 收入其实分为两种： 主动收入 被动收入 所谓主动收入，就是你必须干点什么才能获得点什么的那种收入；而被动收入则相反，就是那种你不必干什么但竟然可以获得的收入。被动收入的最常见例子是利息。利息是需要本金才能获得的，没有本金怎么办？更多的人，不仅没有“睡后收入”，还有很多“睡后支出” —— 分期消费的负担其实挺重的。 不管你处在什么年龄，从现在开始刻意寻找那种可以一次性付出却能够长期获得收入的事情去做。这种事情不像看上去那么难，甚至有越来越简单的趋势。比如，过去只有靠写书被正式出版才能拿到版税，现在很多人写写微信公众号文章就可能获得读者“打赏”，收入甚至比写书高一点，这就是趋势。 拼命锻炼自己的创作技能。可以是任何领域的创作，但必须是可以获得收入的创作。慨叹一句：所谓的创作，从某个角度上来看简直就是“无中生有” —— 一种成本长期趋近于零，收入长期趋近于无限的活动。 “未来是不可知的（unknown）”和“未来是不确定的（uncertain/random）”之间有着看起来细微但实际上意义重大的差异。 未来是不可知的（The Future is unkownable），意味着我们对未来毫无办法，正如我们对过去无可奈何一样。2未来是不确定的（The Future is uncertain/random），意味着我们对未来有一定的概率可以成功预测。 换句话讲，当我们抛出一个硬币，在它落稳之前，我们确实不知道它究竟是哪一面朝上，但我们确实知道任何一面朝上的概率都是 1/2 —— 这是巨大的差异。 科学的敌人并不一定是宗教，科学的敌人一定是那些不愿意改变自己既定人生观、价值观的人。 概率论就是风险控制的基础工具。因为绝大多数人真的不认为科学与自己的生活有太大的关系。学识使人坚毅。金融专业毕业的人通常会想办法全款买房买车，这不仅仅是因为他们可能赚的比较多，更因为他们对利率和理财的理解使他们无法作出分期消费的决定。在今天这个时代，求知就是求富。因为知识变现不仅越来越容易，也越来越快，越来越多。重复的、枯燥的工作应该自动化完成。 这世界发生了很多变化。其中之一就是，越来越多的人靠着一点点的小发明的商业化赚到了越来越多的钱。这就是时代的不同。所谓“屌丝逆袭”的故事只有到了现代才开始批量出现，就是因为智力变现、知识变现可能了、容易了。 在今天这个时代，我们可能并不需要打败谁才能过得更好，起码可以过得足够好。细想想，很多人其实是被自己打败的。他们普遍的特点是一样的：在虽然很难但明明可以选择的情况下，误以为自己完全没有选择，于是只能走进死胡同。放弃了选择，就是被打败了。 在一个普遍认为人们其实没有选择的世界里： 用以学识支持的坚毅认定其实选择是存在的，并且是可追求的，是有很大相对优势的—— 就是这样。 什么叫高品质生活？高品质生活与金钱肯定有着一定的联系自欺欺人不仅无补，甚至有害，尤其是对自己的大脑 —— 人要珍爱自己的大脑。被动收入略高于支付足够高品质的生活必需支出所需要的金额。 对成年人来说，高品质生活从停止自欺欺人开始。比如， “金钱不一定带来高品质生活”，以及它的各种变体：有钱不一定幸福。（但没钱更不容易幸福。）那么拼有什么用？不还是得了乳腺癌？（不拼的人也有很多得了乳腺癌。）我很穷，但我有骨气！（说得好像富人没有骨气似的。） 即便是今天，求知的成本依然相当高。全球范围内连年上涨的大学学费就是明证 —— 真的不是所有人都有钱完成高等教育的，不是吗？正因为富有，他们的勤奋才更容易达成目标，或者反过来，当他们的勤奋没有直接、快速的回报之时，他们也更不容易着急，而是显得更有耐心 —— 时间久了，耐心就真的有了。 事实上，致富失败的人更容易放弃勤奋，而持续勤奋的人最终不可能太穷。很努力依然很穷的人，其实是选择出了问题，而不应该怪罪勤奋本身。 是否能拥有高品质生活与一个人的审美能力有着至关重要的联系。所谓审美，真的不只是在选美大赛中判断哪个姑娘最漂亮而已。审美实际上是一切生活选择的基础。什么是美？审美教育不够普及，就算有也常常失败的重要原因在于 —— 人们误以为“美”与“不美”是一种主观判断，可事实上，美是一种客观存在。所谓的“主观”，实际上指的是对美的感受有多准确。达·芬奇遇到帕西奥利之后，因为帕西奥利教给了他足够的数学知识，他专门为帕西奥利的书《神圣比例论》画了插图。在此之前，达·芬奇其实一直是凭直觉创造美，但被教育之后，美的创作就有了理论依据和指导，这就是黄金分割率的应用。 对美的认知是可以培养的。对美的认知，最基础的来自“五感”，即视觉、听觉、嗅觉、味觉和触觉。即便是小孩子，也有一些天然的审美意识：有些人的相貌是美的，有些风景是美的，有些音乐是美的，有些食物是美的，有些材料是美的有审美意识，有审美能力，有为自己创造美的意愿和动手能力 —— 这是长期培养之后习得的结果。审美认知、审美能力，大多数情况下真的与金钱无关，因为更多更重要的审美体系，需要的不只是某一个器官的感受，而是系统思考的能力。 比如，除了美食、美景、美人之外，还有很多事物都是美的。 有些语言文字很美有些科学证明很美 进而还有更多抽象的美。 简洁很美效率很美创新很美 教育的意义就是让我们拥有更高级、知觉更丰富的器官。科学教育可以让一个人“打开眼睛”，看到不一样的却更真实的世界；音乐训练可以使我们分辨、创造更美的曲调……于是，长期的教育和自我教育会形成个体之间审美能力的巨大差异。最终，审美意识会触及且影响一个人价值观的方方面面。 审美意识的开化和审美能力的积累，自始至终都在影响人们的理财过程。金钱这个东西对于审美来说是“后相关”。什么叫“后相关”呢？这是我自己杜撰的一个词。金钱本身通常对开启审美意识、提高审美能力没什么作用，不过，在有了良好的审美意识、良好的审美能力之后，金钱可以发挥的作用很大，这就是金钱对审美的“后相关”作用。 高品质生活不一定要等到未来，也不一定要有钱才可以拥有。但未来因为现在开始理财成功的你，一定会有更高品质的生活。千万不要胡乱从小刻意灌输理财观念，尤其是大多数父母的观念还是错的。要从更本质的地方开始：开启孩子的审美意识，刻意培养他们的审美能力。 理财也好、投资也罢，要抛弃勇气，注重学识。 人们对勇气、勇敢的理解常常过于肤浅，从未认真审视，甚至干脆忽视。勇气、勇敢背后的支撑究竟是什么？比如，小孩子打架，双方对峙，更多是靠先天条件 —— 身强力壮的更容易“勇敢”，体质弱小的更容易“怯懦”。细想想，这跟勇气的关联并非100% —— 甚至没有勇气什么事，只与体质的强弱有关。 俗话说，“狭路相逢，勇者胜”。这也确实是一种实际存在的情况。在双方势均力敌的情况下，竟然有一方是更有勇气的，最终勇者胜出了。可问题在于，胜出的一方为什么更有勇气呢？更可能的解释是：其中一方想明白了 —— 大家都害怕，你们害怕，我们也害怕，只不过，我不让你们看出来我在害怕，那你们就更害怕了，于是我就有相对优势了。这样的时候，所谓的勇气，已经不再是抽象的特质，而是一种相对精巧的计算（或算计）了。 苏轼在《留侯论》里就说过：“古之所谓豪杰之士，必有过人之节。人情有所不能忍者，匹夫见辱，拔剑而起，挺身而斗，此不足为勇也。天下有大勇者，卒然临之而不惊，无故加之而不怒。此其所挟持者甚大，而其志甚远也。”意思是说，“蛮勇”其实并不算“勇”，只不过是个“然并卵”的东西。苏轼所说的“大勇”是什么呢？换句话讲，其实是脑壮，而不是肉粗。 所谓的勇敢、勇气，尤其是脱离先天条件支撑的勇敢、勇气，其实也是、更是学识与思考的表现。在理财与投资的起点就要明白：成功与所谓的勇气无关，靠的是足够的衡量风险与收益的能力 —— 这才是成功的智慧。智慧的特征是，可习得，可积累。 风险永远无所不在，真正的问题在于你如何识别它们，如何衡量它们，当有收益可能的时候如何计算风险是否可以接受，以及自己是否有足够的实力承受。这些都是可以通过学习获得并进一步提高的思考能力。应对风险的能力是必须花时间学习的，只因为它确实可以习得，但不容易习得。大多数人在生活的方方面面都缺乏风险意识。比如，刚学会开车的人，上路之后就常常后怕 —— 看着不怕车辆的行人才反应过来，原来过去那么多年里，自己其实很多次都是在“九死一生”的状态下过马路的。再如，我个人也是在自己开车之后才明白晚上穿着深色的衣服沿着马路走其实是非常危险的。对没有开过车的人来说，有一些风险“不存在” —— 他们未曾意识到那些很大的风险竟然存在。同样的道理，未曾做过理财和投资的人，往往不知道很多风险的存在，原因仅仅是他们从来没见过、从来没想过。 仅仅能够感知风险的存在，清楚地知道风险有多大，大到什么程度，都是需要大量观察、大量思考才能真正习得的能力。我问过很多专家，他们其实都一样，除了反复说“注意风险”之外拿不出更好的建议。不仅仅是理财，生活中的任何方面其实都一样：安全，要靠避险，而不是冒险；要靠小心，而不是勇气。 从本质上来看，大多数人想着去赚钱，最终却“被赚”了的本质原因在于他们根本就没学习过、没研究过他们所参与的游戏究竟是怎么回事。他们甚至连赌徒都算不上，因为赌徒起码知道应该怎样结合胜率计算收益、怎样决定下注的筹码数量、怎样计算多次下注后的概率变化……所以，实际观察一下就能知道，很多人进了股市，连赌都没有赌，钱就没了。他们只不过是人肉印钞机，为股市“定向增发”。钱没了，他们都不知道是怎么没的，甚至都不知道应该怪谁、该怪什么，只能怨自己运气不好。他们有的其实不是勇气，也不是勇敢，只不过是天然的贪婪而已。 “股市有风险，投资需谨慎”这种建议天天在耳边飘荡，怎么那么多人就是听不进去呢？ 第一个解释就是：无知无畏。 第二个解释是：安全保护会使人放松警惕。正如驾驶员系上安全带之后会不由自主地、下意识放心地提高车速一样，安全保护常常刺激人们放松安全意识。所以，对安全带的争议在于：安全带也许保护了驾车的司机，却可能给路上的其他人、其他车带来更大的危险。 风险与收益一直共存，并且，风险的大小是可以通过对它的了解和学习而被控制的 —— 这是人类进步的基础，也是人类进步的表现。但显然，它不会自动消失，或者自动配合人们的行动。只有通过学习，才能与它共舞。 科技的进步正在某个层面抹平贫富差异所造成的生活质量差异。有了 Uber 之后，人们几乎可以随时轮换着坐各种品牌的豪车，还不需要支付过高的费用 —— 弄不好补贴完发现比搭乘普通的出租车还便宜。 【买书的钱不能省】：在追求学识的过程中，免费常常是陷阱。因为，我们的时间并不是免费的，同时会随着我们自己的学识变得越来越贵。舍不得花钱买好书是最“屌丝”的行为，也是最高效地制造“屌丝”的方式。不仅不能在好书上省钱，还要为了淘到真正的好书，付出“总是得前后买过很多烂书才能提高甄别能力”的代价。再往大里说，一切有助于帮助自己成长的开销都不能省，尤其对年轻人来说更是如此 —— 你的前途取决于此。 【买工具的钱不能省】一切工具，其发明与使用的目的都是一样的 —— 提高效率。花一点钱提高效率，赚大了；为了省一点钱，却要忍受长期的低效率甚至无效率 —— 只有“屌丝”才会觉得没问题。 【事关安全的钱不能省】家里的电源插座之类的东西，绝对不能图便宜，因为这涉及安全。在这样的事情上，没有“万一”，因为天天都在用，所以最终结果是“一定会出事”。买车的时候也一样，要不要加后视影像，要不要配置全景雷达 —— 这些其实完全不是应该省钱的地方，因为它涉及安全。在这样的地方省钱，将来一定会付出更高的代价。 【事关终极体验的钱不能省】终极体验的特点是，当前的享受不可能用未来的享受替代。 【知识产权的钱不能省】我总觉得程序员用盗版软件是个特别“屌丝”的行为 —— 你自己指望用技能、产品赚钱，却坚决不让别人用技能、产品赚钱，这种逻辑让人无语。对知识产权的尊重，对知识产权的保护，是让那些有能力创作的人获得“被动收入”、获得财务自由的基础。没有知识产权保护，有能力创作的人就只能“无产”了 —— 还有什么是比这更阴暗的未来展望呢？ 节省肯定没错，但节省肯定不是创造未来的主要方式。铺张浪费肯定不对，但在一些地方对自己好一点，对今天的年轻人来说，也肯定没错。 被动支出 【通货膨胀是最可怕的被动支出】2015 年 10 月，央行释放 7 万亿元，导致人民币瞬间贬值 2%，也就是说，你兜里揣着的 100 元钱，现在只相当于之前的 98 元了，有 2 元钱已经“不翼而飞”，只不过那张纸币上印着的数字不会自动改变，所以，看起来还是 100 元。越有钱的人，“恢复能力”越强，就好像受了同样的伤，身体强壮的人相对更容易复原一样。假设货币贬值了 2%，即购买力大约下降了 2%。一个月收入 5,000 元的人，如果他的月花销本来就是 5,000 元（也就是说，本来每月刚刚好），那么他现在收入依然是 5,000 元，可每个月的花销却需要大约 5,102 元（5,000 ÷ 0.98） —— 还得去借点钱才够用。而一个月收入 15,000 元的人，假定他的月花销也是 5,000 元，那么，虽然他现在需要用 5,102 元才能满足生活需求，但他依然有 9,898 元可以去储蓄，如果是定存的话，有可能获得 3% 甚至更高的利息，于是没多久，那损失的 2% 就补回来了。如果一个人有几百万元的存款，那么他通常可以在银行买到利率更高的理财产品，比如信托之类，利率可能高达 12% ~ 15% —— 虽然也有一定的风险 —— 于是，他们的恢复能力更强。 【利息对借款者来说也是很可怕的被动支出】借来的钱，之所以要支付利息，是因为在很多情况下钱本身就是一种生产资料，它也可以用来购买其他生产资料，而生产出来的商品是可以以更高的价格卖掉的 —— 能赚到钱。所以，利息这东西，本来就是天经地义的。只是古今中外，在很多文化里，很多人总是下意识地觉得赚取利息的人是不劳而获的，但到了不得已的时候又不惜去借很高利息的贷款 —— 错上加错。 【生活必需品开支其实是一种被动支出】尽量只为生产借钱，尽量不要为消费借钱。也就是说，如果你借来钱，用它可以赚到钱，赚到的钱比利息多，你就是有利润的，这本质上就是生产。如果借钱仅仅是为了消费，钱花出去了，获得的只是享受（即便有些确实是“终极体验”），那就有点亏了，甚至亏大了 —— 别人赚了 1 分钱，你花掉 1 分钱，这加起来就差了 2 分钱呢。 用借来的钱去支付教育费用，这也是生产，因为这相当于提高了自己将来获得更高收入的可能，算是一种投资，其实是很划算的投资。用借来的钱去买房子，虽然复杂一点，也算是投资，但还要看整个经济周期的状况。可用借来的钱去买部 iPhone，然后支付 30% 以上的利息，就不太划算了，因为有更便宜的替代方案存在，比如用坚果手机之类，代价就是 —— 没那么酷呗。但是，如果买来 iPhone，不仅用了，还把它作为开发机、测试机，那就不一样了！ 最后看第三项生活必需品支出。对于生活必需品的支出，对策如果是不吃不喝，显然不怎么明智。在今天这个世界里，竟然要连上网费都省下，那跟原始人有什么区别？过分约束自己，其实并不是一个优势策略，尤其是考虑到终极体验的不可替代性的时候。 一般规律倒也简单：收益越高，风险越大（反过来不一定成立） —— 虽然同时也有很多收益并不高的风险也很大。 别指望从别人那里找到答案，只能靠自己去判断。 人一辈子基本上要靠3种力量： 体力智力财力 即便是在远古时代，体力超群或者智力超群，直接的结果通常就是财力的增加，而财力的增加常常会进一步导致体力和智力的改善。 有两个自然规律在人类史上从来都没有变过： 只有第一被重赏财力积累无上限 自然规律就是“老大通吃”，发展到今天，这个趋势越来越夸张。创投圈里流行一个朴素的认知，其是古老的自然规律：这个世界，只有老大，没有老二。一个人的体力是有上限的，再强壮也有衰老的必然；一个人的智力是有上限的，再好学、再勤奋，时间总是有限的。但是，财力却有着优于体力和智力的属性。 可无限积累可直接继承 后天获得的体力可能遗传，也可能不遗传，也就是说，有可能，但不一定。后天提高的智力，很难遗传，更多的是通过对下一代的教育引导大致达到“遗传”的效果。可财力却不一样，除了可积累、无上限之外，还可以直接让子女继承，若是他们拥有足够的体力和智力，就可以继续积累，且站在更高的起点上继续积累。 从历史上看，只有一种靠谱的途径 —— 长期积累。“一夜暴富”其实很常见，但由于不是通过积累获得的，所谓“暴发户”在财富方面的智力（所谓“财商”）跟不上，于是无论有多少财富都可能很快败光。这种例子非常多，学者们曾经跟踪观察那些中了彩票的人，几乎有一个算一个都最终回到穷困潦倒的状态。 长期积累本来就是很少有人能做到的事情。积累就是难得的习惯，且要长期，这就难上加难。即便有人做到，历史上也有观察 —— 富不过三代，穷不过五服。为什么呢？只因为积累教育实在太难了！但这确实是唯一靠谱的途径。 所以，细想想就会发现，只有养成积累的习惯 —— 无论是在哪方面 —— 才是抵消被动支出的最有效手段。 认识周期周期是理财投资活动中最为关键的考量因素，是开始实践之前必须学习、研究、掌握、遵循的理念和现实，可惜总是被忽略。周期也是市场上大多数理财书籍中干脆不提，或者放在最后一笔带过，实际上却是最为基础、最为关键的知识点。不深入了解周期，就无法进行有效的判断，整个理财投资活动基本上就等于是没有判断的行为，甚至比不过两个人抛硬币赌博。而在这样的时候，墨菲定律一定会显灵：如果一件事可能变坏，那么它一定会变坏。 真正的趋势常常需要在多个周期（至少2个）之后才能真实展现。如果我们探究的是真正的趋势，就会发现，上升与下降只不过是一个真理的表象 —— 现实的经济里没有直线，只有波（动）。 在一个很长的波段中，从任何一个点前后望，看起来都像自己身处在一条直线而不是曲线上，就好像我们站在地球上却很难感知我们自己其实是站在球面上而不是平面上一样。 一个上升与一个下降构成一个周期。2 个或多个周期之后，如果我们发现曲线就好像是数学课本里的 sin 曲线的话，那么所谓的“趋势”实际上就是一条水平线而已，而我们常常说的且在寻找的所谓“趋势”应该是个要么上升、要么下降的线条才对，因为“水平”等于“无变化”，无变化就无趋势。 这就解释了为什么有些人认定的所谓的趋势在另外一些人眼里根本谈不上是趋势，因为后者重视的是1个以上的周期之后所显现的真正的趋势。这也解释了为什么“跟涨杀跌”的人必然吃亏，因为他们所看到的并不是实际的趋势，他们看到的和把握的只不过是幻象而已。 关注周期，以及多个周期背后显现出来的真正趋势，会给你一个全新且更为可靠的世界和视界。 进而，几乎一切事物，无论是抽象的还是具体的，都有它自己的周期。而他们的周期不大可能一致。于是，几乎一切的机会和陷阱都隐藏在周期与周期之间的差异上。据说GDP和股市的周期轮换如下图所示。 还有个“库伯勒 —— 罗丝改变曲线”（Kübler-Ross change curve）特别好玩，它看起来是这样的。 更进一步，人们发现，任何新生事物的发展过程（Transition Curve）也是差不多的。 反思这样的现象了：每次巨大技术变革出现的时候，都有一批投资者死在路上。为什么呢？因为他们看到了所谓的“趋势”，却忘记了或者不知道真正的趋势需要 1 个以上的周期才会真正显现。回顾一下历史吧，互联网、NetPC（后来所谓的“云”）等都是如此。再如，我相对比较了解的比特币，现在在这样一个阶段：比特币正在引发很多人的愤怒。 对周期的深入理解，甚至可能影响一个人的性格。在我看来，所谓的不屈不挠，所谓的坚持不懈，更多的时候，只不过是因为对自己身处某个周期的某个位置非常了解，所以才更容易作出的决定。 事实上，如果你需要理财顾问或者保险顾问1，你会发现，真正专业的理财师、保险师最终都是从你的情况出发，即从你身处的生命周期与经济周期的具体节点出发，制定你的理财计划。 繁殖能力强是王道。拿到理财与投资里说，就是存的越多越好。 太简单了吧？简单到好像没必要教育或学习似的。其实这也是传递重要知识时所面临的困惑与困难 —— 越是重要的东西越是看起来并不相关。比如，品质生活其实与审美能力更正相关，与钱的关系并不大，但是钱却看起来是最重要的、也被认为是最重要的因素。再如，当年我教英语的时候也发现，背单词的方法、找外教之类的学习环境其实都没有另外一个简单的字重要 —— 用。可越是重要的东西，说出来之后越是简单到令人不由自主地轻视。还有，性高潮其实与大脑关系最大。 性格养成一个人的性格是由他的价值观决定的。而所谓的价值观，其实就是一个人分辨好坏主次的思维体系。审美能力让我们分辨美丑，价值观让我们分辨好坏。于是，正如审美能力能够影响生活品质一样，价值观决定了一个人的性格。每个人都有自己的价值观，于是，每个人都有自己的一套体系去判别好坏，进而，好坏的判别，影响每一次的选择。于是，价值观影响选择，选择影响行动，行动构成命运。所以，“一个人的命运是由他的性格决定的”，这话我没办法不同意。 虽然环境对于性格养成的影响很大，但实际上一个人的性格可以脱离环境的影响，或者至少部分脱离。不做没用的事，这也是一种价值观导致的选择 我常常自我审视。现在回头看，对我性格影响最大的一个时期，是我从 2007 年开始写《把时间当作朋友》的两年时间。从我的个人体验来说，那个长达两年的写作过程 ——期间还有一次书稿尽失，只好凭记忆重新来过 —— 是我对自己的价值观的一次细心梳理。虽然很多价值观在那之前就定型了，但那一次的梳理却将更多的细节确定下来 —— 直接的结果就是，对自己可能做出的选择毫无疑问、毫不犹豫。 有什么值得生气的呢？都是想不开造成的。平时人们所说的“想不开”，其实无非就是“价值观混乱”。是什么影响价值观呢？我觉得与影响审美能力的因素是一样的：还是学识。 这个时代的好处是，学识相对容易获得，而且越来越容易获得。读书其实越来越便宜，早已不像过去，只有贵族才有资格读书；正规教育体系固然有很多问题，但毕竟义务教育真的普及了；人们讨论的问题越来越开放，而拥有健康好奇心的人刨根问底也越来越方便 ——若是能读懂英文，再加上 Google，那简直没有边界。 一个人的性格是长期自我选择积累的结果。 “险盲”是我借用“文盲”这个词的结构杜撰出来的一个词汇，是指那些不了解风险，不知道如何回避风险，更不懂如何控制风险的人。文盲的一生其实很吃亏，险盲的一生更是如此。文盲可以通过（自我）教育得到解放，险盲也一样。 风险教育应该是理财教育，甚至应该是整个教育中最重要的组成部分，也不知道为什么它竟然一直被忽略，顶多在学校里搞个防火模拟演习。火灾其实只是风险的一种，有一个术语是“不可抗力造成的系统风险”。这也是为什么我们必须不断自我教育的原因。仅靠别人教永远是不够的，要靠自己学才行。至于“活到老，学到老”，其实只不过是一种生活方式。 首先，要平静地接受第一个事实：风险是一种客观存在。第二，一旦未知存在，就有风险存在。有一个普遍的误解就是认为“风险的概率决定风险的大小”，可实际上，衡量风险的首要因素并不是风险的概率第三，衡量风险大小的决定性因素是赌注的大小。 假设有两个人玩公平的抛硬币赌输赢的游戏，规则是： 赌注大小恒定直至一方输光游戏才能结束请问，最终决定输赢的是什么（单选）？ A.手气 B.谁先抛硬币 C.抛硬币次数 D.总游戏时长 E.以上皆是 F.以上皆不是 关于之前的那道选择题，最终决定输赢的是谁的赌本更多。 由于赌注是大小恒定的，又由于抛硬币是概率为¹⁄₂的游戏，所以，如果双方赌本一样多，那么最终双方输赢的概率就都是¹⁄₂。可是，如果一方的赌本更多，那么他最终获胜的概率就会更大。由于玩的是概率为¹⁄₂的游戏，所以，如果其中一方的赌本是另外一方的2倍以上，那么前者几乎必胜。也就是说，在这个游戏里，赌本相对越多，输的概率越趋近于零。 如果你参与这个游戏，一上来发现那个“恒定大小的赌注”比你的总赌本还多，那么你就不应该参与。如果你的赌本只够下 1 注，虽然赢的概率依然是¹⁄₂，但从长期来看，你没有任何胜算。 很多人看起来一辈子倒霉，可实际上，那所谓的“倒霉”是有来历的。他们对风险的认识是错误的。他们倒霉的原因只有一个： 动不动就把自己的全部赌进去。赌注太大，则意味着结果无法承受。为什么赌本少的人更倾向于下大赌注呢？据说是越差的人梦想越大。高速公路上开得很快还不愿意系安全带的 —— 险盲，因为这些人不知不觉就把自己的性命当成了赌注。经常做铤而走险之事的人 —— 险盲。股市里怕自己赚得少，拿出全部身家（甚至借钱，更甚至借钱做杠杆）的人 —— 险盲。 第四，抗风险能力的高低本质上就是总赌本的大小，尤其是在面临同样概率的风险的时候。赌注相对大的时候，智力会急剧下降。为什么高考的时候总有一些人考砸？就是因为赌注（未来一辈子）太大，以致压力太大，进而无法正常发挥。那些天天刻苦训练的选手，每一个在训练的时候都能经常打出“满贯”，但在整个赛季都没有几个选手能在赛场上做到。为什么呢？就是因为赌注太大了。平时训练的时候没什么赌注，也就没什么压力。这也可以反过来解释一个常见的现象：历史上所有成功的庞氏骗局都有一个普遍的重要特征，那就是“加入费用惊人地高”，因为只有这样，进来的人才能普遍不冷静。所以，人真的不能穷，不能没有积蓄，否则真的会在某一瞬间突然变傻。另外，永远不要“All In”。这在很多时候并不是空话，真的需要放在心上。 第五，冒险没问题，但尽量不要被抽水。“抽水”是赌场里的术语，是指赢家要支付盈利中的一定比例给庄家。不要以为赌场太阴险，实际上，开赌场、保证公平就是需要开销的，所以，玩家支付抽水是合理的。也不要以为股票交易所太贪婪，它们收手续费也是合理的，这就是无所不在、不可消灭的“成本”。公平是有成本的。有抽水机制的赌局本质是倾斜的。因为即便是抛硬币的游戏，加上抽水机制之后，长期来看所有的玩家也都会输光，所有的赌注最终都会转化成抽水者的利润 —— 就好像一个正弦函数被改造成阻尼正弦函数一样。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"坐享其成","date":"2017-01-19T18:10:06.000Z","path":"2017/01/20/MyShare/sit-idle-and-enjoy-the-fruits/","text":"作者：李笑来 坐享，也许是最简单的大脑锻炼方式，这也是人类莫名其妙地已经运用了两千五百年以上的大脑锻炼方式。已经有足够多的科学研究证明，它能使你的大脑皮层表面积加大，能使你的灰质变厚，它也能增强人们的免疫系统，它还能让人们摆脱抑郁症……尽管简单，但也相当神奇。虽然神奇，却又非常简单。 所谓知识（或者知识的基石，即，概念）的三个基本要素，分别是： “是什么”（what） “为什么”（why） “怎么做/用”（how） 从这个角度望过去，不管三七二十一，用起来再说，从来就是人类的智慧。你现在知道为什么我主张不要闲着没事儿就学外语，而是一上来就要用了罢？（详见《人人都能用英语》） “坐享”这个词是我刻意造的中文词汇。在英文中，它叫 Meditation，翻译过来是“冥想”；在东方，它叫打坐、坐禅、禅修、内视、静观…… 其实“静坐”倒是个不错的词，可惜在中国它有另外的含义，不敢乱用。于是，只好生生编造了一个词：坐享。 也许释迦牟尼是地球上第一个知道如何坐享的人，并由此构建了一个系统的、庞杂的、却也足够完整的解释理论：佛教。如此算来，人类练习坐享，因为坐享获得益处迄今为止至少有两千五百多年了，真是神奇得很…… 什么是元认知能力？所谓的元认知，指的就是“认知的认知”。也就是说，你能认知到你的认知，虽然有点拗口，但其实也不是那么难以理解。当你在思考的时候，你能意识到自己在思考，进一步还能意识到自己在思考什么，又进一步还能判断自己的思考方式、思考结果是否正确，更进一步还能纠正自己错误的思考方式或者结果，这就是元认知能力。坐享无非就是通过一种简单合理的方式锻炼自己的“元认知能力”。 元认知能力几乎是一切学习与进步的最底层的、最根本的能力。一个人的潜力有多大，几乎完全取决于他的元认知能力有多强。 很多所谓个性强、脾气大的人，从最底层上来看，其实就是元认知能力困乏而已。因为这样的人其实没有分清楚谁是主人，谁是仆人，他们不明白这个很重要的道理：你的大脑并不是你，你的大脑是属于你的一个器官…… 而不是反过来，你竟然隶属于你的大脑。 元认知能力的强弱，与一个人大脑皮层的面积和灰质的厚度有着正相关的联系。决定一个人聪明与否的并不是脑壳大小，而是大脑皮层的面积。大脑皮层表面有很多沟回，沟回的多少，决定了最终大脑皮层表面积的大小，人和人之间的大脑皮层表面积大小甚至可能相差一倍以上。 通过不断有效地学习，我们的大脑获得更多的锻炼，最终的结果是大脑皮层表面积加大，灰质变厚；而反过来，大脑皮层表面积加大，灰质变厚，也会使学习能力有更大的扩展空间……元认知能力的获得，一方面与知识的习得有关系，因为任何学习过程本质上来看都是“制造更多的沟回”；而另外一方面，我们也可以像锻炼胳膊上的二头肌一样通过一定的方式进行锻炼大脑 —— 坐享就是这种锻炼。 通过放松大脑，长时间只专注于身体的某一部分，坐享可以让一个人逐步通过运用不断加强自己的注意力。注意力，是认知的最重要方式之一。而在不断把被分散的注意力重新集中起来的过程中，练习者可以渐渐感受到、并越来越熟练地应用自己的元认知能力 —— 当他认知到自己的认知并没有按照应该的方式操作的时候，他会运用自己的元认知能力纠正自己的认知及其操作方式。走路够简单吧？每天多走一小时，对身体的帮助可以说是无限大 —— 即便这么简单的事情，也很少有人愿意做，只不过是因为他们并没有深刻意识到那么做的种种好处，更无法想象不这么做的巨大害处。 每天坐享一刻钟或者一小时，已经是足够的大脑锻炼强度。已经有足够的科学研究证明这样做带来的巨大好处，除了大脑皮层面积增大、灰质变厚之外，它还能加强人体的免疫系统。更为重要的是，当一个人的元认知能力加强的时候，他更容易转变为进取型人格，更难被情绪所左右，相对更容易冷静，更容易清楚地思考…… 无论从哪方面看，都是能够极大提高生活品质的活动。 如何开始坐享？由于在坐享过程中，注意力足够集中的时候，全身放松的状态与人体在睡觉的状态几乎相同，所以，要注意保暖，注意风向。 可以找个毯子盖上膝盖； 不能有风持续吹到耳朵周围……(三叉神经汇聚于耳部周围，不小心的话，可能会引起面部偏瘫。) 至于姿势，其实并不重要，只要舒服就好。不一定非要盘腿…… 其实以下任何姿势都可以： 但脊背坐直倒是挺重要，因为最终，长时间弓着背可能更累。 从以下简单的步骤开始： 找个安静的地方 设定一个计时器（从五分钟或者十五分钟开始，渐渐延长到四十五分钟到一小时） 用你自己感觉舒服的方式坐好（最好脊背挺直） 闭上眼睛 开始深呼吸 将自己所有的注意力全部集中到呼吸上 一旦发现注意力转移到其它地方，就要刻意地将注意力集中到呼吸上 持续深呼吸…… 直至计时器将你“唤醒”。 坐享几次之后，可以开始尝试在坐享过程中用你的注意力扫描你的整个身体。 从左脚的脚尖开始…… 左脚掌…… 左脚跟…… 左小腿 ……左膝盖 …… 左大腿…… 左臀…… 顺着脊柱一直到后脖跟…… 划到左肩…… 左上臂…… 左肘…… 左小臂…… 左手腕…… 左手心…… 左指尖…… 再回来…… 左手心…… 左手腕…… 左小臂…… 左肘…… 左上臂…… 左肩……沿着你的肩一直划到右肩…… 右上臂…… 右肘…… 右小臂…… 右手腕…… 右手心…… 右指尖…… 再回来…… 右手心…… 右手腕…… 右小臂…… 右肘…… 右上臂…… 右肩…… 回到后脖根…… 顺着脊柱一直到右臀…… 右大腿…… 右膝盖…… 右小腿…… 右脚后跟…… 右脚心…… 右脚尖…… 在这个过程中，你会感觉到某个地方不舒服。这样的时候，把注意力全部集中到那个不舒服的地方，仔细观察自己的感受，尝试着接受…… 这是个机会，也是个挑战…… 一旦能做到接受那个原本不舒服的感觉，接下来的感觉竟然是解脱…… 尝试着在任何地方坐享。出租车上、火车上、飞机上、甚至颠簸的船上，或者干脆是在某个其实非常嘈杂的地方…… 总而言之，要集中注意力、并且最终可以做到自如地控制注意力才算是坐享 —— 最终的目标是可以做到在越来越长的时间里自如地注意力集中，并且还能控制集中的注意力。而胡思乱想、放空，甚至睡着了，都算不上是坐享，对增大大脑皮层面积，增厚灰质没有什么具体的帮助。 参考文献 Alterations in Brain and Immune Function Produced by Mindfulness MeditationEffect of compassion meditation on neuroendocrine, innate immune and behavioral responses to psychosocial stressBrain Mechanisms Supporting Modulation of Pain by Mindfulness MeditationA comparison of mindfulness-based stress reduction and an active control in modulation of neurogenic inflammationWorkplace based mindfulness practice and inflammation: A randomized trialOpen hearts build lives: Positive emotions, induced through loving-kindness meditation, build consequential personal resources.The Effects of Mindfulness Meditation on Cognitive Processes and Affect in Patients with Past DepressionSystematic Review of the Efficacy of Meditation Techniques as Treatments for Medical IllnessEffectiveness of a meditation-based stress reduction program in the treatment of anxiety disordersThree-year follow-up and clinical implications of a mindfulness meditation-based stress reduction intervention in the treatment of anxiety disordersMindfulness-Based Stress Reduction for Health Care Professionals: Results From a Randomized Trial. A Randomized, Wait-List Controlled Clinical Trial: The Effect of a Mindfulness Meditation-Based Stress Reduction Program on Mood and Symptoms of Stress in Cancer OutpatientsLoving-kindness meditation increases socialx connectedness.Enhancing Compassion: A Randomized Controlled Trial of a Compassion Cultivation Training ProgramCompassion Training Alters Altruism and Neural Responses to SufferingMindfulness-Based Stress Reduction training reduces loneliness and pro-inflammatory gene expression in older adults: A small randomized controlled trialA randomized controlled trial of compassion cultivation training: Effects on mindfulness, affect, and emotion regulationCoherence Between Emotional Experience and Physiology: Does Body Awareness Training Have an Impact?The Brain&apos;s Ability to Look Within: A Secret to Self-MasteryThe underlying anatomical correlates of long-term meditation: Larger hippocampal and frontal volumes of gray matterMeditation experience is associated with increased cortical thicknessMindfulness training modifies subsystems of attentionInitial results from a study of the effects of meditation on multitasking performanceMental Training Affects Distribution of Limited Brain ResourcesMindfulness meditation improves cognition: Evidence of brief mental training","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"Summary and Table of Principles","date":"2017-01-19T15:32:18.000Z","path":"2017/01/19/MyShare/summary-and-table-of-principles/","text":"Principles —-译者：刘念 张帆” Principles 记录了Bridgewater创始人Ray Dalio对自己人生成功过程的反思，试图提供一套能通用的理念，帮助人们在生活中作出正确的选择。Ray Dalio，来自纽约中产之家，中年创建Bridgewater，2011年六十岁时Bridgewater成为世界上第一大对冲基金。 原则汇总列表 To Get the Culture Right…塑造良好的公司文化 … 1) Trust in truth. … 1) 相信真相 … 2) Realize that you have nothing to fear from truth. … 2) 你要知道，真相没什么可怕的。 … 3) Create an environment in which everyone has the right to understand what makes sense and no one has the right to hold a critical opinion withoutspeaking up about it. … 3) 创造这样一种氛围，只要是合理的事情，人人都能相互理解，没有人有权妄加批评，除非他能开诚布公地讲他的理由。 … 4) Be extremely open. … 4) 要极为开放。 … 5) Have integrity and demand it from others. … 5) 保持正直，要求别人也必须保持正直。 a) Never say anything about a person you wouldn’t say to them directly, and don’t try people without accusing them to their face. a) 若当面不对别人进行评论，背地里也不要说。若未曾当面控诉过别人，也不要背地里试探。 b) Don’t let “loyalty” stand in the way of truth and openness. b) 所谓的“忠诚”不能成为真相与开放的拦路虎。 … 6) Be radically transparent. … 6) 要极为透明。 a) Record almost all meetings and share them with all relevant people. a) 记录每一次会议，并分享给与之有关系的人。 … 7) Don’t tolerate dishonesty. … 7) 绝不容忍失信。 a) Don’t believe it when someone caught being dishonest says they have seen the light and will never do that sort of thing again. a) 不要相信失信之人说他已痛改前非，绝不再犯。 … 8) Create a Culture in which it is oK to make mistakes but unacceptable Not to identify, Analyze, and Learn From Them … 8) 创造这样一种文化：容许犯错，并从错误中进行识别、分析、吸取教训。 … 9) Recognize that effective, innovative thinkers are going to make mistakes … 9）要意识到处事高效创新的思考者都会犯错。 … 10) Do not feel bad about your mistakes or those of others. Love them! … 10）不要为自己或别人犯的错而郁郁寡欢，要热爱这些错！ … 11) Observe the patterns of mistakes to see if they are a product of weaknesses. … 11）仔细观察所犯错误的模式，看看它们是不是自身缺点所导致。 … 12) Do not feel bad about your weaknesses or those of others. … 12）不要因为自己或别人的缺点而感到糟糕。 … 13) Don’t worry about looking good - worry about achieving your goals. … 13）别老担心面子上过不过得去，而要担心是否会影响目的的实现。 … 14) Get over “blame” and “credit” and get on with “accurate” and “inaccurate.” … 14）别去管“责备”或“赞扬”，要习惯关注错误的归因是“精准”还是“不精准”。 … 15) Don’t depersonalize mistakes. … 15）错误归因要具体到个人。 … 16) Write down your weaknesses and the weaknesses of others to help remember and acknowledge them. … 16）写下你和别人的缺点，帮助自己牢记并承认这些缺点。 … 17) When you experience pain, remember to reflect. … 17）若因犯了错而感到痛苦，记得要反省。 … 18) Be self-reflective and make sure your people are self-reflective. … 18）要自我反思，也确保你身边的朋友们也都是懂得自我反思的。 … 19) Teach and reinforce the merits of mistake-based learning. … 19）教导和强化基于错误学习的优点。 a) The most valuable tool we have for this is the issues log (explained fully later) , which is aimed at identifying and learning from mistakes. a) 最有效的工具是建立“问题日志”（下文中将详述），旨在鉴别问题，并从中吸取教训。 …20) Constantly Get in Synch. …20）不断争取意见统一。 … 21) Constantly get in synch about what is true and what to do about it. … 21）要去伪存真，争取在解决方案上的意见统一。 … 22) Talk about “Is it true?” and “Does it make sense?” … 22）讨论“这是对的么？”和“这事有意义么？” … 23) Fight for right. … 23）认为对的事情，要据理力争。 … 24) Be assertive and open-minded at the same time. … 24）既要立场坚定，也要保持兼容并蓄。 a) Ask yourself whether you have earned the right to have an opinion. a) 问问自己，是否拥有发表观点的权利。 b) Recognize that you always have the right to have and ask questions. b) 要知道自己始终拥有提问的权利。 c) Distinguish open-minded people from closed-minded people. c) 区分思维开放的人和思想保守的人。 d) Don’t have anything to do with closed-minded, inexperienced people. d) 思想保守、缺乏经验之人，还是敬而远之吧。 e) Be wary of the arrogant intellectual who comments from the stands without having played on the field. e) 谨防纸上谈兵、夸夸其谈的人。 f) Watch out for people who think it’s embarrassing not to know. f) 谨防那些不知为耻的人。 … 25) Make sure responsible parties are open-minded about the questions and comments of others. … 25）确保主要责任方对于他人提出的问题与评论都是持开放态度的。 … 26) Recognize that conflicts are essential for great relationships because they are the means by which people determine whether their principles are alignedand resolve their differences. … 26）要意识到，冲突对于建立重要关系是大有裨益的，因为通过冲突人们才能确定对方的原则是否与自己的一致，便于化解分歧。 a) Expect more open-minded disagreements at Bridgewater than at most other firms. a) 在桥水联合基金公司里，要期待比其他公司更多的不拘于成见的分歧。 b) There is giant untapped potential in disagreement, especially if the disagreement is between two or more thoughtful people b) 分歧中蕴含巨大潜力，尤其对于两个有想法的人之间的分歧而言，更是如此。 … 27) Know when to stop debating and move on to agreeing about what should be done. … 27）知道什么时候终止辩论，进而讨论一致的解决方案。 a) However, when people disagree on the importance of debating something, it should be debated. a) 当有人质疑就某事展开辩论的重要性时，辩论是有必要的。 b) Recognize that “there are many good ways to skin a cat.” b) “办法总比问题多”。 c) For disagreements to have a positive effect, people evaluating an individual decision ordecision-maker must view the issue within a broader context. c) 要想通过分歧获得积极的结果，评估个人抉择或决策者的观点时需要树立大局观。 d) Distinguish between 1) idle complaints and 2) complaints that are meant to lead to improvement. d) 要区分两个概念：1）无用的抱怨 2）旨在实现改善的合理诉求。 … 28) Appreciate that open debate is not meant to create rule by referendum. … 28）赞赏开放式辩论的讨论方式并不意味着要通过全体投票来制定规则。 … 29) Evaluate whether an issue calls for debate, discussion, or teaching. … 29）要评估事项是否需要辩论、讨论或传授。 a) To avoid confusion, make clear which kind of conversation (debate, discussion, or teaching) you are having a) 为了避免产生误解，需要确定使用何种沟通方式（辩论、讨论或传授）。 b) Communication aimed at getting the best answer should involve the most relevant people. b) 旨在获得最佳方案的沟通，应该邀请最相关的人参与其中。 c) Communication aimed at educating or boosting cohesion should involve a broader set of people than would be needed if the aim were just getting the best answer. c) 旨在教育，增强凝聚力的沟通，如果目标是获取最优解决方案，那么就应该听取更多人的意见。 d) Leverage your communication. d) 充分利用各种沟通手段。 … 30) Don’t treat all opinions as equally valuable. … 30) 不要对所有的观点一视同仁。 a) A hierarchy of merit is not only consistent with a meritocracy of ideas but essential forit. a) 能力层级不仅需要与观点优先原则相一致，更是后者的必然要求。 … 31) Consider your own and others’ “believabilities.” … 31）思考自己和别人的可信度。 a) Ask yourself whether you have earned the right to have an opinion. a) 问问自己，是否拥有发表观点的权利。 b) People who have repeatedly and successfully accomplished the thing in question andhave great explanations when probed are most believable. b) 若有人多次成功解决悬而未决的问题，面对质疑也能讲得头头是道，这种人的观点最可信。 c) If someone asks you a question, think first whether you’re the responsible party/rightperson to be answering the question. c) 如果有人问你一个问题，首先要考虑自己是不是能够解答这个问题的人。 … 32) Spend lavishly on the time and energy you devote to “getting in synch”because it’s the best investment you can make. … 32）为了“意见统一”，花再多的时间与精力都不为过，因为这是最有价值的投资。 … 33) If it is your meeting to run, manage the conversation. … 33）如果是你主持会议，请协调好会议中各方的讨论。 a) Make it clear who the meeting is meant to serve and who is directing the meeting. a) 弄清会议的服务方和主持方。 b) Make clear what type of communication you are going to have in light of the objectivesand priorities. b) 根据会议目标与重点议题，确定会议的交流方式。 c) Lead the discussion by being assertive and open-minded. c) 主持讨论要坚定自信，开诚布公。 d) A small group (3 to 5) of smart, conceptual people seeking the right answers in anopen-minded way will generally lead to the best answer. d) 组织三至五人的小组讨论，邀请思维灵活、概念清晰的成员开放地寻求最佳方案，这种情况一般能取得最好的效果。 e) 1+1=3. f) Navigate the levels of the conversation clearly. f) 要明确讨论的层次的方向。 g) Watch out for “topic slip.” g) 注意不要让讨论偏题。 h) Enforce the logic of conversations. h) 增强沟通的逻辑性。 i) Worry about substance more than style. i) 实质内容比形式更重要。 j) Achieve completion in conversations. j) 在讨论中要得出一定结论。 k) Have someone assigned to maintain notes in meetings and make sure follow-throughhappens. k) 安排人做会议纪要，保证会议讨论的事项后续落实。 l) Be careful not to lose personal responsibility via group decision-making. l) 需要注意的是，集体决策时不要忘记了个人的职责。 … 34) Make sure people don’t confuse their right to complain, give advice, anddebate with the right to make decisions. … 34）不要将控诉、献言献策、辩论的权利同抉择权混为一谈。 … 35) Recognize that getting in synch is a two-way responsibility. … 35）要认识到，达成意见统一是双向责任。 … 36) Escalate if you can’t get in synch. … 36）如果意见无法统一，提交上级进行讨论。 To Get the People Right… 选对人，用对人 … 37) Recognize the Most Important Decisions You Make Are Who You Choose toBe Your Responsible Party … 37）要知道，最重要的选择是选谁做负责人。 … 38) Remember that almost everything good comes from having great peopleoperating in a great culture. …38）要记住，几乎所有的成功都是来自优秀的文化以及在其中工作的优秀的人才。 … 39) First, match the person to the design. … 39）首先，要选择合适的人参与规划。 a) Most importantly, find people who share your values. a) 最为重要的是要找同你价值观一致的人。 b) Look for people who are willing to look at themselves objectively and have character. b) 要找愿意客观评价自己且有自身性格特点的人。 c) Conceptual thinking and common sense are required in order to assign someone theresponsibility for achieving goals (as distinct from tasks) . c) 根据需要完成任务和实现目标，选择具备相关概念性思维和常识的人履职尽责。 … 40) Recognize that the inevitable responsible party is the person who bears theconsequences of what is done. … 40）必然责任人是需要承担一切后果的。 … 41) By and large, you will get what you deserve over time. … 41）总的来说，日积月累，你会得到你应得的。 … 42) The most important responsible parties are those who are most responsible forthe goals, outcomes, and machines (they are those higher in the pyramid) . … 42）最重要的责任人要为目标、结果和组织机构负主要责任（即位于组织里的上层的人）。 … 43) Choose those who understand the difference between goals and tasks to runthings. … 43）选择那些明白“目标”与“任务”之间差异的人来做事。 …44) Recognize that People Are Built Very Differently …44) 要知道每个人生来和后天塑造都是不同的。 … 45) Think about their very different values, abilities, and skills. … 45）考虑他们在价值观、能力和技能上的差异。 … 46） Understand what each person who works for you is like so that you know whatto expect from them. … 46）要了解你每个员工的情况，才能知道你能在他们身上有何种期待。 … 47) Recognize that the type of person you fit in the job must match therequirements for that job. … 47）岗位用人要与职位要求相匹配。 … 48) Use personality assessment tests and quality reflections on experiences tohelp you identify these differences. … 48）通过性格测试以及员工工作经历中反映的性格特点来帮助自己了解他们之间的差异。 … 49) Understand that different ways of seeing and thinking make people suitable fordifferent jobs. … 49）要知道，每个人的观察与思考方式不同，因此适合的职位也不同。 a) People are best at the jobs that require what they do well. a) 人们在所擅长的领域工作表现最佳。 b) If you’re not naturally good at one type of thinking, it doesn’t mean you’re precludedfrom paths that require that type of thinking b) 若你天生不擅长某种思维方式，并不意味着就做不好需要这种思维方式的工作。 … 50) Don’t hide these differences. Explore them openly with the goal of figuring outhow you and your people are built so you can put the right people in the rightjobs and clearly assign responsibilities. … 50）不要隐藏这些差异，坦诚沟通，以深入了解自己和员工，把合适的人用在合适的岗位上，并明确任务分工。 … 51) Remember that people who see things and think one way often have difficultycommunicating and relating to people who see things and think another way. … 51）要记住，看待事物与思维方式不同的人，在交流和相处上是存在困难的。 … 52) Hire Right, Because the Penalties of Hiring Wrong Are Huge … 52）雇佣对的人，用错了人，代价会极为惨重。 … 53) Think through what values, abilities, and skills you are looking for. … 53) 仔细审度自己想要的员工应具备什么样的价值观、能力和技能。 … 54) Weigh values and abilities more heavily than skills in deciding whom to hire. … 54）招聘员工时，要多考虑员工的价值观与能力，这比技能更重要。 … 55) Write the profile of the person you are looking for into the job description. … 55）招聘员工时，在岗位说明里描述希望招到一个什么样的员工。 … 56) Select the appropriate people and tests for assessing each of these qualitiesand compare the results of those assessments to what you’ve decided isneeded for the job. … 56）挑选合适人选，根据相应工作岗位应具备的素质要求对他们进行考核评估，比对评估结果与素质要求。 a) Remember that people tend to pick people like themselves, so pick interviewers whocan identify what you are looking for. a) 要记住，人们往往倾向于选择和自己相似的人，因此应挑选那些了解自己想雇佣何种员工的人担任面试考官。 b) Understand how to use and interpret personality assessments. b) 要知道如何使用和解读性格测试。 c) Pay attention to people’s track records. c) 注意受聘者的过往业绩。 d) Dig deeply to discover why people did what they did. d) 深入挖掘，探寻他们过往行为的动机。 e) Recognize that performance in school, while of some value in making assessments,doesn’t tell you much about whether the person has the values and abilities you arelooking for. e) 要认识到，尽管学校表现在进行评估时有一定价值，但却不能体现应聘者是否具备你想要的价值观或能力。 f) Ask for past reviews. f) 要求提供过往业绩的评估。 g) Check references. g) 参考推荐信。 … 57) Look for people who have lots of great questions. … 57）寻找可提出好问题的员工。 … 58) Make sure candidates interview you and Bridgewater. … 58）确保应聘者对你和桥水联合基金也进行了面试。 … 59) Don’t hire people just to fit the first job they will do at Bridgewater; hire peopleyou want to share your life with. … 59）不要聘用那些只把桥水联合基金当做第一份工作的人，要用那些你愿意与之分享人生的人。 … 60) Look for people who sparkle, not just “another one of those.” … 60）要选熠熠生辉之人，而不是又一个平庸之辈。 … 61) Hear the click: Find the right fit between the role and the person. … 61）听到咔哒声：所需职位和聘用之人一定要匹配合适。 … 62) Pay for the person, not for the job. … 62）以人论酬，而不是以岗论酬。 … 63) Recognize that no matter how good you are at hiring, there is a high probabilitythat the person you hire will not be the great person you need for the job. … 63）要知道无论你在招聘人才方面有多在行，你所聘用的人选都很有可能不是岗位的最佳人选。 … 64) Manage as Someone Who Is Designing and Operating a Machine to Achieve the Goal … 64）像设计和运行一台机器一样做好管理工作，才能实现预期目标。 … 65) Understand the differences between managing, micromanaging, and notmanaging. … 65）明白管理、微观管理和不管理之间的区别。 a) Managing the people who report to you should feel like “skiing together.” a) 管理下属应该感觉像是一同滑雪一样。 b) An excellent skier is probably going to be more critical and a better critic of anotherskier than a novice skier. b) 优秀的滑雪者更能挑出对方的毛病，这是初学者很难做到的。 … 66) Constantly compare your outcomes to your goals. … 66）不断比较完成情况和目标之间的差距。 … 67) Look down on your machine and yourself within it from the higher level. … 67）在所管理的机制内，从更高层次审视自己和机制。 … 68) Connect the case at hand to your principles for handling cases of that type. … 68）解决问题要参照同类别问题解决时所遵循的原则。 … 69) Conduct the discussion at two levels when a problem occurs: 1) the “machine”level discussion of why the machine produced that outcome and 2) the “caseat hand” discussion of what to do now about the problem. … 69）问题出现时，要展开两个层面的讨论：1）从机制层面来讨论，为什么会出现这个问题？2）单从问题本身层面来讨论，当下应如何解决。 … 70) Don’t try to be followed; try to be understood and to understand others. … 70）和员工的关系不是服从与被服从，而应是相互理解。 a) Don’t try to control people by giving them orders. a) 不要给员工下命令控制他们。 b) Communicate the logic and welcome feedback. b) 沟通要有逻辑，多听取反馈意见。 … 71) Clearly assign responsibilities. … 71）明确责任分工。 … 72) Hold people accountable and appreciate them holding you accountable. … 72）对员工进行工作问责制度，若他们问责你，要感谢他们。 a) Distinguish between failures where someone broke their “contract” from ones where there was no contract to begin with. a) 要分清楚，有些工作上的失败是因为员工没履行一开始的“约定”，而有些则是因为一开始就没有指定“约定”。 … 73) Avoid the “sucked down” phenomenon. … 73）避免“上级卷入下级工作职责”现象 a) Watch out for people who confuse goals and tasks, because you can’t trust people with responsibilities if they don’t understand the goals. a) 提防那些混淆目标与任务的员工，不能理解工作目标的员工是不值得信任的。 … 74) Think like an owner, and expect the people you work with to do the same. … 74）要有主人翁思维，并希望员工们也能具备这种思维方式。 … 75) Force yourself and the people who work for you to do difficult things. … 75）强迫自己和员工迎难而上。 a) Hold yourself and others accountable. a) 对自己和他人要采取问责制度。 … 76) Don’t worry if your people like you; worry about whether you are helping your people and Bridgewater to be great. … 76）别担忧员工喜不喜欢你，还是多想想自己所做的事情能不能帮员工和桥水联合基金获得成功吧。 … 77) Know what you want and stick to it if you believe it’s right, even if others want to take you in another direction. … 77）知道自己想要什么，坚信自己认为的是正确的事情，不要轻易被人牵着鼻子走。 … 78) Communicate the plan clearly. … 78）计划沟通要清晰明了。 a) Have agreed-upon goals and tasks that everyone knows (from the people in the departments to the people outside the departments who oversee them) . a) 已达成共识的目标任务要让所有相关人士都知道。（包括有关部门的员工及监管层的领导） b) Watch out for the unfocused and unproductive “we should … (do something) .” b) 要警惕交流中出现没有重点，低效无用的句式：我们应该如何。 … 79) Constantly get in synch with your people. … 79）保持与员工意见统一。 … 80) Get a “threshold level of understanding” … 80）充分了解工作相关情况。 … 81) Avoid staying too distant. … 81）避免和员工产生距离感。 a) Tool: Use daily updates as a tool for staying on top of what your people are doing and thinking. a) 工具：使用每日进度更新了解员工工作与思考的情况。 … 82) Learn confidence in your people—don’t presume it. … 82）对员工的信任度不能先入为主，要逐步去了解。 … 83) Vary your involvement based on your confidence. … 83）处理问题时，根据自己感觉有把握的情况来调整参与度。 … 84) Avoid the “theoretical should.” … 84）避免说“理论上应该”。 … 85) Care about the people who work for you. … 85）关爱员工。 … 86) Logic, reason, and common sense must trump everything else in decision-making. … 86）决策中最重要的是讲究逻辑、给明理由且符合常识。 … 87) While logic drives our decisions, feelings are very relevant. … 87）尽管做决策时主要依靠逻辑，但情感感觉也是很重要的。 … 88) Escalate when you can’t adequately handle your responsibilities, and make sure that the people who work for you do the same. … 88）如果发现自己无法有效解决问题时，应将问题提交给上级，确保为你工作的员工们也是这样操作的。 a) Make sure your people know to be proactive. a) 确保员工主动积极。 b) Tool: An escalation button. b) 工具：升级按钮。 … 89) Involve the person who is the point of the pyramid when encountering material cross-departmental or cross sub-departmental issues. … 89）跨部门间或跨子部门间出现问题时，需要上级部门，也就是这个组织的“金字塔尖”的那个人来参与定夺。 … 90) Probe Deep and Hard to Learn What to Expect from Your “Machine” … 90) 认真深入调查，了解机制能够创造什么。 … 91) Know what your people are like, and make sure they do their jobs excellently. … 91) 了解自己的员工，确保他们顺利完成工作。 … 92) Constantly probe the people who report to you, and encourage them to probe you. … 92) 不断调查直接向你汇报的下级，并鼓励他们调查你。 a) Remind the people you are probing that problems and mistakes are fuel for improvement. a) 提醒你调查的员工，问题和错误是改进的动力。 … 93) Probe to the level below the people who work for you. … 93) 调查你属下的下级。 … 94) Remember that few people see themselves objectively, so it’s important to welcome probing and to probe others. … 94) 记住，只要极少人能够客观地看待自己。因此，你应该欢迎调查，同时要去调查别人。 … 95) Probe so that you have a good enough understanding of whether problems are likely to occur before they actually do. … 95) 调查有助于你在问题出现之前充分了解其出现的可能性。 a) When a crisis appears to be brewing, contact should be so close that it’s extremely unlikely that there will be any surprises. a) 如果说有迹象显示危机正在酝酿，那么你就应该保持密切关注，就能在其发生之时没有任何惊讶。 b) Investigate and let people know you are going to investigate so there are no surprises and they don’t take it personally. b) 调查情况的时候要告诉被调查的人，不要让被调查的人措手不及，让他们知道你是对事不对人。 … 96) Don’t “pick your battles.” Fight them all. … 96) 不要挑肥拣瘦，要解决所有问题。 … 97) Don’t let people off the hook. … 97) 不要让人逃避责任。 … 98) Don’t assume that people’s answers are correct. … 98) 不要想当然地认为人们的答案都是正确的。 … 99) Make the probing transparent rather than private. … 99) 将调查透明化，不要私下进行。 … 100) Evaluate People Accurately, Not “Kindly” … 100) 准确地，而不是善意地评估员工。 … 101) Make accurate assessments. … 101) 进行准确评估。 a) Use evaluation tools such as performance surveys, metrics, and formal reviews to document all aspects of a person’s performance. These will help clarify assessments and communication surrounding them. a) 使用各种评估工具来记录员工全方位表现，包括工作表现调查问卷、计量图表、正式评估报告。这些工具能够帮助你将员工的相关评估和沟通整理清楚。 b) Maintain “baseball cards” and/or “believability matrixes” for your people. b) 为员工建立“棒球记录卡”以及“可信度图表”。 … 102) Evaluate employees with the same rigor as you evaluate job candidates. … 102) 以同等的严厉程度来评价员工、雇佣新人。 … 103) Know what makes your people tick, because people are your most important resource. … 103) 充分了解员工的特质，因为人才是最重要的资源。 … 104) Recognize that while most people prefer compliments over criticisms, there is nothing more valuable than accurate criticisms. … 104) 要认识到，尽管大多数人都喜欢被表扬，不喜欢被批评，但准确的批评却是最宝贵的。 … 105) Make this discovery process open, evolutionary, and iterative. … 105) 将这一发现过程公开，循环往复，促其演变。 … 106) Provide constant, clear, and honest feedback, and encourage discussion of this feedback. … 106) 提供频繁的、清楚的、诚实的反馈，并鼓励就这些反馈进行讨论。 a) Put your compliments and criticisms into perspective. a) 正确对待表扬与批评。 b) Remember that convincing people of their strengths is generally much easier than convincing them of their weaknesses. b) 记住，让别人看到自己的长处通常比让他们看到自己的短处要容易得多。 c) Encourage objective reflection c) 鼓励客观的反思。 d) Employee reviews: d) 员工评估报告: … 107) Understand that you and the people you manage will go through a process of personal evolution. … 107) 你以及你管理的人都会经历个人成长的过程。 … 108) Recognize that your evolution at Bridgewater should be relatively rapid and a natural consequence of discovering your strengths and weaknesses; as a result, your career path is not planned at the outset … 108) 要认识到，你在桥水基金的成长会相对较快，这是了解自己优缺点的必然结果。因此，你的职业规划不是在一开始就定下来的。 … 109) Remember that the only purpose of looking at what people did is to learn what they are like. … 109) 要记住，了解员工的过去是为了了解他们的特质。 a) Look at patterns of behaviors and don’t read too much into any one event. a) 关注行为模式，但不要过分解读任何单一事件。 b) Don’t believe that being good or bad at some things means that the person is good or bad at everything. b) 不要认为擅长（或不擅长）某件事的人就一定对所有的事都擅长（或不擅长）。 … 110) If someone is doing their job poorly, consider whether this is due to inadequate learning (i.e., training/experience) or inadequate ability … 110) 如果某人工作做得很差劲，要去想这是因为缺少学习（培训或相关经验）还是因为缺少能力。 … 111) Remember that when it comes to assessing people, the two biggest mistakes are being overconfident in your assessment and failing to get in synch on that assessment. Don’t make those mistakes. … 111) 记住，在评估员工时最常犯的两个错误是：对于评估结果过于自信；对于评估结果意见无法达成一致。不要犯这两个错误。 a) Get in synch in a non-hierarchical way regarding assessments. a) 针对评估争取意见一致时，要以非等级的方式来进行。 b) Learn about your people and have them learn about you with very frank conversations about mistakes and their root causes. b) 通过开展坦诚对话，讨论错误以及犯错的根源，来了解彼此。 … 112) Help people through the pain that comes with exploring their weaknesses. … 112) 帮助人们渡过发现缺点的阵痛期。 … 113) Recognize that when you are really in synch with people about weaknesses, whether yours or theirs, they are probably true. … 113) 要认识到，如果你就某人的弱点达成一致，不管是你的还是其他人的，这个弱点多半是事实。 … 114) Remember that you don’t need to get to the point of “beyond a shadow of a doubt” when judging people. … 114) 记住，在评价员工时，并不需要达到“不含一丝质疑”的程度。 … 115) Understand that you should be able to learn the most about what a person is like and whether they are a “click” for the job in their first year. … 115) 要知道，你是能够了解一个人的大部分特质的，也能够在他们第一年来时判断他们是否能够胜任工作。 … 116) Continue assessing people throughout their time at Bridgewater. … 116) 员工在桥水联合基金工作期间，持续对员工进行评估。 … 117) Train and Test People Through Experiences … 117) 通过实战经验来培训、测试员工。 … 118) Understand that training is really guiding the process of personal evolution. … 118) 要知道，培训对个人的成长过程起着指引作用。 … 119) Know that experience creates internalization … 119) 经验能够内化成为知识。 … 120) Provide constant feedback to put the learning in perspective … 120) 正确对待学习，频繁提供反馈。 … 121) Remember that everything is a case study. … 121) 要记住，每件事都是一个案例 … 122) Teach your people to fish rather than give them fish. … 122) 授人以鱼不如授人以渔。 … 123) Recognize that sometimes it is better to let people make mistakes so that they can learn from them rather than tell them the better decision. … 123) 要认识到，有时让人犯错并从中吸取教训要比直接告诉他们一个更好决定更明智。 a) When criticizing, try to make helpful suggestions. a) 在批评时，要提一些有建设性的意见。 b) Learn from success as well as from failure. b) 从成功中学习，也要从失败中学习。 … 124) Know what types of mistakes are acceptable and unacceptable, and don’t allow the people who work for you to make the unacceptable ones. … 124) 分清哪些错误是可以接受的，哪些是不能接受的。不要让员工犯不可接受的错误。 … 125) Recognize that behavior modification typically takes about 18 months of constant reinforcement. … 125) 要认识到，一般需要18个月持续不断的巩固才能实现行为矫正。 … 126) Train people; don’t rehabilitate them. … 126) 培训员工，而不是改造员工。 a) A common mistake: training and testing a poor performer to see if he or she can acquire the required skills without simultaneously trying to assess their abilities. a) 常见错误：在没有对一个工作表现差的员工进行能力评估之前，培训、测试该员工，试图让他获得所需技能。 … 127) After you decide “what’s true” (i.e., after you figure out what your people are like) , think carefully about “what to do about it.” … 127) 在找到真相之后（即了解到员工的真实情况），谨慎思考下一步该做什么。 … 128) Sort People into Other Jobs at Bridgewater, or Remove Them from Bridgewater … 128) 在桥水基金内部进行换岗，或将其解雇。 … 129) When you find that someone is not a good “click” for a job, get them out of it ASAP. … 129) 一旦发现某人不能胜任工作，尽快将其调离该职位。 … 130) Know that it is much worse to keep someone in a job who is not suited for it than it is to fire someone. … 130) 勉强将某人留在不合适的职位上要比将其开除更糟糕。 … 131) When people are “without a box,” consider whether there is an open box at Bridgewater that would be a better fit. If not, fire them. … 131) 当员工没有岗位时，思考桥水公司内部是否还有更适合的岗位。如果没有，应该将该员工开除。 … 132) Do not lower the bar. … 132) 不要降低标准。 To Perceive, Diagnose, and Solve Problems… 发现、诊断、解决问题 … 133) Know How to Perceive Problems Effectively … 133) 懂得如何有效地发现问题 … 134) Keep in mind the 5-Step Process explained in Part 2. … 134) 时刻牢记在第二部分阐释过的五步流程。 … 135) Recognize that perceiving problems is the first essential step toward great management. … 135) 要认识到，发现问题是优秀管理的第一步。 … 136) Understand that problems are the fuel for improvement. … 136) 要理解，问题是提升的动力。 … 137) You need to be able to perceive if things are above the bar (i.e., good enough) or below the bar (i.e., not good enough) , and you need to make sure your people can as well … 137) 你需要观察事情是在预期之上还是在预期之下，确保你的员工也有此观察力。 … 138) Don’t tolerate badness. … 138) 不要容忍问题。 … 139) “Taste the soup.” … 139) “品尝汤的味道”。 … 140) Have as many eyes looking for problems as possible. … 140) 找尽可能多的人手来一起发现问题。 a) “Pop the cork.” a) “拔出瓶塞。” b) Hold people accountable for raising their complaints. b) 将投诉作为员工义务来进行。 c) The leader must encourage disagreement and be either impartial or open-minded. c) 领导者必须鼓励提出不同的意见，不偏不倚，思想开放。 d) The people closest to certain jobs probably know them best, or at least have perspectives you need to understand, so those people are essential for creating improvement. d) 与某项工作接触最密切的人应该最了解该项工作，或者至少有值得你借鉴的观点。因此，这些人对于促进提升是很重要的。 … 141) To perceive problems, compare how the movie is unfolding relative to your script … 141) 参照你的剧本，比较电影情节的发展，通过这种方式来发现问题。 … 142) Don’t use the anonymous “we” and “they,” because that masks personal responsibility—use specific names. … 142) 不要使用模糊的人称，如“我们”或“他们”，这样做会掩盖个人责任。请使用具体人名。 … 143) Be very specific about problems; don’t start with generalizations. … 143) 具体问题要具体对待，不要一开始就过于宽泛。 … 144) Tool: Use the following tools to catch problems: issues logs, metrics, surveys, checklists, outside consultants, and internal auditors. … 144) 工具：使用以下工具来捕捉问题：问题日志、计量图表、调查问卷、清单、外部咨询，以及内部审计。 … 145) The most common reason problems aren’t perceived is what I call the “frog in the boiling water” problem. … 145) 最常见的无法观察到原因的问题是被称为“温水煮青蛙”的问题。 … 146) In some cases, people accept unacceptable problems because they are perceived as being too difficult to fix. Yet fixing unacceptable problems is actually a lot easier than not fixing them, because not fixing them will make you miserable. … 146) 在某些情况下，因为某些问题实在难以解决，人们不得不接受那些不可接受的问题。但是，解决那些不可接受的问题其实要比不解决它们更容易，因为不解决它们，将后患无穷。 a) Problems that have good, planned solutions are completely different from those that don’t. a) 已经拥有有效周密的解决方案的问题与那些没有解决方案的问题天差地别。 … 147) Diagnose to Understand What the Problems Are Symptomatic Of … 147) 通过诊断分析来理解问题症结所在 … 148) Recognize that all problems are just manifestations of their root causes, so diagnose to understand what the problems are symptomatic of. … 148) 要认识到所有问题只是其根本原因的表征，所以要通过诊断分析来理解问题症结所在。 … 149) Understand that diagnosis is foundational both to progress and quality relationships. … 149) 要明白诊断分析是发展公司和建立良好人际关系的基础。 … 150) Ask the following questions when diagnosing. … 150) 诊断分析时要问自己以下几个问题。 … 151) Remember that a root cause is not an action but a reason. … 151) 要谨记根本原因不是行为而是原因。 … 152) Identify at which step failure occurred in the 5-Step Process. … 152) 找出五步流程中哪一步失败了。 … 153) Remember that a proper diagnosis requires a quality, collaborative, and honest discussion to get at the truth. … 153) 要做好诊断分析，需要深入讨论，共同协作，态度诚恳，只有这样才能触及问题真相。 … 154) Keep in mind that diagnoses should produce outcomes. … 154) 要记得诊断分析应该出结果。 … 155) Don’t make too much out of one “dot”—synthesize a richer picture by squeezing lots of “dots” quickly and triangulating with others. … 155) 不要试图从一个“点”中获取大量信息，而应该快速压榨大量的“点”，并将它们相互联结，从而形成更丰富的图像。 … 156) Maintain an emerging synthesis by diagnosing continuously… 156) 要进行持续性的诊断分析，整合新思路。 … 157) To distinguish between a capacity issue and a capability issue, imagine how the person would perform at that particular function if they had ample capacity. … 157) 要区别才能问题和能力问题，就去想象如果一个人有足够的才能，那他在这个特定职能上的表现会是如何。 … 158) The most common reasons managers fail to produce excellent results or escalate are … 158) 管理者绩效不佳或未能升职最常见的原因有： … 159) Avoid “Monday morning quarterbacking.” … 159) 不要做事后诸葛。 … 160) Identify the principles that were violated. … 160) 找出违背了哪些原则。 … 161) Remember that if you have the same people doing the same things, you should expect the same results. … 161) 要记得如果你让同样的人做同样的事，那么得到的也应该是同样的结果。 … 162) Use the following “drilldown” technique to gain an 80/20 understanding of a department or sub-department that is having problems. … 162) 运用下述的“钻取”方法，重点理解部门或分部面临的问题。 … 163) Put Things in Perspective … 163）理清思维 … 164) Go back before going forward. … 164) 前进之前请先回顾。 a) Tool: Have all new employees listen to tapes of “the story” to bring them up to date. a) 方法：让所有新员工听“故事”磁带，帮助他们了解公司截止到目前的发展状况。 … 165) Understand “above the line” and “below the line” thinking and how to navigate between the two. … 165）理解“宏观”和“微观”的思维模式及其适用范围。 … 166) Design Your Machine to Achieve Your Goals … 166) 设定机制，达成目标 … 167) Remember: You are designing a “machine” or system that will produce outcomes. … 167）要记得：你是在设定一个能够有产出的“机制”或系统。 a) A short-term goal probably won’t require you to build a machine. a) 短期目标可能不需要你设立机制。 b) Beware of paying too much attention to what is coming at you and not enough attention to what your responsibilities are or how your machine should work to achieve your goals. b) 注意不要太过关注你眼前的问题，而忽视了你的职责，以及机制怎样运行并达成目标。 … 168) Don’t act before thinking. Take the time to come up with a game plan … 168）三思而后行。花点时间做计划。 … 169) The organizational design you draw up should minimize problems and maximize capitalization on opportunities. … 169）你拟出的组织设计应该能最小化问题，最大化机会。 … 170) Put yourself in the “position of pain” for a while so that you gain a richer understanding of what you’re designing for. … 170) 将自己体会一段时间的“痛点”，你就会更理解自己的设定针对的是什么样的对象。 … 171) Recognize that design is an iterative process; between a bad “now” and a good “then” is a “working through it” period. … 171) 要认识到，机构设置是一个循环往复的过程，在一个糟糕的“现在”和一个美好的“未来”之间，是“努力实现”的过程。 … 172) Visualize alternative machines and their outcomes, and then choose. … 172) 将可替代的其他机制及其成果形象化，以供选择。 … 173) Think about second- and third-order consequences as well as first-order consequences. … 173) 思考二、三级效应与一级效应。 … 174) Most importantly, build the organization around goals rather than tasks. … 174) 以目标为中心建立机构，而不是以任务为中心，这是重中之重。 a) First come up with the best workflow design, sketch it out in an organizational chart, visualize how the parts interact, specify what qualities are required for each job, and, only after that is done, choose the right people to fill the jobs. a) 首先，设计最佳工作流，在一个组织图中画出草图，将各部分互动情况形象化，标出每个职位所需的特质，最后，选择合适的员工来填充岗位 (根据他们的能力和意愿来进行需求匹配) 。 b) Organize departments and sub-departments around the most logical groupings. b) 按照最富逻辑的组团方式来组建部门和子部门。 c) Make departments as self-sufficient as possible so that they have control over the resources they need to achieve the goals. c) 让每个部门尽可能的自给自足，以此确保他们能够自主控制达成目标所需的资源。 d) The efficiency of an organization decreases and the bureaucracy of an organization increases in direct relation to the increase in the number of people and/or the complexity of the organization. d) 公司效率的下降与官僚作风的扩张程度与公司人数增长和复杂性提升直接相关。 … 175) Build your organization from the top down. … 175) 自上而下组建公司。 a) Everyone must be overseen by a believable person who has high standards. a) 应该给每名员工安排一位拥有高标准的靠谱的人，负责对其进行监管。 b) The people at the top of each pyramid should have the skills and focus to manage their direct reports and a deep understanding of their jobs. b) 位于金字塔尖的管理者应该具备管理直接下属的能力和精力，对下属的工作职责有深入的了解。 c) The ratio of senior managers to junior managers and to the number of people who work two levels below should be limited, to preserve quality communication and mutual understanding. c) 高级管理者与初级管理者、管理者与两级以下的被管理者之间的人数比例应该限定在一定范围内，以确保高质量的沟通与互相理解。 d) The number of layers from top to bottom and the ratio of managers to their direct reports will limit the size of an effective organization. d) 自上而下的层级数量以及管理者与直接下属的比例会制约高效公司的规模。 e) The larger the organization, the more important are 1) information technology expertise in management and 2) cross-department communication (more on these later) . e) 公司越大，越需要1）在管理中运用信息技术；2）跨部门沟通（后详）。 f) Do not build the organization to fit the people. f) 不要为了迁就人员而组建机构。岗位是基于所需完成的工作来设定的，而不是基于人们想要干什么事，能干什么事而设定。 … 176) Have the clearest possible delineation of responsibilities and reporting lines. … 176) 尽可能清楚地描述工作职责与级别关系。 a) Create an organizational chart to look like a pyramid, with straight lines down that don’t cross. a) 建立一个金字塔形的组织图，画出不相交的竖线 … 177) Constantly think about how to produce leverage. … 177) 经常思考该如何让事情发挥最大的效果。 a) You should be able to delegate the details away. a) 你应该将细节工作委派给他人。 b) It is far better to find a few smart people and give them the best technology than to have a greater number of ordinary and less well-equipped people. b) 与其让一众能力平庸之人获得不那么精良的装备，不如只给一小部分聪明人配备最好的技术。c) Use “leveragers.” c) 使用执行力强的人。 … 178) Understand the clover-leaf design.… 178) 理解四叶草形的机构设置。 … 179) Don’t do work for people in another department or grab people from another department to do work for you unless you speak to the boss. … 179) 不要为其他部门做事，也不要在没有和其他部门领导交涉的情况下从其他部门抓人来为你做事。 … 180) Watch out for “department slip.” … 180) 谨防“部门职能错位”。 … 181) Assign responsibilities based on workflow design and people’s abilities, not job titles. … 181) 在分配责任时，注意考虑工作流的设置和员工的能力，而不是岗位头衔。 … 182) Watch out for consultant addiction. … 182) 谨防过分依赖外部咨询。 … 183) Tool: Maintain a procedures manual. … 183) 工具：使用流程手册。 … 184) Tool: Use checklists. … 184) 工具：使用任务清单。 a) Don’t confuse checklists with personal responsibility. a) 不要将任务清单与个人责任混为一谈。 b) Remember that “systematic” doesn’t necessarily mean computerized. b) 记住，系统性并不意味着必须全部由电脑来控制。 c) Use “double-do” rather than “double-check” to make sure mission-critical tasks are done correctly. c) 要“重复工作”，不要“重复检查”，保证重要任务完成无误。 … 185) Watch out for “job slip.” … 185) 谨防“职责错位”。 … 186) Think clearly how things should go, and when they aren’t going that way, acknowledge it and investigate … 186) 考虑清楚工作应该如何开展，如果事情不是朝预期的方向发展，需要及时发现并展开调查。 … 187) Have good controls so that you are not exposed to the dishonesty of others and trust is never an issue. … 187) 加强监管，谨防他人的不诚实，使信任不再成为问题。 a) People doing auditing should report to people outside the department being audited, and auditing procedures should not be made known to those being audited. a) 审计人员应该向被审计部门之外的人汇报审计结果，同时审计程序不能向被审计对象透露。 b) Remember: There is no sense in having laws unless you have policemen (auditors) . b) 记住，如果没有警察（审计人员），法律则形同虚设。 … 188) Do What You Set Out to Do … 188) 按计划进行。 … 189) Push through! … 189) 坚持到底！ To Make Decisions Effectively… 有效决策 …190) Recognize the Power of Knowing How to Deal with Not Knowing …190) 认可处理无知的能力 … 191) Recognize that your goal is to come up with the best answer, that the probability of your having it is small, and that even if you have it, you can’t be confident that you do have it unless you have other believable people test you. … 191) 要认识到，你的目标是找到最佳答案，而找到最佳答案的可能性是很小的，就算你真的找到了，你也无法确信自己成功了，你必须让其他的靠谱的人来对你进行测试。 … 192) Understand that the ability to deal with not knowing is far more powerful than knowing … 192) 要知道，处理无知的能力要比知道某事的能力更强大。 a) Embrace the power of asking: “What don’t I know, and what should I do about it?” a) 鼓励提问：“有什么是我不知道的呢？那我该怎么办呢？” b) Finding the path to success is at least as dependent on coming up with the right questions as coming up with answers. b) 寻找成功的道路上，提出正确的问题与获得正确答案同等重要。 … 193) Remember that your goal is to find the best answer, not to give the best one you have. … 193) 记住，你的目标是寻找最佳答案，而不是在已有的答案中挑一个最好的。 … 194) While everyone has the right to have questions and theories, only believable people have the right to have opinions … 194) 每个人都有权拥有自己的问题和理论，但是只有靠谱的人才有权提出观点。 … 195) Constantly worry about what you are missing. … 195) 时刻警惕考虑不周的情况。 a) Successful people ask for the criticism of others and consider its merit. a) 成功人士会征求别人的批评意见，并看到批评的价值。 b) Triangulate your view. b) 吸收众人观点。 … 196) Make All Decisions Logically, as Expected Value Calculations … 196）做决定要讲逻辑，基于期望值测算 … 197) Considering both the probabilities and the payoffs of the consequences, make sure that the probability of the unacceptable (i.e., the risk of ruin) is nil. … 197）考虑结果的可能性与收益，确保不可接受结果（如搞砸的风险）的可能性为零。 a) The cost of a bad decision is equal to or greater than the reward of a good decision, so knowing what you don’t know is at least as valuable as knowing. a) 不良决策的代价等同于，甚至严重于正确决策带来的回报，因此，知道自己没掌握什么，至少和知道自己掌握什么一样有价值。 b) Recognize opportunities where there isn’t much to lose and a lot to gain, even if the probability of the gain happening is low. b) 鉴别出有亏少利多的机会，就算获利可能性低也要试试。 c) Understand how valuable it is to raise the probability that your decision will be right by accurately assessing the probability of your being right. c) 精准评估，提高决策的准确性十分有价值。 d) Don’t bet too much on anything. Make 15 or more good, uncorrelated bets. d) 任何事情都不能押过多赌注，要留15%或更多的余地给无关联的赌注。 … 198) Remember the 80/20 Rule, and Know What the Key 20% Is … 198）牢记80/20法则，并知道那关键的20%是什么。 … 199) Distinguish the important things from the unimportant things and deal with the important things first. … 199）区分重要事项和不重要事项，先处理重要事项。 a) Don’t be a perfectionist a) 不要做完美主义者。 b) Since 80% of the juice can be gotten with the first 20% of the squeezing, there are relatively few (typically less than five) important things to consider in making a decision. b) 压榨过程进行20%的时候就能得到80%的果汁，所以做决定时，最重要的事项是比较少的（一般少于五件）。 c) Watch out for “detail anxiety,” c) 警惕“细节焦虑”。 d) Don’t mistake small things for unimportant things, because some small things can be very important d) 不要混淆小事情和不重要事项，因为小事情也可能很重要。 … 200) Think about the appropriate time to make a decision in light of the marginal gains made by acquiring additional information versus the marginal costs of postponing the decision. … 200）要根据获取额外信息而取得的边际收益与延迟决定所造成的边际成本的比较与权衡，来思考合适的时间做出一个决定。 … 201) Make sure all the “must do’s” are above the bar before you do anything else. … 201）确保所有“必须完成的任务”在完成时优先于其他任何事情。 … 202) Remember that the best choices are the ones with more pros than cons, not those that don’t have any cons. Watch out for people who tend to argue against something because they can find something wrong with it without properly weighing all the pros against the cons. … 202）要记住，最佳选择是基于赞同意见多于反对意见的，当然不是说不允许任何反对意见。要警惕有人在不恰当权衡正反意见的基础上挑错，进而反对。 … 203) Watch out for unproductively identifying possibilities without assigning them probabilities, because it screws up prioritization. …203）要警惕在没有考虑所有可能性的情况下，就低效地确定其可能性，这样会打乱优先次序。 … 204) Understand the concept and use the phrase “by and large.” … 204）理解并运用“总体来说”的概念。 a) When you ask someone whether something is true and they tell you that “It’s not totally true,” it’s probably true enough. a) 当询问某事的真实性时，若对方告诉你“也不完全是事实”时，其实也八九不离十了。 … 205) Synthesize … 205）综合 … 206) Understand and connect the dots. … 206） 理解并串联关键点 … 207) Understand what an acceptable rate of improvement is, and that it is the level and not the rate of change that matters most. … 207）知道可接受的改善速度是多少，因为改变的程度比改变的速度更关键。 … 208) If your best solution isn’t good enough, think harder or escalate that you can’t produce a solution that is good enough. … 208）如果最佳方案不够令人满意，就得尽力想出更好的办法，实在想不到就提交给上级。 … 209) Avoid the temptation to compromise on that which is uncompromisable. … 209）经受住诱惑，避免让不可妥协的事情得到妥协。 … 210) Don’t try to please everyone … 210）不要试图让所有人都满意。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Management","slug":"Management","permalink":"http://ipcreator.me/tags/Management/"}]},{"title":"向死而生","date":"2017-01-19T11:02:06.000Z","path":"2017/01/19/MyShare/credits-of-death /","text":"李开复《向死而生：我修的死亡学分》 脱去虚名与成就，你的人生还剩下什么? 7 个学分 健康无价； 一切事物都是有它的理由； 珍惜缘分，学会感恩和爱； 学会如何生活，活在当下； 经得住诱惑； 人人平等，善待每一个人； 我们的人生究竟是为什么？ 李开复演讲实录： 谢谢各位，非常感谢今天各位嘉宾的到来。让我有这个机会跟大家分享一下我生病的心路路程。平时我工作的时候，非常热爱我的工作，包括今天，我从来没有想到，要面临死亡，面临癌症，我心中想过的每一个思念都和我的工作丝毫无关。有一个很著名的护士看护了很多临终病人，大部分的临终病人最大的遗憾就是没有和自己的家人在一起。 我们每个人都要临死才会想到这样的事情吗？我相信今天的纪录片和我出的书，能阐述我个人向死而生的过程。向死而生本身的意思，就是人在世俗里面很容易陷入今天的现实世界里面。而面对死亡，我们反而容易得到顿悟，了解生命的意义，让死亡成为生命旅程中无形的好友，温和提醒我们，好好珍惜我们的生命，不是只渡过每一天的日子，也不是只是追求一个现实的名利目标。 学分1：健康无价 在我平时的生活中，我热爱美食，不爱睡眠，认为睡眠是浪费时间，每天起来回E-mail，给我员工证明我工业多努力。生病以后，才深深体会到，其实健康失去了，就什么都没有了，生命最重要，健康和生命是一样重要的。 如果我们要维护自己的健康和生命，很多人会认为说，如果你养生，就没有事业了，什么都不要了，过退休的生活，过慢日子吧。我领悟以后，和几位朋友交流以后，其实真的不是这样的。每一个人的健康，其实不是要放弃一切。我们的健康如果简单来说，其实就是我们的睡眠、压力、运动、饮食。如果这 4 点达到即可，对年轻人来说。你是可以努力工作的，一个礼拜拿三四个小时维护你的健康，我非常希望在这里告诉大家要爱惜自己的健康，不要等到有一天，像我这样几乎后悔，几乎来不及才知道学会要爱惜自己的身体。 学分2：一切的事物都是有它的理由 我们往往把发生在自己身体的事情，一定做错了才惩罚我身上。其实不见得如此，世界的玄妙我们只了解里面的千分之一，万分之一，也许每一件事情的发生都有它的理由，我们应该多思考当一件事发生以后，是不是有什么正面的启示或者正面的力量。发生一个灾难，是不是不要把它当成一个果，而是把它当成因 ，如果把它当成因，任何的灾难都是学习的机会。如果我们生病了，是让我们学会生活更健康，也许我们无助的时候，让我们接受无法改变的事情。也许我们面临死亡才能教会我们分辨什么才是人生最重要的事情。 学分3：珍惜缘分，学会感恩和爱 一直面对死亡的时候，对于家人对我无私的爱，我当年是多么冷漠。虽然我告诉朋友说，我一放假就陪我们的母亲，但是我们只有 4 周的假。陪母亲 5 天以后，我就认为我的任务完成了。一直到我自己面临死亡的时候，我才知道，我是多么冷漠，我是以多么敷衍的方式表达了人们口中的孝顺。 我觉得真正改变应该有三个层次。最基本的是别人对你好，你感觉到了这是感恩，再稍微好一点的是别人对你好你要回报他。第三个层次就是主动不要求回报付出关怀，这才是最高的境界。这是我发现的，不知道过去做的什么好事，如果有上辈子，上辈子做了好事，有这样的家庭，我的父母、姐姐、妻子、女儿都是不要求回报的。无论我怎么对待他们，无论我是因为事业把家庭从美国搬来了中国又搬回美国，再搬回中国，又迁回台湾，整个过程对他们是多么煎熬，我只想做好我的事业。 有一句话，我觉得很有意义，每一次的相遇都是久别重逢，能和亲人在一起，他们能这样对我们，这不是猿猴演变出来的人类，就因为被教导，孔子说的亲情，我觉得这样的缘份，真的是久别之后的重逢，我们应该珍惜人生中的缘份和爱护。 所以我生病以后我就决定说，我要改变我的方式，每一周不但要陪我的妈妈，还要陪我的姐姐。我到了台湾，花更多的时间和我爱人在一起。我女儿要考大学，我帮她做各种准备。后来有一天她弄了一个刺青，刺了一个 try，这就是我没有付出足够教育方式的现象。然后她学业上升了也被大学录取了，然后又把 try 变成了 stay gold，我认为我自己是发光的黄金。也许我对父母的爱可能很难直接给他们回报，但是至少对妻子女儿，过去的 17 个月，我做的一些事情，也学会如何感恩，如何爱，如何直接表达。 父亲节的时候，我发了一条微博，是我女儿亲我的照片，我鼓励更多的孩子亲他们的父亲。我看他们的留言，很多女孩子说这么大了，怎么好意思，父亲很威严。爱不是藏在心里的，是应该表达出来的，如果没有表达，以后没有机会的话会很后悔。 学分4：学会如何生活，活在当下 我的癌症是淋巴癌四期，我认为我的生命并不长了。当时我也想到，如果我的生命真的只有 100 天了，我会怎么样渡过这个时间？我的结论和看护临终病人的护士是非常相似的。我的结论是说，我要让我的亲人知道我如何爱他们，我和他们在一起渡过特别难忘的时光，无论是和妻子去我们蜜月的地方，或者和孩子去一个我们过去特别快乐的地方，怀念回忆过去的美好，去吃我们爱吃的东西，做我们爱做的事情，这才是活。我希望活的时候，能全心全意每一刻活着，不只是脑子不停想我的公司，想我的事情。开始看世界其实是充满了美好的东西的。 如果稍微偶尔慢一下，能活在当下，才能体验到这些美好，才能感觉自己没有白活。我活了 50 多岁，一直没有分清什么是桂花，什么是茉莉花等等，我就知道他们都有香味。有一次我到朋友家这是什么味？我说桂花，什么时候种的？他说种了很长时间了。慢下来的时候，才会感受世界的美好。这是美食，这是我们最爱的酒，最漂亮的衣服，留到哪一天才会穿。我鼓励你们，不要把所有事情都推到以后，别说将来，找机会，还有一天等特殊的日子，我希望我们都活在当下。我们今天为什么不能成为那个特殊的日子呢，让每一天都成为最特殊的一天。我觉得人生如果这样活下去，不仅仅是最后的一百天，而是每一天都这样活下去，一定会非常圆满，丰富。 学分5：经得住诱惑 第五个学分经得住诱惑。我们小的时候，我父亲跟我们说，不要爱钱，对财富来讲，越多越好，但是不要贪婪的想得到更多。中国有一个通病，特别爱美。我们看到这么多古时候的皇帝，各方面的慈善家，做的各种事情都让别人知道自己有好。我父亲留给我 10 个字，有容则乃大，无求则更高。人死留名，我们希望做好的事情是对的，希望留名没有任何的必要，除了孔子以外，有哪个人被大家都记住了。我相信我们每一位 50 年以后都没有被别人记下来。 当你特别纠结自己“名”的时候，或许刻意，或者不刻意，都会让自己追求名成为一种方式。比如说之前我告诉年轻人追求自己的梦想，最大化自己的影响力，做最好的自己。这个话没有错，如果把最大化影响力这个词发挥到极致，每天机械化衡量影响力有没有提升，有没有人听我的演讲，成为我的粉丝。当我人生过去生病前的几年，5-10 年，慢慢越来越越顺，越来越有更多人喜欢把我当成他们的导师，一方面出于善心的帮助年轻人，但是不可避免的，每天的追随希望有更大的影响力。 听起来是很灰色的地带，影响力是好的吗？要一点名没有关系，我和清云大师讨论这个事情的时候，他告诉我，其实人是禁不住诱惑的。你要影响力的目的就是让世界更好，不断做好事情，不断衡量，我和别人都做好事就够了，为什么算我卖了多少本书，有多少粉丝呢？这样的过程，让我发现，虽然我认为我一直追求的方向和建议并没有错，但是如果特别机械化的追求效率，衡量每一天的结果，会让我们变得更冷漠无情。所以我发现，虽然我走的道路是正确的，但是过度追求名声，让我走偏了。 学分6：人人平等，善待每一个人 当你追求每一件事情影响力最大化的时候，你就想认识更多聪明的人。见创业者只见最顶尖的，一个青年人找你签字，如果是普通人，你就不考虑，你会见聪明人，成功人，把自己的一圈都变成社会的顶尖人士。但是我发现，如果真的再继续这么做的话，其实丧失了非常重要的一点就是人人是平等的。当我得了癌症，发的第一条微博，癌症面前人人平等。但是我慢慢觉醒的时候，我发现任何事上，人人都是平等的。世界的奥妙，不允许我们渺小对人类的评估。我们凭什么说这个人是普通人，这个人不怎么样，这个企业不会成功，这个创业者不行。 既然我们没有权利，也没有能力做评估的话，既然人人都是平等的，只要时间允许，我会秉承这样的理念，让我花更多的时间在网上和一些包括所谓的普通网友交流，每一周见一些想要见我的人，哪怕我们从来不认识，哪怕他们并没有特别光辉的履历。我建议大家，不要吝啬给别人爱的关怀。因为你对任何人，优秀的人，普通的人，都是一样的。你对任何人的微笑，一个行为，都可能帮助别人，帮助生命。 学分7：我们的人生究竟是为什么？ 我觉得如果我们太狂妄的说，我们来到人生就是为了改变世界，我们懂得这么小，这么渺小，凭什么狂妄，我们世界改变了，是更好，还是更不好，每天做的每一件事都能评估出来吗？我认为我们不必强求把改变世界作为我们的要求。如果每天拼命改变世界，那是充满压力的。 我认为来到人间，我们有缘认识周围的人，好好体验人生，结交善缘，做事问心无愧，凭良心，做人真诚平等，让自己的每一天都能有学习，成长，其实那就足够了。如果世界上每一个人都这么做，世界就会变得更好。如果过去我的哲学更多的是因为人生只有一次，所以要分秒必争，征求效率做最好的自己。现在我更觉得说，其实生命里很多东西，并没有办法用科学的方法解释，并没有办法每天衡量，比如说人与人之间的缘份。从现在开始，我不再看世界上很多的缺陷，批评他们，我相信每一个平等的生命都是来到这里不断学习，不断成长。人只有有缺陷才能学习成长，我们没有权利过分的批评别人，我们需要做的是怎么让自己成为一个更好更完善的人。 既然每个人都在持续成长，对于那些曾经伤害我，打击我，或者未来打击我的人，我不但宽恕他们，而且感谢他们，因为他们可能点醒我很多的不足。我相信人生的生命是与大宇宙连在一起的，我们有责任提升自己。我们的生命随着心跳停止也没关系，我们的人生只有一次，死去离开世界，如果这一生是体验学习提升，我相信也会让世界更美好，整个世界的群体意识也会变得更正向。 我经过这七个教训，我认为我们珍贵的生命旅程，应该保持着初学者的心态，对世界有儿童一般的好奇心，好好体验人生，让每天的自己都比以前有进步有成长，不要想着改变他人，做事问心无愧，多感恩和爱你周围的人。对人真诚、平等，这样就足够了。如果世界上每个人都能如此，世界就会更美好，谢谢。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"此生未完成","date":"2017-01-18T11:02:06.000Z","path":"2017/01/18/MyShare/unfinished-life/","text":"于娟《此生未完成：一个母亲、妻子、女儿的生命日记》 我们要用多大的代价，才能认清活着的意义。 在生命的最后日子里，于娟完全放下了生死，放下了名利权情，赤裸裸的去反思和写作。所有的浮躁沉淀了，所有的伪装剥离了，所有的喧嚣远去了，所有的执着放下了。只有一个普通的女子，普通的女儿、妻子、母亲对生命最单纯的感悟。在这个故事里，很多读者看到的不是于娟，而是自己。 在生死临界点的时候，你会发现，任何的加班，给自己太多的压力，买房买车的需求，这些都是浮云。如果有时间好好陪陪你的孩子，把买车的钱给父母买双鞋子，不要拼命去换什么大房子 ，和爱的人在一起蜗居也温暖…… 不要认为后面还有更好的，因为现在拥有的就是最好的；不要认为还年轻可以晚些结婚，爱情是不等年龄的；不要因为距离太远而放弃，爱情是可以和你一起坐火车的；不要因为对方不富裕而放弃，只要不是无能的人，彼此鼓励可以让你们富足的；不要因为外人反对而放弃，幸福是靠自己内心来感受的。 人有个好的心态，才能享受人生。不奢望太多的东西，只要这一生中有自己的居所，有自己的小家，甜蜜而温馨，每天过着快乐的生活就够了。随缘的爱是最幸福的爱，无须计划，无须设计，一切都顺理成章，轻松，自然，流淌着最本真的爱，相爱的人儿自是充满着感动，心喜，激动。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"选择的智慧","date":"2017-01-17T01:12:06.000Z","path":"2017/01/17/MyShare/wisdom-of-choose/","text":"李开复写《给中国学生的第六封信》——选择的智慧 有勇气来改变可以改变的事情，有胸怀来接受不可改变的事情，有智慧来分辨两者的不同。 “‘有勇气来改变可以改变的事情’代表了用西方式的积极进取的心态，以永不放弃、永不消沉的主动人生态度，鼓励我们靠自己的努力达到目的。“‘有胸怀来接受不可改变的事情’代表了用中国式的谦恭谨让的度量来培养自己的修养，学会承认和接受真实的、不完美甚至不公正的世界。有智慧来分辨两者的不同，可是，智慧从哪里来呢？”其实，“有智慧来分辨两者的不同”就是要求我们使用自己的智慧，主动发现并选择最完整、最均衡的状态，并通过这一选择获得成功。这里所说的“智 慧”，既是甄别、判断的智慧，也是权衡、折中的智慧，但从根本上讲，它更是在选择中孕育又在选择中升华的最高智慧——我也把它称作“选择成功”的智慧。 中国的青年学生虽然有幸出生在能够自由选择的时代，但时代并没有传授他们选择的智慧。我能帮你做的不是选择，因为你自身的问题只有自己最清楚，自己的未来也只有自己最在意。我能做的只是传授给你选择的智慧，帮你聆听自己心底里最真实的声音，帮助你做出智慧的选择 选择成功的智慧共有八种： 用中庸拒绝极端 用理智分析情景 用务实发挥影响 用冷静掌控抉择 用自觉端正态度 用学习积累经验 用勇气放弃包袱 用真心追随智慧 中庸告诉我们的最重要的一点，就是要避免并拒绝极端和片面。比如说，我认为最重要的积极主动，如果做到了极端，就变成了霸道，喜欢对别人颐指气使，横行跋扈。还有我提出与人相处最重要的同理心，如果做到了极端， 就变成了盲从，失去了自己的选择，什么事都没有主见。极端的自信就成了自傲，极端的勇气就成了愚勇，极端的胸怀就是懦弱，极端的 自省就会变成自卑。 自信、自省、勇气、胸怀，积极、同理心六种态度都是成功的必备要素，也都是成功者需要具备的优点。但是，一旦将其中某一种态度发展到极端，优点就会立刻演变为缺点。下面的图显示的就是这六种成功者必须的态度，和它们发展到极端的后果：内圈代表完整、均衡的状态，外圈代表极端、片面的行为。第一个智慧的真谛就是：我们必须用中庸的思想指导自己，把自己的态度限制在完整、均衡的范畴内，兼顾自信和自省、勇气和胸怀、积极和同理心等各方面因素，时刻防止自己在其中某一方面有过于偏激的表现。 沉默是金和口无遮拦都不可取，那么我们怎么达到“中庸式的智慧沟通”呢？记得我刚进入苹果公司开始我的第一份工 作时，公司里有一位经理叫西恩，大家都知道他是一个非常有才华的人，尤其在开会的时候， 他得体的言辞完美地展现出他过人的才学、情商与口才，足以让在场的 所有人钦佩不已。有一天，我鼓足勇气去向西恩讨教有效沟通的秘诀。 西恩说：“我的秘诀其实很简单：我并不总是抢着发言；当我不懂或不确定时，我的嘴闭得紧 紧的；但是，当我有好的意见时，我绝不错过良机——如果不让我发言，我就不让会议结束。” 我问他：“如果别人都抢着讲话，你怎么发言呢？”西恩说：“我会 先用肢体语言告诉别人：下一个该轮到我发言啦！例如，我会举起手，发出特殊的声响（如清嗓子声），或者用目光要求主持人让我发言。 但是，如果其他人的确霸 占了所有的发言机会，我就等发言人调整呼吸时，迅速接上话头。”我又问他：“如果你懂得不多，但是别人向你咨询呢？” 西恩说：“我会先看看有没有比我懂得 更多的人帮我回答。如果有，我会巧妙地把回答的机会‘让’给他；如果没有，我会说‘我不知道，但是我会去查’，等会开完后，我一定去把问题查清楚。” 跟他 的一席话让我学到了很多东西——只要把握好说话的度，选择好说话的时机，就可以得到周围人的尊敬，而且，别人也会从你的话语中了解到你是一个渊博而谦逊的 人。 “我不同意我的老板，我该站起来发言吗？” 我的回答是：“这要看情形而定。首先，你的老板是一个愿意接纳异议的人吗？如果不是，那么你千万不要乱发言，但是，你可以开始物色一个新 工作和新老板了！如果他能够接受异议，那么，在老板还没做出最后的决定时，不要怕提出异议；但同时也要考虑到，如果是当众发言，自己的话就必须有一定的技 巧，应当顾虑到老板的面子。老板一旦做出了决定，我们无论有无异议，都必须支持和贯彻，有不同意的地方只可以私下与老板沟通。” 在这样一个具体的例子里，我们必须学会用智慧甄别各种复杂的情况，并从不同候选方案中择善而从的方法，这样才能找到提出异议的最佳途径。这个例子中的选择过程也可以用计算机流程图直观地表示出来： 一个出色领导总是拥有上述的六种领导力，并且会理智地分析当前的情景，以便决定运用其中的哪一种。例如， 假设员工表现不佳或 员工是新手，在公司遇到重大危机时，对员工就应该采用指挥、命令的方式； 如果企业需要改变方向，或员工因为不理解方向而士气不高，而你又是一个值得信任的 领导者，那就应该采用宏观掌控的方法； 如果你发现员工对工作得心应手，部门协调没有问题，那就应该注重和谐合作； 当你发现员工知识渊博，或你对结果不确定 的时候，就应该选择民主自由的方式； 如果员工能力很高又是专家，或具备了积极自主的态度，就应该采用授权负责的方式； 如果员工很有动力，愿意把工作做好， 但是经验不足，同时企业并没有处于危机时刻，那应该尽量指导培养。 最好的领导是拥有这六种看起来相互矛盾的领导力，并且用智慧根据不同的情景正确选择的 人。 人生中的绝大多数选择都不是非黑即白、非此即彼的事情。大家要学会在最合适的时候对最合适的人用最合适的方法，要学会在做出决定前用理智全面衡 量各种因素的利弊以及自己的能力和倾向。这些东西并不能靠简单的公式来决定。读者应该凭借自己的智慧，选择最适合自己的成功之路。 史蒂芬·柯维在其所著的《高效能人士的七个习惯》一书中，把所有值得关注的事情称为“关注圈”，把能够发挥影响的事情称为“影响圈”。在整个关注圈中，根据自主程度的高低，人生面临的问题可分为三类： 可直接影响的问题：对于这种问题，解决之道在于用正确的态度执行。这是我们绝对做得到的，也是最核心的“影响圈”。 可间接影响的问题：有赖改进发挥影响力的方法来加以解决，如借助人际关系、团队合作和沟通能力来解决。这是最值得我们努力争取的“影响圈”。 无能为力的问题：需要以平和的态度和胸怀，接纳这些问题。纵使有再多不满，也要泰然处之，如此才不至于让问题征服了我们。 碰到问题时，你只要耐心地将它分解开，看看哪些部分是你可以影响的，哪些部分是你可以关注但却无法影响的。然后，去努力争取那些可以 “间接影响”的问题，让它们变成可“直接影响”的，同时把全部心力投入自己的影响圈——你可以在这样的过程中不断获得进步，这反过来又可以让你进一步扩大 自己的影响圈。解决问题的第一步都要从自己的影响圈开始：先影响自己，再影响别人，最后才有可能影响环境。虽然我们不能改变风，但我们可以调整船帆。人在挫折中学到的 东西会远远多于在成功中学到的。希望你在经过这一次不幸后能够成为一个更成熟、更成功的人。专注于你能够改变的事情，可能最后连当初不能改变的事情也改变了。 在抉择前“重重”思考，抉择后“轻轻”放下。 所谓“重重”思考，就是要培养客观的、精准的判断力。每一个重要的抉择可能都与你自己的前途密切相关，但你在抉择和判断时，一定要避免先入为主的思维定式，要避免自己的主观倾向影响判断的精准和客观。我们该如何做出客观、精准的抉择呢？我给大家提供三个建议： 第一、把影响你抉择的因素罗列成一张“利弊对照表”。 第二、学会用概率论的方法看问题。 第三、当自己不确定时，学会谋之于众。 在利弊对照表中写出每个因素的利益和弊端，然后借助该表客观地分析，哪些利益和弊端对你来说最为重要？这些因素是否符合你的价值观和理想？当你面前摆了这样一张客观而详尽的利弊对照表时，主观因素就不容易影响你的判断力了。借助这样一份利弊对照表，我很快就做出了客观而明智的决定——回中国工作。因为综合考虑各种利弊因素后，回中国工作最能发挥我自身的特长，也最符合我个人的价值观和理想。 我们应当学会分析一件事情“可改变的概率”或“可能发生的概 率”。对于发生概率小的事情，在做之前一定要有失败的心理准备。另一方面，也不要等到事情成功的概率达到100%时才去做，因为即便做成了这种事情，也没 有什么值得骄傲的。做概率分析时，可以列出“最好的可能”和“最坏的打算”，以帮助自己综合考量。例如，上面提到的“回中国建立研究院”的工作，我有100%的把 握，可以把研究院办得与其他任何公司在中国建立的研究院一样好——这是最坏的打算；我有40%的把握，可以做出世界一流的研究机构来——这是最好的可能。用这样的方法考虑到两个极端后，我马上就会明白，即便出现最坏的情况，我和公司也可以坦然接受。因此，我选择回中国工作就成了一件顺理成章的事。许多抉择并没有这么好的“后路”，在这种时候，我们既要谨慎地评估风险因素，也要在适当的时候有勇气挑战自己。美国前国务卿鲍威尔曾在阐 述“领导力”时指出：“当你自估的成功概率达到40~70%，你就该去做这件事了。也许你会失败，但拖延或等待的代价往往是更大的。” 多征求别人的意见总是好的。那些更有经验的人可以用他们多年的积累为我们指引方向，那些聪明绝顶的人可以用他们的智商启发我们的思路，那些懂得人际关系的人可以用他们的情商帮助我们有效沟通…… 最终的决定权在你自己，即便你采纳了别人的意见，你也不可以就此将责任推卸给他人。所谓“轻轻”放下，就是说我们在做出抉择后，应当坦然面对可能发生的任何结果，既不要因为抉择正确而欣喜若狂，也不要因为抉择失误而悔恨终生。 无论你的抉择正确与否，无论它的结果如何，已经做出的决定就无法收回了，你只有坦然接受它，或者在今后想办法补救。对于已经发生的事情， 或者自己已经无法控制的事情，任何担忧或悔恨都是多余的。与其把时间花在无谓的焦虑上，倒不如把这些东西“轻轻”放下，然后一身轻松地去做自己应该做的 事。 人贵有自知之明。这实际上是说，社会生活中的每个人都应当对自己的素质、潜能、特长、缺陷、 经验等各种基本能力有一个清醒的认识，对自己在社会工作生活中可能扮演的角色有一个明确的定位。心理学上把这种有自知之明的能力称为“自觉”，这通常包括 察觉自己的情绪对言行的影响，了解并正确评估自己的资质、能力与局限，相信自己的价值和能力等几个方面。 有自觉的人能够针对自己做出最具有智慧的选择，选择做自己能够胜任的工作，选择做能够得到满足感的工作等等。要做一个自觉的人，既不会对自己的 能力判断过高，也不会轻易低估自己的潜能。对自己判断过高的人往往容易浮躁、冒进，不善于和他人合作，在事业遭到挫折时心理落差较大，难以平静对待客观事 实；低估了自己潜能的人，则会在工作中畏首畏尾、踟蹰不前，没有承担责任和肩负重担的勇气，也没有主动请缨的积极性。无论是上述哪一种情况，个人的潜力都 不能得到充分的发挥，个人事业也不可能取得最大的成功。 有自觉的人在工作遇到挫折的时候不会轻言失败，在工作取得成绩时也不会沾沾自喜。认识自我，准确定位自我价值的能力不仅仅可以帮助个人找到自己合适的空间及发展方向，也可以帮助企业建立起各司其职、协同工作的优秀团队。有自觉的人的抉择让他人更愿意信任。 很多人只是从来没有考虑过要 了解自己。确定计划和原则时，必须完全基于对自己的了解。最关键的是，一定要清楚自己对什么事情最感兴趣。制定了一个计划以后，也许随着时间的推移，会有 某种程度上的修改，但始终要明确自己的大方向。所以我觉得更难的一点是，能经常以旁观者的目光审视自己，看一下自己哪方面做得好，需要保持，哪方面做得 差，需要更加努力，哪方面走入了歧途，需要改正。 西方有一则寓言，说的是一个年轻人向一个年长的智者请教智慧的秘诀。年轻人问：“智慧从哪里来？”智者说：“正确的选择。”年轻人又问：“正确的选择从哪里来？”智者说：“经验。”年轻人进一步追问：“经验从哪里来？”智者说：“错误的选择。”不要畏惧失败。每一个失 败不是惩罚，而是一个学习的经验。 学习经验不是一蹴而就的事情，有时候要经历漫长的过程。英文中有一句名言：“旅途本身就是收获（The journey is the reward）。”很多时候，你的收获并不一定是每件事的成功，而是你在走向成功的旅途中经历的一切。旅途中的每一次正确的或是错误的选择都会让你学到新 的知识、获取新的教训，并以此调整自己的自觉，掌握正确的选择方法。 创新固然重要，但有用的创新更重要。在整个学习的过程中，无论是错误的选择，还是失败的经历，它们都可以成为印刻在我们心底，能够随时拿出来比较、借鉴的“模板 （Template）”。当我们面临新的抉择时，我们就会使用过去积累的“模板”来比较、分析各种不同情况下成功的概率，以权衡利弊，做出正确的抉择。 当新的机会摆在面前的时候，敢于放弃已经获得的一切，这需要相当大的勇气。有时，你在还没有找到“新的机会”之前，就必须放弃你已经拥有的东西，那就需要更多的勇气了。这种眼前的利益往往是阻碍你获得更大成功的根源。当新的机会到来时，勇于放弃已经获得的东西并不是功亏一篑，更不是半途而 废，这是为了谋求新的发展空间。如果你在适当的时候勇敢地——当然也应该是有智慧地——放弃已经拥有但可能成为前进障碍的东西，你多半会惊讶地发现，自己 抛开的不过是一把虽能遮风挡雨，但又会阻碍视线的雨伞，自己因此而看到的却是无比广阔、无比壮丽的江山图景！ 当苹果电脑的一 位副总裁对我说“你要选择终身写些没有人读得懂的论文，还是要选择改变世界”时，我毫不犹豫地选择了改变世界。我的感觉就像是获得了自由。如果我只对我拥有的东西依依不舍，那么我将错过这个“once in a lifetime”的机会。于是，就像我在“追随我新的抉择”中所说的：“我有选择的权利——我选择了Google。我选择了中国。我要做有影响力的事 ——在中国，我能更多地帮助中国的青年，做最有影响力的事。我要成为最好的自己——在Google，我能经过学习新的创新模式，成为最好的自己。”同时， 我放弃了在微软的人脉，放弃了继续与比尔·盖茨工作的机会，放弃了那安稳的工作，放弃了那“世界第一大IT公司”的荣誉。 我人生中这几次勇于放弃的经历，都使我更加清楚自己的追求和兴趣所在，也使我更有激情去从事自己喜爱的事业。放弃意味着失去，但失去的是那些自己缺乏激情的东西，得到的却是自己主动追寻的事业。 最后一个可以帮助你做出正确抉择的“智囊”就是你内心深处的价值观、理想和兴趣了。价值观就是每个人判断是非、善恶的信念体系（What is right？），理想就是我们对自己人生目标的基本设计（What do I want my life to be?），而兴趣则是我们每个人最喜欢、最热爱的事情（What do I love doing?）。这三者共同构成了我们内心深处最为真实的声音。有关如何找到自己的价值观、理想和兴趣，读者可以参看《做最好的自己》一书中的相关章节。 你的价值观是你判断“是非”的准绳，你的理想和兴趣是你辨别“方向”的指南针——它们都是你心底里最真实、最“自我” 的东西，还有什么是比这些更重要，更精确的判断依据呢？ 我建议大家应该通过自己正确的价值观和理想来寻找最为完整、最为均衡的人生状态。任何一个高尚的人，一个有远大理想的人都必然会在积极追寻成功 的道路上运用自己最高的智慧：因为拥有了正确的价值观和远大的理想，他在面临困难和挑战时就必然会听从自己的真心、用冷静的心态权衡各种利弊，他也必然会 在一次又一次或是成功、或是失败的抉择中不断积累经验完善自我……这样的人最能理解完整与均衡的真谛，这样的人最懂得使用自己的“选择”的权利来赢得真正 的成功。 融会中西，均衡发展在今天这个信息化、全球化的时代里，只有融会中西才能成为真正有价值的国际化人才。中国人讲求纪律与服从、重视谦虚和毅力以及西方人强调创意与个性，鼓励积极与勇气的 特长 大部分中国青年和美国青年的优势可以用下表来概括。既需要西方的科技和理性，也需要东方的心胸与美德。 一个人甚至要同时具备多种看似相互矛盾的品质，才能在复杂的境遇中因具体情景不同而运用正确的一种。 用智慧在各种看似矛盾的因素之间主动选择“完整”和“均衡”，这是“选择成功”的最大秘诀。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"孙振耀退休感言","date":"2017-01-15T23:50:06.000Z","path":"2017/01/16/MyShare/retirement-speech-of-HP-president/","text":"HP大中华区总裁孙振耀退休感言 职业生涯首先要关注的是自己，自己想要什么？寻找真正能够使你获得快乐的东西，那才是你想要的东西。有很多的不快乐，其实是源自不满足，而不满足，很多时候是源自于心不定，而心不定则是因为不清楚究竟自己要什么，不清楚要什么的结果就是什么都想要，结果什么都没得到。 关于工作与生活 外企员工的成功很大程度上是公司的成功，并非个人的成功而进外企的人往往并不能很早理解这一点，把自己的成功90％归功于自己的能力看待工作，眼光要放远一点，一时的谁高谁低并不能说明什么。 马拉松比赛 正常人大概要工作35年，这好比是一场马拉松比赛，和真正的马拉松比赛不同的是，这次比赛没有职业选手，每个人都只有一次机会。要知道，有很多人甚至坚持不到终点，大多数人最后是走到终点的，只有少数人是跑过终点的，因此在刚开始的时候，去抢领先的位置并没有太大的意义。每个人的职业生涯中都会碰到几个瓶颈，你熬过去了而别人没有熬过去你就领先了。跑长跑的人会知道，开始的时候很轻松，但是很快会有第一次的难受，但过了这一段又能跑很长一段，接下来会碰到第二次的难受，坚持过了以后又能跑一段，如此往复，难受一次比一次厉害，直到坚持不下去了。大多数人第一次就坚持不了了，一些人能坚持到第二次，第三次，虽然大家都坚持不住了，可是跑到这里的人也没几个了，这点资本足够你安稳活这一辈子了。 初赛 职业生涯就像一场体育比赛，有初赛、复赛、决赛。初赛的时候大家都刚刚进社会，大多数都是实力一般的人，这时候努力一点认真一点很快就能让人脱颖而出，于是有的人二十多岁做了经理，有的人迟些也终于赢得了初赛，三十多岁成了经理。然后是复赛，能参加复赛的都是赢得初赛的，每个人都有些能耐，在聪明才智上都不成问题，这个时候再想要胜出就不那么容易了，单靠一点点努力和认真还不够，要有很强的坚忍精神，要懂得靠团队的力量，要懂得收服人心，要有长远的眼光…… 复赛 看上去赢得复赛并不容易，但，还不是那么难。因为这个世界的规律就是给人一点成功的同时让人骄傲自满，刚刚赢得初赛的人往往不知道自己赢得的仅仅是初赛，有了一点小小的成绩大多数人都会骄傲自满起来，认为自己已经懂得了全部，不需要再努力再学习了，他们会认为之所以不能再进一步已经不是自己的原因了。虽然他们仍然不好对付，但是他们没有耐性，没有容人的度量，更没有清晰长远的目光。就像一只愤怒的斗牛，虽然猛烈，最终是会败的，而赢得复赛的人则象斗牛士一样，不急不躁，跟随着自己的节拍，慢慢耗尽对手的耐心和体力。赢得了复赛以后，大约已经是一位很了不起的职业经理人了，当上了中小公司的总经理，大公司的副总经理，主管着每年几千万乃至几亿的生意。 决赛 最终的决赛来了，说实话我自己都还没有赢得决赛，因此对于决赛的决胜因素也只能凭自己的猜测而已，这个时候的输赢或许就像武侠小说里写得那样，大家都是高手，只能等待对方犯错了，要想轻易击败对手是不可能的，除了使上浑身解数，还需要一点运气和时间。世界的规律依然发挥着作用，赢得复赛的人已经不只是骄傲自满了，他们往往刚愎自用，听不进去别人的话，有些人的脾气变得暴躁，心情变得浮躁，身体变得糟糕，他们最大的敌人就是他们自己，在决赛中要做的只是不被自己击败，等着别人被自己击败。这和体育比赛是一样的，最后高手之间的比赛，就看谁失误少谁就赢得了决赛。 你工作快乐么？你的工作好么？ 你不快乐的根源，是因为你不知道要什么！你不知道要什么，所以你不知道去追求什么，你不知道追求什么，所以你什么也得不到。职业生涯首先要关注的是自己，自己想要什么？大多数人大概没想过这个问题，唯一的想法只是——我想要一份工作，我想要一份不错的薪水寻找自己想要的东西不是和别人比赛，比谁要得更多更高，比谁的目标更远大。你必须听听你内心的声音，寻找真正能够使你获得快乐的东西，那才是你想要的东西。先想好自己要过怎样的人生，再决定要找什么样的职业。有很多的不快乐，其实是源自不满足，而不满足，很多时候是源自于心不定，而心不定则是因为不清楚究竟自己要什么，不清楚要什么的结果就是什么都想要，结果什么都没得到。还是因为生活而工作，不是因为工作而生活，生活是最要紧的，工作只是生活中的一部分。我总是觉得生活的各个方面都是相互影响的，如果生活本身一团乱麻，工作也不会顺利。所以要有娱乐、要有社交、要锻炼身体，要有和睦的家庭……最要紧的，要开心首先的首先，人还是要让自己高兴起来，让自己心态好起来，这种发自内心的改变会让你更有耐心，更有信心，更有气质，更能包容…… 恶性循环你想每隔几年重来一次找工作的过程么？你想每年都在这种对于工作和薪水的焦急不安中度过么？不想的话，就好好想清楚。饮鸩止渴，不能因为口渴就拼命喝毒药。越是焦急，越是觉得自己需要一份工作，越饥不择食，越想不清楚，越容易失败，你的经历越来越差，下一份工作的人看着你的简历就皱眉头。于是你越喝越渴，越渴越喝，陷入恶性循环。 压力大多数人都有生存压力，我也是，有生存压力就会有很多焦虑，积极的人会从焦虑中得到动力，而消极的人则会因为焦虑而迷失方向。所有人都必须在压力下做出选择，这就是世道，你喜欢也罢不喜欢也罢。 重要 VS 紧急 一般我们处理的事情分为重要的事情和紧急的事情，如果不做重要的事情就会常常去做紧急的事情。比如锻炼身体保持健康是重要的事情，而看病则是紧急的事情。如果不锻炼身体保持健康，就会常常为了病痛烦恼。又比如防火是重要的事情，而救火是紧急的事情，如果不注意防火，就要常常救火。找工作也是如此，想好自己究竟要什么是重要的事情，找工作是紧急的事情，如果不想好，就会常常要找工作。往往紧急的事情给人的压力比较大，迫使人们去赶紧做，相对来说重要的事情反而没有那么大的压力，大多数人做事情都是以压力为导向的，压力之下，总觉得非要先做紧急的事情，结果就是永远到处救火，永远没有停歇的时候。（很多人的工作也像是救火队一样忙碌痛苦，也是因为工作中没有做好重要的事情。）那些说自己活在水深火热为了生存顾不上那么多的朋友，今天找工作困难是当初你们没有做重要的事情，是结果不是原因。如果今天你们还是因为急于要找一份工作而不去思考，那么或许将来要继续承受痛苦找工作的结果。 12天下没有轻松的成功，成功，要付代价。请先忘记一切的生存压力，想想这辈子你最想要的是什么？所以，最要紧的事情，先想好自己想要什么。人总想找到那个最好的，可是，什么是最好的？你觉得是最好的那个，是因为你的确了解，还是因为别人说他是最好的？即使他对于别人是最好的，对于你也一定是最好的么？ 什么是好工作 人都是要面子的，也是喜欢攀比的，即使在工作上也喜欢攀比，不管那是不是自己想要的。你想清楚了么？500强一定好么？找工作究竟是考虑你想要什么，还是考虑别人想看什么？“很多事情就像看A片，看的人觉得很爽，做的人未必。” 你究竟是要过谁的一生？人的一生不是父母一生的续集，也不是儿女一生的前传，更不是朋友一生的外篇，只有你自己对自己的一生负责，别人无法也负不起这个责任。自己做的决定，至少到最后，自己没什么可后悔。对于大多数正常智力的人来说，所做的决定没有大的对错，无论怎么样的选择，都是可以尝试的。 好工作，应该是适合你的工作，具体点说，应该是能给你带来你想要的东西的工作，你或许应该以此来衡量你的工作究竟好不好，而不是拿公司的大小，规模，外企还是国企，是不是有名，是不是上市公司来衡量。小公司，未必不是好公司，赚钱多的工作，也未必是好工作。你还是要先弄清楚你想要什么，如果你不清楚你想要什么，你就永远也不会找到好工作，因为你永远只看到你得不到的东西，你得到的，都是你不想要的。 万科的王石登珠穆朗玛峰的体验给我很多启发，虽然在出发时携带大量的物资，但是登顶的过程中，必须不断减轻负荷，最终只有一个氧气瓶和他登上峰顶。登山如此，漫长的人生又何尝不是。 可能，最好的，已经在你的身边，只是，你还没有学会珍惜。人们总是盯着得不到的东西，而忽视了那些已经得到的东西。 普通人 中国的励志比较鼓励人立下大志愿，卧薪尝胆，有朝一日成富成贵。需要用999个失败者来堆砌一个成功者的故事。国外的励志比较鼓励人勇敢面对现实生活，面对普通人的困境，虽然结果也是成富成贵，但起点不一样目标定得高些对于喜欢挑战的人来说有好处，但对于大多数普通人来说，反而比较容易灰心沮丧，很容易就放弃了。 目标其实并没有高低之分，你不需要因为自己的目标没有别人远大而不好意思，达到自己的目标其实就是成功，成功有大有小，快乐却是一样的。我们追逐成功，其实追逐的是成功带来的快乐，而非成功本身。职业生涯的道路上，我们常常会被攀比的心态蒙住眼睛，忘记了追求的究竟是什么，忘记了是什么能使我们更快乐。 这个世界上，有史以来直到我们能够预见得到的未来，成功的人总是少数，有钱的人总是少数，大多数人是一般的，普通的，不太成功的。因此，大多数人的做法和看法，往往都不是距离成功最近的做法和看法。因此大多数人说好的东西不见得好，大多数人说不好的东西不见得不好。大多数人都去炒股的时候说明跌只是时间问题，大家越是热情高涨的时候，跌的日子越近。大多数人买房子的时候，房价不会涨，而房价涨的差不多的时候，大多数人才开始买房子。不会有这样一件事情让大家都变成功，发了财，历史上不曾有过，将来也不会发生。有些东西即使一时运气好得到了，还是会在别的时候别的地方失去的。 只见贼吃肉，不见贼挨揍社会上一夜暴富的新闻很多，这些消息，总会在我们的心里面掀起很多涟漪，涟漪多了就变成惊涛骇浪，心里的惊涛骇浪除了打翻承载你目标的小船，并不会使得你也一夜暴富。“只见贼吃肉，不见贼挨揍。”我们这些普通人既没有当贼的勇气，又缺乏当贼的狠辣绝决，虽然羡慕吃肉，却更害怕挨揍，偶尔看到几个没挨揍的贼就按奈不住，或者心思活动，或者大感不公，真要叫去做贼，却也不敢。 跳槽与积累 不反对跳槽，但跳槽决不是解决问题的办法，而且频繁跳槽的后果是让人觉得没有忠诚度可言，而且不能安心工作。要跳槽肯定是有问题，一般来说问题发生了，躲是躲不开的，很多人跳槽是因为这样或者那样的不开心，如果这种不开心，在现在这个公司不能解决，那么在下一个公司多半也解决不掉。你必须相信，90%的情况下，你所在的公司并没有那么烂，你认为不错的公司也没有那么好。就像围城里说的，“城里的人拼命想冲出来，而城外的人拼命想冲进去。”每个公司都有每个公司的问题，没有问题的公司是不存在的。换个环境你都不知道会碰到什么问题，与其如此，不如就在当下把问题解决掉。很多问题当你真的想要去解决的时候，或许并没有那么难。有的时候你觉得问题无法解决，事实上，那只是“你觉得”。 基本上，35岁以前我们的生存资本靠打拼，35岁以生存的资本靠的就是积累，这种积累包括人际关系，经验，人脉，口碑……工作两三年的人，无论是客户关系，人脉，手下，和领导的关系，在业内的名气……还都是远远不够的，但稍有成绩的人总是会自我感觉良好的，每个人都觉得自己跟客户关系铁得要命，觉得自己在业界的口碑好得很。其实可以肯定地说，一定不是，这个时候，还是要拿出前两年的干劲来，稳扎稳打，积累才刚刚开始。你足够了解你的客户吗？你知道他最大的烦恼是什么吗？你足够了解你的老板么？你知道他最大的烦恼是什么吗？你足够了解你的手下么？你知道他最大的烦恼是什么吗？如果你不知道，你凭什么觉得自己已经积累够了？如果你都不了解，你怎么能让他们帮你的忙，做你想让他们做的事情？如果他们不做你想让他们做的事情，你又何来的成功？ 等待 并不是每次闯红灯都会被汽车撞，并不是每个罪犯都会被抓到， 并不是每个错误都会被惩罚，并不是每个贪官都会被枪毙， 并不是你的每一份努力都会得到回报，并不是你的每一次坚持都会有人看到， 并不是你每一点付出都能得到公正的回报，并不是你的每一个善意都能被理解…… 这个，就是世道。好吧，世道不够好，可是，你有推翻世道的勇气么？如果没有，你有更好的解决办法么？ 有很多时候，人需要一点耐心，一点信心。每个人总会轮到几次不公平的事情，而通常，安心等待是最好的办法。 有很多时候我们需要等待，需要耐得住寂寞，等待属于你的那一刻。 每一个成功者都有一段低沉苦闷的日子，我几乎能想象得出来他们借酒浇愁的样子，我也能想象得出他们为了生存而挣扎的窘迫。在他们一生最中灿烂美好的日子里，他们渴望成功，但却两手空空，一如现在的你。没有人保证他们将来一定会成功，而他们的选择是耐住寂寞。如果当时的他们总念叨着“成功只是属于特权阶级的”，你觉得他们今天会怎样？ 他们在社会上奋斗积累了十几二十年，我们新人来了，他们有的我都想要，我这不是在要公平，我这是在要抢劫。因为我要得太急，因为我忍不住寂寞。二十多岁的男人，没有钱，没有事业，却有蓬勃的欲望。 12345人总是会遇到挫折的，人总是会有低潮的，人总是会有不被人理解的时候的，人总是有要低声下气的时候，这些时候恰恰是人生最关键的时候，因为大家都会碰到挫折，而大多数人过不了这个门槛，你能过，你就成功了。在这样的时刻，我们需要耐心等待，满怀信心地去等待，相信，生活不会放弃你，机会总会来的。至少，你还年轻，你没有坐牢，没有生治不了的病，没有欠还不起的债。比你不幸的人远远多过比你幸运的人，你还怕什么？路要一步步走，虽然到达终点的那一步很激动人心，但大部分的脚步是平凡甚至枯燥的，但没有这些脚步，或者耐不住这些平凡枯燥，你终归是无法迎来最后的那些激动人心。无论什么时候，我们总还是有希望。当所有的人离开的时候，我不失去希望，我不放弃。每天下班坐在车里，我喜欢哼着《隐形的翅膀》看着窗外，我知道，我在静静等待，等待属于我的那一刻。 逆境，是上帝帮你淘汰竞争者的地方。要知道，你不好受，别人也不好受，你坚持不下去了，别人也一样，千万不要告诉别人你坚持不住了，那只能让别人获得坚持的信心，让竞争者看着你微笑的面孔，失去信心，退出比赛。胜利属于那些有耐心的人。 入对行跟对人 第一份工作对人最大的影响就是入行，现代的职业分工已经很细，我们基本上只能在一个行业里成为专家，不可能在多个行业里成为专家。很多案例也证明即使一个人在一个行业非常成功，到另外一个行业，往往完全不是那么回事情其实没有哪个行业特别好，也没有哪个行业特别差，或许有报道说哪个行业的平均薪资比较高，但是他们没说的是，那个行业的平均压力也比较大。看上去很美的行业一旦进入才发现很多地方其实并不那么完美，只是外人看不见。其实选什么行业真的不重要，关键是怎么做。事情都是人做出来的，关键是人。和那些比你强的人打交道，看他们是怎么想的，怎么做的，学习他们，然后跟更强的人打交道。 年轻人在职业生涯的刚开始，尤其要注意的是，要做对的事情，不要让自己今后几十年的人生总是提心吊胆，更不值得为了一份工作赔上自己的青春年华。人还是要看长远一点。很多时候，看起来最近的路，其实是最远的路，看起来最远的路，其实是最近的路。 跟对人是说，入行后要跟个好领导好老师，刚进社会的人做事情往往没有经验，需要有人言传身教。对于一个人的发展来说，一个好领导是非常重要的。所谓“好”的标准，不是他让你少干活多拿钱，而是以下三个。 首先，好领导要有宽广的心胸，如果一个领导每天都会发脾气，那几乎可以肯定他不是个心胸宽广的人，能发脾气的时候却不发脾气的领导，多半是非常厉害的领导。中国人当领导最大的毛病是容忍不了能力比自己强的人，所以常常可以看到的一个现象是，领导很有能力，手下一群庸才或者手下一群闲人。如果看到这样的环境，还是不要去的好。 其次，领导要愿意从下属的角度来思考问题，这一点其实是从面试的时候就能发现的，如果这位领导总是从自己的角度来考虑问题，几乎不听你说什么，这就危险了。从下属的角度来考虑问题并不代表同意下属的说法，但他必须了解下属的立场，下属为什么要这么想，然后他才有办法说服你，只关心自己怎么想的领导往往难以获得下属的信服。 第三，领导敢于承担责任，如果出了问题就把责任往下推，有了功劳就往自己身上揽，这样的领导不跟也罢。选择领导，要选择关键时刻能抗得住的领导，能够为下属的错误买单的领导，因为这是他作为领导的责任。 选择 从某种意义上来说我们的未来不是别人给的，是我们自己选择的每天你都可以选择是否为客户服务更周到一些，是否对同事更耐心一些，是否把工作做得更细致一些，是否把情况了解得更清楚一些，是否把不清楚的问题再弄清楚一些……你也可以选择在是否在痛苦中继续坚持，是否抛弃掉自己的那些负面的想法，是否原谅一个人的错误，是否相信我在这里写下的这些话，是否不要再犯同样的错误……生活每天都在给你选择的机会，每天都在给你改变自己人生的机会，你可以选择赖在地上撒泼打滚，也可以选择咬牙站起来。你永远都有选择。有些选择不是立杆见影的，需要累积，比如农民可以选择自己常常去浇地，也可以选择让老天去浇地，诚然你今天浇水下去苗不见得今天马上就长出来，但常常浇水，大部分苗终究会长出来的，如果你不浇，收成一定很糟糕。 你选择相信什么？你选择和谁交朋友？你选择做什么？你选择怎么做？……我们面临太多的选择，而这些选择当中，意识形态层面的选择又远比客观条件的选择来得重要得多，比如选择做什么产品其实并不那么重要，而选择怎么做才重要。选择用什么人并不重要，而选择怎么带这些人才重要。大多数时候选择客观条件并不要紧，大多数关于客观条件的选择并没有对错之分，要紧的是选择怎么做。一个大学生毕业了，他要去微软也好，他要卖猪肉也好，他要创业也好，他要做游戏代练也好，只要不犯法，不害人，都没有什么关系，要紧的是，选择了以后，怎么把事情做好。 你还可以选择时间和环境，比如，你可以选择把这辈子最大的困难放在最有体力最有精力的时候，也可以走一步看一步，等到了40岁再说，只是到了40多岁，那正是一辈子最脆弱的时候，上有老下有小，如果在那个时候碰上了职业危机，实在是一件很苦恼的事情。与其如此不如在20多岁30多岁的时候吃点苦，好让自己脆弱的时候活得从容一些。你可以选择在温室里成长，也可以选择到野外磨砺，你可以选择在办公室吹冷气的工作，也可以选择40度的酷热下，去见你的客户，只是，这一切最终会累积起来，引导你到你应得的未来。 选择职业销售就是一门跟人打交道的学问，而管理其实也是跟人打交道的学问，这两者之中有很多相通的东西，他们的共同目标就是“让别人去做某件特定的事情。”而财务则是从数字的层面了解生意的本质，从宏观上看待生意的本质，对于一个生意是否挣钱，是否可以正常运作有着最深刻的认识。 公司小的时候是销售主导公司，而公司大的时候是财务主导公司，销售的局限性在于只看人情不看数字，财务的局限性在于只看数字不看人情。公司初期，运营成本低，有订单就活得下去，跟客户也没有什么谈判的条件，别人肯给生意做已经谢天谢地了，这个时候订单压倒一切，客户的要求压倒一切，所以当然要顾人情。公司大了以后，一切都要规范化，免得因为不规范引起一些不必要的风险，同时运营成本也变高，必须提高利润率，把有限的资金放到最有产出的地方。对于上市公司来说，股东才不管你客户是不是最近出国，最近是不是那个省又在搞严打，到了时候就要把业绩拿出来，拿不出来就抛股票，这个时候就是数字压倒一切。 开始的时候我们想“能做什么？”，等到公司做大了有规模了，我们想“不能做什么。”很多人在工作中觉得为什么领导这么保守，这也不行那也不行，错过很多机会。很多时候是因为，你还年轻，你想的是“能做什么”，而作为公司领导要考虑的方面很多，他比较关心“不能做什么”。 践行有人会说，你说得容易，我每天加班，不加班老板就会把我炒掉，每天累得要死，哪有时间娱乐、社交、锻炼？那是人们把目标设定太高的缘故，如果你还在动不动就会被老板炒掉的边缘，那么你当然不能设立太高的目标，难道你还想每天去打高尔夫？你没时间去健身房锻炼身体，但是上下班的时候多走几步可以吧，有楼梯的时候走走楼梯不走电梯可以吧？办公的间隙扭扭脖子拉拉肩膀做做俯卧撑可以吧？谁规定锻炼就一定要拿出每天2个小时去健身房？你没时间社交，每月参加郊游一次可以吧，周末去参加个什么音乐班，绘画班之类的可以吧，去尝试认识一些同行，和他们找机会交流交流可以吧？开始的时候总是有些难的，但迈出这一步就会向良性循环的方向发展。而每天工作得很苦闷，剩下的时间用来咀嚼苦闷，只会陷入恶性循环，让生活更加糟糕。 墓志铭由于受我父亲早逝的影响，我很早就下定决心，要在有生之年实现自己的愿望，我不要像我父亲一样，为家庭生活忙碌一辈子，临终前感伤，懊恼自己有很多没有实现的理想。一本杂志的文章提到我们在生前就应该思考自己的墓志铭，因为那代表你自己对完美人生的定义，我们应该尽可能在有生之年去实现它。Carly Fiorina曾经对我说过“这个世界上有好想法的人很多，但有能力去实现的人很少”，2007年5月21日在北大演讲时，有人问起那些书对我影响较大，我想对我人生观有影响的其中一本书叫 “TriggerPoint”，它的主要观点是：人生最需要的不是规划，而是在适当的时机掌握机会，采取行动。 和任何人一样，要丢掉自己现在所拥有的，所熟悉的环境及稳定的收入，转到一条自己未曾经历过，存在未知风险的道路，需要绝大的勇气，家人的支持和好友的鼓励。有舍才有得，真是知易行难，我很高兴自己终于跨出了第一步。因为割舍及改变对人是多么的困难，我相信大部分的人都有自己人生的理想，但我也相信很多人最终只是把这些理想当成是幻想，然后不断的为自己寻找不能实现的藉口，南非前总统曼德拉曾经说过，“与改变世界相比，改变自己更困难”，真是一针见血。 LakeTahoe我去了多次，但这次的体验有所不同，我从心里欣赏到它的美丽。 我的人生观是“完美的演出来自充分的准备”，“勇于改变自己，适应不断变化的环境，机会将不断出现”，“快乐及有意义的人生来自于实现自己心中的愿望，而非外在的掌声”。 我总结人生有三个阶段，一个阶段是为现实找一份工作，一个阶段是为现实，但可以选择一份自己愿意投入的工作，一个阶段是为理想去做一些事情。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"新生 —— 七年就是一辈子","date":"2017-01-15T10:00:18.000Z","path":"2017/01/15/MyShare/reborn-every-7-years/","text":"“我们的一生其实可以活很多辈子的…… —-李笑来” 没有任何工具能够直接令人进步。真正使人进步的其实只有两个字：践行。切记：只有行动才能发生改变。想到了，就按照正确的想法做了 —— 不管别人是否理解 —— 这就是践行。我这哪里是对自己狠啊？这根本就是对自己的爱惜啊！想到了，学到了，就当真了；当真了，就当真做了，且真的做到了，这才是践行。践行才是真正的学习与创作。讲道理的人很多，践行的人很少很少。 我们就好像计算机一样，通过不断打磨、升级概念与方法论来升级我们自己的操作系统； 我们相信通过学习获得重生 —— 对我们来说，七年就是一辈子。每一辈子都要至少习得一个重要的技能，进而获得不可逆的重生。第一年可以像苍蝇一样左冲右突，一旦找到了突破口就要像蜜蜂一样，朝着既定的方向不断飞行。习得任何技能的过程中，我们都知道刻意训练并不依赖任何运气，只要付出就有收获。越是早期，越应该花更多时间精力去学习（磨练技能）。我们就是相信学识决定一切。 我们崇尚自学，认为没有自学能力的人尚不成熟。我们学习学习再学习。我们向往更好的生活，我们相信本质上一切都依赖学识。我们相信一切的努力都遵循复利效应，只要有耐心，通过积累，就可以达到之前无法想象的效果。财富、能力、魅力，以及抵御变故的能量…… 都是靠积累获得的，都有复利效应。我们相信惊喜（serendipity）其实是复利效应的终极体现。我们总是尝试着融会贯通…… 学习其实很简单，核心只不过是深入理解最重要的概念，不断总结与之相关的方法论。这样的朴素总结，使得我们很容易量化自己的进步 —— 看看自己过去一段时间里习得、打磨的概念与方法论数量就可以了。衡量学习效果的标准也很清楚：生活没有随之改变，就是没学会、没学好 —— 因为只有践行才是唯一有效的学习手段。我们不需要榜样，我们要成为他人的榜样。 要经常全无功利地学习 —— 只有这样才有更多的意外好运。我们向任何人学习，只要他们有长处，我们知道研究别人的失败比研究别人的成功更有价值。 我们珍爱家人，知道那是我们与这个世界最重要的关联。我们珍惜朋友，清楚他们的价值，也时时刻刻在寻找战友；我们寻找共同的价值取向，我们渴望改变自己，也渴望与战友共同参与到这个世界的逐步变好的过程中。我们通过努力把学习变成乐趣，不仅是为了自己，更是为了下一代 —— 聪明不能通过基因遗传，但绝对靠环境的潜移默化影响。 我们不花时间与他人争论，我们只为了弄清楚事实而讨论。我们不鄙视他人的能力 —— 我们自己曾经也能力不足，我们倒是不怕自黑，不过，我们更愿意与那些欣赏我们的人共同成长。我们懂得如何调整焦点，我们会主动尝试从多个角度去看待问题；我们不会把时间浪费在无谓的情绪之中，我们会用时间精力改变那些能够改变的事情。 我们不是圣人，肯定不小心会犯错。做错了事，我们不会逃避，我们不会只用嘴道歉，我们会想办法尽力用行动去弥补，只有这样做才能证明我们是负责任的人。犯了错，我们会认错；若是当初选择错误，我们会接受后果。我们量力而行，我们知道自己不断进步是为了即便出了更大的错误或者麻烦，也依然有能力承担、承受。生活中我们早晚会遇到各式各样的问题，它也总是反复无常，在不同的情况下，我们可能会调整模式，在极端的逆境中，我们也会想办法不被击败。 掌握任何一项新的重要技能，都相当于重生。学了却没有改变生活，那其实就是根本没学会。 重生的手段倒也简单：学习。学习新技能、走入新领域，循环往复。 学习学习再学习 我所说的“学习学习再学习”，不是由三个动词构成的句子；在这个句子中，第一个学习是动词，第二个学习是名词，第三个学习是动词。所以我的意思是说：要先学会学习这件事儿然后再去接着学习，这样才真的有意思。真的不是“学啊学啊学”的意思，更不是所谓的“重要的事情要说三遍”…… 《把时间当作朋友》 一本讲“如何正常、正确思考”的书籍，而不是一本“时间管理书籍” —— 因为时间其实不可管理，所以还是最好管管自己罢。而所谓的成功，其实只不过是用正确的方式去做正确的事情，耐心等待正确的结果出现。所以必须学会正常、正确思考，否则想错了的话，就做错了事情，做错事情的时候，效率越高越可怕，不是吗？选择了正确的事情之后，正确的方式是什么呢？是“一切都靠积累”。 史蒂夫·乔布斯 “You can’t connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in your future.”你无法连接未来的点，你只能连接过去的点。所以你只能也最好相信那些点终究会连起来。乔布斯就是把东西做到最好的人，这是他最可贵的地方。他是神一样的销售，他创造奇迹 —— 别人做不到他却做得到的事儿就是奇迹，这很朴素的道理。他把东西做到最好，好到什么程度呢？苹果也有很多不可理喻的地方，但不重要了，因为其它地方实在是太好了，好到用户无法舍弃的地步。就是这样。 李笑来当年我费尽周折应聘进入新东方，对我个人来说，是个突破。小时候学了点编程原理得过大奖却没能够被保送进清华但终究有点计算机常识；读了完全不喜欢的会计专业却因此收获了最重要的知识：概率和统计；因为本专业并不精湛所以毕业之后只能去做销售却因此锻炼了演讲能力 —— 就是这三点使得我在突破之后成为最受欢迎的老师。突破是突破了，这样的结果，其实并不是“设计”，却也不完全是“偶然”。 再后来的《把时间当作朋友》创作，对我个人来说也是一次突破。教写作不是我的计划与设计，只是教阅读的我听从领导安排去教大家不愿意教的课程 —— 没人愿意教写作课，都觉得费力不讨好。为了教好，自己就要学好，写好。前后写了大量的英文文章，反过来中文竟然写得比以前更清澈了，我自己也没想到。而最终提炼出“时间不可管理”，其实是在写作过程中闪现的“灵感” —— 这一点从我最初给那系列文章取的名字就看得出来：《管理我的时间》…… 在反复折腾中抵达了一个之前完全看不见、想不到的地方。 创建 Knewone，收割大量的比特币，创建比特基金，参与若干个创业项目，甚至像是玩票一样的 Telegram 第三方客户端 Dove…… 这些都是今天我正在做一个教育类社群的成因，但还是相同的类比：是破冰，而不是登山。哪怕在 2015 年的 10 月份，我还没有彻底明了我最终做出来的东西究竟是什么样的。整个破冰过程是 2015 年的 11 月才开始的，然后我就看到了另外一个之前完全无法想象的世界…… 很多道理上清楚正确的事情，却很少有人真的去做。 绝大多数人，差的其实只是一个机会和一点点的训练 —— 如若他真的有一颗不甘的心。恰当的机会、恰当的训练，就是可能让一个人脱胎换骨的 —— 就是我们反复提及的“重生”。 鸡汤 所谓的鸡汤，其实正确的概念名称应该是：进步方法论。 爱因斯坦 “Compound interest is the eighth wonder of the world. He who understands it, earns it … he who doesn’t … pays it.” 复利是世界第八大奇迹。知之者赚、不知之者被赚。 笨蛋 别笑，别以为自己不是笨蛋，我们每个人都有可能是，或者必然曾经是。 复利效应 万幸的、也是公平的是，每个人都一样，在智力上、知识上、经验上，复利效应依然存在的 —— 这是多么令人喜出望外的事实啊！只要能积累的东西，基本上最终都会产生复利效应。如果没有继承资产，那么就持续积累知识罢，我们运气真的很好。我们恰恰活在一个知识变现很容易、且越来越容易、且变现金额越来越大的时代。在没有继承资产的情况下。我选择了知识积累，并且笃信知识的效用 —— 我知道、我相信，在许多年后的某一天，知识会变现的，而且它一旦变现，很可能瞬间就能抵消过往所有的挫折。结果呢？所谓的“许多年之后”，在我 39 岁那年（2011）的时候来临了…… “逃逸速度”（Escape Velocity），又叫做第二宇宙速度（Second Cosmic Velocity） 第一宇宙速度是 7.9 km/s —— 用这个起始速度发射，航天器可以环绕地球飞行； 若是起始速度超过 11.2 km/s，即超过第二宇宙速度，那么航天器可以摆脱地球引力的束缚，飞离地球…… 第三宇宙速度，16.7 km/s，可以让航天器飞离太阳系， 第四宇宙速度，大约应该是 52.5 km/s，能飞离银河系…… 航天飞行器怎么飞起来的呢？科学家们要考虑的是这么几件事情，航天飞行器的重量、起始的速度、可携带的燃料数量 —— 要命的是燃料箱本身也有重量…… 所以，科学家们想出来的办法是，飞到一定高度之后，把一节燃料箱丢弃掉（jettison），降低飞行器的重量；再飞高一段距离之后，还要再丢掉另外一节燃料箱…… 知识是有能量的，且不受“重力加速度”的限制。 你的商业计划就是你的赚钱计划。 既然商业计划就是赚钱计划，这样朴素的描述，使得衡量商业计划的标准特别简单： 你可能赚到多少钱？你最快多久可能赚到那么多钱？注意措辞：是“可能”，不是必然，不是必须。另外，快不是一个单独的变量，数量和速度放在一起才有意义。获得经济自由的方法很简单：就是靠朴素的思考、朴素的方法论、朴素的践行 个人品牌 “个人品牌”的积累，从使用实名那一瞬间开始……认真给自己找乐子的人没办法不招别人喜欢。新鲜感其实完全是可以自己创造的麽！我今天的写作能力也是通过很长很长时间才磨炼出来的。你的苦没人知道。所以，从此坚决不抱怨。但凡有点办法的人，就忙着做事去了，抱怨、诉苦管啥用啊？这就是我的看法。没人害你，你也可能很倒霉。关键时刻，谁都帮不上忙，只能靠自己。 灵感灵感更多的时候是创作过程中获得的，而不是创作的起点。 评论 不删除评论是很重要的，先不说那些冠冕堂皇的话，比如， “你有表达的的自由，我有捍卫你表达的自由的权利”，只说说这对自己的用处：若是真能做到心平气和，那些反对你的和辱骂你的留言和评论，作用很多： 给你一些线索去理解那些人的思考方式； 偶尔你会发现自己的表达不清楚才招致误解； 还有些时候恰恰因为它们的存在而能确认自己确实是对的……绝对不删除任何评论，在那几年里给我带来了另外一个好处：性情真的淡定起来，开始变得很难生气或者难过。 情绪 许多年后，我一直觉得那段经历是我幸运的起点之一，因为我后来的淡定的性格，几乎真的是从那时候开始的，情绪的鸿沟，只要真正跨越一次，就真的不可逆了，因为你已经明白一个道理，情绪与目标无关，相对于“达成目标”只有行动才是相关事件。失败不可怕，可怕的是差一点成功了。关键时刻，不要掉链子，没人能帮你，只有靠自己。情绪这东西，百无一用，行动才是必须的。 主动、创造 我希望有一天我能够卖我自己创造的东西，而不是别人的东西。虽然我不知道我能创造什么，但我知道我要成为一个有创造产品能力的人。在那段时间里，我做出了我人生第一个重大的主动的选择。这次的选择，却是主动的。我在挣扎中看到了自己的未来，我必须成为一个有创造能力的人这次的选择，其实是含混的，我甚至不知道将来要创造的是什么，我只知道我必须成为能创造的人。从 28 岁那次的主动选择之后，做出主动选择的难度在不断降低，所以，这一次再做出一个主动选择就很自然了。所有的重生都是主动的选择。衡量一个人是否真正活着的根本方法，就是看他是否有意愿、有能力做出主动的选择。 自欺欺人 我在某次事件中义愤填膺地觉得“不公平！”，并且四处游说…… 可事后反思的时候，发现自己真正想要的只不过是“分一杯羹”。在自欺欺人的状态下，很多卑劣的行动好像一下子就“理直气壮”、“光明正大”了似的；等冷静下来开始反思的时候，觉得自己每个毛孔都是肮脏的……甚至连呼吸的声音都是猥琐的。高品质生活完全从停止自欺欺人开始……我逐渐开始意识到很多情况下，抢占道德制高点是特愚蠢的事情……人们抢占道德制高点，只不过是被“自欺欺人”的心理所左右。我开始不怕被人们用道德的理由指责我了，我甚至开始懒得争辩，他们说他们的，我做我的，他们舒服他们的，我舒服我的，其实可以互不干涉，只不过是他们以为他们的干涉有用而已，我要是像之前那样一不小心就真的被他们干涉了，那才不划算呢。 犯错 人总是会犯错的——本质上来看，对大多数人来说，这只是运气不好，因为故意犯错的人是坏人，不在考虑范围内。 犯了错之后，绝大多数人只用嘴道歉。 表现更为恶劣的是掩盖、撒谎、或想办法证明对方也不是个好人……这些人其实已经差不多是坏人了， 再下一步就是用嘴道歉之后得不到原谅就说你小心眼啊、没风度啊、不够意思啊什么的，这样的人比坏人还坏。 只有少数人在发现自己不小心犯了错之后，马上用嘴道歉，随后开始用行动道歉，弥补，直至一切恢复原状，甚至比原来更好——这其中可能需要付出很多代价，但他们知道这是自己必须做的，否则就不再是自己。 Live with it! —— 这是我在电影里听到的最震撼心灵的台词。是啊，很多事，最终就留在那里，好啊、坏啊，不重要，重要的是它们挥之不去，一辈子都与你相伴。我用了好几年的时间，才渐渐地感觉自己干净了一些，清爽了一些，也因此感觉自己真的重生了。那几年过后，我开始变得宽容起来 —— 真正的宽容 —— 因为我自己是“走出来的人”。那“自欺欺人”就像个牢笼，何止啊？干脆是个“Panopticon”，我自己走出来了，就好像成功越狱一样，当然明了走出来多难，当然知道在里面多苦，不是吗？ 严于律己、宽于律人，对我来说不再是一句“有道理的废话”，而是清楚的实践。而且，这其实是一种“自私的实践”。严于律己，其实等同于在提高自己的效率；严于律人，其实等同于降低自己的效率，或者用另外一个说法就是，允许他人拖累自己的效率。与此同时，严于律人的副产品常常只不过是“凭什么让他们占便宜？” 或者 “我也不必当个好人罢？” 之类的特别容易转换为行动的愚蠢想法。自我治疗成功的另外一个副作用是，从此不害怕追求进步了。从此不再容易自卑。 “年轻的时候做了蠢事是正常的” —— 何止“正常”啊，简直是“必然”。每个人在成长过程中都会做一些这样那样的蠢事，关键在于一个人是否能够成长到可以承担那些责任，修复那些错误的地步 —— 大多数人不能。没有人是完美的，没有人不曾做过蠢事，即便有一天在某方面成功，也要永远面对自己曾经做过的蠢事，也要 live with it，扛一辈子…… 自信 人要有自信，但，应该是对自己的未来有自信，而对现在的自己，对过去的自己，自信、自负、自卑其实都是无意义的，要现实才对 —— 错了就是错了，蠢了就是蠢了，把自己变得更好才能弥补那些错误，才能承担当初的愚蠢。我应该对自己的未来自信，而不是对自己的现状自信……我能够真心为了别人的进步和成功感到高兴，说明我终于有了真正的自信。衡量一个人是否真正自信，就看他是否能真心为他人的成功而毫无芥蒂地感到高兴。 自卑 该自卑的时候就得自卑。生活中遇到问题，就犹如遇到一个已经被锁上了的锁头，而那钥匙一定不在锁孔里，否则那锁头一拧钥匙就开了啊。遇到打不开的锁头，当然要到其他地方找钥匙，而不是盯着锁头发呆。找钥匙所耗费的时间可能很短，也可能很久。“彻底消灭自卑”的钥匙我找了三十多年…… 找到之后才觉得自己好笨啊！ 停止嘲弄他人 忘记自己的优点 适当地放纵一下自己 自省自省真的是个艰苦卓绝的事情，虽然说起来的时候总是可以做到显得云淡风轻…… 比较拿着现状与他人相互比较，必然总有这样那样的不足 —— 而比较带来的幸福感，通常也是虚妄的。即便是要比较，那被比较的对象也应该是“自己的现状”和“自己的未来”；而不是“自己的现状”与“别人的现状”。为了自己有更好的未来，所以今天必须足够努力，反过来，今天要更加努力，也正因此才对自己有更好的未来确信不疑。(又一次 X 值相对下降，Y 值相对提高……) 错过 错过的原因，无非是一个念头，一个当时想当然的念头而已。这是个活生生的“ 一念之差 ”的例子。想当然的念头，常常来自于周遭环境，一团乱糟糟的东西打成包，直接植入了自己的操作系统，最要命的是它们通常还处于底层，所以才想当然，所以它们的害处才不易察觉。比如，“学外语很难的！” 就是个这样的“想当然的念头”，被打包植入了我们的操作系统，乃至于我们不由自主地变傻了…… 观念 人与人的差异在哪里？在我看来主要是观念上的差异。上面让我错过一辈子的，就是个落后的观念：别人做不好的，我也别做了罢……很多影响我们一生的，竟然都是很小，却又不成比例地重要的环节。 想当然与认知读一本好书，基本上就是对操作系统的一次升级 ，或者起码一点的升级（叫“打补丁”也可以）。然后呢？有的人一年升级 50 次以上，有的人起码 12 次，也有的人好几年都不升级，后来干脆就那么对付着用了，却也不觉得自己落后且越来越心安……很多其实很重要的建议，常常只不过是因为陈述过于笼统而难以传递，难以接受，难以践行。找出那些想当然的念头，挨个审视一遍，看看它对不对？有没有道理？是否应该被升级，或者被替换？这事儿一定要仔细，因为那些不经审视就嵌入操作系统的“想当然”实在是太危险了…… 类比计算机 我们自己其实就是这样的计算机，“厂商”（我们的父母）并没有为我们提供详尽的说明书，也并不负责定期升级我们的操作系统 —— 即便他们并非故意……每个人的大脑里其实都有一个属于自己的操作系统，真的跟计算机一样！每个人都有一套属于自己的输入输出体系（IO 系统），有着一套属于自己的运行处理机制。人和人之间很不一样，就好像计算机和计算机之间也很不一样。有些人的中央处理器（头脑）更强大一些，有些人的内存容量（记忆力）更大一些，有些人的硬盘空间（笔记与藏书）更大一些，有些人的显示器（外表）更漂亮一点，有些人的打印机（写作能力）相对比较高效，有些人配置了网卡（沟通能力）所以可以连网，有些人则不连网，有些人的带宽（沟通有效性）很足，有些人的带宽很小，有点人在互联网上（开放），有的人在局域网里（封闭）…… 操作系统升级 绝大多数人的操作系统竟然从不更新！粗糙、原始的操作系统的主要特征是：它越差就越自洽，漏洞百出却又能持续运转，最关键的是：它没有任何自动升级的机制。我们的操作系统主要由概念及其相关方法论两个紧密相关的部分构成我们操作系统里 —— 描述正确的、理解完整的概念和方法论越多，我们理解新概念、新方法论的速度越快，融会贯通能力也越强……理解速度快了，阅读速度放慢一点，效率可能更高呢。只不过是不断清理自己的概念、扔掉该废弃的，不断吸收新的、有必要的概念，并且通过应用不断完善与那些概念相关的方法论。所谓的“成长”就是操作系统不断完善的过程；所谓的“重生”就是操作系统更新换代的节点；所谓的“不断再生”就是我们意识到这些操作系统更新换代的必要性，于是给自己设置提醒模式，给自己发展自动更新模式的持续动力。(比如给自己设定每七年要有一次大的更新换代……) 硬件升级 所有的体育运动本质上都是在升级“硬件”。熟练使用工具，也是“升级”硬件的一种方法。很多人长期不升级自己的“硬件”的根本原因只不过是“没想到”罢了。 教育就像一副眼镜。 戴上眼镜之前和之后，我们看到的其实是同样的世界；但带上眼镜之后，我们就能看得更清楚。教育也一样，受教育之前与之后，我们身处的其实是同样的世界；可受教育之后，我们就能看得更清楚，想得更明白，选择得更有效，行动起来更有收获…… 科学与信息 VS 房子与砖头 科学确实是由信息构成的，正如房子是用砖头盖的一样。可问题在于，正如仅仅一堆砖头放在那里的时候我们不能称其为房子一样，一堆信息放在一块儿就叫科学，有点不像话…… 创造类比 创造类比本身就是难度很高的活动，一般人做不来 首先要有足够的知识、信息储备，才能在理解新事物的时候找到真正合适的、最恰当的那个“参照物”； 之所以能找到最恰当的，不仅仅是找到最“像”的那个，还要仔细搞清楚“不像”的地方究竟有哪些，以免在传递信息的时候出现偏差……类比也常常是产生“融会贯通”的手段。学会任何一个概念、方法论之后，都要问自己：这个道理还能用在什么地方？ 幸福 VS 商业 … all happy families are alike and all unhappy families are unhappy in their own special way, is not true in business, where I think all happy companies are different because they’re doing something very unique. All unhappy companies are alike because they failed to escape the essential sameness in competition.（这是个反向类比——即，你别以为它们一样，其实它们刚好相反……） ……据说，幸福婚姻都是一样的，不幸的婚姻各有各自的不幸；在商业世界里不是这样的，我倒是认为所有的幸福公司都是不一样的，因为他们都在做不同的事情。而所有不行的公司倒是一样的，因为他们都没能脱离竞争的相同窘境。 编辑 VS 管理 So one of the most important things I learned at Square is the concept of editing. And this is the best metaphor I have ever seen in 14 years of running stuff, of how to think about your job. 所以我在 Square 学到的最重要事情之一就是“编辑”的概念 —— 这是过去我在管理员工的 14 年经历中所遇到的关于如何看待（管理者）工作的最好隐喻（类比）。 “像”与“是”不小心混淆了“像”与“是”的人，在用类比理解新事物的时候，接着下一步要犯的错误就是“以偏概全” —— 因为新事物已经等同于（是）旧事物了，那就没什么需要“理解”的了嘛！更没有了继续研究得必要……理解了那“像”的部分之后，还要继续探究那些“不像”的部分，新事物之所以新，就是因为那些“不像”旧事物的部分啊！在面对新事物的时候，我总是告诫自己，暂时先克制寻找类比的冲动，因为不恰当的类比还不如没有类比，甚至，不恰当的类比干脆相当于有毒，会麻醉我们的大脑，阻止我们有效地思考。我总觉得，在对新事物有了足够的了解之后再去找类比不迟；而对新事物有足够的了解，也是有能力找到精妙类比的前提，万一找到了，可以自己用来辅助面向他人的说明，或者作为帮助他人的辅助理解工具…… 找不到很好的类比，也很正常。好的、精妙的类比超级炫酷，可还是要小心为妙，因为类比真的影响思维。 成功类比 好像人们都喜欢用“登山”去比喻成功的路径，也许“攀登”这个词本身就给人“进取”的印象罢。 可是长期以来，我觉得我所遇到的所有成功与突破，都更像是破冰。我总觉得自己站在一个冰原之上，特别想要把脚下的冰砸开…… 可无论是我使劲跺脚也好，满地打滚也罢，我总是没办法一下子成功，一下子突破。若非换个视角，或者谁给我个透视镜，我真不知道那冰实在是太厚了…… 往往是就好像我在冰原上四处游荡，四处猛砸，猛凿，有时深，有时浅，有时候甚至可以从冰缝或者冰洞里看到冰下的水，可那冰就是那么坚实，我死活都没办法破冰而入…… 还记得美剧越狱里主角是怎样运用胡克定律凿开那堵厚厚的、“坚不可摧”的墙的吗？ 终于破冰的那一瞬间，我的感觉就是，过往我砸过的、凿过冰缝、冰洞，终于以某种方式（几乎肯定是我之前完全不知道的方式）形成了一个三角，力学原理瞬间爆发，那冰一下子大面积破开…… 于是，我终于“入水”了。把登山当作类比，与把破冰当作类比，有一点不一样的地方。把登山当作类比的时候，我们会不由自主地以为“突破”是看得到目标的事情 —— 因为山顶就在那里。把破冰当作类比的时候，我就很自然地不太在意那个可以看得见、想得到的目标，很理直气壮地明白：我要去的是一个现在完全看不到的地方，但肯定是不一样的世界。 概念 概念是一切知识的基石我们要持续升级概念及其相关方法论我们描述一个人能力不够，或者全无能力的时候，经常这么说：xxx 在 yyy 方面根本没概念。司机坐在车里，有完全看不到的盲区车这东西，真不是司机想停下来的时候就能瞬间停下来的……行人在晚上穿着暗色衣服在路边走非常危险……在任何一个领域，对该领域中重要的概念无知，那就真的与白痴无异学习就是让自己变聪明的过程，习得那个领域中最重要的概念，琢磨清楚相关的方法论，就马上“不那么白痴了”。“上火”就是一个早就应该抛弃了的概念，正确的概念是“炎症”，或者“维生素供应不足”。 独立思考 能够独立地、正确地使用正确的概念。 读书 这么厚厚一本书，其实就那么几个概念；讲一个概念就要花费一个章节的篇幅，从结构上来看，其实讲的都一样，无非是一个接一个的概念，要说清楚它是什么，它不是什么，它和别的概念有什么异同；然后就是与它相关的方法论，比如，使用的时候需要注意什么，怎样使用是正确的，怎样使用是错误的，容易发生错误的地方是什么…… 这些都弄明白了，一个概念就算是学透了，这些概念都弄明白了，这本书算是看懂了，就这么简单。 那些之前属于“死记硬背”的东西，其实相当于给自己的大脑安装了很多个“传感器”，一旦听到有人提到它们，因为熟悉，脑子里就会有反应。若是之前完全没有过死记硬背，那些概念在脑子里根本不存在，那么在走神的时候，即便有人在身边提到那个东西，大脑也全然不会有所反应。 教育 今天学了什么呀？那 xxx 是 yyy 吗？那 xxx 为什么不是 yyy 呀？那 yyy 有什么用处啊？那我这么用 yyy 可不可以啊？今天有谁把 yyy 用错了啊？…… 阅读速度真正有意义值得研究的概念是：理解速度。输入是为了处理啊，胡乱处理，甚至无法处理，输入了也没用啊！读书不是吃东西啊，读书就算有点像吃东西，那也是要消化了之后再排泄啊！不消化很难受的好不好？若是阅读速度快就可以了的话，那么谁都拼不过复印机了罢？开什么玩笑？！ 固守与进取人分为两种，一种是固守型的（Be Good Type），一种是进取型的（Be Better Type）。这两种人的主要区别在于，他们做事的时候，关注的焦点不一样：固守型的人（Be Good Type）更关注自己当时的表现，更在意外界对那表现的看法；进取型的人（Be Better Type）更关注自己当时有无进步，并不在意对外界的看法； 第一种人过分在意自己当时当刻的表现，直接带来的结果就是，如果“感觉有可能做不好”，就直接不做了 —— 省的丢人。第二种人常常并不在意外界的看法，他们知道自己有可能做得并不好，但这并不妨碍他们进步，只要下一次比这一次更好，就是他们想要的结果。他们更习惯于接受挑战，处理压力，更懂得积累的好处。 面对同样的压力，这两种人会做出截然相反的选择。固守型的人，在压力下表现会更差，表现差会进一步导致他全方位溃退。进取型的人，在压力下反倒可能更有动力，因为历史经验反复告诉他自己总会越来越好的…… X和Y评测 固守型、进取型这两个重要的概念来自于一本书，《成功，动机与目标》(Succeed: How Can We Reach Our Goals, by Heidi Grant Halvorson)。Halvorson 博士在书中给出了一个小调查文件，用来让读者自行判断自己究竟属于哪一种人：认真地问自己以下问题，如实地回答自己，给每一个问题打分。一点都不同意，是1分，非常正确是6分。 功课或者工作比同学、同事做的更好对我来说非常重要。 我喜欢能让我更了解自己的朋友，尽管有时候得到的不是正面信息。 我常常寻找开发新技能、汲取新知识的机会。 我很在乎是否给人留下好印象。 展示自己的聪明才智与能力对我来说很重要。 我努力和朋友及熟人保持开诚布公的关系。 我努力在学校或者工作中不断学习与进步。 当我和其他人在一起时，我很在意给别人留下的印象如何。 当我知道别人喜欢我时，自我感觉会很好。 我试图比同学或同事更出色。 我喜欢别人挑战我，从而使我成长。 在上学或上班时，我注重施展我的本领。 现在请把第1、4、5、8、9、10、12题的得分相加之后除以7，记为 X。再把第2、3、6、7、11题的得分想家之后除以5，记为 Y。最终，你的得分中，X 和 Y 哪个数值更大呢？X 数值更大的人倾向于“表现导向”（Be-Good Type）；而 Y 数值更大的人倾向于“进步导向”（Be-Better Type）。 有个简便的方法判断一个人的 X 值是否过高？“你只要看他是否害怕被他人嘲弄？”固守型这类人的主要特征是“死要面子活受罪”，但更为可怕的是，他们无法进步。 压力 致命的不是压力本身，而是压力与观念（认为压力有害健康甚至致命）的组合。“很多人其实是被自己慢慢吓死的……”人就是这样一种动物：”心理与生理相互影响。” 成长 学会了哪些原本不知道的概念和方法论？？哪些已有的概念和方法论被进一步打磨了？这样的描述使得“成长”多少可被量化 —— “可量化”很重要，因为量化的结果是最好的反馈。成长从来都是需要过程的（常常是漫长的过程），需要不断有足够的反馈机制去激励。成长可量化了，它就有了足够的动力。而这本身，也是“成长与重生的方法论”。一切都是学识决定的。很多的时候，所谓的耐心、所谓的沉得住气，其实是学识 —— 学识决定一切。 非议、争论，与鄙视链 所谓的“超常的应急反应”其实是可以提前通过各种假想和预演提前反复练习的……善恶其实是次要的。所谓“人人心里有杆秤”——那秤称的其实是强弱。面对非议的时候，真正要解决的问题不是去辩解，而是想办法让自己变得更强。弱者的逻辑都一样，奇葩而又自洽爷又不是人民币，怎么可能谁都喜欢？自己错了，就承认，并且想办法承担后果 —— 我觉得大丈夫就应该这样。而别人错了，承认与承担都是别人的事情，用不着我去操心；如果那错造成了我的损失，可也无法上升到法律保护高度，那我就懒得追究 —— 因为我自认自己的时间精力更为宝贵，不应该浪费在这样的地方，甚至连生气的必要都没有，大好的人生在等着自己，哪里有功夫理会那些？你所处在的那个位置，常常会决定你的视角“有些事情跟处女就不要说了罢” —— 这是一个很好的类比，因为有些人的立场，是不可能有另外一些体验、经历所支持的。这是一方面，于此同时，“有些话跟已经离婚的人就别说了罢” —— 这还是个很好的类比，因为有些人的立场，是不再可能有另外一些体验经历所支持的，因为他们已经确定不会有“百年好合”的结果了。 你手里攥着某个公司的股票（数量很多），那么你的立场就与那些光说不练的股评师不同；跟那些买一点见好就收的短线操作者不同；其实你的立场通常也与董事会那些大股东非常不同…… 在这种情况下，有些争论，其实并不是道理上的冲突，只不过是视角不同、层面不同而已。 最终的数据表明，无论是哪一方都得到了印证自己想法的结果…相信“压力影响健康”的人，健康就真的受到了影响；相信“压力不影响健康”的人，健康就真的没有受到影响 ——这种观念影响结局的现象，使得有些争论永无平息之日，因为从争论双方各自的视角来看，自己都是天经地义地正确的！ 讨论的目标是为了让自己更明白争论的目标是为了彻底说服对方 争论的冲动常常来于自己的弱小。人微易怒。弱小的个体更容易闹情绪，若是有情绪掺杂，那么言论就越发地不靠谱，不靠谱的言论又掺杂着更多的情绪，恶性循环生生不息。彻底逃离鄙视链。有些事情，尤其是倒霉事情，其实是自找的鄙视链也是一样的，那是个循环嵌套的局，一旦置身其中，必然会反过来被鄙视，早晚而已，私下或者公开，谁都逃不掉。不想被鄙视，就别在那个局里。事实上，即便你挣扎着脱离了那个局，一样会被莫名其妙的人鄙视，只不过，因为你自己不在那个局里，所以你清醒，所以你知道，那鄙视是那个人的幻觉，跟你完全没关系。时常反省，就会知道鄙视与争论一样，通常是自身弱小才更容易产生的冲动，常常是自欺欺人的表现。嗯，被鄙视，其实是自找的。 计算机 计算机是由我们人类中的极少数极少数人 —— 比例上来看可能连千万分之一都不到 —— 发明并持续研究完善出来的东西。所以，我们从计算机上可以学到的，其实是极少数极少数聪明人的思维方式和方法论。 通信协议 不同的操作系统之间的通讯，是需要共同的协议支撑的，不使用共同的协议的计算机之间没办法通讯。在互联网上，最常见的协议是 TCP/IP 协议。TCP/IP 协议的运行机理大致如下：网络上有很多台计算机（A ~ Z）相互联网，它们之间使用相同的协议传输数据……A 若是需要传输数据给 Z，那么之前需要 A 与 Z 握手三次，才能确定连接有效…… A 必须先把数据切分成若干个小的数据块，然后逐一传输出去…… A 送出的每个小数据块，到达 Z 的路径每次都可能并不相同：不一定是直接的 A-Z，可能是 A-B-X-Z，可能是 A-X-C-Z，也可能是 A-B-C-Z…… 反正是个各自相通的网络么，所以，无论选择什么路径，只要能够到达就可以…… Z 一旦收到了小数据块，会发出回执，A 收到上一条回执之后就会发出下一条，若是在设定的时间窗口中未获得回执，则判定传输失败，放弃继续传输…… 直至所有数据块全部发送完毕，A 收到所有收据之后，再发出一个“发送完毕”的消息（这个消息也会返回一个收据），Z 在另外一端再把所有数据块按照顺序拼起来，形成一个完整的数据…… 沟通借鉴 很多事儿，其实很复杂，想要一下子说明白，一下子让对方想通，是很难的，甚至是不可能的。那怎么办？必须把整个事情提前拆分好，分清楚主次，分清楚先后，然后一件一件地来，并且在这过程中，还要反复确认确实沟通成功才能进行下一步……沟通成功的关键在于：双方都是讲道理的人（就是肯遵守协议的人）。 我要做好至少尝试确认三次是否真的可以开始沟通； 沟通有很多种方式(至少有直接沟通和间接沟通两种)，不能局限在特定的某种方式上； 我要有个办法确认每次沟通确实成功； 如果事儿足够大，我就会切块，分步沟通； 总而言之每个环节上都一定要有清楚的确认机制…… 夫妻为什么吵架 在选择伴侣的时候，最好……寻找同级别的操作系统；要升级就大家一块儿升级……“门当户对”，其实就可能是为了找到“合适的、可兼容的操作系统”“三观不和最伤感情了……”，其实真的不是玩笑。的确如此，从某个角度望过去，所谓的三观，就是在说操作系统的一部分。保持对异性的魅力的方法其实很简单：持续学习，不断进步。为什么婚姻中普遍存在所谓的“七年之痒”？我的解释是很简单：七年就是一辈子，一辈子都过去了，下辈子还要过同样的生活，多腻歪啊。 底层概念差异 主次不分 价值观不同 立场不同 历史不同 无仲裁夫妻不吵架或者逐步减少吵架频率的方法论无非是：共同“创建”协议，共同”遵守”协议，共同”升级”协议…… 身边还有很多原本应该很亲近但实际上却不那么亲近的人 —— 亲戚。不知道为什么，我发现亲戚竟然是最难与之共同成长群体，也许是现代人的生活结构发生了变化罢。另外一个群体也是如此，老同学 —— 明明心里有那么多的亲近之感，但确实早就失去了共同成长的机会。那怎么办？在自己的大脑里也多创建几个虚拟机才对啊！这真是非常先进的方法论！—— 说多少遍都不过份：向计算机科学学习思考，等同于向地球上最聪明的人学习思考……教书的时候，之所以被学生“感觉教得好”，无非就是相当于我在脑子里开启了一个与他们一样操作系统的虚拟机，所以我知道他们跑出来的结果是什么样的，所以我才有清楚的解决方案啊…… 有规定没问题啊，拿出来给我看看呗……先说清楚啊，我一会儿哪怕嗓门大了，也不是针对你个人，是被你们公司气的…… 生气，是最浪费时间的行为。浪费的不仅仅是气头上的那一段时间，更为可怕的是在气头上做的决定常常连带一个很微妙且又复杂当期影响，最可怕的是，这个影响其实很容易产生“复利效应”，我的意思是说，“负面的复利效应”……首先，不能生气。其次，在不生气的情况下，偶尔可以假装生气，这是工具。再次，一定要先表明立场和态度。最后，只说道理上百分之百站得住脚的话。 多赚钱，快赚钱，有钱到吃得起亏的地步。吃不起亏，就很容易生气；很生气，就很容易失控，最终无法解决问题，既浪费了时间，又不得不接受不好的结果，于是恶性循环……哪里有什么好脾气啊，只有想的明白和想不明白…… 因为想不明白而抓耳挠腮的时候多的去了，实际上，我自己天天都有生气的时候，气自己为什么那么笨，连这点问题都解决不了…… 能解决问题就不用生气了罢。 什么是朋友？ 朋友就是那些与我们共度时光，让我们感觉温暖，让我们心甘情愿地付出的人。而这里所说的付出，常常是我愿意花时间、花精力主动联络，主动维系友谊的那些人。因为老朋友的稀缺性，自己开始为这个类别增加了一个原则：轻易不跟他们产生合作关系，生怕伤到这个稀缺的存在。不是不，而是轻易不，这其实是一种尊重。成熟的特征就是独立，独立的意思是说，生活上、经济上越来越不依赖朋友的存在，朋友更多是精神上的需求。 朋友就是那些愿意与我交往，并且我也钦佩的人。朋友就是那些我愿意花时间与精力，与之共同做成至少一件事儿的人。 对朋友、友情的定义，其实背后是一个很简单很清晰的过程： 依附 独立 共生 友谊中最有价值的部分来自于各自的成长或者共同成长。 维系任何一个关系，都需要有一个主动的人存在，否则，总会渐渐淡忘。这当然也是很多朋友这么长时间以来一直能跟我保持联系的重要原因。每个人的时间都有限，必须认真选择值得花时间的人，否则不划算。于是，我有了几个简单的标准，作为我甄别朋友的方法论： 一技之长追求进步真诚热情 所谓的大牛，就是那些有能力构建自己的世界的人。用嘴道歉的人不值得交往，用行动道歉的人遇到一个就要珍惜一个。 所谓的情商，指的是一个人有多大的能力去创造共赢局面。不要说多人，就是两个人交往，也最好尽量避免求人的状态，这样的关系没办法长久。最好是能够创造一个两人共赢的局面，各自都开心。这不太容易做到，但肯定值得为此多花时间做功课。 有些人别说战友了，连朋友都做不得，尤其是那种“死要面子活受罪”的人。他们总是毫无主张（就是其实没脑子），遇事总是各种纠结（还是没脑子），要么唉声叹气地抱怨，要么无能地暴跳如雷（反正就是没脑子）……遇到这种人，一定要当机立断地断舍离，顶多偶尔为他们打开一个虚拟机，应付一下，但有一扇大门一定要直接关掉，让他们绝对没办法进入属于你的那个领域。 朋友不会自动变为战友。要满足以下几个条件或者经过以下几个阶段，朋友才可能转变成战友：共同目标并肩战斗共享成果 找到共同的目标，并且经过沟通，确立共同的目标，这很重要 —— 否则没有战斗，就算有也是各自的战斗。有了共同的目标，才有并肩战斗，才有同甘共苦，才有荣辱与共，才有出生入死，才有共进退……没有共同目标的，不是战友，是狐朋狗友，不是团队，是团伙。所谓战斗力，长期来看，是脑力，而不是体力，核心是学习能力。要先把自己变成战士，然后才有资格寻找到其他的战士，找到共同目标之后，成为战友，然后共同浴血奋战，达成成就。看看历史书吧，有一个生死战友，就很厉害了，陈胜、吴广，各自只有一个真正的生死战友；有两个生死战友，就可以桃园三结义了……创个业什么的，根本不是什么事儿罢？所谓的领导力，其实就是带着战友战斗，然后自己成长，也帮助他们成长，帮助战友再找到战友……两三个层级下来，就形成了一个真正的团队。 真正有用的书，一本就可能完全改变生活 做出真正好的东西，销售就好像是不存在了一样，放在那里就行 —— 为什么呢？因为这是互联网时代。《把时间当作朋友》更是印证了这个看法，在免费版一直放在网上的情况下，印刷版销量一样也是多年逐步攀升。 把东西做到真好，直至最好，其实是最省心、最省时的方法论。它若是真的已经最好了，任何“推销”都是没必要的。不用费心给别人理论为什么我这个东西最好，也不用理论为什么你一定要买我的东西…… 完全不用。 不学习就要挨打，这肯定是真的。 做出最好的东西，不是不讲理，而是不用讲理了 —— 因为把东西做到最好，就是最大的理，这事儿都做完了，还有啥可讲的？你都把东西做到最好了，还有人说三道四，那就随他们去罢，忽略他们，过滤掉他们，没时间跟他们打交道，就是这样。 这是一个物资极为丰富的时代，这是个任何人都可以光明正大赚到足够多钱的时代。在这样的一个时代里，没必要偷偷摸摸地赚钱，没必要昧着良心做事，没必要靠着雕虫小计讨生活。我希望这不是技巧。这应该只是一个习惯：把客户真的当作好朋友。真的做到这点，你就会发现自己的整个想法都可能变了。别说不好意思，你就是不愿意把不好的东西卖给朋友的。甚至即便是好东西，也要三思而行，万一有什么闪失怎么办？别说卖了，哪怕推荐都要自然而然地三思而行。 那些酒肉朋友，那些平日里跟你热闹的人，绝大多数都是靠不住的。 把东西做到最好的人，往往能自然而然地享受这世上看起来最好的一种状态：头上有光环。光环效应同时可能是毁人的。光环效应之所以存在，并且能量巨大，本质上就是因为绝大多数人无能力判断，甚至不知道自己其实完全无能力判断。于是，光环效应是迷惑人的，但创造者要抵御这股力量，不能被自己的光环晃瞎了自己的眼镜，灼坏了自己的脑子，要想尽一切办法继续做出更好的东西。 说服他人有两个重要的终极诀窍。践行，才是真正的学习；也只有践行，才可能带来真正的改变；只有改变，才会成为榜样。若是已经成为了榜样，根本不需要说服过程，用不着费那些口舌。就是这样。榜样其实不需要完美。只需要确实不断进步，就已经是神一样的榜样了……有效沟通，真的很难。与其花时间精力推销，还真不如把那时间花在自己身上，默默地成为榜样好了。 第一个：让对方自己得出结论，而不是把结论塞给对方。第二个，实际上是第一个的升级版：自己成为榜样，对方若是认同，自然就会追随。 解决问题 解决问题的能力，是人生最重要的能力。遇到解决不了的问题，就烦恼，就痛苦；同样遇到问题，别人解决不了，你能解决，那你就高人一等；别人都解决不了，只有你能解决，那你就可以算作英雄了 —— 这么说并不夸张，因为历史上所有的英雄，本质上来看其实都是解决问题的高手。 （一）有些问题是永远解决不了的（二）有些问题是不用解决的（三）有些问题可能会自动消失（四）有些问题是自己造成的（五）有些问题是其他人的问题（六）有些问题是所有人的问题（七）大多数问题需要特定的人解决 面对永存问题，尽力就好。 “魔鬼在细节之中”，换个朴素的说法：细节很重要。说实话，我并不反对这个建议，但我很少把它当回事儿 —— 更多情况下，我觉得“细节很重要”是用来吓唬那些没做成过事儿甚至压根就没做过事儿的人的。因为最重要的东西没做好，细节再好没用。看看素描初学者的作品就知道了，看着石膏雕塑在纸上把头像上的某一只眼睛画得精准是完全没用的……永远问自己，“什么是最重要的？” —— 先去做那些真正重要、最重要的事儿，先去解决那些真正重要、最重要的问题，至于细节么，那是要等到前面那些事儿做完之后再去做的事情……所以，有些问题不用解决，至少不用在最重要的问题被解决之前解决。 完美主义彻底的完美主义者都是脆弱的。 事实上也确实如此，彻头彻尾的完美主义者是不懂“永存问题”这个概念的，他们离这世界的真相太远，又不自知，于是脑子里追求完美，行动上永远做不到，真的是压力山大，最终都有自杀倾向，这是事实。 演讲 最重要的是什么？ 最重要的是我要有足够好的内容。在讲演的时候，什么是足够好的内容？ 我有没有向听众传递他们之前未知的信息？（已知 vs. 未知） 我有没有向听众传递他们之前未重视的信息？（次要 vs. 重要） 我有没有向听众传递理解足够简单应用足够容易的方法论？（简单 vs. 复杂） 有一点问题就坐立不安的人，本质上只是天真。一般来说，公司内部的问题，基本上都是由于发展不够快，或者发展放缓造成的，够快地发展，持续地发展，相当于免疫力，大多数问题只不过是感冒，甚至不需要治疗，它们并不是癌症晚期之类的不治之症。 英语学习很多人问我，零基础如何开始学英语…… 我很难回答，因为我知道， 大多数人根本不是零基础，而是负基础 —— 这是我不太敢告诉他们的事情。很多人岁数一大把了（二十一岁在我眼里就是三把岁数了……），母语的语文功底还是几近于零，还想学外语，这不是负基础嘛！因为，所有语言的基础元素都是相通的，尽管细节上有差异…… 绝大多数人的母语是完全不过关的，只不过处于“识字而已”的水平 文章逻辑复杂一点，就各种凌乱，读不懂； 文章篇幅稍微长一点，就根本没耐心看完； 自己从来写不出一篇完整的文章； 大多数人看别人写的文章只能不服气，却无法做到有理有据地反驳重点； 很多人连个产品说明书都读不懂； 连个租房合同都不会写，甚至不会读，最终要去打官司，然后还要吃亏； 别说读书学习了，就是读个小说看个电影消遣一下，也常常被带入阴沟而不自知…… 基础很重要！ 这么朴素、简单、有效的建议，绝大多数人这一生都没听进去过 —— 然后，最令人啼笑皆非的是，一生都要为此付出巨大代价却又从不自知。 比如，国内校外英语培训机构的所有收入都来自于那些“一辈子都没学会主动查字典、用语法书的人” —— 这是个可以生出若干个上市公司的庞大产业，我从来不觉得那是教育，我只觉得那是在欺负人…… 不过，被欺负的人们在被欺负这件事儿上倒是主动得很，甚至享受得很，这真是颇有些令人意外。 再比如，各种庞氏骗局，连绵不断，生生不息。为什么呢？很多人没有过恰当的基础理财教育，不懂得 a) 10% 以上的利息就已经开始伴随着巨大的风险，不懂得 b) 本金安全比收益更重要（重要很多倍！）…… 就是这么两个基础概念的缺失，造成了一片又一片的受害者，业内叫“一茬又一茬的韭菜”…… “不一样”的观念 时间就是不可管理的，管理时间的意愿和炼丹求长生没啥太大区别…… 与其控制情绪，不如继续求知，学识才决定人的品行和生活的品质…… 外语发音不好，甚至说不流利又怎样？我使用外语的最大用途是阅读…… 写作技巧都不重要，践行才是创作呢……我就这样把自己活成了行为艺术家…… 想要学什么，我就去教什么，反正我学得快，至少比大多数人的学习经验更多一些，学习时间更长一些…… 谁说不能同时做好几件事情？我跑步的时候还听音乐呢，我走路的时候还听电子书呢，我甚至在写文章的时候也同时看电影呢！DOS 就是理解不了 Unix 罢？ 法定假日是限制企业的，不是限制我个人的，谁说过年之外我就不能回家看望父母了？ 有时候效率并不重要，长期努力更重要，音乐认知上我有过脑受损，但三十年过去了，不也恢复了不少吗？ 为什么要坚持锻炼呢？答案是： 本金最重要。 反思自己年轻的时候，少不经事，不懂得这个道理，于是，浪费了很多时间精力和情绪在自己其实压根就无法解决的问题上，也把很多时间精力和情绪寄托在他人身上，以为他们可以帮我们解决问题， 甚至错误地把责任横加在他们头上 ，想想真是浪费，也真是不应该。 正确的方法论可能是这样： 一方面，专注于自己的进步，让自己成为能解决更多问题、更大问题的人—— 只要时间足够久，进步是一定的； 把自己能解决的问题，都给解决了，为了自己，也为了别人。 另一方面，在自己的能力范围内，尽量帮助那些可能解决很大问题的人。但必须牢记，解决那些问题，可能并不是此人的责任，也不一定是此人能有的运气。 所谓的“平和”只不过是认真思考的结果。 惊喜与创造惊喜的方法论 你必须相信你自己会有好运的什么时候开始笃信自己将来一定会有好运的呢？大学的时候认真研究概率论的时候。如果生活在一定程度上是随机的，而有些事件是好的，有些事件是坏的，那么无论我现在遇到过的坏事儿有多少，好事儿还是会出现的，大小不同而已，早晚而已。这是多简单的道理啊！乐观是一种需要时间、需要耐心才能生成的一种态度。 为什么倒霉事儿相对较多呢？两个主要的原因， 没能力和实力做出 主动的选择 没有足够完善的逻辑思考能力所谓“尽量不做可能倒霉的事情”，其实只不过是打磨自己的逻辑思考能力，使其完善，乃至于你不大可能去做未来可能产生恶果的事情。 笃信逻辑，精于推演，是 活在未来的关键。有些事情，有些选择，在做的那一瞬间，就注定了未来一定会倒霉，这样的事情不能去做。我做事情，该公开的都是公开的；此为其一，其二，我不做需要别人给我保密的事情，那样没劲。 不要给自己建造围墙。围墙的作用除了可能提供一些庇护之外，更大的作用是让别人走不进来、也让你走不出去。开放（Open）就是可以创造好运和惊喜的，无论在哪个领域。 比特币这个例子我说过好多次了，我在 Twitter 上 Follow 了 18,000+ 账户，为什么呢？因为我不觉得预先筛选信息对我有好处。而且从逻辑上看，我们明明要的是 信息 ，却通过 人 来过滤，这是效率相当低下的方式。 迄今为止，别人能看到的，在我身上发生的最大惊喜，就是比特币。 ……当然还有更大的惊喜，只不过我没必要告诉别人而已。我怎么知道比特币的啊？这并不完全是意外，一定程度上，这是我特有的方法论的结果。就是因为我 Follow 了那么多人，我才会有机会“随便扫了一眼，看到一个惊悚的新闻标题”： “这个虚拟币价格超过了一美元！”有些东西、有些知识，一旦知道了，就是不可逆的，你不可能从此装作不知道。于是我就开始去研究这个东西去了…… 可问题是，如果我像绝大多数人一样，给自己建个围墙，提前过滤了很多信息，只关注自己觉得重要的人物，那么我估计早晚也会知道比特币的 —— 许多年后呗。 学习，从来都是创造惊喜、创造好运的最优路径。每个真正习得过技能的人终究有一天会发出惊叹：真没想到在这里可以用上！ 学习 就是掌握一系列新的 概念 。那么为什么持续学习一定会产生好运和惊喜呢？理由也很简单， 只有概念多到一定程度的时候，它们之间才有机会产生“意外的连接” —— 即，所谓的融会贯通。学习就是反复打磨概念与方法论，等着注定的惊喜注定地发生。 只有节点多到一定程度，才可能有“意外的连接”出现。要想办法认识很多真正拥有高效率的操作系统的人。 交流，可能是坐下来喝茶，也可能是读对方的文字，更可能是长期观察。甄别出那些有属于自己的高效操作系统的人，甄别出那些愿意打磨自己的操作系统的人，遇到了，必须 马上连接。 一旦概率论确立，这世界上开始有一些人能够理解随机的概念，开始明白 这世上有些事儿是不讲因果的 。 你抛一个硬币，结果是正面，为什么呢？为什么不是反面呢？不是因为你抛了一个硬币，也不是因为你上一次抛硬币的结果是反面…… 没有原因。反过来，当你抛出一个硬币的时候，因为我们知道那是随机事件，所以我们也知道那结果不是正面就是反面，至于究竟是哪一面，概率是 1:1 —— 虽然我们不知道确切的结果，但我们确切地知道可能性。 学习的时候不要问有什么用，因为不一定在将来在什么时候在什么地方会用到。本质上来看，这也是一种放弃直接因果判断，利用一定的随机性创造惊喜的方法论。 在一些时候，在一定程度上，跨越因果思考与判断，在生活、工作、学习中添加一点随机性，就是创造惊喜的方法论。 一定要想办法把自己打造成一个多任务操作系统。不要做一个低级的单任务操作系统。DOS 是没办法理解 Unix 的。人不能因为自己笨，就觉得别人也笨；更不能要求别人有义务跟自己一样笨。不过，我们反过来倒是能够理解，笨蛋不知道自己笨，即便别人指出来也不肯相信自己笨的。 通过恰当的统筹，让自己多开几个进程，齐头并进地去做一些事情，永远是提高效率的基本手段。 多管齐下，齐头并进，也是创造惊喜的好方法，理由很简单，效率高了，成果就多了，成果这东西，跟之前提到的“连接”啊、“节点”啊一样，越多越好，这些成果本身也是节点，它们之间也会产生连接，最终一样产生聚变，至于能够获得什么，我们还不知道，但我们知道一定会有所获得。 创造惊喜的方法论逻辑很重要、概率学很重要、统筹学很重要 你必须相信你自己会有好运的 尽量不做可能倒霉的事情 保持开放 持续学习 创造更多的连接 保留适当的随机 多管齐下，齐头并进 成功 = 技能 + 运气 所谓“运气”，是完全不可控的，它可能是好的，也可能是坏的，也可能是“0” —— 即，什么影响都没发生。我们不知道它什么时候发生，不知道它是好是坏，也不知道它好坏的程度到底如何；我们只知道最坏的情况下，坏运气可能导致“灭顶之灾”。与之相对，技能却是可控的 —— 通过刻意练习（deliberate practice），绝大多数技能都可以获得极大的提高。在“技能-运气”的横轴上，尽量选择去做靠近左端的活动，就是那些更多依赖技能，更少依赖运气的活动。下棋、学习，都是完全不靠运气的 —— 只靠积累。于此同时，无论做什么，都需要技能，而技能只能靠积累。在技能没有达到一定程度的时候，别指望运气。因为坏运气在这种情况下其实格外可怕。 通过选择来回避坏运气。选择很重要。甚至可以不夸张地讲，人生就是选择。对于选择这件事，我的好朋友铁岭有个精彩的陈述：所谓的（创业）成功，无非是解答题高手作对了选择题。 可这世界上真的有很多人不相信自己有选择的！更准确地讲，他们骨子里完全不相信自由意志的存在。说实话，我完全没办法理解那些不相信自由意志存在的人有什么接着活下去的必要…… 我们可以通过两个层面做出更优的选择： 提高技能值 降低坏运气的绝对值 惊喜（Serendipity） 原本想象不到的好事儿“竟然”发生了……或者反过来说也行，原本想象不到的坏事儿“竟然”没有发生……甚至，原本想象不到的坏事儿即便真的发生了，也没有造成“毁灭性打击”…… 学习（磨练技能）永远是创造惊喜的最根本手段：当坏运气发生的时候，有能力抵御、有能力承受，那么坏事可以变成好事—— 因为那些没有干掉我们的事儿会使我们变得更强（“What doesn’t kill you makes you stronger” —— 有首歌的歌名就是这句话。）……若是没有能力抵御、没有能力承受，那么坏事就铁板钉钉，又因为“因此要提前出局”所以要蒙受的损失大到无法估量…… 所谓的学习，本质上是在提高自身的“免疫力”，让自己不被病毒打倒。这个类比告诉我们，有的时候，我们甚至有必要主动给自己下毒 —— 这就是打疫苗的原理。你看，类比真的影响思维。 切换模式：苍蝇与蜜蜂的启示 问题显然不在眼睛上。因为瓶底朝着窗户，蜜蜂便不停地在亮处寻找出口，却碰到蜜蜂怎么也弄不懂的玻璃，对阳光的敏感和执着使它们不肯到瓶口 —— 那个黑暗的出口去。是呀，黑暗与出口怎么能联系在一起。 但是苍蝇可不管什么光明与黑暗，它们四下乱飞乱闯，瓶子又这么小，碰上瓶口的机会太多了，一群头脑简单、貌似全无所追求的苍蝇就这样获得了自由。 “这件事说明，实验、坚持不懈、试错、冒险、即兴发挥、最佳途径、迂回前进、混乱、刻板和随机应变，所有这些都有助于应付变化。” 无论是谁，若是只有一根筋，总有一天会倒霉。独立思考这事儿，说难也难，因为绝大多数人都是“人家说什么就信什么”，别说独立了，连思考都不做；说简单就特别简单， 凡事儿多琢磨一会儿。一旦真开始想了（思考），就可能得到不一样的结论； 收获多起来之后，遇到重要的事儿，一般都舍不得不想 —— 知道不多想想就会吃亏的。 思考过一根筋的窘境之后，怎么可能再是一根筋的人了呢？知识的获得就是不可逆的。 刚刚冲进一个新领域的时候，我会把自己调整为“苍蝇模式” 。在我找到“门道”之前，我就是一只苍蝇，乱打乱撞实际上就是最佳的选择、最佳策略。 做销售，很快发现信任最重要；做教育很快发现榜样很重要；做留学咨询很快发现家长才是客户；做电商导流很快发现反向筛选客户很重要；做比特币很快发现买进来且拿住才最重要；做互联网创业早期项目投资很快发现行研最重要…… 找到门道之后怎么办？我会马上把自己调到另外一个模式“蜜蜂模式”。 经过如此这般的打磨，我的操作系统一定是升级了的 —— 起码我的是有两个模式的操作系统，不是吗？多任务、多模式的操作系统怎么可能与“一根筋”的操作系统相提并论呢？ 不仅要多模式，还要在很多重要的节点上多模式 调整焦点为什么能够随着大势成长的人永远是极少数呢？大多数人没有那样好的运气。 当一个大的趋势来临的时候，绝大多数人即便绞尽脑汁，也想不出那大势如何为己所用。很多人输就输在，对于新兴事物，看不见、看不起、看不懂、来不及……开始有足够数量的人看不起某种因新趋势的存在而产生的行为模式的时候，基本上总是那个趋势要发力的时间点。 不是问自己，这个大势如何才能为我所用？ 而是问自己，在这个大势中，我去做什么最划算？ 这两个问题的区别在于， 第一个问题的焦点是放在自己身上的； 第二个问题的焦点是放在大势本身上的。把焦点放在自己身上，而后开始思考，思考结果常常是，几乎所有的大势其实都与我没关系…… 把焦点放在大势自身上，而后开始思考，思考的结果常常是一样的： 必须跨界 —— 自己手里正在做的事情，常常与那大势完全没有关系，也并不适合与那大势共存。某个大势出现的时候，一定有一些特定的事情比其他的事情更适合“顺势而为”，万一那些特定的事情恰恰是自己正在做的，或者是最擅长做的，那真是天大的运气； 有办法、有能力让自己变得运气足够好的人 —— 源自于我们有不一样的操作系统： 我们不断升级概念和方法论 我们多任务运行 我们在不同的情况下切换不同的模式 我们还会在不同的时间点转换不同的焦点…… 我们就是那种勤于深入思考的人，更为关键的是，我们就是那种践行者。想到，就要琢磨清楚；搞明白到一定程度之后，就开始行动，在行动中继续思考，在行动中不断调整，在行动中获得更多的灵感，在行动中主动创造各种好运气…… 这就是所谓的“ 主动选择”了。 微信公众号 跳进来，自己动手开始写的目的有这么几个：我想知道这个生态里的每一个细节，不自己跳进来，只看别人做，一切分析在我看来还是“得来终觉浅”……我从来都知道“个人品牌”的重要性，所以，虽然在这事儿上起步晚（那是因为有一段时间我就是在休息），但终归我需要一个信息传播通道，既然微信公共平台已经成了大势，我就不应该任由它把我自己落下；我想验证一个猜想。在没有“早期初始红利”的情况下，什么样的 IP 依然可以迅速获得流量？我的猜想是：那些独特的内容 —— 那些打着作者独特印迹的内容，那些读者一看就知道是谁写的内容，那些天然被搬运工拿走也带着作者独特印迹的内容；而在这一点上，我运气足够好，因为我恰恰懂得如何生产这种内容……我认为如果我能短期之内集聚足够的流量的话，那我一定有什么办法，或者遇到什么机会，搞出一个完全不一样的东西。 果然，在这个过程中，很多之前尚处于模糊状态的念头开始清晰起来，很多之前在脑子里尚未关联起来的节点开始相互碰撞，很多昨天的想法在今天已经开始发酵，很多原本根本不可能认识的人（尤其是那些恰当的人）感觉在突然之间就从各个方向“冒了出来”…… “ IP 多维化 ”。只有一个维度的 IP，没有足够强大的商业潜力，最终只能沦为“发发广告收点钱”的奴隶 —— 这几乎是最没前途的商业模式。好的 IP 从来都是可以锻造出多个维度的，这不是什么新鲜事儿。相比火爆的《盗梦空间》，《星球大战》的 IP 更有潜力，因为后者早已是多维化的 IP，单单玩偶市场就大得不得了，且经久不衰，过去、现在，与将来；前者并非不可能多维，但相对后者明显在多维上有很大的劣势。 转换焦点，是整个征程的起点。 事实上，这就是我在多年后不可能再是一个托福培训教师的根本原因。每当我意识到某个大势存在，并且对之深入思考之后，得到的结论总是一样的： 我必须离开，我必须存在。其实这里套用的是崔健的歌词： 我想要离开，我想要存在，我想要死去之后从头再来…… 真正的大势，很少频繁出现，尤其对个体来说，能够感知的大势更少。 选择 活在未来而不是当下， 研究新生事物的时候更应该关注优点而不是缺点 平日里人们评价“某一个人格局不一样”的时候，本质上来看，其实就是指那个人关注的 焦点 不一样。我们更应该 对自己的未来自信 ，前提只不过是过去与现在以及未来，我们都在挣扎着进步。我们在自信这件事儿上，关注的焦点更多在于自己的未来 ，而不是，或者不仅仅是自己的过去或者现在。 我们不仅应该优先关注这个世界的未来，也要 活在未来而不是当下。为什么我们这么自信，自信自己可以活在未来呢？理由简单而又清晰，我们是掌握了方法论的人，一旦我们通过研究通过思考，发现某个属于未来的大势出现的时候，我们早已调整过自己的关注焦点： 不是问自己，这个大势如何才能为我所用？而是问自己，在这个大势中，我去做什么最划算？人们的平均寿命正在加长 —— 我想，在更长的一生中（好几辈子里），每个人其实都有机会，总能逮到几个大的罢？逮不到，别怪别人。 不能容错的系统肯定是脆弱的 任何一个在现实世界里运转的系统所面对的，必然是一个不完美的、不理想的、各种意外频繁发生的现实世界 。有一点错，就直接停止运转，那系统基本上就是个废物。我们最好给自己的操作系统设置一定的容错机制。绝大多数人在没有恰当训练之前，不懂得容错，就基本上跟废物差不多。看看那些易怒的人罢。有一点差池，他们就暴跳如雷，大脑充血，系统完全瘫痪…… 这不是废物是什么？其实他们比废物还可怕。暴怒的人不大像一个失灵了的冰箱，坏了也就坏了，暴怒的人更像失控的火车，要冲出轨道，毁掉停下来之前撞到的一切…… 没有冗余度设计的系统，通常不够健壮，不够可靠。这地球不是少了你就不运转了！有容错能力的系统更为强壮，有冗余度设计的系统运转更为持久……一切更为健壮的都要耗费更多的成本。学习范围广了，思考更为深入了。容错是自己的事儿。 自学自己的灵魂必须自己塑造你自己就是自己的灵魂的工程师。教，才是最好的学习方法。自学很简单，其实就是不断习得、积累、研究、打磨、升级那些概念和方法论。进一步来看，自学能力是靠积累增强的。开始自学的人，越学越快。自学的人好比给自己的脑子开了个黑洞，刚开始看不出来，因为那黑洞的质量太小，乃至于跟没有一样；但随着时间的推移，那黑洞的质量逐步积累，渐渐地，另外一个现象终究会产生 —— 很多知识就好像是“不由自主”地飞进他们的脑子里。 如何解释这个现象呢？善于自学的人，最终会形成一个重要的能力：融会贯通。 善于学习的人会越来越善于学习，学习能力会越来越强，因为在一个知识点上的感悟，不知道什么时候会在另外一个知识点上发挥效用。知识点（概念与方法论）就好像是有生命的东西一样，它们自己会发酵，它们自己会相互连接，它们自己会相互碰撞，进而产生出更多有生命的东西。 学习几乎是唯一一个可以必然产生惊喜（意外的好运，Serendipity）的日常活动。并且，那些伴随着惊喜的幸福感（多巴胺分泌）就是一直在持续增长。 自学这事儿， 方法并不首要，首要的是态度。 不为自己做的事儿，做久是不大可能的 ，于是，自然而然产生讨厌，产生抗拒，自然最终能放弃就马上放弃。 所以最终，离开学校之后，到了工作岗位上，绝大多数人都不是 给自己打工 ，而是 给别人打工 …… 这只不过是在延续他们长期的生活方式而已。 遇到一个普遍的现象，而后对其做出正确的分析，得到正确的结论，是一个人有良好的思维能力和习惯的重要表现和进一步成长的前提。有一类人做什么事儿都是为了自己而做，即便在某件事儿上做得并不好；另一类人做什么事儿都是为了别人而做，即便在某件事儿上做的还不错； 为自己而努力的人逐步变成所谓的精英，为别人对付事儿的人逐步变成所谓的庸众。是啊，为自己做事儿，就肯定更努力啊！为别人做事儿就自然而然地应付了事么！如果你想创业找个靠谱合伙人，那么请注意两个根基： 远离那些“表现型”选手 ，无论多费劲也要去找到那些“进取型”选手。明明是为了别人而活，却真切地感觉是“为了自己的利益”；这是最底层的价值观，位于“操作系统”的核心位置，很难与不同的操作系统相互兼容。尝试着改造他们是全无意义的，谁都做不到—— 除非有一天他们自己意识到了，自己改，可说实话这希望也太渺茫了。 远离那些应付了事的人 ，无论多费劲也要去找到那些“把事情当作自己的事儿来做”的人。明明是为了自己而活，却最终不仅显得也确实是“大公无私”。 “表现型”选手做事常常不是为了自己的进步 ，而是为了自己当下表现得多好，也就是说，为了获得更多的当时的认可。“进取型”选手做事是为了自己的进步 ，做事的收获，最大的部分不是来自外部的奖励或者赞赏，最大的部分是自己的进步；即便在做得不足够好的时候，甚至外部只有忽视和鄙视的时候，收获依然清晰：无论如何都有一些哪怕看不着但确实体会得到的进步啊！ 所谓的聪明，虽然可能也受先天条件限制，但聪明确实是可积累、可锻炼的。 霍金（Hawkings） Smart is the new sexy.聪明是新兴的性感。 法国生物学家拉马克（Jean-Baptiste Lamarck） 拉馬克认为 用进废退 这种后天获得的性状是可以遗传的，因此生物可把后天锻炼的成果遗传给下一代。 最新的研究表明，拉马克可能是对的。有一项研究表明， 人们的生活状态发生变化时，基因也会发生变化。 智商却是可以习得的、可以积累的，又因为这种通过锻炼习得的特性（Acquired Characteristics）竟然是可以遗传的……哇！这是多性感的一件事儿哦！并且，这世界有很多人是 Sapiosexual 的，只要够聪明，不怕无配偶啊！于是， 多读书罢，让自己更聪明一点，也为了下一代 。 如何真正消化一本书？ 书大抵上分为两种：虚构类（Fiction），非虚构类（Non-Fiction）。阅读，是为了理解，而理解这事儿，慢，即是快；快，便是无。 标题党的文章直接不看了——说实话，即便错过什么了，也没什么可惜。 这个小技巧真的不知道帮我节约了多少时间，提高了多少生活质量。 信息这东西，必须系统才有价值。碎片化的信息也许有用，但就算完全忽略，也不至于致命。舍了就舍了，没啥。这种勇气其实不少人都有，巴菲特就是其中之一。害怕错过什么，是一种情绪，来自于空虚的情绪：因为什么都没有，所以就渴望有一点什么，所以就特别害怕错过任何机会。 充实的人，是不怕错过什么的，因为已经充实，错过点什么，真的无所谓，机会有的是，错过一大把又如何，反正因为充实而能够相信自己确实有实力终归抓到至少一个适合自己的机会。 买好书，读好书，读懂好书，然后用知识改变自己的生活。 拿来一本书，就好像要打一场仗，打仗之前最好先考察一下地形吧？ 同样的道理，拿来一本书，不应该是抓起来就从第一个字开始读起，一直读到最后……应该先看看目录，再看看附录，仔细读读前言， 也不妨在网上先扫扫书评……要先大致对这本书有个了解，然后再开始行动比较好。 在读的过程中，不断整理这些概念与方法论之间的关系，其实是“消化”的必要过程。 在阅读的过程中，要不断向后总结，向前预期 —— 这是最基本的理解技巧。 绝大多数人除了输入之外什么都没有，连处理都没有。最终只有少数人的阅读理解过程是不断循环地“输入、处理、输出”的过程，尽管这里的“输出”某种意义上不过是“伪输出”…… 理解过的东西越多，理解新的东西就越快。说穿了，理解能力差，无非就是见识少，仅此而已。 重要的知识，从来都是通过反复学习才能获得的。一下就能学会得东西，通常上价值不大。 一定要用起来。 不用，学它干嘛？这与我读书的原则也是相通的：不用认真读的书，读它干嘛？这与我对生活的态度也是一样的，既然活着，就要活好，活得精彩。 暂时用不起来怎么办？教！我总是重复这句话：教是最好的学习方法。 分享，不仅需要能力支撑，也是培养能力的最重要手段。知识分享，没有成本，只有收益 —— 双方都有的收益。 分享的技巧很简单： 真诚，只分享自己确实觉得好的东西； 也是真诚，绝对不能居高临下地装蛋； 还是真诚，对方完全有可能不理解你。 这个概念、这个方法论、这个道理、这个知识，还可以用在什么地方？聪明的操作系统总是有更多的想法、更多的方案、更多的可能性。 万一想到了可以“出其不意”地使用的场景，那就赚大了，因为同样的东西到了你的手里却发挥了不一样的作用，你当然与众不同，也只能与众不同。 寻找那些终生学习的人，把他们当作朋友，把他们当作榜样。我就有个很长期的榜样：Bruce Eckel。我根本不认识他，也没有过任何传统意义上的交往，连 email 往来都没有。他是 Thinking In C++ 的作者。十多年前，他在网上发布 Thinking In C++ 第一版的写作计划，然后以极快的速度更新完成…… 毫无疑问，见识到有人这样，就成了后来我写书的时候“雷厉风行”的根本原因和动力。再反过来说，人家写书都可以这样，我们读书怎么可以拖拖拉拉呢？ 人群中的阅读量分布，大抵上应该是这样一个曲线： 若是把年平均阅读，换成“一生平均阅读”，那条曲线可能变成这个样子，嗯，你之前见过的那个曲线， 人与人之间差的岂止 10 倍，100 倍都很正常 ： 在哪儿都一样，真正尊重知识的人就是少数，古今中外都一样。每个月至少读一本好书，是那些关注自我成长的人的最低要求。学门外语（尤其是英语），根本没那么难，甚至很容易，能不能学，能不能学会，只不过是学习意识问题。 网络时代有很多方法可以去了解牛人们在做什么，牛人的共同特征是喜欢分享。他们正在看的东西，是他们筛选过后的，常常有很大参考价值。注意，是“参考价值”，不一定是“价值”。(这里有个很好的例子：Some Books for Software-oriented Humans，文章作者是 Pat Maddox, Rspec 核心开发团队 2 号人物。 什么是更好的知识？ 有价值的信息才可以算作知识。知识有两种： 无繁殖能力的知识 有繁殖能力的知识显然，有繁殖能力的知识，比无繁殖能力的知识更有价值；繁殖能力强的知识，比繁殖能力差的知识更有价值。 什么叫有繁殖能力的知识呢？最好靠举个例子说明罢。 科学方法论，就是一种有繁殖能力的知识，也是迄今为止我习得的最有繁殖能力的知识。再比如说，概率、统计，除了可以帮助我们更准确地理解这个世界之外，甚至可以直接用来赚钱…… 一般来说，有繁殖能力的知识： 可以积累，因为它有积累效应 必须应用，因为它有指导意义 值得传播，因为它可造福大众 把大量用来“牢记”的时间，直接输入到“践行”之中，好像更为牢靠，更为划算。保持好奇心很重要，但若是竟然养成了猎奇心理，那就算是掉进坑了。 如何研究新生事物？绝大多数人都是一根筋地生活的。对他们来说，最好什么都有唯一、正确、标准的答案、方式、手段；一旦答案是“ 看情况 ”，他们就一脸茫然，瞬间进入死机状态。 如何面对、如何研究新生事物？就是一个很好的例子和测试。绝大多数人其实使用一贯的模式（当然那是他们唯一的模式）去面对、研究新生事物。可事实上， 面对新生事物的时候，一定要切换模式，否则就事实上完全无法面对、彻底无法研究。 任何新生事物都是不完美的。 实际上，无论是过去、还是现在，抑或是将来，在任何时间点上出现的新生事物都不是完美的，它之所以出现，核心上来看，只是因为它相比之前的相对物更好而已，一旦它成功，它就不再是新生事物，而是现有世界的一部分，等待着被下一个新生事物所颠覆 —— 几年后、或者几十年后，甚至成千上百年之后。 最终，我们接纳任何新生事物，都不是因为它完美，而是因为它相对更好而已。 在面对、或者研究新生事物的时候，我们应该关注的是它的优点，而不是它的缺点。 也就是说，我们应该让自己的操作系统切换一下模式，从“优先关注缺点模式”，转换到“优先关注优点模式”。 类比是用来帮助我们理解新生事物的；类比不应该是我们用来定义新生事物的。 可是，一旦进入投资领域，这样的操作系统就完全无法运转了 ，因为投资行为的核心本质有这么两个： 投资必须自负盈亏，所以只能、且必须靠独立思考；只有投资未来才有真正的胜算，投资的收益才可能大到有意义的地步。 学习和投资的机会几乎无限多 —— 只有在这样的时代里，知识变现才是可能的，且知识变现的金额才可能是巨大的。仅仅是我的上一代 —— 我父亲的那个年代里 —— 就没有这样的时代恩惠。 学习就是用自己免费的时间与精力再加上少量的金钱去投资自己的未来。 人分为两种，主动升级自己操作系统的，和不升级自己操作系统的；主动升级自己操作系统的人又分为两种，多模式的和单模式的…… 除了在跨界和研究新生事物的时候我们需要调整模式之外，我们还需要在更多的地方调整模式…… 我们永远不要在容易和艰难之间选择，要在错误与正确之间选择 。要做正确的事情，哪怕很艰难也要做；错误的事情，越容易越不应该做。这很清楚，不是吗？ 超越绝大多数人的窍门其实很简单，就是想办法活在未来。生活幸福美满的窍门就在于比别人早半步，早太多了不安全，晚半步就始终遗憾，相对于别人不早不晚，其实就是一样，那就没意思。 如何活在未来呢？这听起来好像是不大可能的事情。但实际上却很简单，就两件事儿： 笃信逻辑。用逻辑去判断明天会发生什么。 你的孩子受教育程度越高，将来的收入就会越高。在我想明白并开始笃信的那一刻，我已经某种程度上“活在未来”了，只不过，我的未来需要时间证明，而我需要要用行动与耐心等待早已经决定的结果最终落实。 做事之前常常要在脑子里预演至少一次做好你的功课。 （Do your homework.）咱是谁啊？！ 有意识地提高自我要求，是切实提高自己水准的前提 —— 我的确相信这事儿。对自己抬高一点点要求，然后做足功课，更好一点的结果就是自然而然的了。 按照未来的你所需要的标准去学习、去工作，将会构建一个完全不同的生活。提前成为未来的你。多花点时间想想自己未来的样子，多花点时间预演一下，多抬高一点点的标准，多做足一点点的功课，就这样，差异应该就一点点地积累形成了。 关于圣人与榜样 这世界根本就没有强者，其实大家都是弱者 —— 只不过弱的程度不一样而已，或者弱的方面不同而已。所谓的原罪，很可能只不过是没有学会学习的结果…… 傲慢是因为认为别人不可能进步，以为自己的优势永存；嫉妒是因为认为自己不可能进步，以为他人的优势永存；懒惰是因为相信自己不可能进步，所以干脆放弃，一了百了；暴怒是因为不知道自己可以进步，所以弱者永远患得患失、永远输不起、吃不起亏；所以强者一旦发现自己的地位可能被动摇就自然而然地勃然大怒；贪婪是因为不知道自己的进步效果不是线性的，而是一个需要长期努力才可能出现的复利曲线，所以才生成的不切实际的欲望…… 所有人都有进步的可能，只不过是有没有放弃而已，若不放弃，那最多是进步程度大小不同而已。原来所谓的“ 宽容 ”、所谓的“ 淡定 ”，竟然如此容易获得 —— 惊喜，绝对是惊喜。嗯，进步（升级）是获得、制造 惊喜 的最有效手段。 自欺欺人是装给自己看；欺世盗名是装给别人看，反正都是装蛋。装蛋有无数种变体，可装蛋的本质，其实都是一样的：对自己的未来不自信。 不要以为你干过的蠢事别人不知道，只是人家没空、或者懒得挖出来而已。唐骏就是个很明显的例子。其实他何必呢？人又不笨，若是当初不投机取巧，不欺世盗名，现在也不会差到哪里去……这个时代的恩惠在于，普通人不必一定大富大贵，老老实实学习、老老实实成长、老老实实工作，做个中产阶级并不是很难 —— 早已不再是“必须你死才能我活”的时代了，真没什么必要欺世盗名的。 别装，千万别装。偶尔装装，不是不可以，但千万别装圣人 —— 绝对不可能的事情就不要做了，这跟不要尝试发明永动机是一个道理，多明显啊！ 其实真的没必要装。 其实大家都是可怜人，最初的时候大家都不怎么样 —— 不一样的只是某些天生条件而已，可那些基本上真的都是 “脑”外之物 —— 比如，遗传的长相，或者继承的财富。 智商这东西，其实不遗传的，大家都是从零开始。 也完全没必要顾镜自怜。 虽然不可否认的是，每个人的成长环境不同，但这世界正在发生变化。一个很重要但常常并不被重视的变化就是人类平均寿命的增加 —— 在今天这个社会，三十岁的时候醒悟过来，和一百年前的人十五岁的时候醒悟过来没什么太大的区别，时间段的增长，明显增加了可以获得并体验 复利效果的概率…… 这就是时代的恩惠。 花几十块钱（人民币或美元）买回来的一本书，哪怕是有其中一点点的内容（有时哪怕是一句话而已）给我带来惊喜，已经很划算了！ 这跟什么很像呢？这样的方法论可以用到其他什么地方呢？—— 习惯于这种提问，是让自己学会 融会贯通 的最直接手段…… 这样的方法论可以用在“向他人学习”的行为上。 无论学什么，都可以同时向多个人学习（就好像可以多买几本相同领域的书一并阅读一样）；只要满足一定条件的人，都可以成为学习对象（就好像挑书那样，设定一些基本条件）；总是可以在这个人身上学到这点，在那个人身上学到另外一点；甚至可以从烂人身上反向学习如何才能避免变成那种烂人？曾经，我也好像需要榜样的激励，后来放弃了。如果把榜样比作好书，理由就清晰了： 好书永远存在；经典书籍永远不止一本；经典书籍也有可能被颠覆的可能；新的好书永远源源不断；众多好书都各有千秋……同样的道理， 榜样永远存在；值得当作榜样的人其实有很多；曾经的榜样，很可能被颠覆，实际上经常被颠覆；新的榜样永远远远不断；即便是普通人也常常各有千秋…… “被装得最好的那个人蒙蔽”，是寻求单一榜样的最可怕后果。完美无缺的榜样，只存在于信息流动不畅通的时代里，不是吗？ 把绝大多数人都当做正常人处理，其实挺解脱的；把别人以为的榜样、偶像也当作正常人处理，自己就变得更正常了。与此同时的 惊喜是，学习对象更多了、学习范围更广了，真是令人大喜过望。 做个正常人，和大家一起做正常人，挺好的。 其实大家都是正常人。 不能改变的最根本原因在于不愿意改变。知道自己的缺点，也知道自己改不掉，其实并不是最坏的情况，最坏的情况是，自己确实有缺点，自己却完全不知道，甚至以为自己其实是完美的 —— 这才是真正不可容忍的缺陷。想改，却最终失败，大抵上都是“误以为改变是瞬间的事情”造成的。 改变常常是个过程，且是个很长的过程，不是瞬间能够完成的。能够瞬间完成的改变大多没有什么意义。比如，改变一下瞬间的站姿（其实也是个过程，虽然很短）很容易，但意义也不是很大，彻底改变日常的错误站姿，却需要矫正很长时间，肯定很有意义；但，就因为这是个长期的过程，这个改变的难度就无限提高了。 这世界是动态的，人们却总是不由自主地用静态的方式去思考、理解这个世界。 下个决心，是瞬间的事情，瞬间的决定，行动才是填补后面非瞬间的整个过程的实际内容。若是真想明白了这个道理，就可以直接把 “下决心的这个瞬间决定” 直接跳过 —— 它没必要存在；直接开始行动就好，这才是关键。 解锁这个关键之后，一切都显得明显了： 改变是个过程。改变最初的时候很难显现。改变需要足够的时间，所以也需要足够的耐心。改变结果出现的时候，已经耗费了很长时间、很多精力、很多耐心。看到自己的改变，会给自己更多的自信；改变是过程，获得、积累自信也是过程。看到别人已经改变的时候，不会盲目地羡慕，因为真正改变过自己的你，知道那意味着什么……最为关键的是，因为自己清楚变化是个过程，知道这个过程在最初的时候不明显，甚至完全看不到，所以，你就不会误以为身边的人都没什么变化…… 也不会因为（许多年后）突然有一天看到朋友的明显变化而感到惊诧甚至懊恼…… 刚开始用力过猛，就基本上注定会失败。绝大多数人成为父母之后，在孩子 0 ~ 3 岁的时候投入过多，耗费了过多的资源，到了孩子 15 ~ 18 岁的时候早已经耗尽资源，甚至，孩子早就成了 “事实上的负担”…… 用力过猛还有另外一个害处：动作变形…… 所以，很多父母把孩子当作自己的骄傲；用力再猛一点，就会把孩子当作自己的炫耀 —— 这已经开始令人讨厌了；用力再猛一点，就会把孩子当作自己当初不曾实现的愿望 —— 这已经开始变得可怜了…… 依照我的经历，我觉得健身是最容易的改变之一，因为它的外部限制因素很少，也几乎完全不依赖运气。但很多人在这种最简单的改变上，还是失败了。怎么失败的呢？就是最初的时候 “用力过猛” 造成的…… 四处告诉他人 “自己就要变了！”买很多配套服装、器材工具……早期过份勤奋，甚至不给自己喘息机会…… 因为早期经济投入太多，后期会出现经济危机；因为早期精力投入太多，后期会出现精力不足…… 因为早期过份勤奋，所以很多该做的事儿都被挤掉了，所以这些该做没做的事情最终会集中起来一起报复你，不信走着瞧！ 千万别用力过猛。避免这个误区的核心在于，心平气和地接受自己最初的弱小。既然改变是个过程，那么就可以把“改变”理解成一股势力，最初相当弱小的势力，它需要时间，需要投入，需要持续投入才能逐步壮大起来。它就跟花儿一样，上来就浇了太多的水，会被涝死的！ 人们普遍认为，在教育行业里，是老师在塑造学生。这好像很自然，但更多的时候，曾经长期从事教师职业的我，却更多的时候看到一个反过来的现象： 很多的时候，其实是那些学生在塑造老师。人是很容易被“ 反向塑造 ”的。你跟什么样的人打交道，哪怕你“高高在上”，你还是会反过来被他们塑造。再比如，同样是做销售，卖奢侈品的、卖高档商品的、卖中档商品的、买低档商品的，各自都会被塑造成不同的样子，不信你就观察一下。 千万不要做免费的、公益的事情。你还没到那时候。 我写书免费公开在网上，是因为我确实不需要指望它赚钱，更重要的是，我 自信到不需要用市场衡量我自己。 如果你做一件事情，是公益的，是免费的，你得到的只能是赞扬——哪怕你做得并不好。这是关键，你可能做得并不好，但由于你是免费的、公益的，所以人家只能对你客气 —— 这其实是不真实的反应。 反过来，你收哪怕一分钱试试？只要你出了问题就会有人骂你，甚至不出问题的时候都有人骂你。 不会回避商业，该收钱就收钱，不能免费、不能公益——这是为了得到真实的反馈。 如果在你做得并不好的时候，依然得到赞扬，你最终只能被麻痹。而你不可能一辈子回避商业的，一旦开始玩真的，你就傻了，因为真实的世界（商业世界）全然不是你过往经历的样子。你被麻痹得越久，你越难以从瘫痪状态恢复过来。 在你做的其实很好的时候，依然被骂，这其实是好事，会让你心理上更成熟，承受能力更强。 千万要小心自己被反向塑造成你原本不应该变成的样子。 近朱者赤，近墨者黑，这不是空话，这也不应该只被肤浅地理解。 认真筛选自己的朋友，很必要 —— 因为他们终究会成为塑造你的一股力量；认真筛选自己面对的所有人，同样必要 —— 因为他们的力量更大，人多势众，生生不息，连绵不绝，所以更要小心，需要更多挣扎。若有可能，要认真选择自己所身处的环境 —— 因为， 地理位置很重要，远比大多数人想象得更为重要。 出淤泥而不染，濯清涟而不妖，那是莲花，那不是人；而人想要摆脱 反向塑造 ，不仅不可能天然做到，而且需要很多努力、很多挣扎。 人要真诚热爱自己 —— 然而，很多人其实没有这样的勇气。 小时候练脑子，下棋绝对是好工具。 倒是看别人下棋很有意思 —— 这倒成了我从来戒不掉的爱好。 观棋不语真君子。落子不悔真君子。真君子罕见。 输了，就得认。悔棋的人，就是那种遇到麻烦不肯买单的人 —— 之前的每一步都是自己选的啊！ 一点都不夸张，任何人大概都有悔棋的冲动（准确地讲，跟悔棋没关系，就是看到失败那一刹那的恐慌和懊恼），可一旦某人提出要悔棋，那么有一个判断就可以确定了：竖子不足与谋。因为能说出来悔棋，已经说明了很多细节： 技不如人且不自知的人很可怕；不尊重规则的人无法合作；爱面子胜过一切的人不可能有什么有意义的进步 如何才能避免制造麻烦？最终的败局，其实来自于很多步之前的某一步错了 —— 从那一步开始，败局已定。后面的只不过都是其实毫无意义的挣扎而已。 于是，再往前推，就是“如何不走出那步败棋？” 而不是“我输了，悔棋行不行？” …… 观棋不语真的是很有意思的事情，你总是可以看到很多人厚下脸皮悔棋，可是他们其实不知道自己真正的败棋是哪一步，于是，最终还是输掉，花了半天的力气，只是让自己输得更彻底，显得更傻屄…… 所以说， 不制造麻烦的人不用解决麻烦。 “那我老婆不讲理怎么办呀？” 其实正确答案挺残酷的： 谁让你当初不认为“能讲道理”是择偶的最重要因素来着呢？ 什么门当户对啊，什么高矮胖瘦啊，什么学历血型啊，都扯淡而已，只有能讲道理这个要求不可或缺。这一步走错了，败局早已经确定。这事儿凄惨在，当初一个人不在意对方是不是能讲道理的人，就说明他自己并不是在意讲道理的人，所以，等有一天他自己觉得麻烦了的时候，他更可能没意识到的是他自己本身就是个麻烦…… 更甚的是，这样的人通常就是那种只知道悔棋，不知道反思，不知道改进的人 —— 更是无解。 人生不可能没有任何麻烦。于是，当遇到麻烦的时候，方法论应该很坚定： 对已经发生的麻烦，认了！ 检查一下根源究竟在哪里，自己的问题究竟在哪里？ 为了将来不再出现同样的麻烦，自己需要改正、改进的是什么？ 进而，如何才能 “未卜先知” 呢？方法论是： 多观察、多研究、多思考别人的失败与麻烦。《黑天鹅》的作者，纳西姆·尼古拉斯·塔勒布有个类比可以借用： 一杯水，放在冰箱里，会冻成冰，那个杯子的形状（水冻成冰之前的形状）可以推测出水冻成冰之后的形状；可反过来，如果一块儿冰放在桌子上，一会儿化成了水，我们看着那水的形状，无论如何都倒推不出化成水之前的冰究竟是怎样的形状……纳西姆·尼古拉斯·塔勒布说的是，研究方向不同，会造成研究难度不同；我的意思是，研究焦点不同，也会造成研究难度不同。研究他人的失败，就好像是第一种情况；研究他人的成功就好像是第二种情况。 我一向认为研究别人的成功很难，因为太多因素其实是隐蔽的；研究别人的失败相对容易，因为有更多更公开的因素可用来研究…… 更为关键的是，研究他人的失败，比研究他人的成功更有指导意义。 看到别人失败了，看到别人遇到麻烦了，就要琢磨自己如何才能避免那样的失败那样的麻烦 —— 其实这是人们每天都在做的事情啊！某次北京下大雨之后有人在车里生生被憋死，于是很多人都反应过来，四处求问，而后才知道原来虽然玻璃无法敲碎，但可以从后备箱逃生……而后才知道有些车竟然不可能这样！ 当一个人从逆境中走出来之后，回头再看那逆境，暗流涌动的背后却可能是个机会，一个塑造传奇的机会。历史总是这样，它就像一条河，时不时地莫名其妙就产生了一处漩涡，大多数人被卷入漩涡，葬身河底，可总有一些人，“配合”着那暗流，走出一条生路，就成了传奇。 特朗博的策略，其实并不是他独有的，细看历史上所有从逆境中走出来的人，大抵上都差不多： 他们就是很有才华；才华这东西，一点点不够用，必须很多很多；他们因为有才华而更为勤奋，更不愿、不敢、不甘浪费一点点生命；他们热爱家庭，那是生活的希望；他们善待朋友，那是他们生存于世的关联与证据；他们专注于做能做的事情，把最重要的事情做到最好；他们与之斗争的，不是哪个人、或者哪群人，而是那个把所有人都变成受害者的历史漩涡；他们最终从逆境里走了出来……当这样的人走出来的那一瞬间，过往的对错其实都不重要了，重要的只有一件事儿：他们走出来了。 《把时间当作朋友》 一切都靠积累。 《新生 —— 七年就是一辈子》 我们必须主动升级自己的操作系统。我们的操作系统由概念和方法论构成。我们要把自己进化为多任务、多模式的操作系统。不断进化的操作系统要与、也只能与其他不断进化的操作系统沟通。沟通的目的是分享，分享最终会形成惊喜…… “急智”其实并不存在，所有的“急智”，其实都是过往积累的结果与表现，而非“信手拈来”、“急中生智”。闲聊，即便常常确实是“生产途径”，但它也绝对是“生产途径”之一而已。更多的生产，或者说是绝大多数的生产，其实发生在闲聊之前的研究、探索与思考。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"把时间当作朋友","date":"2017-01-14T10:18:06.000Z","path":"2017/01/14/MyShare/take-time-as-friend/","text":"李笑来 把时间当作朋友 对年轻人来说，成长比成功更重要，而且，这才是人人都可以做到的事情，才是人人都值得追求的事情。而成长其实只有一条路——积累。 本书主张时间不可管理、一切都靠积累。主张一个人必须在开启心智、提高思考能力之后，才能够用正确的方法做正确的事情。也只有这样，时间才是朋友，否则，它就是敌人。人的理性建立在接受现实的基础上，不能接受现实，一切成长都是虚妄。只有坚强的人才能接受现实，只有接受现实，才有可能开始运用心智作出理性的决定，进而才有可能做时间的朋友。有用的道理往往都是简单的，甚至简单到令大多数人不由自主地忽视的地步。这本书所传递的信息，原本只不过属于常识，可由于种种原因，并没有被真正普及、理解，实在可惜。 作者微信公共帐号：学习学习再学习（xiaolai-xuexi）","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"人人都能用英语","date":"2017-01-13T10:19:06.000Z","path":"2017/01/13/MyShare/english-is-a-friend-for-everybody/","text":"李笑来 人人都能用英语 请李老师用140字概括一下怎样才能学好英语？我回复说：其实一个字就够了：“用”。这本书里的文字，全部的意义，只有两个字：“启发”。 作者真诚地希望读者在读过这些文字之后，（起码）在英语使用方面有所启发。这本书也是《把时间当做朋友》的具体延续。《把时间当做朋友》的主旨很简单：时间不会听从我们的管理，我们最多只能与时间做朋友；与时间做朋友的方法只不过是“用正确的方式做正确的事情”。而这本书，只不过是 把“正确的事情”聚焦在“用英语”上而已，而后再看看可能的“正确的方式”究竟是什么。 作者微信公共帐号：学习学习再学习（xiaolai-xuexi）","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"人人都是工程师","date":"2017-01-12T11:02:06.000Z","path":"2017/01/12/MyShare/everybody-can-be-engineer/","text":"李笑来《人人都是工程师》前言 在中国，对绝大多数人来说，English + Computer Skills = Freedom 程序设计也许是目前地球上最容易变现、最被高估、可事实上却实际上并不难以获得的技能。程序设计的学习难度被有意无意地过分高估了。 人们向来有把学不会的技能神秘化的倾向，也许是因为只有这样心里才舒服，觉得自己学不会正常一点。但，程序设计这个领域，实在是被过份高估了（其程度比第二语言习得领域还要高出许多许多），乃至于很多人只是因为被误导了才望而却步，根本不是做不了做不好的原因。这个领域里的每一项技能，都会让习得者有这样的慨叹，“这样简单的东西竟然这么有用！” 或者 “连这么简单的东西我都没学会的话，实在是太可惜了！” 在计算机这个领域的顶尖范围里，集聚着人类的精英，他们设计了一个又一个的方法论去优化自己的工作环境，优化自己的工作流程，优化自己的产品，没完没了地改善，没完没了地更迭…… 也就是说，在计算机这个领域里，有大量的概念与方法论都是走在最前沿的。学习程序设计，并不是肤浅地学一门编程语言，设计一些函数，更重要、更本质的是学习计算机科学家们用来改变世界的思考方式、行为模式。 这真是个神奇的时代。跟过去不一样了，现在很可能已经是“一门语言打天下”的时代了，学一门 javascript，就有可能什么都做了…… 这在哪怕仅仅是三五年前都是不可能的事情。不过，我们涉及的话题可能很多很多 —— 总而言之，前面有一条路通往“全栈工程师”的方向…… HTML, CSS, JAVASCRIPTPUG, LESS, COFFEESCRIPTMONGODB, RETHINKDBNODEJS, EXPRESSJSREACT, VUE, ANGULARRELUXELECTRONTDD…反正没有什么是不能学的…… 学习是一种生活方式，是少数人的生活方式生活方式决定了生活质量，这是最基本的逻辑。 既然学习是一种他们已经选择了的生活方式，所谓的“终生学习”只是必然的结果每天进步一点点地活着，没有最好，只有更好，不需要成功，只需要不断成长。 自学其实是一种社交活动 学习从来都不是单独孤立的行为，而是社交行为。 生活中，你遇到过这样的现象没有：“看见别人打针，自己先疼得受不了……” 这是因为我们的大脑中有一种神经元，叫做“镜像神经元”（Mirror Neuron），它会让我们“感同身受”，当我们看到另外一个人正在做什么的时候，镜像神经元会尽力给我们足够的刺激，让我们“体验”那个人的感受。以前人们不知道为什么喷嚏竟然会“传染”，现在科学家们很清楚了 —— 那就是镜像神经元在起作用。 镜像神经元的存在，使得我们有模仿能力、有通感能力、有同情心、有同理心…… 这也是为什么人类天然有社交需求的重要原因，因为我们的大脑皮层上都有很多的镜像神经元。 一切的学习起初都基于模仿，一切的模仿，都源自于看到真人的行为 —— 哪怕是在电影里看到，虽然其实只不过是影相而已，并非真人，但毕竟是真人的影相。 所以，无论学什么技能，都要找到用那种技能的人，这样我们的镜像神经元才可能更容易被激发，学习效果才会好。若是能找到热爱那项技能，乃至于一使用那项技能就很开心（最好的情绪之一）的人，那就更好了。激情这东西，是少数幸运儿才长期持有的东西，大多数人小时候挺多，过了十五六岁之后就开始有意无意磨灭了激情，且并不自知。 很多人误以为他们眼里的成功者靠的是“坚持”、靠的是“毅力”，这完全是自己的镜像神经元“尽力”的结果，是“调用自己过往经验去‘感同身受’的结果”…… 事实上呢？那些“成功者”其实并不在意成功，因为到死之前成长不应该也不可能结束，因为那是他们的生活方式，学习、进步、探索、迂回，甚至折腾、挫败和迷茫，都是他们生活中必不可少的内容，这是最初不自觉的选择，谈不上什么“坚持”，谈不上什么“毅力”…… 说实话，对他们来说，不让折腾才真痛苦呢，不学习才需要坚持和毅力呢！ 为什么要选择朋友的原因。人与人之间有很大的差异，最大的差异来自于性格养成，大多数人会沦为表现型人格，只有少数人才会在不断调整中保持、呵护、进一步培养“进取型”人格。他们自然而然地更为乐观，更有耐心，更有承受力，更有战斗力，更能生产与体验学习与进步的乐趣。与这样的人在一起，学习会更容易 —— 只因为镜像神经元会更容易地被正确激发。说清楚了，道理其实挺简单的。 刻意练习是必须自己完成的核心 重复才能练就技艺。刻意练习，必须自己完成。即便是在进取型人格占大多数的社交圈里，一切的改变也都来自于自己的刻意练习，用时间浇灌的践行，才能引发真正的改变与进步。 所谓的智商，其实是一个人最终积累出来的知识经验的总和 —— 若是这样理解的话，就不难理解为什么到最后人与人之间的聪明程度相差天壤。因为有一些人天天往前走啊，另外一些人早就不动了啊！所谓的刻意练习，说来也很简单，就是把那些现在做起来生疏的技能通过反复使用最终做到不假思索就可以做完且做好 —— 这与智商高低全无关系。 一切看起来复杂的技艺，其实都并不难，很多人最终学不会，其实只是练不成，就是说，他们并不是不理解那道理、那原理；可理解本身并无太大用处，因为真正需要做的是通过大量的重复与实践，把那道理、那原理转化为大脑皮层表面的沟回…… 缺少了刻意训练的环节，学什么都是白搭。 你若是去了健身房，并且还能持续频繁地去健身房锻炼，你的身材就是会变的，而且变化还会非常大，那可是一整年啊！事实上，三个月下来，总计一百小时左右，就会发生巨大的无法忽视的变化。对，仅仅一百小时，在绝大多数领域里，就足矣把绝大多数人甩在身后 —— 对一些人来说这个事实可能是解脱；对更多另人来说，这个事实其实非常残酷，因为仅仅一百个小时，他们就已经败下阵来，别说一辈子了，别说七年就是一辈子了，他们在生生世世中，第一百个小时之前就已经死去。 概念与方法论：最少必要知识 什么是“最少必要知识”呢？所谓“最少必要知识”，指的是为了能够实践某项技能，最起码要学会的那一点知识。 MAKE —— Minimal Actionable Knoweldge &amp; Experience。注意这里的一个词：Actionable，“可行动的/可执行的”。比如，开车的最少必要知识是什么呢？学会如何启动学会如何制动再加上一个字：慢 学习编程的最少必要知识是什么呢？ 你得习得几个程序员都应该有的起步方法论。 …… 然后呢？然后你就可以开始边学习，边实践，在学习中实践，在实践中学习更多，虽然有时掉进陷阱，有时误入歧途，但，请你放心，肯定不会死人的。是谓不断进步，是谓 “路漫漫其修远兮，吾将上下而求索”。 只使用 Google 不论你遇到什么困难，都可以去问 Google，这是目前地球上最大的“人工智能”项目。一切能问 Google 的，都不要去问人。 既然你准备当工程师，那么，在使用 Google 的时候，除了那些常用的符号之外，还需要常用以下几个关键字： tutorial example tricks cheatsheet cookbook awesome 在中国，你最好买一个 VPN 服务一切能节省时间的服务都值得购买，因为时间才是最宝贵、最稀缺，压根无法再生的资源，跟时间比，钱算个屁。 在国内，一个程序员的水平怎么样，基本只取决于一件事儿：英语水平 那些在国内学英语专业的人本科毕业去当老师或者靠研究生，真不如脱产学一年计算机呢，拿着这个优势，一下子就干掉国内 90% 的所谓程序员，年薪 60 万人民币，其实指日可待…… 尤其是那些英语系的女生，一脚踏进码农的世界，瞬间就是女神中的女神。 提高英语的最直接、最有效方式，就是从此在某个领域坚决只使用英语 —— 平时，一般人还真的很难有这个环境呢！现在机会来了，你想学习，你想学习计算机，你想成为一个工程师，你就要从今天开始在计算机领域里，只读英文文档。 触类旁通地想想吧，如果不把你的中文使用能力锁起来，那么在这个领域里，你的英文使用能力就一定不能发展起来 —— 就犹如上面那个小女孩的左臂没有被绑起来一样，直接导致右臂永远没有办法恢复 —— 因为大脑会走捷径，于是那一部分功能永远不可能被大脑的另外一部分学会。所以啊，还是那句话：“都已经给你说清楚了，你自己选。” 本来人人都是工程师，只不过很多人明里暗里自己放弃了而已。 我们每天都要给自己洗脑。可这并不是我发明的习惯啊！孔老夫子说，“吾日三省吾身”，你看看他老人家个人卫生习惯多好，不仅洗，还要天天洗，而且还是每天要给自己洗脑至少三次…… 学习其实是一种生活方式，学习本身就是最好的洗脑方式。只要我投入时间精力，长期来看，没有什么是我学不会的。我学会的东西越多，我再学新的东西就只能越来越快。学习不是目的，用起来才是真的，因为价值只能通过创造去实现。我知道我现在看起来很笨拙，但刚开始谁都是这样的，实践多了，就自然了，就自然地好起来了。在学习这件事儿上，他们不理解我是正常的，这方面我也不需要理解，因为我是一个独立的人。我不应该与他们争辩，因为我不想伤害他们；我也不应该被他们影响，因为我不想伤害自己。刻意练习永远是必要的，虽然它通常并不舒适，但它的复利效应确实巨大的。哪怕是为了下一代，我也要通过现在的努力成为学习专家，这样才有资格与我的孩子共同成长……我的路还很长，我要健康，我要干净，尤其是我的脑子更要干净。 所谓的原则，就是一定要恪守的形式准则，如果不能恪守，就不能称之为原则。做个有原则的人，是很重要的原则。 你学你的，用不着别人批准有一件事绝大多数人搞错了，导致了不一样的思路，不一样的结论，不一样的未来和结局： 学习这东西，不是一定要学到大师的程度才可以拿出来开始用的。 真实的学习过程是，学会一点最少必要知识（就是那些知道了之后就可以马上开始行动了的最少知识），然后就要马上开始实际操练…… 最终，大量的细节都是在实际操作过程中进一步学会的 —— 甚至，还有大量的细节如果不进行实际操练的话，就根本没机会学得到。 在中国，每个会开车的人其实早就应该意识到这种学习方式的神奇。在中国，驾校的培训实在是太粗糙、太简单、太粗暴了…… 交了钱，进了驾校，其实前前后后在练习场上实际操作的时间少得可怜 —— 然后就冲出来上路了，虽然各自进度有些差异，但总体上来看，真正的驾驶技能几乎 100% 都来自于在真实世界里实际操作，而非驾校培训，不是吗？ 绝大多数人的眼里，学习成了一条“漫长不归路” —— 听起来多可怕啊，学不成就别出来得瑟，学不成，就别回来见人！天呐。 既然在脑子里把学习这事儿类比为一条“漫长不归路”，那么“它一定是一步一步走过去的……”，于是，无论做什么事情，他们都感觉必须循序渐进，甚至，若是看到别人不循序渐进，就很生气。 循序渐进坑了一代又一代的人…… 仔细观察一下我们的真实生活，我们从来都是这样的：横空出世，向后钻研，向前突击……这才是真实的世界。 我们的教育体系，好像特别痴迷于把我们带到循序渐进的道路上去，父母们也觉得只有这样才放心（其实他们自己也是被弄脏了脑子自己不给自己洗脑的产物）…… 99% 的人循序渐进地从 ABCD 开始学，学英语 16 年，开口说不了，拿笔写不出…… 真不知道图个啥。 最简单的编程，被抬高成“工程师”的境界 —— 可另外一个事实又明显地摆在那里： 很多自称工程师的人，其实看到十四五岁的小黑客做的事情，也不得不心服口服 —— 若是必须、只能循序渐进才行的话，那些小黑客是不可能存在的，不是吗？小黑客们都不是靠循序渐进习得技能的。都是“横空出世”的，他们最开始做的事情，不是打基础，而是“突然有个问题要解决”，于是不管三七二十一只好“向前突破”，用尽各种方法（通常是很土的办法）先把问题解决掉…… 在这个过程中，能补的补（向后钻研），补不上的就先放在那里，留给以后…… 然后反复迂回前进。 鼓励身边的所有人…… 只因为，我实在是太清楚“鼓励”这东西有多么稀缺了。如果你自己是个上进的人，那你就像我一样，天天鼓励那些同道中人罢 —— 我相信这绝对是善事。 谁说学过之后用的不够熟练，就不能用了？！ 谁说没天分的人就不应该学东西了，谁说没天分的人学得不足够好就丢人了？ 我找到了捷径，可惜早已身不在起点。真的有很多捷径…… 比如，现在这篇文章里很多话都是“捷径”，因为你想通了，这些“捷径”就会帮你节省很多很多时间，节省很多很多精力，了却很多很多烦恼，甚至抄很多很多近路…… 捷径，不就是用来节省时间、提高效率的吗？ 我所说的、我所理解的全栈，究竟是什么没必要在语义上争论，但，在真正工程师的生活中，coding 应该基本上只占 20% —— 因为最终代码是用来表达思想的，用来解决问题的；所以，全栈工程师是那种有真正的问题需要解决，有真正有价值的想法需要实现，有品位的设计者、创造者。就好像我们都识字，都能写字，能写漂亮钢笔字的人也很多很多，可最终写好文章、写好教程、写好小说、写好诗歌的人才是“文字工程师”，剩下的都只是“识字而已”。 开始之前……注册一个 Github 帐号 从骨子里来看，习得任何技能的最根本技巧，就是一句话而已： 马上开始像那些已经精通这个技能的人一样生活。 因为从本质上来看，一切的学习与创造，都是学习者与创造者的生活方式、生活内容。去目标技能拥有者最活跃的地方生活，像他们一样生活，直至真的就那么生活 —— 这就是学习与创造的另外一个更为生动、更为本质的描述。所谓近朱者赤近墨者黑，讲的也是一样的道理 —— 因为激活大脑里的“镜像神经元”是学习与创造的最初起点。 Github 其实是目前地球上最先进、最高级、最高质量的社交网站，对，它就是个社交网站 —— 虽然貌似现在的人们普遍认为“社交网站”指的是另外一类东西。在那里，工程师们用他们固有的最高效的方式相互交流。他们写好代码就传到 Github 上去，用 Github 做开发中必须的重要事情： 备份自己的代码 文档与代码的版本管理 相互最高效地交流与协作 通过展现有效活动而获得更高信用 更方便地展示自己与自己的成果 每天都要有一整块的思考时间在传播自由的时代里，真有价值的东西总是会被发现。 工程师不是每天每时每刻都写代码的，他们用更多的时间思考。大家从小上学，挺辛苦地学会了识字、写字，可大多数人一辈子都不会写文章，就算写出来了，也传播不出去 —— 其实只是是因为确实没价值为什么呢？因为他们不思考，也不会思考，所以，等于没有什么东西值得表达 —— 尽管已经掌握了一定的表达技能。 工程师其实跟写书写文章的作者一样，无非是用他们特有的表达技巧去表达他们的思想，作者用自然语言文字，工程师用特定字符构成的代码…… 可关键在于，首先要有表达的标的，之后才有表达好坏的判断。工程师表达什么？他们发现问题之后解决问题，提高效率（通过大量的自动化任务）…… 那么他们天天要思考的事情多的去了，什么值得解决？要解决的话如何解决？我的解决方案是不是比别人的都更好、更优雅？为了搞定这个任务，我需要学会什么？我需要和人么样的人以什么养的方式合作？我能否持续地维护我的解决方案？我如何才能让更多的人支持我？ 与大家认为的“码农”并不一样，真正的工程师，时间分配大抵上是这样的，80% 的时间用来思考，20% 的时间把思考结果用代码表达出来（也许是通过带领团队）。这个思考的过程包括反复搜索(search 多了，就叫 research)，深入阅读各种文档（因为今天的工程师必定要用到大量别人写好的模块），还要思考自己写出来的代码如何写好文档才能让更多的人使用…… 而刚入门的时候，可能是反过来的，80% 的时间用来写代码，没有思想可以表达，就去模仿表达别人的思想…… 但，一定要有 20% 的时间花在真正的思考上，像工程师一样思考。很多人进步慢的根本原因在于，每天都在“学”，但从来不花大块的时间深入“想”。 从一开始就要养成习惯，每天要有起码一小时的时间专心思考： 我将要解决的问题是什么？ 最重要的问题是什么？ 它的核心关键在哪里？ 已有的解决方案都有哪些？ 我如何才能给出一个更好的方案？ 我的方案应该如何拆解，如何逐个实施？ 一边思考，一边写写画画，一小时不知不觉就会过去。 功夫在行外在中国想要成为工程师，竟然有很大的一个关键并不在于技术本身，而是在于英语阅读能力；再比如说，即便成为了一个入门级的工程师，驻足不前的根本原因并不在于技术难关无法攻克，而是在于平时的思考习惯不良，或者干脆没有真正深入思考的习惯…… 成年之后，我拥有比大多数人更为强大的学习能力，无非是在这个过程中养成了几个习惯： 我不怕麻烦，因为再麻烦的事儿，都可以拆分成无数个可处理的小块，于是就不麻烦了； 即便是天赋不好，通过一定量的练习，也可以做到比大部分人好，哪怕滥竽充数也充得更像； 经验告诉我，经过一段时间之后，一定会越来越有能力解决更大的麻烦… 基本开发环境设置一些最常用的命令（’#‘ 之后的文字是注释，输入命令的时候不能有它们）：ls #罗列当前目录下的内容cd #更换工作目录pwd #显示当前完整工作目录touch #创建一个文件mv #移动/更名文件或目录rm #删除文件活目录nano #使用 nano 编辑纯文本文件open #打开一个文件，就好像你在 Finder 里双击那个文件图标一样clear #清空屏幕sudo #用管理员身份去执行一个命令 “通读”是做工程师必须的能力。你不一定要全部能够理解（对任何人来说，最初都不可能做到），但你必须对整个文档有一个整体的认识。这就好像读书的时候，你能做到虽然不能完全读懂，但确实能够完整读完 —— 之后再多读几遍么！古人说的是对的：读书千遍其义自见。还有就是，若是从一开始就没有“通读”的意识，后面不知道会吃多大的亏，而且吃了多少亏自己都完全不知道…… 这很可怕。 很多工程师，用了好多年 Terminal，竟然都不知道竟然还有个快捷键能把光标前的两个词调换一下位置：按一下 esc 键，然后再按一下 t （通常标记为：⎋-t）…… 你想想看他们在过去的那么多年里，浪费了多少次键盘敲击？—— 虽然说起来、听起来没什么，可若是真的严肃起来去想，有什么比时间更重要的呢？浪费了大量的时间、浪费宝贵的生命，只不过是因为最初的时候没有养成“只要是重要的文档，必须通读至少一遍的习惯”而已。 “优秀是一种习惯”真的并不是空话，是放之四海皆准的道理。随后的过程中，我们会建立很多很多的好习惯，甚至这句话本身也会在各个地方重复 —— 生活质量就是这样一点一点提高的，放在哪个领域里其实都一样。 nodejs 有两个版本，一个叫 LTS（Long Term Support，提供长期支持的稳定版），一个叫 Current（提供最新功能的当下版，通常也不够稳定，尚需改进）。很多软件系统都采用这种方式，比如著名的 Ubuntu …… 所以，当我们需要安装什么软件的时候，必须到官方网站上看一看，看看当前的稳定版本是什么，然后选择它就是了。将来你成了高手，啥都敢于、且确实有能力尝鲜的时候，就随便你喽。 永远不要参与编程语言之间或编辑器之间的比较争论 —— 在工程师世界里，那是永无宁日的争论，但价值并不大，事实上，一切争论的价值都不大：平息争论的能力才是更有价值的能力，若是不能平息争论，就不要参与争论了，因为参与无法平息的争论，本质上就是，耗费了时间耗费了生命却没有任何结果 —— 这是一个很重要的价值观，它会帮你节省无数未来的时间精力，它也有可能让你成为那个最终能够平息争论的人。 学任何工具，第一件事情就是去把官方网站翻个遍，是必须的习惯。 拿来任何一个软件工具，快速熟悉并掌握各种快捷键，是一个好习惯 —— 基本上就是耗费半小时而后用一辈子的事情。 肯定无法一下子全读懂，但“即便读不懂也要读完”，是一个特别神奇的能力，古人都知道“读书千遍其义自见” —— 说的就是这事儿。你必须积累这种能力，切记。","comments":true,"categories":[{"name":"技术","slug":"技术","permalink":"http://ipcreator.me/categories/技术/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"},{"name":"Program","slug":"Program","permalink":"http://ipcreator.me/tags/Program/"}]},{"title":"在最好的时代，成为一个超级个体","date":"2017-01-11T11:56:06.000Z","path":"2017/01/11/MyShare/to-be-a-super-individual/","text":"古典 超级个体应该是一群人，或者是一个特别善于和组织合作、共同成长的人；他既能站在科技前沿，又能深刻洞察人性；他具备多学科通识，又能精研某个领域，成为专家； 他比别人成长得更快，有很强的自我驱动能力，持续增值。 “我们已经有了关于商业、趋势、政治和财富的内容，为什么我们不就做一档关于个人的栏目呢？”和罗振宇碰这个节目定位好几次了，直到这句话突然跳出来，我看到他眼睛里放光。恩，我们真应该为个体做档节目。 记得第一次谈客户定位，我就被严肃告知：得到的用户都是一群上进、焦虑、不满足的人。“知识狂躁，这群人。”罗胖捧着脸，一脸痛苦。死磕自己满足这群人，不容易。我心里对应了一下自己，字字中枪。不过嘛，上进焦虑不满足，是件挺酷的事。上世纪美国50年代，美国的精英阶层也集体焦虑。心理学家罗洛梅却说“焦虑是人类面对威胁希望创造自我的正常状态。在这样一个高速发展的时代，焦虑的人才是真的健康、感觉到时代脉搏的人。”敏感才能感到变化、有才华才会有的选，而追求自由才想要把握自己的人生。每个人焦虑的人内心，都有一个很厉害又很自由的人。 2.这个时代的确需要我们变成这样的人。 所有人都在说未来是一个个体崛起的时代，我们用各种词汇描述这个现象：IP、社群、消费升级、设计感、情怀、粉丝经济，阿米巴、共享经济、联盟……今天，个体的能力、价值和需求都变得越来越重要。但是这句话只对了一半，个体崛起的时代，并不是“每一个”个体崛起的时代，而是少数个体崛起的时代。和你看到的所有互联网热潮一样，网络会让两极分化加剧——少部分人获得巨大的讯息、影响力和资源而迅速崛起；同时更多的人会被服务得越来越懒，成为平庸的跟随者。个人崛起的时代，是一部分“超级个体”崛起，和一大群普通个体追随的时代。这群“超级个体”是这样的人：科技 人性：能抓住趋势，善于利用科技，也有高感性能力；T型人才：良好的基础素质，在某一个领域有极致的专长；联盟思维：善于和组织、平台密切合作，共同成长；个人品牌：有自己的个人影响力；自我实现：有点品位、有点追求；每个人，包括我自己，都需要加速升级自己的眼界、心智和能力才能抓住这个趋势。而越是走在靠前的人，他们看得越清晰，所以就越发努力。 3.什么是一个人加速成长的必备条件？ 下面有一个有趣的案例：1968年墨西哥奥运会，跳高运动员福斯贝里（RICHARD FOSBURY）第一次在全世界面前施展他的背越式跳高。在那个流行跨越式或者俯卧式的年代，他的动作诡异而奇特，引来阵阵哄笑。随着横杆一次次升高，笑声没有了。在最后一跳成功后，他获得了奥运会金牌——全场起立鼓掌。跳高运动员福斯贝里福斯贝里是个典型的弯道超车选手，他的身体素质和成绩在普通跳法的时代很一般，更先进的起跳模式让他获胜。这就是加速成长的第一个要素，转换模式。《科学革命的结构》把这种转化称为 范式转换”paradigm transition trans。 飞机的发明就是典型的范式转化的结果。以前的发明家认为飞机应该像鸟儿一样，拍动翅膀起飞，他们尝试了无数方法让飞机的翼拍动，最后却无疾而终。而莱特兄弟那一代人想明白一件事——飞机不应该是鸟，而应该是帆船。飞机的翼应该像帆船的帆一样。一旦范式转化，所有的路径都清晰了，第一架飞机很快被发明出来。不过，仅仅转换模式还不足够，歌颂福斯贝尔创造性思维的人忽略了背越式跳高的第二个必要条件——橡胶垫。一直到上世界60年代，橡胶垫才被用来代替原来的沙坑，在这个之前，大头冲下的背越式跳高就是自杀动作。这是加速成长的第二个要素，学着应用新的工具和技术。在热兵器时代，再好的拳法和内功，也忌惮一个拿枪的人。看到趋势不掌握技术也没用。接下来的故事更有趣——在1972年慕尼黑奥运会上，福斯贝尔连预赛都没有进。在接下来的运动生涯中，也没有再复出——背越式跳高并不难学，他被更多身体素质好，学习能力快的人弯道超车了。这是加速成长的第三个要素，也是最重要的一个——修内功，提高核心素质。正好踩到趋势、技术要靠运气；如果不一定碰的上，最好的方式是提高自己的基础面，持续的关注趋势，学习新技术，发现机会就迎头赶上，把前浪拍死在沙滩上——这是不是更大几率的胜利？这几年的商业世界，先驱先烈，也是这样的游戏。正确的模式、工具技术和个人素质，是加速成长的三个要素。最后一个虽然听上去最不酷，其实花时间最长，也最重要。只听不动的人，往往眼界越来越高，手脚越来越低，变成一只知识瘫痪的“长颈鹿”。曾国藩说：“兵闻拙速，未睹巧之久也”，仅仅是精巧的东西长不了。职业发展是“拙速”，找到一个点，老老实实做事，踏踏实实练习，一年下来就会超过很多人，遇到一个机会，呼啦一下就起来了——成功是长久而持续的积累过程。 4.很多人认识我，是因为我写的一本书《拆掉思维里的墙》，所以我的标签好像是“畅销书作家”。其实在过去10年里，我大多数的时间都在做职业生涯的咨询、高管的教练、课程研发和授课，在我看来，这都是一件事——帮助他人加速发展，也从别人的经历中获得智慧。在这个专栏中，把自己这些年学习的近40门课程、相关的书籍，以及近千个案例中与一流高手交锋的智慧，分享给大家。王小波说，艺术来源于痛苦，但是没必要非来源你的痛苦啊。职业发展这个事也是一样——请相信，总有人用更好的方式在做你现在做的事。你需要的只是学习。 在《超级个体》里，我们准备这么干： 我们会每周探讨一个加速成长的主题——它可能是职业发展的基础能力、也可能是个人成长的底层概念、他们都来自大部分人有困扰的真问题。我把这些52个主题分成这么4大类：对事的竞争力、对人的影响力、对组织的领导力以及内在发动机——自己的个人成长。课程设置​我还加入了一些关于自我探索的测评和工具，一些积极心理学的内容。成功无论在数量还是在人生长度上，都是小概率事件。我们要学会在没成功之前快乐生活。这是一张正在进化中的图，这些主题会持续更新。 每次一个看得懂、记得住、能实操的工具、模型或方法论。知识同样符合28原则，任何一门领域真正核心的内容就是20%，最聪明的办法是用80%的时间学习其中20%的精华。这20%往往是一些核心的模型或工具——他们既是底层逻辑也是方法论。这也是为什么当别人问你上完一门课读完一本书学到些什么时，你的第一反应往往是说：恩，有这么一个模型、法则…………他们是聪明人做事的“套路”，观察世界的方式，有了这些会省你很多时间。拿着这些工具，希望这个专栏的订阅者能开始实践起来，只有当你实践起来，别人的知识变成你的知识，你的知识变成你的能力。所谓行到极处便是知，很多时候，做着做你就懂了。基于这些想法，每天的解都会围绕一张“成长卡”进行——我会把讲到的方法、策略、工具、或者模型浓缩在一张图上。你只要保存好这一年中对你有启发的“卡片”，慢慢的，你就有了自己的技术、自己的发展工具箱。 陪伴成长：我已经出版了两本书，最大的遗憾就是没有办法像讲课一样和读者及时的交流。比起一个千里传音的老师，我更希望做陪伴在你身边的成长教练——这也是我选择在得到开设这个专栏的原因——希望这是一个能陪伴你一年的文字。每周四周五，我都会在这里和你们深度互动、答疑、讨论这周的主题。等栏目走上正轨，我还会邀请更多有趣的超级个体来分享他们的独门经验，和大家一起探讨这个时代的成长方式。 在未来一年，我们一起来做三件事： 每周学习3个加速发展的工具和方法论、你可以逐渐打造一个属于你的超级工具箱 完整的梳理自己、系统展开能力地图，逐渐搭建自己的能力体系 认识更多各个领域的“超级个体”，看到人生不同的可能性有人问我，这群 “超级个体，到底超级在哪里？他们应该是这样一群人：他们理解科技又深具人性，精钻一门又有通识，与组织紧密合作又不失独立；他们是一群自主，自驱也自我成就，成功又幸福的人。在他们身上，做自己不仅是一种态度，更加是一种能力。这个时代就需要这样的超级个体。 ]新精英生涯古典：未来是个体崛起的时代文|MBA智库/子墨 古典老师，著名生涯规划师，高管教练，新精英生涯创始人，销量超过300万畅销书作者。少年文青，玩乐队，练散打，写小说，骑单车从长沙流浪到北京。2007年创办新精英生涯，现已成为中国最专业、培养认证生涯规划师最多的生涯教育与咨询服务商。对于创办新精英的初衷，古典老师说道，每个人进入职场都有个迷茫期，主要有两段。一个是刚刚大学毕业的时候，这个时候表现为不知道怎么面对职场；第二次迷茫期一般在职场中过了三年左右。他们有了一些基础技能以后，不知道怎么长远定位。而在30岁之前、35岁以后都还会有一次迷茫期，人都会阶段性的迷失自己的方向。因目睹无数中国教育下的一流人才的迷茫和纠结，意识到 “找到自我”比“去好大学”更重要。所以当时做新精英也是出于这样一个初心，希望可以帮助迷茫又困惑的职场年轻人，通过具有专业性、指引性、实战性的生涯规划培训和服务，确定自己的方向，跨越职场难关，合理规划自己的职业生涯，长成自己的样子！ 据统计“职业发展”已经成为“薪酬待遇”之后个人择业选择的第二大因素，然而面对新兴企业变化快的职场环境，越来越多的职场青年人对职业发展深感焦虑和迷茫，越来越多的HR和管理者希望通过生涯咨询的方式帮助员工找准职场方向。作为职业生涯这个市场中的一位创业者，古老师表示当下职业生涯是一个远远没有被开发的市场，就好像心理咨询一样。心理咨询市场也是没有被开发，但是如果爆发的话心理咨询市场会比职涯快很多。因为中国人观念都是有病了实在不行才去治，但是职涯就不同，可能每个人觉得有问题过来咨询这样的方式还挺好的；第二个是很少有人通过企业去解决职涯问题，虽然EAP项目能做但是落实在实处员工一般也不会真真正正的在那讲自己的事。而职涯很多企业都是采购职涯去做员工发展的，企业在这方面是有员工需求的，企业也需要员工发展好。 在提到对客户以及用户的把握上，“最重要的就是内容的输出，然后在持续的内容输出的前提下，把门槛降低”，古老师说道。他说，一个东西的流行主要就两个要求，一个让这个东西变得越来越重要，另外一个是变得越来越简单。而目前他们团队在做的就两件事，一个就是通过公关和品牌让产品变得越来越重要，第二就是通过技术让培训和咨询产品更落地更实战，从而让产品变得越来越简单。 古典老师在做客智库课堂（mbalib-class）时提出了超级个体的概念。从公司管理以及运营上，古老师做了更为详细的解释：他认为不管你是上班、自由职业还是创业，未来都是个人崛起的时代。未来的职场，将变成“平台+个体”，组织越来越需要牛人，但是牛人越来越不需要组织。 每个人都必须为自己的成长和职业发展负责，都要学会把自己的天赋和能力做成产品。但是，在未来职场的竞争里，领跑者永远只有少数人，他们就是超级个体。 超级个体并不是超级自由职业者，个体是要深度依赖于组织才能够发挥力量。超级个体并不是超级个人，超级个体应该是一群人，或者是一个特别善于和组织合作、共同成长的人；他既能站在科技前沿，又能深刻洞察人性；他具备多学科通识，又能精研某个领域，成为专家； 他比别人成长得更快，有很强的自我驱动能力，持续增值。 一句话，超级个体组成了未来职场的第一梯队。所以从这个角度来说，这些个体要有 自我驱动、自我管理和自我成就。自我驱动即管理者给他定目标但是不需要管理者来推动他去完成目标：自我管理，就是有一套可以管理自我情绪的方法。这一代人很需要也渴望自主性，但是如果没有自我管理手段，就会变成一个很乱的个体，永远无法成为超级个体。越是不需要被组织管理的人，越是需要有自我管理能力。 以前的企业是你不要有自我意识我来领导我来激励，但是现在的企业是你有自我意识，那你来自我领导、自我激励、自我管理，同时你也得承担自我管理的责任。当企业和个体能够在管理、领导这两个方面达到共识，它自然就形成一个自我成就的过程。因为在这一过程中，个体通过自己能力的提升给企业带来价值，而反过来企业也会把更多的利润比例分给他们。在古老师看来，超级个体是自己给自己自带资源，而 作为领导者是一定既是超级个体，也是好的管理者。 作为出版了两本书的古老师，最大的遗憾就是没有办法像讲课一样和读者及时的交流。比起一个千里传音的老师，他说：“我更希望做陪伴在你身边的成长教练！我们已经有了关于商业、趋势、政治和财富的内容，为什么我们不就做一档关于个人的栏目呢？”在他看来在越来越多商业、趋势的东西之下，个体越是容易被忽略。为个体发声，成为他一直以来的愿景。也正是基于这样的认识，才决定在得到APP推出一档新的栏目“超级个体”，围绕职业发展、个人成长，深度讲解一个主题。 对于目前高压、快节奏的生活，年轻人在理想与现实主义之间该如何找到自己的梦想的话题，古老师笑着说：“首先你必须有一个吧。所谓理想主义是你有一个梦想，而现实主义是你要为这个梦想，设置资源、提供能力和成就的路径。对于这三个方面如果没有研究的话，梦想永远是个梦想！很多人觉得自己有很多梦想，但是在这些梦想中间你有没有个排序？排序之后你有没有配备资源？如果配备资源你还得给自己设置路径，这就是现实主义。”就像他在《你的生命有什么可能》里说到的一样，理想主义者——我要一站到达，现实主义者——试试看，不行就算了，而现实的理想主义者——在迂回和修炼中，不断地去接近梦想！","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"你的生命有什么可能","date":"2017-01-10T15:25:06.000Z","path":"2017/01/10/MyShare/live-your-life/","text":"古典 你的生命有什么可能 即使在这个不那么公平的现实世界里，每个平凡人也都能活出各自的生命可能。 人生四个永恒的主题：影响力、爱、自由、智慧。 这本书将让我们打破自己心智的障碍，开始自由地思考和行走，然后看到人生的更多可能。本书探讨了以下问题：高竞争的工作、高不可攀的房价和房租、 拥挤的交通、糟糕的空气、不安全的食品……在竭尽全力才能生存的时代，年轻人如何追求自己的梦想？在这样的时代，我们的生命又有什么可能？如何才能越过现实和理想的鸿沟，找到和进入自己希望的人生？如何修炼自己在现实中活得更好的能力？如何在现实之中发展自己的兴趣？如何连接现实和理想？如何面对生命里的苦难、贫穷、不完美或者不公正？如何获得心灵的自由？ 人的生命如同水流，奔流的小溪终归静水流深的大河。——俞敏洪幸福人生不是外求，而是内修而来的。——张德芬它引导你探索内心的结构，剖析你成长的困惑，帮助你设计独特的人生蓝图。掩卷之后会为你补充力量，伴你出发并开始努力，在生涯发展的征途上，不断提高你收获幸福的概率。——毕淑敏“找到自己”比“去好大学”更重要，更多人将：成长，长成为自己的样子！——古典 序 你的生命有什么可能？一头奔入梦想不敢，留下过平庸的生活又不甘——这样的时代，我们的生命有什么可能？如何才能越过现实和理想的鸿沟，找到和进入自己希望的人生？ 他本来就应该想到： 你的人生不应该全信一本书，哪怕是神仙写的。 你可以送给你喜欢的人一双绿鞋子。 第一种人生策略是“遇见”：这些人用感觉来判断生活是否是自己想要的，期待自己能“遇见”想要的生活。他们的人生哲学大抵如下：打开一扇门，如果感觉不喜欢，就转身离去，打开下一扇门；喜欢就停留下来，但如果有一天这个地方变得不太好了，就继续试着开下一扇门。 第二种人生策略是“定位”：这些人相信世界上已经有一个最适合自己的人生目标，他们需要做的就是找到并实现它。他们的人生往往是这么玩的：先清晰地搞明白自己到底应该要什么，搞明白在哪里能获得，然后设定出一个清晰的计划，最终一步步地达成。 第三种人生策略是“创造”：这些人不愿意相信任何一种现成的人生答案，希望自己创造出一个；对他们来说，人生最重要的不是功成名就或即时享乐，而是一种“追寻的过程”。他们的人生哲学是这样的：创造的第一步是修炼——如果我无法一下子看到人生的终极意义和目标，那么我能做的就是先找到一个值得一试的目标，在达成的路上修炼自己的能力，扩大自己的眼界——反复重复这一过程——逐渐明白自己到底想要什么。当定见形成、能力变强，就没有什么能阻挡他们创造自己想要的自己和生活了。 定位人生最重要的条件，是你要生活在一个稳定和有序的时代。 如果以前的社会像一列慢悠悠喷着蒸汽向前的绿皮火车，那么今天的社会就像坐过山车——你永远不知道下一个弯路在哪儿。所以很多人等子弹飞到靶心，才发现物是人非。他们问：人生大叔，说好的幸福一辈子呢？人生大叔摊摊手：不是我不明白，是这世界变化快啊。 虽然定下来的确让我们安心，但 这是一个“定不下来”的年代。 以前老人们能对孩子们说：“听我的，因为我经历过你未来要经历的。”而今天，他们的孩子会说：“不，你从未经历过我将要经历的未来。” 今天的职业人需要到至少30岁才能逐渐理解趋势，看到自己的终生方向。 如果你学不会享受这种不确定感，不懂得在其中获得点乐子，这时代真的会要了你的老命。 开放的社会和互联网带来了人生的多元选择。80后大学生的大多数梦想都是下面四种：功成名就，让父母过好一些，组建自己的幸福家庭，为社会做贡献。 新一代人的生命没有上一代人的固定模板和样式，他们眼中的生命有无限可能。 当哈佛公开课在网上点击就可免费看时，你很难再像以前一样膜拜些什么人。大家的关注点重新回到自己身上——如何成为一个让自己喜欢的人？ 公司越来越小而美。这是一个个体的世界。 下面是书中的一些观点： 家庭背景对成长影响很大，拼爹确有其事；知识只能从一定程度上改变命运； 面对逐年加大的就业压力和文凭贬值，毕业生深陷于现实与理想的泥沼； 房租房贷占收入的比例很高，生活压力负担沉重； 本该由社会承担的教育、养老责任被硬性嫁接到家庭身上，独生子女发展中面临明显的“优势递减效应”； 他们希望以个人努力改变命运，却又无法逃离更大的社会力量的左右。 如果要把当代年轻人当成一个人，他/她应该是这样的：他的眼睛遥望着5000米外的七色彩虹，心中坚信每个人都平等自由，脚却踩在一片稀巴烂的烂泥之中； 他的脑子已经接受了要活出自我的想法，心里却困惑得要死，到底什么才是自己？ 人生有这么多可能，哪一个才是属于我的？ 目标有这么多个，哪个背后才是最好的？ 达成的方式有千百种，到底哪一条路确定能走通？ 我的想法那么好，家人反对怎么办？ 有人拼爹怎么办？房子怎么办？当他们的目光在美好的未来和脚下干瘪的现实之间来回切换时，迷茫、焦虑、浮躁由此产生，成为“定不下来”年代的时代病。 修炼与创造人生在“定不下来”的年代，人生不应该是规划出来的——规划意味着你的人生有一群“专家”比你更懂（还记得开头那本神仙的书吗？），规划还意味着早点确定，确定了就不要改变。连IBM这样的靠战略吃饭的公司也只制订五年战略规划。非要一个人做个长达10年甚至20年的生涯规划，除了有点励志的作用外，并不太靠谱。 在这个定不下来的年代，修炼和创造人生反而成为一种最有效的策略——以不变应万变——如果你不知道这世界和你将要去哪儿，最好的策略是先全力炼出一种在哪儿都能活好的能力，在有足够力量和眼界的时候，开始创造自己的人生！就像开头那个故事——你可以送她一双绿鞋子，还要成为一个值得的男人。 今天的人生发展不应该像狙击手，而应该更像导弹——先尽快地发射出去，让自己适应变化的环境，让自己飞得又快又稳；然后每秒都用激光重新定位目标，调整弹道，最后发现目标，一击必中。 当然，创造人生的模式也有自己的缺点，从心理感受来说，它让你面临比前面两种更多的不确定感：如果把人生比作航海，求遇见的人把命运之舵交给外界，自己回床位休息；求定位的人在打开自动巡航抵达目的地之前会有一程安心；而修炼之人则需要站在船长室，时刻把握着命运之舵，对每一种人生的不确定做出快速反应，在狂风暴雨中找到自己的星光。 所以这群人生的创造者总会有点“玩商”，他们善于把修炼本身变成一个有趣的经历，当过程值回票价，结果也就不那么患得患失了。 生涯是一门探讨人们如何在现实中生存、生活和生长的学问。 职业是人们实现生涯目标的手段之一，成功也只是幸福的副产品，生涯的真正目的是帮助人们发展自己的人生。 每个人先把自己修炼成生活的高手，然后用自己的独特天赋、不同的方式，追寻自己领悟的人生意义，在热爱的领域努力地玩，活出最喜欢的人生。这样的人生才精彩有趣，是不是？这就是这本书想谈的话题——你的生命有很多可能。这本书不准备做真理候选人，也不准备开山立派。只希望拆掉思维里的墙的你，能看到这个世界上的光。而当你看到光，希望你有能力成为一个走入光明的人。 价值观的修炼我如何知道自己要什么？如何找到自己想要的东西？找到了又如何保护自己坚信的东西？ 人生的四个永恒的主题：影响力、爱、自由、智慧。这是我自己最喜欢的一部分。我想努力地证明，即使在这个不公平的残酷世界，每个人也都能活出各自的生命可能。 在热爱的领域努力地玩！ 热爱，努力，玩耍。好的人生，就是在自己热爱的领域努力地玩。 热爱、努力、玩耍，孩子们整天过着这样的生活，他们总能找到自己热爱的领域，在其中全力以赴地努力，却又能对结果一笑而过。 有的人在热爱的领域里努力，却放不下得失之心来玩。他们对自己苛刻，活得太一本正经，像台永不疲倦的机器，忘记自己也有玩耍、快乐的要求。他们活得身心俱疲。 有些人在热爱的领域里玩耍，却因为害怕努力了也无法成功而从未真正全力以赴。当一份工作做不好，他们迅速转移并爱上另一个。他们表现得天马行空、毫不在意，掩饰自己对生活的无能。 还有些人在某个领域里努力地玩，却并不热爱——这些人往往看起来混得不错，是人生大赢家，只是他们从未意识到自己除了成功或失败，还能选择玩什么游戏、和谁玩、玩不玩——还能成为选择自己人生的人。 当你羡慕旁人时，有没有想过——也许那不是幸运，而是一种习得的能力。一个人命中的财富、成就和光环，也许的确有幸运的成分，但是那人展现出来的快乐、热爱和努力，都不是“遇上”的，而是“修炼”出来的。 所有的美好人生都是修炼和管理出来的。每一项人生要素背后，都有支撑它的能力。 兴趣：提升兴趣让我们持续发现新的事物，给生命注入玩耍和快乐的体验；能力：强化能力让我们固化自己的努力，得以掌控生活和工作，取得成就；价值观：固化价值观让我们产生定见，抗拒各种诱惑，聚焦热爱的领域，获得宁静与满足。 兴趣产生了快乐，努力产生了能力，而价值观则帮你发现热爱的领域。兴趣、能力与价值观是三种最重要的管理生命的能力——当你拥有强大的兴趣、能力和价值观，你就会很容易地发现自己热爱的领域，在里面努力投入地玩耍；而如果你缺失了这些幸福的能力，即使你有幸能找到这个领域，你也无力把握。 过好人生是一种能力，而非天赋。当你开始掌握正确的练习方法，每个人都有无限的可能。 兴趣让你发现适合的行业，能力让你进入能胜任的职位，而价值观则帮你筛选你喜欢的工作方式、同事和公司。 是兴趣推动你持续地在职业领域学习，发现新的机会；能力帮你持续地产生竞争力；而价值观则帮你在机会爆发的时候保持聚焦。 大学生就业难，年轻人职业适应力差，就是 过于强调“匹配”而非“修炼”的结果。 谈恋爱也是一样——你的兴趣决定你喜欢什么类型，能力决定你能搞定谁，而价值观则帮助你理解谁是一夜情、谁能与你长久走下去。如果不多见几个人，你怎么知道你对谁感兴趣？如果你从未与异性单独约会，你如何有搞定对方的能力？如果你没有体验过恋爱，你怎么会知道自己更看重精神交流还是稳定的生活？ 张学友说得好：等待着别人给幸福的人，往往都过得不怎么幸福。 成熟的爱情观应该是：爱情不是幸运，而是一种能力。先走出去，多接触人，在恋爱中学会恋爱——发现自己，修炼自己，使自己成为一个有趣的、有能力爱的、知道自己想要什么的人，你总能找到你想要的爱情。 兴趣为你打开一扇又一扇门，能力帮你走好一段路，而价值观则帮你不断关上不属于你的门。三者结合，让你在热爱的领域努力地玩。 任何人，不管家庭出身、学历和天赋如何，都可以通过修炼自己的兴趣、提升自己的能力和打磨自己的价值观，找到自我实现的平台，在现实的生活中，收获快乐、成就和幸福的人生。 幸福是一种能力。好的人生并非外求，而是内修而成。每个人都可以通过整合和管理自己的生命资源，最大化自己的人生价值，达到个人与社会的双重满意。也正是在这样的过程中，我们逐渐发现自己永不停歇的好奇、浑然不觉的天赋、发自灵魂的热爱，最终成长为自己的样子。 转动三叶草：掌控自己的人生比方说运动，你觉得NBA明星很帅，很明显你对打篮球感“兴趣”，而有人觉得足球更炫，他对足球更感兴趣；当你开始投入时间练习打球，发现有人跑得快，有人跳得高，有人则投得准，每个人都施展出不同的“能力”；即使是两个能力一模一样的人，因为“价值观”不同，也会有不同的球风——热爱“团队合作”的人喜欢把球传给最佳位置的人，看他们把球投进；而热爱“挑战”的人喜欢从最多人拦截的地方带球突破；而热爱“异性关注”的人在妹子围观的时候会突然爆发，女生们一走，他就蔫了。 我们先会对某一件事情感“兴趣”，这兴趣驱动我们学习和练习；持续地学习和练习让我们有“能力”完成很多事情；然后我们开始寻找一种合适的方式（往往是某种职业）把能力兑现成 自己想要的“价值”。而价值强化会使我们产生下一轮的兴趣。兴趣、能力和价值观的三叶草，就是这样旋转起来，让我们掌握和精通某一个领域的，然后进入更大一轮的“兴—能—价”循环。为了好记，也有人将其称为“性能佳”循环——让自己保持在这个循环中，你就是性能最佳的！ 想要知道更多专业知识（兴趣），把能力提高到专业水平（能力），可以帮助更多的人（价值观）。 永不衰竭的好奇心、高超的能力以及惊人又可怕的内心动力。 这本书也按照三叶草的循环写成：当我有零零碎碎的想法时，我只有一些小兴趣，这兴趣只够驱动我写一条140字的微博——如果你一大早看我发一些莫名其妙的小感叹，那就是它们了。如果很多人转，我会自我感觉不错，收获些价值，这价值让我有动力写一篇博文或者专栏，而如果这个专栏或者博文反响不错，就会吸引我把它们扩展成一个章节。这当然需要更大的能力：篇章结构、考据、案例、荐书……当然，如果你能看到这本书、购买这本书，更大的价值也将汇入我的三叶草，酝酿下一轮的转动。 —反对派讨厌规划师，会说，你凭什么规划我的人生？崇拜者则会说，大师，请你给我一个详细的、精确到每一天该干什么的规划吧！这种人该轮到规划师讨厌他。 你真正能控制和衡量的，是自己的三叶草转动的方向和节奏，正如我在《拆掉思维里的墙》（以下简称《拆墙》）中所说的：成功就是越走越近。 推动大家的生涯“发展”起来，看到更多可能，然后选择一个，走下去。找到你的生涯三叶草的起点，然后推动它开始循环，它会带你进入你所未知的人生。 情绪比你会说话：找到成长的突破点 当缺失“兴趣”的时候，我们表现出“厌倦”的情绪，再严重点会开始觉得“活得没意思”；当缺失“能力”的时候，我们表现出“焦虑”的情绪，再恶化就顿生“无力感”；当缺失“价值”的时候，我们表现出“失落”的情绪，持续很久以后内化成“自卑”。 HR会给这个人三板斧：要不要休息一段时间？要不要团队拉出去团建一下？要不要找个人进来搞搞培训？实在搞不定的话，要不要调个岗？ 如果是厌倦带来的倦怠，休假的确是一个不错的方法，培训只会让他越来越烦；业务培训是焦虑的员工最好的治愈方式，但如果是虚头巴脑的企业文化培训，只会占用大家时间，让人更加焦虑；而如果是价值缺失带来的倦怠，休假只会让人越休越不想工作。 接纳自己是成长的第一步。当你读懂了情绪背后的需求，你就能找到自己成长的方向。厌倦需要变化，焦虑需要学习，失落需要价值。 因为知道不重要，改变才重要。 我天生就没有……兴趣该怎么办？ 兴趣的确有基因或者外在的因素，但是影响微乎其微。兴趣与其说是一种天赋，不如说是一种自我技能——那些生活得有趣的人，往往是下意识掌握这种技术的人，而我们大部分人可以通过有意识地学习，让自己活得有趣。一旦明白兴趣是门自我管理的技术，那么任何人只要下定决心，就一定能够活得有趣。 你的兴趣从何而来？ 心理学认为，兴趣是一种情绪，而情绪是人类进化出来的一种生存工具。这种情绪能够穿过百万年的进化留下来，一定是因为其有莫大的好处。 有趣（interested）是一种和不确定相关度很高的情绪；愉悦（comfortable）是一种和确定性相关度很高的情绪。而有趣和愉悦，是两种完全不同甚至相反的情绪——当一件事情复杂、新奇且不确定的时候，人们就会感到有趣；而当一件事情简单、稳定和确定的时候，我们就会感觉到愉悦。愉悦的事情，不一定有趣，而有趣的事情，不一定会愉悦。变态辣鸡翅有趣而羊肉串愉悦，创业有趣而公务员愉悦。 好生活=愉悦+有趣 它们温暖、简单、安全，带给我们幸福与愉悦的感觉。 好的生活应该是愉悦又有趣的。动画片的设计最能说明这个问题：为了让注意力时间很短的孩子坐在荧屏前一个多小时，即使可能没有心理学知识，动画片大师也都直觉般使用了这个愉悦+有趣的模式——在大部分动画中，总有一个复杂、新奇、或神秘或搞怪的二号人物，又有一个直接、温暖、简单的主角，如驴子和史莱克、流川枫和樱木花道、佐助和鸣人、豪猪和小狮子王，所以这些动画片既愉悦又有趣。 兴趣是一种应对成长中的“不确定”的情绪——当我们遇到了“不确定”，我们会下意识地躲回自己的舒适区寻求“愉悦”。所有的成长都来自舒适区之外，这样一来，我们永远也无法成长。这时候“有趣”的情绪会出现，帮我们渡过难关——此时大脑跑出来个小人挑逗：“多好玩啊，要不试试看？”于是我们继续前进，越过那些不确定。兴趣鼓励我们走出安全区，让我们变得越来越强，而世界变得越来越大。兴趣是成长的催化剂。 大人把孩子抛起来玩耍，孩子会先有些恐惧，但是一旦被接住，他就会咯咯大笑，笑声像广场上飞起来的鸽子。几次之后，孩子只要一被抛起来，就呵呵地乐。他开始穿越这种不确定性带来的恐惧，觉得有趣，他的勇气变得更大，他的信任感变得更强。 有趣和愉悦的界线，在于“不确定性”的程度。过于不确定的生活毫无愉悦可言，充满焦虑；而一旦不确定太少，日子又无趣得很，日复一日能淡出个鸟来。有智慧的人懂得调配出适合自己的“不确定”。有趣如菜里的盐，而愉悦如菜本身，如调配得当，管自己、做项目、办公司、治大国如烹小鲜。 好的生活应该是愉悦加有趣，适当的不确定。但是很多人对“感兴趣”的事情持有幻想，他们认为感兴趣的事情应该是特别快乐、舒适、天生就会的。有这种信念的人把自己玩得很惨——他们终生寻找自己“感兴趣”的事情，一旦遇到困难与不确定，就声称自己“不感兴趣”，然后闪人，寻找下一个“感兴趣”的事情。其实，他要的不是兴趣，而是愉悦。 如果是不愉悦，则需要做减法，找到核心价值，降低其他目标，进入一个相对简单、清晰的职业环境中去；而如果是无趣，则需要做加法——提高一些难度，或让自己进入更复杂、更不确定的职业环境。 像这位仁兄一样，我们常常因为白饭吃多了，就以为自己想以腐乳为生。我把这种现象称为“火锅效应”——如果你问一个天天吃家常菜的人想吃点什么，他会说：“火锅！我最爱吃火锅！”但是如果你抓他吃一个月的火锅——哪怕变着花样，他估计就会哭着喊着要回家了。最好的生活，是经常吃米饭，偶尔点火锅。 如果你真的希望生活过得特有趣，就让我告诉你兴趣的真相吧：兴趣不是那件让你舒舒服服就成功拿到结果的事，兴趣是那件让你白天痛苦地想、晚上睡不好、早上五点爬起来，一边苦笑着骂娘一边咧着嘴干完的事情。这才是兴趣本来的样子。 有趣是一种力量 “兴趣是最好的老师。”该如何用好这个老师呢？兴趣老师的第一种功能是推动你探索和发现新的世界，为未来做好能力储备。在人生每一个成长的重要阶段，兴趣都会提前到达，提醒你将要面临的阶段，帮助你搜集好要使用的信息和能力。正如心理学家Berlyne所说：“每多获取一分信息，就会让我们对未来的复杂、沮丧或者无助多一分保障。我们的神经系统选择在那些除了紧急要求（包括睡觉、休息）之外少有的自由时刻做些有趣的事情，这真是个最佳选择。” 兴趣的种子在小苗阶段被杀灭，怎么会开花？所以，如果你发现自己对某件事情突然感兴趣起来，先别着急评价这会不会浪费你的精力，有没有偏离你的规划，是不是有足够回报，留出一段空间，先让自己顺着这个兴趣走几步。这也许是生活对你的提醒。也许在模模糊糊的兴趣背后，有一个全新的领域在等着你。如果你千年朽木脑袋突然抽出绿芽，难道不是因为春天来了？ 高手在单调的重复中生成，求快不配做高手。 高手们为什么可以扛得住这样长达几万小时的重复和单调？研究发现，每个行业的高手都知道各种让无聊的工作变得更有趣的策略——邮差懂得吹着口哨打发骑车的无聊，搬运工懂得唱出劳动号子来应对肩膀的疼痛，训练场上的球员懂得隔段时间给自己挥拳打气，而几乎所有的IT公司都有荤段子文化——在写代码的时候猛讲黄色笑话——他们太需要一些东西抵御码代码的无趣。我的兄弟老杜告诉我，他听贝多芬写代码，不知道是有欣赏贝多芬的趣味，还是贝多芬也能听出荤味来。总之，高手们都觉得修炼挺有趣，他们是“玩”成高手的。 研究还发现，只是强调重要性并不会使一件事情变得有趣，过度的强调会适得其反。有趣的事情不一定重要，所以 学会让重要的事情变得有趣，才是关键。 理智带来的驱动力，永远没有情绪发动机——兴趣推动得有力。当我去学习太极的时候，老师告诉我，练太极最好的心态就是“玩”。艺术家们最才华横溢的作品，往往是在前期“玩”的阶段创造出来的。 爱因斯坦只说“兴趣是最好的老师”，却没有详细说明这个老师好在哪儿。现在我们知道兴趣是个人成长中出现过的最好的老师——它在我们人生面临考验前，提醒我们提前学习；它在我们讨厌重复学习的时候，提供有力的鼓励，让我们发展出知识与技能。 如何利用好这个老师？为什么有些人的兴趣老师温柔而坚定地一门课教几十年，而有些人的老师则抽了风一样天天给你开新课？请接着看，如何养大一个兴趣。 如何养大一个兴趣（一）：兴趣金字塔 关注每一届星云奖和雨果奖。在国内的作家里，刘慈欣的《三体》系列对我影响最深。我曾经自己写过一小段面壁者罗辑（《三体》男主人公）的外传，发在自己的博客上了，有两万多的点击量。如果可以，我很希望从事和文字相关的工作。 直观兴趣（又称感官兴趣），自觉兴趣与潜在兴趣（志趣）。 我们的感官兴趣正如乐曲中的小女孩，好奇、多变而不稳定。外界的刺激决定着感官兴趣的长度和强度，这是我们最动物的一面。也正是因为这样，感官兴趣让我们当时很爽，却又无法让我们集中在任何一个事物上，形成能力。正如你刷完一天微博，或者大吃一顿自助餐后感觉到的那样——没有什么留下印象。 自觉兴趣是认知行为参与的兴趣。 自觉兴趣比感官兴趣更高级，第一个理由是思维的加入，这让我们的兴趣可以更加持久并定向在一个领域，从而在脑子里形成回路，产生能力。而能力又反过来让我们能体会和学习更多。“能力—兴趣”的循环，让我们慢慢精通某项能力，打开世界。 一开始接触的老师似乎很普通……但他们在启动热情，然后把小火花培养成熊熊之火，他们教的是热爱。第一阶段的学习目标似乎是让学习者参与，并且沉迷其中，使他们想了解更多的信息和专业知识。” 有趣的人往往懂得主动发展更高层的直觉兴趣——兴趣推动学习，学习带来了行动，在行动中发展出能力，能力又发展出更大的兴趣。有了关于京剧的知识，你也许会开始享受京剧的韵味；有了更多关于葡萄酒的知识，你也许会发现除了兑雪碧还有更多好玩的喝法；学习词源和词根，词汇学习也许变得没有那么枯燥了。你学得越多，你能感到的乐趣就越大，这就是有趣之人兴趣持久的秘密。 养兴趣和养花一样，有人养什么活什么，有人养什么死什么。关键是让兴趣与能力循环。 当我们把兴趣的源头从外求转为内寻，我们就有了一个让自己变得有趣的内在泉源，自得其乐的人最无敌。 不，这群世界级的高手在自觉兴趣之上，发展出一种更加强大而持久的兴趣，去对抗高手之路上世界级的重复和倦怠。这就是人类最高的兴趣等级：潜在兴趣，也称为志趣。志趣的秘密不仅在于有感官和认知能力，还加入了更深一层的内在发动机——志向与价值观。 内控的兴趣、明确的方向与强大的动力。 就像登山家看到险峰、极限单车运动员见到陡坡一样。他的助手觉得无趣，因为他们的兴趣在于成功，而爱迪生的兴趣在于奥秘。当他一点点展开自然的图卷时，他越来越兴奋并觉得有趣——这才是他的动力之源。 知之者不如好之者，好之者不如乐之者，乐之者不如志之者。 上天给了我们有限的时间、有限的天赋，却留给我们无数的机会与诱惑。志趣让我们坚定地专心。 如何养大一个兴趣（二）：兴趣饲养攻略 兴趣饲养三步法：第一步，让自己先沉浸在足够多的感官体验中，获得兴趣的第一步动力。第二步，在感官兴趣还没有消退时，尽快掌握更多的知识，使自己的感官兴趣进化到自觉兴趣。第三步，给自己找一个兑换价值的方式，把这个兴趣和你最感兴趣的价值绑定。别把自己的目标设定得太高，以免产生失落感。不断地重复这个过程，兴趣就会慢慢固化下来。 用同样的兴趣饲养攻略，我们审视一下为什么很多人“想学好英语”，却永远没有真的成行。第一是因为他们并没有真正被刺激到，“学好英语”顶多只是一个“我应该学好”或者“我渴望好一点”的概念，而不是一个真实的、浸泡式的体验，一个清晰的、可见的愿景。所以一旦刺激消失，他们就该干什么干什么去了。第二是因为他们没有及时地研究关于英语学习的各种观点和理论，找到自己想要付诸行动的。今天听听美剧，后天学学语法，不成系统，也无法进步。第三点最关键——他们有些学了也没用武之地，没有价值的兑换。有些目标订得太高，如“一年之内学好英语”，但是什么叫学好？多好才叫好？这样的目标即使你背过整本新概念4也没法儿达到。所以，他们的兴趣无法持续长大。反观很多不会英语却被丢到英语环境里的人，他们为什么都能迅速学会一口让自己生存下去的英语？因为第一他们有被刺激的环境，第二有足够多的学习资料和机会，第三是他们的英语能马上兑换出价值。而且作为初学者，国外其实有比国内更宽容的环境，他们也不害怕讲错。集齐感官、知识和价值兑换机制这三种维生素，每个人都能养好自己的一个兴趣！ 为什么你活得无趣？ 在“有用”的人看来，有趣的人总是显得不安分、特立独行、乐呵呵、莽撞、好奇与想象力四溅，终日做着些“没什么用”的事情。有趣的人时常会听到这样的批判：找工作能赚钱啊！——旅行有什么用？能赚到钱吗？跑步能锻炼身体！——跳舞有什么用？能锻炼吗？考个会计证能加薪啊！——学画画？能卖钱吗？结婚就安定下来了啊！——谈恋爱搞浪漫？还不是要结婚？有什么用？ 无用的人生卑微，而无趣的人生悲哀。 一旦一个人把 是否“有用” 作为事情的唯一评价标准，那么这个人活得无趣就天经地义。这种功利与短视的背后，是深刻的不安全感与焦虑。 和这样的无趣之人对话特别费劲——你和他们谈起一个好玩的东西，他会先问你：“赚钱吗？”然后是：“好弄吗？”如果答案是肯定的，他又会问：“肯定吗？”这些问题只要有一个是否定的，他们就不感兴趣，转移方向。 当课堂外的一分一秒都充满了确定性，当每一个行为都必须在系统里置换出有用的结果，兴趣这个老师就彻底被开除了，随之而来的好奇心、想象力、创造力更无从谈起。 读书只求有用，就如吃饭只管饱一样——我干吗非要有用啊？！ 事情可能有用，也有可能无用；有趣是投资能力，而不是消费生活。有趣能让我们拥有越来越多的可能，同时也越来越生机勃勃。而无趣之人逐渐长大，世界与他们越来越无关了。 有趣是种活着的、元气淋漓的状态，有趣证明我们还年轻，还在打开新的世界，还在长大，没有长老。 兴趣攻略：避免活得太有用 Different Night要想在生活中创造不确定性，先要留出生命中的空白。 我们的大脑喜欢空白，一旦出现空白，就会把自己潜意识里迫切的东西填进去。每周给自己设定一个different night（第八夜），不要设定任何比如说“我要养成一个习惯”或者“要发现自己的兴趣”这样的期待；然后以自己最放松的状态投入，随便干点什么——你可以漫步某个地方，约一个不常见的人，或者参加一个此前不会参加的聚会，总之，做点不一样的事情。 与有趣的人待在一起找到身边你觉得有趣的人，和他们待在一起，看看他们业余时间在干什么。作为讲师，总需要出差。头几年还觉得有趣，看看名胜古迹，几年下来全国好玩的地方都去过了。但全国也迅速地变得越来越一模一样，我对出差开始厌倦。直到我有一天想：既然地方被扫荡完了，为什么不找有趣的人？于是我做了一张中国好玩的人地图——每一个城市，我都标出来自己想认识的人，出发前给他们私信，要求拜访。@秋叶语录老师就是这么认识的。我开始爱出差去武汉了。 不跟团的自助游 加入一个全新的兴趣小组 我们从读书时代迅速进入博客时代、微博时代、读图时代、视频时代。这都是为了满足我们永不满足的感官兴趣——一个接着一个，一个接着一个，不要停。请注意这种碎片化信息流的危险，它们无穷无尽、日益刺激、频率切换太快，这些都让我们没有时间深度思考，进入自觉兴趣。 人的注意力资源有限，当你的大部分注意力都陷入感官刺激的泥潭，你也就没有精力发展出那个兴趣金字塔的尖，取而代之的是，你把自己发展成一块板砖——知识面狂宽，但是肤浅得可怕。也造成了潜意识思维的短路，因而既阻碍我们进行深入思考，也阻碍我们进行创造性思考。 你的头脑像不像被轰炸的汉堡？每分钟传来的无数信息让你丧失了注意力焦点，在一天的“轰炸”后，你累得要死，却一架飞机都没有打中。当你习惯了一分钟的烟花，你就可能再也感受不到整夜的宁静星空了。 专业的寿司食客在每两个寿司之间，会吃一块姜片，让自己的味觉重新回到原点，才能更好地感受下一个寿司的滋味。而在每天的感官轰炸中，你也可以给自己一段静默时间，让自己有机会发动更高层次的兴趣。电子静默就是个好方法。 一眨眼一小时就过去了；感觉做任何事情都尽在掌控又流畅；精神高度集中，目标专注；把一切烦恼抛诸脑后；有一种高度的兴奋和充实感……你正停留在你的“心流”（flow）里面。这是兴趣发展的极致。在大洋底下有很多看不见的洋流，神驰。 你喜欢从事的活动；你能专注的且不会忧虑的；有清晰目标的；有立即回馈的；有主控感的；时间感流逝停止的…… 你想到了什么？男生想到了玩游戏，女生想到了购物。这些都是喜欢的、能专注的、有清晰目标和立即回馈的活动，如果你只看不买的话，也没有忧虑。所以男女各自能在游戏和商店里待一整天，完全感受不到时间流逝。如果工作也能像玩游戏和逛街一样，那该有多好！（想想一个无论如何也无法通关的游戏、陪女友购物刷卡的人、一项难度太高的工作吧），而如果能力太高但挑战太低，则会产生厌倦（比如把你分到幼儿园组踢足球）。 一开始我们要提高技能（A），但是一旦感到自己厌倦了，就马上提高挑战难度（B），一直到自己觉得焦虑，然后开始学习新的技能，一直到厌倦感又来临，再继续提高挑战难度。 游戏设计的原理：在一开始的时候先让你很容易升级，也很容易拿到点数，继而逐渐提高升级的难度，也让你掌握越来越难的操作技能。如果游戏设计得好，你会一直玩下去。只要你对于自己的状态有觉察，同时有足够的挑战和技能可学，让工作像逛街一样其实不难。好的教练通过心流设定学习进度，好的电影通过心流设计剧情和镜头惊喜，好的老师通过心流让课堂不知不觉地进行。而你能做的事情，则是找到自己心流通道的宽度、斜度以及工作方式。 外一篇：有趣的王小波《一只特立独行的猪》 智慧本身就是好的，有一天我们都会死去，追求智慧的道路还会有人在走着。死掉以后的事我看不到，但在我活着的时候，想到这件事，心里就很高兴。我对自己的要求很低，我活在世上，无非想要明白些道理，遇见些有趣的事，倘能如我所愿，我的一生就算成功。 证明有趣与有用无关，证明不管生活多平庸，任何人下定决心，依然可以活得有趣。 兴趣的总结：每个人都能活得有趣！●兴趣不是一种天生的属性，而是一种自我管理技能。人人都可以活得有趣。●调试你生涯中的愉悦/兴趣比例。●提高你的兴趣层级，越高层级的兴趣越稳固，对生涯的影响也越深远。●有趣杀手：太追求“有用”、感官轰炸、走出心流通道。 温度计，热水壶，漱口杯，雨衣和降落伞。如果我能够重来一次，我会到处走走，什么都试试，并且轻装上路。 如果我能够从头活过，我会延长打赤脚的时光。从尽早的春天到尽晚的秋天。我会更经常地逃学。我不会考那么高的分数，除非是一不小心。我会多骑些旋转木马，我会采更多的雏菊。 成长空洞——填满你内心的空洞 我们每个人都希望变得比现在更好、更强大或更美丽、更自信或更自在，我们心里住着一个完美的自己、一个“希望成为的状态”，这就是自我概念。你只有把现在的自己和自我概念做对比，才会觉得“不满足”。在每个对生活和自己不满足的背后，都是每个人成长的需求。 如果你是个愤怒青年，你就应该拥有一个世界应该更好的信念，当你觉得自己做什么都无法让世界变好时，你就会对这种无力感到愤怒；而如果你是一个自卑的人，你脑子里一定住着个不知道从什么地方搞来的、大到完全无法填满的自我概念，你真实的自我穿着17厘米的内增高再加上大号的垫胸垫肩才撑得起来，生怕别人看到真正的自己。不过，愤怒和自卑的人都不可怕，可怕的是那种对生活完全失去兴趣和意见的人。他们没有什么成长的空洞，自我概念裹在真实的自我外面，他们已经没有什么可能 成长的空洞让我们感到自己心灵的空洞，这空洞感就变成了“内心的需要”。你想要一间可容身的房子、一份适合自己的工作、一个爱自己的恋人、一个听话乖巧的孩子……这都是你填满空洞的需要。因为你的自我概念认为这些你应该有，而真实的你却没有——这就产生了你的需求。 理想和现实的差距产生了空洞，这空洞产生了需求。 所以愤怒都是空洞的，王小波说，所有的痛苦本质上都是对自己无能的痛恨。人生就是一个不断发现空洞、填满空洞的过程。 我们的基因、家庭、环境、社会文化与人生经历共同创造了现在的我们，也建构了我们的自我概念，这让我们生出大大小小、各自不同的成长空洞。这些成长的空洞构成我们对“值得”的观念和想法，价值观就这样产生了。 基因+社会与家庭环境=自我概念自我概念-现在的自我=需求 虽然成长空洞人人不同，但每个人的努力方向都一样——填满那些空洞，成长为自己的样子。看到自己的成长空洞，了解这些洞需要用什么填，在有限的资源中按照什么顺序去填，就是找回自己、理解自己、成长为自己的过程。 玩“假我游戏”的人 房子填满安全感的洞、钞票填满自尊的洞、学历填满智慧的洞、消费填满快乐的洞 被物质充满的人，逐渐会认为物质才是真的自我 如果你身处一个什么都用钱才能买到的社会，你自然会认为——钱最重要。难怪很多人会把一定数量的钱当作生命目标呢。你肯定自然而然地认为——财富、物质和尽可能的满足自己需求，是生命最重要的三个部分。拜金、成功学和享乐主义，三者合谋，构建出这个建立在物质之上的虚假自我骗局。用物质填洞的人最大的悲剧是：没有人的能力能跑赢欲望 总有一天，你填入了所有东西，却无力地发现，那个空洞还在。物质也许能带来短暂的一次次快乐，但绝非幸福。快乐和幸福，本就是两个东西。你占据的东西，也在占据你。 在我们成年之前，我们一直都在寻找认同。 经历过真正爱情或友情的人都明白，心疼才不是一种文学的比喻手法，那是一种真实的生理体验。两个人互相用对方填满了自己的空洞，他们如此紧密地在一起，待了那么久，像一对连体姐妹。日子一长，你把这些被填满的部分认为是自己的一部分。这种感觉如此美丽，就好像“两个灵魂在一个身体”，而等到关系结束，两个人不得不分开，这种感觉又会如此痛苦——这种分离带来的强烈的撕裂感，就好像要扯掉一个已经长在你身上的器官一样。古往今来，已经有太多文字、歌曲、戏剧等艺术记录了这种情感的美妙与痛苦。 你会感到安全和快乐——慢慢的，你开始认为这些都是自己的一部分。当你获得越来越多的人的认同，你就觉得自己在不断地“成长”，越来越“有面子有地位”。当这种外界的认同成为你自我的主要部分，你开始认为，那个“被认同”的部分、你的名声、地位，才是你真实的自我。从那一刻开始，你就被别人的认同绑架了。 被认同填满的人，逐渐成为认同者的绑架对象一辈子按照他们的意愿来生活。为了不失去朋友或同事的认同，甘心一辈子做没有主张和方向的“老好人”，不和任何人冲突；为了不失去大众的认同，名人们甘心做一个粉丝眼中完美的“假人”，被粉丝绑架。这并非善良，而是无能的表现。 如果没有意识到你心里的洞、从内至外地去修炼，这个轮回会永无休止。所以，亲密关系中，你是谁，你就会遇到谁。你若盛开，清风自来。 寻求“被认同”是社会构成的基石，但是一旦过度追求“被认同的我”，真我就会遍体鳞伤。尤其在我们这个提倡以和为贵的文化中，每个人都乐此不疲，玩得好的甚至被称为美德。不知道你怎么想，看着那些被称为早慧、年纪轻轻就八面玲珑的孩子，我总觉得可怜又恶心。 玩“被认同”的游戏并不是自我成长之路。当认同一次次填充进来，你会上瘾一样地享受着这种既快乐又自虐的快感，渴求更多的自我妥协。正如席慕容在《独白》里面所说： 在一回首间，才忽然发现，原来，我的一生的种种努力，不过只是为了周遭的人都对我满意而已。为了要博得他人的称许与微笑，我战战兢兢地将自己套入所有的模式、所有的桎梏。走到途中，才忽然发现，我只剩下一副模糊的面目，和一条不能回头的路。 慢慢的，你会发现其实你并不是世界的中心，其实你谁也不是。你只是为别人认同而活的工具。你以为大家都喜欢和离不开你，其实是你离不开他们的喜爱。 谁被夸的时候都很快乐，但是遇到批评或指责，很多人的反应总是破罐子破摔。 做得不好，暴露出你成长的空洞，而自残的人的回应则是彪悍地说：根本不是“我”的问题，不是我努力想做却还差一点，而是先天的问题、环境的问题，或者是我根本就不想做好！ 破罐子破摔的回应虽然暂时能让自己舒服，但是相应地，成长的可能性全部破灭。从此以后，这件事情不可能做得更好，而关系也无法向前一步。不仅这样，在空洞旁边，已经培养起来的很多能力也忽然被割舍——因为手臂上的一个小地方发炎，你不愿意面对，就把整条手臂都剁了下来。 这比喻虽血腥却真实，这也是为什么我把这个类型的“假我”游戏叫作自残的人——为了逃避痛苦，他们不断地砍掉自己真实的自我的各个部分，最后缩小到自己都看不上的地步，自卑是自残者的必然结果。 你放弃了痛苦，但也放弃了自己。 **人不见得比猴子好多少。我们总是挖健康的坑，来填事业的坑；挖自由的坑，来填安全的坑；挖自尊的坑，填成就的坑。当我们填坑的时侯，我们和早餐时的猴子一样，开心满足，认为这些都是白来的；而等到晚餐时分，当我们面对自己的坑洞时，会痛苦不堪，又希望挖下一个坑来填现在这个。比猴子的故事更加可悲的是，生命并不如果子一样是个零和游戏。有些坑一旦被挖出来，需要10倍的力量去往回填——比如健康、自尊；而有一些坑则再也填不回来——比如说青葱的恋爱、孩子的10岁生日会、你生命里的任何一段重要时光。 填坑的人常常集中在25~35岁之间，这阶段人的角色暴增，从单一的工作者和儿女，慢慢地加入管理者、丈夫或妻子、儿媳妇或姑爷、爸爸或妈妈的角色，每一项角色的增加，都意味着全新的自我概念，也意味着新的成长的空洞。这个阶段的人有太多的东西需要生长出来。他们一旦乱了手脚，就会从其他地方挖出一个坑来，填满眼前这个。事业出问题，牺牲身体；身体出问题，拖累家庭；家庭修补好了，孩子又出事；孩子勉强搞定，工作又开始亮红灯……挖了填，填了挖，你的生命就像一个永远无法停工的城市道路施工现场，四处救火，步步惊心。 我们渴望成长而产生空洞，我们用非我的东西填洞，我们逐渐认为填充物才是真实的自己，现在它们开始反过来占据我们，真实的自己被我们丢了。这就是虚假自我的游戏脚本。当你把“成长空洞”换成“钱、爱情、关系、认同、自尊”，再填上年代时间地点姓名，就构成了这世间的各种悲剧故事。** 那天是你用一块红布，蒙住我双眼也蒙住了天。你问我看见了什么，我说我看见了幸福。这个感觉真让我舒服，它让我忘掉我没地儿住。——崔健《一块红布》 来玩一场“真我游戏” 友谊和纯净的心才是真正的魔力。象征外界的魔力被销毁，而自己从心里升起真正的魔力，这就是一个魔力失去后自己重新找回来的故事。 失去、痛苦、面对、追寻、重获，这就是所有成长的脚本。 给自己来场成人礼！ 你必须脱离他人的认同，置身于真正的孤独，独立完成艰巨的任务，你必须学会自己认同自己，与自己独处。 成长就是一个完整的失去、痛苦、面对、追寻、重获的成长脚本。 在我们今天的社会里基本没有真正的成年礼，家长像宝贝一样拽着我们，一直到自己实在拽不动为止。而很多孩子不仅物质上啃老，在精神上也从未断过奶。 你经济不独立，精神不独立，失去家人的认同，你连事情都做不了，你还好意思说自己成熟？你父母的判断非常正确，你的确不成熟，你空有独立之心，却从来没有长大到能践行你的思想。 有人说旅行有三种意义：看风景，发现可能，还有找回自己。最后那种，就是成年礼。 年轻的时候，不管是读书、游历、交友、搞对象还是读大学，野得越远越好，这种远不应该仅是地理上的，更是心理上和文化上的。我同情那些一出生就生活在最大最好的城市里，觉得这里最好哪里也不愿意去的孩子。他们从来不明白，长大在远方。 拥抱变化，走出舒适什么样的人永远不会成长？第一是自我概念已经和真实自我完全重合的，他们完满了。第二是虽然有成长的想法，但是不愿意冒险的人。他们怕疼，怕冒险，所以他们从来不愿意尝试自己不懂的事、玩自己不确定能赢的game（游戏）。他们先为自己玩不好的游戏找出各种理由，然后安心地躲在舒适区，只玩安全的游戏。 你会很容易发现人的惰性本质——人们总是愿意在把握程度高的事情上反复花时间，而在真正重要的事情上不用力。慢慢的，他们自己停止了成长，然后找几个借口把重要的事情敷衍过去。不冒险其实是最大的冒险。要持续舒服的最好方式是让自己不舒服。 空洞里的填充物离开，你失手、失败、被抛弃、被生活欺骗、被事情淹没。这时候，痛苦、羞愧、后悔百感交集，像在大广场被扒光了衣服一样尴尬。但成长者并不会着急用别的东西掩盖和填充。他知道痛苦不来自填充之物，而来自自己对成长的渴求。一旦填埋这些空洞，真实的需求就会被深埋。接纳自己此刻的空洞与无能，是成长为自我最重要的一步。 成长者允许痛苦发生，好奇地看到空洞的底部真实自我的袒露，他理解每个痛苦都源于强烈的成长需要。最好的方法是努力让自己从底部向上生长，把这个洞填满。自我成长者总是能够读出空洞背后的成长希望——他们知道，失落越大，空洞越大，背后的力量也就越强大。 你永远也不知道自己有多坚强、勇敢和努力。如果没有那段经历。 愤怒带出无能的空洞，也告诉我们需要提供能力。失恋带来无价值的空洞，也让我们需要努力爱自己。厌倦带来不新鲜的空洞，也提醒我们生命需要更多可能。正如每一次新生都伴随着母亲的痛苦，每一种痛苦都是新生的启示，你要学会读懂它。 见过孩子玩过家家游戏吗？他们全情投入，扮演老鹰的人不可一世，而扮演小鸡的人则吓得吱哇乱叫。他们知道要全力投入，要努力获胜，才能享受这个游戏。但是等到游戏结束，他们又嘻嘻哈哈地在一起，完全看不出老鹰小鸡的区别，他们知道，游戏的目的是为了“好玩”。 **我们的关注点便从麻木的、患得患失的虚假自己，变成了真实的、慢慢成长的自己；我们计量自我价值的方式，也就从物质、成就和他人评价，转变为自己的成就感、充实以及学到的东西；当我们的立足点从不可捉摸的外界和他人观点，变成了稳定宁静的成长需求，当我们自己不立于流沙之上，就能看到实情——什么时候你该更投入，什么时候你可以撤回来。当成长比成功更重要、过程比结果更重要、价值比价格更重要时，你就拥有了看透却不看破的心态。 这种转变创造出一种更大的格局和智慧：以入世的心态来玩，却以出世的心态来发现价值。这格局孕育着更大的成长速度，成功是成长，失败也成长。** 期待我们幸福，又懂得用自己的方式寻找自己的幸福；当我们看到一个洞出现，我们不着急在其他地方挖一个洞填上，而是找到生命的重心，寻求平衡稳定。 马斯洛不是也说吗，人生的巅峰体验来自“成长的过程中牵涉到自我与环境的配合……是‘内在需求’与‘外在需求’一致、‘我想要’及‘我必须’之间的协调。唯有如此，你才能自由自在、快快乐乐、全心全意地拥抱自己的志向。你的命运就是自己的选择及意愿。 当我们说一个人的内心强大，就是指这种永远能站在真实自我之上，对于痛苦强大的洞见和选择，在不确定的结果背后确定的价值汲取能力。 真我游戏的修炼者终生在自己的道上修习这种能力，他们在任何情境中，都能收获自己想要的价值。 这样的人在顺境中成长，在逆境中也能成长；在富足的时候幸福，在困苦的时候也幸福； 亚当夏娃的价值观童话 单反穷三代，苹果毁一生 记得彼此尊重。死亡是人类最好的礼物，当生命有了限度，每个人的价值就会浮现。 马斯洛需求高管会 我到底希望做一家什么企业？如果要做这样的企业，这家企业最核心的竞争力是什么？对比现在，我最缺什么？ 一个清晰的价值观，能让你重新管理你的需求，重新掌控自己的人生。因为自我概念决定了你的空洞，所以当你决定你希望成为什么样的人的时候，你就确定了什么对你的生命有“价值”、什么是“值得”做的；当很多事情都值得做的时候，你必须选出“最值得的”，这就是你的“价值观”。有了价值观，你就找到了成长为自己的样子的最佳路径。 价值观——给生活来点定见！ 春雨老师的价值观就是买手机吗？当然不是，他的价值观是新奇。“新奇”是一种抽象的目标，新手机是这个价值观在现实世界的具体目标。具体目标会随着你的行动和环境改变。如果春雨生在非洲大陆原始部落，就会满脑子琢磨怎么搞一只火烈鸟春天生出的最新鸟蛋。 他的“价值观”马上就会改变——在那里，钱不值一文。 价值观来自对内心感受的评价，没有对错，只有真实与否 社会流行的价值观。有的高尚点变成了“道德”，有的有地域“风俗”；有的很重要，被强制执行，叫作“法律”，你和小伙伴之间定的叫“规矩”，还有些三天两头变，叫作“流行”。 当你开始学会自己认同自己，他人认同也就没有那么重要了。所以特立独行的人只有两种：内心强大到不需要认同，或者自卑到认为大家都不可能认同。当然，做前者好些。 一旦了解了价值观与情绪的关系，你就能明白为什么符合价值观的东西会成为你的核心发动机——来自情绪的动力比来自理智的动力强大一万倍。回顾一下你的赖床经历就能明白，如果你“不想起来”，你的大脑就会飞转，给自己找到千百种理由继续赖着。但是如果你有一件“特别想去干”的事，你根本就睡不着，清早醒来，绝尘而去。 我翻译的《适合比成功更重要》中提到，价值观（value）来自拉丁文词根valeo，意思是“坚强起来”。当你找到真正有价值的事情，任何胆小的人都会坚强起来。即使看似温驯的小动物，也会在保护幼崽的时候变得强大无比；胆小的人在遇到自己坚守的事情时会变得坚忍强大。为什么伟大的公司必须有伟大的价值观？因为伟大之路障碍重重，非坚硬的价值观不能破。所以该走哪条路才能成功？走你“最坚硬的一面”的路。 一旦一个人习惯于集体主义的环境，他们就很难区分“道德”和“价值观”，因为在他们看来两者是完全一致的，单一价值观和极端集体主义都会狠狠修理任何与道德观不同的价值观，一直到大家都老实为止——这个时候，“对的”就是“你应该”的，你应该的，为什么你还不做？ 比如许多中年人，当他们认定一件事情是“对”的，就会持续地要求你去做，并且对你的不作为感到发自内心的诧异和困惑——既然是“对”的，你怎么可能“不愿意”呢？ 仔细听他们说话，你就会发现他们的逻辑，先努力在脑中找到一个道德原则，让自己先爬到高处，然后转身以此要求你——如果不听话，就受“这是不对的！”的道德折磨、良心审判吧！比如我父母想有个小孩子玩，就绝不会说我想玩小孩，你快给我生一个，而是从“不孝有三，无后为大”，或者“让爷爷在有生之年四代同堂”，或者“我们的朋友都说30岁以后生孩子对身体不好”开始。 我从来不希望我父母改变，没有被烦到的时候，甚至还觉得好玩。因为他们也是受害者。在小时候，别人就是这样要求他们的；而当他们长大，他们也是在内心这样战战兢兢、如履薄冰地审判自己。道德是个好东西——但他们是被道德绑架的人。 价值观就是“什么是重要的”和“这些东西之间有什么关系”的观念 什么比什么更重要？到底是“精彩的生活”还是“助人”重要？每个人都有自己的观念。这就是“什么是重要的”。 到底是“智慧”有了，就会有“自由”，还是只要足够“自由”，就会产生“智慧”？“安全感”和“精彩的生活”是冲突的吗？有人说年轻要努力赚钱，老了才自由，还有些人说年少要游历，别总想着赚钱，到底谁是对的？关于生活，每个人也都有自己的想法，这就是“它们有什么关系”。 这种关于“价值”的“观念”，感悟、形成、冲突又汇聚，最后慢慢稳定下来，形成你的稳定的价值观，也就是你对生活的“定见”。 She is not Rachel.（她不是瑞秋。） 剧集会结束，红颜会老去，而生活中的真实关系，会面临比电视剧中更复杂、更琐碎的麻烦，只有最坚硬的价值观才能抵御。 “冒险是人类精神皇冠上最伟大最闪烁的一颗宝石”，但我们还是不敢冒险。 压了葫芦浮了瓢，哪壶不开提哪壶。生活是个系统工程：如果过于钻牛角尖，往往就会忽略现实的其他因素；但如果过于散焦，又会牵绊太多，什么都得不到。这时候就要探讨价值之间有什么关系。最高效率实现的价值观系统，就是最好的价值观系统。 想宽些，要生一个孩子，除了钱，还需要什么？思考之下不难理解，还需要身体、心情、出国时机，甚至是父母亲的身体状况等。想深一步，要生一个孩子是为了实现自己什么价值？追求的也许是自己心目中的“社会认同”“内心和谐”。这个价值观系统如下图： 西谚“小心你的梦想实现”就是这个意思——实现了却发现这并非梦想，比无法实现梦想更加可怕。 人要活得明白、活得清爽，掂量得出好歹，就需要反复打磨自己的价值观系统。 阅历阅历，第一需要经历，第二需要审阅。前者只能自己使劲，生涯规划师则可以加速后者，帮你照镜子，帮你更快地了解自己，不需要栽太多跟头。 重要性让你按照你认为的这些价值的重要程度排列：有什么是不可或缺的？有什么是没那么重要的？哪些即使不太满足也能生活？哪些是一旦抽离就会让生命大楼坍塌的？保护好最重要的，找机会做次重要的。 从价值观来看，真实比伟大更重要。太极拳经云：守正出奇。一旦重要性确认了，我们就能找到生活的重心，一旦守住了重心，其他部分的价值缺失，即使摇摇晃晃，也能回来。 就算会有一天/没人与我合唱/至少在我的心中/还有个尚未崩坏的地方——五月天 舒适的生活：一种充足丰富的生活家庭安全：家人的身体、精神安全自由：独立与自由地做选择健康：身体和心理健康家庭安全：家人的身体、精神安全健康：身体和心理健康快乐：一种享受和闲暇的生活自尊：自我尊重成就感：持续地有所成就智慧：对生命的成熟洞见 你心中无数次预演这个情景——你推开键盘，冲着老板大吼一声：要加班，毋宁死！但当你听到背后有脚步声、屏幕上有身影闪过，就马上转过身去堆起笑脸说：“老大您来啦，我这儿正忙着哪。”当看到自己的价值观与别人不一样的时候，我们开始焦虑，偷偷地调整自己的价值排序。这种人其实有一个最深藏的核心价值——你把“认同”排在第一位。 一旦把“获得大家认同”的价值观放到首位，就等于你把“永远随着别人的要求来委屈自己”作为生命的必然脚本，而你如果决定出演这么一场戏，你死得一点都不冤。 8. 为什么你总不知道自己要什么？ 完美主义你有一个虚幻的价值观叫“完美”。你希望“既可以要到这个，又可以保持那个”“既学好，又不难”“既可以获得，又不用付出”。 一个选择了“完美”的人，就是选择了“不损失”的人，背后真正的价值其实是“安全感”。因为值得去的地方永无捷径，困难重重，所以这种人也就是间接选择了“不可能”或者“累死你”的人。 面对问题—安全—求完美—纠结不选择—拖延—事情变糟糕（要么就是必须选一个，要么就是两个都选不上了）—自卑—更不安全 安全感是重要的价值观，但是完美并不指向“安全”——因为所有的完美都是减出来的，而不是加出来的。不用取舍的完美不是一种目标，而是一种幻觉——即使生命真的有完美存在，那也是在做出巨大的付出和牺牲之后留下的东西。 只要这样，本身就是价值。 1000万—大房子—对老婆有交代—不上班看书—智慧不孝有三，无后为大。你只有早点生孩子才算孝顺！（生孩子—孝顺—认同）没有事业的男人叫什么男人？（事业—男人？）劳斯莱斯，成功人士的选择。（名车—成功—有能力）你上这么个二流学校，都不好意思跟人说！（学校—社会地位）在北京收入至少要一万二，才有可能活得像个人样！（钱—舒适生活）钻石恒久远，一颗永流传。（钻石—爱情）办了健身卡，你就能有健康的体魄。（服务—健康）爱她，就请她吃哈根达斯。（冰激凌—爱情） 比如父母对你说：“成绩真好！真是我的好孩子！”你强化的就是“成绩认同”。这样的孩子会努力在各方面做到最优秀而期待认同，想象一下他们在不以成绩定对错的职场、感情中感到的无助——他们努力提高成绩，却发现并无认同；他们甚至不知道该提高哪些方面来获取认同——他们越努力就越远离。 社会也在反复地给我们输入各种价值观链接，比如深深链接在我们内心深处的农业社会的乡土价值观“房子—安全感”，再比如在商业文化冲击下形成的“有钱—幸福”的价值链。这些链接如街道纵横交错，变成我们心中的世界地图。 这些价值观系统在我们生命中，有意、无意、善意、恶意地被传达、固化，并无数次被强化，就像分子的结构组合，在我们生命中慢慢地固定，形成 我们对世界的看法（世界观）以及如何应对的心智模式（人生观）。 如果缺乏有意识的觉察，我们不仅不会主宰自己的人生，反过来还会被这些地图主宰，带到沟里去。可悲的是，我们还一直以为那是自己想要的。 如果我们把过去的路标认为是唯一的通途，通还好，一旦不通，人生就会越走越窄。 我们需要明白路标并非终点，目标并非目的，月亮并非手指。我们可以走不同的路，达到最终的目的。 成为智慧的人，除了在家里看书，还有很多很多方式。一个追求智慧的人，在生活的任何空隙都能找到智慧；他也能意识到，除了买座大房子之外，还有很多方式让太太满意。最后他也许会发现，智慧之路其实并不遥远，生活和工作中有各种通往智慧的路：可以在下班路上坚持听自己喜欢的有声书；可以空出陪客户喝酒的一天时间去附近大学蹭课；可以和太太做一次深谈，发现她最需要的其实是多陪陪她……他可以在这样的宁静和充实之下，慢慢地成为一个智慧的人。而且有这种心态的人，赚到1000万的概率也会大很多吧。 真的高手，总在城市的任何角落，找到回家的路。 9. 假如你迷失了梦想的路但在真正的生活中，为什么人们总是只看到手指呢？甚至骑单车去。当找到手指背后的月亮，然后从月亮往回看，你会发现条条大路通罗马。生活的高手最常用的招数，就是“价值探戈”。探戈你没跳过也一定见过，先后退一步，站稳重心，然后找到节奏向前走一步。还记得前面谈到的价值链吗？比如“钱—幸福”“房子—安全感”“公务员—稳定”“早结婚—父母安心”。当你想达成的目标暂时无力达成，不妨在价值链上后退一步，想清楚自己到底要什么，然后再找到可以实现的方式，向前一步。 成功是一个重要的人生目标，但是如果你找到“世俗成功”背后指向的“成就感”和“幸福”，你将意识到，成功的经历带来成果，而失败的经历带来智慧，不管成功与否，都不要因此丢掉自己的幸福感。 生活如城市的街道，街道不会欺骗你，只是你自己会迷路，忘记为什么出发。当洞见了目标与目的、路标与终点、手指与月亮的关系，别忘了在绝境时跳这曲探戈——我们每个人都能在或丰满或干瘪的现实里面，吮吸幸福，找到自己的人生价值。 10. 生活高手的价值探戈什么是生活的高手？真正的生活的高手掌握着这种技能——让自己在任何资源和方式中，都能吸吮到自己想要的价值。这是一种生活的修炼，有了这种技能，你就能随时活得幸福。 越是生活的高手，他们越能找到各种通往价值的幸福之路，而这条幸福之路越不依赖外物，就越容易到达终点。没有可能，他们就用资源创造可能；没有资源，他们就把自己当作资源；即使一切都没有，他们依然可以选择面对苦难的态度。 而所谓强大的内心，就拥有这样一种技能，这种精神正如沙漠里盛开的花朵，它们无法选择自己播种的地方，于是深深地把根插入干涸的土地，吸取每一分养料。热爱生命的人，也应该有这种勇气、智慧和技术。 晚年的奥黛丽·赫本说：物质越丰裕，我要的越少；许多人想登上月球，我却想多看看树。 I Went to the Woods——（美）亨利·戴维·梭罗I went to the woodsbecause I wanted to live deliberately.I wanted to live deepand suck out all the marrow of life！To put to rout all that was not life…and not，when I came to die，discover that I had not lived. 我步入丛林，因为我希望认真地活。我希望活得深刻，吸吮生命中所有的精髓！把非生命的一切全都击溃，以免，当生命终结，我却发现自己从未活过。 定见的修炼 明白了，当我明白我要不成荷塘其实是因为我要了电影，心里就舒服多了。这就是知足吧。永跃若有所悟。知足常乐。这就是舍得之乐。舍得：吃饭＞电影＞荷塘 不完美的 完美，平衡之乐。 付出：疯狂付出，换回来所有——吃饭+电影+荷塘 价值观冲突只有三条途径：舍得、平衡和付出。如果你既不愿意放弃，又要完美，还不愿意付出，那就只好等待奇迹出现——对此奇迹也表示很无奈。 什么是好的选择？付出自己最能付出的，换回来自己最重要的，就是好的选择。 生活中只有一种英雄主义，那就是在认清生活真相之后依然热爱生活。——罗曼·罗兰 梦想与他人的期待冲突怎么办？ 我把那些指向你的目标价值的建议，称为“给我的建议”，把那些其实是指向别人的目标价值的建议称为“他对你的期待”。你甚至可以将其简化为“他建议我”和“他期待我”。 当我们涉世未深时，大部分人会坚信别人的建议就一定是毫无私心的“给我的建议”，所以当发现背后还有“他期待我”的时候，我们会愤怒失望，觉得被欺骗和背叛了。慢慢的，我们习惯了，却又偏向另外一边——我们认为别人的建议一定另有其意，不会那么简单。 其实大部分情况下，别人的建议都带有“他建议我”和“他期待我”的因素，一旦想到我们自己都经常驾驭着欲望干点傻事，你就可以对别人的动机释然了。关键是接下来你对待这些建议的态度。 事实上，我们不可能同时满足所有人的要求，最后的方案只能是谁闹得更厉害、谁的声音更大，我们就听谁的。在不同人的期望和建议中，我们疲于奔命。这深深伤害了你最好的朋友——“你自己”。当别人打着“为你好”的旗号伤害“你自己”这个朋友的时候，你不仅不让他躲开，还按住他说：“别还手，这都是自己人。 不管你要对爸爸妈妈、亲亲爱爱，还是小强小明好，第一步都是照顾好自己，因为这一切都是通过“你自己”来实现的——一个伤心的母亲不可能教育出快乐的孩子，一个无奈哀叹的女子不可能带来家庭幸福，一个不幸福的上司也不可能带给下属幸福——一个对自己都不好的人，难道还期待他们对你比对自己好吗？ 叛逆和成熟最大的区别，在于前者并无主见，让往东偏往西，让往南则往北；成熟者则内心有定见，如果你说往西，他会继续往东，而如果你说往东，他仍继续往东。 13. 谢谢你，但我有更重要的事情要做生活的智慧能让我们游刃有余——不是每个期待都需要被满足：我们可以接纳他人的期待，但并不一定要满足它们。 生命不长，你会遇到很多很多的期待，但是能够满足的只有不多的几个，你会把谁的、哪些期待排在前面？我喜欢美国心理协会会长塞利格曼（Seligman）的说法，他认为人生只有两个时期，一个是扩张期，一个是收缩期。他这样描述一个人从第一时期进入第二时期的转变：“你慢慢发现，你接触过的事物、你所爱的人，并非达成任何目标的手段，而是以这些事物本身为目的。你对那些新鲜、疯狂的事情不再感兴趣，你离别人的期望越来越远。” 谢谢，这很好，但是我有更重要的事情要做。 14. 成长为自己的样子正如我们在真我假我游戏中说的那样，找到的迟早会丢掉。自己的样子不是“找到”的，而是“生长”出来的。这种对于自己想要的生命的坚定想法，我称之为“定见”。 你是否也有过这样的经历？你曾梦到过你想要的生活，你曾见过自己的梦想在别人身上实现。这一切打动了你，也打开了你的幻想之门。你有那么一瞬间，那么清晰地确定过自己的渴望……但是当你从幻想中清醒过来时，你沮丧地发现，那只是一个梦，而你只是一个距离目标很远的人。别沮丧，那是定见的第一层修炼——体验。我们需要在生活中遇到自己的价值代表，然后体验它。 定见的第二层修炼：确认。 一个人总在推动身边的人去做某事，其实那是他内心未竟的愿望，他只是暂时缺乏勇气自己主张——但是当爸爸问他要去哪里时，他会说：“我要去……卖面条。”阿宝爱他的父亲，不想让父亲失望，几分钟后，他背上那愚蠢的面条车，出发去看神龙武士。 就像阿宝一样，当我们对生活有了自己的见解，却没有勇气公开表达，我们就遇到了定见的第三层修炼——主张。当你知道自己想要什么时，面对那些渴望的眼睛，你敢公开主张吗？你敢向父母主张自己的生活吗？你敢向领导主张自己的观点吗？你敢向同伴主张自己的与众不同之处吗？又或者，当与众不同成为一种潮流，你敢主张自己的平凡吗？主张是我们定见修炼的重要一关，决定我们是成为一个心怀不满、内在分裂的人，还是成为一个愿意尝试、身心如一的人。 在你第一次主张之后，命运之轮开始转动。在你第一次主张之后，压力与斗争也随之而来。害怕冲突的懦弱的人，无法前行。 定见的最后阶段——践行。阿宝也想过放弃，他曾半夜逃下山未果，曾想过与父亲一起逃难，但是最后他依然坚持下来，成为自己希望成为的样子。践行这个阶段的最大困难是——我们总在等待一个救世主出现，其实到了最后，我们发现，从来就没有救世主——我们必须亲身践行自己的生活选择。正如特蕾莎修女所说：“不要等待谁来带领你，先独自去做吧，从一个人到另一个人。” 体验、确认、主张与践行带来我们的定见。 我们总羡慕英雄横空出世、内心坚定，可我们真的不知道一个人曾经要多么在意，才会显得毫不在意。定见意味着一次次地发现、确认、主张、践行，生命不息，修炼不止。没有人会说做自己是一件简单的事，但是每个走过的人都说真的值。 成长，长成为自己的样子。 守住自己的底线 请记得向对的方向迈一步，因为当你开始迈出这一步，这个世界的光明就变得大了一些，当越来越多的人迈出这一步，世界就会变得越来越好。而如果每个人都在这时候躲一步，世界就会变得越来越黑暗。 自我概念与真实自我之间有成长空洞，这空洞产生了需求； 虚假自我的游戏总是失去—填充—假我—失去，而真实自我的游戏是失去—接纳—追寻—获得；价值观是关于人生什么是“重要的”“值得的”的观念。它包括“什么最重要”和“它们有什么关系”。价值观的修炼在于：发现自己的需求，理解这些需求，选择自己的生活方向，并在实际生活中体验、检验和践行这种选择，形成对人生的定见，并且修炼出在任何情况下都能获取人生价值的能力。 外一篇：这世界有普世价值吗？ 分配者和回应者都需要面对自利和追求公平的权衡，他们都需要在内心回答一个问题——你愿意损失多少私利来追求公平？ 无数证据说明，我们渴望获利，但是我们同时也渴望公平，人类并不是被自私占据的种族。 研究结果显示，同卵双胞胎不管是作为分配者还是回应者，都有显著的相关性，而异卵双胞胎则没有显示出相关性。换言之，对公平的诉求，深深根植于人类的基因之中。 人类文明的六种共同美德 知识、技能与才干——能力全息图 能力也是一样。当我们看到了高手的能力的全貌，我们会大大加快自己能力的提升速度，成为顶尖的高手。 知识：我们知道和理解的东西，广度和深度是评价标准。技能：我们能操作和完成的技术，熟练程度是评价标准。才干：我们无意识使用的技能、品质和特质。有强烈的个人特色，无评价标准。 知识：生涯理论基础、多年积累的案例、大量的阅读技能：写作能力、分析与综合能力、概念化能力、数据收集、沟通能力（如和插图画手）才干：好奇心、幽默感、求真 不同的人其风格千差万别：如果你写作能力强，你文章的阅读快感就强一点；如果你逻辑能力强，你的文章就精练一点；如果你数据收集能力强，你的文章就会有一堆好例子；如果你优势在于沟通能力，插图画手能彻底领悟你的意图，插图就会好看一点。这些技能每个人都在认真练习，也都能学得差不多。但是才干层面则完全不同，王鹏的实用主义、赵昂的洞察力、老马的犀利、春雨的文艺、我的嬉皮笑脸，这些风格我们谁也置换不了，因为我们从小就开始练习啦。 如何炼成某一领域的高手？ 只要你的搜索技术好，基本上大部分知识是廉价甚至免费的。其次，搜索技术改变了知识存储的方式，人们只要记得关键词，知道在哪里找就好。最后，这个年代的人面对太多全新的问题，相关的知识也不断更新，以至于无法知道哪些是被验证过的、哪些是扯淡。这就需要我们有独立思考的能力。这个年代，知识的差距转向了能力的较量——搜索能力、好奇心、独立思考能力——谁能在同样的知识海洋中学得更快、更多、更精准，谁就容易获胜。 拐个弯，谈谈中国式英语教学的问题，他们把英语当成一种知识来教——你清晰地知道［θ］是从喉咙发出的气流通过上颌冲出唇齿之间摩擦发出的清辅音，但是你不一定能发得标准。你可以对虚拟语气的12种可能了如指掌，但还是无法脱口而出：如果我是你，我死了算了（If I were you，I would rather die）。 语言是技能，而不是知识。知识能学到，而技能只能习得。 知识学习是瞬间的，知道与不知道之间几乎可以瞬间转变。技能则需要漫长的笨拙期——如果你不接受自己笨拙的开始，你永远也不会学好任何技能。也正因为这面心智之墙，很多知识优胜者死死不愿走入技能的练习领域。这也是为什么“好学生”往往不如“坏学生”混得好的原因——“混社会”是门技能啊。 明星有“明星感”，老师有“个人魅力”，商业决策者有“精准的直觉”，一流的运动员有特殊的“节奏”，好的员工有天生的“责任心”，这些不一定是“天赋”，而是经过大量技能练习后，才干与天赋交融的体现。人家是练出来的。 才干如此“自动自发，习焉不察”，以至于很多人从来不知 剑招—剑术—剑意对应到职业生涯里面来，就是“知识—技能—才干”。这么短的时间里，“如何出剑”的知识和“出得熟练”的技能，显然不可能马上掌握，只有传递“剑意”才能成功。而才干的核心，就是自动自发、无知有能，所以“剑招”忘记得越干净越好。 上乘武功的才干一致，技能相通，只是知识略有不同。正如当你站在17楼往下看，你就一定会比楼下的人明白，去某个公交站怎么走。当你在某一个领域做到顶尖，你就会很容易掌握另一个领域的知识和技能，在外人看来，就是一通百通了。 真正的高手，就是这样炼成的。 只有结合了生涯和写作的技能，才干才能外化出职业能力——才干才有了被识别的价值。 如果你只是希望通过找到天赋少付出些努力来超车，你就根本没有资格谈天赋。 好不容易炼出来的专业浪费了怎么办？ 知识是最没有迁移能力的，即使你读到了医科博士，也照样不一定会做麻婆豆腐，隔行如隔山，说的是知识的差距。 但是到了技能层面，事情就变得不一样了。大部分职业技能都由70%的通用技能（如运营、执行、营销、沟通、管理）和30%的专业技能组成。你完全可以把以前学到的技能迁移到新的工作里使用，再加上新学习的技能，工作就能迅速上手。职业与职业之间并无太大的差距。 而到了才干层面，职业之间的界限完全被打破。不仅是职业的界限，工作中培养的才干会蔓延到你生活中的每一个方面，你不想使用都不行。 彼得·德鲁克在《管理的实践》中说，他认真地研究了当时（20世纪50年代）大学中所开设的课程，发现其中只有两门对培养管理者最有帮助——短篇小说写作与诗歌鉴赏。诗歌帮助一个学生用感性的、富有想象力的方式去影响他人，而短篇小说的写作则培养对人及人际的入微体察。诗歌和领导力、写作和管理，虽然知识和技能都相去甚远，但在才干上高度一致。 这门学科带给我理科生的思考框架、工科生的实用观——这让我在研究生涯的时候，一方面不会太文艺（我已经够文艺的了），能区分科学和忽悠；一方面很注意实用的技术，我宁愿设计一个简单能用的模型，也不愿复杂得谁都不明白。 我的MBTI（迈尔斯—布里格斯个性类型测量表）老师一直好奇我作为一个ENFP（外向、直觉、情感、感知，一种人格测试的术语，简单来说就是“伟大的激发者+著名的不靠谱者”），为什么对细节、字号、颜色、字体有那么多设计要求。她认为这和我的人格不符。我会告诉她，这是我在一个格子间里每天改12小时设计图，就因为一个破字号或者线条就需要重新返工练出来的吗？估计就是在那时，我人格分裂了，一个说：“我要做伟大的激发者！”一个说：“别瞎想，图又来啦，你还是靠谱点吧！” 《星际争霸》是使神族的吗？什么时候防守，什么时候进攻，什么时候攀科技树，什么时候开分基地（公司），都有规律。当下即道场，把经历炼成才干带走，怎么会浪费？ 职场的技能迁移策略 “如果我努力做好现在的工作，把能力炼得很好，可万一这不是我要的工作，那怎么办？”“如果你努力做好现在的工作，赚到了钱，万一这不是你要的工作，那怎么办？”我反问。“那我就带着钱走，换下一份工作呗。”“能力也一样。”我告诉他。 你到底适合哪一棵树呢？你总得做几次模考，才知道考试大概能考多少分；你得玩几局，才知道自己适合玩哪个英雄，是不是？职场这棵树也是这样——枝繁叶茂，你站在下面，永远只能看到上面几米的风景——如果你不试着爬一爬，你永远也不知道自己适合哪棵树，即使你在树下做再多的测评、看再多的帖子，也不行。很多人都在树下等待一个最好的答案，等到某一天被当年的同龄人的“猿粪”砸到，才追悔莫及。 如果不试着爬几米，你永远也不知道自己适合哪棵树。一旦你开始决定爬几步，那个问题又开始浮现出来：万一我跑到树顶，发现不是自己的树，那我岂不是在浪费时间？ 我们可以很容易地从一个行业转入另外一个行业，而不需要从头来过，这个技术就是：技能迁移。 以前一维到头的工作观可以改变——只要你懂得技能迁移，就可以从一个貌似完全没有关系的领域，一步步迁移到自己喜欢的目标职业。 横跨七个完全不同的行业，一点点积累自己的能力，从一个贫民窟的小男孩，到演员协会的会长、《GE剧场》的主持人，继而到州长和美国总统。我想你也猜到了，他是美国年龄最大的总统——里根，在他70岁成为总统的那一瞬间，没有人知道他走过了漫长的迁移之路。 六次转行成总统——技能迁移之神里根 —因为他是电影人中的军人，也是军人中最懂得电影的人 里根用以前的各种经历和技能组合出自己独特的政治魅力：穷孩子、电台节目解说员、电影演员、电视节目主持 找到自己最有可能进入的领域，在其中积累新的能力，在恰当的时候迁移到“更适合”的新的工作中去，通过不断地修炼、迁移和组合，找到你最适合的领域，同时也就拥有了你独特的竞争力。 里根不是一个天资过人的人，作为播音员，他不算太出名；作为演员，他的演技三流；作为主持人，他后来被《GE剧场》主动放弃；而作为政治家，甚至连盟国的首脑也认为他智商不高，知识有限。撒切尔夫人1986年在英国会见他之后曾评论道：“在他的两耳之间空无一物。”（指他没有脑子。）他不是一个拿着一手好牌的天才，但是他把这手牌打到了极致。 功不唐捐卡梅隆——《阿凡达》为什么这么牛 “功不唐捐”出自《法华经》。意思是：你付出的努力和功德，从来不会白白地付出，终有一天，会回到你身上来。胡适先生给人题字，除了喜欢写“为者常成，行者常至”，另一个就是“功不唐捐”。 所谓功不唐捐，就是努力地做好每件小事，回头发现自己无意中做了件大事 《真实的谎言》，片中他成立的“数字领域”特技公司第一次在片中小试牛刀。还从给特技人员画受力分析图，解释大船沉没原理，到为杰克画素描。“外界的质疑声一直是成就卡梅隆电影帝国的基础。 有人去山里寻找灵感，有人与人交谈寻找灵感，卡梅隆这种找灵感的方式，伟大而疯狂，让人望尘莫及。在安静的海底，他注视着泰坦尼克号的残骸，杰克和罗丝的爱情故事如海草般慢慢浮上来。 《深渊》+《终结者Ⅱ》+《真实的谎言》=《泰坦尼克号》《泰坦尼克号》+之前的所有积累=《阿凡达》 卡梅隆也摸索出自己的导演风格：不用著名演员，把所有钱都花在特效上。《泰坦尼克号》中的两位主演莱昂纳多·迪卡普里奥和凯特·温斯莱特虽年少成名，但也不是商业巨星。而《阿凡达》里的澳大利亚人萨姆·沃辛顿，更是陌生脸孔，一般人闻所未闻。 12岁 写科幻小说，被认为是《深渊》的原型14岁 看到电影《2001太空漫游》而迷上科幻电影，开始尝试拍短片17岁 上大学读物理系，然后辍学23岁 看到电影《星球大战》，决定从事电影制作26岁 为《星球大战》《杀出银河系》等影片制作模型与特技27岁 导演《食人鱼Ⅱ：繁殖》 什么都不想，全力把眼前的事情做好，做到更好，做到极致的好，然后总有一天会有回报。 或者回报也不重要——当你全心投入，这过程就值回票价，回报只是个惊喜。越是在遥远的未来，你越会发现当年所有的功夫都没有白费。不知道什么时候，以前的经历就派上了用场。这就是功不唐捐。 等待一个确定的机会才开始投入的人，机会永远等不及你。卡梅隆的工作方式，就是 把当下当道场，在任何时候做到极致，看似最笨，往往却是最聪明的 洋葱、萝卜和西红柿，不相信世界上有南瓜这种东西。他们认为那是一种空想，南瓜不说话，只是默默地成长。——舒比格《当世界年纪还小的时候》 新喜剧之王黄渤 一个人要达到高峰，需要做多少准备，走多长的路，承担多久的不理解——如果你每一步都希望听到掌声，那么也许你只能永远在自己舒服的小天地玩。只有那些敢于走得更远的人，才知道自己到底有可能到哪儿。 如果你是一个依靠别人评价而活的人，你从理想中获得的痛苦远远比快乐要多。因为大众往往不寻求品位，也看不到成长，只是寻求刺激，他们夸或者踩你，并不意味着他们真的有什么坚持的观点和品位，他们评价仅仅是为了排遣自己的寂寞。当他们发现下一个目标，就会集体奔腾而去，你的光荣和耻辱都不值一文。 一朵花开需要一个春天，而其间有多少人路过会停下来，又笑着摇摇头。Bob Dylan 其实每个人都是这样，你最大的优势不在于你的学校、学历和专业。你的优势在于你的生活、生长、受的教育、朋友、世界观，还在于你对待周遭世界的认真程度。真正优秀的人，会认真做好每一件事情——因为他们知道即使老板不为认真发工资，未来也必会给认真发工资。 不想当飞行员的程序员不是好老师 人生过往的经历好像散落的珍珠，而机会好像一条线，把所有的可能性穿了起来。这并不是命运的神奇，因为这神奇的命运其实是他努力而就的。我想赞颂的是他的韧性，一个人在没有看到线的时候，依然能够好好地孕育珍珠，才能够在线出现的时候，有东西可以穿。 因为你知道，所谓功不唐捐，就是如果你不知道未来要去哪里，最好的方法就是把手头事情做到最好，因为现在，连接着未来。 三种未来职场的核心竞争力 未来10年的中国，人们需要学会新的能力发展策略，因为未来的20年，中国的职业将会面临前所未有的变动：① 互联网、移动互联网带来的全球化和全国化。② 中国的人口红利消失，从中国制造变为中国创造。③ 中国经济腾飞，从Made in China（中国制造）到Made for China（为中国制造），这也意味着全球化竞争的开始。在未来的20年里，依靠行业、学历、专业、企业、地域的职业资源和能力会慢慢减弱；改变越来越快，成功与失败都会更快；人们越来越开始为自己的职业生涯负责，每个人都需要学会新的能力策略。 终生学习未来10年会是一个职业和职业需求都迅速变化的年代。先把学历读到无比高，然后一辈子靠这个混的策略早就过时了。未来的职业发展大概以3~5年为一个阶段，每个阶段之间需要系统地重新学习新的领域。在职培训、证书与学历教育将会成为常事，间隔年的旅行和学习会成为潮流。企业也会逐渐在内部建立学习中心甚至企业大学，同时送有潜质的员工出去学习。 欢迎来到终生学习的年代。 播放器不能识别WMA或者MP4格式的文件，你就必须用一个转码软件转码，电脑才能读出这段视频。 同样的道理，很多人的职业发展不顺，不是因为能力不强，而是不知道如何把过去的能力和资源“转码”出来，让新的东家能读懂。以家庭妇女重返职场为例，很多女性生完孩子，重回职场，都面临尴尬的局面：过去的职位不太喜欢，或不再适合职场妈妈；新的职业看上去门槛很高，自己缺乏专业能力；离开职场的两年间，社会发生了很大变化，觉得自己跟不上节奏，于是只好不甘心地重回家庭。 起床喂次奶，没睡过一个好觉，孩子走路前你需要时时刻刻抱着，练就一双汉子般的臂膀，这是不是“高度责任心”？有没有磨练你的“耐心和毅力”？ 从20岁就开始了，一生坚持了70多年。当所有领域的感悟迁移到管理领域，被翻译为管理学的专业术语，彼得·德鲁克的文字就变得更有历史纵深感，成为当之无愧的管理学大师。 最后，总结一下从生涯规划来看的能力观： &gt; 能力三核：能力由知识、技能和才干三者组成。知识无法迁移，技能能在大部分职业中迁移，而才干则贯穿人的所有部分。越高度提纯，越内化。 把知识炼成技能，使技能内化为才干。一通百通。 功不唐捐，连点成线。正是因为能力可以迁移，我们没有必要找到最终boss（首领）才开始修炼能力。最佳的策略是在每个阶段都全力投入，提高能力，遇到新的挑战再重新整合。 未来的三大能力策略：学习、整合与翻译。 扎克伯格的成功之道：修炼内职业生涯 除了技术，好的创业者需要人的部分——更深刻地理解他的未来用户：最精英的一群年轻人需要些什么？真正理解人们的需求，需要和他们泡在一起、混在一起，甚至成为其中一员——哈佛大学的学生宿舍恰恰给了他这个机会。 超过10年的成功的互联网产品开发经验微软95万年薪的offer（纳贤帖）名校人脉（Harvardconnection让他手上有近七成的哈佛学生资料）两次创业“失败”经历（被关闭的Facemash和退出的Harvardconnection） 我们很容易看到一个人外功（外职业生涯）的飞跃——拿出某个成果、职位升迁、成功上市，却很难看到内功（内职业生涯）的发展——他从哪里积累到的知识、如何识别机会、怎样获取资源……我们被闪亮的红色高度线闪瞎了眼睛，却看不见灰色苦涩的深度线。 从内外生涯的关系，你能看出成功的某些规律——红色的外职业生涯有两个特点： 跳跃前进：外职业生涯的上升是跳跃性的r型，往往是一鸣惊人，八方震惊。看上去得来全不费功夫。 迭代效用：这意味着成功最慢的是前面几步，越到后面，资源越密集，发展越快。这两者结合起来使得成功人士的履历（外职业生涯线）往往很容易给人飞黄腾达、连升三级的感觉。 而内功（内职业生涯）则恰恰相反： 稳重潜行：内职业生涯呈现U型，这意味着在上升之前，需要经历一个漫长的积累期，才有可能跃升一个台阶。这期间需回想一下你听广播练听力，第一周没有提升，第二周没有提升，第三周还没有提升，很多人就此放弃，认为自己“没有英语细胞”；而有些人不小心坚持到第四周，突然有一天早上，发现自己很多词语“不知不觉”地听懂了！真正的英语学习者都有这样的经历，坚持很久，突然上了一台阶。你不是没有英语细胞，而是不懂得生涯发展的规律。 演讲、太极、咨询、冥想、看财报……大部分内职业生涯的高手，都体会过这种漫长的平台期后，突然跃升的快乐。 大部分的“成功学”故事只会告诉你这个人遇到什么机遇，不告诉你为什么机遇只垂青他；只告诉你他有多激扬潇洒，不告诉你他有多厚重坚实；只告诉你他收获多少，不告诉你他付出更多——一种可能是，如果告诉你，你就不上他的课了，这过程可真比“努力就能成功”难一万倍，也不好玩一万倍！另一种可能是他们也把自己催眠了，无法透过闪闪发光的外职业生涯线，看到背后那条真正坚实有力的内职业生涯线。 好东西就是聪明人下的笨功夫 才捕捉到了给电梯旁边加上一块LED屏幕的创意。从想到到说服商家花了半年时间，从群雄割据到统一市场，又用了三年。“……世界上最可怕的两个词，一个叫执着，一个叫认真。认真的人改变自己，执着的人改变命运。” 职业生涯的成功犹如熔岩，在地下奔腾积累多时，一朝爆发，于是无可匹敌。而我们往往只看到别人走到山顶，在地上挖个洞，就火山爆发了。能不浮躁？ 只有他们才知道，需要多么努力，才能显得毫不费力。 职业生涯的内功与外功 内职业是外职业的前提，内职业生涯带动外职业生涯 要有多努力，才能显得毫不费力 企业按照小强的职位，给他一个难度为10分的任务，由于小强的内职业发展快于外职业生涯，他能做到12分。企业尝到甜头，于是尝试给他20分的任务（外职业生涯上升），而他的能力发展到可以回馈24分，于是企业决定给他一个50分难度的职位。 而小明的外职业生涯比内职业发展得要快。当企业也给他一个10分的任务时，他觉得自己的能力被低估了，他应该做一些更大的事情，于是他心不在焉地做出来8分。企业看到10分的难度做不到，于是主动下调到6分，小明彻底觉得自己被愚弄了，于是回报4分。最后企业只好给他4分的职位了。 希望得到明确的职场目标和许诺才开始学习，这种“不主动”是职场新人常犯的毛病。无论是职业还是商业，都是一门先给后得的艺术，而越是大的跃升，需要给的就越多；越是完美的商业模式，就需要越长的回报。这需要源源不断的内职业发展来支持。 首先，内职业生涯需要外职业生涯的指导。只有定期了解企业和行业需要什么样的人，才有可能方向正确地培养自己的内功。其次，内职业生涯的套现往往会吸引来很多资源，而资源会重新导入内职业生涯，形成下一轮的职业发展高潮。 较好的状态是，内职业生涯保持超前外职业生涯一步，这样的状态最舒心。内职业生涯超前一大段时，你会容易出现职业倦怠，比较虐心，觉得无趣，打不起精神，觉得没有价值感。 努力就一定有回报吗？ 如果你是一个真诚、勇敢同时又有一定阅历的人，你一定无法回避这个事实：我们这个世界，不是一个公平的世界。 这个社会有很多资源稀缺，且分配不公。这些资源有的可以通过努力获得，比如说眼界、工资、能力；有一些需要几代人的努力，比如说更好的教育、平台、名声、地位；还有一些则完全无法通过后天的努力弥补，如天赋、体质和机遇。 如果你是一个真诚、勇敢同时又有一定阅历的人，你会清晰地意识到，如果人生是一场长跑，我们就是站在不同的起跑线、穿着不同的鞋的人——有人打赤脚，有人穿回力到最新款耐克跑鞋，还有人甚至根本不跑，而是开着法拉利——向着不同的终点奔跑。 正如在操场上跑圈，当你第一圈超过前面那个看起来比你健壮得多的男生，你千万不要窃喜。你不是比他强，只是比他的起步线靠前一点。他已经跑了15圈，这是他最后一圈的冲刺。而后面那个看起来文弱的女生像小鹿一样轻松地点着地滑过你，你也不要沮丧——她出身体育世家，六岁开始田径训练，每天以你想象不到的毅力跑10公里，至今已经12年啦。 还是安心算你的圈，跑你的步吧。 贫富由什么决定？ 《我花了18年，才能和你在一起喝咖啡》。 无论是他们的商学院知识、斗志、商业模式，还是精英思维，都无法让他们抵御穷困起跑线带来的绝望。今天如果你把那些成功人士拉到社会底层，也许有三分之一的人永远无法回到原位，还有三分之一的人甚至不及他看不上的穷人。富贵靠什么？努力只占一小部分，命运比努力要重要得多。 请尊敬你身边的穷人们，他们也许不比你懒惰，不比你无能，仅仅是因为命运的安排而活得不如你光鲜。如果你陷入过命运的深渊，你也一定能体会他们的绝望。 你以为我矮小、卑微、不美，我就没有心、没有灵魂吗？…… 如果上帝给我点美貌和一些财富，我也会让你难以离开我，就像我现在难以离开你一样。我不是凭借习俗、常规，甚至也不是肉体在这里与你对话——我凭借我的灵魂与你的灵魂对话。就像有一天我们死去，一同站在上帝面前，彼此平等，就像我们原本那样。 幸福，没那么贵 巨大财富背后的巨大好运 除了顶级成功者们自身的努力，他们还有一个共同点——他们幸运地在恰当的时候，遇见一个前所未有的经济发展高潮，抓住了自己的机会。 第一，恰逢一个百年不遇的经济高增长时期。第二，他们都在增长的关键行业（大陆的互联网和台湾的电子、香港的地产），抓住了一个机会。第三，他们当时基本都在27~40岁之间，而且在这个关键领域已有一段时间创业积累——等你看到机会再开始往往就跟不上了。 从生涯的角度看，27~35岁是人们开始创业的最好时机——此时人的智力、社会视野和眼界慢慢成熟，人脉也渐广，同时还没有太多的家庭和思想负担，正好可以开始。一旦过了这个时机，不是负担太重，就是害怕失败，很多人宁愿做职业经理人。 如果第二条“在关键行业抓到关键机会”考的是后天的眼力的话，第一条和第三条则有很大幸运成分在——谁也无法独立掀起大潮，而谁又能管得住自己的年龄？ 他们恰好在百年不遇的经济腾飞时期（天时）、在合适的行业（地利）、在最合适的年龄（人和）做好了准备，才成就了他们幸运的财富传奇。这让我想起中国一句古话： 生死有命，富贵在天。 只要努力，定有小成，但是极端的贫穷和富有很大程度由机遇决定，成功路上的竞争，并不公平。 成功可以复制，可没法粘贴啊 在每一个人生的十字路口，我们都会遇到这样的情况——我们像站在任何一个城乡接合部的车站，这里停着无数快载满人的车，在每一辆车上，都站着一个人在卖力兜售：快上快上，马上走了！这个时候，你会上哪一辆车？到底哪一辆车，是你的命运终点？ 《小马过河》的老故事吗？小马希望过河又不敢，老马建议他问问朋友们。老黄牛说河流很浅，过河就是a piece of cake（小菜一碟）；小松鼠说河水深不可测，有去无回。小马困惑了……回去问妈妈。 老马鼓励小马自己试试看——当然老马自己走过，知道那条河不至于把她亲儿淹死——最后小马成功渡河，并且理解到： 别人的建议，总是别人的。主意只能你自己“生成”一个。 当你安装上建议翻译器，你会发现他们每一个人都希望你“好”，之所以建议不同，是因为他们对“好”的标准完全不同，因为他们本身就是不一样的人啊。就像那些拉你上车的长途汽车售票员，他们每个人都希望你坐上他们自己的车，这天经地义。问题是：你自己想去什么地方？ 每个人对“靓仔”的评价标准不同，其实大家对“好”和“幸福”的标准也各异。二姨觉得“少走弯路”是好，发小儿认为“精彩的生命”是好，室友认为“更多的可能”是好，而父母则认为“家庭和谐”是好。所以虽然每个人都很真诚，但他们都在说“如果我是你，我会……”的建议。这些建议都没有问题，而志明之所以困惑，背后真正的问题是：我到底是谁？我想要什么？ 志明和你们每一个人一样，都是独特的。你们有自己独特的人生意义，有独特的能力、天赋和独特的思考方式（上帝保佑你真的有），对未来也有各自不同的期待，你们还有独特的能力和资源，能创造与其他人不同的自己的生活。 每个渴望成为独立个体的人，都需要创建自己的定见——一开始肯定没有，那么就多收集各路信息，小范围地试试错，先上一辆最想上的车，舒服就坐下去，不舒服尽快下车，然后回到车站，这次你的选择一定会更加精准——定见不诞生于别人的建议之中，而是在自己一次次的试错里。我们不是“找”到自己的样子，而是“成长”为自己的样子。 什么？你问，如果是我，我会如何回答？ 我也有自己的定见。我会说，如果我是你，我会尽快开始尝试一下。因为如果不尝试，我们永远也不知道前路是否适合。我痛恨像傻子一样站在路口等待答案，期待某一天会出现大师般的人告诉我该如何，我也痛恨某一天我随便上了一辆车，仅仅是因为那一瞬间有人声音很大，而我又恰巧寂寞难耐。 &gt;●所有的建议都是“如果我是你……”的建议；●你的人生方向是你自己“找”出来的，不是听回来的；●你得知道自己想要什么，至少你应该开始试着去知道。 如何再造一个乔布斯？ 乔布斯的才干，从他不可复制的生活经历中打磨出来。 什么叫才干？在“能力”一章里我们提到其定义：“个人所展现的自发而持久的并能产生效益的思维、感觉或行为模式。”才干常用来形容人的个性、品质和特征，它对职业业绩优秀有很大的贡献，在生活和工作中被无意识地使用。 看到自己很自然地在上课前走到陌生的学生堆里面去聊天，看到自己蹲下来听某个人说话，看到自己舒服地坐在咨询椅上，对面的来询者逐渐放松下来……我深深地意识到我真的有“亲和力”的才干。而我竟然20多年对此一无所知！ 与其说乔布斯改变了世界，不如说是世界选择了让乔布斯发动这个改变。 他生活在20世纪60年代的硅谷，这让他与世界上最伟大的IT领袖成为朋友或者敌人。他的导师是甲骨文公司的拉里·埃里森，他的敌人是IBM和微软的比尔·盖茨，先友后敌的是百事可乐CEO史考利和Google的拉里·佩齐…… 一个人伟大，往往不仅因为他的经历，更因为他的伙伴、他的对手，还有他的时代。 伟大从来都是天时地利人和交集的东西。 在20年前，商界人士无法想象：一个百年的化工公司竟在10年内被数码产品商打败，手机厂商则在10年之内逐渐取代数码产品，而一个硬件厂商在五年内动摇世界份额第一的手机厂商。这个世界变化越来越快，而且不可预测。 再回观苹果，它现在面临几大强敌——做搜索引擎的Google、做手机的三星（以及中国市场的小米），还有做电子书的Kindle。乔布斯改变了世界，他猜到了开头，却没有猜到结尾——这个世界改变得比他想象的快多了。 我也不知道，崔健说：“不是我不明白，是这世界变化快。” 如果只剩第一名，其他人的机会在哪里？第二名的机会在于与第一名完全不同，第三名的机会也许在于服务比较好，而其他人的机会则在于更细分的市场，或者让那些无法取代的、针对个体的服务或咨询必须出现。这是我看到的趋势，也是新精英现在努力的方向。 回到关于复制成功的主题，即使两个一模一样的人，也无法通过模仿对方获得成功，因为这个时代变化太快。那些当年让你成功的因素，也许会让你在10年后的社会惨败。 大部分人的耀眼成功，都是汇聚了天时地利人和。即使他本尊亲临，也无法复盘。不管如何努力，再造一个乔布斯的计划，一定会全盘失败。 如果有人问围棋大师，哪一步是你下出的最好一步？大师也只能摇头无语——最好的一步只有在那盘棋局中才能显现，脱离棋局去说“最好”毫无意义。成功人士的巨大成功，也许就是那个年代的棋局里最好的一步。 你与成功者经历不同、内在才干不同，最后即使你能搞定前两者，能让你成功的环境和时代也早已改变。所以成功无法复制。齐白石说“学我者生，似我者死”，就是这个意思。这个世界上只有一种方式一定不能成功，那就是模仿别人的成功。 成功的道理，追忆起来头头是道，面对未来如履薄冰。 成功漏斗模型——成功人士看不见 第一，打篮球不光是投篮，重要的是要跑位；第二，不要朝球的位置跑，要朝传球的方向跑。 职业生涯规划多年，我深深理解这个道理。尤其对于“体力”不好的职场新人，不要向现在的职业最高点方向走，要向未来的职业方向走；不要做现在能兑换价值的事情，要做未来能兑换价值的事情。一个职业经理人，如果没有生存问题，30岁前，不要想着赚钱，而是要赚本钱。 刚进入职场，体力和能力不是最强时，记得向传球的方向跑。也许对行业趋势的分析能帮你看到前景。如果你期待更大的成功，则需要看到更大的格局与趋势，耐心下一盘更大的棋。 趋势与机会到处都有，但是如果你只是看到，就仅仅是观众。而决定参与和投身其中，则需要极强的判断力。二者差异巨大，看到趋势那叫视力，而投入趋势，才叫眼光。 看到趋势，决定参与，就一定能够成功？其实也不一定，你还需要拥有参与的能力与才干。就好比当年三国，天下大乱，各地枭雄辈出，谁都知道赢了就是皇帝，但是又有几个人能够剑锋所指、人心所向？曹操把着天子，孙权占着江东，刘备流着皇叔血统，这都是才干与资源。 比错过趋势更加闹心的，是看到趋势却发现自己完全插不上手——以此献给刚刚进入职场，忙于思考公司战略、时代机遇、商业模式、定位等的职场新人，当我们眼光越来越高，手越来越低的时候，我们会慢慢变成一只长颈鹿。 也以此提醒“吸引力法则”的盲从者，我觉得比吸引不到机会更闹心的情况是，机会吸引来了，你却Hold（把控）不住。我觉得吸引力法则的真意应该是，如果要吸引外界，先吸引自己。 总之，需要拥有能力，你才能成为竞争者，而不是观众。 1/70，这也许就是机遇和坚持最好的注脚。 成功者 正如右图所示，从漏斗底部向上看，你能总结的就是：“我看到了一个趋势，然后就坚持一直走下去，最后成功了。”或者说得再文艺一些，“发现心中热爱，坚持追随，不要放弃，就是成功”。 这于你是实话，你看到了趋势（时代机遇），且心中热爱（兴趣匹配），然后一直坚持（有达到生存底线的能力与才干，并且不断提升），不言放弃——长生才能救世——一直到有一天，你遇到了机遇。 但是如果你走回去看看，会发现很多发现趋势、内心热爱却缺乏能力资源的人，只沦为了观众（为考公务员又被刷下来的人们默哀一下吧）。很多看到趋势、拥有才干却在竞争中被刷下来的人，成了炮灰（中国中小企业的平均寿命是2.97年）。还有一些死在最后一关的人，他们也许比成功者坚持得更久，却还是没有等到机遇，他们没有成为先驱，反成先烈，音容宛在（还记得大明湖畔的团购网站吗？）。坚持与努力是成功的必要条件，但成功的条件有很多，有时候，还需要一点点幸运。 上帝开的努力银行 踏实前行型：原来成功与能力不完全相关——成功不能证明你真的有价值，当龙卷风袭来，猪都会飞；不成功也不能证明你很糟糕，那只是下一个故事的开始——关键是走在路上的状态。我们慢慢明白，成功就是用自己的节奏越走越近。 我最喜欢的是创造型：既然我们处于一个全新的时代，有着与众不同的才干，拥有一个能够改变的未来，为什么我们不创造一个自己喜欢的成功故事？从那些传奇的成功故事中汲取属于自己的智慧，在全新的世界，搭建一个有无穷可能的未来。就是这些现实的理想主义者，在慢慢改变世界。 行文至此，我想对职业的成功做一个总结：&gt; 努力必有收获。小付出小收获，大努力至少定有小成； 成功=眼光+能力+坚持，巨大的成功=成功+机遇； 内职业生涯发展是外职业生涯发展之源； 通过生涯的学习，掌握规划、技能迁移、竞争力组合等手段，可以加快成功； 求快不配做高手； 有个叫上帝的人，他开了一家努力银行。每个人都有一个自己名下的努力账户。每个人每天都在往里面存自己的努力。有的人存得多，有的人存得少。有人存了第二天就取，有的人则在很多年以后一次性取出来。 努力银行上帝在干什么呢？上帝要保证每个人账目公平，不能有错账。上帝还要标注那些存努力存得最多的金卡客户，给他们分配更多的回报。上帝很忙很忙。但事实总是这样，总是那么几个最努力的人有最多的回报，这工作也太不好玩啦。所以每隔10年，上帝就调出所有的金卡客户，抽一次奖，然后随机把一个巨大的成功分给中奖的那个幸运的家伙。所以，宝宝，只要努力，就会有合理的回报。而那些巨大的成功，往往来自幸运——但是请先确定，你努力地拿到了金卡。 你的人生有什么可能？我们的生命有多少维度，有什么可能？ 人生的四种方向：高度、深度、宽度和温度 我的生涯 高度：问问自己：我能否热衷于成为一个对于世界、群体、组织或家庭有重要与深远影响的人？我能开创或管理多么伟大的组织或公司？我能多大程度地用自己的方式改变世界？生涯高度是一个外显的维度，我们可以通过 社会地位、财富收入、名声与权力大小判断一个人的生涯高度。 生涯的第二个发展维度：深度 终极价值：卓越与智慧传说雅典被罗马攻陷之日，两个士兵闯入阿基米德的房间，看见他在桌子前面整理几何手稿，他的最后一句话是：等等，让我算完这个算式。我相信这个关于阿基米德的故事。所有在深度路上的追寻者，一辈子都在用生命说这句话：等等，让我想明白这个问题。 生涯深度指的是人们 在思想、智慧、艺术与体能上达到的卓越与精进程度。 正如于丹解读的《论语》名气最大却不一定是最专业的，影响力最大的人，并不一定是最精通这一领域的人。生涯的另一个维度就此展开，生涯深度的追寻者们渴求真理、寻求极致、反复打磨，让自己炉火纯青，他们希望站在人类知识的顶峰、思考的极限边缘。 我的生涯深度：问问自己：你是否曾渴望在某一个领域达到最高的知识或技能水平？你是否对突破自己某方面的极限感到兴奋？你是否愿意在某一个专一的技术领域投入自己巨大的努力？生涯深度往往通过行业内的专业奖项评定。如学术界的学术地位、科学界的诺贝尔奖、新闻界的普利策奖、体育界的奥林匹克金牌等。 生涯的第三个发展维度：宽度终极价值：爱与和谐 有没有意识到，在更高和更深的两个维度之外，我们的生命还蕴藏着另一个维度：宽度。高度如攀山，越高位置越少；深度如挖洞，越深知音越少。而这个维度则会让我们从山上和洞里走出来，越走越宽，越来越多地与世界联系。 我的生涯宽度：问问自己：你是否渴望体验生命中更多的角色？你的各种角色是否都发展完整和成熟？你的各种角色之间是否平衡？1957—1990年，著名的美国生涯大师舒伯以生涯彩虹图表达了对终生生涯发展的见解，总结出人生最常见的八种角色：子女、学生、休闲者、公民、工作者、持家者等。舒伯指出：生涯的重要任务是帮助人们形成一个整合的、恰当的、清晰的自我概念。 不管怎样——特蕾莎修女人们经常是不讲道理的、没有逻辑的和以自我为中心的。不管怎样，你要原谅他们。即使你是友善的，人们可能还是会说你自私和动机不良。不管怎样，你还是要友善。当你功成名就，你会有一些虚假的朋友和一些真实的敌人。不管怎样，你还是要取得成功。即使你是诚实的和率直的，人们可能还是会欺骗你。不管怎样，你还是要诚实和率直。你多年来营造的东西，有人在一夜之间把它摧毁。不管怎样，你还是要去营造。如果你找到了平静和幸福，他们可能会嫉妒你。不管怎样，你还是要快乐。你今天做的善事，人们往往明天就会忘记。不管怎样，你还是要做善事。 即使把你最好的东西给了这个世界。也许这些东西永远都不够，不管怎样，把你最好的东西给这个世界。 即使把你最好的东西给了这个世界。也许这些东西永远都不够，不管怎样，把你最好的东西给这个世界。 生涯温度指的是我们对生命的热度，我们对生活有多大的热爱与激情，能多大程度活出自己本来的面目。生涯温度的追寻者们渴求自由，探索内在世界，追寻真实鲜活的生命状态，寻找自己存在的意义与天命。 这是生涯最内在的一个维度，是评判标准最个性化的一个维度，却也是与幸福相关度最紧密的一个维度。 我的生涯温度：你希望以怎样的激情与热度投入生活？你是否时常有“那就是我”的自我感？如果时间暂停三天，你做什么都能成功，你会做些什么？正是因为这个维度如此不容易察觉，所以很多人用其他三个维度来评价这个维度，比如说认为“功成名就”“优秀卓越”“儿孙满堂”等已然足够。他们认为，这样我们就“应该”温度很高了吧。其实温度就是温度，各人吃饭各人饱，自己温度自己掌握。 第二次的返场，杨丽萍最后一个走了出来，观众有节奏地鼓掌。那一瞬间，每个人都理解了她的想法。我联想到我上课的最后一天，一定会忍不住哭起来，因为为了这个讲台，我曾付出那么多，只有我自己知道，太不容易了。 但杨丽萍让我们所有人失望了。她轻轻鞠躬，就好像任何一次演出返场一样，利落地离开了。这谢幕超越之前的整场演出，成为我当晚印象最深的艺术。当所有人都恋恋不舍时，她挥一挥手，蹦跳着离开。追寻温度者，当自在如是。我们为她可惜，而在她看来，我们的可惜才是可惜的。有人把杨丽萍作为生涯不平衡的例子，这想法挺可笑；有人则说这是她为艺术做的牺牲，我觉得他们不懂。说杨丽萍热爱舞蹈都是亵渎，她就是舞蹈本身。这样的生命没什么不好，而且值得尊敬——她明白自己的人生路向，明白自己所为何来。她跳舞不为名利、不为权力，艺术顶峰也只是一个台阶，她踏在其上，向终极自由一个箭步冲去。 曾有人问登山家：“为什么要登山？”登山家的回答是：“因为山在那里。”“为什么你要这样生活？”“因为这是我的生活。”这也是一种选择。 你的生命有无限可能那么，我们的人生，到底有多少种可能？如你看到的那样，我们的生涯有四个维度，除了追寻 功成名就 之路，至少还有另外三个可能：追寻智慧、爱与关系和自由。人们陷入生涯困境，往往因为他们匆匆忙忙，却只能看到一个人生方向。当你看到立体的生命出现，而每一个维度又可以有自己的方式时，生命就有无限可能。 幸福的方式不止一种 这意味着虽然他们所处的环境、收入、社会地位千差万别，却各自都有让生涯变得幸福和有价值的可能。一个企业家、一个全职太太、一个工程师、一个老农，还有更多更多不同生活状态的人，他们对幸福定义的方式各自不同。当我们看到人生的方向有很多种时，我们都能在自己的道路上通过努力获得幸福。 你更尊敬哪一种人？ “我们可以从学历和工资层面知道两者的差别，但是这两个人为自己的生活所付出的努力和智慧，不会有明显的区别。那位老校工之所以是老校工，也许并非个人不够努力，而是生活的选择，或者错过了某个机会。而那位清华的教授，除了个人的努力和天赋，也许还有家庭的经济、教养环境和社会机遇的帮助。他们的职位无论高低，都受很多非自己的因素影响。我们不应该用职位的高低判断人格的高低。” 一个不好好讲课的教授，跟一个刚才认真擦黑板的校工相比，后者的生命更有价值。因为我们并没有能力选择自己生命的起点和终点，但是我们能够选择在路上以什么样的态度和姿势前进。” 此事震撼了杨澜，她回忆说：“诺贝尔奖也好，科学成就也好，社会承认也好，都不足以弥补他的失去和永远的心痛。如果我做节目，还停留在讲述人们所谓的成功故事层面的话，我们也就失去了对人性更深层的了解和体会，最终归于浅薄。”杨澜隐隐约约感觉到了生命其他维度的存在。 生涯不仅有高度，还有宽度。正如坐标系显示的一样，这两条轴线只在原点相交——即使再高的高度，也无法弥补任何一点宽度。它们本就是两个维度的东西。不识字的农民，还是诺贝尔奖得主？这是一个重大的选择。 机会的不公平、人生的不平等，但依然能找出自己的人生发展方向，活出自己最好的可能。我们尊敬这样的人。 你的人生模型是什么样的？ 比如在我们的文化中，男性的模型像个微冷的大金字塔——高度为主，兼顾宽度和深度，温度最次；而女性的模型则像一个温暖的圆抱枕——宽度第一，温度第二，深度和高度差不多就好。这也是为什么男人在高度宽度为主的职业，如政治、经济、商业、学术、专业技术等，能有更多优势；而女性会在温度和宽度方面，比如家庭关系、公益组织、助人、身心灵等方面，更有优势。 只有一个方向的人生就像一场考试——大家进入世界这个大教室，看一模一样的教材，然后参加同一场考试，等待一次又一次的判卷和排名。而四度的人生并不是这样。我常想，世界不应该这样，世界应该是一座大图书馆——早上一开馆，我们就欢呼雀跃地跑进去，找到自己最喜欢的一本书——你可以从头到尾地看完，也可以跳着选择不同的书，如果你有兴趣，还能自己写一本——这样的人生，才有无限可能。 人生最痛苦的事情，莫过于你内心选择了一条生涯之路，却非要绑架着自己走另一条路。大家越行越爽越开心，你越走越远越寂寞。你需要每天挥刀自宫——先努力灭掉自己内心的想法，再应付外界的俗事，很多努力才能换来一点点成功。心中苍凉，四顾孤独，大家还觉得你很不错。那种苍凉只有经历过的人才知道。 追寻高度的方式是竞争与超越。 追寻高度的人生正如登山，越往上走，视野越开阔，可能性越多，同时也能被越多人看到，影响与改变世界。但选择高度的同时，你也选择了高处不胜寒，选择了孤独和竞争。越往上走，能站的人越少。为了上到顶峰，你必须放弃很多。但顶峰永远只能站一个人，总有一天有人会把你踢下来。 追寻深度的方式是修炼与精进。 追寻深度的人生正如向下挖洞，专注一点，反复钻研，不断否认与超越自己，在苦修中超凡入胜。深度的挖掘使你的方向越来越聚焦，也越来越极致，但视野也越来越狭窄。追寻深度的生涯选择面很小，无法回头，一旦选择，唯一的突破方式就是前行，做到极致。相比追寻高度来说，追寻深度更容易名垂千古——只要你挖出来的路还有人走着，别人就不会忘记你。写《红楼梦》的曹雪芹你一定还记得，他的当朝皇帝是谁，你一定早忘了。 追寻温度的生涯是自燃式的绚丽。 按照温度的法则来生活的人，终其一生与开心人做快乐事，他们被自由与激情环绕，活得绚烂多姿。但温度追随者的风险也正在于此，追寻温度者过于自我，不容易有稳定的安全感与关系，而且因为太过挥霍生命，容易过早自燃殆尽。 一个人到了30多岁，就应该慢慢地意识和选择自己的生涯四度的排序，一旦这些维度确定，人生的格局和限制就都逐渐明晰起来。多看看不同的生活形态，接触些不同的人。有一些会让你惊叹，却觉得自己绝无可能；有一些会让你觉得：我就是要那样的生活。慢慢地，一些选择会离开你视野，另外一些则越来越清晰。这时，人生天命慢慢浮现，定见因而产生。 年轻的时候，你不愿意放弃成功，不希望在竞争中落败；在工作3~5年之后，你又必须面对专业还是管理方向的选择，你一开始绝不放手，认为自己两个都行，慢慢地你在专业和管理领域的往返跑中精疲力竭，决定选择一个投入；年近三十，你发现自己需要承担来自家庭和社会的期望和压力，父母在变老，孩子们在长大，他们都希望你是一个对家庭负责的人；等到这一切你都竭尽全力地做完，你却发现自己已心力交瘁，内心冰冷，生活也离你热爱的方向越来越远。 于是你准备为这么多年失落的自我做些什么，你开始让自己追随内心，做些以前不敢或者没有时间做的事情，但是一旦你开始行动，从另外三个维度传来的抱怨声就会此起彼伏，大家纷纷觉得你变了一个人，对你表示失望。你刚自我一点，却发现孩子的班主任开始找你；好不容易搞定这个，公司的项目又出现强力竞争者；你扑到工作中力挽狂澜，却发现身体早已吃不消，大病 不完美才是真人生 生命的本质就是不完美，生涯的总体能量守恒。 如果你要些什么，你就必须放弃些什么。如果你要得特别多，你就需要放弃特别多。这才是人生。 天才不仅需要天赋，还需要做严肃的人生选择。 为什么非要成功？ 喜欢一个完美的人或事物，不能叫欣赏力——因为傻子都会。欣赏是总能绕过对方的缺陷，看到真正美丽的部分。 所以他们注定是一群庸人。而曾国藩说“小人求全，君子守缺”，就是这个意思。 没有人能同时过上功成名就、智慧卓越、生活宽广，同时又自由自在的生活。既然历史的各路枭雄天才都无法幸免，我想你也不能。 惨胜如败的一维度成功 生涯四度中，高度和深度外显，而宽度和温度则内含。如果一个人看不到生涯的全貌，他就会下意识地用单一的、外显的维度来评价自己的人生，同时也通过牺牲其他维度的方式来达到所谓的“成功”。这就是一维度的伪成功。我们抽取今天这个社会里两群最“成功”的人——高考状元与亿万富翁，谈谈一维度的伪成功。 学科压力大、极度自负与自卑、生活障碍、健康不佳、学科专业不适合、缺乏创造力等从他们身上反映出来。有些学生读到了硕士，依然不会自己洗衣服，上街买东西受骗，无法与同学交流，生活依靠钟点工照顾。这样的人，从经历与心理韧性来说，都很难担当“青年科学家”的重任。 而这些能力为什么没有被培养出来？在和朋友打闹、成群结伙地晃荡在学校和家之间的路上时，我们学习到友谊，而他们在学习。当我们16岁第一次自己出门，被别人骗光了钱的时候，我们学习到社会，而他们在学习。当我们18岁第一次给心爱的女孩子写情书的时候，当我们在泡妞或者被妞泡的时候，我们学习到爱情，而他们也许还在学习。等到我们成年，凭以上这些能力开始展开我们的生涯，让我们的生命变成立体而非直线的时候，他们只会学习了。 “学生过早地被灌输这种竞技思想，而他们的文化积累、人生感悟都不够，加之他们所演奏的绝大多数作品都是西方钢琴音乐，导致他们很难理解这种非本民族的东西……比如弹巴赫的音乐，他们连教堂都没有去过，没有见过自然也谈不上感受，所以难以弹出地道的巴赫……学生本人未必喜欢钢琴，要么弹到最后自己都不知道来干吗了，要么就仅仅平添一种谋生的手段。” 音乐的深度，需要生涯的宽度与温度来滋养，世界上不存在一维度的成功。 **不管是“学而优则仕”“音乐竞技化”“有钱就是爷”，还是“我爸是李刚”，都是典型的“高度衡量一切”的一维思维。而放弃其他维度的发展，无疑让原来立体的生命变成一条直线——当成绩（高度）被寄予了拯救人生这种不可能完成的任务时，也就产生了两种变态：一是所有的努力都放到了一只篮子里，但这只篮子里只有少数胜利者，这让人焦虑；二是人们为了唯一的希望，不惜扭曲自己，搭上所有的精力，这让人压抑。 像一个胖子非要把两条腿都穿进牛仔裤的同一条裤腿一样，一维成功使人焦虑且压抑。** 当这些焦虑又压抑的人成为社会的中坚分子，你怎么能期望他们不搞突击应付领导检查，不牺牲尊严去赢得竞争，不放弃自己的梦想去追逐名利？那是他们唯一的可能了。 你用短跑的速度冲刺，结果在马拉松的前1000米超出老远，还向观众挥手，觉得自己很成功。你这不叫成功，叫“二”。 这些离开人世的亿万富翁中，我把“伏法”“他杀”和“疾病”算作一类：被剥夺游戏权利。出于过于自信或者身不由己，这类人通常曾经深深透支了其他维度：“伏法”的透支了法律道德，“他杀”的透支了伦理良心，“疾病”的透支了身心健康。出来混，总是要还的。当要还的时候，他们还不起了。 我把“自杀”算作第二类：自动放弃游戏权利。这些人知道自己无力偿还，选择了不玩。就像在QQ游戏上拿到一手烂牌，你直接选择拔网线一样。 最后的“意外”我则不知道该归于哪一类，暂且不提。 这些离开人世的富翁虽然在财富上成就惊人，却在其他方面亏欠很多，他们都曾大大地透支自己的生命——这些透支像是对信用卡的拙劣操作：他们在自己生涯的其他方面不断刷卡，反复取现——这的确让他们在短期之内成功过，成为众人眼中的“赢家”，却也在某一天“催款单”来临的时候，让他们无力支付。 家庭、事业、健康是企业家最重要的三大支柱；旅游、进修和慈善是企业家热衷的三大活动； 我们到底在“混”什么？我们又在用什么方式“还”？为了高度和成就，人生是否一定要放弃一些东西？如果答案是“是”的话，那么孤独和凄凉是否是成功者的唯一结局？如果“不是”的话，我们放弃的限度又在哪里？ 缺乏自我：在中国这个以交际为核心的商业环境中，商业的成功往往在酒桌与交际中完成。富豪们白天主内处理管理，晚上主外处理关系，回到家里还要处理家事。各种关系下，是各种角色的扮演需要。在我调查的14个企业总裁或董事长中，每周能够自己掌控的“自由时间”平均不超过四小时，在家吃饭平均0.8次。他们和自己相处的时间很少——从自己的温度账户里透支了太多快乐——很容易崩盘。 缺乏支持系统：成功者被赋予了“强大”的社会形象，内心自负。早期多有独立打拼的创业经验，早已习惯高处不胜寒的孤独，其中还包括一些问题因为灰色黄色绿色无法与外人道，这让他们遇到问题喜欢独自承受。这些问题日积月累，终于让他们觉得即使停下来也比现在温暖——那是怎样冰冷的一种决心。 我更希望通过这些分析形成一个思考：成就我们的高度的代价到底是什么？牺牲其他维度的成功，到底是收益，还是仅仅是转账？ 如果当初那些离开我们的亿万富翁在生涯的一开始，就知道和明白高度的代价，他们还会那样选择吗？他们会不会在高度和内心温度以及生活与家庭的决策中稍微犹豫一下，然后走上那条不那么光鲜，但是可能更卓越、更温暖、更自由的道路？ 他们永远不知道那些东西值多少钱。 一维度的成功往往是伪成功——只求“快”的激素猪肉损人健康，求“有效”的速成教育毁人心智，求“来钱”的豆腐渣工程夺人性命…… 小心那些只用成功做唯一生命价值标准的人，他们是把自己当成工具的自我恐怖主义者。他们一定不会犹豫在一个只看GDP的国家污染环境，在一瓶只检测氮含量的牛奶里投放工业原料，在一次只看利润的交易中不择手段，在一份只看钱的工作里出卖朋友，在一个让自己少奋斗10年的结婚对象前放弃爱情，培养出一个只看排名和学校的孩子。 管理你的生命质量 找到生命的重心 生涯四度中，高度和深度都是外显而可测的；而深度和温度则是内在的，难以量化。越是生涯价值低的人，往往越渴求外在的维度表达，而总体价值越高的人，则越寻求整体维度的平衡。 同样的心理让我们中的大部分人急于寻求外在的维度名片上更加吓人的头衔、更加光鲜的证书、更加拉风的车子，我们都在证明自己的高度和深度。追求这些维度并没什么不妥，但是当贪婪过界，我们就会忍不住从那些内显的维度中提取，这就是浮躁的来源。 我们被这些越来越“成功”的指标淹没，我们的生涯系统也在慢慢被摧毁、腐烂。这让我们更加焦虑——因为我们心中知道，我们穷得只有这个了。 平衡是生涯四度最好的解答，无数证据指出，平衡是一个系统价值最大化的体现。 我们都知道，生命和所有运动一样，每个人的平衡方式都不同，要找到平衡，就要先找到自己的重心。但如何找到生涯的重心？ 那个时候我们多大？按照30年一代估算，大概是30~50岁之间。那个时候我们最需要有的是“从容强大的心灵”“有自己的方向”“稳定的经济收入”，而这几项获得与否，又与你毕业后几年的努力相关。 所以，毕业后那几年，你越是为了孝敬父母，就越应该让自己有一个健康、持续发展的职业生涯。 在你的每一个生命阶段里，生涯每个维度都有自己的需求，关键是找到核心的那个。有人高度不足是因为深度积累不够，所以没有竞争力；有人则因为温度不足，无法维系宽度…… 在一个阶段内，总有一个生命维度，是改变生命的杠杆，生涯平衡点就在其后面。 我瞄准一个绿球，呼出一口气，推出一杆，说：“你这么一说，他好像的确没起什么作用。但是从那以后，我们家的每个人都更加信任彼此。年龄越大，我就越了解父亲的牺牲有多大。我们也就越知道彼此能为这个家付出些什么，这让我们家这么多年虽然有很多冲突，但是一直很幸福。” 一直到晚上临睡的时候，她才突然说：“我想起自己家里的很多事，我突然明白，原来我的家里，缺的就是这些没用的付出。”说完这句话，她哭了。高度在很多时候可以转化为宽度、温度，效果却不会马上显现，信任会作为账户储存起来在很多年以后，酿成美酒。而一件事情有用没用，也许只有时间与生命知道。 成功的游戏规则我在前面的章节里谈得很详细。职场的成功大概有自己的固定套路：角度—深度—高度—格局—机遇。 刚刚进入社会，找到一个好的切入角度：好公司、好项目或者好职位。这个时候千万不要寻求高度，因为此时没有积累，直接立起来肯定会断。慢慢积累自己的深度，让自己有力量、足够强壮，然后找个机会上位，也就有了高度。如果光有高度没有格局，很快这面旗帜就会倒下，因为立不稳。格局让你看到更多，向四面八方生出旁枝，让自己立稳。从电线杆到金字塔，到这个地步，人能做的事情也就差不多了，接下来就看天时地利是否能推起这座金字塔了。 《老马的职业“鬼”话》马华兴（“新精英”资深职业规划师的犀利职场观）《管理的常识》陈春花（中国人写的最简单、通俗又深刻的管理书） 看到高手不等于你能超过他，但是如果你没有看到，就连门都没有。一旦你看到你所在领域的高手，马上就能知道自己是否具有登上顶峰的资质；如果你能找到与你气质接近的高手，马上就能知道 自己该如何走上顶峰。看原典、听本人的课、找到行业内真正的牛人，是成为高手的必经之路。 《学习之道》维茨金 在职业规划咨询中，我要求即使是实习咨询师做公益咨询的时候，也要来询者为咨询师和自己付喝咖啡的费用。因为任何人都知道，一旦一次咨询需要付费（即使是一杯咖啡钱），就会让来询者有期待、让咨询师有压力，真正的成长则从此开始。 问题，当你可以讲个笑话就搪塞过去而不用解决问题，当你对大家说“我也不懂，就是分享一下”的时候，你就已经选择了一个平庸的对手，而你的能力也被限制了。下棋的人应该知道，和庸手下一辈子的棋，还是庸手。 《一万小时天才理论》科伊尔《异类》格拉德威尔 过乔峰的降龙十八掌，你不觉得，那是因为他上了太多武功“课程”吗？ 对照现实和理想的饼图，看看有什么因素妨碍了你的理想实现，想想可以做点什么让你的理想尽可能实现。 很多认识我的人都很诧异，像我这么瞎忙的人，要做管理、要讲课、要研发、要写作、要上课，还要减肥，居然可以每年出去旅游两次。 很早我就发现，宽度方面的时间，是软时间，即可以压缩的时间。关系可以处可以不处，旅游可以去可以不去，聚会可以有可以没有，爱好可以做可以不做，反正也没有绩效考核。长久下去，真的给你放三天假，你都不知道找谁去。所以越是软时间，越需要提前变硬一点。我会在每年年初的时候，以硬性的方式定下旅游时间，列入日历，并和团队提前沟通好，这个时间段对我很重要，多重要的事情都不要安排。如果你安排得够早，同时能让大家理解这件事情的重要性，你的时间就能有保证。唯一保护软时间的方法，就是比硬时间更硬。 谁更有效？孩子是最诚实的人。 能为我花钱并不珍贵，为我花精力才珍贵。 提升爱的能力现代人经常困惑的问题是：如果我就是放不下工作，我就是没有那么多精力，那该怎么办？如果你不能投入更多的资源，却希望获得更多的质量，你也许必须提高你的技能。是的。高度有技能，深度有技能，为什么宽度和温度没有技能？以前你需要花一小时才能让夫妻关系恢复，现在通过学习两性沟通，你能15分钟做好，这是不是技能？以前你需要花三小时才能让孩子听话，现在通过学习教练式辅导，你能用几个问题解决，这是不是技能？以前你要和父母待一天才慢慢开始融洽，现在你找到关键点，很快就能进入状态，这是不是技能？如果你想要时间更短，却收获更多，你就必须提高生活的技能。 在家里挂一幅可刮擦的世界地图，把去过的地方刮开，这可以鼓励我们走遍世界。给父母设立一个旅游基金，恐吓他们说如果这里面的钱今年不用完，明年就没啦。这都是我的生涯宽度管理技术。 下面是一些培育“亲子关系”、很受业内人士推荐的书：《好妈妈胜过好老师》尹建莉《喂故事书长大的孩子》汪培珽《孩子你慢慢来》《亲爱的安德烈》《目送》龙应台《正面管教》简·尼尔森《父母效能训练手册（PET）》戈登《孩子，把你的手给我》海姆·G.吉诺特如果你感兴趣，还可以了解一下家庭教育指导师这个职位。 《男人来自火星，女人来自金星》约翰·格雷（描述两性关系的很好的书）《爱的五种语言》盖瑞·查普曼（恋爱中的男女适合看）《为家庭疗伤》李维榕（上集比下集好看） 温度 找到至少一种让自己开心的方式有一次在企业家沙龙的分享聚会上，我问了一个问题：在座有多少人知道，怎么样让你的员工在三分钟内开心起来？ 下面几乎都举手了，这是领导力的表现。 有多少人知道自己的老婆孩子要些什么？怎么样让他们在三分钟内开心起来？下面的举手变得稀稀拉拉，好像插秧。我再问：有多少人知道自己需要些什么？怎么样能让自己在三分钟内开心起来？下面没有什么人敢举手了。这是不是我们的尴尬？我们有很多取悦别人的方法，却对如何让自己开心所知甚少。其实每个人都有让自己开心的方式。 与自己的约会：●设想你要去约见一个与你一模一样的人，你希望让他非常快乐和开心，你会做些什么安排？●把这件事情记录下来，安排到你的日程里去，告诉你身边的人自己要留出这个时间段。每天10~20分钟就好。●坚持两周，你的生涯温度就会上升。 ●可以从看感兴趣的经典书开始，建立一个系统的知识框架，然后再精细地深入一门学习，这样不容易走火入魔。●区别知识与技能，系统地学习，但拿到一个心理学硕士学位也许并不能帮你解决温度问题。体验式或互动式的课程，更加适合非专业人士。●正经的心理学和身心灵学习里，没有什么方法是对每个人都有效或者任何时候都有效的“终极法则”，每个人都有适合自己的方式，如果你觉得老师的方式不适合自己，不是你有问题，离开就好。●别太功利，如果你希望提高自己的温度，就别再给自己又制定一个目标。 《真实的幸福》《活出最乐观的自己》《认识自己，接纳自己》马丁·塞利格曼（经典积极心理学三部曲，大部分的理论都在里面了）《幸福多了40%》索尼娅·柳博米尔斯基（又一本被名字毁掉了的好书，记录了很多积极心理学的技巧与干货） 《遇见未知的自己》张德芬（都市灵性小说、灵性入门课） 刚开始的时候，突然看到了整个人生的系统，发现自己的很多缺失和各种可能，人生处于打开状态。修补某个维度或者扩张某个维度，往往会迅速地提高整体的幸福度。这个阶段是一个发现可能、找回平衡的过程。 成长的三个阶段第二个阶段是提高效能的过程。当人生重新找回平衡，我们要做的事情就是提高每一个方面的效能，让人生的整体价值最大化。这个时候，投入哪个维度的学习，就会提升哪个维度的效能。第三个阶段则是做重要的选择。效能提高终有极限，在不同维度往返跑也会越来越难，人生总需要做真正严肃的选择。如果你只能挑一个维度深入，你会选择哪个？ 人生需要做真正严肃的选择。梦想残酷且美丽，美丽是因为你在最希望的路上行走，残酷则是因为你因此放弃了那么多的可能。只有勇敢的人能做出这种选择。 好的生命，是有事做、有人爱、有问题可想、有选择的自由。 如何解决现实和理想的冲突？ 你不甘走现实的路，却又不敢走理想的路。所以真正的问题其实是：怎样从现在的现实，走到未来的现实？ 先冲入现实之路吧。在这里修炼，获得必要的锻炼、给养、技术、技巧；在做好储备、更好地了解自己之后，你可以开始寻 找两条路的交会之处。你在现实之路上走得越远，朋友越多，发现与梦想之路的交会也就越容易。 如果把生活比作一场球赛，适应现实等于防守，而坚持理想等于进攻。如果一个球队一直进攻却毫无防守之力，会死得绝惨。今天你也能看到那么多忙于适应生活却忘记梦想的人——他们一直防守，从不进攻，这些人为什么要踢球呢？ 我们为什么要工作？ 职业的本质，是一种通过满足他人或社会需求而自我生存、发展和实现的社会交换形式。简单来说，职业是通过满足他人需求来实现自我的社会交换方式。 职业中自我实现的方式是什么？什么是工作的意义？我们为什么要工作？ 工作是为了活出自我，实现自己对世界的价值。稻盛和夫在《活着》中认为工作即道场，工作的目的是“自我修炼”，为了让自己拥有“美好心灵、圆满人格和智慧”。李开复说“做最好的自己”，乔布斯说“活着就是为了改变世界”，都属于此列。 生存、被认同和自我实现，分别对应着职业发展的三个阶段——工作（job）、职业（career）、事业（calling）。 让我能生存，让我被认同和被尊敬，同时在其中实现自我和社会的价值。 梦想如此美好，现实如此残酷。人们要么追寻理想，为生存碰得头破血流；要么放弃梦想，一头跳入生活的浊流（反正大家都黑，谁也别嫌弃谁），沿着社会设定的道路行进，却发现自己早就忘记了出发的理由。慢慢地，我们会遇到人生最可悲的事：30岁的你早上起来站在浴室镜子前，挂着假模假样的微笑，发现自己变成了小时候最讨厌的那种人。 大部分老一辈中国人就是这么想的——职业是用来谋生的手段，所以他们的游戏规则特别简单——尽可能在职业期攒更多的钱，用很少的钱照顾好自己，然后转投到下一代的生存期，让自己不要成为儿女的负担，让儿女少吃点苦，多读点书，尽量度过生存期。 这种职业观也传承给我们身边的大部分人——他们努力地在工作中赚更多钱、走到更高的位置，同时学习更多精细的花钱方法，投资到孩子的教育中去，希望他们能画出更加好看的一条曲线。但是，仅此而已。 很少明白职业能承载更深层次的可能——发挥天赋、找到自己、理解和发现工作背后的意义 我们所处时代普遍存在的神经症……很多现代人所受的痛苦，不是源于临床观察而定义的神经症，而是源于他们对生活的麻木感和空虚感。——荣格 追寻工作的意义 我们不仅希望通过工作换取体面的生活、受人尊敬，我们还期待工作本身给我们带来意义和价值——能激发我们的热情与好奇，能发挥我们的天赋，能实现我们内心的价值，让我们在热爱的领域努力地玩，能让世界因为我们的存在有些不同。 21世纪最重要的一次职业的革命，就是在工作中，人们开始寻找意义。 对期望在工作中找到人生意义的人来说，一定要经营自己生涯的第三条线：事业线。但值得去的地方永无捷径，你需要经过“探索——投入——建立——进入”四个阶段。 你一直渴望的。你有一种鱼遇到水的感觉——这条线的成长速度，远远高于职业线。 进入期：慢慢地，有一天你会发现，你在事业线中获得的职业收益，已经达到生存线——这意味着你实现了职业自由——仅凭自己的理想工作，也可以生存了。这是人生的现实理想逆转点，是人生攻防的大逆转，是你个人商业模式的break event（逆转点）——你可以从此全力以赴地经营自己的梦想了。 你一直渴望的。你有一种鱼遇到水的感觉——这条线的成长速度，远远高于职业线。 进入期：慢慢地，有一天你会发现，你在事业线中获得的职业收益，已经达到生存线——这意味着你实现了职业自由——仅凭自己的理想工作，也可以生存了。这是人生的现实理想逆转点，是人生攻防的大逆转，是你个人商业模式的break event（逆转点）——你可以从此全力以赴地经营自己的梦想了。 生存期：生存线与职业线相交之前形成了第一个阶段——生存期。这个阶段的主要任务是生存，求职以能力为导向。发展期：生存期之后、职业自由点之前形成了第二个阶段——发展期。这个阶段的主要任务是在现实中获取更多的能力和资源，扩大视野，更深入地了解自己，为自我实现做准备。自我实现期：职业自由点之后。这个阶段的任务是全力奔向自己的天命。 鲁迅没开始写作之前，都在干吗？ 从职业生涯来说，鲁迅是个典型的冲动型规划的家伙——因为看到自己的父亲重病，他决定医治更多人，于是开始从医（很多人的大学专业都是这么选的吧）。在日本学医看到了一段中国人围观中国人被砍头的影片，又接触到哲学，引发他对国民性的思考，让他认为文字更能救国，于是他转投文艺（刚毕业的鲁迅却找不到和文学对口的职业）。公务员的14年生涯，帮助鲁迅慢慢积累了从事文艺的能力和平台，写作和教学都是呈现自己文字能力的方式。 蔡元培（此公是近代史奇人之一，给中国的教育和文化带来了巨变，也是鲁迅的超级大贵人），鲁迅开始创办自己的文学刊物《语丝》《萌芽》，写作和翻译成为他主要的工作内容。以今天的观念来看，他成为一个“自媒体”。两年后，他自由撰稿的收入，达到每月500圆（近50000元）以上。至此，鲁迅彻底实现经济自由。从生涯三阶段来看，他顺利地完全跨入事业维持期阶段。 当人们遇见天命，当兴趣、天赋、特质、渴望和时代需求最好地结合在一起时，会产生意想不到的巨大力量。 他既非从小立志成为救国英雄，也并非在斗争中活得清苦。鲁迅的生活不比我们大部分人差——换算成2012年的购买力，鲁迅从31~55岁共24年的职业生涯中，总收入约为1109万元，平均年薪为48.2万元，平均月薪4万元。这让鲁迅能有一个让自己体体面面、养活三口之家、有闲钱买书买古玩的生活。在这个基础之上，斗士鲁迅才能从心而发，真正战斗起来。 梦是好的；否则，钱是要紧的。钱这个字很难听，或者要被高尚的君子们所非笑，……凡承认饭需钱买，而以说钱为卑鄙者，倘能按一按他的胃，那里面怕总还有鱼肉没有消化完，须得饿他一天之后，再来听他发议论。……自由固不是钱所能买到的，但能够为钱而卖掉。——《鲁迅全集》第一集 先养活自己，照顾好家庭，然后慢慢地摸索自己生命的可能；这期间有成功，也有失败。鲁迅在46岁中年时渐入佳境，找到自我实现的最佳路径。一旦找到，则投入自己的全部生命。在文字上毫不妥协的他，在职业生涯发展中展现出来巨大的韧性，令人尊敬。 我尊敬穷困的理想主义者，但是搞理想不一定非要穷困。因为要找到一个生活稳定的理想主义者，远远比我一个穷困潦倒的绝地斗士，概率要大很多。 如说是梦想投机分子，梦想和自我实现只是他们的另外一种成功学。这种梦想投机分子，根本就不配谈梦想。 鲁迅的职业生涯故事还告诉我们，如果他在46岁才开始全心写作，依然能成为现代影响力最大的几个作家之一。如果从现在开始，把你喝咖啡和刷微博的时间省下来，我想你的梦想一定也来得及实现。 李开复的生涯三阶段：从职业线起跳 对理解生涯三阶段的人来说，李开复的跳槽其实是顺应职业发展的必然选择。职业生涯就像个人的生命一样，是一个不断发展和突破的过程。就好像孩子，该叛逆的时候要叛逆，该结婚的时候要结婚。每一个阶段都有自己的不同需求，这些不同需求没有必要非在同一个职位完成、同一个组织完成。一个希望拥有完整的职业生涯体验的人，往往会发生两到三次的巨大变动。理解职业人发展规律的公司，懂得提前为他们的员工设计自我实现的 路径，实现个人与社会的双赢。 今天的社会中，如果一个人在35岁之前，还没找到能发挥自己特长的领域，这个人的职业发展则相当堪忧。30岁以后，我们的体能开始下降，努力不会成为核心竞争力，只能通过经验胜过年轻人、通过才干和资源胜过同龄人、通过聚焦来胜过更强者。 如果你在前两个阶段职业生涯发展顺利，到了这个年纪，就要专业有专业、要人脉有人脉、要财力也有财力，你具有冲击职业顶峰的能力。 —其实所谓“道”，并不是地上画好的线条，而是你回首的时候自己踏出来的那条路。 2005年7月，他从微软跳到谷歌，惹上一场国际官司。同年九月《做最好的自己》一书出版。这两者相互借力，使他在青年人中的影响力提升到一个前所未有的高度。他在谷歌中国的工作定位也就顺其自然：公共关系和中国工程院的运营。 进入这个阶段，职业发展从关注外在成功的职业阶段（career），进入关注内在成功的事业阶段（calling），也就是我们说的道法自然——成长为自己的样子。什么叫“自然”？“然”是“……的样子”的意思，“自然”就是“自己的样子”。 这个生涯故事也完美地说明一个生涯三阶段的道理——发展好当前的职业生涯是自我实现的重要手段。从山顶起跳，好歹也能落在山腰上。如果你暂时找不到自己清晰的梦想，那么踏踏实实地做好现在这份职业，让自己努力向顶峰走去。在上山途中积累的所有一切都会在梦想出现时刻，转化成自我实现的力量。你的职业线画得越好，你就为你的梦想积累越多的“存款”，当你的事业线出现的那一刻，你就能越快地投入与开始。 职业发展的规律是：生存、定位、发展、自我实现。时间可以缩短，但是阶段无法跨越。每一个人都可以成为自己的传奇，只要你努力、机敏、坚持，而且敢于放弃。 跟周杰伦学习如何做屌丝 其一，完美的工作不是一下子就能获得的，需要长期技能的积累和经验的积累，如何渡过这个难关？先让自己生存下来是关键。其二，大部分学生毕业的时候，最需要补的不是专业技能，而是适应社会的心态。这堂心态课可以在任何工作里面学到，心态往往比能力更加重要。综上所述，毕业后最好的职业规划选择应该是：找一份自己能做的工作，培养自己适应社会的心态。同时注意培养进入理想工作的能力，把完美工作作为长期目标来努力。 完美的工作是从不完美的工作中开始的。 真正让吴宗宪感动的是这个年轻人对自己创作的认真程度。打动吴宗宪的，与其说是才气，不如说是认真。我的很多名企的咨询经验也告诉我：不管能力有多大，企业往往只选择那些认真对待自己工作的人，这本身是一种最重要的能力。 进入行业内的第一平台并展示自己。 每一个人进入职场的时候，都会遇到类似的问题。犯下大错、领导批评、不被人认同……学习犯错是职业发展期中最重要的部分：如何对待错误，比错误本身更加重要。没有被上司的讽刺打倒的周杰伦，反而用更多的努力征服了他的上司。胜利者不一定是总赢的人，能够接受打击，能够仔细反思自己的问题，能够更加积极地对待事业，才能取得最终的胜利——我们可以做错的事，不要做错的人。 越早开始者，往往越容易成功。 一种方式是先努力发展职业线，暂时放下梦想，找到别的生存支点，然后在职业发展稳定的情况下，慢慢切回梦想领域。如李开复、鲁迅这种完全自食其力的榜样，最靠谱； 第二种方式是找到个有实力支持你且认同你事业的人，帮你扛着生存线。如恩格斯之于马克思，如凡·高的弟弟提奥之于凡·高，如EB（Etienne Balsan）之于香奈儿。这种方式你既有惊天才华，又能遇到贵人相助； 最后一种是你家底丰厚，完全不存在生存期，可以直接从事业线入手。如爷爷是英国首相的哲学家罗素勋爵，如老爸是开唱片公司的歌手陈慧琳同学。这种情况，呵呵——你知道一下就好了。 但是为什么很多人即使有好职业、贵人相助或者丰厚的身家，却依然没能开始事业期？原因很简单——大部分的人，从来没有真正走出过生存期。 自由=能力-欲望 这意味着什么？意味着我有足够的经济实力和空闲时间来看书、弹琴、旅游、和有趣的人交往，能让我兴致起来就飞去某个城市见老友，能参加一场有点贵的音乐会，或者去美国参加个学术大会。意味着有一天，当“新精英”可以自运营时，我可以跑到国外读个和职业发展毫无关系的蓝调硕士、哲学博士。也意味着我可以不把“新精英”看成赚钱的工具，而真正做点有意思的事。在同龄人中，我的收入中等，但是我享有比大多数人更多的——自由。 能力的加法需要时日，而欲望的减法则快捷很多；如果能力暂时不足，至少我们能控制自己的欲望。我们称失去自由的人为“奴”，当你的欲望大于能力，你就成为了把自己套死的“奴”——刷的比赚的多，谓之“卡奴”；开着无力承担的车，谓之“车奴”；住在需要45岁前全力以赴才能还清房贷的房子里，叫“房奴”。欲望为你自己套上了脚镣。 消费主义是理想主义的大敌。如果你拥有宽裕的财力，房子的确是个不错的投资和保值品；但是如果你需要把你未来10年的大部分收入都押到一个房子里去，如果你觉得即使吐血也要iPhone，如果你觉得没有某个牌子的包包、衣服或车就没法出门……如果你生活有了太多的“必须”，那你就成了消费欲的奴隶——无论你是卡奴、车奴还是房奴，无论你欲望的理由是面子、丈母娘还是好好爱自己，超越能力的欲望都会给你的理想带上锁链，使你卖身为奴——即使你能看到你的理想，你的欲望主子也不会放你过去。 控制你的欲望是自我实现的重要手段。 如何找到事业线？ 你的事业应该是能让你在“热爱的领域努力地玩”的领域，同时满足兴趣、能力和价值，符合你的生涯需求。但是如何进入这些职业？下面是一些常见的攻略。 财务自由的人如果不符合第一条，那么财务自由是另一个很重要的因素。在新的领域，只要有足够的无压力的时间，能力和资源都可以慢慢积累。这个时候，财务自由（一个人可以不通过工作就获得让自己能生活的收入）就变得重要。财务自由有很多方法：理财、期权股票、家庭支持等。很多生完孩子的职场女性、家庭相对宽裕的子女或者有成功经验的二次创业者，都适合这个方式。 Pro-Am（Professional Amateur），意思是：用业余时间来做，并不作为主业，却在专业水平方面达到了职业水平的人。 从事着很多无法一下子兑现价值的职业的人，都选择了用业余专业者的方式实现梦想。 “既然当年明月可以做着海关官员写出来《明朝那些事儿》，为什么我不能？” 世界上第一批乐手和运动员都是Pro-Am，这也是乐器和球类都可以play的原因。 什么人适合选择Pro-Am的事业方式？ ① 需要个人技艺，但是不太需要团队合作的职业，如音乐、艺术、文学、心理、职业咨询、色彩、健身、瑜伽教练、户外等方面，都容易出现Pro-Am。 ② 网站站长、个人博客、淘宝店长这些不需要固定上班时间也能完成的职业，也是Pro-Am的重要领域。你能想象Linux系统是几千个世界顶尖程序员自发免费开发出来的吗？这些行业往往需要漫长的积累期，前期回报不明显，全职进入往往无法跨越生存线。这个时候，Pro-Am往往是最好选择。 为生存，为做好，为世界。当一个人从职业期进入事业期，他的职业虽无变动，但立意转换，格局扩大，他变得心灵宁静，他的眼神也变得平静且坚定。 写书何尝不是如此？从我第一次战战兢兢地写《拆墙》，我就处在写作的生存期，并无太多积累，文体、素材都是最适合大众的路子。等到写这本书，已经走到职业发展的阶段，可以慢慢地按自己心中所想，搭自己喜欢的架子，建构一个完整的学科。这个时候重要的是，千万不要对畅销有太多的欲望，守住生存线就好。一旦有了这种定见，自由度大增。 现实和理想总如蝴蝶的双翼，只有一起扑腾才能飞。 写给你，其实也写给自己 无须讳言，就像你每一个以“我有一个朋友”开头的笑话其实都是你自己的糗事，这里每一篇《写给……的你》，都是我自己曾经的心路历程。我曾经愤怒、装睡、接触苦难、想走捷径、不完美，又崇尚身心灵、爱自由、想意义……我就是这样一个满身缺点、磕磕碰碰，又总相信生命无比美好的人。在走的路上想到了些什么，就记录下来给自己，成了这一章。 写给苦难中的你 如果你必须面对一个苦难，那么你一定已经拥有了改变这苦难的资源。千万别认为自己渺小、卑微、无力。每个人身上都有改变世界的因子，每个人都能用自己的方式去改变世界。 乔布斯就这样把每一次跌倒都变成一个机会——他每摔倒一次，就抓起一把命运的沙，吹走污泥，找到里面的宝石。 一切的经历都是学习，一切的苦难都是机遇。 当他被苦难击倒，他琢磨这苦难与目标的关系；当他重新回到路上，他带回其他人所不具备的智慧与能力——而我们大部分人，目标都太短浅，所以我们害怕失败；也正是因为我们害怕失败，才缺乏那些不寻常的精彩与可能。 总有一天，你的生命会像电影一样，在你眼前一闪而过，请确定它值得一看。 简单来说，如果一个人觉得自己活得苦哈哈（是指内心痛苦，不是物质清贫）还在疯狂付出，那么付出就只是一种自我逃避或者治愈的自助手段而已。自助比自残好很多，但并不算纯粹。而如果一个人不断付出，而且还内心快乐，活得幸福，这则是一个人自我实现后，最干净、纯粹的付出。 更让人吃惊的是，经过思考，他把自己遇到的苦难归因于“他们从小缺乏教育”，并且尝试靠自己来改变这一切。这真让人吃惊。他没有像有些网民一样，一边在网上抱怨高考制度黑暗，一边送孩子上最好的奥数班；他好像也没有意识到，他自己都只是一个高二的辍学生——他本人就是缺乏教育的受害者之一。如果当年把他吊在电扇的那群人听到这个想法，估计会狂笑着把电扇开到最大一档——教育？！你转晕了吧？ 这念头有多不自量力，阿里木就有多坚定。从在烤肉钱里面翻出300元递给一位求助的慈善人士开始，到在贵州大学建立奖学金5000元……一直到今天，阿里木一共捐出10万元善款，帮助了160名贫困学生。一根羊肉串利润三毛，这是他33万串的利润。在这期间，他继续住棚屋，在被老板娘骂“抠得要死”的小店吃馒头和凉粉，和他的老婆嬉皮笑脸地拌嘴，继续在夜市里面嬉皮笑脸地卖他的羊肉串。 有个笑话说：一个人去医院急诊室，发现医生都不见了。问干吗去了，答学雷锋日，上街学雷锋去了。和这个笑话一样，在教育培训界多年，我见过太多抓狂的情商教练、无人知晓的营销专家、迟到的时间管理讲师，和从来不按自己讲的方式管理公司的管理专家。 对于任何一个苦难，我们有能力，有态度，也有意义。每个人都能完成对苦难的修炼。 所以，我们应该有勇气，把苦难酿为美酒，把深渊变成大河，把破口补成鲜花，让苦难成为信仰，让自己成为改变自己命运的神。 生存模式：面对苦难与挫折，从此在苦难、损伤的地方一蹶不振，这种模式叫作生存。恢复模式：面对苦难时状态下降，但有自己的弹性，在一段时间后，他们慢慢恢复到原先的水平。升华模式：苦难没有打倒他们，却让他们得以在苦难中更强大，获得新的技能和思考，这种模式叫作升华。 写给愤怒的你 我认同民智的提升，我渴望民主。但是我天生与那些只攻击社会的黑暗面、制度不公而没有进一步行动的观点保持距离——我们如此愤怒地攻击社会、攻击时代，殊不知愤怒也是无能的代名词。 愤怒是好的，但愤怒也是不够的。愤怒意味着我们依然生机勃勃，依然没有被现实压倒屈服，依然愿意对世界感到不满，依然认为世界能比现在好。但愤怒也意味着我们把自己幸福的可能性托付于对方，依然与对方在同一个系统，依然在这个系统里被压迫，依然对这种压迫，无能为力。 你痛恨这件事情，结果却完全认同了这个方式。你不是痛恨这个游戏规则，只是痛恨自己玩不好。这样的愤怒并不能让世界更好，甚至也不会让自己更好。一万个、一亿个这样愤怒的人，也无法有主张地让世界变好——因为这些人好像推翻皇帝暴政的奴隶，他们逐渐会成为下一个皇帝的奴隶；即使这些人有一天真正成为某个领域的主人，他们会发现自己成了当年自己最痛恨的人。 你唯一的能量，花在表达你的仇人们有多么不道德上。你除了为这个世界上增加一个悲惨故事，并且自己全情出演主角之外，没什么意义。 如果你能善待自己，这已经是件了不起的事了。如果能够再进一步，就是悲悯。 如果你能够再强大一些，也许你会发现更多的真相。你会发现，那些当年你痛恨的人、那些让你愤怒的人，也是游戏的牺牲品——他们已经被世界狠狠地报复过了。他们不需要另一次鞭打，他们需要的也是帮助。 当一个人伤害你的时候，他已经被深深地伤害过，他不需要再一次鞭打，需要的是怜悯。 不再愤怒，做自己，帮身边人，改善世界。 他们曾经也愤怒过，但最终，现实的理想主义者不再愤怒，做自己，帮身边人，改善世界。你也许会说，你是个梦想家，但不是唯一的。如果有一天，你也能加入我们，世界将有所不同。 ① 你可以不喜欢这个游戏，但是你可以玩得很好。② 上策是玩得快乐也心安，中策是把自己搭进去至少还能赢，下策是抱怨这是个最糟糕的游戏。③ 除了同流合污和冰清玉洁，我们还有很多选择。关键是你要有离开这个游戏还能活的能力。④ 玩好不意味着一直要赢，而是找到自己的定见。成王败寇要认，但是 莫以成败论英雄，英雄是维护自己信念的人。 写给装睡的你 第一个结局：呼喊的人声势越来越浩大，积聚所有的力量，大家打开了铁屋子，重获新生。这个故事你不陌生，人类大部分的进步，都是这样的趋势。文艺复兴、启蒙运动、新中国成立，都是这样。 这个故事你也并不陌生，苏格拉底被希腊市民毒死、布鲁诺被烧死——先知往往死于非命。 这个故事你不陌生，我们身边很多的人，都是装睡的人。他们受过良好的教育，他们偷偷关注很多呼喊的人，他们清楚地知道好坏、善恶、科学、民主，他们能够从书上、网上找到很多生活应该这样和那样的理由和论据。 但是他们唯一不敢做的，就是站起身来帮忙。他们敢于在网上转各种骂政府骂社会的帖子，却不敢在真实的生活里拒绝领导的一次举杯；他们能写出一篇万字的洋洋洒洒的关于美国人的素质有多好的文章，却不敢在公交车上看到小偷时大喝一声；他们去庙里还愿，几万几万地敬，且每天念佛，他们相信因果报应，却毫不犹豫地往产品里面加各种添加剂。 比愚昧更加可怕的是装睡。装睡的人虚伪又懦弱，他们知道一切该如何，却从来不愿意投入。这就是装睡的人。装睡的人以为自己和房子倒塌没有关系，其实他们是最大的合谋者。因为发言只需一人，而沉默却需要合谋。 他说：“公平。”讲完这个故事，他接着说，如果在国外，那样的人搞不好会被群殴。 尊严这东西不是你的西服，可以在开始的时候脱下放一边，混出来以后再抖抖穿起来。心里面的界线像是我们的手脚，一旦砍掉，也许一辈子都无法生长回来。 但是“新精英”不想装睡——我们的目标不是把现有市场里面的资源全部占据，而是让更多外面的人理解生涯规划；我们也不是想让每一个人都非来“新精英”学习不可，但是我们期待更多人能成长为自己的样子——这也是我忍不住又要写不仅会让我失业，也可能会让我很多同事失业的第二本书的原因。 坚持这样的原则，一开始很难，后来就越来越容易——因为很多对手看到了我们的态度，成为了朋友。而新精英自己的发展也加速起来——我们发现把观察别人找缺点的时间和精力放在成长上，足够把自己的核心竞争力打造出来。“夫唯不争，故天下莫能与之争”就是这个道理吧。而如果反过来，一开始就抢客户，虽然开局很容易，后来就越走越难了。很多事情都如是。 我们有个牛×基金，每年给员工一个月薪水和15天假期，让他们做一件自己认为牛×的事情。有人用来横穿美国、环游台湾、飞回去和暗恋对象表白或者给自己刺一个纹身。只要你觉得这是成长的突破，并且通过员工委员会审核，我们都支持。 我们相信善意、相信分享、相信人们会成长为自己的样子。如果你相信一个东西，总得有人为他做些什么。 宋飞：“因为我爱学生、爱音乐、爱教育。因为我自己成长的过程没有经历过这个，所以我才想当一个老师，给其他学生带来我从小经历过的那种希望。” 宋飞：“因为，我不说话就已经不能给从事这个事业的学生带来平安和幸福了。那我宁可损失掉我自己的平安幸福、别人想象当中的这种完美。” 如果大学里面没有知识，只有欲望和交易，是不是洪水？是不是人们头脑里面的洪水？我们说，是的。后来我进入了学校，我慢慢看到，洪水来了。 这件事情有个喜忧参半、有中国特色的结尾：中国音乐学院补录了四名学生，而央视的节目在首播后没有按照惯例再重播；宋飞没有停止自己的教学生涯，继续当她的老师。 我感谢这期节目的所有工作人员，因为他们不仅把镜头对准了一个著名学府的腐败事件，更带我们去见证了一个明知难以回天却依然挺身抗争的弱女子的勇气。这无关名誉，也无关成败，只有一个醒着的人最宝贵的清醒与勇气。 我觉得不公平。有更多不装睡的人，那个铁屋子，就一定能打开。最先他们逮捕共产党员——马丁·尼默勒在德国，起初他们追杀共产主义者，我没有说话——因为我不是共产主义者；接着他们追杀犹太人，我没有说话——因为我不是犹太人；后来他们追杀工会成员，我没有说话——因为我不是工会成员；此后他们追杀天主教徒，我没有说话——因为我是新教教徒；最后他们奔我而来，却再也没有人站出来为我说话。 最后他们奔我而来，却再也没有人站出来为我说话。 写给怕走弯路的你 By acclamation, Michael Jordan is the greatest basketball player of all time.一片欢呼声中，乔丹成为历史上最伟大的篮球运动员。 乔丹在内心深深地享受这份宁静，他的棒球生涯是献给父亲的，并不精彩，但温暖。在父亲离开后的几年，他重新触到自己在篮球场上无法触及的生命的温度。乔丹的生涯走出一条巨大的曲线，父亲的离开让他直面生命的其他维度，他决定遵循自己的内心，为自己和父亲打两年球。谁又能说，那两年的乔丹，那个在篮球场上宛若上帝本人亲临，却在棒球场四处嘘声中灰头土脸的乔丹，他的手指上，没有戴着自己心中的冠军戒指？ 很多人不懂得这个道理，他们认为如果一个人既没有提升，又没有变得更加专业，那就一定是在无所事事、不务正业。他们无法理解为什么有人要放着好好的工作不干出门旅游一个月，他们无法理解为什么好好的日子不过要折腾些幺蛾子。其实也许那个人正在你看不到的维度努力挑战着自己的极限，修炼着自己的功课。企业管理者也是一样，规则和结果带来绩效和专业，而文化和包容则带来温度和宽度，所有伟大的企业，在有自己的高度和深度的同时，都一定有一个匹配的温度和宽度系统。 回到乔丹身上，在积累了越来越多的内心温度的同时，乔丹也在发现自己的限制——他的确无法把篮球场上的优秀带入棒球场中。 我想乔丹的收获有三。第一个是父亲的心结已了，他可以安心地打篮球了。第二是他在棒球场上重新深刻地认识了自己的篮球天赋。第三，他了解了失败，更加珍惜成功。 看上去的生涯 实际的生涯 所以站得远的外人，总会羡慕走在线上的人一帆风顺。只有当事人和同行者知道，那只是看上去很美，而其中坎坷又何足为外人道呢？因为自己没有走过，永远都不会明白。 我们在瞬间交换了一个秘密，只有那些经历过真实生涯的人才能明白的秘密。人生无直线，因为直线从不转弯。而转弯和改变，是人生必经之事。何况，你不走点弯路，怎么知道什么是直线呢？ 写给不完美的你 好的，不管结果如何，现在的你创造了这样一张独一无二的白纸，就像你也拥有了自己这样一个随机的独一无二的不完美生命。如果你将要用接下来一小时的时间，只能在这张纸上工作，你会如何处理这个缺陷？ 间学习和模仿那些台前侃侃而谈、随机应变的人，却总是差距很大（别人也在进步啊）。可惜的是他从来没有关注自己作为内向者的优势——他是一个能花三小时把PPT做到尽善尽美、图文并茂、每一个数据都清晰明白的人，而这往往不是一个随机应变者能下的笨功夫。转变思路以后，他成了公司里最能展示的几个人之一。 化疗、放疗和手术是癌症治疗的三种常用方式。化疗以化学毒物杀灭正在激活中的癌细胞，同时也会杀灭身体中大量正常的免疫细胞。化疗也无法杀灭休眠中的癌细胞和正常细胞，这也是为什么化疗后，往往会发生各种转移——如加压的地壳和爆发的火山口的关系，这个地方的增殖被扑灭，另一个地方的癌细胞又被激活起来。 作为病人的医生自己也选择了生活质量高，但是死亡率高的医疗方案。也许作为医生的角色，他们需要以杀灭疾病作为“绩效”，但他们自己懂得生活质量比杀灭疾病更重要。 比如人的智商，基因决定你是80~120的普通人，还是110~160的天才段位，而你的个人努力决定了你是靠80还是靠120那一端。 奥普拉并不是个例，科学实验的数据结果也类似——500个超出标准体重50%的胖子使用此种方法减肥，有一半人坚持到了最后，超重的部分平均减少42%。但是三个月以后，一旦恢复正常的饮食结构，这些人的超重部分又反弹到80%左右。最好的结果是有13%的参与者在三年后依然保持身材。时间越长，减肥的效果会慢慢减弱，你的体重又会回到稳定状态。 科学家还发现，体重波动对身体的损害比肥胖更大。简单来说，胡乱减肥比肥更具危害性。 （在《认识自己，接纳自己》中，塞利格曼列了哪些是能改变的、哪些是不能改变的表格。） 以前有一个著名的木桶理论——一个木桶能装多少水，取决于最短的一块板。在工业化时代，这个理论的确非常有效。但是在全球互联的时代，这个理论实际早已破产。 所以今天的企业发展从短板原理，变成长板原理——当你把桶倾斜，你会发现能装多少水决定于你的长板（核心竞争力），而当你有了一块长板，就可以围绕这块长板展开布局，为你赚到利润。如果你同时拥有系统化的思考，你就可以用合作或购买的方式，补足你其他的短板。 所以在职业生涯发展中，最好的能力策略是“一专多能零缺陷”。“一专”指让自己有一项非常非常强的专长；“多能”指有可能多储备几项能力搭配着使用。通过自身努力和对外合作，让自己的弱势变得及格即可；而最需要避免的情况是“性情大于才情”——你有些小优势，但是由于与你合作的成本太高，没有人愿意和你合作。这与应对疾病的策略一样，先让自己别得快速致死的“急性病”（比如工作态度、诚信、合作能力等基本的综合能力），然后和自己的“慢性病”（比如某些方面的天赋与技能不足）和平共处，专注发挥自己的优势去。 汪冰说：“你看，你总是在接到任务时迟迟不开始行动，但是最后结果又总不错。是不是你在一开始的时候，潜意识就开始酝酿，只是在最后一刻，才突然孵化出来？你这个大脑或许不是拖延症的居住地，而是一个孵化器。”春雨一拍他那个烫得已经很像鸡窝（鸡蛋孵化器）的大脑袋说：“哈哈，我喜欢这个想法！”从这以后，他还真的孵化出不少好点子。 写给不完美的你所以，亲爱的，不完美的你，生命被点上黑点、努力擦拭的你，在你的生命中，有没有不可抹掉的黑点？不如意的出生，缺失的机会和教育，不公平的社会环境……但是是什么让你今天依然活得坚挺？是什么让你今天愿意试试看一本叫《你的生命有什么可能》的书？是什么让你今天还有继续生活的勇气？在你的生命里，一定还有些部分在发光，一定还有something works（一些东西在发挥作用）。专注于生命可能的部分，让那部分发挥价值，此生就已足够。正如那句著名的祈祷词一样：让我有胸怀去接纳不可改变的，有勇气去改变可以改变的，并有智慧区分两者。修正自己是一种勇气，接纳自己的不完美也许更是，而接纳自己后掉头去追寻自己想要改变的，则是一种智慧的人生态度。加缪说：重要的不是治愈，而是带着伤痛前行。持续聚焦于做正确的事情，就没有机会做不正确的事情。持续做幸福的事情，控制好不幸福的事，幸福就会生长起来。 花园里种满了鲜花，就没有机会长草。专注于生命可能之事，让生命如夏花般怒放。 积极心理学：黑点不是重点，还有很多地方有空白。别花时间搞黑点啦，关键是把白纸的价值用出来！ 写给爱自由的你 发现了吗？在这个世界里，你的每一个行为都会与其他人发生作用。当你拥有无拘无束的“自由”的时候，对他人来说，你则拥有了一个毫无约束地伤害他人的特权——这种人没有人愿意和你玩。 当涉及别人，自由和责任同时出现了。 哈耶克在《自由宪章》里强调了法律对自由的重要性：“法律的目的不是取消或限制自由，而是维护和扩大自由。” 所以，你的自由以他人为界，你挥舞的拳头以我的鼻子为界。孔夫子在人生最高的境界“从心所欲”后面，加上了一个“不逾矩”。因为如果仅仅是从心所欲，那么一岁小孩都会，而从心所欲不逾矩，才是真正的自由。 那么，有钱就能有一切的自由吗？首先，有钱的确能让你提高自由度，但是赚钱本身就是件需要满足他人需求的不太自由的事，你该看到花钱的自由背后不自由的代价。即使天生有钱的富二代，也有要满足他们父母亲的需求的责任——一旦过了18岁，他们的父母亲也有给不给钱的自由。其次，世上有钱买不到的东西实在太多，友情、爱情、才华、格局、智慧……在所有钱无法购买的领域，你都没有自由。你的自由以他人为界，而你所期待的随心所欲的自由，并不存在。 但是当提到法律和社会制度下的“自由”时，几乎所有的正式文件都用了另一个词“liberty”。 比如说自由女神叫Statue of Liberty（别去美国丢人啊，free woman是“免费女郎”）。《独立宣言》中“每个人都被赋予了不可剥夺的权力，生存、自由以及对幸福的追寻”用的是“life, liberty and the pursuit of happiness”。亨利在1775年弗吉尼亚议会上的名言是：Give me liberty or give me death（不自由，毋宁死）。Liberty是什么意思呢？ 经济自由是指你有“自己决定钱花在哪里”的自由，而不是“爱买什么就买得起什么”的自由。 “按照自己希望的方式而非强制的方式”来生活，“决定什么东西和谁的需求对自己最重要，是一个自由人的基本权利和义务之一”。 你可以理解为什么处于任何环境下的人，都曾经、正在也永远会有选择的自由。 他可以选择在不喜欢的情况下慢慢适应现在的工作，以之作为生存和发展的跳板，也可以选择不好好干。他可以选择讨好父母获得学费，也可以选择自己攒钱不需要靠父母认同。他可以选择晚上加班读研，也可以选择保存精力不再苦读。他可以选择即使父母不愿意也要坚持，也可以选择妥协。他有选择的自由，但是没有选项的自由。 我希望人们放弃的是他们痛苦的根源，那就是：他们总渴望存在这样一种不可能的选项的 自由： 而对于一个成熟的自由人，游戏规则其实很简单：你有好好干还是大闹天宫的自由，而公司也有升你还是降你的自由；你有听或不听父母的自由，而你的父母同时也有发飙或不发飙的自由；你有追寻感兴趣的工作的自由，而企业也有寻找能力更强的人的自由。你可以自由地挑选哪一个更好，但是你并没有能力要求世界为你而改变。你们都平等地拥有选择的自由。追寻“选项自由”的人，他们像等待戈多一样，在人生站台等待这永不进站的“自由”；终其一生，自由没来，无奈倒总是准点。很多人沉醉于这种不切实际的幻想中还有一个更深层次的心智问题——不愿意或者无力承担自由背后的责任。 不想选择—觉得无奈—愤怒—受害—恨 不选择，其实是最糟糕的选择。 类似的选择困境其实很多：在家人的反对之下，我是否有追求自己想过的生活的自由？是否有用自己的方式工作的自由？我是否有交自己喜欢的朋友的自由？我是否有做自己想做的事情的自由？不是说人生而自由吗，为什么我们没有选择自己生活的自由？以小娟的故事为例，她有认为“自己想要的爱情方式和自己的需求”更重要的自由，也有选择如何应对的自由，但每个选择背后她也都需要为可预见的结果负责。 自由意味着责任，而责任需要能力承担。人们畏惧自由，往往是因为畏惧背后的责任与无能。如果你想要有决定自己未来的自由，一定要有决定自己未来的能力，并且愿意用这些能力为自己负责。 自由与责任成长是一个自由逐渐扩大的过程，你慢慢开始可以自由地花钱、居住、择偶、工作、生孩子……随着自由的好处越来越多，必须承担的责任也就越来越多。自由与责任不仅不是对立，反而是不可分割的。法律上规定18岁之前，孩子们尚不能为自己的行为完全负责，所以他们也并未获得完全的自由；精神病人不能自由选择自己的行为，所以也无须为此负法律责任。我们有开车的自由，同时就有遵守交规的责任。 自由与责任，一如太极的阴阳、鸟的双翼，同起同落。 2000年开始，大学生开始双向选择，享受到突如其来的就业的自由，却并没有承担起自我定位和求职的责任。正如哈耶克所说：“在自由社会中，我们不仅有了技术，而且还应该有让自己的技术被认知价值的能力。” 对现代的职业人来说：你当然有选择一份喜欢的工作的自由，所以你也需要承担起自我销售、与人竞争的责任。你当然有升职和自我实现的自由，所以你也需要承担起表明自己有能力胜任的责任。你当然有特立独行的自由，所以你也需要承担大家不支持你的责任。你当然有频繁跳槽、不断选择的自由，所以你也要承担起社会对频繁跳槽者的评判，以及也许你会选错的责任。女性有生孩子或者不生孩子的自由，所以也要承担起社会可能对生育期职场女性的歧视，承担起自我整合、重回职场的责任。大小城市的选择也是一个经典的自由与责任问题。如何选择大小城市，一个比较幸福的方式是，去大城市闯荡，到小城市养老。为什么我们年轻的时候都想闯荡天下，而老了又纷纷叶落归根？显而易见，大城市自由多，责任也多，压力大；而小城市相对不自由，但责任也小得多。 所谓成熟，就是懂得评价自己能承担的责任，选择自己能享受的自由。 即使是有人做错，却还是需要你来负责。 你站在一个十字路口，准备过马路。车行的路口亮起红灯，而行人通道亮起绿灯，你迈步前行。正走到马路中间，有一辆大卡车闯了红灯，向你冲来。你看了一眼红灯，确认是他违规。你有什么反应？A. 躲开，先自保。有可能的话，记下车牌举报。B. 站在马路中间，对这车大喊：你错了！然后，砰……啊……啊……啊……你会选择哪一个？肯定是A。但是我们生活中还有很多人选择B，为了证明对方错了，他们不惜把自己搭进去。 为了证明昔日恋人的分手是错的，他们与一个不喜欢的人在一起，“证明给你看你失去了什么”；为了证明别人的想法是错的，“就做出来给你看看”；为了证明世界不够好，他们宁愿自己过着糟糕的生活。 毕老师回答说：“你的钢笔和你的父母都不是你能够改变的，但是你的那支一毛二分钱的笔却是你能把握的。只要这支笔写出来的答案，与那支钢笔写出来的一样，就会获得同样的分数。而如果你能够持续写出更好的分数，你就能慢慢改变自己的生活。”我喜欢这个回答。我们渴求公平，正因为世界本不公平。所以重要的不是判断是否公平，而是如何面对不公平。世界没有给我们选项的自由，但我们总有选择的自由。 总有人在你生命里犯错，但是只有你在你的生命里负责。请担起责任来。2从“愤怒—无奈—恨”到“自由—责任—能力”循环，我大概花了一年时间。当看到问题，解决就变得简单——我大概花了一年多时间，让自己重新慢慢提高管理能力，开始重新自由一点。希望你比我快一些。 简单地说，过度地为别人负责的人，是剥夺别人自由的人。 乔布斯承担了苹果前进的大部分责任，所以他也获得了足够多的自由。 当你有了按时高质量交付的执行力，你就有了时间自主的自由；当你有了快速学习和迁移的能力，你就有了轻松跨行业的自由；当你有了照顾好自己的能力，你就有了安心等待自己喜欢的人、全情投入恋爱的自由；当你有了语言能力和健康的身体，你就有了周游世界的自由；当你有了背起自己的责任的能力，你就获得了全世界的自由。能力，是自由的第一要务。 能力越大，责任越大。他决定担起这份责任。 曾国藩无疑是近代史上的一只巨牛。他28岁中进士，然后在京当官10年，连升10级，从一个正处活活干到正厅局级，算是学霸。43岁时太平天国大乱，他带领3000湘军打仗，11年后攻陷天京，算是军神。他握天下兵权，算是皇帝候选人，但他选择了主动解散湘军。他55岁上书请求解除一切职务，注销爵位，未遂，创建江南制造总局。他61岁提出在美国设立“中国留学生事务所”，算是留学祖父。 如果你希望自由，控制欲望是你必需的修炼。在大清朝必需，在科幻小说里必需，现在在科技社会更必需。 高科技能让人们更自由的想法由来已久：从工业革命开始，人们就相信，当机器越来越多地替代人工作的时候，人们就可以从工作中解放出来，开始休闲。 问题就在这里，当技术让我们的效率提高一倍时，我们的欲望却无暇休闲，而是希望能提高三倍。在我的大学时代，当我们用一个下午亲手写完一封信，然后把纸张折成喜欢的形状，信封贴上邮票，用胶水或者饭粒封上封口，心里期待这封信件可以在三天后尽快地在心爱的人手上展开。但是当我们可以在三秒内就发出一封e-mail的时候，我们却认为每天至少要回复20封电子邮件才是正常的。我们原来期待十年磨一剑，现在我们希望三年上市。我们每天挤车一小时回家，站在公交车上看着开小车的人，心里想着有一天自己能开车上班该多好，但是当我们真的有了车，我们又开始频频按喇叭，希望自己能够在15分钟内到家，而这个时候，你或许已经住在一个开车也需要一小时的地方了。 今天，企业家不快乐，高分学生不幸福，高官不安心，因为他们都在用太多的精力饲养他们的欲望。中医说，在求不得和想得到之间，全是火气。 自由=能力-欲望。一个人的自由之路无非有两条，一条是给能力做加法，一条是给欲望做减法。提高能力让你能承担更多责任从而获得更多自由；而降低欲望则让你宁静下来，让生命变轻，把自由还给自由。 写给追寻生命意义的你 他问我：“你说人活着，为了什么？” 正如你问一个旅行的人：这次旅行最有意义的部分是什么？ 所以当所谓的成功人士试图把人生的意义总结成几句话告诉你的时候，你一定要清醒——那只是他自己的生命意义的其中一个说法而已，不是你的。所以，人生的意义，绝对不在别人那里，只在你那里。 即使我们的生命真的有终极的意义，我们也不可能在活着的时候知道它。因为一旦我们知道了自己生命的终极意义，知道这件事本身就会改变我们的人生，让我们拥有新的意义（听上去很拗口吧，不过就是这么回事）。但是，我们又那么渴望知道一个意义，该怎么办？ —我们不知不觉地长大，有一天，我们无法回避自己的存在，不得不开始思考，我的人生有什么意义？ 你希望自己的生命有什么样的意义？你能够为这个意义承担什么样的责任？你能为这个意义付出什么样的代价？你能为生命付出什么、承担什么责任，生命就可以有什么样的意义。 我不信神，在我看来，人生本没有什么设定的意义。如果想要有意义，你就只能自己创造一个。创造自己生命的意义，就是我的宗教。 这篇墓志铭会记录关于你的什么部分？它会如何评价你？会记录你此生做过的哪些重要事情？会提到你的什么贡献？找个安静不受打扰的时刻，写下你的人生墓志铭。 跋 愿你过上我从未看见与理解的生活 这本书是我的成长三部曲的第二部——这三本书是一个完整的体系，从打破思维障碍的《拆掉思维里的墙》，到看到更多《你的生命有什么可能》，到讨论如何自我成长的《成长为自己的样子》——所以这个跋，也像是《成长为自己的样子》这本书的序。 所以弯弯，重要的不是小心翼翼地活着、谁也不伤害、谁也不得罪。让谁都喜欢你，这不可能。关键是创造你自己的生命——让自己活出意义来、活出特色来，活得让自己对得起因为你而失去生命的牛牛羊羊猪猪，对得起人们为你注入的生命力。好的生命不是完美，也不是安全，而是值得。 亲爱的弯弯，这个世界并不公平。努力能在一定程度上改变命运，但是不一定能颠覆命运。所以记得，与别人相比是没有意义的，那是一种永无宁日、 绝无胜算的自我折磨。如果你有能力，记得要和自己比，让自己过得好一些，理解自己的心有多大，给人生做加法带来快乐，做减法带来安心，加加减减到让自己舒服。世界虽然没有给每个人提供完美的生活，却给每个人足够的资源让他们收获自己应得的。 有个叫上帝的人，他开了一家努力银行。每个人都有一个自己名下的努力账户。每个人每天都在往里面存自己的努力。有的人存得多，有的人存得少。有人存了第二天就取，有的人则在很多年以后一次性取出来。 上帝要保证每个人账目公平，不能有错账。上帝还要标注那些存努力存得最多的金卡客户，给他们分配更多的回报。上帝很忙很忙。但事实总是这样，总是那么几个最努力的人有最多的回报，这工作也太不好玩啦。所以每隔10年，上帝就调出所有的金卡客户，抽一次奖，然后随机把一个巨大的成功分给中奖的那个幸运的家伙。所以，宝宝，只要努力，就会有合理的回报。而那些巨大的成功，往往来自幸运——但是请先确定，你努力地拿到了金卡。 记得要活得精彩，活得认真，跟自己比。愿你过上我从未看见与理解的生活。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"IPCreator的书单","date":"2017-01-10T06:30:18.000Z","path":"2017/01/10/MyView/Book/my-book-list/","text":"“美好的事物值得付出、等待和分享” 创新 创新者的基因 英文标题:The Innovator’s DNA：Mastering the Five Skills of Disruptive Innovators作者：Clayton M. Christensen豆瓣评分：7.4 观察，联系，发问，实验，交际 横向思维 英文标题:Lateral Thinking作者：Edward de Bono豆瓣评分：7.8 条条大道通罗马 六顶思考帽作者：Edward de Bono豆瓣评分：7.4 一个全面思考问题的模型，落实平行思维的工具蓝色思考帽：蓝色负责控制思考帽的使用顺序，它规划和管理整个思考过程，并负责做出结论。白色思考帽：白色是中立而客观的，关注客观的事实和数据。黄色思考帽：黄色代表价值与肯定。从正面考虑问题，表达乐观的、满怀希望的、建设性的观点。红色思考帽：红色是情感的色彩，表现自己的情绪、直觉、感受、预感等。黑色思考帽：黑色代表否定、怀疑、质疑的看法，合乎逻辑的批判。绿色思考帽：绿色代表茵茵芳草，象征勃勃生机，寓意创造力和想象力。 专利 图解专利法－专利知识12讲 一图胜千言 管理 像TED一样演讲 副标题:创造世界顶级演讲的9个秘诀作者：Carmine Gallo豆瓣评分：7.7 一个主题、三个要点、十八分钟 影响力英文标题:Influence: The Psychology of Persuasion作者：Robert B. Cialdini豆瓣评分：8.6 影响力的武器：互惠、承诺和一致、社会认同、喜好、权威、短缺 成长 你的生命有什么可能作者：古典豆瓣评分：8.4 成长，长成为自己的样子！ 拆掉思维里的墙作者：古典豆瓣评分：8.0 向自己的生命发问 把时间当作朋友 副标题:运用心智获得解放作者：李笑来豆瓣评分：8.5 要管理的不是时间，而是自己。 做最好的自己作者：李开复豆瓣评分：7.9 有勇气改变可以改变的事情，有胸怀来接受不可以改变的事情，有智慧来分辨两者的不同。 破解幸福密码作者：毕淑敏 豆瓣评分：7.6 幸福是一种心灵的感受，有意义的快乐就是幸福。 罗辑思维 副标题:运用心智获得解放作者：罗振宇豆瓣评分：7.2 独立、理性的思考通往自由的彼岸。 你要如何衡量你的人生 英文标题:How will you measure your life?作者：Clayton M. Christensen豆瓣评分：8.0 工作是为了更好地生活。 此生未完成 副标题:一个母亲、妻子、女儿的生命日记作者：于娟豆瓣评分：9.0 为什么是我？又为什么不是你？ 向死而生 副标题:我修的死亡学分作者：李开复豆瓣评分：7.3 不忘初心，心怀感恩，随缘随喜 投资 投资中最简单的事作者：邱国鹭豆瓣评分：8.7 定价权是核心竞争力，人弃我取逆向投资，便宜才是硬道理。 时寒冰说：未来二十年，经济大趋势（现实篇）作者：时寒冰豆瓣评分：8.3 感悟趋势之美 时寒冰说：未来二十年，经济大趋势（未来篇）作者：时寒冰豆瓣评分：8.0 感悟趋势之美 技术","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"成长之我见","date":"2017-01-06T05:53:18.000Z","path":"2017/01/06/MyView/my-view-of-growing-up/","text":"The true joy of life is the trip.The station is only a dream. It constantly outdistances us. Happy is a duty. 天道酬勤，一分付出一分收获鉴赏水平和底蕴，需要日积月累和沉淀日子慢慢过，好书/音乐/电影需要慢慢品良好的生活作息和工作习惯，需要磨练过去的种种，消化、放下、转身、前行, Live without it聚焦新阶段新目标，日日精进，贵在坚持保持节奏感、创造成就感，在自己喜欢和擅长的领域放肆玩成长的阶段，经历必有益，不忘初心，方得始终，Live with it冰曝三尺非一日之寒，千里之行始于足下别急，慢慢来，一切都来得及，何况急躁有害无益 do yourself, live your life ,fight for your dream. 做自己，过自己的人生，为自己的梦想而拼搏 任何选择都会有风险，不选择就是最大的风险 任何选择都会有得失，值不值在于在于如何衡量人生 有得必有失，反之亦然，有失必有得，得失平衡 快不快乐，首要是：弄清楚自己想要什么 充不充实，关键是：是否朝着既定目标前行 成与不成，秘诀是：自知自胜、贵在坚持 幸不幸福，基础是：健康、家人、事业 先让自己变得有价值，做出有价值的产品，再谈其它 先提高审美和技能，再欣赏、模仿和创新 很多恐惧和担忧来自想象，源自眼界/无知和缺乏目标/信念/经验/技能…Success is a habit, so do failure. The way leading to success is commitment.-Q:这么做有用吗？ 这么坚持有意义吗？…-A:你做了没有？坚持了没有？为什么没用？为什么没坚持？…成长的人从自身找原因，为成功找方法逃避的人从外界找理由，为失败找借口 基本概念 什么是爱？ 陪伴就是爱 什么是幸福？ 健康、充实、知足和感恩 什么是成功？ 按自己的意愿过一生 什么是思维升级？ 技术/法律–&gt;商业思维 什么是自由？ 自由=能力-欲望参考阅读：《如何控制自己的情绪》 如何避免被洗脑？ 事情本身是否符合常识和逻辑 事情及对方的利益立场是什么 独立判断能力的重要性 美国的卡耐基说：成功来自于85%的人脉关系，15%的专业知识中国的李笑来说：学习重要，还是经营人脉重要？我的个人逻辑，分阶段调节不同比例，如：成长初级阶段（学校/应届生等）个人/人脉比例85/15，中级阶段（主管/经理等）50/50，高级阶段（总监/副总裁等）15/85 为什么系列 为什么要努力？ 拥有更多选择的自由 为什么要读书？ 开启心智，增长见识 为什么要留在大城市？ 见识参考阅读：《罗振宇：拒绝逃离北上广 见识决定命运》 痛点系列 功名VS幸福应试VS素质理论VS实践抽象VS具体宏观VS微观说说VS执行 创新基本概念 什么是创新？ 你无我有、你有我优、你优我快 什么是体验？ 用起来很爽，很智能非常快 快速智能示例一 支持联系人拼音首字母键盘定位，智能屏蔽无数据按键 快速智能示例二支持联系人分组一键群发短信，智能屏蔽呼出按钮，以防用户误操作 ## 管理 基本概念 什么是管理？ 管事理人 什么是领导？ 让追随者“升官发财” 什么是狼性？ 以结果为导向，多为成功找方法 自我 &gt;自知者明、自胜者强、自律者自由 主管 参考阅读：JMT主管管理技能培训 中层 参考阅读：MTP管理才能发展培训 高层 参考阅读：LTP领导力训练 关于分享 &gt;柳传志给杨元庆写过这样一封信：你最初是小鸡，你长成大鸡的时候没有人佩服你，当你长成火鸡的时候，也没有人佩服你，只有你变成鸵鸟的时候，别人才会佩服你，因为你比别人都大。所以，你的分享不会带来任何好处，只会给你带来不必要的管理困扰。 参考阅读：王治全反思：被我“毁掉”的兄弟！ 关于黑天鹅 &gt;塔勒布在他后一本书《反脆弱》中给出的应对之道——黑天鹅的出现，和观察者有关。一只被喂养了很久的火鸡，它会觉得屠夫很爱它，对它来说，它在感恩节被宰杀就是一个黑天鹅事件，但这不会让屠夫吃惊。所以，塑造新的思维模式的办法就是，不要成为火鸡。应对科技挑战的最佳解决方式，就是让自己成为一家科技公司。 参考阅读：刘湘明：应对科技挑战的最佳方式，就是让自己成为一家科技公司 关于“推销” &gt;李笑来《新生——七年就是一辈子》之第19章节“如何克制自己的“推销”欲望” 推销知识很难的更深层次的原因在于： - 仅仅说是肯定没用的，得做，不然说没分量； - 做都不一定是有用的，得有改变，没改变不算数； - 有改变也不一定够，得有看得见的改变，看不见还是没分量； - 有看得见的改变还是不一定成功，因为对方可能并不服气； - 改变太大了也不行，因为对方一看，吓倒了，直接放弃了…… &gt;真的感谢互联网，它给了我们另外一个可以分享的通道。自从我开始写博客之后，之前此类的烦恼彻底消失了。 有分享欲望的时候，可以喷在网上，又由于没有了特定的对象，反倒没有了“获取认可”的压力，分享变成了一个纯粹开心的行为。 能否有因获得认可而产生的快乐，只取决于两个因素， 1. 我是否真的真诚（这个不用提）; 2. 我是否运气好，消息能传递给那些能理解我的人（我好像这方面运气一直都不错）…… &gt;于是，整个人就感觉少了很大一个负担， 1. 该干嘛就去干嘛，说那么多有什么用？ 2. 做了，就有变化，有变化，自己先开心，别人看不看得到其实并不重要罢？ 3. 少说导致更专注，更专注导致变化最大化，有时候吓到别人，也怪不得自己罢？ ## 专利 基本概念 什么是专利？ 专有的权利 什么是专利的价值？ 风险控制、增值经营、竞争超越 参考阅读：现代公司法务的核心商业价值构建 什么是好的专利？ 能带来价值的专利 参考阅读：移动互联时代的知识产权新特征 什么是好的专利布局？ 产出更多更高价值专利的挖掘和扩展 如何有效实施专利布局？ 五位一体/沙漠寻路/三步六法","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"酷派集团：“五位一体”高效管理7000件专利申请","date":"2017-01-05T09:22:06.000Z","path":"2017/01/05/MyView/MyPast/my-article-for-newspaper/","text":"文章下载 酷派集团：“五位一体”高效管理7000件专利申请 “非苹果，即酷派。”酷派集团董事长郭德英在去年世界互联网大会上的豪言壮语仍言犹在耳，这份自信不仅源于酷派集团雄厚的技术研发实力，还得益于其前瞻性的专利布局和高效的专利管理。 酷派集团在手机领域耕耘多年，掌握了手机领域的诸多核心技术，在智能手机技术研发、专利布局、产品创新和提升用户体验等方面积累了丰富的经验。 在持续开展专利布局的同时，如何对7000余件专利申请进行高效管理？酷派集团给出的答案是：通过实施“一把手工程”、打造“五位一体”专利布局体系和采用“开放式”的创新模式，制定了以“提升商业竞争力”为核心目标的知识产权战略，以此发挥专利的最大价值。 “一把手”的管理理念 郭德英是酷派集团的首席发明人，自2001年提交第一件专利申请开始，截至目前，他已提交了100多件专利申请。以郭德英为代表的公司领导对技术创新和专利布局的高度重视，并身体力行地践行着专利布局是“一把手工程”的发展理念，是酷派集团高效开展专利管理工作的关键。 “企业开展专利管理的基础是以自主创新能力作为支撑，并服务于公司战略发展需要，但关键因素是公司领导的高度重视和支持，而酷派集团实施的‘一把手工程’为我们开展专利管理工作提供了有力支撑。”酷派集团知识产权部经理汪智勇在接受中国知识产权报记者采访时表示。 “截至目前，酷派集团在全球范围内已提交了7000余件专利申请，其中90%以上是发明专利申请，内容涉及多模多待、双系统、UI交互、手机安全等方面。”汪智勇向本报记者介绍，目前，酷派集团已有1500余件专利申请获得授权，其中包括数十件涉及通信领域基础技术的基础专利和数百件提升酷派集团智能手机高端市场竞争力的核心专利。 得益于公司领导的高度重视，酷派集团很早就开展了专利管理工作，并确立了以“提升商业竞争力”为核心目标的知识产权战略。汪智勇介绍，酷派集团实施的知识产权战略包括3个方面，即立足研发、聚焦市场，知识产权工作要全方位嵌入公司的生产经营环节；建立完善的知识产权防御体系，支撑公司的经营战略，并提高公司开拓市场的自由度；降低知识产权风险，同时加强知识产权运营。 “五位一体”的专利布局 打造“体验、技术、产品、专利和标准”五位一体的专利布局体系是酷派集团专利管理工作的第二大特色，其核心思想为技术、产品、专利和标准都是以提升用户体验为出发点及落脚点，并相互融合促进。 汪智勇介绍，通过给业务部门设置专利考核指标等方式，酷派集团把专利布局嵌入到了产品生命周期的各个环节，以确保创新技术、产品能在第一时间得到全面的专利保护。 “五位一体”的专利布局体系为酷派集团高质量、全方位开展专利挖掘和布局工作奠定了基础。汪智勇介绍， “五位一体”中的体验是指日常生活中典型的用户场景或痛点；技术是指解决用户痛点、提升用户体验的创新技术，并在第一时间将其转化为产品，同时开展专利布局，并争取使其成为行业标准；产品是指产品立项和创新要以用户需求为中心，在遵循标准的基础上，结合用户对产品的反馈进一步开展技术创新和专利布局；专利是指以创新技术或产品为载体开展专利布局，并争取将其纳入到标准中，进而成为标准专利。 “通过加大技术创新力度，有效提高了专利质量。与此同时,在专利布局时开展的专利检索和数据分析也为产品创新开拓了新的视角。”汪智勇表示，通过实施“五位一体”的专利布局体系，酷派集团不仅提升了用户体验，而且还达到了体验、技术、产品、专利和标准“五位一体”的良好效果。 “开放式”的创新模式 对于不同的企业而言，其都会根据所在行业采取不同的专利管理策略。在汪智勇看来，专利管理工作要服务于公司的商业战略，并根据自身情况“量体裁衣”，这就需要企业专利管理人员结合移动互联网时代的新形势，提前做好应对和转型升级。 通常来说，传统企业的创新模式是封闭式的，企业的技术研发人员都是自主研发，而在移动互联网时代，企业的技术创新往往需要从外界获取大量创新资源，这就要求企业专利管理人员积极引导企业创新模式从“封闭式”逐渐转为“开放式”，比如企业可以与用户、供应商、科研院所、服务机构、行业协会，甚至竞争对手等相关部门建立协同创新机制。汪智勇向记者举例说，酷派集团每年有很多技术创新点源自高校合作项目或竞争对手的用户论坛等外部渠道。 在汪智勇看来， 企业专利管理人员要始终坚持“专利战略服务于商业战略”，因此，专利管理人员不仅要具有传统的技术思维和法律思维，还要具备相应的商业思维，比如使专利管理工作服务于产品宣传和品牌建设等。","comments":true,"categories":[{"name":"专利","slug":"专利","permalink":"http://ipcreator.me/categories/专利/"}],"tags":[{"name":"Patent","slug":"Patent","permalink":"http://ipcreator.me/tags/Patent/"}]},{"title":"IPCreator专利清单","date":"2017-01-04T12:53:06.000Z","path":"2017/01/04/MyView/MyPast/my-patent-list/","text":"检索方法1、打开专利检索网址大为；2、以“汪智勇”为关键字进行检索；3、在检索结果中，以申请（权利人）为“宇龙/Yulong” or “酷派/Coolpad”进行二次筛选便可得出结果。 备注 以下清单，基于2017.1.27日以前公开的专利库进行检索，未纳入未公开的相关专利申请（中国/PCT）。 专利清单 序号 公开号 专利名称 发明人 1 WO2013000123A1 PASTING METHOD AND TERMINAL THEREOF WANG ZHIYONG;YE BIQING;FENG YUHUI;LIU DONGHAI 2 WO2016106938A1 CONTACT-BASED SYSTEM SWITCHING METHOD AND APPARATUS AND TERMINAL LIU DONGHAI;WANG ZHIYONG 3 WO2016115760A1 TERMINAL SYSTEM CONTROL METHOD, DEVICE, AND TERMINAL LIU DONGHAI;WANG ZHIYONG 4 WO2016119288A1 DATA ACQUISITION METHOD, DATA ACQUISITION DEVICE AND TERMINAL XU XING;LIU DONGHAI;WANG ZHIYONG 5 WO2016173072A1 DATA INFORMATION PROCESSING METHOD, DATA INFORMATION PROCESSING DEVICE, AND TERMINAL ZHOU WEI;WANG ZHIYONG;PANG MIN 6 WO2016173075A1 SYSTEM SWITCHING METHOD AND DEVICE LIU DONGHAI;WU DIANQING;WANG ZHIYONG 7 WO2016192161A1 DATA PROCESSING METHOD AND DEVICE LIU DONGHAI;WANG ZHIYONG 8 WO2016192163A1 METHOD AND SYSTEM FOR REDUCING POWER CONSUMPTION OF MOBILE TERMINAL, AND MOBILE TERMINAL WU KEBIAO;WANG ZHIYONG 9 WO2017000341A1 INFORMATION PROCESSING METHOD, DEVICE, AND TERMINAL LIU DONGHAI;WANG ZHIYONG 10 WO2017000344A1 OPERATING METHOD AND TERMINAL BASED ON FINGERPRINT RECOGNITION LIU DONGHAI;WANG ZHIYONG 11 WO2017000354A1 FINGERPRINT PASSWORD VERIFICATION METHOD, SYSTEM, AND TERMINAL LIU DONGHAI;WANG ZHIYONG 序号 申请号 专利名称 发明人 1 CN201510344976.5 一种图像处理方法、装置及终端 吕楠;汪智勇;蒋罗 2 CN201510306351.X 一种用于降低移动终端功耗的方法和系统、以及移动终端 吴科标;汪智勇 3 CN201610567614.7 一种消息处理的方法及装置 吴殿清;汪智勇;闫娟;唐冬兰 4 CN201610565644.4 一种消息处理的方法及装置 吴殿清;汪智勇;闫娟;唐冬兰 5 CN2015082964 METHOD AND SYSTEM FOR REDUCING POWER CONSUMPTION OF MOBILE TERMINAL, AND MOBILE TERMINAL WU KEBIAO;WANG ZHIYONG 6 CN201610200631.7 一种指纹操作方法及终端设备 吴殿清;汪智勇;张娜;雷武 7 CN201610567587.3 一种消息处理的方法及装置 吴殿清;汪智勇;闫娟;唐冬兰 8 CN201610178390.0 基于智能水杯的信息调整方法、信息调整装置及智能水杯 吴殿清;汪智勇;闫娟;张娜 9 CN201610200353.5 一种多指纹混合登记的预警处理方法及移动终端 吴殿清;郭德英;汪智勇;张娜 10 CN201510236129.7 一种红外遥控方法及系统 吕楠;汪智勇;蒋罗 11 CN201510992251.7 一种应用程序下载安装方法及终端设备 刘东海;党乐;吴殿清;汪智勇 12 CN201610179140.9 用于智能水杯的控制方法、控制装置及智能水杯 吴殿清;汪智勇;闫娟;潘露杰 13 CN201610177989.2 用于智能水杯的控制方法、控制装置及智能水杯 涂欣;汪智勇;闫娟 14 CN201610184737.2 电梯控制方法、电梯控制装置和终端 梅各各;吴殿清;汪智勇;闫娟 15 CN201511019709.7 指纹识别的安全管理方法及装置、终端 刘东海;汪智勇 16 CN201610184821.4 通信处理方法及通信处理装置 潘晓;吴殿清;汪智勇;潘露杰 17 CN201610177915.9 基于智能水杯的信息调整方法、信息调整装置及智能水杯 吴殿清;汪智勇;闫娟;唐冬兰 18 CN201510369387.2 指纹密码的验证方法、系统和终端 刘东海;汪智勇 19 CN201510288979.1 虹膜信息采集方法、虹膜信息采集装置及终端 吕楠;蒋罗;汪智勇 20 CN201511018264.0 数据访问方法、数据访问系统和终端 刘东海;吴殿清;汪智勇 21 CN201510290387.3 水印嵌入方法、水印嵌入装置和终端 刘东海;汪智勇 22 CN201510458375.7 一种基于用户信息识别的设备控制方法及移动终端 刘东海;郭建军;李沙;吴殿清;汪智勇 23 CN201510460556.3 密码信息的验证方法、密码信息的验证系统和终端 刘东海;郭建军;吴殿清;汪智勇 24 CN201510615614.5 鉴权方法和终端 刘东海;汪智勇 25 CN201510374951.X 一种信息处理方法、装置以及终端 刘东海;汪智勇 26 CN201510374233.2 一种基于指纹识别的操作方法及终端 刘东海;汪智勇 27 CN201510282913.1 一种酒驾检测方法及终端、服务器 刘东海;汪智勇 28 CN201510456437.0 一种环境监控方法及用户终端 吴殿清;汪智勇;闫娟 29 CN201510734361.3 移动支付的监控方法、系统及智能终端 陈历伟;汪智勇 30 CN201510466796.4 指纹校验方法及装置 刘东海;郭建军;吴殿清;汪智勇 31 CN201510386218.X 一种数据处理方法及设备 刘东海;李仕伦;汪智勇 32 CN201510454769.5 一种室内环境监控方法及物联网终端 吴殿清;汪智勇;闫娟 33 CN201510854609.X 一种支付方法及其装置 陈历伟;汪智勇 34 CN201410464798.5 一种终端运行方法和装置 詹谷;黄焕荣;袁刚;汪智勇 35 CN201510848857.3 远程控制方法、远程控制装置、终端和远程控制系统 蒋罗;吕楠;汪智勇 36 CN201510623457.2 一种登录信息的配置方法、装置和移动终端 吴殿清;汪智勇;闫娟 37 CN201510618247.4 一种多系统间的应用安全保护方法及终端 刘东海;张碧君;汪智勇;吴殿清 38 CN201410303207.6 跨平台关联设备间的应用的安装方法及其系统 刘东海;汪智勇 39 CN201510615266.1 一种用户数据的保护方法及终端 刘东海;许奕波;吴殿清;汪智勇 40 CN201410195732.0 一种超级用户权限控制方法及装置 李仕伦;汪智勇;阳得常 41 CN201510611610.X 虹膜认证方法、虹膜认证装置及终端 梁文栋;黄习昌;闫娟;汪智勇 42 CN201410165760.8 一种安全驾驶的预警方法及系统 李仕伦;汪智勇;冯玉慧 43 CN201410066559.4 消息通知方法、消息通知装置、移动设备和消息通知系统 汪智勇;郭德英;郭建军;吴殿清;王文清 44 CN201510288853.4 一种数据处理方法和装置 刘东海;汪智勇 45 CN201510209238.X 一种系统切换方法和装置 刘东海;吴殿清;汪智勇 46 CN201510209832.9 数据信息处理方法、数据信息处理装置和终端 周威;汪智勇;庞敏 47 CN201510201478.5 系统切换方法、系统切换装置和终端 胡军杰;汪智勇 48 CN201410856593.1 多系统终端的系统切换方法、装置和终端 石爱民;汪智勇 49 CN201510054797.8 数据获取方法、数据获取装置和终端 许行;刘东海;汪智勇 50 CN201510044131.4 应用程序的运行控制方法、运行控制系统和终端 胡军杰;汪智勇 51 CN201410843159.X 基于联系人的系统切换方法及装置 刘东海;汪智勇 52 CN201410579593.1 丢失终端的管理方法及系统 刘东海;汪智勇;冯玉慧;叶必清;李仕伦 53 CN201510026623.0 一种终端系统的控制方法、装置和终端 刘东海;汪智勇 54 CN201410719656.9 一种汽车监控方法及系统 刘东海;汪智勇 55 CN201410453522.7 一种低电量提示方法、装置及终端设备 詹谷;黄焕荣;卓优;汪智勇 56 CN201410301262.1 一种基于虚拟键盘的文字输入方法及装置 林荣辉;汪智勇;陈运哲;战磊 57 CN201410204656.5 信息同步系统和信息同步方法 叶必清;汪智勇 58 CN201410056902.7 数据保护系统及方法 汪智勇;王正泽;王旭;郭德英;邓小英 59 CN201410099365.4 一种智能输入法切换方法及装置 叶必清;汪智勇 60 CN201410042322.2 一种终端及防止敏感信息泄露的方法 陈祥;汪智勇 61 CN201310625749.0 一种文件的传输方法及装置 李仕伦;汪智勇;叶必清 62 CN201310530882.8 商品信息的处理方法及装置 汪智勇;李俊;邓小英 63 CN201110451257.5 一种图片下载的方法、移动终端及服务器 冯玉慧;汪智勇;叶必清 64 CN201210527902.1 一种应用协同方法及移动终端 汪智勇;王文清;王正泽 65 CN2011076513 PASTING METHOD AND TERMINAL THEREOF WANG ZHIYONG;YE BIQING;FENG YUHUI;LIU DONGHAI 66 CN201110384354.7 一种应用程序安全预判装置及方法 汪智勇;朱宗伟;王新颖;冯玉慧 67 CN201110291506.9 终端和数据处理方法 罗彪;汪智勇;冯玉慧 68 CN201110283313.9 一种通信信息提醒方法、系统及移动终端 叶必清;廖迴敏;冯玉慧;汪智勇;刘东海;王新颖 69 CN201110301688.3 一种对数据进行操作的方法及移动终端 汪智勇;叶必清;冯玉慧 70 CN201110304416.9 一种应用程序的显示及分类方法、系统及移动终端 汪智勇;李自来;廖迴敏;冯玉慧 71 CN201110295666.0 好友搜索方法、设备和系统 冯玉慧;廖迴敏;王新颖;汪智勇 72 CN201110204888.7 应用程序管理方法和终端 汪智勇;叶必清;冯玉慧;刘东海;王新颖;张开营;廖迴敏 73 CN201110215246.7 终端和文件保存方法 汪智勇;冯玉慧;王新颖;廖迴敏 74 CN201110174335.1 应用程序管理装置和应用程序管理方法 汪智勇;叶必清;冯玉慧;刘东海 75 CN201110090127.3 一种应用程序访问权限设置方法、系统及移动终端 汪智勇;冯玉慧;李仕伦 76 CN201110084844.5 应用程序安装方法和终端 汪智勇;刘东海;冯玉慧 77 CN201110086742.7 手机应用分类管理方法及装置 冯玉慧;汪智勇 78 CN201110037376.6 一种应用程序监控方法及装置 汪智勇;叶必清;冯玉慧 79 CN201010624198.2 智能呈现联系人相关信息的方法、系统及移动终端 汪智勇;叶必清;冯玉慧;王志标;王玮;刘东海;李仕伦 80 CN201110044252.0 一种移动终端内应用程序的升级方法、移动终端及服务器 汪智勇;刘东海;冯玉慧 81 CN201110031882.4 一种基于android平台应用安装控制方法及系统 汪智勇;叶必清;冯玉慧 82 CN201010589186.0 信息处理方法及装置 叶必清;汪智勇;冯玉慧 83 CN201010596846.8 基于Android的应用程序升级方法、系统及应用开发平台 汪智勇;冯玉慧;刘东海;李仕伦;王玮;叶必清 84 CN201010598458.3 移动终端中应用运行条件的评估方法及装置、移动终端 汪智勇;冯玉慧;叶必清 85 CN201010523146.6 一种应用协同的操作方法、系统及移动终端 汪智勇;冯玉慧 86 CN201010578230.8 应用程序管理方法、装置以及终端 汪智勇;冯玉慧 87 CN201010508288.5 一种联系人菜单智能生成的方法、系统及移动终端 汪智勇;冯玉慧;孟宪衡;邱圣华 88 CN201020532495.X 一种触摸式移动终端 王灿;汪智勇;冯玉慧 89 CN201010531736.3 控制应用程序并行运行的方法、装置及具有该装置的终端 汪智勇;冯玉慧 90 CN201010286512.0 实现移动终端的一号多卡的方法和系统 邱圣华;张碧君;汪智勇;冯玉慧;孟宪衡;张毓华 91 CN201010282444.0 联系人分组方法及终端 汪智勇;冯玉慧;邱圣华;孟宪衡 92 CN201010270503.2 一种应用程序使用状态的提醒方法、系统及移动终端 汪智勇;冯玉慧 93 CN200910041406.3 一种终端功能协同方法及对应的终端 郭和平;汪智勇 94 CN200910040535.0 一种数据排序的方法及移动通信终端 汪智勇 95 CN200910038390.0 数据协同的方法、终端及系统 汪智勇 96 CN200810198086.8 一种终端监控方法、装置及系统 杨鹏辉;汪智勇 97 CN200810026989.8 一种信息显示方法、主机端及子机端 杨鹏辉;汪智勇","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Patent","slug":"Patent","permalink":"http://ipcreator.me/tags/Patent/"}]},{"title":"IPCreator工作历程","date":"2017-01-03T11:37:06.000Z","path":"2017/01/03/MyView/MyPast/my-resume/","text":"对生命而言，成长是唯一的密码，到了某个时间点，就干该干的事情，不纠结，不犹豫，遵从自己的内心，走好生命的每一段旅程。 成长经历创业(2016年6月 ~ 至今) 创业者 听从内心真实而又强烈的声音：“为什么不基于先进的平台和工具，把好的创新想法付诸实践呢”？打工快10年，为何还要为别人的梦想而拼搏呢？ 跟随AI浪潮，基于谷歌的Tensor和Android平台，聚焦UI和IPR两大领域，开发系列产品和服务，为用户带来“快捷、智能、高效”的创新体验。 承担的职责：负责产品的架构、设计及开发，打通从创新思想到智能产品/服务的关键落地环节。 宇龙酷派 （2012年8月 ~ 2016年6月） 职位：知识产权部经理职责：团队/制度流程建设、专利布局、奖项申报、专利诉讼等。 示范企业及专利奖项申报承担项目经理职责，全程组织申报材料的撰写、递送及答辩，2015年荣获深圳市专利奖并成功申报国家知识产权示范企业，带领团队连续三年获得中国专利优秀奖（十六届、十七届和十八届）。 公司级布局项目制定和落实集团专利储备战略，构建“沙漠寻路/三步六法”专利布局体系及配套制度/流程/模板，作为第一负责人，主导完成公司级布局项目10+个，均受到公司高层的充分肯定和专项表彰，其中，“体验、技术、产品、专利和标准”五位一体布局体系在中国知识产权报上发表和推广。 其他项目作为集团第一个欧洲项目的知识产权代表，建立了海外知识产权风险防控体系，创建了中国/美国/欧洲律所资源池，制定了公司律所招标流程/专利诉讼处理流程及配套模板；主导处理了集团在美国的第一个专利诉讼，并以最低代价胜诉结案；主导处理了集团在中国的第一个大额专利诉讼案件，包括无效请求和不侵权分析，最后以涉案专利被成功无效，原告主动撤诉大获全胜；作为公司专利运营项目第一负责人， 制定并推行专利运营流程及配套模板，创建国内外专利运营资源池， 并主导专利组合评估相关工作。 宇龙酷派 （ 2007年7月 ~ 2012年8月 ） 职位：开发工程师/软件项目经理职责：软件开发、项目管理、团队建设等。 F608/F603项目担任软件项目经理，负责F608/F603移动TD畅销机型的软件业务，先后荣获最佳产品质量奖，最佳项目团队奖，杰出贡献奖，参加软件项目经理手册、软件质量过程监控等流程及知识库建设，荣获知识库建设之星1次， 过程改进奖4次。 软件开发担任开发工程师，负责多个核心系统模块和应用的开发，其中，联系人应用在第三方组织的用户调查中荣获最高评分，个人先后获得最佳代码质量奖，最佳应用奖，最佳设计文档等奖项，并多次被评为天道酬勤之星。 其他项目负责运营商业务小组，培养出多名项目经理和高级工程师，荣获最佳导师称号，团队共通过国内外专利申请100+篇(专利清单)。 求学经历 （ ~ 2007年7月 ） 学历：本科（优秀毕业生）/研究生（保送） 中南大学 专业：计算机应用技术 英语：国家六级 技术：高级程序员（2003） 个人博客：http://ipcreator.me 行业博客：http://blog.163.com/zhuxuanlv@126/ Email：ipcreator@yeah.net","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"2016年最精彩科学美图","date":"2017-01-02T12:24:06.000Z","path":"2017/01/02/MyShare/view-of-scientific-discovery/","text":"这一年有啥留恋：看2016年最精彩科学美图 随着2016年即将接近尾声，美国新闻聚合网站BuzzFeed评选出2016年最精彩的科学美图。这些美图展示了今年被发现的科学奇迹，包括揭示了从微观到宇宙尺度等不同物体的形态，比如国际空间站、鲨鱼、变色龙等，下面就让我们带领大家欣赏这些令人震撼的图片。 这张照片获得2016年度英国生态学会摄影大赛的总冠军，图中是古巴翠蜂鸟。 沙丘鹤正从西伯利亚向墨西哥长途迁徙，正在内布拉斯加州躲避风暴。这是美国《国家地理》杂志年度最佳图片。 7月16日，在450多米高空拍摄的航拍图，可以看到下面大块的海冰、融化的池塘以及开阔的水域。 11月10日，南极拉森冰架（Larsen C ice shelf）上的大裂谷。 保存在琥珀中的9900万年前恐龙尾部羽毛。 10月3日，在国际空间站上拍摄利比亚西部的撒哈拉沙漠。 火星轨道侦测器拍摄到的火星山谷。 这是西门子资助的、由皇家摄影协会主办的国际科学图片摄影大奖获奖作品之一。从小型液态燃料露营炉中缓缓上升的热空气形成无形湍流。纹影摄影（Schlieren photography）让我们可以看到和记录被火焰加热的空气与周围环境中冷空气之间的折射率差异。 “好奇”号火星探测器自拍照。 10月30日，搭载3名宇航员的俄罗斯“联盟”号飞船在哈萨克斯坦着陆。 世界野生动物基金会12月份发布报告宣称，在东南亚大湄公河地区发现了新的蝾螈物种。 天文学家们发现的最新证据显示，这可能是有史以来发现的最极端的脉冲星或旋转的中子星。 这只毛虫遭到黄蜂袭击，背部寄生蛹也开始爆发，它的生命已经到了最后时刻。图中的液滴是血淋巴，也就是毛虫的血液。这张照片获得2016年度英国生态学会摄影大赛学生类作品大奖。 这是眼线化妆品中发现的微小塑料块，又被称为微球体。由于其体型过小，无法在污水处理过程中清除出去，可对海洋生命造成危害。这张照片来自一个摄影项目，主要研究微小塑料对环境的影响。 这些蚂蚁正在吃用糖着色的食物，摄入液体让它们的身体变成蓝色。 这是在喜马拉雅山海拔4400多米处拍摄的照片，展示云海上空的银河系。 风喉蜥蜴又被称为“草原战士”，它们是由高度领土意识的生物，会不遗余力地保护自己的领地。这张照片是夏季时在印度马哈拉施特拉邦拍摄的，当时正处于蜥蜴交配季节。 10月份，通过哈勃太空望远镜观察大的螃蟹星云。它是一团巨大的气体云，形成于2600年前的恒星爆炸，距离我们大约有1600光年远。 这是在泰国旅游胜地普吉岛上发现的飞龙科树蜥(Acanthosaura phuketensis)，它们看起来就像迷你飞龙。 这是格陵兰鲨，属于睡鲨的一种。这些体型巨大、行动缓慢的生物正在大西洋深处优雅的游动。最新研究发现，格陵兰鲨是寿命最长的脊椎动物，有的标本至少已经活了392岁。 这些小星团正围绕透镜状星系NGC 5308旋转。这里所谓的“小”只是相对来说，每个星团都包含着数十万颗恒星。 这是在显微镜下看到的潜水甲虫腿部末端，它大约有2毫米长，可在交配时帮助黏在雌性甲虫背上。 从国际空间站上观看闪电和地球城市灯光，前面则是2艘俄罗斯飞船。 这些黑鳍礁鲨正在塞舌尔群岛的低潮浅水中潜伏，等待涨潮。 这是巴哈马群岛北部被称为“老虎滩”的地方，这里以常见虎鲨闻名。 这是在澳大利亚内陆通过银河系与河外星系全天默奇森广域阵列(Galactic and Extragalactic All-sky Murchison Widefield Array）射频望远镜拍摄到的宇宙射频图像。 在坦桑尼亚谢伦盖蒂平原上，鲁氏粗鲁氏秃鹫（黑白兀鹫）与非洲白背秃鹫正啄食斑马的遗骸。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Share","slug":"Share","permalink":"http://ipcreator.me/tags/Share/"}]},{"title":"罗辑思维","date":"2017-01-01T22:00:06.000Z","path":"2017/01/02/MyShare/iGet/luozhenyu-logic-thinking/","text":"逻辑思维 简介：罗振宇，又称“罗胖”。一个每天在微信上坚持60秒的男人，一个每周“死磕自己、愉悦大家”的说书人。《罗辑思维》是罗胖的个人知识型脱口秀节目。在节目中，罗胖天文地理、古今中西，无所不谈。每次都做足功课，为你颠覆直觉，清理误区，引入趣味，连接断层，随口八卦。不求立意高深，只为打破每个人的认知屏障和信息茧房，让你在短时间内得到一锅知识浓汤。 受众：爱智求真的跨界学习者；需要丰富谈资的社交达人；在变动的时代，渴望实现个人崛起的年轻人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"商业内参","date":"2017-01-01T21:00:06.000Z","path":"2017/01/02/MyShare/iGet/lixiang-reference-of-business-inside/","text":"商业内参 李翔商业内参大佬都在看马云：李翔从不人云亦云，有自己的判断。雷军：主编创业，李翔顺势而为。我一定会订阅并且关注《李翔商业内参》柳传志：《李翔商业内参》是为了让大家以更高的效率获得高质量的内容。陈可辛：很期待李翔帮助更多人理解商业变化。李开复：李翔是我认识的媒体人中非常有职业操守和有传媒精神的人。我一定会关注和订阅《李翔商业内参》。 李翔是谁中国最好的商业记者之一 李翔任《时尚先生》主编时主持的一期封面柳传志、王石、马云、史玉柱、沈文荣、李开复、俞敏洪、李书福、郭广昌、曹国伟、宋卫平、潘石屹、田溯宁、丁磊、程维、王兴、张旭豪……这几乎是中国最近三十多年商业明星的合影。毋庸置疑，李翔是中国最好的商业记者之一。也许是因为他的诚意，也许是因为他的敏锐，他总是能在这些企业家生命中的关键时刻，以恰当的方式，出现在他们面前。老一辈的企业家愿意从他那里听听年轻人的想法；而新一代的创业者愿意从他那里听听过去的掌故。一定程度上，他们超越了采访者和受访者的关系。 我们为什么要做商业内参？让我们的用户在竞争中取得领先优势 马云说过：“很多人输就输在，对于新兴事物，第一看不见，第二看不起，第三看不懂，第四来不及。” 我们的初心就是，让我们的用户在竞争中取得领先优势，让看不见、看不起、看不懂的人最终来不及跟上他们的脚步。 有一些事，是你本来就想做的，我们相信，李翔商业内参能帮你更高效地完成它。有一些事；是在你意料之外的，我们希望，《李翔商业内参》能让你有更广阔的视野，开启你更精彩的财富人生。 李翔商业内参能做到什么？怎么做到？ 每天 10 条左右的精选信息。这个产品能筛选出真正有价值的信息，缓解你的信息焦虑；能给出可行的建议，让你做重要决定时更有把握；能提示商业变量，使你不会错过转瞬即逝的机会。 李翔个人的解读和点评。这个时代，信息，大家都能看到，但能看出什么来，和每个人的认知能力高度相关。就像罗胖所说的，这个产品卖的不是信息，而是李翔基于超过十年的商业报道经验而获得的认知能力。 每条信息就像一个插件，即插即用。这个产品是根据应用场景来打造的，特点就是有用。你做 PPT 的时候需要金句，聊天的时候需要谈资，做判断的时候需要行内人的洞察或者记者圈的小道消息，这个产品全都能提供。 专注于极致内容的生产。这个产品基于付费订阅，内容团队不用写软文拉广告，他们能抵抗伤害内容品质的短期诱惑，专心为你提供好服务。 适宜人群企业家、创业者，以及所有对商业世界的变化感兴趣的人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"前哨","date":"2017-01-01T20:00:06.000Z","path":"2017/01/02/MyShare/iGet/wangyuquan-front-guard/","text":"前哨 每年拿5个亿为自己的判断买单，今天把他的侦查给你看。 为什么要订阅这个产品？他是你深入人类创新文明最前沿的侦察兵因为我们正处于一个急速变动的时代，创新科技呈几何级数加速发展，人类的未来会发生根本性重塑。这种时候，哪怕一点点视野上的差距，都将导致难以逾越的认知障碍，差之毫厘、失之千里。雇佣王煜全做你的私家“哨探”，他就是你的“望远镜”，视野比别人更开阔；他也是你的“显微镜”，认知比别人更清晰。 因为王煜全有三种能力。一是判断真伪的能力。哪些是真正可以改变未来的科技，哪些只是臆想和传说，在他眼里就隔着一张窗户纸，一点即透。二是判断价值的能力。哪些科技只是热闹好玩，哪些科技会对人类的未来产生重大影响。他给你的，不止是信息和知识，更是机会和行动纲领，帮你先人一步摸到全球科技创新的风口。三是判断时点的能力。他的探查与判断将是两年之后出现在媒体上的“大新闻”与“黑科技”，从现在就开始提前布局，两年之后抢占风口的就会是你。 他会成为你深入人类创新文明最前沿的侦察兵。帮助你，用最低的成本、最少的精力和时间，获得最顶级的视野。他会尽其所能，帮助你在对创新这件事的理解上，远超其他人。 作者简介王煜全官方头衔是：海银资本创始合伙人，资深市场营销和战略咨询专家。但是记不住最好，因为根本不重要。 他是个非常特别的投资人。一般的投资人，都是在美国融钱，然后跑到中国来投资，但他恰恰相反，他是带着中国新兴中产阶级的钱，跑到美国去投资，而且专投那些高科技创新企业。 他一口“京片子”，但却对北京不太熟，为什么？一年里有大半时间都在美国呗。每年他要拿5个亿的真金白银去投资，换来大量的知识和经验，并为他自己做出的所有判断买单。 适宜人群跨国协作的企业家、捕捉全球机会的投资者、寻找下一轮创新风口的创业者；对未来充满好奇心的年轻人，每个生活在这个急速变动时代的聪明人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"雪枫音乐会","date":"2017-01-01T20:00:06.000Z","path":"2017/01/02/MyShare/iGet/liuxuefeng-classic-music/","text":"雪枫音乐会 雪枫音乐会带你一年听懂260首古典音乐5月28日起，刘雪枫在得到App（罗辑思维出品）开设为期一年的订阅专栏，周一到周五，每天精选一首古典音乐讲给你听。 白岩松: 如果说古典音乐是宗教，那刘雪枫一定是最好的传教士。徐小平: 音乐给我带来了无限的欢乐和滔滔不绝的灵感，成为了我生活的底色。余华: 刘雪枫人生的追求、生活的乐趣，全在古典音乐里面，除了这个没有别的。谭盾: 雪枫在我眼里是音乐家，让更多的人走进音乐。胡歌：让我们一起和古典音乐成为朋友，享受我们属于我们的文明和智慧。欢迎订阅《雪枫音乐会》。 彻底被征服：小宝宝们的最爱：大宝宝更爱：启蒙国人的美学教育：音乐抒发情感，评论都是诗人：往来无白丁，专业留言密集： 白岩松说：“雪枫音乐会”，就是要拆掉人们进入古典音乐领域的“墙”。这面墙如果有个名字，可以叫“懂”。因为，这是让很多人困惑的致命障碍，在于“我怎么没听懂呢？” 刘雪枫中国著名的古典音乐评论家和推广者。出席过上千场国内外顶级音乐会。发表专业乐评近 200 万字。收藏古典音乐唱片 100000 张。曾任两本古典音乐杂志《爱乐》和《留声机》的主编。长期以来，和他一起听音乐会、收藏唱片的往来友好名单中陆续添加了投资家徐小平、主持人白岩松、作家余华和李陀、画家何多苓、诗人北岛和欧阳江河、歌唱家龚琳娜、京剧名伶史依弘和孙慧珠，还有演员孙淳和葛优等等“大人物”。 适宜人群艺术家、企业家、白领、教师、学生……适合所有爱音乐、享受音乐的朋友。只要你希望生活美一点，再美一点。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"超级个体","date":"2017-01-01T19:00:06.000Z","path":"2017/01/02/MyShare/iGet/gudian-super-individual/","text":"超级个体 未来是个人崛起的时代不管你是上班、自由职业还是创业，未来都是个人崛起的时代。整个时代都在加速往前跑，领跑者永远只有少数人，大部分人只能跟随。要成为领跑者，你需要快速成长，长成超级个体。 超级个体是什么样的？ 他有超强的个人影响力，又善于和各种组织合作，共同成长； 他既能站在科技前沿，又能深刻洞察人性； 他具备多学科通识，又能精研某个领域，成为专家； 他比别人成长得更快，有很强的自我驱动能力，持续增值。 一句话，超级个体是未来的第一梯队。 ##《超级个体》专栏主要内容 我们会每周探讨一个加速发展的职场主题，重新认知个体崛起时代的职场 如果把你当成一家公司，你的核心能力由这4个部分组成：产品能力（对事的竞争力）、媒体能力（对人的影响力）、运营能力（对组织的领导力）以及战略能力（自己的个人成长）。这4大类型8个板块的能力，构成一个人职业核心竞争力。 未来5年职场将有什么变化，如何应对？ 有哪些越来越火的新职业方式会出现？ 职场人如何获得更大限度的自由？ 个人魅力时代，如何塑造个人品牌？ 如何发现天赋并打造自己的优势？ 如何更快提升专业能力？ 怎样在奋斗的同时保持精力充沛？ 怎样快速做出不后悔的决策？ 什么是这个时代有效的「人脉管理」？ 怎样成为一个既自律又有趣的人？ 每次一个看得懂、记得住、能实操的工具、模型或方法论。知识同样符合二八原则，任何一个领域真正核心的内容就是20%，最聪明的办法是用80%的时间学习这20%的精华。这20%往往是一些核心的模型或工具——它们既是底层逻辑也是方法论，是聪明人做事的“套路”，观察世界的方式，有了这些会省你很多时间。 陪伴成长我希望做陪伴在你身边的成长教练——这也是我选择在“得到”开设这个专栏的原因。每周四和周五，我都会在这里和你们深度互动、答疑、讨论这周的主题。未来我还会邀请更多有趣的超级个体，来分享他们的独门经验，和大家一起探讨这个时代的成长方式。 在未来一年，我们一起来做三件事： 每周学习3个加速发展的工具和方法论，你可以逐渐打造一个属于你的超级工具箱 完整地梳理自己，系统展开能力地图，逐渐搭建自己的能力体系 认识更多各个领域的“超级个体”，看到人生不同的可能性 专栏主理人古典，著名生涯规划师，高管教练，新精英生涯创始人。著有畅销书《拆掉思维里的墙》，5年销量超过300万册，被翻译成4种语言。古典会在这个专栏里，每个星期围绕职业发展、个人成长，深度讲解一个主题，给你3个加速发展的实用工具和模型。他还会及时回答你的问题，解决你的困惑，用自己积累多年的经验，全力帮你快速精进，跻身职场第一梯队。 适宜人群未来是个人崛起的时代。不管是上班、自由职业还是创业，所有希望快速成长，超越别人，一路领跑的人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"硅谷来信","date":"2017-01-01T18:00:06.000Z","path":"2017/01/02/MyShare/iGet/wujun-letters-from-silicon-valley/","text":"硅谷来信 提升自己的快捷方法美国最杰出的商业哲学家吉米·罗恩（Jim Rohn）曾经有一个经典的论断——“你就是你平常花最多时间相处的五个人的平均值”。和优秀的人亲密接触，是提升自己的快捷方法。还有比这更快捷的方法吗？有。那就是和你亲密接触的优秀者，每天还在和更多优秀的人朝夕相处。 “吴军·硅谷来信”订阅专栏，给你提供一个提高朋友圈质量的机会。在这里，你将有一年的时间，和一位优秀人物，以及围绕在他身边的众多顶尖科学家、商界领袖和文化精英朝夕相处，去熟悉他们的思维方式，掌握一套深入洞察世事和人生的独特方法，进而寻找到成功的轨迹。 专栏的主理人吴军博士，计算机科学家，硅谷投资人，《浪潮之巅》、《文明之光》等畅销书的作者。他曾先后供职于谷歌和腾讯，是谷歌中、日、韩搜索算法的发明人；他既是活跃在硅谷的投资人，也是美国两家风险投资基金的董事和顾问；他先后写过六本书，横跨数学、教育、IT、文明史本本畅销，最新出版的《智能时代》在罗辑思维独家首发，首印1.5万册，不到10小时售罄； 硅谷来信的主要内容在“吴军·硅谷来信”订阅专栏，吴军博士会把他的见闻、想法，以书信的方式，第一时间与你分享。从2016年10月10日起，截至2017年10月9日，你会在每周收到至少五篇由吴军博士从硅谷发来的信件，每封信的开头都会写有你的名字。这些信件将主要围绕以下几大主题展开： 介绍新的、媒体尚未报道的科技成就的金融、科技类文章——如果你是希望参与跨国合作的企业家，或是正在捕捉全球机会的投资者，亦或是寻求下一个创新风口的创业者，这一部分内容，也许会对你有帮助； 国外优秀科技公司的先进做法及管理经验分享——如果你是一位创业者，或是普通企业中的管理者，这部分内容分享也许会对你有帮助； 教育主题的文章——由于吴军博士在给美国几所顶级的大学担任顾问，每年都要花时间走访各个大学，他会在信中与你分享这些名校的特点和教育理念，无论你是家长、学生还是教育从业者，这部分内容也许能给你一些启发； 对时事的评述文章——在这个信息过载的时代，对于即时资讯的在处理能力，往往决定了一个人的学习、思考结果，进而客观上决定了一个人最后的发展走向，如果你是一个爱智求真，不甘于盲从的人，在重要的热点事件发生时，希望吴军博士的分析和洞察，能够给你提供一个独特的视角，帮你辨伪存真。 世界各地的艺术、历史、风土人情，以及吴军博士生活中点点滴滴的经验、体会——勤奋工作和享受生活从来不是对立的，如果你是个热爱生活的人，这个专栏能带你去看一个更大的世界。 如果你没有太多时间浏览图文，“吴军·硅谷来信”专栏还邀请了前中央人民广播电台知名配音演员为你一字一句朗读信件，每天只需抽出大约10分钟的时间，即可完成一次小小的自我升级。期待一年之后，你的见识飞升，并且结交一帮可能让你终身收益的学友伙伴。 适宜人群适合每一位渴望提升洞察力，从而在纷繁复杂的世界一眼洞穿真相、做出正确决策的朋友。帮你成为迷茫时代里的明白人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"通往财富自由之路","date":"2017-01-01T17:00:06.000Z","path":"2017/01/02/MyShare/iGet/lixiaolai-lead-to-freedom-of-wealth/","text":"通往财富自由之路 李笑来是谁？中国最会赚钱的人之一，天使投资人，连续创业者，原新东方名师，区块链专家，著有《把时间当作朋友》、《新生——七年就是一辈子》等畅销读物。他真正摆脱财务束缚的起点，是他写的一本书——《TOEFL 核心词汇 21 天突破》，销量超过百万册。仅仅是《TOEFL 核心词汇 21 天突破》、《TOEFL iBT 高分作文》、《把时间当作朋友》等长销书，就已经让李笑来获得了足够多的“睡后收入”，实现了财富自由。比特币兴起之后，李笑来又比别人更早、更快地抓住机会，跻身亿万富翁的行列。 赚钱是所有人都必需的技能，可它偏偏是一种学校里不教的技能，是绝大多数人终其一生都没有习得、或没有学得足够好的技能。其实，大多数人不是没有机会，没有努力，而是选错了道路，用错了力气而已。在获取财富这个领域里，李笑来可算是个老司机，并且恰好还是个乐于分享的老司机。他坚信，在通往财富自由这条路上，人人都有至少一次机会。 为什么开设这个订阅专栏？ 没钱是一种病，不能放弃治疗 其实钱是世界上最干净的东西，每个人都应该学会科学、合理地赚钱。 可问题是，赚钱这玩意儿，不是每个人都会。 比如，很多赚不到钱的穷人，他们最大的悲哀不是没钱，而是不相信自己会有钱。 有钱不一定是努力的结果，但没钱不应该成为你不努力的理由； 再比如，钱这个东西，不足够多就等于没有。大部分人只靠工资，不可能变得“有钱”； 如果说没钱是一种病，那这个订阅专栏就是一个药方，希望能帮助更多的人修正错误的赚钱观念，找到实现财富自由的方法。 通往财富自由之路能做什么 不看可能多走很多弯路 在接下来的一年内，他将会跟大家分享下面这些内容： 赚钱的速度太慢等于失败，花钱的方法太差等于贫穷。该如何正确地赚钱和花钱？ 为什么说冒险常常并不赚钱？ 什么资产的复利效应最大？ 你最宝贵的财富是什么？最宝贵的个人资产是什么？ 只涨不跌的资产都有哪些？ 运气并不是虚无缥缈的事情，如何让运气更好？ 为什么说一时的风光是最错误的追求？ 为什么说个人最快的成长方式是成为创始人？ 个人商业模式升级的几个台阶都是什么？ 在这个专栏里，亿万富翁李笑来带着大家每周更新一个观念，一年 52 次深入探讨，请大家上车，一起赶路，通往财富自由。 适宜人群所有渴望实现财富自由，并对自己能实现财富自由深信不疑的人。","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]},{"title":"美丽风景合集","date":"2017-01-01T12:28:06.000Z","path":"2017/01/01/MyView/Journey/view-of-journey/","text":"“美好的事物值得付出、等待和分享” 儿童乐园 地点：侨香路以南，广深高速以北，农林路以西特色：儿童、游乐场、免费推荐指数：★★★★★ 欢乐海岸 地点：南山区白石路8号与海园二路交界 特色：彩灯、喷泉、酒吧 推荐指数：★★★★★ 大沙河公园 地点：北环大道与沙河东路交叉口附近特色：广场、草地、运动推荐指数：★★★★★ 仙湖植物园简介 地点：罗湖区莲塘仙湖路特色：弘法寺、植物推荐指数：★★★★★ 月亮湾公园简介 地点：南山青青世界下边特色：百年荔枝古树、廉政主题推荐指数：★★★☆☆ 巽寮湾（xùn liáo wān）简介 地点：惠州市惠东县的大亚湾畔 特色：石奇美、水奇清、沙奇白 推荐指数：★★★★★","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Share","slug":"Share","permalink":"http://ipcreator.me/tags/Share/"}]},{"title":"英语之美","date":"2016-12-30T16:02:05.000Z","path":"2016/12/31/MyView/English/view-of-english/","text":"图文来源：金山词霸 英语功夫 自知者明 自胜者强 He who knows others is learned, and he who knows himself is wise. To conquer yourself is more powerful than to defeat other people. 学以致用 知行合一 Study serve the practical purpose. Knowledge is action, action is knowledge. 不忘初心 方得始终 Don’t forget why start off, otherwise it is difficult to achieve the ultimate goal. Many people start a career with a dream, then get busy forgetting it.很多人一开始为了梦想而忙，后来忙得忘了梦想。 You are never too old to set another goal or to dream a new dream. 再设一个目标或拥有一个新梦想永远都不晚。 “Without purpose, the days would have ended, as such days always end, in disintegration.” – Explorer 「少了目标，一天还是会结束，它总是以支离破碎的形式结束。」 – 理查‧伯德 (探险家) “If you set your goals ridiculously high and it’s a failure, you will fail above everyone else’s success.”– James Cameron, Filmmaker「如果你把目标设的不可思议的高，然后失败了，你的失败也会是在别人的成功之上。」– 詹姆斯·卡麦隆 (导演) “Our plans miscarry because they have no aim. If one does not know to which port one is sailing, no wind is favorable.”– Lucius Annaeus Seneca, Philosopher「我们的计划不成功是因为没有目标，一个人若不知道他要航向哪个港口，没有风向会是顺风的。」– 塞内卡 (哲学家) Be yourself, don’t change for anyone. If they don’t like you at your worst, then they don’t deserve you at your best.勇敢的做自己，不要为任何人而改变。如果他们不能接受最差的你，也不配拥有最好的你。 Life is like angry birds.There are always several pigs laughing when you lose.人生就像愤怒的小鸟，当你失败时，总有几头猪在笑！ A reader lives a thousand lives before he dies… The man who never reads lives only one.阅读的人在临终前经历了一千个人生…… 从不阅读的人只经历一个人生。 “一日不读书，无人看得出；一周不读书，开始会爆粗；一月不读书，智商输给猪。” 孔子语录英文版 性相近也，习相远也。 By nature, men are nearly alike; by practice, they get to be wide apart. 过而不改，是谓过矣。 Not to mend the fault one has made is to err indeed. 己所不欲，勿施于人。 What you do not want done to yourself, do not do to others. 言必信，行必果。 Keep what you say and carry out what you do. 君子以文会友，以友辅仁。 The superior man on grounds of culture meets with his friends, and by their friendship helps his virtue. 三军可夺帅也，匹夫不可夺志也。 The commander of the forces of a large State may be carried off, but the will of even a common man cannot be taken from him. 后生可畏，焉知来者之不如今也？ A youth is to be regarded with respect. How do you know that his future will not be equal to our present? 有朋自远方来，不亦乐乎？ Is it not delightful to have friends coming from distant quarters? 人不知而不愠，不亦君子乎？ Is he not a man of complete virtue, who feels no discomposure though men may take no note of him? 父在，观其志。父没，观其行。三年无改于父之道，可谓孝矣。 While a man’s father is alive, look at the bent of his will; when his father is dead, look at his conduct. If for three years he does not alter from the way of his father, he may be called filial. 不患人之不己知，患不知人也。 I will not be afflicted at men’s not knowing me; I will be afflicted that I do not know men. 诗三百，一言以蔽之，曰：思无邪。 In the Book of Poetry are three hundred pieces, but the design of them all may be embraced in one sentence– “Having no depraved thoughts.” 关睢乐而不淫，哀而不伤。 The Kwan Tsu is expressive of enjoyment without being licentious, and of grief without being hurtfully excessive. 父母在，不远游，游必有方。 While his parents are alive, the son may not go abroad to a distance. If he does go abroad, he must have a fixed place to which he goes. 德不孤，必有邻。 Virtue is not left to stand alone. He who practices it will have neighbors. 吾十有五而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲，不逾矩。 At fifteen I set my heart upon learning. At thirty, I planted my feet firm upon the ground. At forty, I no longer suffered from perplexities. At fifty, I knew what were the biddings of Heaven. At sixty, I heard them with docile ear. At seventy, I could follow the dictates of my own heart; for what I desired no longer overstepped the boundaries of right. 贤哉回也!一箪食，一瓢饮，在陋巷，人不堪其忧，回也不改其乐。贤哉回也! Incomparable indeed was Hui! A handful of rice to eat, a gourdful of water to drink, living in a mean street. Others would have found it unendurable depressing, but to Hui’s cheerfulness it made no difference at all. Incomparable indeed was Hui. 知者乐水，仁者乐山。知者动，仁者静。知者乐，仁者寿。 The wise find pleasure in water; the virtuous find pleasure in hills. The wise are active; the virtuous are tranquil. The wise are joyful; the virtuous are long-lived. 逝者如斯夫，不舍昼夜。 It passes on just like this, not ceasing day or night! 食不厌精，脍不厌细。 He did not dislike to have his rice finely cleaned, nor to have his minced meat cut quite small. 非礼勿视，非礼勿听，非礼勿言，非礼勿动。 Look not at what is contrary to propriety; listen not to what is contrary to propriety; speak not what is contrary to propriety; make no movement which is contrary to propriety. 人无远虑，必有近忧。 If a man take no thought about what is distant, he will find sorrow near at hand. 君子有三戒。少之时，血气未定，戒之在色。及其壮也，血气方刚，戒之在斗。及其老也，血气既衰，戒之在得。 There are three things which the superior man guards against. In youth, when the physical powers, are not yet settled, he guards against lust. When he is strong and the physical powers are full of vigor, he guards against quarrelsomeness. When he is old, and the animal powers are decayed, he guards against covetousness.","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"English","slug":"English","permalink":"http://ipcreator.me/tags/English/"}]},{"title":"欢迎访问我的个人博客","date":"2016-12-30T16:01:06.000Z","path":"2016/12/31/MyView/my-hello-world/","text":"IPCreator = IP + Creator 网易中文博客 Do yourself.Live your life.Fight for your dream. 创新不难、专利有趣学以致用、知行合一自知者明、自胜者强不忘初心、方得始终 明代杨慎《临江仙》 滚滚长江东逝水，浪花淘尽英雄。是非成败转头空。青山依旧在，几度夕阳红。白发渔樵江渚上，惯看秋月春风。一壶浊酒喜相逢。古今多少事，都付笑谈中。 明代唐伯虎：《桃花庵歌》 桃花坞里桃明代花庵，桃花庵里桃花仙；桃花仙人种桃树，又摘桃花换酒钱。酒醒只在花间坐，酒醉还来花下眠；半醒半醉日复日，花开花落年复年。但愿老死花酒间，不愿鞠躬车马前；车尘马足贵者趣，酒盏花枝贫者缘。若将贫贱比贫者，一在平地一在天；若将贫贱比车马，他得驱驰我得闲。别人笑我太疯癫，我笑他人看不穿；不见五陵豪杰墓，无花无酒锄作田。 李笑来：Hello World学习其实只不过是一种生活方式，否则为什么会有的人就是停不下来呢？学习不需要坚持、不需要毅力、不需要信念，不需要各种“不得已而为之的概念”，它只不过是一种选择，一个一旦真选了就再也不可逆的选择。仅此而已。 123while (alive) &#123; learn();&#125; 嗯，七年就是一辈子，干嘛不玩得高兴一点？","comments":true,"categories":[{"name":"个人","slug":"个人","permalink":"http://ipcreator.me/categories/个人/"}],"tags":[{"name":"Growing Up","slug":"Growing-Up","permalink":"http://ipcreator.me/tags/Growing-Up/"}]}]